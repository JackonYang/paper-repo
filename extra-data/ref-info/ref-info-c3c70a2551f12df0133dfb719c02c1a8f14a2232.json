{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729896"
                        ],
                        "name": "Sergi Robles Mestre",
                        "slug": "Sergi-Robles-Mestre",
                        "structuredName": {
                            "firstName": "Sergi",
                            "lastName": "Mestre",
                            "middleNames": [
                                "Robles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergi Robles Mestre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 235
                            }
                        ],
                        "text": "It should also be noted, that contrary to other initiatives, it was not originally conceived as a fullyfledged platform, but it has evolved responding to the needs of a particular research community as we perceived them over the years [21]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 18738539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "928d2eda05c1a70b26a28806f76a82fe09adf0a1",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a set of on-line software tools for creating ground truth and calculating performance evaluation metrics for text extraction tasks such as localization, segmentation and recognition. The platform supports the definition of comprehensive ground truth information at different text representation levels while it offers centralised management and quality control of the ground truthing effort. It implements a range of state of the art performance evaluation algorithms and offers functionality for the definition of evaluation scenarios, on-line calculation of various performance metrics and visualisation of the results. The presented platform, which comprises the backbone of the ICDAR 2011 (challenge 1) and 2013 (challenges 1 and 2) Robust Reading competitions, is now made available for public use."
            },
            "slug": "An-on-line-platform-for-ground-truthing-and-of-text-Karatzas-Mestre",
            "title": {
                "fragments": [],
                "text": "An on-line platform for ground truthing and performance evaluation of text extraction systems"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The presented platform implements a range of state of the art performance evaluation algorithms and offers functionality for the definition of evaluation scenarios, on-line calculation of various performance metrics and visualisation of the results."
            },
            "venue": {
                "fragments": [],
                "text": "2014 11th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] initially focusing only on scene text detection and recognition, and was later extended to include challenges on borndigital images [2], video sequences [3], and incidental scene text [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6379469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce39eb5cc1049a1060a499d6b6e94c8b2ec11da1",
            "isKey": false,
            "numCitedBy": 592,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the robust reading competitions forICDAR 2003. With the rapid growth in research over thelast few years on recognizing text in natural scenes, thereis an urgent need to establish some common benchmarkdatasets, and gain a clear understanding of the current stateof the art. We use the term robust reading to refer to text imagesthat are beyond the capabilities of current commercialOCR packages. We chose to break down the robust readingproblem into three sub-problems, and run competitionsfor each stage, and also a competition for the best overallsystem. The sub-problems we chose were text locating,character recognition and word recognition.By breaking down the problem in this way, we hope togain a better understanding of the state of the art in eachof the sub-problems. Furthermore, our methodology involvesstoring detailed results of applying each algorithm toeach image in the data sets, allowing researchers to study indepth the strengths and weaknesses of each algorithm. Thetext locating contest was the only one to have any entries.We report the results of this contest, and show cases wherethe leading algorithms succeed and fail."
            },
            "slug": "ICDAR-2003-robust-reading-competitions-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The robust reading problem was broken down into three sub-problems, and competitions for each stage, and also a competition for the best overall system, which was the only one to have any entries."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098117"
                        ],
                        "name": "Anguelos Nicolaou",
                        "slug": "Anguelos-Nicolaou",
                        "structuredName": {
                            "firstName": "Anguelos",
                            "lastName": "Nicolaou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anguelos Nicolaou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39937691"
                        ],
                        "name": "Suman K. Ghosh",
                        "slug": "Suman-K.-Ghosh",
                        "structuredName": {
                            "firstName": "Suman",
                            "lastName": "Ghosh",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suman K. Ghosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749498"
                        ],
                        "name": "Andrew D. Bagdanov",
                        "slug": "Andrew-D.-Bagdanov",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bagdanov",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew D. Bagdanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802086"
                        ],
                        "name": "V. Chandrasekhar",
                        "slug": "V.-Chandrasekhar",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Chandrasekhar",
                            "middleNames": [
                                "Ramaseshan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandrasekhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771189"
                        ],
                        "name": "Shijian Lu",
                        "slug": "Shijian-Lu",
                        "structuredName": {
                            "firstName": "Shijian",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijian Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809705"
                        ],
                        "name": "S. Uchida",
                        "slug": "S.-Uchida",
                        "structuredName": {
                            "firstName": "Seiichi",
                            "lastName": "Uchida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2864362"
                        ],
                        "name": "Ernest Valveny",
                        "slug": "Ernest-Valveny",
                        "structuredName": {
                            "firstName": "Ernest",
                            "lastName": "Valveny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernest Valveny"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 188
                            }
                        ],
                        "text": "[1] initially focusing only on scene text detection and recognition, and was later extended to include challenges on borndigital images [2], video sequences [3], and incidental scene text [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13322740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b02f729e6d442f6872078f599fc9da5c3605cee",
            "isKey": false,
            "numCitedBy": 787,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Results of the ICDAR 2015 Robust Reading Competition are presented. A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text. Challenge 4 is run on a newly acquired dataset of 1,670 images evaluating Text Localisation, Word Recognition and End-to-End pipelines. In addition, the dataset for Challenge 3 on Video Text has been substantially updated with more video sequences and more accurate ground truth data. Finally, tasks assessing End-to-End system performance have been introduced to all Challenges. The competition took place in the first quarter of 2015, and received a total of 44 submissions. Only the tasks newly introduced in 2015 are reported on. The datasets, the ground truth specification and the evaluation protocols are presented together with the results and a brief summary of the participating methods."
            },
            "slug": "ICDAR-2015-competition-on-Robust-Reading-Karatzas-Bigorda",
            "title": {
                "fragments": [],
                "text": "ICDAR 2015 competition on Robust Reading"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new Challenge 4 on Incidental Scene Text has been added to the Challenges on Born-Digital Images, Focused Scene Images and Video Text and tasks assessing End-to-End system performance have been introduced to all Challenges."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 247
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 528469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "feaee4dbf7ed20387cc2fc400669aff9d2f99267",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Large-scale digitisation has led to a number of new possibilities with regard to adaptive and learning based methods in the field of Document Image Analysis and OCR. For ground truth production of large corpora, however, there is still a gap in terms of productivity. Ground truth is not only crucial for training and evaluation at the development stage of tools but also for quality assurance in the scope of production workflows for digital libraries. This paper describes Aletheia, an advanced system for accurate and yet cost-effective ground truthing of large amounts of documents. It aids the user with a number of automated and semi-automated tools which were partly developed and improved based on feedback from major libraries across Europe and from their digitisation service providers which are using the tool in a production environment. Novel features are, among others, the support of top-down ground truthing with sophisticated split and shrink tools as well as bottom-up ground truthing supporting the aggregation of lower-level elements to more complex structures. Special features have been developed to support working with the complexities of historical documents. The integrated rules and guidelines validator, in combination with powerful correction tools, enable efficient production of highly accurate ground truth."
            },
            "slug": "Aletheia-An-Advanced-Document-Layout-and-Text-for-Clausner-Pletschacher",
            "title": {
                "fragments": [],
                "text": "Aletheia - An Advanced Document Layout and Text Ground-Truthing System for Production Environments"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Aletheia is described, an advanced system for accurate and yet cost-effective ground truthing of large amounts of documents which aids the user with a number of automated and semi-automated tools which were partly developed and improved based on feedback from major libraries across Europe and from their digitisation service providers which are using the tool in a production environment."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170742"
                        ],
                        "name": "Nibal Nayef",
                        "slug": "Nibal-Nayef",
                        "structuredName": {
                            "firstName": "Nibal",
                            "lastName": "Nayef",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nibal Nayef"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2670280"
                        ],
                        "name": "Imen Bizid",
                        "slug": "Imen-Bizid",
                        "structuredName": {
                            "firstName": "Imen",
                            "lastName": "Bizid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Imen Bizid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111539105"
                        ],
                        "name": "Hyunsoo Choi",
                        "slug": "Hyunsoo-Choi",
                        "structuredName": {
                            "firstName": "Hyunsoo",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyunsoo Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150671031"
                        ],
                        "name": "Yuan Feng",
                        "slug": "Yuan-Feng",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2637107"
                        ],
                        "name": "Zhenbo Luo",
                        "slug": "Zhenbo-Luo",
                        "structuredName": {
                            "firstName": "Zhenbo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhenbo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153476282"
                        ],
                        "name": "Christophe Rigaud",
                        "slug": "Christophe-Rigaud",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Rigaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Rigaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2726424"
                        ],
                        "name": "Joseph Chazalon",
                        "slug": "Joseph-Chazalon",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Chazalon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Chazalon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2712108"
                        ],
                        "name": "Wafa Khlif",
                        "slug": "Wafa-Khlif",
                        "structuredName": {
                            "firstName": "Wafa",
                            "lastName": "Khlif",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wafa Khlif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120439"
                        ],
                        "name": "M. Luqman",
                        "slug": "M.-Luqman",
                        "structuredName": {
                            "firstName": "Muhammad",
                            "lastName": "Luqman",
                            "middleNames": [
                                "Muzzamil"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Luqman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690398"
                        ],
                        "name": "J. Burie",
                        "slug": "J.-Burie",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Burie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 520,
                                "start": 517
                            }
                        ],
                        "text": "The 2017 edition of the Competition introduced five new challenges on: scene text detection and recognition based on the COCO-Text dataset [5]; text extraction from biomedical literature figures based on the DeText dataset [6]; video scene text localization and recognition on the Downtown Osaka Scene Text (DOST) dataset [7]; constrained real world end-to-end scene-text understanding based on the > 1M images French Street Name Signs (FSNS) dataset [8]; Multi-lingual scene text detection and script identification [9]; and information extraction in historical handwritten records [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4761162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d899525e35ef784afd2aeeac977d7bb361fd7092",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection and recognition in a natural environment are key components of many applications, ranging from business card digitization to shop indexation in a street. This competition aims at assessing the ability of state-of-the-art methods to detect Multi-Lingual Text (MLT) in scene images, such as in contents gathered from the Internet media and in modern cities where multiple cultures live and communicate together. This competition is an extension of the Robust Reading Competition (RRC) which has been held since 2003 both in ICDAR and in an online context. The proposed competition is presented as a new challenge of the RRC. The dataset built for this challenge largely extends the previous RRC editions in many aspects: the multi-lingual text, the size of the dataset, the multi-oriented text, the wide variety of scenes. The dataset is comprised of 18,000 images which contain text belonging to 9 languages. The challenge is comprised of three tasks related to text detection and script classification. We have received a total of 16 participations from the research and industrial communities. This paper presents the dataset, the tasks and the findings of this RRC-MLT challenge."
            },
            "slug": "ICDAR2017-Robust-Reading-Challenge-on-Multi-Lingual-Nayef-Yin",
            "title": {
                "fragments": [],
                "text": "ICDAR2017 Robust Reading Challenge on Multi-Lingual Scene Text Detection and Script Identification - RRC-MLT"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper presents the dataset, the tasks and the findings of this RRC-MLT challenge, which aims at assessing the ability of state-of-the-art methods to detect Multi-Lingual Text in scene images, such as in contents gathered from the Internet media and in modern cities where multiple cultures live and communicate together."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688013"
                        ],
                        "name": "F. Shafait",
                        "slug": "F.-Shafait",
                        "structuredName": {
                            "firstName": "Faisal",
                            "lastName": "Shafait",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Shafait"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809705"
                        ],
                        "name": "S. Uchida",
                        "slug": "S.-Uchida",
                        "structuredName": {
                            "firstName": "Seiichi",
                            "lastName": "Uchida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Uchida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729896"
                        ],
                        "name": "Sergi Robles Mestre",
                        "slug": "Sergi-Robles-Mestre",
                        "structuredName": {
                            "firstName": "Sergi",
                            "lastName": "Mestre",
                            "middleNames": [
                                "Robles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergi Robles Mestre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40016884"
                        ],
                        "name": "J. M. Romeu",
                        "slug": "J.-M.-Romeu",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Romeu",
                            "middleNames": [
                                "Mas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Romeu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50313341"
                        ],
                        "name": "D. F. Mota",
                        "slug": "D.-F.-Mota",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mota",
                            "middleNames": [
                                "Fern\u00e1ndez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. F. Mota"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467588"
                        ],
                        "name": "Jon Almaz\u00e1n",
                        "slug": "Jon-Almaz\u00e1n",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Almaz\u00e1n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jon Almaz\u00e1n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578506"
                        ],
                        "name": "Llu\u00eds-Pere de las Heras",
                        "slug": "Llu\u00eds-Pere-de-las-Heras",
                        "structuredName": {
                            "firstName": "Llu\u00eds-Pere",
                            "lastName": "Heras",
                            "middleNames": [
                                "de",
                                "las"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds-Pere de las Heras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "[1] initially focusing only on scene text detection and recognition, and was later extended to include challenges on borndigital images [2], video sequences [3], and incidental scene text [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206777226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcd7b547bf0a6646a282f521db880e74974aa838",
            "isKey": false,
            "numCitedBy": 886,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the final results of the ICDAR 2013 Robust Reading Competition. The competition is structured in three Challenges addressing text extraction in different application domains, namely born-digital images, real scene images and real-scene videos. The Challenges are organised around specific tasks covering text localisation, text segmentation and word recognition. The competition took place in the first quarter of 2013, and received a total of 42 submissions over the different tasks offered. This report describes the datasets and ground truth specification, details the performance evaluation protocols used and presents the final results along with a brief summary of the participating methods."
            },
            "slug": "ICDAR-2013-Robust-Reading-Competition-Karatzas-Shafait",
            "title": {
                "fragments": [],
                "text": "ICDAR 2013 Robust Reading Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The datasets and ground truth specification are described, the performance evaluation protocols used are details, and the final results are presented along with a brief summary of the participating methods."
            },
            "venue": {
                "fragments": [],
                "text": "2013 12th International Conference on Document Analysis and Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801759"
                        ],
                        "name": "B. Lamiroy",
                        "slug": "B.-Lamiroy",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Lamiroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lamiroy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "In terms of more generic frameworks, the Document Annotation and Exploitation (DAE)8 platform [18], [19] consists of a repository for document images, implementations of algorithms and their results when applied to data in the repository."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206600783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4a015a6a7880b44b823b2ab3c7cd21d6b64365c",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The Document Analysis and Exploitation platform is a sophisticated technical environment that consists of a repository containing document images, implementations of document analysis algorithms, and the results of these algorithms when applied to data in the repository. The use of a web services model makes it possible to set up document analysis pipelines that form the basis for reproducible protocols. Since the platform keeps track of all intermediate results, it becomes an information resource for the analysis of experimental data. This paper provides a tutorial on how to get started using the platform. It covers the technical details needed to overcome the initial hurdles and have a productive experience with DAE."
            },
            "slug": "The-Non-geek's-Guide-to-the-DAE-Platform-Lamiroy-Lopresti",
            "title": {
                "fragments": [],
                "text": "The Non-geek's Guide to the DAE Platform"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper provides a tutorial on how to get started using the Document Analysis and Exploitation platform and covers the technical details needed to overcome the initial hurdles and have a productive experience with DAE."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3424460"
                        ],
                        "name": "Marcel W\u00fcrsch",
                        "slug": "Marcel-W\u00fcrsch",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "W\u00fcrsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcel W\u00fcrsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "The more recent DIVAServices framework [20], is retake on the DAE idea, using a RESTful Web service architecture."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38891502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f2731d21e77ec3b8ecdbc537b771198faf23e37",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article we present a web service framework providing automatic document processing methods to the public. Furthermore, an assessment environment and sample applications using this framework are briefly described. Research on Document Image Analysis (DIA) focuses mainly on developing and refining automatic processing steps, e.g. text line extraction, binarization, and layout analysis. While many state-of-the-art methods perform satisfactorily, the algorithms applied to obtain the results are not easily accessible for other researchers. Making the source code available is often not sufficient as it typically requires a cumbersome installation of required libraries and reading long manuals about the usage. We present a new approach for making methods available to researchers in the digital humanities without detailed knowledge of the algorithms.\n\nFor our approach we propose a RESTful web service architecture, the current state of the art in online web communication. For a developer this reduces the steps needed to access a method to sending and receiving HTTP requests with Java Script Object Notification data, removing all installation steps. We will build on standards such as the Text Encoding Initiative and the International Image Interoperability Framework. Thus, methods hosted on DivaServices can be integrated easily into document processing workflows by any software engineer in computer science, but also the digital humanities without specific knowledge of the mathematical and algorithmic details of DIA."
            },
            "slug": "DivaServices-A-RESTful-web-service-for-Document-W\u00fcrsch-Ingold",
            "title": {
                "fragments": [],
                "text": "DivaServices - A RESTful web service for Document Image Analysis methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new approach for making methods available to researchers in the digital humanities without detailed knowledge of the algorithms of DIA is presented, and a RESTful web service architecture, the current state of the art in online web communication is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Digit. Scholarsh. Humanit."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093215205"
                        ],
                        "name": "Raul Gomez",
                        "slug": "Raul-Gomez",
                        "structuredName": {
                            "firstName": "Raul",
                            "lastName": "Gomez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raul Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276155"
                        ],
                        "name": "Baoguang Shi",
                        "slug": "Baoguang-Shi",
                        "structuredName": {
                            "firstName": "Baoguang",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baoguang Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532509"
                        ],
                        "name": "Luk\u00e1s Neumann",
                        "slug": "Luk\u00e1s-Neumann",
                        "structuredName": {
                            "firstName": "Luk\u00e1s",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luk\u00e1s Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799898"
                        ],
                        "name": "Andreas Veit",
                        "slug": "Andreas-Veit",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Veit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Veit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "The 2017 edition of the Competition introduced five new challenges on: scene text detection and recognition based on the COCO-Text dataset [5]; text extraction from biomedical literature figures based on the DeText dataset [6]; video scene text localization and recognition on the Downtown Osaka Scene Text (DOST) dataset [7]; constrained real world end-to-end scene-text understanding based on the > 1M images French Street Name Signs (FSNS) dataset [8]; Multi-lingual scene text detection and script identification [9]; and information extraction in historical handwritten records [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4705150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c76352dd5003e20b942f6c5586a9961994b98163",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This report presents the final results of the ICDAR 2017 Robust Reading Challenge on COCO-Text. A challenge on scene text detection and recognition based on the largest real scene text dataset currently available: the COCO-Text dataset. The competition is structured around three tasks: Text Localization, Cropped Word Recognition and End-To-End Recognition. The competition received a total of 27 submissions over the different opened tasks. This report describes the datasets and the ground truth, details the performance evaluation protocols used and presents the final results along with a brief summary of the participating methods."
            },
            "slug": "ICDAR2017-Robust-Reading-Challenge-on-COCO-Text-Gomez-Shi",
            "title": {
                "fragments": [],
                "text": "ICDAR2017 Robust Reading Challenge on COCO-Text"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The datasets and the ground truth are described, the performance evaluation protocols used are detailed and the final results are presented along with a brief summary of the participating methods."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109112009"
                        ],
                        "name": "Chang Ha Lee",
                        "slug": "Chang-Ha-Lee",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Lee",
                            "middleNames": [
                                "Ha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chang Ha Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5763610,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13a4f8e6231612e67d0acd85d15ab82c8214f305",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-architecture-of-TrueViz:-a-groundTRUth/metadata-Lee-Kanungo",
            "title": {
                "fragments": [],
                "text": "The architecture of TrueViz: a groundTRUth/metadata editing and VIsualiZing ToolKit"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2729896"
                        ],
                        "name": "Sergi Robles Mestre",
                        "slug": "Sergi-Robles-Mestre",
                        "structuredName": {
                            "firstName": "Sergi",
                            "lastName": "Mestre",
                            "middleNames": [
                                "Robles"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergi Robles Mestre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40016884"
                        ],
                        "name": "J. M. Romeu",
                        "slug": "J.-M.-Romeu",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Romeu",
                            "middleNames": [
                                "Mas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Romeu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38417650"
                        ],
                        "name": "F. Nourbakhsh",
                        "slug": "F.-Nourbakhsh",
                        "structuredName": {
                            "firstName": "Farshad",
                            "lastName": "Nourbakhsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Nourbakhsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40813600"
                        ],
                        "name": "P. Roy",
                        "slug": "P.-Roy",
                        "structuredName": {
                            "firstName": "Partha",
                            "lastName": "Roy",
                            "middleNames": [
                                "Pratim"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "[1] initially focusing only on scene text detection and recognition, and was later extended to include challenges on borndigital images [2], video sequences [3], and incidental scene text [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4377688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c507148d502245c459df2ec883dc02fabc0ecad",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of the first Challenge of ICDAR 2011 Robust Reading Competition. Challenge 1 is focused on the extraction of text from born-digital images, specifically from images found in Web pages and emails. The challenge was organized in terms of three tasks that look at different stages of the process: text localization, text segmentation and word recognition. In this paper we present the results of the challenge for all three tasks, and make an open call for continuous participation outside the context of ICDAR 2011."
            },
            "slug": "ICDAR-2011-Robust-Reading-Competition-Challenge-1:-Karatzas-Mestre",
            "title": {
                "fragments": [],
                "text": "ICDAR 2011 Robust Reading Competition - Challenge 1: Reading Text in Born-Digital Images (Web and Email)"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper presents the results of the first Challenge of ICDAR 2011 Robust Reading Competition, focused on the extraction of text from born-digital images, specifically from images found in Web pages and emails."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144322499"
                        ],
                        "name": "D. Bridson",
                        "slug": "D.-Bridson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bridson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bridson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 253
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14185946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0165d47727ddb97f3b2b056e1754f15ee6fb6d43",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past two decades a significant number of layout analysis (page segmentation and region classification) approaches have been proposed in the literature. Each approach has been devised for and/or evaluated using (usually small) application-specific datasets. While the need for objective performance evaluation of layout analysis algorithms is evident, there does not exist a suitable dataset with ground truth that reflects the realities of everyday documents (widely varying layouts, complex entities, colour, noise etc.). The most significant impediment is the creation of accurate and flexible (in representation) ground truth, a task that is costly and must be carefully designed. This paper discusses the issues related to the design, representation and creation of ground truth in the context of a realistic dataset developed by the authors. The effectiveness of the ground truth discussed in this paper has been successfully shown in its use for two international page segmentation competitions (ICDAR2003 and ICDAR2005)."
            },
            "slug": "Ground-Truth-for-Layout-Analysis-Performance-Antonacopoulos-Karatzas",
            "title": {
                "fragments": [],
                "text": "Ground Truth for Layout Analysis Performance Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The effectiveness of the ground truth discussed in this paper has been successfully shown in its use for two international page segmentation competitions (ICDAR2003 and ICDAR2005)."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757030"
                        ],
                        "name": "Berrin A. Yanikoglu",
                        "slug": "Berrin-A.-Yanikoglu",
                        "structuredName": {
                            "firstName": "Berrin",
                            "lastName": "Yanikoglu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berrin A. Yanikoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820595"
                        ],
                        "name": "L. Vincent",
                        "slug": "L.-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8690249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3125b0dd9affad0ddcaa6dc2e26b0b45f5d304f",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pink-Panther:-A-Complete-Environment-For-And-Page-Yanikoglu-Vincent",
            "title": {
                "fragments": [],
                "text": "Pink Panther: A Complete Environment For Ground-Truthing And Benchmarking Document Page Segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732764"
                        ],
                        "name": "S. Yacoub",
                        "slug": "S.-Yacoub",
                        "structuredName": {
                            "firstName": "Sherif",
                            "lastName": "Yacoub",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yacoub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066296059"
                        ],
                        "name": "Vinay Saxena",
                        "slug": "Vinay-Saxena",
                        "structuredName": {
                            "firstName": "Vinay",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinay Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392697693"
                        ],
                        "name": "Sayeed Nusrulla Sami",
                        "slug": "Sayeed-Nusrulla-Sami",
                        "structuredName": {
                            "firstName": "Sayeed",
                            "lastName": "Sami",
                            "middleNames": [
                                "Nusrulla"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sayeed Nusrulla Sami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206776598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4dd58dcc8c151ef44f006e92b2154cdff75f694",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present PerfectDoc; a ground truthing and document correction tool. The tool provides post processing correction capabilities that are required after complex document analysis and understanding tasks. The tool has the advantage of being comprehensive (integration of most common correction tasks), easy to use (minimal clicks for corrections), configurable (can be used for different types of documents), and provides separate correction views. We used the tool to correct the output from a document understanding system used to extract articles from 80-years archive of Time weekly magazine."
            },
            "slug": "PerfectDoc:-a-ground-truthing-environment-for-Yacoub-Saxena",
            "title": {
                "fragments": [],
                "text": "PerfectDoc: a ground truthing environment for complex documents"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "The PerfectDoc tool is presented; a ground truthing and document correction tool that provides post processing correction capabilities that are required after complex document analysis and understanding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154925588"
                        ],
                        "name": "Chun Yang",
                        "slug": "Chun-Yang",
                        "structuredName": {
                            "firstName": "Chun",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682664"
                        ],
                        "name": "Xu-Cheng Yin",
                        "slug": "Xu-Cheng-Yin",
                        "structuredName": {
                            "firstName": "Xu-Cheng",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xu-Cheng Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145174375"
                        ],
                        "name": "Hong Yu",
                        "slug": "Hong-Yu",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144149886"
                        ],
                        "name": "Yu Cao",
                        "slug": "Yu-Cao",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Cao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 223
                            }
                        ],
                        "text": "The 2017 edition of the Competition introduced five new challenges on: scene text detection and recognition based on the COCO-Text dataset [5]; text extraction from biomedical literature figures based on the DeText dataset [6]; video scene text localization and recognition on the Downtown Osaka Scene Text (DOST) dataset [7]; constrained real world end-to-end scene-text understanding based on the > 1M images French Street Name Signs (FSNS) dataset [8]; Multi-lingual scene text detection and script identification [9]; and information extraction in historical handwritten records [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30356427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c56da136b8d62125009a131f6dc21fcd0dd6a559",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Hundreds of millions of figures are available in the biomedical literature, representing important biomedical experimental evidence. Since text is a rich source of information in figures, automatically extracting such text may assist in the task of mining figure information and understanding biomedical documents. Unlike images in the open domain, biomedical figures present a variety of unique challenges. For example, biomedical figures typically have complex layouts, small font sizes, short text, specific text, complex symbols and irregular text arrangements. This paper presents the final results of the ICDAR 2017 Competition on Text Extraction from Biomedical Literature Figures (ICDAR2017 DeTEXT Competition), which aims at extracting (detecting and recognizing) text from biomedical literature figures. Similar to text extraction from scene images and web pictures, ICDAR2017 DeTEXT Competition includes three major tasks, i.e., text detection, cropped word recognition and end-to-end text recognition. Here, we describe in detail the data set, tasks, evaluation protocols and participants of this competition, and report the performance of the participating methods."
            },
            "slug": "ICDAR2017-Robust-Reading-Challenge-on-Text-from-Yang-Yin",
            "title": {
                "fragments": [],
                "text": "ICDAR2017 Robust Reading Challenge on Text Extraction from Biomedical Literature Figures (DeTEXT)"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The final results of the ICDAR 2017 Competition on Text Extraction from Biomedical Literature Figures (ICDAR2017 DeTEXT Competition), which aims at extracting (detecting and recognizing) text from biomedical literature figures, are presented."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056126626"
                        ],
                        "name": "Wontaek Seo",
                        "slug": "Wontaek-Seo",
                        "structuredName": {
                            "firstName": "Wontaek",
                            "lastName": "Seo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wontaek Seo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40078651"
                        ],
                        "name": "Mudit Agrawal",
                        "slug": "Mudit-Agrawal",
                        "structuredName": {
                            "firstName": "Mudit",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mudit Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9690930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a65cb30aaf625ab2977c5945dab6f4b313e26df",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a set of Performance Evaluation Tools (PETS) for document image zone segmentation and classification. The tools allow researchers and developers to evaluate, optimize and compare their algorithms by providing a variety of quantitative performance metrics. The evaluation of segmentation quality is based on the pixel-based overlaps between two sets of zones proposed by Randriamasy and Vincent. PETS extends the approach by providing a set of metrics for overlap analysis, RLE and polygonal representation of zones and introduces type-matching to evaluate zone classification. The software is available for research use."
            },
            "slug": "Performance-Evaluation-Tools-for-Zone-Segmentation-Seo-Agrawal",
            "title": {
                "fragments": [],
                "text": "Performance Evaluation Tools for Zone Segmentation and Classification (PETS)"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A set of Performance Evaluation Tools (PETS) for document image zone segmentation and classification that provides a set of metrics for overlap analysis, RLE and polygonal representation of zones and introduces type-matching to evaluate zone classification."
            },
            "venue": {
                "fragments": [],
                "text": "2010 20th International Conference on Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686569"
                        ],
                        "name": "A. Forn\u00e9s",
                        "slug": "A.-Forn\u00e9s",
                        "structuredName": {
                            "firstName": "Alicia",
                            "lastName": "Forn\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Forn\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144340605"
                        ],
                        "name": "Ver\u00f3nica Romero",
                        "slug": "Ver\u00f3nica-Romero",
                        "structuredName": {
                            "firstName": "Ver\u00f3nica",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ver\u00f3nica Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882773"
                        ],
                        "name": "Arnau Bar\u00f3",
                        "slug": "Arnau-Bar\u00f3",
                        "structuredName": {
                            "firstName": "Arnau",
                            "lastName": "Bar\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnau Bar\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46408430"
                        ],
                        "name": "J. I. Toledo",
                        "slug": "J.-I.-Toledo",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Toledo",
                            "middleNames": [
                                "Ignacio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. I. Toledo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1928123"
                        ],
                        "name": "Joan-Andreu S\u00e1nchez",
                        "slug": "Joan-Andreu-S\u00e1nchez",
                        "structuredName": {
                            "firstName": "Joan-Andreu",
                            "lastName": "S\u00e1nchez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan-Andreu S\u00e1nchez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143783065"
                        ],
                        "name": "E. Vidal",
                        "slug": "E.-Vidal",
                        "structuredName": {
                            "firstName": "Enrique",
                            "lastName": "Vidal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vidal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 587,
                                "start": 583
                            }
                        ],
                        "text": "The 2017 edition of the Competition introduced five new challenges on: scene text detection and recognition based on the COCO-Text dataset [5]; text extraction from biomedical literature figures based on the DeText dataset [6]; video scene text localization and recognition on the Downtown Osaka Scene Text (DOST) dataset [7]; constrained real world end-to-end scene-text understanding based on the > 1M images French Street Name Signs (FSNS) dataset [8]; Multi-lingual scene text detection and script identification [9]; and information extraction in historical handwritten records [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10834633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c365ae3c5e5f2d7dbeaad961af6352ce575b8863",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The extraction of relevant information from historical handwritten document collections is one of the key steps in order to make these manuscripts available for access and searches. In this competition, the goal is to detect the named entities and assign each of them a semantic category, and therefore, to simulate the filling in of a knowledge database. This paper describes the dataset, the tasks, the evaluation metrics, the participants methods and the results."
            },
            "slug": "ICDAR2017-Competition-on-Information-Extraction-in-Forn\u00e9s-Romero",
            "title": {
                "fragments": [],
                "text": "ICDAR2017 Competition on Information Extraction in Historical Handwritten Records"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal is to detect the named entities and assign each of them a semantic category, and therefore, to simulate the filling in of a knowledge database."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35613969"
                        ],
                        "name": "M. Iwamura",
                        "slug": "M.-Iwamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Iwamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Iwamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066653143"
                        ],
                        "name": "Naoyuki Morimoto",
                        "slug": "Naoyuki-Morimoto",
                        "structuredName": {
                            "firstName": "Naoyuki",
                            "lastName": "Morimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naoyuki Morimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47835956"
                        ],
                        "name": "Keishi Tainaka",
                        "slug": "Keishi-Tainaka",
                        "structuredName": {
                            "firstName": "Keishi",
                            "lastName": "Tainaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keishi Tainaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2644209"
                        ],
                        "name": "Dena Bazazian",
                        "slug": "Dena-Bazazian",
                        "structuredName": {
                            "firstName": "Dena",
                            "lastName": "Bazazian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dena Bazazian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730090"
                        ],
                        "name": "L. G. I. Bigorda",
                        "slug": "L.-G.-I.-Bigorda",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Bigorda",
                            "middleNames": [
                                "G\u00f3mez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. G. I. Bigorda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694974"
                        ],
                        "name": "Dimosthenis Karatzas",
                        "slug": "Dimosthenis-Karatzas",
                        "structuredName": {
                            "firstName": "Dimosthenis",
                            "lastName": "Karatzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimosthenis Karatzas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 322
                            }
                        ],
                        "text": "The 2017 edition of the Competition introduced five new challenges on: scene text detection and recognition based on the COCO-Text dataset [5]; text extraction from biomedical literature figures based on the DeText dataset [6]; video scene text localization and recognition on the Downtown Osaka Scene Text (DOST) dataset [7]; constrained real world end-to-end scene-text understanding based on the > 1M images French Street Name Signs (FSNS) dataset [8]; Multi-lingual scene text detection and script identification [9]; and information extraction in historical handwritten records [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35495973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fb635801e65a12b5c52085da78152d2df6c2ff2",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Results of ICDAR 2017 Robust Reading Challenge on Omnidirectional Video are presented. This competition uses Downtown Osaka Scene Text (DOST) Dataset that was captured in Osaka, Japan with an omnidirectional camera. Hence, it consists of sequential images (videos) of different view angles. Regarding the sequential images as videos (video mode), two tasks of localisation and end-to-end recognition are prepared. Regarding them as a set of still images (still image mode), three tasks of localisation, cropped word recognition and end-to-end recognition are prepared. As the dataset has been captured in Japan, the dataset contains Japanese text but also include text consisting of alphanumeric characters (Latin text). Hence, a submitted result for each task is evaluated in three ways: using Japanese only ground truth (GT), using Latin only GT and using combined GTs of both. Finally, by the submission deadline, we have received two submissions in the text localisation task of the still image mode. We intend to continue the competition in the open mode. Expecting further submissions, in this report we provide baseline results in all the tasks in addition to the submissions from the community."
            },
            "slug": "ICDAR2017-Robust-Reading-Challenge-on-Video-Iwamura-Morimoto",
            "title": {
                "fragments": [],
                "text": "ICDAR2017 Robust Reading Challenge on Omnidirectional Video"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Results of ICDAR 2017 Robust Reading Challenge on Omnidirectional Video are presented and baseline results in all the tasks are provided in addition to the submissions from the community."
            },
            "venue": {
                "fragments": [],
                "text": "2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801759"
                        ],
                        "name": "B. Lamiroy",
                        "slug": "B.-Lamiroy",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Lamiroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lamiroy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "In terms of more generic frameworks, the Document Annotation and Exploitation (DAE)8 platform [18], [19] consists of a repository for document images, implementations of algorithms and their results when applied to data in the repository."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43084023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e18a598caa8238ca97a4424addb810cb626187",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the DAE Platform in the specific context of reproducible research. DAE was developed at Lehigh University targeted at the Document Image Analysis research community for distributing document images and associated document analysis algorithms, as well as an unlimited range of annotations and \u201cground truth\u201d for benchmarking and evaluation of new contributions to the state-of-the-art."
            },
            "slug": "The-DAE-Platform:-A-Framework-for-Reproducible-in-Lamiroy-Lopresti",
            "title": {
                "fragments": [],
                "text": "The DAE Platform: A Framework for Reproducible Research in Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work presents the DAE Platform in the specific context of reproducible research with an unlimited range of annotations and \u201cground truth\u201d for benchmarking and evaluation of new contributions to the state-of-the-art."
            },
            "venue": {
                "fragments": [],
                "text": "RRPR@ICPR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763321"
                        ],
                        "name": "E. Saund",
                        "slug": "E.-Saund",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Saund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118746573"
                        ],
                        "name": "Jing Lin",
                        "slug": "Jing-Lin",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126187"
                        ],
                        "name": "Prateek Sarkar",
                        "slug": "Prateek-Sarkar",
                        "structuredName": {
                            "firstName": "Prateek",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prateek Sarkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 218
                            }
                        ],
                        "text": "In the particular domain of document image analysis, open tools and platforms for research are a recurrent theme, including over the years attempts like the Pink Panther [11], TrueViz [12], PerfectDoc [13], PixLabeler [14], PETS [15] and Aletheia [16], [17], to mention just a few."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "146c6023d5052f0b7cda864cb9a4332e470b1b45",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a user interface design for labeling elements in document images at a pixel level. Labels are represented by overlay color, which might map to such terms as \u201chandwriting\u201d, \u201cmachine print\u201d, \u201cgraphics\u201d, etc. The primary purpose is to streamline processes for manual production of ground truth data, which is necessary for training algorithms and evaluating performance. Unlike general paint-type programs, the UI design is targeted specifically toward selection of collections of foreground pixels that are likely to be meaningful elements in a document image analysis context. Our implementation, called PixLabeler, is available for download and allows customized plug-ins for bootstrapping according to the labeling task."
            },
            "slug": "PixLabeler:-User-Interface-for-Pixel-Level-Labeling-Saund-Lin",
            "title": {
                "fragments": [],
                "text": "PixLabeler: User Interface for Pixel-Level Labeling of Elements in Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The primary purpose is to streamline processes for manual production of ground truth data, which is necessary for training algorithms and evaluating performance in document image analysis context."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108985360"
                        ],
                        "name": "Raymond W. Smith",
                        "slug": "Raymond-W.-Smith",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Smith",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond W. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39599498"
                        ],
                        "name": "Chunhui Gu",
                        "slug": "Chunhui-Gu",
                        "structuredName": {
                            "firstName": "Chunhui",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunhui Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24344368"
                        ],
                        "name": "Dar-Shyang Lee",
                        "slug": "Dar-Shyang-Lee",
                        "structuredName": {
                            "firstName": "Dar-Shyang",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dar-Shyang Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38488570"
                        ],
                        "name": "Huiyi Hu",
                        "slug": "Huiyi-Hu",
                        "structuredName": {
                            "firstName": "Huiyi",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiyi Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256849"
                        ],
                        "name": "R. Unnikrishnan",
                        "slug": "R.-Unnikrishnan",
                        "structuredName": {
                            "firstName": "Ranjith",
                            "lastName": "Unnikrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Unnikrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46920727"
                        ],
                        "name": "Julian Ibarz",
                        "slug": "Julian-Ibarz",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Ibarz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Ibarz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1911894"
                        ],
                        "name": "Sacha Arnoud",
                        "slug": "Sacha-Arnoud",
                        "structuredName": {
                            "firstName": "Sacha",
                            "lastName": "Arnoud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sacha Arnoud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110496309"
                        ],
                        "name": "Sophia Lin",
                        "slug": "Sophia-Lin",
                        "structuredName": {
                            "firstName": "Sophia",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sophia Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 454,
                                "start": 451
                            }
                        ],
                        "text": "The 2017 edition of the Competition introduced five new challenges on: scene text detection and recognition based on the COCO-Text dataset [5]; text extraction from biomedical literature figures based on the DeText dataset [6]; video scene text localization and recognition on the Downtown Osaka Scene Text (DOST) dataset [7]; constrained real world end-to-end scene-text understanding based on the > 1M images French Street Name Signs (FSNS) dataset [8]; Multi-lingual scene text detection and script identification [9]; and information extraction in historical handwritten records [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2409316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dc4a9010ec77c7c12839865752e7c6e492dbe1f",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the French Street Name Signs (FSNS) Dataset consisting of more than a million images of street name signs cropped from Google Street View images of France. Each image contains several views of the same street name sign. Every image has normalized, title case folded ground-truth text as it would appear on a map. We believe that the FSNS dataset is large and complex enough to train a deep network of significant complexity to solve the street name extraction problem \u201cend-to-end\u201d or to explore the design trade-offs between a single complex engineered network and multiple sub-networks designed and trained to solve sub-problems. We present such an \u201cend-to-end\u201d network/graph for Tensor Flow and its results on the FSNS dataset."
            },
            "slug": "End-to-End-Interpretation-of-the-French-Street-Name-Smith-Gu",
            "title": {
                "fragments": [],
                "text": "End-to-End Interpretation of the French Street Name Signs Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents an \u201cend-to-end\u201d network/graph for Tensor Flow and its results on the FSNS dataset, a large and complex dataset consisting of more than a million images of street name signs cropped from Google Street View images of France."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV Workshops"
            },
            "year": 2016
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 9,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Robust-Reading-Competition-Annotation-and-Karatzas-Bigorda/c3c70a2551f12df0133dfb719c02c1a8f14a2232?sort=total-citations"
}