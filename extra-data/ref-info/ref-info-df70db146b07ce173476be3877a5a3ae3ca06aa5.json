{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60622931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "697c7f995188ef30b8687e4458c2c7fd33163184",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many situations where linguistic and pictorial data are jointly presented to communicate information. In the general case, each of these two sources conveys orthogonal information. A computer model for integrating information from the two sources requires an initial interpretation of both the text and the picture followed by consolidation of information. The problem of performing general-purpose vision without apriori knowledge (needed in such a situation) is nearly impossible. However, in some situations, the text describes salient aspects of the picture. In such situations, it is possible to extract visual information from the text, resulting in a conceptualised graph describing the structure of the accompanying picture. This graph can then be used by a computer vision system in the top-down interpretation of the picture. \nIn this dissertation, a computational model for understanding pictures based on information in accompanying captions is presented. The use of SNePS (Semantic Network Processing System) as the common intermediate representation for both linguistic and pictorial information is discussed. Specifically, we present the knowledge representations and interpretations that comprise the model. \nThe focus of this dissertation is on the generation of a conceptualised graph, a SNePS network which reflects a cognitive agent's conceptualisation of a picture based on information contained in a descriptive caption. This representation includes information about objects appearing in the picture and spatial constraints between them, information used in the subsequent task of labelling objects in the picture. A substantial portion of the dissertation is devoted to techniques of extracting such visual information from text. The techniques are based on both syntactic and semantic considerations. We classify linguistic methods of identifying objects in pictures into several broad categories and, for each category, discuss the manner in which visual information can be extracted. The problem of dynamically generating model descriptions for objects (and for entire pictures) is illustrated. A theoretical solution to this problem is presented and illustrated through an example. \nAs a test of the model, we present an implementation, PICTION, whereby information obtained from parsing a caption of a newspaper photograph is used to identify human faces in the photograph. A key component of the system is the utilisation of spatial constraints in order to reduce the number of possible labels that could be associated with a face. These constraints are generated by a natural-language processing system that examines the caption in detail. We report on the extensive testing of the system and discuss the results obtained. The method of evaluating the performance of PICTION can be used by any face-identification system."
            },
            "slug": "Extracting-visual-information-from-text:-using-to-Srihari",
            "title": {
                "fragments": [],
                "text": "Extracting visual information from text: using captions to label faces in newspaper photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A computational model for understanding pictures based on information in accompanying captions, PICTION, whereby information obtained from parsing a caption of a newspaper photograph is used to identify human faces in the photograph."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011596"
                        ],
                        "name": "D. Burhans",
                        "slug": "D.-Burhans",
                        "structuredName": {
                            "firstName": "Debra",
                            "lastName": "Burhans",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burhans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications [11] [12] [13] [14] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1433969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fabd30916cba34f9711ab9ba18d8868e3df346ae",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This research explores the interaction of textual and photographic information in document understanding. The problem of performing general-purpose vision without a priori knowledge is difficult at best. The use of collateral information in scene understanding has been explored in computer vision systems that use scene context in the task of object identification. The work described here extends this notion by defining visual semantics, a theory of systematically extracting picture-specific information from text accompanying a photograph. Specifically, this paper discusses the multi-stage processing of textual captions with the following objectives: (i) predicting which objects (implicitly or explicitly mentioned in the caption) are present in the picture and (ii) generating constraints useful in locating/identifying these objects. The implementation and use of a lexicon specifically designed for the integration of linguistic and visual information is discussed. Finally, the research described here has been successfully incorporated into PICTION, a caption-based face identification system."
            },
            "slug": "Visual-Semantics:-Extracting-Visual-information-Srihari-Burhans",
            "title": {
                "fragments": [],
                "text": "Visual Semantics: Extracting Visual information from Text Accompanying Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper discusses the multi-stage processing of textual captions with the following objectives: predicting which objects are present in the picture and generating constraints useful in locating/identifying these objects."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2969789"
                        ],
                        "name": "C. Carson",
                        "slug": "C.-Carson",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Carson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Carson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143942875"
                        ],
                        "name": "H. Greenspan",
                        "slug": "H.-Greenspan",
                        "structuredName": {
                            "firstName": "Hayit",
                            "lastName": "Greenspan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Greenspan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "Search using a simple conjunction of keywords and image features is provided in Blobworld [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Previous work [1] was limited to a subset of the Corel dataset and features from Blobworld [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14715074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fedf7729b620ec2cf4e79705d2898f82e9a2ba66",
            "isKey": false,
            "numCitedBy": 1629,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images from large and varied collections using image content as a key is a challenging and important problem. We present a new image representation that provides a transformation from the raw pixel data to a small set of image regions that are coherent in color and texture. This \"Blobworld\" representation is created by clustering pixels in a joint color-texture-position feature space. The segmentation algorithm is fully automatic and has been run on a collection of 10,000 natural images. We describe a system that uses the Blobworld representation to retrieve images from this collection. An important aspect of the system is that the user is allowed to view the internal representation of the submitted image and the query results. Similar systems do not offer the user this view into the workings of the system; consequently, query results from these systems can be inexplicable, despite the availability of knobs for adjusting the similarity metrics. By finding image regions that roughly correspond to objects, we allow querying at the level of objects rather than global image properties. We present results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects."
            },
            "slug": "Blobworld:-Image-Segmentation-Using-and-Its-to-Carson-Belongie",
            "title": {
                "fragments": [],
                "text": "Blobworld: Image Segmentation Using Expectation-Maximization and Its Application to Image Querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results indicating that querying for images using Blobworld produces higher precision than does querying using color and texture histograms of the entire image in cases where the image contains distinctive objects are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497400"
                        ],
                        "name": "D. Moldovan",
                        "slug": "D.-Moldovan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Moldovan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moldovan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8804548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f7a8aea8b1b7ebaf3be143f8b01611ec7e27e1e",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a Word Sense Disambiguation method based on the idea of semantic density between words. The disambiguation is done in the context of WordNet. The Internet is used as a raw corpora to provide statistical information for word associations. A metric is introduced and used to measure the semantic density and to rank all possible combinations of the senses of two words. This method provides a precision of 58% in indicating the correct sense for both words at the same time. The precision increases as we consider more choices: 70% for top two ranked and 7'3% for top three ranked. 1 I n t r o d u c t i o n Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et a1.1992), (Miller et a1.1994), (Agirre and Rigau, 1995), (Li et a1.1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale, Church et al., 1992), (Ng and Lee, 1996}; 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky 1995) (Resnik 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau, Asterias et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. On the other hand, the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined. To our knowledge, none of the statistical methods disambiguate adjectives or adverbs so far. One approach to WSD is to determine the conceptual distance between words, that is to measure the semantic closeness of the words within a semantic network. Essentially. it is the length of the shortest path connecting the concepts (Rada et a1.1989), (Rigau. Asterias et al., 1997). By measuring the conceptual distance between words, it is possible to determine the likelihood of word sense associations. For example, the method proposed in (Li et a1.1995) tries to determine the possible sense of a noun associated with a verb using WordNet and a large text. Based on other occurrences of the verb or semantically related verbs in the text, the possible object is determined by measuring the semantic similarity between the noun objects. Methods that do not need large corpora are usually based exclusively on MRD. A proposal in this sense has been made in (Agirre and Rigau, 1995): they measure the conceptual density between nouns, by using WordNet, but the method proposed in their paper cannot be applied to measuring a conceptual distance between a verb and a noun, as no direct links are provided in MRDs between the nouns and verbs hierarchies. A WordNet-based method for measuring the semantic similarity between nouns was also proposed in (Richardson et ai., 1994). Their method consists of using hierarchical concept graphs constructed from WordNet data files, and a semantic similarity formula. Still, the method does not provide a link between different part-of-speech words. 2 O u r a p p r o a c h The approach described in this paper is based on the idea of semantic density. This can be measured by the number of common words that are within a semantic distance of two or more words. The closer the semantic relationship between two words the higher the semantic density between them. The way it is defined here. the semantic density works well in the case of uniform MRD. In reality there are gaps in the knowledge representations and the semantic density can provide only an estimation of the actual semantic relatedness between words. We introduce the semantic density because it is"
            },
            "slug": "Word-Sense-Disambiguation-based-on-Semantic-Density-Mihalcea-Moldovan",
            "title": {
                "fragments": [],
                "text": "Word Sense Disambiguation based on Semantic Density"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A metric is introduced and used to measure the semantic density and to rank all possible combinations of the senses of two words, which provides a precision of 58% in indicating the correct sense for both words at the same time."
            },
            "venue": {
                "fragments": [],
                "text": "WordNet@ACL/COLING"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "We exploit this phenomenon, and extend a method for organizing image databases using both image features and associated text ([1], using a probabilistic model due to Hofmann [2])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Previous work [1] was limited to a subset of the Corel dataset and features from Blobworld [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Our model is a generative hierarchical model, inspired by one proposed for text by Hofmann [2] [16], and first applied to multiple data sources (text and image features) in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13121800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e36d141e2964817c3d926c380793e404a3a3367",
            "isKey": false,
            "numCitedBy": 615,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a statistical model for organizing image collections which integrates semantic information provided by associate text and visual information provided by image features. The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features. Furthermore, since the model learns relationships between text and image features, it can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "slug": "Learning-the-semantics-of-words-and-pictures-Barnard-Forsyth",
            "title": {
                "fragments": [],
                "text": "Learning the semantics of words and pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The model is very promising for information retrieval tasks such as database browsing and searching for images based on text and/or image features, and can be used for novel applications such as associating words with pictures, and unsupervised learning for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099025541"
                        ],
                        "name": "R. Chopra",
                        "slug": "R.-Chopra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications [11] [12] [13] [14] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 906540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cba4740274e6bf4d5f4197b0c8da3072a26f5c0",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an efficient control mechanism for incorporating picture-specific context in the task of image interpretation. Although other knowledge-based vision systems use general domain context in reducing the computational burden of image interpretation, to our knowledge, this is the first effort in exploring picture-specific collateral information. We assume that constraints on the picture are generated from a natural language understanding module which processes descriptive text accompanying the pictures. We have developed a unified framework for exploiting these constraints both in the object location and identification (labeling) stage. In particular, we describe a technique for incorporating constrained search in context-based vision. Finally, we demonstrate the effectiveness of this approach in PICTION, a system that uses captions to label human faces in newspaper photographs."
            },
            "slug": "Control-Structures-for-Incorporating-Context-in-Chopra-Srihari",
            "title": {
                "fragments": [],
                "text": "Control Structures for Incorporating Picture-Specific Context in Image Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper describes an efficient control mechanism for incorporating picture-specific context in the task of image interpretation and describes a technique for incorporating constrained search in context-based vision."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 131886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fa28d8a77e438d58b3d3670028b4e4f5380732b",
            "isKey": false,
            "numCitedBy": 616,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well-known that there are polysemous words like sentence whose \"meaning\" or \"sense\" depends on the context of use. We have recently reported on two new word-sense disambiguation systems, one trained on bilingual material (the Canadian Hansards) and the other trained on monolingual material (Roget's Thesaurus and Grolier's Encyclopedia). As this work was nearing completion, we observed a very strong discourse effect. That is, if a polysemous word such as sentence appears two or more times in a well-written discourse, it is extremely likely that they will all share the same sense. This paper describes an experiment which confirmed this hypothesis and found that the tendency to share sense in the same discourse is extremely strong (98%). This result can be used as an additional source of constraint for improving the performance of the word-sense disambiguation algorithm. In addition, it could also be used to help evaluate disambiguation algorithms that did not make use of the discourse constraint."
            },
            "slug": "One-Sense-Per-Discourse-Gale-Church",
            "title": {
                "fragments": [],
                "text": "One Sense Per Discourse"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An experiment confirmed the hypothesis that if a polysemous word such as sentence appears two or more times in a well-written discourse, it is extremely likely that they will all share the same sense and found that the tendency to share sense in the same discourse is extremely strong."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3174044"
                        ],
                        "name": "L. H. Armitage",
                        "slug": "L.-H.-Armitage",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Armitage",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. H. Armitage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "Enser and others have studied the nature of the image database query task [8] [9] [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45350741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "316440b3a78715902ebdf9a433867143c70f1b85",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a project in which an analysis was undertaken of user queries addressed to seven libraries which manage archives of widely varying still and moving image material. The sampling procedure is described, in which queries obtained from each library were broadly categorised by image content, identification and accessibility. Attention is focused on the image content requests, for which a categorisation based on facet analysis is developed. The analytical tool which is used for this purpose is based on a schema already well established for the analysis of levels of meaning in images. The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material. The paper concludes with observations on the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "slug": "Analysis-of-user-need-in-image-archives-Armitage-Enser",
            "title": {
                "fragments": [],
                "text": "Analysis of user need in image archives"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The project demonstrates the possibility of formulating a general categorisation of requests which seek widely different still and moving image material, and the potential value of embedding such a schema within the user interface of unmediated-query visual information retrieval systems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Inf. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114316817"
                        ],
                        "name": "M. La Cascia",
                        "slug": "M.-La-Cascia",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "La Cascia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. La Cascia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120772285"
                        ],
                        "name": "S. Sethi",
                        "slug": "S.-Sethi",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sethi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sethi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "Going further, Cascia et al integrate some text and histogram data in the indexing [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6349236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78462bcbcd3e8592dc45f41db56e697a2e26209d",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A system is proposed that combines textual and visual statistics in a single index vector for content-based search of a WWW image database. Textual statistics are captured in vector form using latent semantic indexing (LSI) based on text in the containing HTML document. Visual statistics are captured in vector form using color and orientation histograms. By using an integrated approach, it becomes possible to take advantage of possible statistical couplings between the content of the document (latent semantic content) and the contents of images (visual statistics). The combined approach allows improved performance in conducting content-based search. Search performance experiments are reported for a database containing 100,000 images collected from the WWW."
            },
            "slug": "Combining-textual-and-visual-cues-for-content-based-Cascia-Sethi",
            "title": {
                "fragments": [],
                "text": "Combining textual and visual cues for content-based image retrieval on the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A system is proposed that combines textual and visual statistics in a single index vector for content- based search of a WWW image database and allows improved performance in conducting content-based search."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE Workshop on Content-Based Access of Image and Video Libraries (Cat. No.98EX173)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137152"
                        ],
                        "name": "P. Enser",
                        "slug": "P.-Enser",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Enser",
                            "middleNames": [
                                "G.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Enser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Enser and others have studied the nature of the image database query task [8] [9] [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206393711,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "ef94d01afd7e972fa0ad8401c91e5ccd792e89f2",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial. The paper is contextualised by the notion of a visually stimulated society, in which the ease of record creation and transmission in the visual medium is contrasted with the difficulty of gaining effective subject access to the world's stores of such records. The technological developments which, in casting the visual image in electronic form, have contributed so significantly to its availability are reviewed briefly, as a prelude to the main thrust of the paper. Concentrating on still and moving pictorial forms of the visual image, the paper dwells on issues related to the subject indexing of pictorial material and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need."
            },
            "slug": "Progress-in-Documentation-Pictorial-Information-Enser",
            "title": {
                "fragments": [],
                "text": "Progress in Documentation Pictorial Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper surveys theoretical and practical issues associated with a particular type of information retrieval problem, namely that where the information need is pictorial, and discusses four models of pictorial information retrieval corresponding with permutations of the verbal and visual modes for the representation of picture content and of information need."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096985"
                        ],
                        "name": "G. Miller",
                        "slug": "G.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66511259"
                        ],
                        "name": "R. Beckwith",
                        "slug": "R.-Beckwith",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Beckwith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beckwith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145386345"
                        ],
                        "name": "Derek Gross",
                        "slug": "Derek-Gross",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113623689"
                        ],
                        "name": "K. Miller",
                        "slug": "K.-Miller",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2146137,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "4bd970a37c59c97804ff93cbb2c108e081de3a37",
            "isKey": false,
            "numCitedBy": 5334,
            "numCiting": 133,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list. Unfortunately, there is no obvious alternative, no other simple way for lexicographers to keep track of what has been done or for readers to find the word they are looking for. But a frequent objection to this solution is that finding things on an alphabetical list can be tedious and time-consuming. Many people who would like to refer to a dictionary decide not to bother with it because finding the information would interrupt their work and break their train of thought."
            },
            "slug": "Introduction-to-WordNet:-An-On-line-Lexical-Miller-Beckwith",
            "title": {
                "fragments": [],
                "text": "Introduction to WordNet: An On-line Lexical Database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Standard alphabetical procedures for organizing lexical information put together words that are spelled alike and scatter words with similar or related meanings haphazardly through the list."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46865129"
                        ],
                        "name": "Jianbo Shi",
                        "slug": "Jianbo-Shi",
                        "structuredName": {
                            "firstName": "Jianbo",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianbo Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "Feature extraction has also been improved largely through Normalized Cuts segmentation [18] [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14848918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b94c7ff9532ab26c3aedbee3988ec4c7a237c173",
            "isKey": false,
            "numCitedBy": 12814,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging."
            },
            "slug": "Normalized-cuts-and-image-segmentation-Shi-Malik",
            "title": {
                "fragments": [],
                "text": "Normalized cuts and image segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats image segmentation as a graph partitioning problem and proposes a novel global criterion, the normalized cut, for segmenting the graph, which measures both the total dissimilarity between the different groups as well as the total similarity within the groups."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "There are reviews in [1] [3]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30970545,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bef4b861e087fcf84f6a811714ff2dbe66248610",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Very large collections of images are now common. Indexing and searching such collections using indexing languages is difficult. Computer vision offers a variety of techniques for searching for pictures in large collections. Appearance methods compare images based on the overall content of the image using such criteria as similarity of color histograms, texture histograms, spatial layout, and filtered representations. Finding methods concentrate on matching subparts of images, defined in a variety of ways, in the hope of finding particular objects. These ideas are illustrated with a variety of examples from the current literature."
            },
            "slug": "Computer-Vision-Tools-for-Finding-Images-and-Video-Forsyth",
            "title": {
                "fragments": [],
                "text": "Computer Vision Tools for Finding Images and Video Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "In this paper, computer vision offers a variety of techniques for searching for pictures in large collections using indexing languages, and finding methods concentrate on matching subparts of images in the hope of finding particular objects."
            },
            "venue": {
                "fragments": [],
                "text": "Libr. Trends"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications [11] [12] [13] [14] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118627231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1d0496f5d4a5bc8563cc377728242f494d797a3",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The human face is an object that is easily located in complex scenes by infants and adults alike. Yet the development of an automated system to perform this task is extremely challenging. An attempt to solve this problem raises two important issues in object location. First, natural objects such as human faces tend to have boundaries which as yet have not been accurately described by analytical functions. This renders the commonly used parameter-based techniques like the Hough transform inadequate for extracting the shape. Second, the object of interest could occur in a scene in various sizes, thus requiring scale independent techniques which can detect instances of the object at all scales. \nAlthough, the task of identifying a well-framed face (as one of a set of labeled faces) has been well researched, the task of locating a face in a natural scene is relatively unexplored. We present a computational theory for locating human faces in scenes with certain constraints. Our experiments will be confined to instances where people's faces are the primary subject of the scene, occlusion is minimal, and the faces contrast well against the background. \nA hypothesis generate-and-test paradigm is proposed and justified as a methodology for face location. Alternative methods of hypothesis testing by either performing rigorous face-specific analysis or using collateral information have been addressed. The shape of the object is defined in terms of features selected using cognitive principles of human perception. Geometrical relationships between features are not rigid. Rather, they are represented by spring functionals that allow several configurations of the features to match against the model. The framework of spring functionals provides a mathematical basis for evaluating the \"goodness\" of matches between the data and the model."
            },
            "slug": "A-computational-theory-for-locating-human-faces-in-Govindaraju",
            "title": {
                "fragments": [],
                "text": "A computational theory for locating human faces in photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A hypothesis generate-and-test paradigm is proposed and justified as a methodology for face location and alternative methods of hypothesis testing by either performing rigorous face-specific analysis or using collateral information have been addressed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733049"
                        ],
                        "name": "Eneko Agirre",
                        "slug": "Eneko-Agirre",
                        "structuredName": {
                            "firstName": "Eneko",
                            "lastName": "Agirre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eneko Agirre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1567907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e55023e67ee4681736b0ca5ef516b8abaca0ca0",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for the resolution of lexical ambiguity and its \nautomatic evaluation over the Brown Corpus. The method relies on the use of \nthe wide-coverage noun taxonomy of WordNet and the notion of conceptual \ndistance among concepts, captured by a Conceptual Density formula developed \nfor this purpose. This fully automatic method requires no hand coding of \nlexical entries, hand tagging of text nor any kind of training process. The \nresults of the experiment have been automatically evaluated against SemCor, \nthe sense-tagged version of the Brown Corpus."
            },
            "slug": "A-Proposal-for-Word-Sense-Disambiguation-using-Agirre-Rigau",
            "title": {
                "fragments": [],
                "text": "A Proposal for Word Sense Disambiguation using Conceptual Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The method relies on the use of the wide-coverage noun taxonomy of WordNet and the notion of conceptual distance among concepts, captured by a Conceptual Density formula developed for this purpose, for the resolution of lexical ambiguity."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2696305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ec00abf9ff66d6f16378978faf907b047834cbb",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling and predicting co-occurrences of events is a fundamental problem of unsupervised learning. In this contribution we develop a statistical framework for analyzing co-occurrence data in a general setting where elementary observations are joint occurrences of pairs of abstract objects from two finite sets. The main challenge for statistical models in this context is to overcome the inherent data sparseness and to estimate the probabilities for pairs which were rarely observed or even unobserved in a given sample set. Moreover, it is often of considerable interest to extract grouping structure or to find a hierarchical data organization. A novel family of mixture models is proposed which explain the observed data by a finite number of shared aspects or clusters. This provides a common framework for statistical inference and structure discovery and also includes several recently proposed models as special cases. Adopting the maximum likelihood principle, EM algorithms are derived to fit the model parameters. We develop improved versions of EM which largely avoid overfitting problems and overcome the inherent locality of EM--based optimization. Among the broad variety of possible applications, e.g., in information retrieval, natural language processing, data mining, and computer vision, we have chosen document retrieval, the statistical analysis of noun/adjective co-occurrence and the unsupervised segmentation of textured images to test and evaluate the proposed algorithms."
            },
            "slug": "Statistical-Models-for-Co-occurrence-Data-Hofmann-Puzicha",
            "title": {
                "fragments": [],
                "text": "Statistical Models for Co-occurrence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A statistical framework for analyzing co-occurrence data in a general setting where elementary observations are joint occurrences of pairs of abstract objects from two finite sets is developed and a novel family of mixture models is proposed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145022783"
                        ],
                        "name": "E. Brill",
                        "slug": "E.-Brill",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5216592,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe30dc915eefa40755b25a363813fcc575536661",
            "isKey": false,
            "numCitedBy": 1715,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic part of speech tagging is an area of natural language processing where statistical techniques have been more successful than rule-based methods. In this paper, we present a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers. The rule-based tagger has many advantages over these taggers, including: a vast reduction in stored information required, the perspicuity of a small set of meaningful rules, ease of finding and implementing improvements to the tagger, and better portability from one tag set, corpus genre or language to another. Perhaps the biggest contribution of this work is in demonstrating that the stochastic method is not the only viable method for part of speech tagging. The fact that a simple rule-based tagger that automatically learns its rules can perform so well should offer encouragement for researchers to further explore rule-based tagging, searching for a better and more expressive set of rule templates and other variations on the simple but effective theme described below."
            },
            "slug": "A-Simple-Rule-Based-Part-of-Speech-Tagger-Brill",
            "title": {
                "fragments": [],
                "text": "A Simple Rule-Based Part of Speech Tagger"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a simple rule-based part of speech tagger which automatically acquires its rules and tags with accuracy comparable to stochastic taggers, demonstrating that the stochastics method is not the only viable method for part ofspeech tagging."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1487550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944cba683d10d8c1a902e05cd68e32a9f47b372e",
            "isKey": false,
            "numCitedBy": 2536,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints---that words tend to have one sense per discourse and one sense per collocation---exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%."
            },
            "slug": "Unsupervised-Word-Sense-Disambiguation-Rivaling-Yarowsky",
            "title": {
                "fragments": [],
                "text": "Unsupervised Word Sense Disambiguation Rivaling Supervised Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121941586"
                        ],
                        "name": "C. Frankel",
                        "slug": "C.-Frankel",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Frankel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Frankel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720747"
                        ],
                        "name": "V. Athitsos",
                        "slug": "V.-Athitsos",
                        "structuredName": {
                            "firstName": "Vassilis",
                            "lastName": "Athitsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Athitsos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Webseer [5] uses similar ideas for query of images on the web, but also indexes the results of a few automatically estimated image features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7811959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "105b158b73511030ff10ac0f0f1cbee65236e4a6",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Because of the size of the World Wide Web and its inherent lack of structure, finding what one is looking for can be a challenge. PC-Meters March, 1996, survey found that three of the five most visited Web sites were search engines. However, while Web pages typically contain both text and images, all the currently available search engines only index text. This paper describes WebSeer, a system for locating images on the Web. WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs."
            },
            "slug": "WebSeer:-An-Image-Search-Engine-for-the-World-Wide-Frankel-Swain",
            "title": {
                "fragments": [],
                "text": "WebSeer: An Image Search Engine for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "WebSeer uses image content in addition to associated text to index images, presenting the user with a selection that potentially fits her needs on the Web."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143936663"
                        ],
                        "name": "Thomas Hofmann",
                        "slug": "Thomas-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 174
                            }
                        ],
                        "text": "We exploit this phenomenon, and extend a method for organizing image databases using both image features and associated text ([1], using a probabilistic model due to Hofmann [2])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "A naive implementation of the method described in [2] requires a data structure for the vertical indicator variables which increases linearly with four parameters: the number of images, the number of clusters, the number of levels, and the number of items (words and image segments)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 238
                            }
                        ],
                        "text": "This involves introducing hidden variables H d c , indicating that training document d is in cluster c, and V d i l , , indicating that item i of document d was generated at level l. Additional details on the EM equations can be found in [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "Our model is a generative hierarchical model, inspired by one proposed for text by Hofmann [2] [16], and first applied to multiple data sources (text and image features) in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8069201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7682b0fe481c345ea973ca07d2d979e003fd20a2",
            "isKey": true,
            "numCitedBy": 28,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "ion levels of words document partitioning abstraction levels (a) (b)"
            },
            "slug": "Learning-and-representing-topic-a-hierarchical-for-Hofmann",
            "title": {
                "fragments": [],
                "text": "Learning and representing topic-a hierarchical mixture model for word occurences in document databas"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "In this chapter three levels of words document partitioning abstraction levels are calculated using a model based on the model developed in [Bouchut-Boyaval, M3AS, 2013]."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "To train the model we use the Expectation- Maximization algorithm [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48405,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099025541"
                        ],
                        "name": "R. Chopra",
                        "slug": "R.-Chopra",
                        "structuredName": {
                            "firstName": "Rajiv",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011596"
                        ],
                        "name": "D. Burhans",
                        "slug": "D.-Burhans",
                        "structuredName": {
                            "firstName": "Debra",
                            "lastName": "Burhans",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burhans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92876288"
                        ],
                        "name": "M. Venkataraman",
                        "slug": "M.-Venkataraman",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Venkataraman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Venkataraman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 130
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications [11] [12] [13] [14] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59669097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1720b6e3e41edd77a86ef45ad5fc49bc73990b80",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Use-of-Collateral-Text-in-Image-Interpretation-Srihari-Chopra",
            "title": {
                "fragments": [],
                "text": "Use of Collateral Text in Image Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083462951"
                        ],
                        "name": "Fran ine Chena",
                        "slug": "Fran-ine-Chena",
                        "structuredName": {
                            "firstName": "Fran",
                            "lastName": "Chena",
                            "middleNames": [
                                "ine"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fran ine Chena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103312311"
                        ],
                        "name": "Ullas Gargib",
                        "slug": "Ullas-Gargib",
                        "structuredName": {
                            "firstName": "Ullas",
                            "lastName": "Gargib",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ullas Gargib"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096374698"
                        ],
                        "name": "Les Nilesa",
                        "slug": "Les-Nilesa",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Nilesa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Les Nilesa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "Others have also experimented with using image features as part of a query refinement process [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17630005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c196925c50862a363f5c87446832c8c7ca7ad181",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multi-Modal-Browsing-of-Images-in-Web-Do-uments-Chena-Gargib",
            "title": {
                "fragments": [],
                "text": "Multi-Modal Browsing of Images in Web Do uments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical models for cooccurrence data,\u201d Massachusetts Institute of Technology, A.I. Memo 1635,1998, likelihood from incomplete data via the EM algorithm,"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society. Series B"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Our model is a generative hierarchical model, inspired by one proposed for text by Hofmann [2] [16], and first applied to multiple data sources (text and image features) in [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical models for cooccurrence data"
            },
            "venue": {
                "fragments": [],
                "text": "Massachusetts Institute of Technology, A.I. Memo"
            },
            "year": 1635
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Feature extraction has also been improved largely through Normalized Cuts segmentation [18] [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available from http://dlp.CS.Berkeley.EDU/~doron/software/ncuts"
            },
            "venue": {
                "fragments": [],
                "text": "Available from http://dlp.CS.Berkeley.EDU/~doron/software/ncuts"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "We exploit this phenomenon, and extend a method for organizing image databases using both image features and associated text ([1], using a probabilistic model due to Hofmann [2])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Kobus Barnard, Pinar Duygulu, and David Forsyth Computer Division, University of California, Berkeley {kobus, duygulu, daf}@cs.berkeley.edu"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "Note that in (1) there is a separate probability distribution over the nodes for each document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Reference omitted for blind review"
            },
            "venue": {
                "fragments": [],
                "text": "Reference omitted for blind review"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Srihari and others have used text information to disambiguate image features, particularly in face finding applications [11] [12] [13] [14] [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extracting Visual Information from Text: Using Captions to Label Human Faces in Newspaper Photographs, SUNY at Buffalo"
            },
            "venue": {
                "fragments": [],
                "text": "Extracting Visual Information from Text: Using Captions to Label Human Faces in Newspaper Photographs, SUNY at Buffalo"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "Enser and others have studied the nature of the image database query task [8] [9] [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Query analysis in a visual information retrieval context"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Document and Text Management"
            },
            "year": 1993
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Clustering-art-Barnard-Sahin/df70db146b07ce173476be3877a5a3ae3ca06aa5?sort=total-citations"
}