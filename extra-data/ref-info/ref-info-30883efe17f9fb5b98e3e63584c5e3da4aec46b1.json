{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46138594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b39beea0f761152e65fac0e498af387821d887f1",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. We use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2550/spl times/3300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise."
            },
            "slug": "Document-Representation-and-Its-Application-to-Page-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Document Representation and Its Application to Page Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In addition to the above approaches which share some common features, Antonacopoulos [ 10 ] used white tiles to extract contours of regions and features for classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18315157,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "33242ff2f1320647d14d21daf30c2afa29964b88",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "There is an ever increasing number of publications which do not have the \u201ctraditional\u201d layout where printed regions are rectangular. Text paragraphs and areas of graphic type may be of any shape, individually rotated and in any arrangement. Previous document analysis techniques are not well suited to such complex layouts. This paper introduces a new method for the segmentation of images of document pages having both traditional and complex layouts. The underlining idea is to efficiently produce a flexible description (by means of tiles) of the background space which surrounds the printed regions in the page image under all the above conditions. Using this description of space, the contours of printed regions are identified with significant accuracy. The new approach is fast as there is no need for skew detection and correction, and only few simple operations are performed on the description of the background (not on the pixel-based data)."
            },
            "slug": "Page-Segmentation-Using-the-Description-of-the-Antonacopoulos",
            "title": {
                "fragments": [],
                "text": "Page Segmentation Using the Description of the Background"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new method for the segmentation of images of document pages having both traditional and complex layouts is introduced, to efficiently produce a flexible description of the background space which surrounds the printed regions in the page image under all the above conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3361432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e393d7d2a5a1f9bfd59db0c14a5a1e8c972f8f1d",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for extracting words, textlines and text blocks by analyzing the spatial configuration of bounding boxes of connected component on a given document image. The basic idea is that connected components of black pixels can be used as computational units in document image analysis. In this paper, the problem of extracting words, textlines and text blocks is viewed as a clustering problem in the 2-dimensional discrete domain. Our main strategy is that profiling analysis is utilized to measure horizontal or vertical gaps of (groups of) components during the process of image segmentation. For this purpose, we compute the smallest rectangular box, called the bounding box, which circumscribes a connected component. Those boxes are projected horizontally and/or vertically, and local and global projection profiles are analyzed for word, textline and text-block segmentation. In the last step of segmentation, the document decomposition hierarchy is produced from these segmented objects."
            },
            "slug": "Document-page-decomposition-by-the-bounding-box-Ha-Haralick",
            "title": {
                "fragments": [],
                "text": "Document page decomposition by the bounding-box project"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The problem of extracting words, textlines and text blocks is viewed as a clustering problem in the 2-dimensional discrete domain and profiling analysis is utilized to measure horizontal or vertical gaps of (groups of) components during the process of image segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13615381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d91e0d202fa23b7a2e81c5b3b04eb4cc5327b0f9",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs. The physical reader of the paper document is the scanner just like the physical reader of the floppy is the floppy drive and the physical reader of the tape cartridge is the tape cartridge drive, and the physical reader of the CDROM is the CDROM drive. In the survey presented, we restrict ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences. Understanding such documents involves estimating the rotation skew of each document page, determining the geometric page layout, labeling blocks as text or non-text, determining the read order for text blocks, recognizing the text of text blocks through an OCR system, determining the logical page layout, and formatting the data and information of the document in a suitable way for use by a word processing system or by an information retrieval system.<<ETX>>"
            },
            "slug": "Document-image-understanding:-geometric-and-logical-Haralick",
            "title": {
                "fragments": [],
                "text": "Document image understanding: geometric and logical layout"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs and restricts ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 70
                            }
                        ],
                        "text": "In addition to the above approaches which share some\ncommon features, Antonacopoulos [10] used white tiles to\nextract contours of regions and features for classification."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "In addition to the above approaches which share some common features, Antonacopoulos [10] used white tiles to extract contours of regions and features for classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14874178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7da9b89252a7ac69c8cfb63ac810a46738c45469",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "There is an ever increasing number of publications which do not have the \u201ctraditional\u201d layout where printed regions are rectangular. Text paragraphs and areas of graphic type may be of any shape, individually rotated and in any arrangement. Previous document analysis techniques are not well suited to such complex layouts. This paper introduces a new method for the segmentation of images of document pages having both traditional and complex layouts. The underlining idea is to efficiently produce a flexible description (by means of tiles) of the background space which surrounds the printed regions in the page image under all the above conditions. Using this description of space, the contours of printed regions are identified with significant accuracy. The new approach is fast as there is no need for skew detection and correction, and only few simple operations are performed on the description of the background (not on the pixel-based data). c \u00a9 1998 Academic Press"
            },
            "slug": "Segmentation-Using-the-Description-of-the-Antonacopoulos",
            "title": {
                "fragments": [],
                "text": "Segmentation Using the Description of the Background"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new method for the segmentation of images of document pages having both traditional and complex layouts by means of underlining a flexible description of the background space which surrounds the printed regions in the page image under all the above conditions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7232446"
                        ],
                        "name": "B. Gatos",
                        "slug": "B.-Gatos",
                        "structuredName": {
                            "firstName": "Basilios",
                            "lastName": "Gatos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gatos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144368634"
                        ],
                        "name": "N. Papamarkos",
                        "slug": "N.-Papamarkos",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Papamarkos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Papamarkos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728570"
                        ],
                        "name": "C. Chamzas",
                        "slug": "C.-Chamzas",
                        "structuredName": {
                            "firstName": "Christodoulos",
                            "lastName": "Chamzas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chamzas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In order to extract the periodicity of a region, we first find the page skew angle () by a skew detection algorithm [ 14 ] and then get the horizontal (or vertical) projection profile according to the page skew angle (), as shown in (2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205905844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c664274b7cce4997a11f5db2d2eddeff08979c5a",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Skew-detection-and-text-line-position-determination-Gatos-Papamarkos",
            "title": {
                "fragments": [],
                "text": "Skew detection and text line position determination in digitized documents"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971263"
                        ],
                        "name": "K. Etemad",
                        "slug": "K.-Etemad",
                        "structuredName": {
                            "firstName": "Kamran",
                            "lastName": "Etemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15806531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37c7f31be030b82a0188e5934cbaa8abbbaad98b",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A new algorithm for layout independent document image segmentation is suggested. Text, image and graphics regions in a document image are treated as three diierent \\texture\" classes. Feature vectors based on multi-scale wavelet packet representation are used for local classiication. Segmentation is performed by propagating soft local decisions made on small windows across neighboring blocks and integrating them to reduce their \\ambiguities\" and increase their \\conndence\" as more contextual evidence is obtained from the image data. Local votes propagate in a neighborhood, within and across scales, and majorities of weighted votes give the nal decisions. The method has been tested on document page decomposition tasks, and the results of these tests are presented. The algorithm is general, can be applied to other segmentation and classiication tasks, is based on parallel, distributed and independent computations and has low complexity."
            },
            "slug": "Multiscale-Document-Page-Segmentation-Using-Soft-Etemad-Doermann",
            "title": {
                "fragments": [],
                "text": "Multiscale Document Page Segmentation Using Soft Decision Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A new algorithm for layout independent document image segmentation that is general, can be applied to other segmentation and classiication tasks, is based on parallel, distributed and independent computations and has low complexity."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144434788"
                        ],
                        "name": "A. Amin",
                        "slug": "A.-Amin",
                        "structuredName": {
                            "firstName": "Adnan",
                            "lastName": "Amin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Amin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126430"
                        ],
                        "name": "R. Shiu",
                        "slug": "R.-Shiu",
                        "structuredName": {
                            "firstName": "Ricky",
                            "lastName": "Shiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shiu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 2
                            }
                        ],
                        "text": "First of all, to achieve this transformation, geometric document layout analysis should be performed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13020550,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f004c27e44c64b34d6b4f65dafd293b2a5a7b7b",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image processing has become an increasingly important technology in the automation of office documentation tasks. Automatic document scanners such as text readers and OCR (Optical Character Recognition) systems are an essential component of systems capable of those tasks. One of the problems in this field is that the document to be read is not always placed correctly on a flat-bed scanner. This means that the document may be skewed on the scanner bed, resulting in a skewed image. This skew has a detrimental effect on document analysis, document understanding, and character segmentation and recognition. Consequently, detecting the skew of a document image and correcting it are important issues in realizing a practical document reader. This paper presents the use of analyzing the connected components extracted from the binary image of a document page. Such an analysis provides a lot of useful information, and will be used to perform skew correction, segmentation and classification of the document. Moreover, we describe two new algorithms \u2014 one for skew detection and one for skew correction. The new skew correction algorithm we propose has been shown to be fast and accurate, with run times averaging under 1.5 CPU seconds and 30 seconds real time to calculate the angle on a 5000/20 DEC workstation. Experiments on over 100 pages show that the method works well on a wide variety of layouts, including sparse textual regions, mixed fonts, multiple columns, and even for documents with a high graphical content."
            },
            "slug": "Page-Segmentation-and-Classification-Utilizing-Amin-Shiu",
            "title": {
                "fragments": [],
                "text": "Page Segmentation and Classification Utilizing Bottom-Up Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The use of analyzing the connected components extracted from the binary image of a document page provides a lot of useful information, and will be used to perform skew correction, segmentation and classification of the document."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Image Graph."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081746109"
                        ],
                        "name": "D. Drivas",
                        "slug": "D.-Drivas",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Drivas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Drivas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144434788"
                        ],
                        "name": "A. Amin",
                        "slug": "A.-Amin",
                        "structuredName": {
                            "firstName": "Adnan",
                            "lastName": "Amin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Amin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "to as bottom-up methods [1], [2], [3]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "A well-known method in bottom-up approaches is the connected components grouping method [2], where connected components are extracted from the image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61785232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1caa2d8edf58440c8e3f9c4a7e10faba0bb2fcf9",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the use of analysing the connected components extracted from the binary image of a document page. Such an analysis provides a lot of useful information, and will be used to perform skew correction, segmentation and classification of the document. We present a new algorithm for determining the skew angle of lines of text in an image of a document with the advantage that it only performs one iteration to determine the skew angle. Experiments on over 30 pages show that the method works well on a wide variety of layouts, including sparse textual regions, mixed fonts, multiple columns, and even for documents with a high graphical content."
            },
            "slug": "Page-segmentation-and-classification-utilising-a-Drivas-Amin",
            "title": {
                "fragments": [],
                "text": "Page segmentation and classification utilising a bottom-up approach"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new algorithm for determining the skew angles of lines of text in an image of a document with the advantage that it only performs one iteration to determine the skew angle is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39319377"
                        ],
                        "name": "Yu Zhong",
                        "slug": "Yu-Zhong",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zhong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 64
                            }
                        ],
                        "text": "One major problem associated with such texture-based approaches [6], [7] is that the time complexity is too high since different filters are tuned to capture a desired local spatial frequency and the orientation characteristics of a textured region, so that many masks are used for extracting local features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39821816,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14371d83ac90edc11b3604d4bf64915f99e45678",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Page-segmentation-using-tecture-analysis-Jain-Zhong",
            "title": {
                "fragments": [],
                "text": "Page segmentation using tecture analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15144597"
                        ],
                        "name": "Franck Lebourgeois",
                        "slug": "Franck-Lebourgeois",
                        "structuredName": {
                            "firstName": "Franck",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Franck Lebourgeois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2372426"
                        ],
                        "name": "Z. Bublinski",
                        "slug": "Z.-Bublinski",
                        "structuredName": {
                            "firstName": "Zbigniew",
                            "lastName": "Bublinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Bublinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 91
                            }
                        ],
                        "text": "However, it is not trivial to automatically transform paper documents into electronic format."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62602509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a2c3f55e7a84ad5fa5eaa577d8d58ee73e14e2b",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Outlines a fast and efficient method for extracting graphics and text paragraphs from printed documents. The method presented is based on bottom-up approach to document analysis and it achieves very good performance in most cases. During the preprocessing characters are linked together to form blocks. Created blocks are segmented, labelled and merged into paragraphs. Simultaneously, graphics are extracted from the image. Algorithms for each step of processing are presented. Also, the obtained experimental results are included.<<ETX>>"
            },
            "slug": "A-fast-and-efficient-method-for-extracting-text-and-Lebourgeois-Bublinski",
            "title": {
                "fragments": [],
                "text": "A fast and efficient method for extracting text paragraphs and graphics from unconstrained documents"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "Outlines a fast and efficient method for extracting graphics and text paragraphs from printed documents based on bottom-up approach to document analysis and achieves very good performance in most cases."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863322"
                        ],
                        "name": "Anik\u00f3 Simon",
                        "slug": "Anik\u00f3-Simon",
                        "structuredName": {
                            "firstName": "Anik\u00f3",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anik\u00f3 Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1907819"
                        ],
                        "name": "Jean-Christophe Pret",
                        "slug": "Jean-Christophe-Pret",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Pret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Christophe Pret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406054409"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "First of all, to achieve this transformation, geometric document layout analysis should be performed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29276706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7094063edf765c44dcce4aada3ed0ca725b74d96",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new bottom-up method for document layout analysis. The algorithm was implemented in the CLIDE (Chemical Literature Data Extraction) system, but the method described here is suitable for a broader range of documents. It is based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure. The method has all the major advantages of bottom-up systems: independence from different text spacing and independence from different block alignments. The algorithms computational complexity is reduced to linear by using heuristics and path-compression."
            },
            "slug": "A-Fast-Algorithm-for-Bottom-Up-Document-Layout-Simon-Pret",
            "title": {
                "fragments": [],
                "text": "A Fast Algorithm for Bottom-Up Document Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new bottom-up method for document layout analysis based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39702442"
                        ],
                        "name": "Y. Tang",
                        "slug": "Y.-Tang",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Tang",
                            "middleNames": [
                                "Yan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143607634"
                        ],
                        "name": "Hong Ma",
                        "slug": "Hong-Ma",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144128094"
                        ],
                        "name": "Jiming Liu",
                        "slug": "Jiming-Liu",
                        "structuredName": {
                            "firstName": "Jiming",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiming Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46708490"
                        ],
                        "name": "B. Li",
                        "slug": "B.-Li",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Li",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2310605"
                        ],
                        "name": "Dihua Xi",
                        "slug": "Dihua-Xi",
                        "structuredName": {
                            "firstName": "Dihua",
                            "lastName": "Xi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dihua Xi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62003646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c871f41c0885caf21e75d4726b1319667d91a499",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on wavelets, a theoretical method has been developed to process multi-gray level documents. In this method, two-dimensional multiresolution analysis, a wavelet decomposition algorithm, and compactly supported orthonormal wavelets are used to transform a document image into sub-images. According to these sub-images, the reference lines of a multi-gray level document can be extracted, and knowledge about the geometric structure of the document can be acquired. Particularly, this approach is more efficient to process form documents with gray level background. Experiments indicate that this new method can be applied to process documents with promising results."
            },
            "slug": "Multiresolution-analysis-in-extraction-of-reference-Tang-Ma",
            "title": {
                "fragments": [],
                "text": "Multiresolution analysis in extraction of reference lines from documents with gray level background"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experiments indicate that this new method based on wavelets can be applied to process documents with promising results, and is more efficient to process form documents with gray level background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971263"
                        ],
                        "name": "K. Etemad",
                        "slug": "K.-Etemad",
                        "structuredName": {
                            "firstName": "Kamran",
                            "lastName": "Etemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27678281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95dffcc92bda88d9f4f5b112d100f43951745b8c",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information. Multiscale feature vectors are classified locally using a neural network to allow soft/fuzzy multi-class membership assignments. Segmentation is performed by integrating soft local decision vectors to reduce their \"ambiguities\"."
            },
            "slug": "Multiscale-Segmentation-of-Unstructured-Document-Etemad-Doermann",
            "title": {
                "fragments": [],
                "text": "Multiscale Segmentation of Unstructured Document Pages Using Soft Decision Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "An algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122930"
                        ],
                        "name": "J. Ha",
                        "slug": "J.-Ha",
                        "structuredName": {
                            "firstName": "Jaekyu",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17179084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f03c5e7b1e66936544eaf329cbe38c57ccf5feb0",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A top-down page segmentation technique known as the recursive X-Y cut decomposes a document image recursively into a set of rectangular blocks. This paper proposes that the recursive X-Y cut be implemented using bounding boxes of connected components of black pixels instead of using image pixels. The advantage is that great improvement can be achieved in computation. In fact, once bounding boxes of connected components are obtained, the recursive X-Y cut is completed within an order of a second on Sparc-10 workstations for letter-sized document images scanned at 900 dpi resolution."
            },
            "slug": "Recursive-X-Y-cut-using-bounding-boxes-of-connected-Ha-Haralick",
            "title": {
                "fragments": [],
                "text": "Recursive X-Y cut using bounding boxes of connected components"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes that the recursive X-Y cut be implemented using bounding boxes of connected components of black pixels instead of using image pixels, so that great improvement can be achieved in computation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749800"
                        ],
                        "name": "T. M. Ha",
                        "slug": "T.-M.-Ha",
                        "structuredName": {
                            "firstName": "Thien",
                            "lastName": "Ha",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. M. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503093"
                        ],
                        "name": "D. Niggeler",
                        "slug": "D.-Niggeler",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Niggeler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Niggeler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34856733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c549ae45f077aed7d820a8af6ed0c6d530974e85",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a system for segmentation and recognition of totally unconstrained handwritten numeral strings. The system is built upon a number of components, namely, a presegmentation module, an isolated numeral recognizer, a segmentation-free module and a merging module. Presegmentation consists in dividing the input numeral string image into groups of numerals each of which represents an integer number of numerals. For each group, the actual number of numerals and their identity are then determined by a cascade of two recognition-based tests: isolated numeral and segmentation-free. The last one is able to recognise a numeral group of any length. All results from all groups are eventually merged yielding the final interpretation of the input numeral string. We also introduce the concept of dummy symbol in order to overcome the problem of noisy parts that cannot be eliminated by standard filtering algorithms. Preliminary experiments on totally unconstrained data from the CEDAR database yielded a segmentation rate of 94.5% and a recognition rate of 84.2% at string level. These results compare favorably to other published methods."
            },
            "slug": "A-system-for-segmenting-and-recognising-totally-Ha-Niggeler",
            "title": {
                "fragments": [],
                "text": "A system for segmenting and recognising totally unconstrained handwritten numeral strings"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The concept of dummy symbol is introduced in order to overcome the problem of noisy parts that cannot be eliminated by standard filtering algorithms and compare favorably to other published methods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146876323"
                        ],
                        "name": "Hui Cheng",
                        "slug": "Hui-Cheng",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745655"
                        ],
                        "name": "C. Bouman",
                        "slug": "C.-Bouman",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bouman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bouman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1593494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc36171e540f3bf78cc927e2ddf2a34fa516931c",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Most previous approaches to Bayesian segmentation have used simple prior models, such as Markov random fields (MRF), to enforce regularity in the segmentation. While these methods improve classification accuracy, they are not well suited to modeling complex contextual structure. In this paper, we propose a context model for multiscale segmentation which can capture very complex behaviors on both local and global scales. Our method works by using binary classification trees to model the transition probabilities between segmentations at adjacent scales. The classification trees can be efficiently trained to model essential aspects of contextual behavior. In addition, the data model in our approach is novel in the sense that it can incorporate the correlation among the wavelet feature vectors across scales. We apply our method to the problem of document segmentation to illustrate its usefulness."
            },
            "slug": "Trainable-context-model-for-multiscale-segmentation-Cheng-Bouman",
            "title": {
                "fragments": [],
                "text": "Trainable context model for multiscale segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A context model for multiscale segmentation which can capture very complex behaviors on both local and global scales is proposed and can incorporate the correlation among the wavelet feature vectors across scales."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2356353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b78626ce1a562c05b1c06f9c805e839f9760b9ab",
            "isKey": false,
            "numCitedBy": 20814,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/sup j/ (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions. In L/sup 2/(R), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function psi (x). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed. >"
            },
            "slug": "A-Theory-for-Multiresolution-Signal-Decomposition:-Mallat",
            "title": {
                "fragments": [],
                "text": "A Theory for Multiresolution Signal Decomposition: The Wavelet Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/Sup j/ can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111237291"
                        ],
                        "name": "Su S. Chen",
                        "slug": "Su-S.-Chen",
                        "structuredName": {
                            "firstName": "Su",
                            "lastName": "Chen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su S. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In Section 4, to verify the performance of the proposed method, experimental results with the document database from the University of Washington [ 17 ] and the MediaTeam Document Database [18] are analyzed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "4E XPERIMENTAL RESULTS AND ANALYSIS Our proposed method has been tested on 150 images from the document database volume II available from the University of Washington (UWDB) [ 17 ] and all 233 images in the article category out of 512 images from the MediaTeam Document Database [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The example of the processes using our method is shown in Fig. 15. The performance result with UWDB [ 17 ] and MediaTeam DB [18] is quantitatively evaluated, as shown in Table 2. In addition, the corresponding graph is illustrated in Fig. 14 to show the performance comparison of the proposed method with recursive X-Y cut method [4] and Block Adjacency Graph (BAG) method [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3258255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de1580d4cc0c47e4985c8ce52d106c6a7432ff70",
            "isKey": true,
            "numCitedBy": 127,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of a comprehensive standard document database for machine-printed documents is presented. The effort to produce a series of carefully ground-truthed document databases to be issued on CD-ROMs is described in detail. The databases can be utilized by the OCR and document understanding community as a common platform to develop, test, and evaluate their algorithms.<<ETX>>"
            },
            "slug": "CD-ROM-document-database-standard-Phillips-Chen",
            "title": {
                "fragments": [],
                "text": "CD-ROM document database standard"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The design of a comprehensive standard document database for machine-printed documents is presented and can be utilized by the OCR and document understanding community as a common platform to develop, test, and evaluate their algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49814656"
                        ],
                        "name": "K. Barraclough",
                        "slug": "K.-Barraclough",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Barraclough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Barraclough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": "proposed method with recursive X-Y cut method [4] and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "However, with the previous methods [4], [5], the complex document layout which is composed of nonrectangular images and various character font sizes makes it difficult to segment correctly in a topdown manner."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120156521,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "666010dc3621e1a08fb6830f03a1f7857c7377cc",
            "isKey": false,
            "numCitedBy": 36584,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There is, I think, something ethereal about i \u2014the square root of minus one. I remember first hearing about it at school. It seemed an odd beast at that time\u2014an intruder hovering on the edge of reality.\n\nUsually familiarity dulls this sense of the bizarre, but in the case of i it was the reverse: over the years the sense of its surreal nature intensified. It seemed that it was impossible to write mathematics that described the real world in \u2026"
            },
            "slug": "I-and-i-Barraclough",
            "title": {
                "fragments": [],
                "text": "I and i"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "There is, I think, something ethereal about i \u2014the square root of minus one, which seems an odd beast at that time\u2014an intruder hovering on the edge of reality."
            },
            "venue": {
                "fragments": [],
                "text": "BMJ : British Medical Journal"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "The performance result with UWDB [17] and MediaTeam DB [18] is quantitatively evaluated, as shown in"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "In Section 4, to verify the performance of the proposed method, experimental results with the document database from the University of Washington [17] and the MediaTeam Document Database [18] are analyzed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "18 shows the result of experimentation on the images\nfrom the UWDB."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 87
                            }
                        ],
                        "text": "The proposed method was experimented with the document database from the University of Washington and the MediaTeam Document Database."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "Our proposed method has been tested on 150 images from the document database volume II available from the University of Washington (UWDB) [17] and all 233 images in the article category out of 512 images from the MediaTeam Document Database [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "The performance result with UWDB [17] and\nMediaTeam DB [18] is quantitatively evaluated, as shown in\nTable 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 76
                            }
                        ],
                        "text": "The proposed\nmethod was experimented with the images from the\nUniversity of Washington Database and images from\nMediaTeam Document Database."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "Haralick, aCD-ROM Document Database Standard,o Proc. Second Int'l Conf. Document Analysis and Recognition, pp. 478-483"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Block Adjacency Graph (BAG) method [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "A comparison of the results between our method and the BAG method [11] is shown in Fig."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Jain and Yu [11] used the traditional bottom-up approach for page segmentation and region identification and employed a document model to preserve top-down generation of information for logical layout analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Experimental results for the BAG method [11] (left) and the proposed method (right)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "2 Motivation of this Work Variations in character font sizes, text line spacings, and document layout structures have made it difficult to design a general-purpose document layout analysis algorithm [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aDocument Representation and Its Application to Page Decomposition,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Decomposition of an image An 1f into Anf, D1nf, D 2 nf, and D3nf [12].\nmatrix of the corresponding class and bi is 1 if the assigned class of bi is equal to class c; c 2 fI; T ;H; V g, otherwise, bi is 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Finally, the HH subimage has high frequencies in both horizontal and vertical directions and it corresponds to D3nf [13]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "The 2D Harr wavelet transform [12] has been adopted for texture analysis since it is the simplest and fastest transform among the various MRA transforms and can be applied to binary images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Decomposition of an image An\u00871f into Anf, D(1)nf, D 2 nf, and D(3)nf [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aA Theory for Multiresolution Signal Decomposition: The Wavelet Representation,o"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chamzas, \u00aaSkew Detection and Text Line Position Determination in Digitized Documents,\u00ba Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Chamzas, \u00aaSkew Detection and Text Line Position Determination in Digitized Documents,\u00ba Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "In order to extract the periodicity of a region, we first find the page skew angle ( ) by a skew detection algorithm [14] and then get the horizontal (or vertical) projection profile according to the page skew angle ( ), as shown in (2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "Chamzas, aSkew Detection and Text Line Position Determination in Digitized Documents,o Pattern Recognition, vol. 30, pp. 1505-1519"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPage Segmentation Using the Description Background,\u00ba Computer Vision and Image Understanding"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaPage Segmentation Using the Description Background,\u00ba Computer Vision and Image Understanding"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "to as bottom-up methods [1], [2], [3]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "To reduce this computational complexity, a new bottom-up layout analysis method [3] has been presented."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and A"
            },
            "venue": {
                "fragments": [],
                "text": "Johnson, aA Fast Algorithm for Bottom- Up Document Layout Analysis,o IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 19, pp. 273-276"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Decomposition of an image An 1f into Anf, D1nf, D 2 nf, and D3nf [12].\nmatrix of the corresponding class and bi is 1 if the assigned class of bi is equal to class c; c 2 fI; T ;H; V g, otherwise, bi is 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Finally, the HH subimage has high frequencies in both horizontal and vertical directions and it corresponds to D(3)nf [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Finally, the HH subimage has high frequencies in both horizontal and vertical directions and it corresponds to D3nf [13]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and D"
            },
            "venue": {
                "fragments": [],
                "text": "Xi, aMultiresolution Analysis in Extraction of Reference Lines from Documents with Gray Level Background,o IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 19, pp. 921-926"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "To avoid this problem, the multiscale analysis has been applied in recent researches [8], [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aTrainable Context Model for Multiscale Segmentation,o"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Int'l Conf. Image Processing,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "to as bottom-up methods [1], [2], [3]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "After applying the Run Length Smoothing Algorithm (RLSA) [1] for linking disconnected ruling lines because of the binarization, if a region is composed of one connected component and its ratio of width to height or height to width is larger than 5, it is classified as a ruling line."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and H"
            },
            "venue": {
                "fragments": [],
                "text": "Emptoz, aA Fast and Efficient Method for Extracting Text Paragraphs and Graphics from Unconstrained Documents,o Proc. 11th Int'l Conf. Pattern Recognition, pp. 272-276"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, conclusions and further research directions are given in Section 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaPage Segmentation Using Texture Analysis,\u00ba Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "\u00aaPage Segmentation Using Texture Analysis,\u00ba Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Armi Professional for Windows 95/98 and NT Version 5"
            },
            "venue": {
                "fragments": [],
                "text": "Armi Professional for Windows 95/98 and NT Version 5"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "One major problem associated with such texture-based approaches [6], [7] is that the time complexity is too high since different filters are tuned to capture a desired local spatial frequency and the orientation characteristics of a textured region, so that many masks are used for extracting local features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "aText Segmentation Using Gabor Filters for Automatic Document Processing,o"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications,"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Geometric document layout analysis, parameter-free method, periodicity estimation, multiscale analysis, page segmentation.\n\u00e6"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Second Int'l Conf. Document Analysis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Second Int'l Conf. Document Analysis and Recognition"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Index Terms\u00d0Geometric document layout analysis, parameter-free method, periodicity estimation, multiscale analysis, page segmentation.\n\u00e6"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00aaMediaTeam Document Database ,\u00ba A CD-ROM Collection of Document Images"
            },
            "venue": {
                "fragments": [],
                "text": "Univ. of Oulu"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "To avoid this problem, the multiscale analysis has been applied in recent researches [8], [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and R"
            },
            "venue": {
                "fragments": [],
                "text": "Chellappa, aMultiscale Document Page Segmentation Using Soft Decision Integration,o IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 19, pp. 92-96"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OmniPage Pro for Windows 95/98 and NT Version 9"
            },
            "venue": {
                "fragments": [],
                "text": "OmniPage Pro for Windows 95/98 and NT Version 9"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 16,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Parameter-Free-Geometric-Document-Layout-Analysis-Lee-Ryu/30883efe17f9fb5b98e3e63584c5e3da4aec46b1?sort=total-citations"
}