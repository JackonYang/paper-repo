{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "We tried other features, including Gaussian filter responses [25], but the above set seemed to work the best."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The image matching problem is difficult and has prompted a number of publications that propose algorithms and features for the approach [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14013501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb5b66e55a73dc03b3dc675b4f5011e40ea27e9e",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "For the transition from traditional to digital libraries, the large number of handwritten manuscripts that exist pose a great challenge. Easy access to such collections requires an index, which is currently created manually at great cost. Because automatic handwriting recognizers fail on historical manuscripts, the word spotting technique has been developed: the words in a collection are matched as images and grouped into clusters which contain all instances of the same word. By annotating \"interesting\" clusters, an index that links words to the locations where they occur can be built automatically. Due to the noise in historical documents, selecting the right features for matching words is crucial. We analyzed a range of features suitable for matching words using dynamic time warping (DTW), which aligns and compares sets of features extracted from two images. Each feature's individual performance was measured on a test set. With an average precision of 72%, a combination of features outperforms competing techniques in speed and precision."
            },
            "slug": "Features-for-word-spotting-in-historical-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "Features for word spotting in historical manuscripts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A range of features suitable for matching words using dynamic time warping (DTW) are analyzed, which aligns and compares sets of features extracted from two images and outperforms competing techniques in speed and precision."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "If thresholding applied to the features extracted from the query and a candidate image determines that the images are dissimilar, we do not assign a similarity score to the candidate image (see [26] for details of this process)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The image matching problem is difficult and has prompted a number of publications that propose algorithms and features for the approach [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 42
                            }
                        ],
                        "text": "Several techniques have been investigated [24, 26, 27], with the best performing being Dynamic Time Warping matching [26], which we explain here in detail."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "DTW[26]: Dynamic Time Warping word image matching as described above."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15554170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e20e64661424bee772c7f002d45c1ac79578fb03",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Libraries and other institutions are interested in providing access to scanned versions of their large collections of handwritten historical manuscripts on electronic media. Convenient access to a collection requires an index, which is manually created at great labor and expense. Since current handwriting recognizers do not perform well on historical documents, a technique called word spotting has been developed: clusters with occurrences of the same word in a collection are established using image matching. By annotating \"interesting\" clusters, an index can be built automatically. We present an algorithm for matching handwritten words in noisy historical documents. The segmented word images are preprocessed to create sets of 1-dimensional features, which are then compared using dynamic time warping. We present experimental results on two different data sets from the George Washington collection. Our experiments show that this algorithm performs better and is faster than competing matching techniques."
            },
            "slug": "Word-image-matching-using-dynamic-time-warping-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "Word image matching using dynamic time warping"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents an algorithm for matching handwritten words in noisy historical documents that performs better and is faster than competing matching techniques and presents experimental results on two different data sets from the George Washington collection."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103948542"
                        ],
                        "name": "N. Srimal",
                        "slug": "N.-Srimal",
                        "structuredName": {
                            "firstName": "Nitin",
                            "lastName": "Srimal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Srimal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20611223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a32b8d899f3f41103445b81a93bb834125a480",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Indexing large archives of historical manuscripts, like the papers of George Washington, is required to allow rapid perusal by scholars and researchers who wish to consult the original manuscripts. Presently, such large archives are indexed manually. Since optical character recognition (OCR) works poorly with handwriting, a scheme based on matching word images called word spotting has been suggested previously for indexing such documents. The important steps in this scheme are segmentation of a document page into words and creation of lists containing instances of the same word by word image matching. \n \nWe have developed a novel methodology for segmenting handwritten document images by analyzing the extent of \"blobs\" in a scale space representationof the image. We believe this is the first application of scale space to this problem. The algorithm has been applied to around 30 grey level images randomly picked from Different sections of the George Washington corpus of 6,400 handwritten document images. An accuracy of 77-96 percent was observed with an average accuracy of around 87 percent. The algorithm works well in the presence of noise, shine through and other artifacts which may arise due aging and degradation of the page over a couple of centuries or through the man made processes of photocopying and scanning."
            },
            "slug": "Scale-Space-Technique-for-Word-Segmentation-in-Manmatha-Srimal",
            "title": {
                "fragments": [],
                "text": "Scale Space Technique for Word Segmentation in Handwritten Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A novel methodology for segmenting handwritten document images by analyzing the extent of \"blobs\" in a scale space representation of the image is developed, believed to be the first application of scale space to this problem."
            },
            "venue": {
                "fragments": [],
                "text": "Scale-Space"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2603631"
                        ],
                        "name": "C. Tomai",
                        "slug": "C.-Tomai",
                        "structuredName": {
                            "firstName": "Catalin",
                            "lastName": "Tomai",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tomai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119453473"
                        ],
                        "name": "Bin Zhang",
                        "slug": "Bin-Zhang",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117208225"
                        ],
                        "name": "Venu Govindaraju",
                        "slug": "Venu-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Venu Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[33] have shown how difficult this can be: the authors aligned a page of Thomas Jefferson with its manually generated transcript using recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14677442,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73843182aabc5f45efef4f49f9481ce45aba4558",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a large number of scanned historical documents that need to be indexed for archival and retrieval purposes. A visual word spotting scheme that would serve these purposes is a challenging task even when the transcription of the document image is available. We propose a framework for mapping each word in the transcript to the associated word image in the document. Coarse word mapping based on document constraints is used for lexicon reduction. Then, word mappings are refined using word recognition results by a dynamic programming algorithm that finds the best match while satisfying the constraints."
            },
            "slug": "Transcript-mapping-for-historic-handwritten-images-Tomai-Zhang",
            "title": {
                "fragments": [],
                "text": "Transcript mapping for historic handwritten document images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A framework for mapping each word in the transcript to the associated word image in the document and a dynamic programming algorithm that finds the best match while satisfying the constraints is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103948542"
                        ],
                        "name": "N. Srimal",
                        "slug": "N.-Srimal",
                        "structuredName": {
                            "firstName": "Nitin",
                            "lastName": "Srimal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Srimal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 58
                            }
                        ],
                        "text": "Segmentation for historical documents was investigated in [17, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Previous work by [17, 16] has dealt with the problem of segmenting such images of historical documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16554591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52a55cc457c6ebe2e1d6bde34ccb06c552bcddde",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Indexing large archives of historical manuscripts is required to allow rapid perusal by scholars and researchers who wish to consult the original manuscripts. However, automatic conversion of handwritten manuscripts to digital form allowing eecient storage and retrieval of the original documents is a challenging problem. Word spotting is a scheme to index such data. The important steps in this scheme are segmentation of a document page into words and creation of lists containing instances of the same word by word image matching. We have developed a novel methodology for segmenting handwritten document images by analyzing the extent of \\blobs\" in a scale space representation of the image. The algorithm was been applied to around 30 grey level images randomly picked from diierent sections of the George Washington corpus of 6,400 handwritten document images. An accuracy of 77 ? 96 percent was observed with an average accuracy of around 87 percent. The algorithm works well in the presence of noise, shine through and other artifacts which may arise due aging and degradation of the page over a couple of centuries or through the man made processes of photocopying and scanning. end ital-ics mode"
            },
            "slug": "Scale-Space-Technique-for-Word-Segmentation-in-Manmatha-Srimal",
            "title": {
                "fragments": [],
                "text": "Scale Space Technique for Word Segmentation in Handwritten Manuscripts"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A novel methodology for segmenting handwritten document images by analyzing the extent of \"blobs\" in a scale space representation of the image is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1886047"
                        ],
                        "name": "Chengfeng Han",
                        "slug": "Chengfeng-Han",
                        "structuredName": {
                            "firstName": "Chengfeng",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengfeng Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The image matching problem is difficult and has prompted a number of publications that propose algorithms and features for the approach [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6141115,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c15155645fb0eebbd5400cbd2cd772ab22af0cc",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many historical manuscripts written in a single hand which it would be useful to index. Examples include the W.B. DuBois collection at the University of Massachusetts and the early Presidential libraries at the Library of Congress. Since Optical Character Recognition (OCR) does not work well on handwriting, an alternative scheme based on matching the images of the words is proposed for indexing such texts. The current paper deals with the matching aspects of this process. Two different techniques for matching words are discussed. The first method matches words assuming that the transformation between the words may be modelled by a translation (shift). The second method matches words assuming that the transformation between the words may be modelled by an affine transform. Experiments are shown demonstrating the feasibility of the approach for indexing handwriting. The method should also be applicable to retrieving previously stored material from personal digital assistants (PDAs)."
            },
            "slug": "Word-spotting:-a-new-approach-to-indexing-Manmatha-Han",
            "title": {
                "fragments": [],
                "text": "Word spotting: a new approach to indexing handwriting"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experiments are shown demonstrating the feasibility of the approach for indexing handwriting and the method should also be applicable to retrieving previously stored material from personal digital assistants (PDAs)."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845217"
                        ],
                        "name": "Jamie L. Rothfeder",
                        "slug": "Jamie-L.-Rothfeder",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Rothfeder",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie L. Rothfeder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1857558"
                        ],
                        "name": "Shaolei Feng",
                        "slug": "Shaolei-Feng",
                        "structuredName": {
                            "firstName": "Shaolei",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaolei Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "On query set B, the average precision scores for DTW and CORR are lower than on the smaller subset A."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The image matching problem is difficult and has prompted a number of publications that propose algorithms and features for the approach [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 42
                            }
                        ],
                        "text": "Several techniques have been investigated [24, 26, 27], with the best performing being Dynamic Time Warping matching [26], which we explain here in detail."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 313,
                                "start": 309
                            }
                        ],
                        "text": "DTW is compared with a number of other techniques including XOR, affine-corrected Euclidean Distance Matching, shape context [2], intensity correlation using sum-of-squared differences, an affine matching point matching algorithm due to Scott and Longuet-Higgins [30] and a point correlation voting algorithm [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "This shows that the DTW and CORR matching techniques are more robust to document degradation than EDM, with DTW - again - showing superior performance to CORR on the exhaustive query set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "CORR[27]: This technique recovers similarities between a small number of corner points in the query and candidate images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "CORR[27]: This technique recovers similarities between a small number of corner\npoints in the query and candidate images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "While the performance of all approaches is generally low on data set C, DTW\u2019s and CORR\u2019s performance is almost four times better than that of EDM (58.81% and 59.96% vs. 15.05%)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "The DTW and CORR algorithms were also used in experiment B (all images used as templates)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Comparing the running times of the investigated algorithms (see Table 5) shows CORR in the lead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "EDM, DTW and CORR clearly outperform any of the other techniques."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "We compared the results of the SC, CORR, EDM and DTW techniques on data set C."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "While the performance of DTW was slightly worse than CORR\u2019s on the smaller query set A, DTW outperforms CORR on query set B, which is much larger and makes for a better comparison."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "CORR\u2019s superior execution is a result of the very few corner points that are considered for establishing correspondences between the query and a candidate image."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2964604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc3e163518ef7324dd3b563b349da1d64e4b26b5",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Libraries contain enormous amounts of handwritten historical documents which cannot be made available on-line because they do not have a searchable index. The wordspotting idea has previously been proposed as a solution to creating indexes for such documents and collections by matching word images. In this paper we present an algorithm which compares whole word-images based on their appearance. This algorithm recovers correspondences of points of interest in two images, and then uses these correspondences to construct a similarity measure. This similarity measure can then be used to rank word-images in order of their closeness to a querying image. We achieved an average precision of 62.57% on a set of 2372 images of reasonable quality and an average precision of 15.49% on a set of 3262 images from documents of poor quality that are even hard to read for humans."
            },
            "slug": "Using-Corner-Feature-Correspondences-to-Rank-Word-Rothfeder-Feng",
            "title": {
                "fragments": [],
                "text": "Using Corner Feature Correspondences to Rank Word Images by Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents an algorithm which compares whole word-images based on their appearance, and recovers correspondences of points of interest in two images, and then uses these correspondences to construct a similarity measure which can be used to rank word- images in order of their closeness to a querying image."
            },
            "venue": {
                "fragments": [],
                "text": "2003 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845217"
                        ],
                        "name": "Jamie L. Rothfeder",
                        "slug": "Jamie-L.-Rothfeder",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Rothfeder",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie L. Rothfeder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 58
                            }
                        ],
                        "text": "Segmentation for historical documents was investigated in [17, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 17
                            }
                        ],
                        "text": "Previous work by [17, 16] has dealt with the problem of segmenting such images of historical documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12534822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c3b3565ea3df7d6b1d8364f7f5e4b48d08df723",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Many libraries, museums, and other organizations contain large collections of handwritten historical documents, for example, the papers of early presidents like George Washington at the Library of Congress. The first step in providing recognition/retrieval tools is to automatically segment handwritten pages into words. State of the art segmentation techniques like the gap metrics algorithm have been mostly developed and tested on highly constrained documents like bank checks and postal addresses. There has been little work on full handwritten pages and this work has usually involved testing on clean artificial documents created for the purpose of research. Historical manuscript images, on the other hand, contain a great deal of noise and are much more challenging. Here, a novel scale space algorithm for automatically segmenting handwritten (historical) documents into words is described. First, the page is cleaned to remove margins. This is followed by a gray-level projection profile algorithm for finding lines in images. Each line image is then filtered with an anisotropic Laplacian at several scales. This procedure produces blobs which correspond to portions of characters at small scales and to words at larger scales. Crucial to the algorithm is scale selection that is, finding the optimum scale at which blobs correspond to words. This is done by finding the maximum over scale of the extent or area of the blobs. This scale maximum is estimated using three different approaches. The blobs recovered at the optimum scale are then bounded with a rectangular box to recover the words. A post processing filtering step is performed to eliminate boxes of unusual size which are unlikely to correspond to words. The approach is tested on a number of different data sets and it is shown that, on 100 sampled documents from the George Washington corpus of handwritten document images, a total error rate of 17 percent is observed. The technique outperforms a state-of-the-art gap metrics word-segmentation algorithm on this collection."
            },
            "slug": "A-scale-space-approach-for-automatically-segmenting-Manmatha-Rothfeder",
            "title": {
                "fragments": [],
                "text": "A scale space approach for automatically segmenting words from historical handwritten documents"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A novel scale space algorithm for automatically segmenting handwritten (historical) documents into words is described and it is shown that the technique outperforms a state-of-the-art gap metrics word-segmentation algorithm on this collection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34800213"
                        ],
                        "name": "S. Kane",
                        "slug": "S.-Kane",
                        "structuredName": {
                            "firstName": "Satoshi",
                            "lastName": "Kane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934311"
                        ],
                        "name": "A. Lehman",
                        "slug": "A.-Lehman",
                        "structuredName": {
                            "firstName": "April",
                            "lastName": "Lehman",
                            "middleNames": [
                                "Rasala"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lehman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35219135"
                        ],
                        "name": "E. Partridge",
                        "slug": "E.-Partridge",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Partridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Partridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The image matching problem is difficult and has prompted a number of publications that propose algorithms and features for the approach [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 42
                            }
                        ],
                        "text": "Several techniques have been investigated [24, 26, 27], with the best performing being Dynamic Time Warping matching [26], which we explain here in detail."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14305638,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfd71f70b31c8dd6f0ce21d1b8779f574c62d871",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In a multimedia world, one would like electronic access to all kinds of information. But a lot of important information still only exists on paper and it is a challenge to efficiently access or navigate this information even if it is scanned in. The previously proposed \u201cword spotting\u201d idea is an approach for accessing and navigating a collection of handwritten documents available as images using an index automatically generated by matching words as pictures. The most difficult task in solving this problem is the matching of word images. The quality of the aged documents and the variations in handwriting make this a challenging problem. Here we present a number of word matching techniques along with new normalization methods that are crucial for their success. Efficient pruning techniques, which quickly reduce the set of possible matches for a given word, are also discussed. Our results show that the best of the discussed matching algorithms achieves an average precision of 73% for documents of reasonable quality."
            },
            "slug": "Indexing-for-a-Digital-Library-of-George-A-Study-of-Rath-Kane",
            "title": {
                "fragments": [],
                "text": "Indexing for a Digital Library of George Washington\u2019s Manuscripts: A Study of Word Matching Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A number of word matching techniques along with new normalization methods that are crucial for their success are presented, and efficient pruning techniques, which quickly reduce the set of possible matches for a given word, are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61402834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c7853e6b8375a1a305f008e019dce92155c879",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "Historical library collections across the world hold huge numbers of handwritten documents. By digitizing these manuscripts, their content can be preserved and made available to a large community via the Internet or other electronic media. Such corpora can nowadays be shared relatively easily, but they are often large, unstructured, and only available in image formats, which makes them difficult to access. In particular, finding specific locations of interest in a handwritten image collection is generally very tedious without some sort of index or other access tool. \nThe current solution for this problem is to manually annotate a historical collection, which is very costly in terms of time and money. In this work we explore several automatic techniques that allow the retrieval of handwritten document images with text queries. These are (i)\u00a0word spotting, an approach that clusters word images to identify and annotate content-bearing words in a collection, (ii)\u00a0handwriting recognition followed by text retrieval, and (iii)\u00a0cross-modal retrieval models, which capture the joint occurrence of annotations and word image features in a probabilistic model. We compare the performance of these approaches empirically on several test collections. \nThe main contributions of this work are a detailed examination of retrieval approaches for historical manuscripts, and the development of the first image retrieval system for historical manuscripts that allows text queries. This system extends the field of digital libraries beyond machine printed text into historical handwritten documents. Building such a system involves challenges on numerous levels: the noisy historical manuscript domain requires adequate image filtering, normalization and representation techniques, as well as a robust and scalable retrieval framework. We describe the construction of a prototype system, which demonstrates the feasibility of the proposed techniques for a large collection of handwritten historical documents."
            },
            "slug": "Retrieval-of-handwritten-historical-document-images-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "Retrieval of handwritten historical document images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The construction of a prototype system is described, which demonstrates the feasibility of the proposed techniques for a large collection of handwritten historical documents, and the development of the first image retrieval system for historical manuscripts that allows text queries is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1886047"
                        ],
                        "name": "Chengfeng Han",
                        "slug": "Chengfeng-Han",
                        "structuredName": {
                            "firstName": "Chengfeng",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengfeng Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15], treats a collection of documents as a collection of word images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9140590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e933c380d2921cb122657675baf45bd13b4bb40",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many historical manuscripts written in a single hand which it would be useful to index. Examples include the W. B. DuBois collection at the University of Massachusetts and the early Presidential libraries at the Library of Congress. The standard technique for indexing documents is to scan them in, convert them to machine readable form (ASCII) using Optical Character Recognition (OCR) and then index them using a text retrieval engine. However, OCR does not work well on handwriting. Here an alternative scheme is proposed for indexing such texts. Each page of the document is segmented into words. The images of the words are then matched against each other to create equivalence classes (each equivalence classes contains multiple instances of the same word). The user then provides ASCII equivalents for say the top 2000 equivalence classes. The current paper deals with the matching aspects of this process. Due to variations in even a single person\u2019s handwriting, it is expected that the matching will be the most difficult step in the whole process. A matching technique based on Euclidean distance mapping is discussed. Experiments are shown demonstrating the feasibility of the approach."
            },
            "slug": "Indexing-handwriting-using-word-matching-Manmatha-Han",
            "title": {
                "fragments": [],
                "text": "Indexing handwriting using word matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Due to variations in even a single person\u2019s handwriting, it is expected that the matching will be the most difficult step in the whole process."
            },
            "venue": {
                "fragments": [],
                "text": "DL '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450058"
                        ],
                        "name": "S. Khoubyari",
                        "slug": "S.-Khoubyari",
                        "structuredName": {
                            "firstName": "Siamak",
                            "lastName": "Khoubyari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khoubyari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18352124,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science",
                "Education"
            ],
            "id": "b3e9bc137ff6d84f42cfa0c3a5088e6f3941cd5f",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "It may be difficult to locate keywords in noisy document images because of degraded OCR performance. A new technique for word image matching has the potential to select those. word images in a document that . represent potential keywords and to generate improved prototypes for those keywords. No explicit recognition is pe~formed in this process, but better OCR performance will occur on the improved prototypes' than \u2022 would occur on any of the isolated\" words. The proposed method for keyword selection and recognition is best suited for document indexing in an image-based document retrieval system.. This paper presents an algorithm for word image clustering and discusses how it is applied to locate groups of equivalent word images in a document. Improved prototypes are generated for clusters that represent potential keywords. The results of applying the algorithm to an article in the Brown Corpus are given. The keywdrds chosen by this' approach and those chosen from the ASCII text of the article by a conventional keyword selection methodology are compared. The potential for improvementin recognition performance on those keywords is also demonstrated."
            },
            "slug": "Keyword-Location-in-Noisy-Document-Images-Khoubyari-Hull",
            "title": {
                "fragments": [],
                "text": "Keyword Location in Noisy Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "An algorithm for word image clustering is presented and how it is applied to locate groups of equivalent word images in a document is discussed and improved prototypes are generated for clusters that represent potential keywords."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[32] proposed the first automatic retrieval system for historical handwritten documents using relevance models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Results are not directly comparable since the aim of the paper [32] was to do retrieval while the results reported here focus on word error rates (WER)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 14226850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e8a66067ec01e486ea39c0d6bec42fee80a3dc0",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Many museum and library archives are digitizing their large collections of handwritten historical manuscripts to enable public access to them. These collections are only available in image formats and require expensive manual annotation work for access to them. Current handwriting recognizers have word error rates in excess of 50% and therefore cannot be used for such material. We describe two statistical models for retrieval in large collections of handwritten manuscripts given a text query. Both use a set of transcribed page images to learn a joint probability distribution between features computed from word images and their transcriptions. The models can then be used to retrieve unlabeled images of handwritten documents given a text query. We show experiments with a training set of 100 transcribed pages and a test set of 987 handwritten page images from the George Washington collection. Experiments show that the precision at 20 documents is about 0.4 to 0.5 depending on the model. To the best of our knowledge, this is the first automatic retrieval system for historical manuscripts using text queries, without manual transcription of the original corpus."
            },
            "slug": "A-search-engine-for-historical-manuscript-images-Rath-Manmatha",
            "title": {
                "fragments": [],
                "text": "A search engine for historical manuscript images"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work describes two statistical models for retrieval in large collections of handwritten manuscripts given a text query, which is the first automatic retrieval system for historical manuscripts using text queries, without manual transcription of the original corpus."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2352980"
                        ],
                        "name": "T. Rath",
                        "slug": "T.-Rath",
                        "structuredName": {
                            "firstName": "Toni",
                            "lastName": "Rath",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[10] trained an HMM model on 19 pages of the dataset used in this paper and tested on the remaining page."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "The annotated data set is publicly available and was originally used in [10] for doing recognition experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17052863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba92485155695e1af13b905f03ac63add113bb4d",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Most offline handwriting recognition approaches proceed by segmenting words into smaller pieces (usually characters) which are recognized separately. The recognition result of a word is then the composition of the individually recognized parts. Inspired by results in cognitive psychology, researchers have begun to focus on holistic word recognition approaches. Here we present a holistic word recognition approach for single-author historical documents, which is motivated by the fact that for severely degraded documents a segmentation of words into characters will produce very poor results. The quality of the original documents does not allow us to recognize them with high accuracy - our goal here is to produce transcriptions that will allow successful retrieval of images, which has been shown to be feasible even in such noisy environments. We believe that this is the first systematic approach to recognizing words in historical manuscripts with extensive experiments. Our experiments show recognition accuracy of 65%, which exceeds performance of other systems which operate on non-degraded input images (nonhistorical documents)."
            },
            "slug": "Holistic-word-recognition-for-handwritten-documents-Lavrenko-Rath",
            "title": {
                "fragments": [],
                "text": "Holistic word recognition for handwritten historical documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work believes that this is the first systematic approach to recognizing words in historical manuscripts with extensive experiments, which exceeds performance of other systems which operate on non-degraded input images (nonhistorical documents)."
            },
            "venue": {
                "fragments": [],
                "text": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35709566"
                        ],
                        "name": "Francine R. Chen",
                        "slug": "Francine-R.-Chen",
                        "structuredName": {
                            "firstName": "Francine",
                            "lastName": "Chen",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francine R. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308281"
                        ],
                        "name": "D. Bloomberg",
                        "slug": "D.-Bloomberg",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Bloomberg",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bloomberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144115507"
                        ],
                        "name": "L. Wilcox",
                        "slug": "L.-Wilcox",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Wilcox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Wilcox"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43449911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e871748fa5f64a4085d9c77ba6e4423a6b767dd0",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A system that searches for user-specified phrases in imaged text is described. The search `phrases' can be word fragments, words, or groups of words. The imaged text can be composed of a number of different fonts and can contain graphics. A combination of morphology, simple statistical methods and hidden Markov modeling is used to detect and locate the phrases. The image is deskewed, and then bounding boxes are found for text-lines in the image using multiresolution morphology. Baselines, toplines and the x-height in a text-line are identified using simple statistical methods. The distance between baseline and x-height is used to normalize each hypothesized text-line bounding box, and the columns of pixel values in a normalized bounding box serve as the feature vector for that box. Hidden Markov models are crated for each user-specified search string and to represent all text and graphics other than the search strings. Phrases are identified using Viterbi decoding on a spotting network created from the models. The operating point of the system can be varied to trade off the percentage of words correctly spotted and the percentage of false alarms. Results are given using a subset of the UW English Document Image Database I."
            },
            "slug": "Spotting-phrases-in-lines-of-imaged-text-Chen-Bloomberg",
            "title": {
                "fragments": [],
                "text": "Spotting phrases in lines of imaged text"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A system that searches for user-specified phrases in imaged text using a combination of morphology, simple statistical methods and hidden Markov modeling to detect and locate the phrases."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719436"
                        ],
                        "name": "A. Vinciarelli",
                        "slug": "A.-Vinciarelli",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vinciarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vinciarelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "More recently, the community has started to look at large-vocabulary tasks [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9158529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4977e1a4317d2e31cca2b9e8438bbbfc0c39f9cc",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a system for the offline recognitionof cursive handwritten lines of text. The system is based oncontinuous density HMMs and Statistical Language Models.The system recognizes data produced by a single writer.No a-priori knowledge is used about the content of the textto be recognized. Changes in the experimental setup withrespect to the recognition of single words are highlighted.The results show a recognition rate of ~85% with a lexiconcontaining 50'000 words. The experiments were performedover a publicly available database."
            },
            "slug": "Offline-recognition-of-large-vocabulary-cursive-Vinciarelli-Bengio",
            "title": {
                "fragments": [],
                "text": "Offline recognition of large vocabulary cursive handwritten text"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper presents a system for the offline recognition of cursive handwritten lines of text based on continuous density HMMs and Statistical Language Models, which shows a recognition rate of ~85% with a lexicon containing 50'000 words."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36784079"
                        ],
                        "name": "H. Xue",
                        "slug": "H.-Xue",
                        "structuredName": {
                            "firstName": "Hanhong",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Xue"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Govindaraju and Xie [3] also investigated the problem of handwriting recognition in historical documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14728858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7f498bd15b66be8b7910edf7e94d4881cf3935b9",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwriting recognition (HR) has been successfully used in several applications such as postal address interpretation [S. Srihari et al., (1997)], bank check reading [S. Impedovo et al., (1997)], and forms reading [S. Madhvanath et al., (1995)]. These applications are all characterized by small or fixed lexicons afforded by contextual knowledge. Machine recognition of handwriting in historical documents presents two primary challenges: (i) large lexicons (over 10000 words) leading to low recognition accuracy (less than 50%) and (ii) a need for high speed HR given the millions of handwritten manuscripts in digital library repositories and that the speed is usually inversely proportional to lexicon size. We address the issue of speed when dealing with large lexicons. We present several techniques to improve the processing speed for a gain of up to 7 times in matching time and describe a method whereby the large lexicon is divided into smaller sets and processed in parallel. With 4 processors 18 times speedup for the matching phase is achieved."
            },
            "slug": "Fast-handwriting-recognition-for-indexing-documents-Govindaraju-Xue",
            "title": {
                "fragments": [],
                "text": "Fast handwriting recognition for indexing historical documents"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work presents several techniques to improve the processing speed for a gain of up to 7 times in matching time and describes a method whereby the large lexicon is divided into smaller sets and processed in parallel."
            },
            "venue": {
                "fragments": [],
                "text": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143723939"
                        ],
                        "name": "G. Jones",
                        "slug": "G.-Jones",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144774480"
                        ],
                        "name": "J. Foote",
                        "slug": "J.-Foote",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Foote",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Foote"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We would like to note that the idea of spotting keywords has been proposed before in speech [ 8 ] and for printed documents [3,10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37833635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c36ac1278637875f0e31e34f7a86810c5bb1e",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of the video mail retrieval project is to integrate state-of-the-art document retrieval methods with high accuracy word spotting to yield a robust and efficient retrieval system. This paper describes a preliminary study to determine the extent to which retrieval precision is affected by word spotting performance. It includes a description of the database design, the word spotting algorithm, and the information retrieval method used. Results are presented which show audio retrieval performance very close to that of text."
            },
            "slug": "Video-mail-retrieval:-the-effect-of-word-spotting-Jones-Foote",
            "title": {
                "fragments": [],
                "text": "Video mail retrieval: the effect of word spotting accuracy on precision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A preliminary study to determine the extent to which retrieval precision is affected by word spotting performance is described, which shows audio retrieval performance very close to that of text."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157691706"
                        ],
                        "name": "Gyeonghwan Kim",
                        "slug": "Gyeonghwan-Kim",
                        "structuredName": {
                            "firstName": "Gyeonghwan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyeonghwan Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117208225"
                        ],
                        "name": "Venu Govindaraju",
                        "slug": "Venu-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Venu Govindaraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "There is much less work on historical handwritten documents which are much more challenging."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8835228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4ad2ee0cca4e30b61343453d11fa1df241f50a4",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. This paper presents an end-to-end system for reading handwritten page images. Five functional modules included in the system are introduced in this paper: (i) pre-processing, which concerns introducing an image representation for easy manipulation of large page images and image handling procedures using the image representation; (ii) line separation, concerning text line detection and extracting images of lines of text from a page image; (iii) word segmentation, which concerns locating word gaps and isolating words from a line of text image obtained efficiently and in an intelligent manner; (iv) word recognition, concerning handwritten word recognition algorithms; and (v) linguistic post-pro- cessing, which concerns the use of linguistic constraints to intelligently parse and recognize text. Key ideas employed in each functional module, which have been developed for dealing with the diversity of handwriting in its various aspects with a goal of system reliability and robustness, are described in this paper. Preliminary experiments show promising results in terms of speed and accuracy."
            },
            "slug": "An-architecture-for-handwritten-text-recognition-Kim-Govindaraju",
            "title": {
                "fragments": [],
                "text": "An architecture for handwritten text recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Key ideas employed in each functional module, which have been developed for dealing with the diversity of handwriting in its various aspects with a goal of system reliability and robustness, are described in this paper."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37526757"
                        ],
                        "name": "Urs-Viktor Marti",
                        "slug": "Urs-Viktor-Marti",
                        "structuredName": {
                            "firstName": "Urs-Viktor",
                            "lastName": "Marti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs-Viktor Marti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In [ 18 ], the authors discuss the application of a Hidden Markov model for recognizing"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10207300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15725948c2ea8b190b825a0887e430dc4898428",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a system for the reading of totally unconstrained handwritten text is presented. The kernel of the system is a hidden Markov model (HMM) for handwriting recognition. The HMM is enhanced by a statistical language model. Thus linguistic knowledge beyond the lexicon level is incorporated in the recognition process. Another novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided. A number of experiments with various language models and large vocabularies have been conducted. The language models used in the system were also analytically compared based on their perplexity."
            },
            "slug": "Using-a-Statistical-Language-Model-to-Improve-the-Marti-Bunke",
            "title": {
                "fragments": [],
                "text": "Using a Statistical Language Model to Improve the Performance of an HMM-Based Cursive Handwriting Recognition System"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel feature of the system is that the HMM is applied in such a way that the difficult problem of segmenting a line of text into individual words is avoided and linguistic knowledge beyond the lexicon level is incorporated in the recognition process."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690399"
                        ],
                        "name": "T. Paquet",
                        "slug": "T.-Paquet",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Paquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Paquet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346993"
                        ],
                        "name": "Y. Lecourtier",
                        "slug": "Y.-Lecourtier",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Lecourtier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lecourtier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "37% for a 966 word vocabulary reported in [ 21 ], to a recognition rate of 55.6% in a 1600"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30994356,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "cf6e4d615a728f6b255a9d0082b7fbf990a9002f",
            "isKey": true,
            "numCitedBy": 37,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recognition-of-handwritten-sentences-using-a-Paquet-Lecourtier",
            "title": {
                "fragments": [],
                "text": "Recognition of handwritten sentences using a restricted lexicon"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16902271"
                        ],
                        "name": "H. P. Luhn",
                        "slug": "H.-P.-Luhn",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Luhn",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. P. Luhn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Luhn argued that index terms should be taken from the middle of that distribution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "This is followed by a discussion of which clusters are \u201cinteresting\u201d to index based\non Luhn\u2019s ideas [12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following Luhn\u2019s line of thought, we can identify clusters that should make good candidates for an index."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "Early work in information retrieval by Luhn [12] lets us concretize the notion of \u201cinteresting\u201d clusters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15475171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6dcc17c6f3dbc2d203ade9ff671a895a9dead7c",
            "isKey": true,
            "numCitedBy": 3145,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Excerpts of technical papers and magazine articles that serve the purposes of conventional abstracts have been created entirely by automatic means. In the exploratory research described, the complete text of an article in machine-readable form is scanned by an IBM 704 data-processing machine and analyzed in accordance with a standard program. Statistical information derived from word frequency and distribution is used by the machine to compute a relative measure of significance, first for individual words and then for sentences. Sentences scoring highest in significance are extracted and printed out to become the \"auto-abstract.\""
            },
            "slug": "The-Automatic-Creation-of-Literature-Abstracts-Luhn",
            "title": {
                "fragments": [],
                "text": "The Automatic Creation of Literature Abstracts"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "In the exploratory research described, the complete text of an article in machine-readable form is scanned by an IBM 704 data-processing machine and analyzed in accordance with a standard program."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2779846"
                        ],
                        "name": "H. Sakoe",
                        "slug": "H.-Sakoe",
                        "structuredName": {
                            "firstName": "Hiroaki",
                            "lastName": "Sakoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35805230"
                        ],
                        "name": "S. Chiba",
                        "slug": "S.-Chiba",
                        "structuredName": {
                            "firstName": "Seibi",
                            "lastName": "Chiba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chiba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17900407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f355d7ef4aa9f82bf5c00f84e46714efa5fd77",
            "isKey": false,
            "numCitedBy": 5370,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition. First, a general principle of time-normalization is given using time-warping function. Then, two time-normalized distance definitions, called symmetric and asymmetric forms, are derived from the principle. These two forms are compared with each other through theoretical discussions and experimental studies. The symmetric form algorithm superiority is established. A new technique, called slope constraint, is successfully introduced, in which the warping function slope is restricted so as to improve discrimination between words in different categories. The effective slope constraint characteristic is qualitatively analyzed, and the optimum slope constraint condition is determined through experiments. The optimized algorithm is then extensively subjected to experimental comparison with various DP-algorithms, previously applied to spoken word recognition by different research groups. The experiment shows that the present algorithm gives no more than about two-thirds errors, even compared to the best conventional algorithm."
            },
            "slug": "Dynamic-programming-algorithm-optimization-for-word-Sakoe-Chiba",
            "title": {
                "fragments": [],
                "text": "Dynamic programming algorithm optimization for spoken word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper reports on an optimum dynamic progxamming (DP) based time-normalization algorithm for spoken word recognition, in which the warping function slope is restricted so as to improve discrimination between words in different categories."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144586498"
                        ],
                        "name": "R. Plamondon",
                        "slug": "R.-Plamondon",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Plamondon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plamondon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In recent years, research in handwriting recognition [ 22 ]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15782139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12864a8acbab1830be755bfb9cb177e31ca5e20",
            "isKey": false,
            "numCitedBy": 2743,
            "numCiting": 719,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered."
            },
            "slug": "On-Line-and-Off-Line-Handwriting-Recognition:-A-Plamondon-Srihari",
            "title": {
                "fragments": [],
                "text": "On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[35]), such that an approximate reconstruction of a word from its features would be possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205015030,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8b7804abc030ee93eff2f5baa306b8b95361c57",
            "isKey": false,
            "numCitedBy": 1450,
            "numCiting": 137,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-extraction-methods-for-character-survey-Trier-Jain",
            "title": {
                "fragments": [],
                "text": "Feature extraction methods for character recognition-A survey"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711390"
                        ],
                        "name": "G. Leedham",
                        "slug": "G.-Leedham",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Leedham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leedham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29809744"
                        ],
                        "name": "S. Varma",
                        "slug": "S.-Varma",
                        "structuredName": {
                            "firstName": "Saket",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34241580"
                        ],
                        "name": "A. Patankar",
                        "slug": "A.-Patankar",
                        "structuredName": {
                            "firstName": "Anish",
                            "lastName": "Patankar",
                            "middleNames": [
                                "Anil"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Patankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "our purposes. For more sophisticated foreground/background separation, see [ 11 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7432306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e933ad6f822a46fb5f92a2a33915dec9896f98a0",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Before any processing of the textual content of a document image can be performed the text must be separated from the background of the image. Several thresholding algorithms have previously been proposed and are widely used in document processing. None have been shown effective at thresholding difficult documents where the background and foreground are non-uniform. In this paper we investigate the use of three global thresholding algorithms (Otsu's, Kapur's entropy and Solihin's quadratic integral ratio (QIR)) as the first stage in a multi-stage thresholding algorithm for use in degraded document images. It is concluded that Otsu's and Kapur's algorithms do not work well for difficult documents as they tend to over-threshold the image, thus losing much of the useful information. The QIR algorithm is more accurate in separating the foreground and background in these images, leaving a range of undecided, fuzzy, pixels for later processing in a subsequent stage."
            },
            "slug": "Separating-text-and-background-in-degraded-document-Leedham-Varma",
            "title": {
                "fragments": [],
                "text": "Separating text and background in degraded document images - a comparison of global thresholding techniques for multi-stage thresholding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper investigates the use of three global thresholding algorithms as the first stage in a multi-stage thresholding algorithm for use in degraded document images and concludes that Otsu's and Kapur's algorithms do not work well for difficult documents as they tend to over-threshold the image, thus losing much of the useful information."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth International Workshop on Frontiers in Handwriting Recognition"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685310"
                        ],
                        "name": "F. Itakura",
                        "slug": "F.-Itakura",
                        "structuredName": {
                            "firstName": "Fumitada",
                            "lastName": "Itakura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Itakura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 154
                            }
                        ],
                        "text": "Our implementation of DTW uses the Sakoe-Chiba band [28] (see Figure 7(b); the warping path must lie in the shaded region), but the Itakura parallelogram [6] is also a popular choice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61601418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf2b0948ec73e21f6d5a67b22a31a20d503cc9e",
            "isKey": false,
            "numCitedBy": 1241,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections. The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time."
            },
            "slug": "Minimum-prediction-residual-principle-applied-to-Itakura",
            "title": {
                "fragments": [],
                "text": "Minimum prediction residual principle applied to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual through optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701931"
                        ],
                        "name": "G. Scott",
                        "slug": "G.-Scott",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Scott",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Scott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92269846"
                        ],
                        "name": "H. C. Longuet-Higgins",
                        "slug": "H.-C.-Longuet-Higgins",
                        "structuredName": {
                            "firstName": "Hugh",
                            "lastName": "Longuet-Higgins",
                            "middleNames": [
                                "Christopher"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. C. Longuet-Higgins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13011932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "281a3859b8ead503067f52e653dff28ed534d6d2",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe an algorithm that operates on the distances between features in the two related images and delivers a set of correspondences between them. The algorithm maximizes the inner product of two matrices, one of which is the desired \u2018pairing matrix \u2019 and the other a \u2018proximity matrix \u2019 with elements exp (\u2013 r2ij/2\u03c32), where rij is the distance between two features, one in each image, and \u03c3 is an adjustable scale parameter. The output of the algorithm may be compared with the movements that people perceive when viewing two images in quick succession, and it is found that an increase in \u03c3 affects the computed correspondences in much the same way as an increase in interstimulus interval alters the perceived displacements. Provided that \u03c3 is not too small the algorithm will recover the feature mappings that result from image translation, expansion or shear deformation \u2013 transformations of common occurrence in image sequences \u2013 even when the displacements of individual features depart slightly from the general trend."
            },
            "slug": "An-algorithm-for-associating-the-features-of-two-Scott-Longuet-Higgins",
            "title": {
                "fragments": [],
                "text": "An algorithm for associating the features of two images"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An algorithm that operates on the distances between features in the two related images and delivers a set of correspondences between them and will recover the feature mappings that result from image translation, expansion or shear deformation even when the displacements of individual features depart slightly from the general trend."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Royal Society of London. Series B: Biological Sciences"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145043192"
                        ],
                        "name": "C. Ratanamahatana",
                        "slug": "C.-Ratanamahatana",
                        "structuredName": {
                            "firstName": "Chotirat",
                            "lastName": "Ratanamahatana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ratanamahatana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50543766"
                        ],
                        "name": "Eamonn J. Keogh",
                        "slug": "Eamonn-J.-Keogh",
                        "structuredName": {
                            "firstName": "Eamonn",
                            "lastName": "Keogh",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eamonn J. Keogh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Recent work [23] shows that the size and shape of the global path constraint can be adapted, leading to faster DTW computations and better matching performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 368401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e2ecadc4f7dd691e89ea2c245cc0b83b043f9f1",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been known that Dynamic Time Warping (DTW) is superior to Euclidean distance for classification and clustering of time series. However, until lately, most research has utilized Euclidean distance because it is more efficiently calculated. A recently introduced technique that greatly mitigates DTWs demanding CPU time has sparked a flurry of research activity. However, the technique and its many extensions still only allow DTW to be applied to moderately large datasets. In addition, almost all of the research on DTW has focused exclusively on speeding up its calculation; there has been little work done on improving its accuracy. In this work, we target the accuracy aspect of DTW performance and introduce a new framework that learns arbitrary constraints on the warping path of the DTW calculation. Apart from improving the accuracy of classification, our technique as a side effect speeds up DTW by a wide margin as well. We show the utility of our approach on datasets from diverse domains and demonstrate significant gains in accuracy and efficiency. E u clid ean D istan c e D yn am ic T im e W arp in g D is tan ce Figure 1: Note that while the two time series have an overall similar shape, they are not aligned in the time axis. Euclidean distance, which assumes the i point in one sequence is aligned with the i point in the other, will produce a pessimistic dissimilarity measure. The non-linear Dynamic Time Warped alignment allows a more intuitive distance measure to be calculated."
            },
            "slug": "Making-Time-Series-Classification-More-Accurate-Ratanamahatana-Keogh",
            "title": {
                "fragments": [],
                "text": "Making Time-Series Classification More Accurate Using Learned Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work targets the accuracy aspect of DTW performance and introduces a new framework that learns arbitrary constraints on the warping path of the DTW calculation and speeds up DTW by a wide margin."
            },
            "venue": {
                "fragments": [],
                "text": "SDM"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108246"
                        ],
                        "name": "D. Ruppert",
                        "slug": "D.-Ruppert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ruppert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruppert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "descriptions of clustering techniques can be found in relevant literature, e.g. [ 4 ]. Except for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118901444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5176a2f31dace77db9135dde7020d2c37f78cca0",
            "isKey": false,
            "numCitedBy": 11808,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In the words of the authors, the goal of this book was to \u201cbring together many of the important new ideas in learning, and explain them in a statistical framework.\u201d The authors have been quite successful in achieving this objective, and their work is a welcome addition to the statistics and learning literatures. Statistics has always been interdisciplinary, borrowing ideas from diverse \u008e elds and repaying the debt with contributions, both theoretical and practical, to the other intellectual disciplines. For statistical learning, this cross-fertilization is especially noticeable. This book is a valuable resource, both for the statistician needing an introduction to machine learning and related \u008e elds and for the computer scientist wishing to learn more about statistics. Statisticians will especially appreciate that it is written in their own language. The level of the book is roughly that of a second-year doctoral student in statistics, and it will be useful as a textbook for such students. In a stimulating article, Breiman (2001) argued that statistics has been focused too much on a \u201cdata modeling culture,\u201d where the model is paramount. Breiman argued instead for an \u201calgorithmic modeling culture,\u201d with emphasis on black-box types of prediction. Breiman\u2019s article is controversial, and in his discussion, Efron objects that \u201cprediction is certainly an interesting subject, but Leo\u2019s paper overstates both its role and our profession\u2019s lack of interest in it.\u201d Although I mostly agree with Efron, I worry that the courses offered by most statistics departments include little, if any, treatment of statistical learning and prediction. (Stanford, where Efron and the authors of this book teach, is an exception.) Graduate students in statistics certainly need to know more than they do now about prediction, machine learning, statistical learning, and data mining (not disjoint subjects). I hope that graduate courses covering the topics of this book will become more common in statistics curricula. Most of the book is focused on supervised learning, where one has inputs and outputs from some system and wishes to predict unknown outputs corresponding to known inputs. The methods discussed for supervised learning include linear and logistic regression; basis expansion, such as splines and wavelets; kernel techniques, such as local regression, local likelihood, and radial basis functions; neural networks; additive models; decision trees based on recursive partitioning, such as CART; and support vector machines. There is a \u008e nal chapter on unsupervised learning, including association rules, cluster analysis, self-organizing maps, principal components and curves, and independent component analysis. Many statisticians will be unfamiliar with at least some of these algorithms. Association rules are popular for mining commercial data in what is called \u201cmarket basket analysis.\u201d The aim is to discover types of products often purchased together. Such knowledge can be used to develop marketing strategies, such as store or catalog layouts. Self-organizing maps (SOMs) involve essentially constrained k-means clustering, where prototypes are mapped to a two-dimensional curved coordinate system. Independent components analysis is similar to principal components analysis and factor analysis, but it uses higher-order moments to achieve independence, not merely zero correlation between components. A strength of the book is the attempt to organize a plethora of methods into a coherent whole. The relationships among the methods are emphasized. I know of no other book that covers so much ground. Of course, with such broad coverage, it is not possible to cover any single topic in great depth, so this book will encourage further reading. Fortunately, each chapter includes bibliographic notes surveying the recent literature. These notes and the extensive references provide a good introduction to the learning literature, including much outside of statistics. The book might be more suitable as a textbook if less material were covered in greater depth; however, such a change would compromise the book\u2019s usefulness as a reference, and so I am happier with the book as it was written."
            },
            "slug": "The-Elements-of-Statistical-Learning:-Data-Mining,-Ruppert",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book is a valuable resource, both for the statistician needing an introduction to machine learning and related \u008e elds and for the computer scientist wishing to learn more about statistics, and statisticians will especially appreciate that it is written in their own language."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Nagy [19] discusses papers published in PAMI on document analysis during the last 20 years."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 620082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce3b569e18670f6c10e61aa9a8bda7c30fd37411",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "slug": "Twenty-Years-of-Document-Image-Analysis-in-PAMI-Nagy",
            "title": {
                "fragments": [],
                "text": "Twenty Years of Document Image Analysis in PAMI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The contributions to document image analysis of 99 papers published in the IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) are clustered, summarized, interpolated, interpreted, and evaluated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979211"
                        ],
                        "name": "Andr\u00e1s Kornai",
                        "slug": "Andr\u00e1s-Kornai",
                        "structuredName": {
                            "firstName": "Andr\u00e1s",
                            "lastName": "Kornai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e1s Kornai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143677016"
                        ],
                        "name": "K. Mohiuddin",
                        "slug": "K.-Mohiuddin",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Mohiuddin",
                            "middleNames": [
                                "Moidin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mohiuddin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40640960"
                        ],
                        "name": "S. Connell",
                        "slug": "S.-Connell",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Connell",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Connell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "Srihari and Kim [31] described an early system for reading unconstrained handwriting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12328136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14c0e359d164bbee9dd2e5f1f5ef3b2a18ba39a7",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The system described in this paper applies Hidden Markov technology both to the task of recognizing the cursive legal amount on personal checks and the isolated (numeric) courtesy amount."
            },
            "slug": "Recognition-of-Cursive-Writing-on-Personal-Checks-Kornai-Mohiuddin",
            "title": {
                "fragments": [],
                "text": "Recognition of Cursive Writing on Personal Checks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The system described in this paper applies Hidden Markov technology both to the task of recognizing the cursive legal amount on personal checks and the isolated (numeric) courtesy amount."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145323121"
                        ],
                        "name": "J. Nelder",
                        "slug": "J.-Nelder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nelder",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nelder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189443"
                        ],
                        "name": "R. Mead",
                        "slug": "R.-Mead",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mead"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "The fitting was performed with the \u201cNelder-Mead\u201d optimization procedure [20], which minimizes the sum of squared differences between the actual vocabulary sizes and the ones 26"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2208295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "017ddb7e815236defd0566bc46f6ed8401cc6ba6",
            "isKey": false,
            "numCitedBy": 25599,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n 41) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point. The simplex adapts itself to the local landscape, and contracts on to the final minimum. The method is shown to be effective and computationally compact. A procedure is given for the estimation of the Hessian matrix in the neighbourhood of the minimum, needed in statistical estimation problems."
            },
            "slug": "A-Simplex-Method-for-Function-Minimization-Nelder-Mead",
            "title": {
                "fragments": [],
                "text": "A Simplex Method for Function Minimization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A method is described for the minimization of a function of n variables, which depends on the comparison of function values at the (n 41) vertices of a general simplex, followed by the replacement of the vertex with the highest value by another point."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104832"
                        ],
                        "name": "H. Heaps",
                        "slug": "H.-Heaps",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Heaps",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Heaps"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "Early work in information retrieval by Heaps [5] provides an empirical estimate for the vocabulary size of a collection from the size of the collection in words."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 185
                            }
                        ],
                        "text": "The fitting was performed with the \u201cNelder-Mead\u201d optimization procedure [20], which minimizes the sum of squared differences between the actual vocabulary sizes and the ones\npredicted by Heaps\u2019 law."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 30
                            }
                        ],
                        "text": "We estimated K and \u03b2 by fitting Heaps\u2019 law to the ground truth transcription of a collection of 100 pages (21324 word images) from George Washington\u2019s letters, which does not include our testing set on which we performed clustering experiments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 34
                            }
                        ],
                        "text": "4\nTable 6 shows the accuracy that Heaps\u2019 law achieves when predicting the vocabulary size of the data set."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 72
                            }
                        ],
                        "text": "The rule, which is known to be quite effective [1], has become known as Heaps\u2019 law."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 57
                            }
                        ],
                        "text": "First, the desired number of clusters is estimated using Heaps\u2019 law."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 62
                            }
                        ],
                        "text": "For each n, we determined the vocabulary size and then fitted Heaps\u2019 law to the resulting curve."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Heaps\u2019 law, an empirical rule, provides the tool for the estimation, which is discussed in the following section."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60505294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb2815dc569c48139f3c6659582ed7a6e791bdb4",
            "isKey": true,
            "numCitedBy": 617,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-retrieval,-computational-and-aspects-Heaps",
            "title": {
                "fragments": [],
                "text": "Information retrieval, computational and theoretical aspects"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "The obtained mean average precision scores for experiments A and B had to be corrected, because of an evaluation problem in [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "SLH[7]: Scott and Longuet-Higgins algorithm [30]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "DTW is compared with a number of other techniques including XOR, affine-corrected Euclidean Distance Matching, shape context [2], intensity correlation using sum-of-squared differences, an affine matching point matching algorithm due to Scott and Longuet-Higgins [30] and a point correlation voting algorithm [27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "XOR[7]: The images are aligned to compensate for shear and scale changes, binarized\nand then a difference image is computed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "The other algorithms (including our implementation of SLH) all use the actual images (rather than the 1D profiles used by DTW) and hence are much slower."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SSD[7]: This approach translates the query and candidate images relative to one\nanother to find the minimum cost based on the sum of squared differences of the pixel intensities."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "In the XOR image, difference pixels in larger\nregions are weighted more heavily, because they are likely to result from structural differences between the template and the candidate image, not from noise."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "While the quality of the segmentation algorithm has been improved in the meantime, we used the same segmentation results as in [7], for comparability."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "SSD[7]: This approach translates the query and candidate images relative to one another to find the minimum cost based on the sum of squared differences of the pixel intensities."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "Four experiments were conducted (A and C were initially proposed in [7]): Experiment A: 15 images from test set 1 were selected as queries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "The matching cost is the cumulative weight of the difference pixels in the XOR image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "XOR[7]: The images are aligned to compensate for shear and scale changes, binarized and then a difference image is computed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Indexing george washington\u2019s handwritten manuscripts"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. rep., Center for Intelligent Information Retrieval, Univ. of Massachusetts Amherst,"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2886380"
                        ],
                        "name": "S. Sturrock",
                        "slug": "S.-Sturrock",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Sturrock",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sturrock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "For a more detailed discussion of continuity constraints and alternatives to the one used in this work, we refer the reader to [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 86397843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abcab02ebe45bdfc4b8e5e272ebb3f7471a2cdec",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Time-Warps,-String-Edits,-and-Macromolecules-\u2013-The-Sturrock",
            "title": {
                "fragments": [],
                "text": "Time Warps, String Edits, and Macromolecules \u2013 The Theory and Practice of Sequence Comparison . David Sankoff and Joseph Kruskal. ISBN 1-57586-217-4. Price \u00a313.95 (US$22\u00b795)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 78
                            }
                        ],
                        "text": "[15], and a number of different word matching algorithms were investigated in [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 136
                            }
                        ],
                        "text": "The image matching problem is difficult and has prompted a number of publications that propose algorithms and features for the approach [14, 13, 24, 26, 25, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61972416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32165a58b9addbb3dd427589bbaae129fcd4874b",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Word-spotting:-indexing-handwritten-manuscripts-Manmatha-Croft",
            "title": {
                "fragments": [],
                "text": "Word spotting: indexing handwritten manuscripts"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4632093"
                        ],
                        "name": "G. Zipf",
                        "slug": "G.-Zipf",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Zipf",
                            "middleNames": [
                                "Kingsley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zipf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141120597,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "2bcf3e6c2b45c052a0bd0183cc29c03acc4b49ac",
            "isKey": false,
            "numCitedBy": 7038,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Human-behavior-and-the-principle-of-least-effort-Zipf",
            "title": {
                "fragments": [],
                "text": "Human behavior and the principle of least effort"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "Our implementation of DTW uses the Sakoe-Chiba band [28] (see Figure 7(b); the warping path must lie in the shaded region), but the Itakura parallelogram [6] is also a popular choice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic programming optimization for spoken word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Acoustics, Speech and Signal Processing"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "SLH[7]: Scott and Longuet-Higgins algorithm [30]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 235
                            }
                        ],
                        "text": "81% Table 3: Mean average precision scores on all data sets (results for test set A and B have been corrected, XOR: matching using difference images, SSD: sum of squared differences technique, SLH: technique by Scott & Longuet-Higgins [30], SC: shape context matching [2], EDM: euclidean distance mapping, CORR: corner-point correlation, DTW: dynamic time warping matching)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 263
                            }
                        ],
                        "text": "DTW is compared with a number of other techniques including XOR, affine-corrected Euclidean Distance Matching, shape context [2], intensity correlation using sum-of-squared differences, an affine matching point matching algorithm due to Scott and Longuet-Higgins [30] and a point correlation voting algorithm [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for associating the features of two patterns"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the Royal Society of London"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Srihari and Kim [31] described an early system for reading unconstrained handwriting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Penman: A system for reading unconstrained handwritten page images. In Symposium on document image understanding technology (SDIUT"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Srihari and Kim [31] described an early system for reading unconstrained handwriting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Penman : A system for reading unconstrained handwritten page images"
            },
            "venue": {
                "fragments": [],
                "text": "Symposium on document image understanding technology ( SDIUT"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "Table 1 contains pseudo-code of the DTW algorithm (adapted from [34]) using the local continuity constraint from Figure 7(a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatische Erkennung von handgeschriebenen Worten mithilfe des Level-building Algorithmus"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The rule,whichisknowntobequiteeffective[ 1 ],hasbecome knownasHeaps\u2019law.Itpredictsthatthevocabularysize of a collection of n words can be estimated to be"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modern Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 28,
            "methodology": 12,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Word-spotting-for-historical-documents-Rath-Manmatha/2032ca157296c50db62fafb90ba970b77262ed17?sort=total-citations"
}