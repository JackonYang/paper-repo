{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403895663"
                        ],
                        "name": "S. Souafi-Bensafi",
                        "slug": "S.-Souafi-Bensafi",
                        "structuredName": {
                            "firstName": "Souad",
                            "lastName": "Souafi-Bensafi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Souafi-Bensafi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747913"
                        ],
                        "name": "M. Parizeau",
                        "slug": "M.-Parizeau",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Parizeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Parizeau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7107611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2af5cac4def83146f220db0cb3b49648a0225450",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses logical labeling in documents, which is one basic step in logical structure recognition. Logical labels have to be attributed to text blocks composing the layout structure. Our study is based on physical characteristics having a visual aspect: typographic, geometric and/or topologic attributes. Our objective is to map a low level logical structure, which consists of a set of logical labels, on the extracted layout structure components. We have to build a model that allows this mapping. However, the documents we consider have various layout and logical structures, thus, we chose to perform this task by supervised learning on the basis of a set of training documents. This allows us to define a generic method to solve this problem, without imposing any constraint on document structure. We propose a probabilistic model represented by a Bayesian Network (BN), which is a graphical model used in our problem as a classifier. A prototype has been implemented, and applied to tables of contents in periodicals."
            },
            "slug": "Logical-labeling-using-Bayesian-networks-Souafi-Bensafi-Parizeau",
            "title": {
                "fragments": [],
                "text": "Logical labeling using Bayesian networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The objective is to map a low level logical structure, which consists of a set of logical labels, on the extracted layout structure components, and proposes a probabilistic model represented by a Bayesian Network, which is a graphical model used in the problem as a classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46138594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b39beea0f761152e65fac0e498af387821d887f1",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. We use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2550/spl times/3300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise."
            },
            "slug": "Document-Representation-and-Its-Application-to-Page-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Document Representation and Its Application to Page Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126865"
                        ],
                        "name": "Yasuto Ishitani",
                        "slug": "Yasuto-Ishitani",
                        "structuredName": {
                            "firstName": "Yasuto",
                            "lastName": "Ishitani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasuto Ishitani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We find such approaches with multi-agents systems [13], and interaction systems [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34900183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "647bd217eaca0f4513afd64606bdd9685079c836",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for logical structure analysis of document images is proposed in this paper as the basis for a document reader which can extract logical information from various printed documents. The proposed system consists of five basic modules: typography analysis, object recognition, object segmentation, object grouping and object modification. Emergent computation, which is a key concept of artificial life, is adopted for the cooperative interaction among the modules in the system in order to achieve an effective and flexible behavior of the whole system. It has two principal advantages over other methods: adaptive system configuration for various and complex logical structures, and robust document analysis that is tolerant of erroneous feature detection."
            },
            "slug": "Logical-structure-analysis-of-document-images-based-Ishitani",
            "title": {
                "fragments": [],
                "text": "Logical structure analysis of document images based on emergent computation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A new method for logical structure analysis of document images is proposed in this paper as the basis for a document reader which can extract logical information from various printed documents."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Introduced by Rosenfeld, Hummel et Zucker [ 161 then used in pattern recognition and image segmentation in [ 17 ], probabilistic relaxation is a general approach to classify objects on the basis of certain properties and to iteratively adjust classification by using compatibilities with other objects found in the neighborhood."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37145569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66abe203288f31c06282ce1c3cf69fca3b592663",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes the processing of magazine or newspaper images which need to be segmented in gray level. The first part proposes an original method to extract the physical layout of gray-level documents. The second part of the paper describes a rough logical structure by analyzing the typography, aiming to extract relevant information about the logical layout by combining information about colors, typography, and the physical structural layout for use by an automatic document indexation system. Character prototypes were automatically extracted by grouping characters which have the same binary patterns. We suggest using this character-grouping method to extract typographical information and recognize different font styles and sizes used in the document."
            },
            "slug": "Document-analysis-in-gray-level-and-typography-Lebourgeois-Emptoz",
            "title": {
                "fragments": [],
                "text": "Document analysis in gray level and typography extraction using character pattern redundancies"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An original method to extract the physical layout of gray-level documents by analyzing the typography by combining information about colors, typography, and the physical structural layout for use by an automatic document indexation system is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11498408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b76bbddf92d247705c839436b5836081ab0add8a",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "The economic feasibility of maintaining large data bases of document images has created a tremendous demand for robust ways to access and manipulate the information these images contain. In an attempt to move toward a paperless office, large quantities of printed documents are often scanned and archived as images, without adequate index information. One way to provide traditional data-base indexing and retrieval capabilities is to fully convert the document to an electronic representation which can be indexed automatically. Unfortunately, there are many factors which prohibit complete conversion including high cost, low document quality, and the fact that many nontext components cannot be adequately represented in a converted form. In such cases, it can be advantageous to maintain a copy of and use the document in image form. In this paper, we provide a survey of methods developed by researchers to access and manipulate document images without the need for complete and accurate conversion. We briefly discuss traditional text indexing techniques on imperfect data and the retrieval of partially converted documents. This is followed by a more comprehensive review of techniques for the direct characterization, manipulation, and retrieval, of images of documents containing text, graphics, and scene images."
            },
            "slug": "The-Indexing-and-Retrieval-of-Document-Images:-A-Doermann",
            "title": {
                "fragments": [],
                "text": "The Indexing and Retrieval of Document Images: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A survey of methods developed by researchers to access and manipulate document images without the need for complete and accurate conversion is provided."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107969145"
                        ],
                        "name": "X. Huang",
                        "slug": "X.-Huang",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6948518,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "df578f35419f0b7766ae6bd70ed9726a92d75e32",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Document knowledge plays a very important role in many document image understanding methods. In these methods, the document knowledge is utilized to classify/extract individual item data interpretatively from paper-based sheets as a kind of document model: these days, this knowledge is specified into the document image understanding system in advance. In this paper, we propose an experimental method to acquire the layout knowledge automatically from sample document images. In particular, we focus on the acquisition of the layout of business cards. Our idea is to generate the layout knowledge of business cards from a predefined logical structure, which is used as a kind of meta-knowledge to interpretatively generate the layout knowledge of given business cards."
            },
            "slug": "Automatic-acquisition-of-layout-knowledge-for-cards-Watanabe-Huang",
            "title": {
                "fragments": [],
                "text": "Automatic acquisition of layout knowledge for understanding business cards"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The idea is to generate the layout knowledge of business cards from a predefined logical structure, which is used as a kind of meta-knowledge to interpretatively generate the layouts knowledge of given business cards."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Approaches based on syntactical inferences, graphs and hierarchical trees transformation are commonly used for documents having little structure variability like bibliographical catalogues or scientific papers [10-12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16107554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "717a4ae91ad20667f7ac03ce5538eff36313c299",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for extracting alternating horizontal and vertical projection profiles are from nested sub-blocks of scanned page images of technical documents is discussed. The thresholded profile strings are parsed using the compiler utilities Lex and Yacc. The significant document components are demarcated and identified by the recursive application of block grammars. Backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs. Results of the segmentation and labeling process are stored in a labeled x-y tree. It is shown that families of technical documents that share the same layout conventions can be readily analyzed. Results from experiments in which more than 20 types of document entities were identified in sample pages from two journals are presented. >"
            },
            "slug": "Syntactic-Segmentation-and-Labeling-of-Digitized-Krishnamoorthy-Nagy",
            "title": {
                "fragments": [],
                "text": "Syntactic Segmentation and Labeling of Digitized Pages from Technical Journals"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that families of technical documents that share the same layout conventions can be readily analyzed and backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13615381,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d91e0d202fa23b7a2e81c5b3b04eb4cc5327b0f9",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs. The physical reader of the paper document is the scanner just like the physical reader of the floppy is the floppy drive and the physical reader of the tape cartridge is the tape cartridge drive, and the physical reader of the CDROM is the CDROM drive. In the survey presented, we restrict ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences. Understanding such documents involves estimating the rotation skew of each document page, determining the geometric page layout, labeling blocks as text or non-text, determining the read order for text blocks, recognizing the text of text blocks through an OCR system, determining the logical page layout, and formatting the data and information of the document in a suitable way for use by a word processing system or by an information retrieval system.<<ETX>>"
            },
            "slug": "Document-image-understanding:-geometric-and-logical-Haralick",
            "title": {
                "fragments": [],
                "text": "Document image understanding: geometric and logical layout"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Document image understanding encompasses the technology required to make paper documents equivalent to other computer exchange media like floppies, tapes, and CDROMs and restricts ourselves to documents such as business letters, forms, and scientific and technical articles such as those found in archival journals and technical conferences."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20661771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ceaabecf9e51ea41133eee63abea62f5e469200",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image analysis is the automatic computer interpretation of images of printed and handwritten documents, including text, drawings, maps, music scores, etc. Research in this field supports a rapidly growing international industry. This is the first book to offer a broad selection of state-of-the-art research papers, including authoritative critical surveys of the literature, and parallel studies of the architectureof complete high-performance printed-document reading systems. A unique feature is the extended section on music notation, an ideal vehicle for international sharing of basic research. Also, the collection includes important new work on line drawings, handwriting, character and symbol recognition, and basic methodological issues. The IAPR 1990 Workshop on Syntactic and Structural Pattern Recognition is summarized,including the reports of its expert working groups, whose debates provide a fascinating perspective on the field. The book is an excellent text for a first-year graduate seminar in document image analysis,and is likely to remain a standard reference in the field for years."
            },
            "slug": "Structured-Document-Image-Analysis-Baird-Bunke",
            "title": {
                "fragments": [],
                "text": "Structured Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This is the first book to offer a broad selection of state-of-the-art research papers, including authoritative critical surveys of the literature, and parallel studies of the architecture of complete high-performance printed-document reading systems."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46756347"
                        ],
                        "name": "Chiu L. Yu",
                        "slug": "Chiu-L.-Yu",
                        "structuredName": {
                            "firstName": "Chiu",
                            "lastName": "Yu",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chiu L. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39702442"
                        ],
                        "name": "Y. Tang",
                        "slug": "Y.-Tang",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Tang",
                            "middleNames": [
                                "Yan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45008358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43dff8099c6cd19dbb78cd2e93a16203341aedf0",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An intelligent document processing system which can process unconstrained format-free documents is presented. A new document format definition language called Document Architecture Language (DAL) which can handle both rectangular and irregular blocks is presented. Combined with pattern recognition techniques, DAL can be widely used in document analysis and understanding with very wide scopes including general newspaper articles, editorials, financial forms, advertisements, front page of magazine, etc. Bank cheques are employed as an example.<<ETX>>"
            },
            "slug": "Document-architecture-language-(DAL)-approach-to-Yu-Tang",
            "title": {
                "fragments": [],
                "text": "Document architecture language (DAL) approach to document processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "A new document format definition language called Document Architecture Language (DAL) which can handle both rectangular and irregular blocks is presented and can be widely used in document analysis and understanding with very wide scopes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128453"
                        ],
                        "name": "A. Bela\u00efd",
                        "slug": "A.-Bela\u00efd",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Bela\u00efd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bela\u00efd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3297415"
                        ],
                        "name": "Y. Chenevoy",
                        "slug": "Y.-Chenevoy",
                        "structuredName": {
                            "firstName": "Yannick",
                            "lastName": "Chenevoy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chenevoy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14755098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b367b6458fd20dd0bfe01f8c45dc4f6136e730ff",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a constraint propagation method for logical structure extraction of Library references without the use of ocr. The accent is put on the search of anchor points from visual indices extraction. A mixed strategy is performed. For each anchor points. the system proposes in a bottom-up manner the most probable model hypothesis and tries to verify in a top-down manner its left and right contexts."
            },
            "slug": "Constraint-Propagation-vs.-Syntactical-Analysis-for-Bela\u00efd-Chenevoy",
            "title": {
                "fragments": [],
                "text": "Constraint Propagation vs. Syntactical Analysis for the Logical Structure Recognition of Library References"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A constraint propagation method for logical structure extraction of Library references without the use of ocr, which proposes in a bottom-up manner the most probable model hypothesis and tries to verify in a top-down manner its left and right contexts."
            },
            "venue": {
                "fragments": [],
                "text": "BSDIA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333419"
                        ],
                        "name": "G. Kopec",
                        "slug": "G.-Kopec",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kopec",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kopec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720816"
                        ],
                        "name": "P. Chou",
                        "slug": "P.-Chou",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Chou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17899690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944db1fc7f65d13a77cf9c70679ee2ff4ef5fba8",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a communication theory approach to document image reconstruction, patterned after the use of hidden Markov models in speech recognition. A document recognition problem is viewed as consisting of three elements-an image generator, a noisy channel, and an image decoder. A document image generator is a Markov source which combines a message source with an imager. The message source produces a string of symbols which contains the information to be transmitted. The imager is modeled as a finite-state transducer, which converts the message into an ideal bitmap. The channel transforms the ideal image into a noisy observed image. The decoder estimates the message from the observed image by finding the a posteriori most probable path through the combined source and channel models using a Viterbi-like algorithm. Application of the proposed method to decoding telephone yellow pages is described.<<ETX>>"
            },
            "slug": "Document-image-decoding-using-Markov-source-models-Kopec-Chou",
            "title": {
                "fragments": [],
                "text": "Document Image Decoding Using Markov Source Models"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A communication theory approach to document image reconstruction, patterned after the use of hidden Markov models in speech recognition, is described, and application of the proposed method to decoding telephone yellow pages is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30489560"
                        ],
                        "name": "R. Hummel",
                        "slug": "R.-Hummel",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Hummel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hummel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698824"
                        ],
                        "name": "S. Zucker",
                        "slug": "S.-Zucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Zucker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18603445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5df9cdc54c8085781c4199a95576a14cb7198b9d",
            "isKey": false,
            "numCitedBy": 1518,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of objects in a scene whose identifications are ambiguous, it is often possible to use relationships among the objects to reduce or eliminate the ambiguity. A striking example of this approach was given by Waltz [13]. This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of (object, identification) data. Several different models of the process are developed, convergence properties of these models are established, and simple examples are given."
            },
            "slug": "Scene-Labeling-by-Relaxation-Operations-Rosenfeld-Hummel",
            "title": {
                "fragments": [],
                "text": "Scene Labeling by Relaxation Operations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of object, identification data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3166512"
                        ],
                        "name": "Fr\u00e9d\u00e9ric Bapst",
                        "slug": "Fr\u00e9d\u00e9ric-Bapst",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Bapst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fr\u00e9d\u00e9ric Bapst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497000"
                        ],
                        "name": "R. Brugger",
                        "slug": "R.-Brugger",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Brugger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brugger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163684"
                        ],
                        "name": "Abdel Wahab Zramdini",
                        "slug": "Abdel-Wahab-Zramdini",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Zramdini",
                            "middleNames": [
                                "Wahab"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel Wahab Zramdini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14619808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92cdf0e8efab0328c60eb78e05d74702459af2e4",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of a new project around structured document recognition, we address the problem of designing a software architecture which is able to integrate all the necessary, but heterogeneous know-how. Starting from the new needs brought by the CIDRE project, we propose a concrete framework built upon existing software pieces, and following the multi-agent paradigm. DAFS serves as the main document management package. The computational engine is written on a distributed and multi-threaded platform, and an original coupling with the GUI is presented. To demonstrate the validity of the approach, a prototype that interactively recognizes the entire physical structure has been developed."
            },
            "slug": "Integrated-Multi-Agent-Architecture-for-Assisted-Bapst-Brugger",
            "title": {
                "fragments": [],
                "text": "Integrated Multi-Agent Architecture for Assisted Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a concrete framework built upon existing software pieces, and following the multi-agent paradigm, which serves as the main document management package and a prototype that interactively recognizes the entire physical structure has been developed."
            },
            "venue": {
                "fragments": [],
                "text": "DAS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703247"
                        ],
                        "name": "A. Kak",
                        "slug": "A.-Kak",
                        "structuredName": {
                            "firstName": "Avinash",
                            "lastName": "Kak",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kak"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Introduced by Rosenfeld, Hummel et Zucker [16] then used in pattern recognition and image segmentation in [17], probabilistic relaxation is a general approach to classify objects on the basis of certain properties and to iteratively adjust classification by using compatibilities with other objects found in the neighborhood."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60845912,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "e10f473947a7afd55aa2ff13cf031e0f8a1accdd",
            "isKey": false,
            "numCitedBy": 3600,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Digital-Picture-Processing-Rosenfeld-Kak",
            "title": {
                "fragments": [],
                "text": "Digital Picture Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119309580"
                        ],
                        "name": "Y. Tang",
                        "slug": "Y.-Tang",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Tang",
                            "middleNames": [
                                "Yan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34129860"
                        ],
                        "name": "C. D. Yan",
                        "slug": "C.-D.-Yan",
                        "structuredName": {
                            "firstName": "Chang",
                            "lastName": "Yan",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145541445"
                        ],
                        "name": "M. Cheriet",
                        "slug": "M.-Cheriet",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Cheriet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cheriet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59873975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db902be1369ffe4c2a84422a6a49bbfb25daa818",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-Analysis-and-Understanding-of-Documents-Tang-Yan",
            "title": {
                "fragments": [],
                "text": "Automatic Analysis and Understanding of Documents"
            },
            "venue": {
                "fragments": [],
                "text": "Handbook of Pattern Recognition and Computer Vision"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Chenevoy, Constraints Propagation vs Syntactical Analysis for the logical structure Recognition of library References, Lecture notes in computer science"
            },
            "venue": {
                "fragments": [],
                "text": "BSDIA"
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Document-understanding-using-probabilistic-on-of-of-Lebourgeois-Emptoz/903ccab9fb896466bd36d170b870ace511a5cd80?sort=total-citations"
}