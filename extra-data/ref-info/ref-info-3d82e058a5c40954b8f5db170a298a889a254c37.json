{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62637304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72820bb2e725b73af7e2cd848ef0b103d15cdc39",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition must contend with the statistical and sequential nature of the human speech production system. Hidden Markov Models (HMM) provide a powerful method to cope with both of these, and their use made a breakthrough in speech recognition. However, the a priori choice of a model topology and weak discriminative power limit HMM capabilities. Recently, connectionist models have been recognized as an alternative tool. Their main useful properties lie in their discriminative power while capturing input-output relations. They have also proved useful in dealing with statistical data. However, the sequential aspect remains difficult to handle in connectionist models. The statistical use of a particular classic form of a connectionist system, the Multilayer Perceptron (MLP), is described in the context of the recognition of continuous speech. Relations with Hidden Markov Models are explained and preliminary results are reported."
            },
            "slug": "Statistical-Inference-in-Multilayer-Perceptrons-and-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Statistical Inference in Multilayer Perceptrons and Hidden Markov Models with Applications in Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The statistical use of a particular classic form of a connectionist system, the Multilayer Perceptron (MLP), is described in the context of the recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": "NATO Neurocomputing"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17831368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5001470e8808afe9887afbe48e2eaaf1a0395d10",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We are developing a phoneme based, speaker-dependent continuous speech recognition system embedding a Multilayer Perceptron (MLP) (i.e., a feedforward Artificial Neural Network), into a Hidden Markov Model (HMM) approach. In [Bourlard & Wellekens], it was shown that MLPs were approximating Maximum a Posteriori (MAP) probabilities and could thus be embedded as an emission probability estimator in HMMs. By using contextual information from a sliding window on the input frames, we have been able to improve frame or phoneme classification performance over the corresponding performance for Simple Maximum Likelihood (ML) or even MAP probabilities that are estimated without the benefit of context. However, recognition of words in continuous speech was not so simply improved by the use of an MLP, and several modifications of the original scheme were necessary for getting acceptable performance. It is shown here that word recognition performance for a simple discrete density HMM system appears to be somewhat better when MLP methods are used to estimate the emission probabilities."
            },
            "slug": "A-Continuous-Speech-Recognition-System-Embedding-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "A Continuous Speech Recognition System Embedding MLP into HMM"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown here that word recognition performance for a simple discrete density HMM system appears to be somewhat better when MLP methods are used to estimate the emission probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14700006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee50abb5aff3e5c43a38f24396b9552d593a9ae0",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The statistical use of a particular classic form of a connectionist system, the multilayer perceptron (MLP), is described in the context of the recognition of continuous speech. A discriminant hidden Markov model (HMM) is defined, and it is shown how a particular MLP with contextual and extra feedback input units can be considered as a general form of such a Markov model. A link between these discriminant HMMs, trained along the Viterbi algorithm, and any other approach based on least mean square minimization of an error function (LMSE) is established. It is shown theoretically and experimentally that the outputs of the MLP (when trained along the LMSE or the entropy criterion) approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities. Results of a series of speech recognition experiments are reported. The possibility of embedding MLP into HMM is described. Relations with other recurrent networks are also explained. >"
            },
            "slug": "Links-Between-Markov-Models-and-Multilayer-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Links Between Markov Models and Multilayer Perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown theoretically and experimentally that the outputs of the MLP approximate the probability distribution over output classes conditioned on the input, i.e. the maximum a posteriori probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721513"
                        ],
                        "name": "B. Lowerre",
                        "slug": "B.-Lowerre",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lowerre",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lowerre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61409851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdb3f20fe41bb95f6bc9d162e827de8db3f952d7",
            "isKey": false,
            "numCitedBy": 480,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The Harpy connected speech recognition system is the result of an attempt to understand the relative importance of various design choices of two earlier speech recognition systems developed at Carnegie-Mellon University: The Hearsay-1 system and the Dragon system. Knowledge is represented in the Hearsay- 1 system as procedures and in the Dragon system as a Markov network with a- priori transition probabilities between states. Systematic performance analysis of various design choices of these two systems resulted in the HARPY system, in which knowledge is represented as a finite state transition network but without the a-priori transition probabilities. Harpy searches only a few 'best' syntactic (and acoustic) paths in parallel to determine the optimal path, and uses segmentation to effectively reduce the utterance length, thereby reducing the number of state probability updates that must be done. Several new heuristics have been added to the HARPY system to improve its performance and speed: detection of common sub-nets and collapsing them to reduce overall network size and complexity, eliminating the need for doing an acoustic match for all phonemic types at every time sample, and semi-automatic techniques for learning the lexical representations (that are needed for a steady-state system of this type) and the phonemic templates from training data, thus automatically accounting for the commonly occurring intra-word coarticulation and juncture phenomena. Inter-word phenomena are handled by the use of juncture rules which are applied at network generation time, thereby eliminating the need for repetitive and time consuming application of phonological rules during the recognition phase."
            },
            "slug": "The-HARPY-speech-recognition-system-Lowerre",
            "title": {
                "fragments": [],
                "text": "The HARPY speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The HARPY system is the result of an attempt to understand the relative importance of various design choices of two earlier speech recognition systems developed at Carnegie-Mellon University, in which knowledge is represented as a finite state transition network but without the a-priori transition probabilities."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 859773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d96910d3ac99d939563b484d6180efbcbb5b4a0",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors have previously demonstrated that feedforward networks can be used to estimate local output probabilities in hidden Markov model (HMM) speech recognition systems (Renals et al., 1991). These connectionist techniques are integrated into the DECIPHER system, with experiments being performed using the speaker-independent DARPA RM database. The results indicate that: connectionist probability estimation can improve performance of a context-independent maximum-likelihood-trained HMM system; performance of the connectionist system is close to what can be achieved using (context-dependent) HMM systems of much higher complexity; and mixing connectionist and maximum-likelihood estimates can improve the performance of the state-of-the-art context-independent HMM system.<<ETX>>"
            },
            "slug": "Connectionist-probability-estimation-in-the-speech-Renals-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist probability estimation in the DECIPHER speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Results indicate that connectionist probability estimation can improve performance of a context-independent maximum-likelihood-trained HMM system; performance of the connectionist system is close to what can be achieved using (context-dependent) HMM systems of much higher complexity."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242830"
                        ],
                        "name": "Victor Abrash",
                        "slug": "Victor-Abrash",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Abrash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Abrash"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5049191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4d53c75cabc89ad9f3926976430cdffb213ad16",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "n M In this paper we present a hybrid multilayer perceptron (MLP)/hidde arkov model (HMM) speaker-independent continuous-speech recogni-b tion system, in which the advantages of both approaches are combined y using MLPs to estimate the state-dependent observation probabilities p of an HMM. New MLP architectures and training procedures are resented which allow the modeling of multiple distributions for phonetic a p classes and context-dependent phonetic classes. Comparisons with ure HMM system illustrate advantages of the hybrid approach both in terms of recognition accuracy and number of parameters required."
            },
            "slug": "Hybrid-neural-network/hidden-Markov-model-Cohen-Franco",
            "title": {
                "fragments": [],
                "text": "Hybrid neural network/hidden Markov model continuous-speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A hybrid multilayer perceptron (MLP)/hidde arkov model (HMM) speaker-independent continuous-speech recogni-b tion system, in which the advantages of both approaches are combined using MLPs to estimate the state-dependent observation probabilities of an HMM."
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2786,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39206632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1528918ae0c9f70ba6da030cb8dbc72f71bc198b",
            "isKey": false,
            "numCitedBy": 427,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of current speech recognition systems is far below that of humans. Neural nets offer the potential of providing massive parallelism, adaptation, and new algorithmic approaches to problems in speech recognition. Initial studies have demonstrated that multilayer networks with time delays can provide excellent discrimination between small sets of pre-segmented difficult-to-discriminate words, consonants, and vowels. Performance for these small vocabularies has often exceeded that of more conventional approaches. Physiological front ends have provided improved recognition accuracy in noise and a cochlea filter-bank that could be used in these front ends has been implemented using micro-power analog VLSI techniques. Techniques have been developed to scale networks up in size to handle larger vocabularies, to reduce training time, and to train nets with recurrent connections. Multilayer perceptron classifiers are being integrated into conventional continuous-speech recognizers. Neural net architectures have been developed to perform the computations required by vector quantizers, static pattern classifiers, and the Viterbi decoding algorithm. Further work is necessary for large-vocabulary continuous-speech problems, to develop training algorithms that progressively build internal word models, and to develop compact VLSI neural net hardware."
            },
            "slug": "Review-of-Neural-Networks-for-Speech-Recognition-Lippmann",
            "title": {
                "fragments": [],
                "text": "Review of Neural Networks for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Further work is necessary for large-vocabulary continuous-speech problems, to develop training algorithms that progressively build internal word models, and to develop compact VLSI neural net hardware."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12251177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "834b3738673dacc767563c2714239852a8a6d4b4",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.<<ETX>>"
            },
            "slug": "Phoneme-recognition:-neural-networks-vs.-hidden-vs.-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A time-delay neural network for phoneme recognition that was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation and does not rely on precise alignment or segmentation of the input."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36927358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "864601066818348e85e2612d866f08a0921bacbb",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis is concerned with two principal issues. Firstly the radial basis functions (RBF) network is introduced and its properties related to other statistical and neural network classifiers. Results from a series of speech recognition experiments, using this network architecture, are reported. These experiments included a continuous speech recognition task with a 571 word lexicon. Secondly, a study of the dynamics of a simple recurrent network model is presented. This study was performed numerically, via a survey of network power spectra and a detailed investigation of the dynamics displayed by a particular network. Word and sentence recognition errors are reported for a continuous speech recognition system using RBF network phoneme modelling with Viterbi smoothing, using either a restricted grammar or no grammar whatsoever. In a cytopathology task domain the best RBF/Viterbi system produced first choice word errors of 6% and sentence errors of 14%, using a grammar of perplexity 6. This compares with word errors of 4% and sentence errors of 8% using the best CSTR hidden Markov model configuration. RBF networks were also used for a static vowel labelling task using hand-segmented vowels excised from continuous speech. Results were not worse than those obtained using statistical classifiers. The second part of this thesis is a computational study of the dynamics of a recurrent neural network model. Two investigations were undertaken. Firstly, a survey of network power spectra was used to map out the temporal activity of this network model (within a four dimensional parameter space) via summary statistics of the network power spectra. Secondly, the dynamics of a particular network were investigated. The dynamics were analysed using bifurcation diagrams, power spectra, the computation of Liapunov exponents and fractal dimensions and the plotting of 2-dimensional attractor projections. Complex dynamical behaviour was observed including Hopf bifurcations, the RuelleTakens-Newhouse route to chaos with mode-locking at rational winding numbers, the period-doubling route to chaos and the presence of multiple coexisting attractors."
            },
            "slug": "Speech-and-neural-network-dynamics-Renals",
            "title": {
                "fragments": [],
                "text": "Speech and neural network dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The radial basis functions (RBF) network is introduced and its properties related to other statistical and neural network classifiers and the dynamics of a recurrent neural network model are investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20678424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c86590e947c28e8791d1e8bab8fc8ab53302341f",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the work described here, the backpropagation neural network learning procedure is applied to the analysis and recognition of speech. This procedure takes a set of input/output pattern pairs and attempts to learn their functional relationship; it develops the necessary representational features during the course of learning. A series of computer simulation studies was carried out to assess the ability of these networks to accurately label sounds, to learn to recognize sounds without labels, and to learn feature representations of continuous speech. These studies demonstrated that the networks can learn to label presegmented test tokens with accuracies of up to 95%. Networks trained on segmented sounds using a strategy that requires no external labels were able to recognize and delineate sounds in continuous speech. These networks developed rich internal representations that included units which corresponded to such traditional distinctions as vowels and consonants, as well as units that were sensitive to novel and nonstandard features. Networks trained on a large corpus of unsegmented, continuous speech without labels also developed interesting feature representations, which may be useful in both segmentation and label learning. The results of these studies, while preliminary, demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "slug": "Learning-the-hidden-structure-of-speech.-Elman-Zipser",
            "title": {
                "fragments": [],
                "text": "Learning the hidden structure of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results of these studies demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144001744"
                        ],
                        "name": "J. Tebelskis",
                        "slug": "J.-Tebelskis",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Tebelskis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tebelskis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459610"
                        ],
                        "name": "B. Petek",
                        "slug": "B.-Petek",
                        "structuredName": {
                            "firstName": "Bojan",
                            "lastName": "Petek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Petek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2034115"
                        ],
                        "name": "O. Schmidbauer",
                        "slug": "O.-Schmidbauer",
                        "structuredName": {
                            "firstName": "Otto",
                            "lastName": "Schmidbauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Schmidbauer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15812234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "447d1b23a8b7efa06cfb262b5eb00f8e759f1aee",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a large vocabulary, continuous speech recognition system based on linked predictive neural networks (LPNNs). The system uses neural networks as predictors of speech frames, yielding distortion measures which can be used by the one-stage DTW algorithm to perform continuous speech recognition. The system currently achieves 95%, 58%, and 39% word accuracy on tasks with perplexity 7, 111, and 402, respectively, outperforming several simple HMMs that have been tested. It was also found that the accuracy and speed of the LPNN can be slightly improved by the judicious use of hidden control inputs. The strengths and weaknesses of the predictive approach are discussed.<<ETX>>"
            },
            "slug": "Continuous-speech-recognition-using-linked-neural-Tebelskis-Waibel",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition using linked predictive neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The authors present a large vocabulary, continuous speech recognition system based on linked predictive neural networks (LPNNs), which achieves 95%, 58%, and 39% word accuracy on tasks with perplexity 7, 111, and 402, respectively, outperforming several simple HMMs that have been tested."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47749181"
                        ],
                        "name": "M. Franzini",
                        "slug": "M.-Franzini",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Franzini",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franzini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110051082"
                        ],
                        "name": "K. Lee",
                        "slug": "K.-Lee",
                        "structuredName": {
                            "firstName": "K.-F.",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12292955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f866ac085771f5676800db2d9b102975b2a1b2d7",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A hybrid method for continuous-speech recognition which combines hidden Markov models (HMMs) and a connectionist technique called connectionist Viterbi training (CVT) is presented. CVT can be run iteratively and can be applied to large-vocabulary recognition tasks. Successful completion of training the connectionist component of the system, despite the large network size and volume of training data, depends largely on several measures taken to reduce learning time. The system is trained and tested on the TI/NBS speaker-independent continuous-digits database. Performance on test data for unknown-length strings is 98.5% word accuracy and 95.0% string accuracy. Several improvements to the current system are expected to increase these accuracies significantly.<<ETX>>"
            },
            "slug": "Connectionist-Viterbi-training:-a-new-hybrid-method-Franzini-Lee",
            "title": {
                "fragments": [],
                "text": "Connectionist Viterbi training: a new hybrid method for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A hybrid method for continuous-speech recognition which combines hidden Markov models (HMMs) and a connectionist technique called connectionist Viterbi training (CVT) is presented and can be run iteratively and applied to large-vocabulary recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861227"
                        ],
                        "name": "K. Iso",
                        "slug": "K.-Iso",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Iso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Iso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110691850"
                        ],
                        "name": "Takao Watanabe",
                        "slug": "Takao-Watanabe",
                        "structuredName": {
                            "firstName": "Takao",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takao Watanabe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57863167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2898aabdf8a0eef517c87bf82fdd113c2b3ebd40",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A speech recognition model called the neural prediction model (NPM) is proposed. The model uses a sequence of multilayer perceptrons (MLPs) as a separate nonlinear predictor for each class. It is designed to represent temporal structures of speech patterns as recognition cues. In particular, temporal correlation in successive feature vectors of a speech pattern is represented in the mappings formed as MLP input-output relations. Temporal distortion of speech is efficiently normalized by a dynamic-programming technique. Recognition and training algorithms are presented based on the combination of dynamic-programming and back-propagation techniques. Evaluation experiments were conducted using ten-digit vocabulary samples uttered by 107 speakers. A 99.8% recognition accuracy was obtained. This suggests that the model is effective for speaker-independent speech recognition.<<ETX>>"
            },
            "slug": "Speaker-independent-word-recognition-using-a-neural-Iso-Watanabe",
            "title": {
                "fragments": [],
                "text": "Speaker-independent word recognition using a neural prediction model"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A speech recognition model called the neural prediction model (NPM) is proposed, which uses a sequence of multilayer perceptrons (MLPs) as a separate nonlinear predictor for each class to represent temporal structures of speech patterns as recognition cues."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47749181"
                        ],
                        "name": "M. Franzini",
                        "slug": "M.-Franzini",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Franzini",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franzini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61727617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24ca5231df7cbd31e11a154c0c63ad48295f0398",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe two systems in which neural network classifiers are merged with dynamic programming (DP) time alignment methods to produce high-performance continuous speech recognizers. One system uses the connectionist Viterbi-training (CVT) procedure, in which a neural network with frame-level outputs is trained using guidance from a time alignment procedure. The other system uses multi-state time-delay neural networks (MS-TDNNs), in which embedded DP time alignment allows network training with only word-level external supervision. The CVT results on the, TI Digits are 99.1% word accuracy and 98.0% string accuracy. The MS-TDNNs are described in detail, with attention focused on their architecture, the training procedure, and results of applying the MS-TDNNs to continuous speaker-dependent alphabet recognition: on two speakers, word accuracy is respectively 97.5% and 89.7%.<<ETX>>"
            },
            "slug": "Integrating-time-alignment-and-neural-networks-for-Haffner-Franzini",
            "title": {
                "fragments": [],
                "text": "Integrating time alignment and neural networks for high performance continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors describe two systems in which neural network classifiers are merged with dynamic programming (DP) time alignment methods to produce high-performance continuous speech recognizers."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714393"
                        ],
                        "name": "R. Mori",
                        "slug": "R.-Mori",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Mori",
                            "middleNames": [
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2376916"
                        ],
                        "name": "G. Flammia",
                        "slug": "G.-Flammia",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Flammia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Flammia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688499"
                        ],
                        "name": "R. Kompe",
                        "slug": "R.-Kompe",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Kompe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kompe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 894840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffbe67c217967b6bfb0a5ecc0dc4cdd5cda65776",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) is proposed. ANNs are suitable for performing phonetic classification, whereas HMMs have been proven successful at modeling the temporal structure of the speech signal. In the approach described, the ANN outputs constitute the sequence of observation vectors for the HMM. An algorithm is proposed for global optimization of all the parameters. Results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported.<<ETX>>"
            },
            "slug": "Global-optimization-of-a-neural-network-hidden-Bengio-Mori",
            "title": {
                "fragments": [],
                "text": "Global optimization of a neural network-hidden Markov model hybrid"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An original method for integrating artificial neural networks (ANN) with hidden Markov models (HMM) with results on speaker-independent recognition experiments using this integrated ANN-HMM system on the TIMIT continuous speech database are reported."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781290"
                        ],
                        "name": "H. Murveit",
                        "slug": "H.-Murveit",
                        "structuredName": {
                            "firstName": "Hy",
                            "lastName": "Murveit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murveit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35577831"
                        ],
                        "name": "J. Bernstein",
                        "slug": "J.-Bernstein",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072624667"
                        ],
                        "name": "G. Baldwin",
                        "slug": "G.-Baldwin",
                        "structuredName": {
                            "firstName": "Gay",
                            "lastName": "Baldwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Baldwin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143888510"
                        ],
                        "name": "D. Bell",
                        "slug": "D.-Bell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bell",
                            "middleNames": [
                                "Elliott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60483016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc93ff65a6b301d9f993b1688912bd2243f61932",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A speaker-independent, continuous-speech, large-vocabulary speech recognition system, DECIPHER, has been developed. It provides state-of-the-art performance on the DARPA standard speaker-independent resource management training and testing materials. The approach is to integrate speech and linguistic knowledge into the HMM (hidden Markov model) framework. Performance improvements arising from detailed phonological modeling and from the incorporation of cross-word coarticulatory constraints are described. It is concluded that speech and linguistic knowledge sources can be used to improve the performance of HMM-based speech recognition systems provided that care is taken to incorporate these knowledge sources appropriately.<<ETX>>"
            },
            "slug": "Linguistic-constraints-in-hidden-Markov-model-based-Weintraub-Murveit",
            "title": {
                "fragments": [],
                "text": "Linguistic constraints in hidden Markov model based speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is concluded that speech and linguistic knowledge sources can be used to improve the performance of HMM-based speech recognition systems provided that care is taken to incorporate these knowledge sources appropriately."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47944231"
                        ],
                        "name": "L. Dodd",
                        "slug": "L.-Dodd",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Dodd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Dodd"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62649110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6c94cc324f585bd6c004f2b99b5589568643e45",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors extend to continuous speech recognition (CSR) the Alphanet approach to integrating backprop networks and HMM (hidden Markov model)-based isolated word recognition. They present the theory of a method for discriminative training of components of a CSR system, using training data in the form of complete sentences. The derivatives of the discriminative score with respect to the parameters are expressed in terms of the posterior probabilities of state occupancies (gammas) under two conditions called 'clamped' and 'free' because they correspond to the two conditions in Boltzmann machine training. The authors compute these clamped and free gammas using the forward-backward algorithm twice, and use the differences to drive the adaptation of a preprocessing data transformation, which can be thought of as replacing the linear transformation which yields MFCCs, or which normalizes a grand covariance matrix.<<ETX>>"
            },
            "slug": "An-Alphanet-approach-to-optimising-input-for-speech-Bridle-Dodd",
            "title": {
                "fragments": [],
                "text": "An Alphanet approach to optimising input transformations for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The authors extend to continuous speech recognition (CSR) the Alphanet approach to integrating backprop networks and HMM (hidden Markov model)-based isolated word recognition and present the theory of a method for discriminative training of components of a CSR system, using training data in the form of complete sentences."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61826819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd0568b4faa03910ae3c07d00c627666f404305d",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A phoneme based, speaker-dependent continuous-speech recognition system embedding a multilayer perceptron (MLP) (i.e. a feedforward artificial neural network) into a hidden Markov model (HMM) approach is described. Contextual information from a sliding window on the input frames is used to improve frame or phoneme classification performance over the corresponding performance for simple maximum-likelihood probabilities, or even maximum a posteriori (MAP) probabilities which are estimated without the benefit of context. Performance for a simple discrete density HMM system appears to be somewhat better when MLP methods are used to estimate the probabilities.<<ETX>>"
            },
            "slug": "Continuous-speech-recognition-using-multilayer-with-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition using multilayer perceptrons with hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A phoneme based, speaker-dependent continuous-speech recognition system embedding a multilayer perceptron (MLP) into a hidden Markov model (HMM) approach is described, which appears to be somewhat better when MLP methods are used to estimate the probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128671"
                        ],
                        "name": "K. Hassanein",
                        "slug": "K.-Hassanein",
                        "structuredName": {
                            "firstName": "Khaled",
                            "lastName": "Hassanein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hassanein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144029931"
                        ],
                        "name": "M. Elmasry",
                        "slug": "M.-Elmasry",
                        "structuredName": {
                            "firstName": "Mohamed",
                            "lastName": "Elmasry",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Elmasry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16432123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7da859c7309775535ecba0d4a31c9ad72578d484",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A speech recognizer is developed using a layered neural network to implement speech-frame prediction and using a Markov chain to modulate the network's weight parameters. The authors postulate that speech recognition accuracy is closely linked to the capability of the predictive model in representing long-term temporal correlations in data. Analytical expressions are obtained for the correlation functions for various types of predictive models (linear, nonlinear, and jointly linear and nonlinear) in order to determine the faithfulness of the models to the actual speech data. The analytical results, computer simulations, and speech recognition experiments suggest that when nonlinear and linear prediction are jointly performed within the same layer of the neural network, the model is better able to capture long-term data correlations and consequently improve speech recognition performance.<<ETX>>"
            },
            "slug": "Neural-network-architecture-for-linear-and-hidden-Deng-Hassanein",
            "title": {
                "fragments": [],
                "text": "Neural-network architecture for linear and nonlinear predictive hidden Markov models: application to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The analytical results, computer simulations, and speech recognition experiments suggest that when nonlinear and linear prediction are jointly performed within the same layer of the neural network, the model is better able to capture long-term data correlations and consequently improve speech recognition performance."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing Proceedings of the 1991 IEEE Workshop"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144711425"
                        ],
                        "name": "T. Robinson",
                        "slug": "T.-Robinson",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Robinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1998157"
                        ],
                        "name": "F. Fallside",
                        "slug": "F.-Fallside",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Fallside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fallside"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61818881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "758eae04fc9f4331b0ceab797387c8fc9f00db58",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-recurrent-error-propagation-network-speech-system-Robinson-Fallside",
            "title": {
                "fragments": [],
                "text": "A recurrent error propagation network speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748407"
                        ],
                        "name": "J. Bellegarda",
                        "slug": "J.-Bellegarda",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Bellegarda",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bellegarda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713978"
                        ],
                        "name": "D. Nahamoo",
                        "slug": "D.-Nahamoo",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nahamoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nahamoo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6331060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44ee2287d2cd08986d33dcbc766faa7a91dc0c70",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The acoustic-modeling problem in automatic speech recognition is examined with the goal of unifying discrete and continuous parameter approaches. To model a sequence of information-bearing acoustic feature vectors which has been extracted from the speech waveform via some appropriate front-end signal processing, a speech recognizer basically faces two alternatives: (1) assign a multivariate probability distribution directly to the stream of vectors, or (2) use a time-synchronous labeling acoustic processor to perform vector quantization on this stream, and assign a multinomial probability distribution to the output of the vector quantizer. With a few exceptions, these two methods have traditionally been given separate treatment. A class of very general hidden Markov models which can accommodate feature vector sequences lying either in a discrete or in a continuous space is considered; the new class allows one to represent the prototypes in an assumption-limited, yet convenient way, as tied mixtures of simple multivariate densities. Speech recognition experiments, reported for two (5000- and 20000-word vocabulary) office correspondence tasks, demonstrate some of the benefits associated with this technique. >"
            },
            "slug": "Tied-mixture-continuous-parameter-modeling-for-Bellegarda-Nahamoo",
            "title": {
                "fragments": [],
                "text": "Tied mixture continuous parameter modeling for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A class of very general hidden Markov models which can accommodate feature vector sequences lying either in a discrete or in a continuous space is considered; the new class allows one to represent the prototypes in an assumption-limited, yet convenient way, as tied mixtures of simple multivariate densities."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46254718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "090f3ea5bc188bbb03aec02aba9ed9c7b38ff870",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain. First we give a concise review of the literature with emphasis on the Baum-Welch algorithm. This is followed by a detailed discussion of three issues not treated in the literature: alternatives to the Baum-Welch algorithm; critical facets of the implementation of the algorithms, with emphasis on their numerical properties; and behavior of Markov models on certain artificial but realistic problems. Special attention is given to a particular class of Markov models, which we call \u201cleft-to-right\u201d models. This class of models is especially appropriate for isolated word recognition. The results of the application of these methods to an isolated word, speaker-independent speech recognition experiment are given in a companion paper."
            },
            "slug": "An-introduction-to-the-application-of-the-theory-of-Levinson-Rabiner",
            "title": {
                "fragments": [],
                "text": "An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper presents several of the salient theoretical and practical issues associated with modeling a speech signal as a probabilistic function of a (hidden) Markov chain, and focuses on a particular class of Markov models, which are especially appropriate for isolated word recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69854558"
                        ],
                        "name": "S. S. Marcus",
                        "slug": "S.-S.-Marcus",
                        "structuredName": {
                            "firstName": "Sm",
                            "lastName": "Marcus",
                            "middleNames": [
                                "Stephen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 142765410,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "65b66e5c72b217338cd7fee7d9b714fb38c0e7bd",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ERIS-context-sensitive-coding-in-speech-perception-Marcus",
            "title": {
                "fragments": [],
                "text": "ERIS-context sensitive coding in speech perception"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678451"
                        ],
                        "name": "K. Choukri",
                        "slug": "K.-Choukri",
                        "structuredName": {
                            "firstName": "Khalid",
                            "lastName": "Choukri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Choukri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3175118"
                        ],
                        "name": "S. Soudoplatoff",
                        "slug": "S.-Soudoplatoff",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Soudoplatoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Soudoplatoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079741223"
                        ],
                        "name": "A. Wallyn",
                        "slug": "A.-Wallyn",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Wallyn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wallyn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9457270"
                        ],
                        "name": "F. Bimbot",
                        "slug": "F.-Bimbot",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Bimbot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bimbot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2594646"
                        ],
                        "name": "H. Valbret",
                        "slug": "H.-Valbret",
                        "structuredName": {
                            "firstName": "H\u00e9l\u00e8ne",
                            "lastName": "Valbret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Valbret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741426"
                        ],
                        "name": "P. Gallinari",
                        "slug": "P.-Gallinari",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Gallinari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gallinari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734694"
                        ],
                        "name": "Youn\u00e8s Bennani",
                        "slug": "Youn\u00e8s-Bennani",
                        "structuredName": {
                            "firstName": "Youn\u00e8s",
                            "lastName": "Bennani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youn\u00e8s Bennani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1411243248"
                        ],
                        "name": "\u00c1. Varga",
                        "slug": "\u00c1.-Varga",
                        "structuredName": {
                            "firstName": "\u00c1d\u00e1m",
                            "lastName": "Varga",
                            "middleNames": [
                                "Csaba"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c1. Varga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094458344"
                        ],
                        "name": "Manfred Immend\u00f6rfer",
                        "slug": "Manfred-Immend\u00f6rfer",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Immend\u00f6rfer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred Immend\u00f6rfer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054677"
                        ],
                        "name": "T. Michaux",
                        "slug": "T.-Michaux",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Michaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Michaux"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11637696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7243d98430c8fb783c7fbb2fc2b51665838df34",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-processing-and-recognition-using-integrated-Choukri-Soudoplatoff",
            "title": {
                "fragments": [],
                "text": "Speech processing and recognition using integrated neurocomputing techniques (Esprit Basic Research Action 3228: SPRINT)"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60769407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1aa31d5deb45f477a6de45b3b75b62c7f4a213e7",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This thesis examines the acoustic-modeling problem in automatic speech recognition from an information-theoretic point of view. This problem is to design a speech-recognition system which can extract from the speech waveform as much information as possible about the corresponding word sequence. The information extraction process is broken down into two steps: a signal processing step which converts a speech waveform into a sequence of information bearing acoustic feature vectors, and a step which models such a sequence. This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N. It explores the trade-off between packing a lot of information into such sequences and being able to model them accurately. The difficulty of developing accurate models of continuous parameter sequences is addressed by investigating a method of parameter estimation which is specifically designed to cope with inaccurate modeling assumptions."
            },
            "slug": "The-acoustic-modeling-problem-in-automatic-speech-Brown",
            "title": {
                "fragments": [],
                "text": "The acoustic-modeling problem in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis is primarily concerned with the use of hidden Markov models to model sequences of feature vectors which lie in a continuous space such as R sub N and explores the trade-off between packing a lot of information into such sequences and being able to model them accurately."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62025798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a55d31784aca11871985096644a025f036633569",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speech-pattern-discrimination-and-multilayer-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Speech pattern discrimination and multilayer perceptrons"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73429655"
                        ],
                        "name": "Hanazawa G. Hinton",
                        "slug": "Hanazawa-G.-Hinton",
                        "structuredName": {
                            "firstName": "Hanazawa",
                            "lastName": "Hinton",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanazawa G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71055078"
                        ],
                        "name": "Ic Shikano Ic",
                        "slug": "Ic-Shikano-Ic",
                        "structuredName": {
                            "firstName": "Ic",
                            "lastName": "Ic",
                            "middleNames": [
                                "Shikano"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ic Shikano Ic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62490901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "918aeead4adb3052bd0c437ac40939c116ba65db",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "neme recognition which is characterized by two important properties: 1.) Using a 3 layer arrangement of simple computing units, it can represent arbitrary nonlinear decision surfaces. The TDNN learns these decision surfaces automatically using error back-propagatioii[l]. 2.) he time-delay arrangement enables the network to discover acoustichonetic features and the temporal relationships between them indeendent of position in time and hence not blurred by temporal shifts in the input. For comparison, several discrete Hidden Markov Models (HMM) were trained to perform the same task, i.e., the speakerdependent recognition of the phonemes \"B\", \"D\", and \"G\" extracted We show that the TDNN \"invented\" well-known acoustic-phonetic"
            },
            "slug": "Phoneme-Recognition:-Neural-Networks-vs-Waibel-Hinton",
            "title": {
                "fragments": [],
                "text": "Phoneme Recognition: Neural Networks vs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the TDNN \"invented\" well-known acoustic-phonetic features and the temporal relationships between them are indeendent of position in time and hence not blurred by temporal shifts in the input."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107817206"
                        ],
                        "name": "M. Nakamura",
                        "slug": "M.-Nakamura",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Nakamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nakamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66980418"
                        ],
                        "name": "S. Tamura",
                        "slug": "S.-Tamura",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Tamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734761"
                        ],
                        "name": "S. Sagayama",
                        "slug": "S.-Sagayama",
                        "structuredName": {
                            "firstName": "Shigeki",
                            "lastName": "Sagayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sagayama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62593718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53cbbb0636048b27f1404f18709e873014774652",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A phoneme filter neural network (PFN) approach to vowel recognition is described. The PFN is a multilayer neural network with fewer hidden units than input units prepared for each of the phoneme categories. Each network is trained as identity mapping by speech data belonging to one phoneme category. In the recognition process, the similarity between the input data and output data is computed for each network. The results of an experiment involving the Japanese vowel recognition task showed that the PFN recognition rates for the top two or more choices are higher than those of a conventional three-layer neural network and the PFN outputs represented candidate likelihoods. It was also confirmed that the PFN has a mapping ability and recognition performance superior to those of the linear K-L transformation method because of the nonlinearity of the PFN.<<ETX>>"
            },
            "slug": "Phoneme-recognition-by-phoneme-filter-neural-Nakamura-Tamura",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition by phoneme filter neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The results of an experiment involving the Japanese vowel recognition task showed that the PFN recognition rates for the top two or more choices are higher than those of a conventional three-layer neural network and thePFN outputs represented candidate likelihoods."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57067402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d90c8bd8c52992a62e98dbfede2664540e44d37",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "HMMs model signal dynamics rather poorly. Modeling accuracy can be improved by adding vector linear predictors to each state in order to predict the value of the current observation based on correlations with nearby observations. A vector linear predictive HMM is discussed and re-estimation formulae for the predictor parameters presented. Multiple speaker recognition experiments on a 104 talker British English E-set database were performed to test the method on a difficult speech recognition task. It was found that a baseline test set error rate of 5.6% improved to 4.1% using a single diagonal predictor. Further improvements in performance along with a reduction in computation were obtained by using the method of discriminative output distributions on the prediction error. This resulted in a best test set error rate of 2.8% from a system that required only half the computation of the baseline.<<ETX>>"
            },
            "slug": "Hidden-Markov-models-using-vector-linear-prediction-Woodland",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models using vector linear prediction and discriminative output distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A vector linear predictive HMM is discussed and re-estimation formulae for the predictor parameters presented and improvements in performance along with a reduction in computation were obtained by using the method of discriminative output distributions on the prediction error."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2459610"
                        ],
                        "name": "B. Petek",
                        "slug": "B.-Petek",
                        "structuredName": {
                            "firstName": "Bojan",
                            "lastName": "Petek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Petek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144001744"
                        ],
                        "name": "J. Tebelskis",
                        "slug": "J.-Tebelskis",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Tebelskis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tebelskis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14885834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1927da6124219daa2e5336f0a3254f3441eb74f1",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Integrated-phoneme-and-function-word-architecture-Petek-Waibel",
            "title": {
                "fragments": [],
                "text": "Integrated phoneme and function word architecture of hidden control neural networks for continuous speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065228513"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61066528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "028a2afb076ad3ab79345cca74958931f6a5a5ad",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, connectionist models have been recognized as an interesting alternative tool to hidden Markov models for speech recognition. Their main property lies in their combination of good discriminating power and the ability to capture input-output relations. They have also been proved useful in dealing with statistical data. However, the serial aspect remains difficult to handle in that kind of model, and several authors have proposed original architectures to deal with this problem. This study establishes links among them and compares their respective advantages. Relations with hidden Markov models are explained.<<ETX>>"
            },
            "slug": "Speech-dynamics-and-recurrent-neural-networks-Bourlard-Wellekens",
            "title": {
                "fragments": [],
                "text": "Speech dynamics and recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This study establishes links among connectionist models for speech recognition and compares their respective advantages, and explains relations with hidden Markov models."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143869759"
                        ],
                        "name": "P. Kohn",
                        "slug": "P.-Kohn",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Kohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62171015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e49679db76aae02c07b802e304e3ab142a4390e",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors investigate the use of continuous features derived by perceptual linear predictive (PLP) analysis, examine the effect of adding temporal features, and compare it to the previously studied use of multiframe input. Comparisons of the MLP (multilayer perceptron) and conventional Gaussian classifiers are also reported. The speaker-dependent portion of the Resource Management database was used for this test. Additionally, some experiments were performed with a perplexity-2200 speaker-independent recognition task on a subset of the TIMIT database. In each case, the PLP features were used as input to the networks. The experiments show the advantage of continuous PLP features and their first and second temporal derivatives.<<ETX>>"
            },
            "slug": "Continuous-speech-recognition-using-PLP-analysis-Morgan-Hermansky",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition using PLP analysis with multilayer perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors investigate the use of continuous features derived by perceptual linear predictive (PLP) analysis, examine the effect of adding temporal features, and compare it to the previously studied use of multiframe input."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8461145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a529e0a5a796001e466ddf305b7c66abef90ce41",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives a unified theoretical view of the Dynamic Time Warping (DTW) and the Hidden Markov Model (HMM) techniques for speech recognition problems. The application of hidden Markov models in speech recognition is discussed. We show that the conventional dynamic time-warping algorithm with Linear Predictive (LP) signal modeling and distortion measurements can be formulated in a strictly statistical framework. It is further shown that the DTW/LP method is implicitly associated with a specific class of Markov models and is equivalent to the probability maximization procedures for Gaussian autoregressive multivariate probabilistic functions of the underlying Markov model. This unified view offers insights into the effectiveness of the probabilistic models in speech recognition applications."
            },
            "slug": "On-the-hidden-Markov-model-and-dynamic-time-warping-Juang",
            "title": {
                "fragments": [],
                "text": "On the hidden Markov model and dynamic time warping for speech recognition \u2014 A unified view"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A unified theoretical view of the Dynamic Time Warping (DTW) and the Hidden Markov Model (HMM) techniques for speech recognition problems is given and offers insights into the effectiveness of the probabilistic models in speech recognition applications."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Bell Laboratories Technical Journal"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2452389"
                        ],
                        "name": "E. McDermott",
                        "slug": "E.-McDermott",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "McDermott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. McDermott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715709"
                        ],
                        "name": "S. Katagiri",
                        "slug": "S.-Katagiri",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Katagiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katagiri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46066535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8809e0f221bd2c8227057d124b37b71841a3d9a",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A shift-tolerant neural network architecture for phoneme recognition is described. The system is based on algorithms for learning vector quantization (LVQ), recently developed by Kohonen (1986, 1988), which pay close attention to approximating optimal decision lines in a discrimination task. Recognition performances in the 98%-99% correct range were obtained for LVQ networks aimed at speaker-dependent recognition of phonemes in small but ambiguous Japanese phonemic classes. A correct recognition rate of 97.7% was achieved by a large LVQ network covering all Japanese consonants. These recognition results are as good as those obtained in the time delay neural network system developed by Waibel et al. (1989), and suggest that LVQ could be the basis for a high-performance speech recognition system. >"
            },
            "slug": "LVQ-based-shift-tolerant-phoneme-recognition-McDermott-Katagiri",
            "title": {
                "fragments": [],
                "text": "LVQ-based shift-tolerant phoneme recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "Recognition results are as good as those obtained in the time delay neural network system developed by Waibel et al. (1989), and suggest that LVQ could be the basis for a high-performance speech recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901373"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Evan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727234"
                        ],
                        "name": "Y. Chow",
                        "slug": "Y.-Chow",
                        "structuredName": {
                            "firstName": "Yen-lu",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353221"
                        ],
                        "name": "O. Kimball",
                        "slug": "O.-Kimball",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Kimball",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kimball"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4953636"
                        ],
                        "name": "M. Krasner",
                        "slug": "M.-Krasner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Krasner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krasner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60579533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df53e0dc66eb13bb51c6e4803ceae56d3ebe6f23",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the results of our work in designing a system for phonetic recognition of unrestricted continuous speech. We describe several algorithms used to recognize phonemes using context-dependent Hidden Markov Models of the phonemes. We present results for several variations of the parameters of the algorithms. In addition, we propose a technique that makes it possible to integrate traditional acoustic-phonetic features into a hidden Markov process. The categorical decisions usually associated with heuristic acoustic-phonetic algorithms are replaced by automated training techniques and global search strategies. The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "slug": "Context-dependent-modeling-for-acoustic-phonetic-of-Schwartz-Chow",
            "title": {
                "fragments": [],
                "text": "Context-dependent modeling for acoustic-phonetic recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The combination of general spectral information and specific acoustic-phonetic features is shown to result in more accurate phonetic recognition than either representation by itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '85. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17627898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "502752ad5481e5920f25ddef03f174d2ce10c65d",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors review the use of feedforward neural networks as estimators of probability densities in hidden Markov modelling. In this paper, they are mostly concerned with radial basis functions (RBF) networks. They not the isomorphism of RBF networks to tied mixture density estimators; additionally they note that RBF networks are trained to estimate posteriors rather than the likelihoods estimated by tied mixture density estimators. They show how the neural network training should be modified to resolve this mismatch. They also discuss problems with discriminative training, particularly the problem of dealing with unlabelled training data and the mismatch between model and data priors.<<ETX>>"
            },
            "slug": "Probability-estimation-by-feed-forward-networks-in-Renals-Morgan",
            "title": {
                "fragments": [],
                "text": "Probability estimation by feed-forward networks in continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "The authors review the use of feedforward neural networks as estimators of probability densities in hidden Markov modelling and discusses problems with discriminative training, particularly the problem of dealing with unlabelled training data and the mismatch between model and data priors."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing Proceedings of the 1991 IEEE Workshop"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61961691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "120e4d34c196195e307a945e854237dd1b4faa86",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The Lincoln robust HMM (hidden Markov model) recognizer has been converted from a single Gaussian or Gaussian mixture PDF per state to tied mixtures in which a single set of Gaussians is shared between all states. There were initial difficulties caused by the use of mixture pruning but these were cured by using observation pruning. Fixed weight smoothing of the mixture weights allowed the use of word-boundary-context-dependent triphone models for both speaker-dependent (SD) and speaker-independent (SI) recognition. A second-differential observation stream further improved SI performance but not SD performance. A novel form of phonetic context model, the semiphone, is also introduced. This model significantly reduces the number of states required to model a vocabulary and unifies triphone and diphone modeling.<<ETX>>"
            },
            "slug": "The-Lincoln-tied-mixture-HMM-continuous-speech-Paul",
            "title": {
                "fragments": [],
                "text": "The Lincoln tied-mixture HMM continuous speech recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Lincoln robust HMM (hidden Markov model) recognizer has been converted from a single Gaussian or Gaussian mixture PDF per state to tied mixtures in which a single set of Gaussians is shared between all states."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2452389"
                        ],
                        "name": "E. McDermott",
                        "slug": "E.-McDermott",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "McDermott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. McDermott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715709"
                        ],
                        "name": "S. Katagiri",
                        "slug": "S.-Katagiri",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Katagiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katagiri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61730658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b773060ea50c203c25f442847f656cd4ed596db",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a shift-tolerant neural network architecture for phoneme recognition. The system is based on LVQ2, an algorithm which pays close attention to approximating the optimal Bayes decision line in a discrimination task. Recognition performances in the 98-99% correct range were obtained for LVQ2 networks aimed at speaker-dependent recognition of phonemes in small but ambiguous Japanese phonemic classes. A correct recognition rate of 97.7% was achieved by a single, larger LVQ2 network covering all Japanese consonants. These recognition results are at least as high as those obtained in the time delay neural network system and suggest that LVQ2 could be the basis for a successful speech recognition system.<<ETX>>"
            },
            "slug": "Shift-invariant,-multi-category-phoneme-recognition-McDermott-Katagiri",
            "title": {
                "fragments": [],
                "text": "Shift-invariant, multi-category phoneme recognition using Kohonen's LVQ2"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A shift-tolerant neural network architecture for phoneme recognition based on LVQ2, an algorithm which pays close attention to approximating the optimal Bayes decision line in a discrimination task, which is suggested to be the basis for a successful speech recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12926318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de996c32045df6f7b404dda2a753b6a9becf3c08",
            "isKey": false,
            "numCitedBy": 1885,
            "numCiting": 229,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes NETtalk, a class of massively-parallel network systems that learn to convert English text to speech. The memory representations for pronunciations are learned by practice and are shared among many processing units. The performance of NETtalk has some similarities with observed human performance. (i) The learning follows a power law. (ii) The more words the network learns, the better it is at generalizing and correctly pronouncing new words, (iii) The performance of the network degrades very slowly as connections in the network are damaged: no single link or processing unit is essential. (iv) Relearning after damage is much faster than learning during the original training. (v) Distributed or spaced practice is more effective for long-term retention than massed practice. Network models can be constructed that have the same performance and learning characteristics on a particular task, but differ completely at the levels of synaptic strengths and single-unit responses. However, hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units. This suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "slug": "Parallel-Networks-that-Learn-to-Pronounce-English-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "Parallel Networks that Learn to Pronounce English Text"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "H hierarchical clustering techniques applied to NETtalk reveal that these different networks have similar internal representations of letter-to-sound correspondences within groups of processing units, which suggests that invariant internal representations may be found in assemblies of neurons intermediate in size between highly localized and completely distributed representations."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41994273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c91c2ac02e33caff601b2e4d62a6841b33ca3929",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Alpha-nets:-A-recurrent-'neural'-network-with-a-Bridle",
            "title": {
                "fragments": [],
                "text": "Alpha-nets: A recurrent 'neural' network architecture with a hidden Markov model interpretation"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2154317"
                        ],
                        "name": "J. Wilpon",
                        "slug": "J.-Wilpon",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Wilpon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wilpon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24032191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9e7c418a63470dcbc98eb8cc3e58529243521ee",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major drawbacks of the standard pattern-recognition approach to isolated word recognition is that poor performance is generally achieved for word vocabularies with acoustically similar words. This poor performance is related to the pattern similarity (distance) algorithms that are generally used in which a global distance between the test pattern and each reference pattern is computed. Since acoustically similar words are, by definition, globally similar, it is difficult to reliably discriminate such words, and a high error rate is obtained. By modifying the pattern-similarity algorithm so that the recognition decision is made in two passes, we can achieve improvements in discriminability among similar words. In particular, on the first pass the recognizer provides a set of global distance scores which are used to decide a class (or a set of possible classes) in which the spoken word is estimated to belong. On the second pass we use a locally weighted distance to provide optimal separation among words in the chosen class (or classes), and make the recognition decision on the basis of these local distance scores. For a highly complex vocabulary (letters of the alphabet, digits, and three command words), we obtain recognition improvements of from 3 to 7 percent using the two-pass recognition strategy."
            },
            "slug": "A-two-pass-pattern-recognition-approach-to-isolated-Rabiner-Wilpon",
            "title": {
                "fragments": [],
                "text": "A two-pass pattern-recognition approach to isolated word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Modifying the pattern-similarity algorithm so that the recognition decision is made in two passes can achieve improvements in discriminability among similar words, and for a highly complex vocabulary, this strategy is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "The Bell System Technical Journal"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091434"
                        ],
                        "name": "G. Kuhn",
                        "slug": "G.-Kuhn",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kuhn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1822055"
                        ],
                        "name": "Raymond L. Watrous",
                        "slug": "Raymond-L.-Watrous",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Watrous",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond L. Watrous"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18612099"
                        ],
                        "name": "B. Ladendorf",
                        "slug": "B.-Ladendorf",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Ladendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ladendorf"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12608180,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "7649115331fb03ec168cfea8b308de1aa2705429",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connected-recognition-with-a-recurrent-network-Kuhn-Watrous",
            "title": {
                "fragments": [],
                "text": "Connected recognition with a recurrent network"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145048087"
                        ],
                        "name": "E. A. Martin",
                        "slug": "E.-A.-Martin",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Martin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. A. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61685722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1923e2149604d4365d29e81d888b763a85fa18c1",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a two-stage isolated word speech recognition system that uses a Hidden Markov Model (HMM) recognizer in the first stage and a discriminant analysis system in the second stage. During recognition, when the first-stage recognizer is unable to clearly differentiate between acoustically similar words such as \"go\" and \"no\" the second-stage discriminator is used. The second-stage system focuses on those parts of the unknown token which are most effective at discriminating the confused words. The system was tested on a 35 word, 10,710 token stress speech isolated word data base created at Lincoln Laboratory. Adding the second-stage discriminating system produced the best results to date on this data base, reducing the overall error rate by more than a factor of two."
            },
            "slug": "Two-stage-discriminant-analysis-for-improved-Martin-Lippmann",
            "title": {
                "fragments": [],
                "text": "Two-stage discriminant analysis for improved isolated-word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A two-stage isolated word speech recognition system that uses a Hidden Markov Model (HMM) recognizer in the first stage and a discriminant analysis system in the second stage, reducing the overall error rate by more than a factor of two."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054846284"
                        ],
                        "name": "A. Krause",
                        "slug": "A.-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183055"
                        ],
                        "name": "H. Hackbarth",
                        "slug": "H.-Hackbarth",
                        "structuredName": {
                            "firstName": "Heidi",
                            "lastName": "Hackbarth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hackbarth"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60531553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dd3e28f59df81d58fa2bb5824f34cd7b71939aa",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial neural networks were investigated as an approach to speaker-independent recognition of isolated words from a variable-size vocabulary. A scaly pattern of connecting links between the input and hidden layer was established within a strict feed-forward wiring structure. The amount of training material and vocabulary size as well as the choice of network dimensions, such as the number of layers and input and hidden units, are discussed. Experimental results are reported and compared to the recognition performance obtained with a fully connected layered network. Error rates lower than 5% for vocabularies with up to 20 words suggest that appropriately designed artificial neural networks are well suited for a speaker-independent recognition task.<<ETX>>"
            },
            "slug": "Scaly-artificial-neural-networks-for-recognition-of-Krause-Hackbarth",
            "title": {
                "fragments": [],
                "text": "Scaly artificial neural networks for speaker-independent recognition of isolated words"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "Artificial neural networks were investigated as an approach to speaker-independent recognition of isolated words from a variable-size vocabulary and showed good results."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5568049,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "291a8fbdd0ca670af9e901531eb9e6d5c1936944",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of neural networks to modeling time-invariant nonlinear systems has been difficult for complicated nonstationary signals, such as speech, because the networks are unable to characterize temporal variability. This problem is addressed by proposing a network architecture, called the hidden control neural network (HCNN), for modeling signals generated by nonlinear dynamical systems with restricted time variability. The mapping implemented by a multilayered neural network is allowed to change with time as a function of an additional control input signal. The network is trained using an algorithm based on ;backpropagation' and segmentation algorithms for estimating the unknown control together with the network's parameters. Application of the network to the segmentation and modeling of a signal produced by a time-varying nonlinear system, speaker-independent recognition of spoken connected digits, and online recognition of handwritten characters demonstrates the ability of the HCNN to learn time-varying nonlinear dynamics and its potential for high-performance recognition of signals produced by time-varying sources."
            },
            "slug": "Hidden-control-neural-architecture-modeling-of-time-Levin",
            "title": {
                "fragments": [],
                "text": "Hidden control neural architecture modeling of nonlinear time varying systems and its applications"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proposed hidden control neural network (HCNN) architecture for modeling signals generated by nonlinear dynamical systems with restricted time variability demonstrates the ability of the HCNN to learn time-varying nonlinear dynamics and its potential for high-performance recognition of signals produced by time-Varying sources."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145778742"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Juang",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11358505,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d076613d7c36dbda4a6ff42fbdd076604b96630",
            "isKey": false,
            "numCitedBy": 2945,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The basic theory of Markov chains has been known to mathematicians and engineers for close to 80 years, but it is only in the past decade that it has been applied explicitly to problems in speech processing. One of the major reasons why speech models, based on Markov chains, have not been developed until recently was the lack of a method for optimizing the parameters of the Markov model to match observed signal patterns. Such a method was proposed in the late 1960's and was immediately applied to speech processing in several research institutions. Continued refinements in the theory and implementation of Markov modelling techniques have greatly enhanced the method, leading to a wide range of applications of these models. It is the purpose of this tutorial paper to give an introduction to the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition."
            },
            "slug": "An-introduction-to-hidden-Markov-models-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "An introduction to hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The purpose of this tutorial paper is to give an introduction to the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE ASSP Magazine"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15553242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "436f38dc28ca25af965b202ebe0e27c747888da6",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a signal modeling technique based upon finite mixture autoregressive probabilistic functions of Markov chains is developed and applied to the problem of speech recognition, particularly speaker-independent recognition of isolated digits. Two types of mixture probability densities are investigated: finite mixtures of Gaussian autoregressive densities (GAM) and nearest-neighbor partitioned finite mixtures of Gaussian autoregressive densities (PGAM). In the former (GAM), the observation density in each Markov state is simply a (stochastically constrained) weighted sum of Gaussian autoregressive densities, while in the latter (PGAM) it involves nearest-neighbor decoding which in effect, defines a set of partitions on the observation space. In this paper we discuss the signal modeling methodology and give experimental results on speaker independent recognition of isolated digits. We also discuss the potential use of the modeling technique for other applications."
            },
            "slug": "Mixture-autoregressive-hidden-Markov-models-for-Juang-Rabiner",
            "title": {
                "fragments": [],
                "text": "Mixture autoregressive hidden Markov models for speech signals"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The signal modeling methodology is discussed and experimental results on speaker independent recognition of isolated digits are given and the potential use of the modeling technique for other applications are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120460"
                        ],
                        "name": "L. Niles",
                        "slug": "L.-Niles",
                        "structuredName": {
                            "firstName": "Les",
                            "lastName": "Niles",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Niles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748100"
                        ],
                        "name": "H. Silverman",
                        "slug": "H.-Silverman",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Silverman",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Silverman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1918411"
                        ],
                        "name": "G. Tajchman",
                        "slug": "G.-Tajchman",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Tajchman",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tajchman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959145"
                        ],
                        "name": "M. Bush",
                        "slug": "M.-Bush",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Bush",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bush"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61646362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "853e23daa0704cd5f2aae6d55341fdf2423928e2",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiments comparing artificial neural network (ANN), k-nearest-neighbor (KNN), and Bayes' rule with Gaussian distributions and maximum-likelihood estimation (BGM) classifiers were performed. Classifier error rate as a function of training set size was tested for synthetic data drawn from several different probability distributions. In cases where the true distributions were poorly modeled, ANN was significantly better than BGM. In some cases, ANN was also better than KNN. Similar experiments were performed on a voiced/unvoiced speech classification task. ANN had a lower error rate than KNN or BGM for all training set sizes, although BGM approached the ANN error rate as the training set became larger. It is concluded that there are pattern classification tasks in which an ANN is able to make better use of training data to achieve a lower error rate with a particular size training set.<<ETX>>"
            },
            "slug": "How-limited-training-data-can-allow-a-neural-to-an-Niles-Silverman",
            "title": {
                "fragments": [],
                "text": "How limited training data can allow a neural network to outperform an 'optimal' statistical classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is concluded that there are pattern classification tasks in which an ANN is able to make better use of training data to achieve a lower error rate with a particular size training set."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144435557"
                        ],
                        "name": "A. Kehagias",
                        "slug": "A.-Kehagias",
                        "structuredName": {
                            "firstName": "Athanasios",
                            "lastName": "Kehagias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kehagias"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 121785663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8867d879777a5dd684a5d647bccb58546655051b",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-Control-for-training:-The-missing-link-and-Kehagias",
            "title": {
                "fragments": [],
                "text": "Optimal Control for training: The missing link between Hidden Markov Models and Connectionist Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59636530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f462943c8d0af69c12a09058251848324135e5a",
            "isKey": false,
            "numCitedBy": 1100,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with feed-forward non-linear networks (multi-layer perceptrons, or MLPs) with multiple outputs. We wish to treat the outputs of the network as probabilities of alternatives (e.g. pattern classes), conditioned on the inputs. We look for appropriate output non-linearities and for appropriate criteria for adaptation of the parameters of the network (e.g. weights). We explain two modifications: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non-linearity. The two modifications together result in quite simple arithmetic, and hardware implementation is not difficult either. The use of radial units (squared distance instead of dot product) immediately before the softmax output stage produces a network which computes posterior distributions over class labels based on an assumption of Gaussian within-class distributions. However the training, which uses cross-class information, can result in better performance at class discrimination than the usual within-class training method, unless the within-class distribution assumptions are actually correct."
            },
            "slug": "Probabilistic-Interpretation-of-Feedforward-Network-Bridle",
            "title": {
                "fragments": [],
                "text": "Probabilistic Interpretation of Feedforward Classification Network Outputs, with Relationships to Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two modifications are explained: probability scoring, which is an alternative to squared error minimisation, and a normalised exponential (softmax) multi-input generalisation of the logistic non- linearity of feed-forward non-linear networks with multiple outputs."
            },
            "venue": {
                "fragments": [],
                "text": "NATO Neurocomputing"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14789841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4775e2f0d27e8be4aae7b5b5c2560b96ce2eb58",
            "isKey": false,
            "numCitedBy": 1403,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them."
            },
            "slug": "A-Maximum-Likelihood-Approach-to-Continuous-Speech-Bahl-Jelinek",
            "title": {
                "fragments": [],
                "text": "A Maximum Likelihood Approach to Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes a number of statistical models for use in speech recognition, with special attention to determining the parameters for such models from sparse data, and describes two decoding methods appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2138480"
                        ],
                        "name": "B. Necioglu",
                        "slug": "B.-Necioglu",
                        "structuredName": {
                            "firstName": "Burhan",
                            "lastName": "Necioglu",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Necioglu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57374151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13dc3da91f4672f2262cc21f400b21e978d83b80",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition of the Wall Street Journal (WSJ) pilot database, a continuous-speech-recognition (CSR) database which supports 5 K, 20 K, and up to 64 K-word CSR tasks, is examined. The original Lincoln tied-mixture hidden Markov model (HMM) CSR was implemented using a time-synchronous beam-pruned search of a static network which does not extend well to this task because the recognition network would be too large. Therefore, the recognizer has been converted to a stack decoder-based search strategy. This decoder has been shown to function effectively on up to 64 K-word recognition of continuous speech. Recognition-time adaptation has also been added to the recognizer. The acoustic modeling techniques and the implementation of the stack decoder used to obtain these results are described.<<ETX>>"
            },
            "slug": "The-Lincoln-large-vocabulary-stack-decoder-HMM-CSR-Paul-Necioglu",
            "title": {
                "fragments": [],
                "text": "The Lincoln large-vocabulary stack-decoder HMM CSR"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Recognition of the Wall Street Journal (WSJ) pilot database, a continuous-speech-recognition (CSR) database which supports 5 K, 20 K, and up to 64 K-word CSR tasks, is examined and the recognizer has been converted to a stack decoder-based search strategy."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143632131"
                        ],
                        "name": "P. Kenny",
                        "slug": "P.-Kenny",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Kenny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kenny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959613"
                        ],
                        "name": "Matthew Lennig",
                        "slug": "Matthew-Lennig",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Lennig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Lennig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143791674"
                        ],
                        "name": "P. Mermelstein",
                        "slug": "P.-Mermelstein",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Mermelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mermelstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9833220,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "8c2218c2cd3efb1454b6c4f512fd9f7a61029ddf",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a new type of Markov model developed to account for the correlations between successive frames of a speech signal. The idea is to treat the sequence of frames as a nonstationary autoregressive process whose parameters are controlled by a hidden Markov chain. It is shown that this type of model performs better than the standard multivariate Gaussian HMM (hidden Markov model) when it is incorporated into a large-vocabulary isolated-word recognizer. >"
            },
            "slug": "A-linear-predictive-HMM-for-vector-valued-with-to-Kenny-Lennig",
            "title": {
                "fragments": [],
                "text": "A linear predictive HMM for vector-valued observations with applications to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A new type of Markov model developed to account for the correlations between successive frames of a speech signal that performs better than the standard multivariate Gaussian HMM (hidden Markov models) when it is incorporated into a large-vocabulary isolated-word recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399226527"
                        ],
                        "name": "Naftali Z. Tisby",
                        "slug": "Naftali-Z.-Tisby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tisby",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Z. Tisby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20995572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e763f3f0d3ed7a0a99ea3a730934d670cca1c954",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear predictive hidden Markov models have proved to be efficient for statistically modeling speech signals. The possible application of such models to statistical characterization of the speaker himself is described and evaluated. The results show that even with a short sequence of only four isolated digits, a speaker can be verified with an average equal-error rate of less than 3 %. These results are slightly better than the results obtained using speaker-dependent vector quantizers, with comparable numbers of spectral vectors. The small improvement over the vector quantization approach indicates the weakness of the Markovian transition probabilities for characterizing speaker-dependent transitional information. >"
            },
            "slug": "On-the-application-of-mixture-AR-hidden-Markov-to-Tisby",
            "title": {
                "fragments": [],
                "text": "On the application of mixture AR hidden Markov models to text independent speaker recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results show that even with a short sequence of only four isolated digits, a speaker can be verified with an average equal-error rate of less than 3 %, and the small improvement over the vector quantization approach indicates the weakness of the Markovian transition probabilities for characterizing speaker-dependent transitional information."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60864895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0802c70eba26b9798e1e8cbb6e285bce842fd5c",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Automatic recognition of continuous speech involves estimation of a sequence X(1), X(2), X(3), ..., X(T) which is not directly observed (such as the words of a spoken utterance), based on a sequence Y(1), Y(2), Y(3), ..., Y(T) of related observations (such as the sequence of acoustic parameter values) and a variety of sources of knowledge. Formally the author wishes to find the sequence x(1:T) which maximizes the a posteriori probability Pr(x(1:T))=(1:T) Y(1:T) =y(1:T),A,L.P,S), where A,L,P,S represent the acoustic-phonetic, lexical, phonological, and syntactic-semantic knowledge. A speech recognition system must attempt to approximate a solution to this problem, whether or not the system uses a formal stochastic model. The DRAGON speech recognition system models the knowledge sources as probalistic functions of Markov processes. The assumption of the Markov property allows the use of an optimal search strategy. A simplified implementation of the DRAGON system has been developed using knowledge A and L, and some of the knowledge from S."
            },
            "slug": "Stochastic-modeling-as-a-means-of-automatic-speech-Baker",
            "title": {
                "fragments": [],
                "text": "Stochastic modeling as a means of automatic speech recognition."
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A simplified implementation of the DRAGON speech recognition system has been developed using knowledge A and L, and some of the knowledge from S, where A,L,P,S represent the acoustic-phonetic, lexical, phonological, and syntactic-semantic knowledge."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686820"
                        ],
                        "name": "B. M\u00e9rialdo",
                        "slug": "B.-M\u00e9rialdo",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "M\u00e9rialdo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M\u00e9rialdo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60968219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3fa9a9a9652ab70dec27b0f4d333bdbbe9a31b1",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of maximum-mutual-information (MMI) training to hidden Markov models (HMMs) is studied for phonetic recognition. MMI training has been proposed as an alternative to standard maximum-likelihood (ML) training. In practice, MMI training performs better (produces models that are more accurate) than ML training. The fundamental notions of HMM, ML and MMI training are reviewed, and it is shown how MMI training can be applied easily to the case of phonetic models and phonetic recognition. Some computational heuristics are proposed to implement these computations practically. Some experiments (training and recognition) are detailed that show that the phonetic error rate decreases significantly when MMI training is used, as compared with ML training.<<ETX>>"
            },
            "slug": "Phonetic-recognition-using-hidden-Markov-models-and-M\u00e9rialdo",
            "title": {
                "fragments": [],
                "text": "Phonetic recognition using hidden Markov models and maximum mutual information training"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The application of maximum-mutual-information (MMI) training to hidden Markov models (HMMs) is studied for phonetic recognition and shows that the phonetic error rate decreases significantly when MMI training is used, as compared with ML training."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61910495,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8514a38e5819bdb0872b7d3491194f063fb30b58",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to speech processing, based on nonlinear dynamical systems, is presented. It is shown that two fundamental problems in speech processing, dimensionality reduction and nonlinear temporal variability, can be addressed using geometrical methods from nonlinear dynamics. An effective dynamical system is extracted by training a nonlinear predictor of the signal samples. A variety of signal characteristics is then obtained from the properties of the resulting dynamical system such as the dimensionality and stability of its trajectories. The problem of time warping of speech is approached using a similar dynamical predictor, now acting directly on the acoustic features, provided that the magnitude of the time derivative of the feature vector is included in the predictor input. For the latter case the existence of a nonlinear predictor whose functional form is invariant with respect to nonlinear transformations of time is proven. The use of such dynamical predictors can replace or enhance existing methods for speech recognition.<<ETX>>"
            },
            "slug": "A-dynamical-systems-approach-to-speech-processing-Tishby",
            "title": {
                "fragments": [],
                "text": "A dynamical systems approach to speech processing"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "It is shown that two fundamental problems in speech processing, dimensionality reduction and nonlinear temporal variability, can be addressed using geometrical methods from nonlinear dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762024"
                        ],
                        "name": "R. Bakis",
                        "slug": "R.-Bakis",
                        "structuredName": {
                            "firstName": "Raimo",
                            "lastName": "Bakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119929465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8291be2289154cf1dcd5a4009222c1899533e253",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Continuous speech was treated as if produced by a finite\u2010state machine making a transition every centisecond. The observable output from state transitions was considered to be a power spectrum\u2014a probabilistic function of the target state of each transition. Using this model, observed sequences of power spectra from real speech were decoded as sequences of acoustic states by means of the Viterbi trellis algorithm. The finite\u2010state machine used as a representation of the speech source was composed of machines representing words, combined according to a \u201clanguage model.\u201d When trained to the voice of a particular speaker, the decoder recognized seven\u2010digit telephone numbers correctly 96% of the time, with a better than 99% per\u2010digit accuracy. Results for other tests of the system, including syllable and phoneme recognition, will also be given."
            },
            "slug": "Continuous-speech-recognition-via-centisecond-Bakis",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition via centisecond acoustic states"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "When trained to the voice of a particular speaker, the decoder recognized seven\u2010digit telephone numbers correctly 96% of the time, with a better than 99% per\u2010digit accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62236094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c5c1621ed69da09ffbd7c42b363486e0c9d2565",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Discusses the problem of estimating the parameter values of hidden Markov word models for speech recognition. The authors argue that maximum-likelihood estimation of the parameters does not lead to values which maximize recognition accuracy and describe an alternative estimation procedure called corrective training which is aimed at minimizing the number of recognition errors. Corrective training is similar to a well-known error-correcting training procedure for linear classifiers and works by iteratively adjusting the parameter values so as to make correct words more probable and incorrect words less probable. There are also strong parallels between corrective training and maximum mutual information estimation. They do not prove that the corrective training algorithm converges, but experimental evidence suggests that it does, and that it leads to significantly fewer recognition errors than maximum likelihood estimation.<<ETX>>"
            },
            "slug": "A-new-algorithm-for-the-estimation-of-hidden-Markov-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "A new algorithm for the estimation of hidden Markov model parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The authors argue that maximum-likelihood estimation of the parameters does not lead to values which maximize recognition accuracy and describe an alternative estimation procedure called corrective training which is aimed at minimizing the number of recognition errors."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144001744"
                        ],
                        "name": "J. Tebelskis",
                        "slug": "J.-Tebelskis",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Tebelskis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tebelskis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 21676552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d01fcd90db72ad9900b5e8462745dc5f38aaa767",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A large-vocabulary isolated word recognition system based on linked predictive neural networks (LPNNs) is presented. In this system, neural networks are used as predictors of speech frames, enabling a pool of such networks to serve as phoneme models. Higher-level algorithms are used to organize these networks, linking them into sequences corresponding to the phonetic spellings of words, and to train and evaluate the networks for word recognition. By virtue of linking phonemic networks, the LPNN is vocabulary independent and can be applied to large-vocabulary recognition. Recognition rates of 94% for a 234-word Japanese vocabulary of acoustically similar words and 90% for a larger vocabulary of 924 words are obtained.<<ETX>>"
            },
            "slug": "Large-vocabulary-recognition-using-linked-neural-Tebelskis-Waibel",
            "title": {
                "fragments": [],
                "text": "Large vocabulary recognition using linked predictive neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "In this system, neural networks are used as predictors of speech frames, enabling a pool of such networks to serve as phoneme models, and the LPNN is vocabulary independent and can be applied to large-vocabulary recognition."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7203896,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d45b8dcc1f929a43f4dae4dbd69a12d163aa8ed8",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-generalized-hidden-Markov-model-with-trend-of-for-Deng",
            "title": {
                "fragments": [],
                "text": "A generalized hidden Markov model with state-conditioned trend functions of time for the speech signal"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15052804,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b578f4faeb00b808e8786d897447f2493b12b4e9",
            "isKey": false,
            "numCitedBy": 2939,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, is presented and examined. This technique uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum: (1) the critical-band spectral resolution, (2) the equal-loudness curve, and (3) the intensity-loudness power law. The auditory spectrum is then approximated by an autoregressive all-pole model. A 5th-order all-pole model is effective in suppressing speaker-dependent details of the auditory spectrum. In comparison with conventional linear predictive (LP) analysis, PLP analysis is more consistent with human hearing. The effective second formant F2' and the 3.5-Bark spectral-peak integration theories of vowel perception are well accounted for. PLP analysis is computationally efficient and yields a low-dimensional representation of speech. These properties are found to be useful in speaker-independent automatic-speech recognition."
            },
            "slug": "Perceptual-linear-predictive-(PLP)-analysis-of-Hermansky",
            "title": {
                "fragments": [],
                "text": "Perceptual linear predictive (PLP) analysis of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new technique for the analysis of speech, the perceptual linear predictive (PLP) technique, which uses three concepts from the psychophysics of hearing to derive an estimate of the auditory spectrum, and yields a low-dimensional representation of speech."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149620"
                        ],
                        "name": "D. Mergel",
                        "slug": "D.-Mergel",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Mergel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mergel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801257"
                        ],
                        "name": "A. Noll",
                        "slug": "A.-Noll",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Noll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Noll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968677"
                        ],
                        "name": "A. Paeseler",
                        "slug": "A.-Paeseler",
                        "structuredName": {
                            "firstName": "Annedore",
                            "lastName": "Paeseler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paeseler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62408966,
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "id": "52d36c9349ec5ac54150fa39bf5f763312d92d65",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a data-driven organization of the dynamic programming beam search for large vocabulary, continuous speech recognition. This organization can be viewed as an extension of the one-pass dynamic programming algorithm for connected word recognition. In continuous speech recognition we are faced with a huge search space, and search hypotheses have to be formed at the 10-ms level. The organization of the search presented has the following characteristics. Its computational cost is proportional only to the number of hypotheses actually generated and is independent of the overall size of the potential search space. There is no limit on the number of word hypotheses, there is only a limit to the overall number of hypotheses due to memory constraints. The implementation of the search has been studied and tested on a continuous speech data base comprising 20672 words."
            },
            "slug": "A-data-driven-organization-of-the-dynamic-beam-for-Ney-Mergel",
            "title": {
                "fragments": [],
                "text": "A data-driven organization of the dynamic programming beam search for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper describes a data-driven organization of the dynamic programming beam search for large vocabulary, continuous speech recognition, which can be viewed as an extension of the one-pass dynamic programming algorithm for connected word recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195701839,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf2dbecb0adcd9b1bec1ec90f78f7bf4aaa13db4",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Context-dependent phone models are applied to speaker-independent continuous speech recognition and shown to be effective in this domain. Several previously proposed context-dependent models are evaluated, and two new context-dependent phonetic units are introduced: function-word-dependent phone models, which focus on the most difficult subvocabulary; and generalized triphones, which combine similar triphones on the basis of an information-theoretic measure. The subword clustering procedure used for generalized triphones can find the optimal number of models, given a fixed amount of training data. It is shown that context-dependent modeling reduces the error rate by as much as 60%. >"
            },
            "slug": "Context-independent-phonetic-hidden-Markov-models-Lee",
            "title": {
                "fragments": [],
                "text": "Context-independent phonetic hidden Markov models for speaker-independent continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Two new context-dependent phonetic units are introduced: function-word-dependent phone models, which focus on the most difficult subvocabulary; and generalized triphones, which combine similar triphones on the basis of an information-theoretic measure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115945547"
                        ],
                        "name": "H. Sawai",
                        "slug": "H.-Sawai",
                        "structuredName": {
                            "firstName": "Hidefumi",
                            "lastName": "Sawai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9293147"
                        ],
                        "name": "A. Waibei",
                        "slug": "A.-Waibei",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Waibei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1970204"
                        ],
                        "name": "M. Miyatake",
                        "slug": "M.-Miyatake",
                        "structuredName": {
                            "firstName": "Masanori",
                            "lastName": "Miyatake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Miyatake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14999196,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "8798a360b78b97f4ff96f1aaa1176d6157e4bc5e",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "To extend the performance of TDNNs (time-delay neural networks) to all phoneme recognition and word/continuous speech recognition, the authors present several techniques. First, they show that it is possible to scale up the TDNN to a large phonemic TDNN aimed at discriminating all phonemes without loss of recognition performance and without excessive training tokens. Second, the authors propose fast backpropagation learning methods which make it possible to train a large phonemic TDNN within 1.5 hours. Finally, they show several methods for spotting Japanese CV syllables/phonemes in input speech based on TDNNs: they constructed a TDNN which can discriminate a single CV syllable or phoneme. Syllable and phoneme spotting experiments show excellent results, with syllable and phoneme spotting rates of better than 96.7% and 92% correct, respectively.<<ETX>>"
            },
            "slug": "Parallelism,-hierarchy,-scaling-in-time-delay-for-Sawai-Waibei",
            "title": {
                "fragments": [],
                "text": "Parallelism, hierarchy, scaling in time-delay neural networks for spotting Japanese phonemes CV-syllables"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "To extend the performance of TDNNs (time-delay neural networks) to all phoneme recognition and word/continuous speech recognition, the authors present several techniques and constructed a TDNN which can discriminate a single CV syllable or phoneme."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35749818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e90c15e0de8b5452c6291359e98ddc099e3b93f6",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend previous work on isolated-word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal with a continuous Gaussian mixture density. In this manner the inherent quantization error introduced by the discrete representation is essentially eliminated. The resulting recognizer was tested on a vocabulary of the ten digits across a wide range of talkers and test conditions and shown to have an error rate comparable to that of the best template recognizers and significantly lower than that of the discrete symbol hidden Markov model system. We discuss several issues involved in the training of the continuous density models and in the implementation of the recognizer."
            },
            "slug": "Recognition-of-isolated-digits-using-hidden-Markov-Rabiner-Juang",
            "title": {
                "fragments": [],
                "text": "Recognition of isolated digits using hidden Markov models with continuous mixture densities"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This paper extends previous work on isolated-word recognition based on hidden Markov models by replacing the discrete symbol representation of the speech signal with a continuous Gaussian mixture density, thereby eliminating the inherent quantization error introduced by the discrete representation."
            },
            "venue": {
                "fragments": [],
                "text": "AT&T Technical Journal"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781290"
                        ],
                        "name": "H. Murveit",
                        "slug": "H.-Murveit",
                        "structuredName": {
                            "firstName": "Hy",
                            "lastName": "Murveit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murveit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786606"
                        ],
                        "name": "R. Brodersen",
                        "slug": "R.-Brodersen",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Brodersen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brodersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10142942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0978da7a46fd60c42278408b21fcde97992cbd",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A high-performance, flexible, and potentially inexpensive speech recognition system is described. The system is based on two special-purpose integrated circuits that perform the speech recognition algorithms very efficiently. One of these integrated circuits is the front-end processor, which computes spectral coefficients from incoming speech. The second integrated circuit computes a dynamic-time-warp algorithm. The system can compare an input word with 1000-word templates and respond to a user within \\frac{1}{4} s. The system demonstrates that computational complexity need not be a major limiting factor in the design of speech recognition systems."
            },
            "slug": "An-integrated-circuit-based-speech-recognition-Murveit-Brodersen",
            "title": {
                "fragments": [],
                "text": "An integrated-circuit-based speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A high-performance, flexible, and potentially inexpensive speech recognition system that can compare an input word with 1000-word templates and respond to a user within 1-4 s demonstrates that computational complexity need not be a major limiting factor in the design of speech recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145044772"
                        ],
                        "name": "D. Morgan",
                        "slug": "D.-Morgan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Morgan",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957320"
                        ],
                        "name": "C. Scofield",
                        "slug": "C.-Scofield",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Scofield",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Scofield"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59634353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b867f4307000de31d27a06b6b55fe458b8541963",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Speech processing is a unique discipline which encompasses a broad range and variety of technologies and applications. Many of these applications are not well known or are overshadowed by the intense interest in speech-to-text transcription, or automatic speech recognition. ASR research has a high profile because it will undoubtedly have the largest economic impact of all the speech technologies. Thus, there has been considerable funding for research in this area, and recently, much of this funding has been directed toward ANN implementations."
            },
            "slug": "Neural-networks-and-speech-processing-Morgan-Scofield",
            "title": {
                "fragments": [],
                "text": "Neural networks and speech processing"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Speech processing is a unique discipline which encompasses a broad range and variety of technologies and applications, and recently, much of this funding has been directed toward ANN implementations."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119573500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cca0e1afb4bc9a13bbadd84d4b79803db666c3cf",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A connected speech recognition method based on the Baum forward backward algorithm is presented. The segmentation of the test sentence uses the probability that an acoustic vector lays at the separation of two speech subunit models (Hidden Markov models). The labelling rests on the highest probability that a vector has been emitted on the last state of a subunit model. Results are presented for word- and phoneme-recognition."
            },
            "slug": "Global-connected-digit-recognition-using-Baum-Welch-Wellekens",
            "title": {
                "fragments": [],
                "text": "Global connected digit recognition using Baum-Welch algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A connected speech recognition method based on the Baum forward backward algorithm is presented that segmentation of the test sentence uses the probability that an acoustic vector lays at the separation of two speech subunit models."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189909"
                        ],
                        "name": "R. Beale",
                        "slug": "R.-Beale",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Beale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Beale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2504590"
                        ],
                        "name": "Thomas W. Jackson",
                        "slug": "Thomas-W.-Jackson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Jackson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas W. Jackson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60933208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b74902a4e8a30084a98905f1f4f85c9126d41af",
            "isKey": false,
            "numCitedBy": 912,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "INTRODUCTION Humans and computers The structure of the brain Learning in machines The differences Summary PATTERN RECOGNITION Introduction Pattern recognition in perspective Pattern recognition-a definition Feature vectors and feature space Discriminant functions Classification techniques Linear classifiers Statistical techniques Pattern recognition-a summary THE BASIC NEURON Introduction Modeling the single neuron Learning in simple neurons The perceptron: a vectorial perspective The perceptron learning rule: proof Limitations of perceptrons The end of the line? Summary THE MULTILAYER PERCEPTRON Introduction Altering the perceptron model The new model The new learning rule The multilayer perceptron algorithm The XOR problem revisited Visualizing network behavior Multilayer perceptrons as classifiers Generalization Fault tolerance Learning difficulties Radial basis functions Applications Summary KOHONEN SELF-ORGANIZING NETWORKS Introduction The Kohonen algorithm Weight training Neighborhoods Reducing the neighborhood Learning vector quantization (LVQ) The phonetic typewriter Summary HOPFIELD NETWORKS Introduction The Hopfield model The energy landscape The Boltzmann machine Constraint satisfaction Summary ADAPTIVE RESONANCE THEORY Introduction Adaptive resonance theory (ART) Architecture and operation ART algorithm Training the ART network Classification Conclusion Summary of ART ASSOCIATIVE MEMORY Standard computer memory Implementing associative memory Implementation in RAMs RAMs and N-tupling Willshaw's associative net The ADAM system Kanerva's sparse distributed memory Bidirectional associative memories Conclusion Summary INTO THE LOOKING GLASS Overview Hardware and software implementations Optical computing Optical computing and neural networks INDEX"
            },
            "slug": "Neural-Computing-An-Introduction-Beale-Jackson",
            "title": {
                "fragments": [],
                "text": "Neural Computing - An Introduction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356015"
                        ],
                        "name": "Marco Saerens",
                        "slug": "Marco-Saerens",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Saerens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Saerens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41460311,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eca42804cef760df65a43b6693817876163bea62",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-continuous-time-dynamic-formulation-of-Viterbi-Saerens",
            "title": {
                "fragments": [],
                "text": "A continuous-time dynamic formulation of Viterbi algorithm for one-Gaussian-per-state hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793645"
                        ],
                        "name": "H. Gish",
                        "slug": "H.-Gish",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Gish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gish"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123202935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c6be95e99e6d5538dfa362d18ac9b7e3ecce92a",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "It is shown that training a neural network using a mean-square-error criterion gives network outputs that approximate posterior class probabilities. Based on this probabilistic interpretation of the network operation, information-theoretic training criteria such as maximum mutual information and the Kullback-Liebler measure are investigated. It is shown that both of these criteria are equivalent to the maximum-likelihood estimation (MLE) of the network parameters. MLE of a network allows for the comparison of network models using the Akaike information criterion and the minimum-description length criterion.<<ETX>>"
            },
            "slug": "A-probabilistic-approach-to-the-understanding-and-Gish",
            "title": {
                "fragments": [],
                "text": "A probabilistic approach to the understanding and training of neural network classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "It is shown that training a neural network using a mean-square-error criterion gives network outputs that approximate posterior class probabilities and information-theoretic training criteria such as maximum mutual information and the Kullback-Liebler measure are investigated."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13699908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45099a4db6d8d71590ae37f6b629e40c5ac2c833",
            "isKey": false,
            "numCitedBy": 671,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The factors that make speech recognition difficult are examined, and the potential of neural computers for this purpose is discussed. A speaker-adaptive system that transcribes dictation using an unlimited vocabulary is presented that is based on a neural network processor for the recognition of phonetic units of speech. The acoustic preprocessing, vector quantization, neural network model, and shortcut learning algorithm used are described. The utilization of phonotopic maps and of postprocessing in symbolic forms are discussed. Hardware implementations and performance of the neural networks are considered.<<ETX>>"
            },
            "slug": "The-'neural'-phonetic-typewriter-Kohonen",
            "title": {
                "fragments": [],
                "text": "The 'neural' phonetic typewriter"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A speaker-adaptive system that transcribes dictation using an unlimited vocabulary is presented that is based on a neural network processor for the recognition of phonetic units of speech."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801257"
                        ],
                        "name": "A. Noll",
                        "slug": "A.-Noll",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Noll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Noll"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61023354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "280d0643b26a10ecc302d986514a154374a8fda4",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Deals with the use of continuous mixture densities for phenome modelling in large vocabulary continuous speech recognition. The concept of continuous mixture densities is applied to the emission probability density functions of hidden Markov models for phonemes in order to take into account phonetic-context dependencies. It is shown that the advantage of continuous mixture densities is the ability to lead to parameter estimates that are accurate and at the same time robust with respect to the limited amount of training data. Training and recognition algorithms for mixture densities in the framework of phoneme modelling are described. Recognition results for a 917-word task, requiring only 7 min of speech for training and an overlap of 43 words between training vocabulary and test vocabulary, are presented.<<ETX>>"
            },
            "slug": "Phoneme-modelling-using-continuous-mixture-Ney-Noll",
            "title": {
                "fragments": [],
                "text": "Phoneme modelling using continuous mixture densities"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that the advantage of continuous mixture densities is the ability to lead to parameter estimates that are accurate and at the same time robust with respect to the limited amount of training data."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861227"
                        ],
                        "name": "K. Iso",
                        "slug": "K.-Iso",
                        "structuredName": {
                            "firstName": "Ken-ichi",
                            "lastName": "Iso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Iso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110691850"
                        ],
                        "name": "Takao Watanabe",
                        "slug": "Takao-Watanabe",
                        "structuredName": {
                            "firstName": "Takao",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takao Watanabe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62041813,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "62b443e0c8d425646fb20da65c100485d3c8f03e",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present improvements in the neural prediction model. The improvements include the introduction of backward prediction in the pattern predictors and the modification of the prediction error measure with covariance matrices. Using the demisyllable as a subword recognition unit, speaker-dependent large vocabulary recognition experiments were carried out. Results indicate a 97.6% recognition accuracy for a 5000-word test set, and the effectiveness of the proposed model improvements and the demisyllable subword units was confirmed.<<ETX>>"
            },
            "slug": "Large-vocabulary-speech-recognition-using-neural-Iso-Watanabe",
            "title": {
                "fragments": [],
                "text": "Large vocabulary speech recognition using neural prediction model"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Improvements in the neural prediction model include the introduction of backward prediction in the pattern predictors and the modification of the prediction error measure with covariance matrices and the demisyllable subword units are presented."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681269"
                        ],
                        "name": "M. Fanty",
                        "slug": "M.-Fanty",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fanty",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fanty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428458"
                        ],
                        "name": "M. Gopalakrishnan",
                        "slug": "M.-Gopalakrishnan",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Gopalakrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gopalakrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144548377"
                        ],
                        "name": "R. Janssen",
                        "slug": "R.-Janssen",
                        "structuredName": {
                            "firstName": "R.D.T.",
                            "lastName": "Janssen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Janssen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62684696,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5486488352a6668815f1f933b2027a0fe4dac0a9",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A system that recognizes names spelled with pauses between letters using high quality speech is described. The system uses neural network classifiers to locate and classify letters, then searches a database of names to find the best match to the letter scores. The directory name retrieval system was evaluated on 1020 names provided by 34 speakers who were not used to train the system. Using a database of 50000 names, 972, or 95.3%, were correctly identified as the first choice. Of the remaining 48 names, all but 10 were in the top three choices. 99% of letters were correctly located, although speakers failed to pause completely about 10% of the time. Classification of individual spoken letters that were correctly located was 93%.<<ETX>>"
            },
            "slug": "Speaker-independent-name-retrieval-from-spellings-a-Cole-Fanty",
            "title": {
                "fragments": [],
                "text": "Speaker-independent name retrieval from spellings using a database of 50000 names"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A system that recognizes names spelled with pauses between letters using high quality speech using neural network classifiers to locate and classify letters, then searches a database of names to find the best match to the letter scores."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781290"
                        ],
                        "name": "H. Murveit",
                        "slug": "H.-Murveit",
                        "structuredName": {
                            "firstName": "Hy",
                            "lastName": "Murveit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murveit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35577831"
                        ],
                        "name": "J. Bernstein",
                        "slug": "J.-Bernstein",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60554400,
            "fieldsOfStudy": [
                "Physics",
                "Linguistics"
            ],
            "id": "573a1bb7a78c49c5ec23b1d2e36693db3dfe0f81",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A large-vocabulary, continuous-speech system, called DECIPHER, which is based on a hidden Markov model (HMM) approach and is designed to achieve high word accuracy in a speaker-independent mode is described. The results of a series of experiments that test acoustic and phonological adaptation of the DECIPHER system to the pronunciations of a single speaker in a speaker-dependent task are presented. Estimating the probabilities of alternative pronunciations and speaker-dependent phonology are discussed.<<ETX>>"
            },
            "slug": "The-decipher-speech-recognition-system-Cohen-Murveit",
            "title": {
                "fragments": [],
                "text": "The decipher speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A large-vocabulary, continuous-speech system, called DECIPHER, which is based on a hidden Markov model (HMM) approach and is designed to achieve high word accuracy in a speaker-independent mode is described and the probabilities of alternative pronunciations and speaker-dependent phonology are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153290394"
                        ],
                        "name": "K. Davis",
                        "slug": "K.-Davis",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102478527"
                        ],
                        "name": "R. Biddulph",
                        "slug": "R.-Biddulph",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Biddulph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Biddulph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102716575"
                        ],
                        "name": "S. Balashek",
                        "slug": "S.-Balashek",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Balashek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Balashek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121505424,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "00f62d4316c4612081f1ba2054a114e329f9e8c5",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognizer discussed will automatically recognize telephone\u2010quality digits spoken at normal speech rates by a single individual, with an accuracy varying between 97 and 99 percent. After some preliminary analysis of the speech of any individual, the circuit can be adjusted to deliver a similar accuracy on the speech of that individual. The circuit is not, however, in its present configuration, capable of performing equally well on the speech of a series of talkers without recourse to such adjustment.Circuitry involves division of the speech spectrum into two frequency bands, one below and the other above 900 cps. Axis\u2010crossing counts are then individually made of both band energies to determine the frequency of the maximum syllabic rate energy with each band. Simultaneous two\u2010dimensional frequency portrayal is found to possess recognition significance. Standards are then determined, one for each digit of the ten\u2010digit series, and are built into the recognizer as a form of elemental memory. By means of..."
            },
            "slug": "Automatic-Recognition-of-Spoken-Digits-Davis-Biddulph",
            "title": {
                "fragments": [],
                "text": "Automatic Recognition of Spoken Digits"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102981024"
                        ],
                        "name": "A. Poritz",
                        "slug": "A.-Poritz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Poritz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poritz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62479678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6627d8efde3ed55e34ccee059eb6cdac99bb2fe",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling is a probabilistic technique for the study of time series. Hidden Markov theory permits modeling with any of the classical probability distributions. The costs of implementation are linear in the length of data. Models can be nested to reflect hierarchical sources of knowledge. These and other desirable features have made hidden Markov methods increasingly attractive for problems in language, speech and signal processing. The basic ideas are introduced by elementary examples in the spirit of the Polya urn models. The main tool in hidden Markov modeling is the Baum-Welch (or forward-backward) algorithm for maximum likelihood estimation of the model parameters. This iterative algorithm is discussed both from an intuitive point of view as an exercise in the art of counting and from a formal point of view via the information-theoretic Q-function. Selected examples drawn from the literature illustrate how the Baum-Welch technique places a rich variety of computational models at the disposal of the researcher.<<ETX>>"
            },
            "slug": "Hidden-Markov-models:-a-guided-tour-Poritz",
            "title": {
                "fragments": [],
                "text": "Hidden Markov models: a guided tour"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main tool in hidden Markov modeling is the Baum-Welch algorithm for maximum likelihood estimation of the model parameters, which is discussed both from an intuitive point of view as an exercise in the art of counting and from a formalpoint of view via the information-theoretic Q-function."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16642315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e4193d03eb3c5a695a3d8b3506f80704f9dfc19",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is of tutorial nature and describes a one-stage dynamic programming algorithm for file problem of connected word recognition. The algorithm to be developed is essentially identical to one presented by Vintsyuk [1] and later by Bridle and Brown [2] ; but the notation and the presentation have been clarified. The derivation used for optimally time synchronizing a test pattern, consisting of a sequence of connected words, is straightforward and simple in comparison with other approaches decomposing the pattern matching problem into several levels. The approach presented relies basically on parameterizing the time warping path by a single index and on exploiting certain path constraints both in the word interior and at the word boundaries. The resulting algorithm turns out to be significantly more efficient than those proposed by Sakoe [3] as well as Myers and Rabiner [4], while providing the same accuracy in estimating the best possible matching string. Its most important feature is that the computational expenditure per word is independent of the number of words in the input string. Thus, it is well suited for recognizing comparatively long word sequences and for real-time operation. Furthermore, there is no need to specify the maximum number of words in the input string. The practical implementation of the algorithm is discussed; it requires no heuristic rules and no overhead. The algorithm can be modified to deal with syntactic constraints in terms of a finite state syntax."
            },
            "slug": "The-use-of-a-one-stage-dynamic-programming-for-word-Ney",
            "title": {
                "fragments": [],
                "text": "The use of a one-stage dynamic programming algorithm for connected word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The algorithm to be developed is essentially identical to one presented by Vintsyuk and later by Bridle and Brown, but the notation and the presentation have been clarified and the computational expenditure per word is independent of the number of words in the input string."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403852834"
                        ],
                        "name": "S. Makram-Ebeid",
                        "slug": "S.-Makram-Ebeid",
                        "structuredName": {
                            "firstName": "Sh\u00e9rif",
                            "lastName": "Makram-Ebeid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Makram-Ebeid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144515983"
                        ],
                        "name": "J. Sirat",
                        "slug": "J.-Sirat",
                        "structuredName": {
                            "firstName": "Jacques-Ariel",
                            "lastName": "Sirat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sirat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91994182"
                        ],
                        "name": "J. Viala",
                        "slug": "J.-Viala",
                        "structuredName": {
                            "firstName": "Jean-Renaud",
                            "lastName": "Viala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Viala"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13368740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a627e7af91aeed04179b75d16dcc45e86c6bcffc",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is proposed for learning in multilayer perceptrons. It includes self-adapting features that make it suited to deal with a variety of problems without the need for parameter readjustments. The validity of the approach is benchmarked for two types of problems. The first benchmark is performed for the topologically complex parity problem. The number of binary inputs range from, 2 (simplest Exclusive OR problem) to 7 (much more complex problem). The statistically averaged learning times obtained, which are reduced by two to three orders of magnitude, are compared with the best possible results obtained by conventional error backpropagation (EBP). The second problem type occurs when a high accuracy in separating example classes is needed. This corresponds to instances where different output sign patterns of the MLP are requested for slightly different input variables. When the minimum Euclidean distance epsilon between the classes to be separated decreases, the best learning times obtained with conventional EBP increase roughly as I/ epsilon /sup 2/. The present algorithm yields substantially shorter learning times that behave like log (1/ epsilon ).<<ETX>>"
            },
            "slug": "A-rationalized-error-back-propagation-learning-Makram-Ebeid-Sirat",
            "title": {
                "fragments": [],
                "text": "A rationalized error back-propagation learning algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A method is proposed for learning in multilayer perceptrons that includes self-adapting features that make it suited to deal with a variety of problems without the need for parameter readjustments and yields substantially shorter learning times."
            },
            "venue": {
                "fragments": [],
                "text": "International 1989 Joint Conference on Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144823960"
                        ],
                        "name": "J. Deller",
                        "slug": "J.-Deller",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Deller",
                            "middleNames": [
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991940"
                        ],
                        "name": "J. Proakis",
                        "slug": "J.-Proakis",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Proakis",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Proakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144270764"
                        ],
                        "name": "J. Hansen",
                        "slug": "J.-Hansen",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hansen",
                            "middleNames": [
                                "H.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hansen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60886106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cd904d6f31b4f4abf79c67729c1c99c3245f895",
            "isKey": false,
            "numCitedBy": 2742,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the IEEE Edition. Preface. Acronyms and Abbreviations. SIGNAL PROCESSING BACKGROUND. Propaedeutic. SPEECH PRODUCTION AND MODELLING. Fundamentals of Speech Science. Modeling Speech Production. ANALYSIS TECHNIQUES. Short--Term Processing of Speech. Linear Prediction Analysis. Cepstral Analysis. CODING, ENHANCEMENT AND QUALITY ASSESSMENT. Speech Coding and Synthesis. Speech Enhancement. Speech Quality Assessment. RECOGNITION. The Speech Recognition Problem. Dynamic Time Warping. The Hidden Markov Model. Language Modeling. The Artificial Neural Network. Index."
            },
            "slug": "Discrete-Time-Processing-of-Speech-Signals-Deller-Proakis",
            "title": {
                "fragments": [],
                "text": "Discrete-Time Processing of Speech Signals"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The preface to the IEEE Edition explains the background to speech production, coding, and quality assessment and introduces the Hidden Markov Model, the Artificial Neural Network, and Speech Enhancement."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50305884"
                        ],
                        "name": "B. Hanson",
                        "slug": "B.-Hanson",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Hanson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2873368"
                        ],
                        "name": "T. H. Applebaum",
                        "slug": "T.-H.-Applebaum",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Applebaum",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. H. Applebaum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62605988,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c321ffef4aa244a456edd5817dd6acd7c91cf644",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Speaker-independent recognition of Lombard and noisy speech by a recognizer trained with normal speech is discussed. Speech was represented by static, dynamic (first difference), and acceleration (second difference) features. Strong interaction was found between these temporal features, the frequency differentiation due to cepstral weighting, and the degree of smoothing in the spectral analysis. When combined with the other features, acceleration raised recognition rates for Lombard or noisy input speech. Dynamic and acceleration features were found to perform much better than the static feature for noisy Lombard speech. This suggests that an algorithm which excludes the static feature in high ambient noise is desirable.<<ETX>>"
            },
            "slug": "Robust-speaker-independent-word-recognition-using-Hanson-Applebaum",
            "title": {
                "fragments": [],
                "text": "Robust speaker-independent word recognition using static, dynamic and acceleration features: experiments with Lombard and noisy speech"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Speaker-independent recognition of Lombard and noisy speech by a recognizer trained with normal speech is discussed, and dynamic and acceleration features were found to perform much better than the static feature for noisy Lombard speech."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18821787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f3175b3930d0c71495a52a7bccb3889e5f33520",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We have done an empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization performance. Two experiments are reported. In one, we use simulated data sets with well-controlled parameters, such as the signal-to-noise ratio of continuous-valued data. In the second, we train the network on vector-quantized mel cepstra from real speech samples. In each case, we use back-propagation to train the feedforward net to discriminate in a multiple class pattern classification problem. We report the results of these studies, and show the application of cross-validation techniques to prevent overfitting."
            },
            "slug": "Generalization-and-Parameter-Estimation-in-Netws:-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Generalization and Parameter Estimation in Feedforward Netws: Some Experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An empirical study of the relation of the number of parameters (weights) in a feedforward net to generalization performance and the application of cross-validation techniques to prevent overfitting is done."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681269"
                        ],
                        "name": "M. Fanty",
                        "slug": "M.-Fanty",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fanty",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fanty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2243174,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "93dd13fe015294569b0f50a358413daeb59e988a",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic recognition of spoken letters is one of the most challenging tasks in the field of computer speech recognition. The difficulty of the task is due to the acoustic similarity of many of the letters. Accurate recognition requires the system to perform fine phonetic distinctions, such as B vs. D, B vs. P, D vs. T, T vs. G, C vs. Z, V vs. Z, M vs. N and J vs. K. The ability to perform fine phonetic distinctions---to discriminate among the minimal sound units of the language---is a fundamental unsolved problem in computer speech recognition."
            },
            "slug": "Spoken-Letter-Recognition-Cole-Fanty",
            "title": {
                "fragments": [],
                "text": "Spoken Letter Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents an attempt to solve the fundamental unsolved problem of automatic recognition of spoken letters, which requires the system to perform fine phonetic distinctions among the minimal sound units of the language."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1234937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e08d090d1e586610d636a46004876e9f3ded8209",
            "isKey": false,
            "numCitedBy": 640,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-time-delay-neural-network-architecture-for-word-Lang-Waibel",
            "title": {
                "fragments": [],
                "text": "A time-delay neural network architecture for isolated word recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61239657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22ac813753d5ccaec7ef39c1e46adee4aa22c8f7",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The Lincoln stress-resistant HMM (hidden Markov model) CSR has been extended to large-vocabulary continuous speech for both speaker-dependent (SD) and speaker-independent (SI) tasks. Performance on the DARPA resource management task (991-word vocabulary, perplexity 60 word-pair grammar) is 3.5% word error rate for SD training of word-context-dependent triphone models and 12.6% word error rate for SI training of (word-context-free) tied-mixture triphone models.<<ETX>>"
            },
            "slug": "The-Lincoln-robust-continuous-speech-recognizer-Paul",
            "title": {
                "fragments": [],
                "text": "The Lincoln robust continuous speech recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Lincoln stress-resistant HMM (hidden Markov model) CSR has been extended to large-vocabulary continuous speech for both speaker-dependent (SD) and speaker-independent (SI) tasks."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781290"
                        ],
                        "name": "H. Murveit",
                        "slug": "H.-Murveit",
                        "structuredName": {
                            "firstName": "Hy",
                            "lastName": "Murveit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murveit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143428311"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48258694"
                        ],
                        "name": "P. Price",
                        "slug": "P.-Price",
                        "structuredName": {
                            "firstName": "Patti",
                            "lastName": "Price",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Price"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072624667"
                        ],
                        "name": "G. Baldwin",
                        "slug": "G.-Baldwin",
                        "structuredName": {
                            "firstName": "Gay",
                            "lastName": "Baldwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Baldwin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744182"
                        ],
                        "name": "M. Weintraub",
                        "slug": "M.-Weintraub",
                        "structuredName": {
                            "firstName": "Mitch",
                            "lastName": "Weintraub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weintraub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35577831"
                        ],
                        "name": "J. Bernstein",
                        "slug": "J.-Bernstein",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bernstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15606320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "184555767c3b586b2548ae0b7da67e6bfd4365b1",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "SRI has developed a speaker-independent continuous speech, large vocabulary speech recognition system, DECIPHER, that provides state-of-the-art performance on the DARPA standard speaker-independent resource management training and testing materials. SRI's approach is to integrate speech and linguistic knowledge into the HMM framework. This paper describes performance improvements arising from detailed phonological modeling and from the incorporation of cross-word coarticulatory constraints."
            },
            "slug": "SRI\u2019s-DECIPHER-System-Murveit-Cohen",
            "title": {
                "fragments": [],
                "text": "SRI\u2019s DECIPHER System"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Performance improvements arising from detailed phonological modeling and from the incorporation of cross-word coarticulatory constraints are described."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57931704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcdb9bd64e3d7885c10938291153257b94f3df91",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMotivated by the remarkable fluidity of memory the way in which items are pulled spontaneously and effortlessly from our memory by vague similarities to what is currently occupying our attention Sparse Distributed Memory presents a mathematically elegant theory of human long term memory. \nThe book, which is self contained, begins with background material from mathematics, computers, and neurophysiology; this is followed by a step by step development of the memory model. The concluding chapter describes an autonomous system that builds from experience an internal model of the world and bases its operation on that internal model. Close attention is paid to the engineering of the memory, including comparisons to ordinary computer memories. \nSparse Distributed Memory provides an overall perspective on neural systems. The model it describes can aid in understanding human memory and learning, and a system based on it sheds light on outstanding problems in philosophy and artificial intelligence. Applications of the memory are expected to be found in the creation of adaptive systems for signal processing, speech, vision, motor control, and (in general) robots. Perhaps the most exciting aspect of the memory, in its implications for research in neural networks, is that its realization with neuronlike components resembles the cortex of the cerebellum. \nPentti Kanerva is a scientist at the Research Institute for Advanced Computer Science at the NASA Ames Research Center and a visiting scholar at the Stanford Center for the Study of Language and Information. A Bradford Book."
            },
            "slug": "Sparse-Distributed-Memory-Kanerva",
            "title": {
                "fragments": [],
                "text": "Sparse Distributed Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Pentti Kanerva's Sparse Distributed Memory presents a mathematically elegant theory of human long term memory that resembles the cortex of the cerebellum, and provides an overall perspective on neural systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2537431"
                        ],
                        "name": "Axel Cleeremans",
                        "slug": "Axel-Cleeremans",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Cleeremans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Axel Cleeremans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403615640"
                        ],
                        "name": "D. Servan-Schreiber",
                        "slug": "D.-Servan-Schreiber",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Servan-Schreiber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Servan-Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701656"
                        ],
                        "name": "James L. McClelland",
                        "slug": "James-L.-McClelland",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "McClelland",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James L. McClelland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7741931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd46c1b5948abe04e565a8bae6454da63a1b021e",
            "isKey": false,
            "numCitedBy": 513,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore a network architecture introduced by Elman (1988) for predicting successive elements of a sequence. The network uses the pattern of activation over a set of hidden units from time-step t1, together with element t, to predict element t 1. When the network is trained with strings from a particular finite-state grammar, it can learn to be a perfect finite-state recognizer for the grammar. When the network has a minimal number of hidden units, patterns on the hidden units come to correspond to the nodes of the grammar, although this correspondence is not necessary for the network to act as a perfect finite-state recognizer. We explore the conditions under which the network can carry information about distant sequential contingencies across intervening elements. Such information is maintained with relative ease if it is relevant at each intermediate step; it tends to be lost when intervening elements do not depend on it. At first glance this may suggest that such networks are not relevant to natural language, in which dependencies may span indefinite distances. However, embeddings in natural language are not completely independent of earlier information. The final simulation shows that long distance sequential contingencies can be encoded by the network even if only subtle statistical properties of embedded strings depend on the early information."
            },
            "slug": "Finite-State-Automata-and-Simple-Recurrent-Networks-Cleeremans-Servan-Schreiber",
            "title": {
                "fragments": [],
                "text": "Finite State Automata and Simple Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A network architecture introduced by Elman (1988) for predicting successive elements of a sequence and shows that long distance sequential contingencies can be encoded by the network even if only subtle statistical properties of embedded strings depend on the early information."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1822055"
                        ],
                        "name": "Raymond L. Watrous",
                        "slug": "Raymond-L.-Watrous",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Watrous",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raymond L. Watrous"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15329984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "934e49dac717a924bfda841bf6e54c32e900f0d1",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of learning using connectionist networks, in which network connection strengths are modified systematically so that the response of the network increasingly approximates the desired response can be structured as an optimization problem. The widely used back propagation method of connectionist learning [19, 21, 18] is set in the context of nonlinear optimization. In this framework, the issues of stability, convergence and parallelism are considered. As a form of gradient descent with fixed step size, back propagation is known to be unstable, which is illustrated using Rosenbrock's function. This is contrasted with stable methods which involve a line search in the gradient direction. The convergence criterion for connectionist problems involving binary functions is discussed relative to the behavior of gradient descent in the vicinity of local minima. A minimax criterion is compared with the least squares criterion. The contribution of the momentum term [19, 18] to more rapid convergence is interpreted relative to the geometry of the weight space. It is shown that in plateau regions of relatively constant gradient, the momentum term acts to increase the step size by a factor of 1/1-\u03bc, where \u03bc is the momentum term. In valley regions with steep sides, the momentum constant acts to focus the search direction toward the local minimum by averaging oscillations in the gradient. Comments University of Pennsylvania Department of Computer and Information Science Technical Report No. MSCIS-88-62. This technical report is available at ScholarlyCommons: http://repository.upenn.edu/cis_reports/597 LEARNING ALGORITHMS FOR CONNECTIONIST NETWORKS: APPLIED GRADIENT METHODS OF NONLINEAR OPTIMIZATION"
            },
            "slug": "Learning-Algorithms-for-Connectionist-Networks:-of-Watrous",
            "title": {
                "fragments": [],
                "text": "Learning Algorithms for Connectionist Networks: Applied Gradient Methods of Nonlinear Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that in plateau regions of relatively constant gradient, the momentum term acts to increase the step size by a factor of 1/1-\u03bc, where \u03bc is the momentumTerm, and in valley regions with steep sides,The momentum constant acts to focus the search direction toward the local minimum by averaging oscillations in the gradient."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086268"
                        ],
                        "name": "F. Failside",
                        "slug": "F.-Failside",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Failside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Failside"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10802530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b247fe6efc9e1011555428647f390dd98bdd3446",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Error propagation nets have been shown to be able to learn a variety of tasks in which a static input pattern is mapped onto a static output pattern. This paper presents a generalisation of these nets to deal with time varying, or dynamic patterns, and three possible architectures are explored. As an example, dynamic nets are applied to the problem of speech coding, in which a time sequence of speech data are coded by one net and decoded by another. The use of dynamic nets gives a better signal to noise ratio than that achieved using static nets."
            },
            "slug": "Static-and-Dynamic-Error-Propagation-Networks-with-Robinson-Failside",
            "title": {
                "fragments": [],
                "text": "Static and Dynamic Error Propagation Networks with Application to Speech Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a generalisation of error propagation nets to deal with time varying, or dynamic patterns, and three possible architectures are explored."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49819964"
                        ],
                        "name": "M. Richard",
                        "slug": "M.-Richard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Richard",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Richard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990248"
                        ],
                        "name": "R. Lippmann",
                        "slug": "R.-Lippmann",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lippmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lippmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37584437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a6d820385527df2183a36ae1615f426ba894c5d",
            "isKey": false,
            "numCitedBy": 1166,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Many neural network classifiers provide outputs which estimate Bayesian a posteriori probabilities. When the estimation is accurate, network outputs can be treated as probabilities and sum to one. Simple proofs show that Bayesian probabilities are estimated when desired network outputs are 1 of M (one output unity, all others zero) and a squared-error or cross-entropy cost function is used. Results of Monte Carlo simulations performed using multilayer perceptron (MLP) networks trained with backpropagation, radial basis function (RBF) networks, and high-order polynomial networks graphically demonstrate that network outputs provide good estimates of Bayesian probabilities. Estimation accuracy depends on network complexity, the amount of training data, and the degree to which training data reflect true likelihood distributions and a priori class probabilities. Interpretation of network outputs as Bayesian probabilities allows outputs from multiple networks to be combined for higher level decision making, simplifies creation of rejection thresholds, makes it possible to compensate for differences between pattern class probabilities in training and test data, allows outputs to be used to minimize alternative risk functions, and suggests alternative measures of network performance."
            },
            "slug": "Neural-Network-Classifiers-Estimate-Bayesian-a-Richard-Lippmann",
            "title": {
                "fragments": [],
                "text": "Neural Network Classifiers Estimate Bayesian a posteriori Probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Results of Monte Carlo simulations performed using multilayer perceptron (MLP) networks trained with backpropagation, radial basis function (RBF) networks, and high-order polynomial networks graphically demonstrate that network outputs provide good estimates of Bayesian probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36366900,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "17423cc37eee7423423c03624f4a637b191eb998",
            "isKey": false,
            "numCitedBy": 4120,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper gives an exposition of linear prediction in the analysis of discrete signals. The signal is modeled as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal. In the frequency domain, this is equivalent to modeling the signal spectrum by a pole-zero spectrum. The major part of the paper is devoted to all-pole models. The model parameters are obtained by a least squares analysis in the time domain. Two methods result, depending on whether the signal is assumed to be stationary or nonstationary. The same results are then derived in the frequency domain. The resulting spectral matching formulation allows for the modeling of selected portions of a spectrum, for arbitrary spectral shaping in the frequency domain, and for the modeling of continuous as well as discrete spectra. This also leads to a discussion of the advantages and disadvantages of the least squares error criterion. A spectral interpretation is given to the normalized minimum prediction error. Applications of the normalized error are given, including the determination of an \"optimal\" number of poles. The use of linear prediction in data compression is reviewed. For purposes of transmission, particular attention is given to the quantization and encoding of the reflection (or partial correlation) coefficients. Finally, a brief introduction to pole-zero modeling is given."
            },
            "slug": "Linear-prediction:-A-tutorial-review-Makhoul",
            "title": {
                "fragments": [],
                "text": "Linear prediction: A tutorial review"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This paper gives an exposition of linear prediction in the analysis of discrete signals as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47218730"
                        ],
                        "name": "B. Townshend",
                        "slug": "B.-Townshend",
                        "structuredName": {
                            "firstName": "Brent",
                            "lastName": "Townshend",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Townshend"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121761594,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "db4716d89bb0a39bf6eebfa0abcf833e26bd1ea4",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Measurements were made of the correlation dimension of normally spoken speech from a single speaker, and the results reveal that most of the points in the state space of the signal lie very close to a manifold of a dimensionality of less than three. This result indicates that one should be able to construct a nonlinear predictor for speech that significantly outperforms linear predictors. To validate this conclusion, a nonparametric predictor was constructed which was able to produce a prediction gain approximately 3 dB better than an equivalent linear predictor. Similar improvements in signal-to-noise ratio were also observed when the nonlinear predictor was added to a simple speech coder.<<ETX>>"
            },
            "slug": "Nonlinear-prediction-of-speech-Townshend",
            "title": {
                "fragments": [],
                "text": "Nonlinear prediction of speech"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Measurements were made of the correlation dimension of normally spoken speech from a single speaker, and the results reveal that most of the points in the state space of the signal lie very close to a manifold of a dimensionality of less than three, indicating that one should be able to construct a nonlinear predictor for speech that significantly outperforms linear predictors."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3140752"
                        ],
                        "name": "Charles R. Rosenberg",
                        "slug": "Charles-R.-Rosenberg",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Rosenberg",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles R. Rosenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13921532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "406033f22b6a671b94bcbdfaf63070b7ce6f3e48",
            "isKey": false,
            "numCitedBy": 761,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Unrestricted English text can be converted to speech by applying phonological rules and handling exceptions with a look-up table. However, this approach is highly labor intensive since each entry and rule must be hand-crafted. NETtalk is an alternative approach that is based on an automated learning procedure for a parallel network of deterministic processing units. ~ f t e r ' training on a corpus of informal continuous speech, it achieves good performance and generalizes to novel words. The distributed internal representations of the phonological regularities discovered by the network are damage resistant."
            },
            "slug": "NETtalk:-a-parallel-network-that-learns-to-read-Sejnowski-Rosenberg",
            "title": {
                "fragments": [],
                "text": "NETtalk: a parallel network that learns to read aloud"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "NETtalk is an alternative approach that is based on an automated learning procedure for a parallel network of deterministic processing units that achieves good performance and generalizes to novel words."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7840452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a57c6d627ffc667ae3547073876c35d6420accff",
            "isKey": false,
            "numCitedBy": 1574,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-Learning-Procedures-Hinton",
            "title": {
                "fragments": [],
                "text": "Connectionist Learning Procedures"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144091892"
                        ],
                        "name": "M. Hwang",
                        "slug": "M.-Hwang",
                        "structuredName": {
                            "firstName": "Mei-Yuh",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34413227"
                        ],
                        "name": "Sanjoy Mahajan",
                        "slug": "Sanjoy-Mahajan",
                        "structuredName": {
                            "firstName": "Sanjoy",
                            "lastName": "Mahajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjoy Mahajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502114"
                        ],
                        "name": "R. Reddy",
                        "slug": "R.-Reddy",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Reddy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Reddy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60888798,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "b32ee423671b727523a0dfdfea039e7a7fca36b8",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A description is given of SPHINX an accurate large-vocabulary speaker-independent continuous speech recognition system. The authors have made several recent enhancements, including generalized triphone models, word duration modeling, function-phrase modeling, between-word coarticulation modeling, and corrective training. On the 997-word resource management task, SPHINX attained a word accuracy of 96% with a grammar (perplexity 60), and 82% without grammar (perplexity 997).<<ETX>>"
            },
            "slug": "The-SPHINX-speech-recognition-system-Lee-Hon",
            "title": {
                "fragments": [],
                "text": "The SPHINX speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A description is given of SPHINX an accurate large-vocabulary speaker-independent continuous speech recognition system that attained a word accuracy of 96% with a grammar, and 82% without grammar on the 997-word resource management task."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing,"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62710001,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9b486c647916df9f8be0f8d4fc5c94c493bfaa80",
            "isKey": false,
            "numCitedBy": 1889,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Part I attempts to review the background, basic sources of data, concepts, and methodology to be employed in the study of perceptrons. In Chapter 2, a brief review of the main alternative approaches to the development of brain models is presented. Chapter 3 considers the physiological and psychological criteria for a suitable model, and attempts to evaluate the empirical evidence which is available on several important issues. Chapter 4 contains basic definitions and some of the notation to be used in later sections are presented. Parts II and III are devoted to a summary of the established theoretical results obtained to date. Part II (Chapters 5 through 14) deals with the theory of three-layer series-coupled perceptrons, on which most work has been done to date. Part III (Chapters 15 through 20) deals with the theory of multi-layer and cross-coupled perceptrons. Part IV is concerned with more speculative models and problems for future analysis. Of necessity, the final chapters become increasingly heuristic in character, as the theory of perceptrons is not yet complete, and new possibilities are continually coming to light."
            },
            "slug": "PRINCIPLES-OF-NEURODYNAMICS.-PERCEPTRONS-AND-THE-OF-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "PRINCIPLES OF NEURODYNAMICS. PERCEPTRONS AND THE THEORY OF BRAIN MECHANISMS"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The background, basic sources of data, concepts, and methodology to be employed in the study of perceptrons are reviewed, and some of the notation to be used in later sections are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60666828,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "424710825d726e10b016204ed2bc979e2a342d10",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The real-time recurrent learning algorithm is a gradient-following learning algorithm for completely recurrent networks running in continually sampled time. Here we use a series of simulation experiments to investigate the power and properties of this algorithm. In the recurrent networks studied here, any unit can be connected to any other, and any unit can receive external input. These networks run continually in the sense that they sample their inputs on every update cycle, and any unit can have a training target on any cycle. The storage required and computation time on each step are independent of time and are completely determined by the size of the network, so no prior knowledge of the temporal structure of the task being learned is required. The algorithm is nonlocal in the sense that each unit must have knowledge of the complete recurrent weight matrix and error vector. The algorithm is computationally intensive in sequential computers, requiring a storage capacity of the order of the thi..."
            },
            "slug": "Experimental-Analysis-of-the-Real-time-Recurrent-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "Experimental Analysis of the Real-time Recurrent Learning Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A series of simulation experiments are used to investigate the power and properties of the real-time recurrent learning algorithm, a gradient-following learning algorithm for completely recurrent networks running in continually sampled time."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62359231,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f1277592f221ea26fa1d2321a38b64c58b33d75b",
            "isKey": false,
            "numCitedBy": 8011,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This completely revised second edition presents an introduction to statistical pattern recognition. Pattern recognition in general covers a wide range of problems: it is applied to engineering problems, such as character readers and wave form analysis as well as to brain modeling in biology and psychology. Statistical decision and estimation, which are the main subjects of this book, are regarded as fundamental to the study of pattern recognition. This book is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field. Each chapter contains computer projects as well as exercises."
            },
            "slug": "Introduction-to-Statistical-Pattern-Recognition-Fukunaga",
            "title": {
                "fragments": [],
                "text": "Introduction to Statistical Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This completely revised second edition presents an introduction to statistical pattern recognition, which is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9858,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10158697,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "21e82ed12c620fba1f5ee42162962aae74a23510",
            "isKey": false,
            "numCitedBy": 4063,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In the paper \"Approximation by Superpositions of a SigmoidaI Function\" [C], the proof given for Lemma i is incorrect since it relies on the erroneous statement that simple functions are dense in L=(R). The author has pointed out that the proof in I'C] can be corrected by changing, at the bottom of page 307 and the top of page 308, the occurrences of L~(R) to L=(J) for a compact interval, J, containing {yrx lx ~ I,}, where y is fLxed. It should also be noted that the reduction of multidimensional density to one-dimensional density as in the proof of Lemma 1 had previously been obtained by Dahmen and Micchelli, using the same techniques, in work on ridge regression (see Lemma 3.2 of [DM]). We thank Raymond T, Melton, who pointed out the error in the proof of Lemma 1 in [C] and supplied a proof, showing that the Fourier transform of the measure /~ must be zero because the/~-measure of every half-plane is zero [M]."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The reduction of multidimensional density to one-dimensional density as in the proof of Lemma 1 had previously been obtained by Dahmen and Micchelli, using the same techniques, in work on ridge regression."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56128297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f09ce0dd760857e0d0e4879f6e2543f04c5d33",
            "isKey": false,
            "numCitedBy": 926,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for estimating the parameters of hidden Markov models of speech is described. Parameter values are chosen to maximize the mutual information between an acoustic observation sequence and the corresponding word sequence. Recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "slug": "Maximum-mutual-information-estimation-of-hidden-for-Bahl-Brown",
            "title": {
                "fragments": [],
                "text": "Maximum mutual information estimation of hidden Markov model parameters for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A method for estimating the parameters of hidden Markov models of speech is described and recognition results are presented comparing this method with maximum likelihood estimation."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144902513"
                        ],
                        "name": "P. Baldi",
                        "slug": "P.-Baldi",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Baldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14333248,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9552ac39a57daacf3d75865a268935b5a0df9bbb",
            "isKey": false,
            "numCitedBy": 1336,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-networks-and-principal-component-analysis:-Baldi-Hornik",
            "title": {
                "fragments": [],
                "text": "Neural networks and principal component analysis: Learning from examples without local minima"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 411526,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50a42ed2f81b9fe150883a6c89194c88a9647106",
            "isKey": false,
            "numCitedBy": 42028,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples."
            },
            "slug": "A-new-look-at-the-statistical-model-identification-Akaike",
            "title": {
                "fragments": [],
                "text": "A new look at the statistical model identification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402969335"
                        ],
                        "name": "A. El-Jaroudi",
                        "slug": "A.-El-Jaroudi",
                        "structuredName": {
                            "firstName": "Amro",
                            "lastName": "El-Jaroudi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. El-Jaroudi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40598043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adf81acbfb348c7ebacb97858beb3d193766bb2a",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors introduce an error criterion for training which improves the performance of neural nets as posterior probability estimators, as compared to using least squares. The proposed criterion is similar to the Kullback-Leibler information measure and is simple to use. A straightforward iterative algorithm for the minimization of the error criterion which has been shown to have good convergence properties is described. The authors applied the proposed technique to some classification examples and showed it to produce better posterior probability estimates than least squares, especially for low probabilities"
            },
            "slug": "A-new-error-criterion-for-posterior-probability-El-Jaroudi-Makhoul",
            "title": {
                "fragments": [],
                "text": "A new error criterion for posterior probability estimation with neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "An error criterion for training is introduced which improves the performance of neural nets as posterior probability estimators, as compared to using least squares, and is similar to the Kullback-Leibler information measure."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61904772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c180f387357d9302a558bcd643209831744c639b",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities."
            },
            "slug": "The-DRAGON-system--An-overview-Baker",
            "title": {
                "fragments": [],
                "text": "The DRAGON system--An overview"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper briefly describes the major features of the DRAGON speech understanding system, which makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2403454"
                        ],
                        "name": "E. Baum",
                        "slug": "E.-Baum",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Baum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15659829,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "25406e6733a698bfc4ac836f8e74f458e75dad4f",
            "isKey": false,
            "numCitedBy": 1696,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the question of when a network can be expected to generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples are drawn from the same distribution. Among our results are the following bounds on appropriate sample vs. network size. Assume 0 < \u220a 1/8. We show that if m O(W/\u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 1 \u220a of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with one hidden layer, any learning algorithm using fewer than (W/\u220a) random training examples will, for some distributions of examples consistent with an appropriate weight choice, fail at least some fixed fraction of the time to find a weight choice that will correctly classify more than a 1 \u220a fraction of the future test examples."
            },
            "slug": "What-Size-Net-Gives-Valid-Generalization-Baum-Haussler",
            "title": {
                "fragments": [],
                "text": "What Size Net Gives Valid Generalization?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that if m O(W/ \u220a log N/\u220a) random examples can be loaded on a feedforward network of linear threshold functions with N nodes and W weights, so that at least a fraction 1 \u220a/2 of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify a fraction 2 \u220a of future test examples drawn from the same distribution."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34915378"
                        ],
                        "name": "R. Rohwer",
                        "slug": "R.-Rohwer",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rohwer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rohwer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 736183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af7802a50a8c294ebfd539ad72158475e5ecd9f2",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple method for training the dynamical behavior of a neural network is derived. It is applicable to any training problem in discrete-time networks with arbitrary feedback. The algorithm resembles back-propagation in that an error function is minimized using a gradient-based method, but the optimization is carried out in the hidden part of state space either instead of, or in addition to weight space. Computational results are presented for some simple dynamical training problems, one of which requires response to a signal 100 time steps in the past."
            },
            "slug": "The-\"Moving-Targets\"-Training-Algorithm-Rohwer",
            "title": {
                "fragments": [],
                "text": "The \"Moving Targets\" Training Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A simple method for training the dynamical behavior of a neural network using a gradient-based method and the optimization is carried out in the hidden part of state space either instead of, or in addition to weight space."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31220579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1339348aeef592802288d9d929a085cb3ae61c4b",
            "isKey": false,
            "numCitedBy": 451,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes error-correction adjustment procedures for determining the weight vector of linear pattern classifiers under general pattern distribution. It is mainly aimed at clarifying theoretically the performance of adaptive pattern classifiers. In the case where the loss depends on the distance between a pattern vector and a decision boundary and where the average risk function is unimodal, it is proved that, by the procedures proposed here, the weight vector converges to the optimal one even under nonseparable pattern distributions. The speed and the accuracy of convergence are analyzed, and it is shown that there is an important tradeoff between speed and accuracy of convergence. Dynamical behaviors, when the probability distributions of patterns are changing, are also shown. The theory is generalized and made applicable to the case with general discriminant functions, including piecewise-linear discriminant functions."
            },
            "slug": "A-Theory-of-Adaptive-Pattern-Classifiers-Amari",
            "title": {
                "fragments": [],
                "text": "A Theory of Adaptive Pattern Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "It is proved that, by the procedures proposed here, the weight vector converges to the optimal one even under nonseparable pattern distributions, and there is an important tradeoff between speed and accuracy of convergence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Electron. Comput."
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145145320"
                        ],
                        "name": "J. Beck",
                        "slug": "J.-Beck",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Beck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143869759"
                        ],
                        "name": "P. Kohn",
                        "slug": "P.-Kohn",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Kohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748118"
                        ],
                        "name": "J. Bilmes",
                        "slug": "J.-Bilmes",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Bilmes",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bilmes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143657504"
                        ],
                        "name": "E. Allman",
                        "slug": "E.-Allman",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Allman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Allman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153308817"
                        ],
                        "name": "J. Beer",
                        "slug": "J.-Beer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Beer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61533625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a960153ad93d1f831c3d7caf1b6b13aa801008c2",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors have designed and implemented a ring array processor, RAP, for fast implementation of layered neural network algorithms. The RAP is a multi-DSP system targeted at continuous speech recognition using connectionist algorithms. Four boards, each with four Texas Instruments, TMS 320C30 DSPs, serve as an array processor for a 68020-based host running a real-time operating system. The overall system is controlled from a Sun workstation via the Ethernet. Each board includes 16 MB of dynamic memory (expandable to 64 MB) and 1 MB of fast static RAM. Theoretical peak performance is 128 MFLOPS/board, and test runs with the first working board show a sustained throughput of roughly one-third to one-half of this for algorithms of interest. Software development is aided by a Sun workstation-based command interpreter, tools from the standard C environment and a library of matrix and vector routines.<<ETX>>"
            },
            "slug": "The-RAP:-a-ring-array-processor-for-layered-network-Morgan-Beck",
            "title": {
                "fragments": [],
                "text": "The RAP: a ring array processor for layered network calculations"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The authors have designed and implemented a ring array processor, RAP, for fast implementation of layered neural network algorithms, a multi-DSP system targeted at continuous speech recognition using connectionist algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings of the International Conference on Application Specific Array Processors"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144215175"
                        ],
                        "name": "R. Jacobs",
                        "slug": "R.-Jacobs",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9947500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9ef2995e8e1bd57a74343073219364811c2ace0",
            "isKey": false,
            "numCitedBy": 1988,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Increased-rates-of-convergence-through-learning-Jacobs",
            "title": {
                "fragments": [],
                "text": "Increased rates of convergence through learning rate adaptation"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2213649"
                        ],
                        "name": "C. Wellekens",
                        "slug": "C.-Wellekens",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wellekens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wellekens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120363714,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ff5a3d6464f842c8bcd4f2c60a9796de0aac25b9",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The Hidden Markov models are generalized by defining a new emission probability which takes the correlation between successive feature vectors into account. Estimation formulas for the iterative learning both along Viterbi and Maximum likelihood criteria are presented."
            },
            "slug": "Explicit-time-correlation-in-hidden-Markov-models-Wellekens",
            "title": {
                "fragments": [],
                "text": "Explicit time correlation in hidden Markov models for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The Hidden Markov models are generalized by defining a new emission probability which takes the correlation between successive feature vectors into account andimation formulas for the iterative learning both along Viterbi and Maximum likelihood criteria are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741996"
                        ],
                        "name": "N. Karayiannis",
                        "slug": "N.-Karayiannis",
                        "structuredName": {
                            "firstName": "Nicolaos",
                            "lastName": "Karayiannis",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Karayiannis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707519"
                        ],
                        "name": "A. Venetsanopoulos",
                        "slug": "A.-Venetsanopoulos",
                        "structuredName": {
                            "firstName": "Anastasios",
                            "lastName": "Venetsanopoulos",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Venetsanopoulos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60327505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e68135d261dcd5c26bbe221fedf7860fda841787",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction. 2. Neural Network Architectures and Learning Schemes. 3. ELEANNE: Efficient LEarning Algorithms for Neural NEtworks. 4. Fast Learning Algorithms for Neural Networks. 5. ALADIN: Algorithms for Learning and Architecture DetermINation. 6. Performance Evaluation of Single-Layered Neural Networks. 7. High-Order Neural Networks and Networks with Composite Key Patterns. 8. Applications of Neural Networks: A Case Study. 9. Applications of Neural Networks: A Review. 10. Future Trends and Directions. References. Subject Index. Author Index."
            },
            "slug": "Artificial-neural-networks-learning-algorithms,-and-Karayiannis-Venetsanopoulos",
            "title": {
                "fragments": [],
                "text": "Artificial neural networks - learning algorithms, performance evaluation, and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This book discusses Neural Network Architectures and Learning Schemes, a meta-modelling framework for learning and architecture DetermINation, and some of the algorithms used in this framework."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12781225,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5d11aad09f65431b5d3cb1d85328743c9e53ba96",
            "isKey": false,
            "numCitedBy": 9066,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The first of these questions is in the province of sensory physiology, and is the only one for which appreciable understanding has been achieved. This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory. With regard to the second question, two alternative positions have been maintained. The first suggests that storage of sensory information is in the form of coded representations or images, with some sort of one-to-one mapping between the sensory stimulus"
            },
            "slug": "The-perceptron:-a-probabilistic-model-for-storage-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "The perceptron: a probabilistic model for information storage and organization in the brain."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14711886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce9a21b93ba29d4145a8ef6bf401e77f261848de",
            "isKey": false,
            "numCitedBy": 3832,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length."
            },
            "slug": "A-Learning-Algorithm-for-Continually-Running-Fully-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145145320"
                        ],
                        "name": "J. Beck",
                        "slug": "J.-Beck",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Beck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143869759"
                        ],
                        "name": "P. Kohn",
                        "slug": "P.-Kohn",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Kohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748118"
                        ],
                        "name": "J. Bilmes",
                        "slug": "J.-Bilmes",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Bilmes",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bilmes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143657504"
                        ],
                        "name": "E. Allman",
                        "slug": "E.-Allman",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Allman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Allman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153308817"
                        ],
                        "name": "J. Beer",
                        "slug": "J.-Beer",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Beer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30380934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f4d66aca349516cf38c4cdc87559f04134110d4",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Ring-Array-Processor:-A-Multiprocessing-for-Morgan-Beck",
            "title": {
                "fragments": [],
                "text": "The Ring Array Processor: A Multiprocessing Peripheral for Connection Applications"
            },
            "venue": {
                "fragments": [],
                "text": "J. Parallel Distributed Comput."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144763324"
                        ],
                        "name": "Y. Pao",
                        "slug": "Y.-Pao",
                        "structuredName": {
                            "firstName": "Yoh-Han",
                            "lastName": "Pao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Pao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45377743,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce8ea838392475df77db85a74cf48d206373fec8",
            "isKey": false,
            "numCitedBy": 2221,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "It's coming again, the new collection that this site has. To complete your curiosity, we offer the favorite adaptive pattern recognition and neural networks book as the choice today. This is a book that will show you even new to old thing. Forget it; it will be right for you. Well, when you are really dying of adaptive pattern recognition and neural networks, just pick it. You know, this book is always making the fans to be dizzy if not to find."
            },
            "slug": "Adaptive-pattern-recognition-and-neural-networks-Pao",
            "title": {
                "fragments": [],
                "text": "Adaptive pattern recognition and neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This is a book that will show you even new to old thing, and when you are really dying of adaptive pattern recognition and neural networks, just pick this book; it will be right for you."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793645"
                        ],
                        "name": "H. Gish",
                        "slug": "H.-Gish",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Gish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18820742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3f073ac7513183a9bf3a76154dcd245748d2ab6",
            "isKey": false,
            "numCitedBy": 903,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantization, the process of approximating continuous-amplitude signals by digital (discrete-amplitude) signals, is an important aspect of data compression or coding, the field concerned with the reduction of the number of bits necessary to transmit or store analog data, subject to a distortion or fidelity criterion. The independent quantization of each signal value or parameter is termed scalar quantization, while the joint quantization of a block of parameters is termed block or vector quantization. This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization. Vector quantization is presented as a process of redundancy removal that makes effective use of four interrelated properties of vector parameters: linear dependency (correlation), nonlinear dependency, shape of the probability density function (pdf), and vector dimensionality itself. In contrast, scalar quantization can utilize effectively only linear dependency and pdf shape. The basic concepts are illustrated by means of simple examples and the theoretical limits of vector quantizer performance are reviewed, based on results from rate-distortion theory. Practical issues relating to quantizer design, implementation, and performance in actual applications are explored. While many of the methods presented are quite general and can be used for the coding of arbitrary signals, this paper focuses primarily on the coding of speech signals and parameters."
            },
            "slug": "Vector-quantization-in-speech-coding-Makhoul-Roukos",
            "title": {
                "fragments": [],
                "text": "Vector quantization in speech coding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization, and focuses primarily on the coding of speech signals and parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144497046"
                        ],
                        "name": "N. Nilsson",
                        "slug": "N.-Nilsson",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Nilsson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Nilsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20370792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "affcf19551b01c4c8009d061750700d91c2f79e9",
            "isKey": false,
            "numCitedBy": 3832,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A classic introduction to artificial intelligence intended to bridge the gap between theory and practice, \"Principles of Artificial Intelligence\" describes fundamental AI ideas that underlie applications such as natural language processing, automatic programming, robotics, machine vision, automatic theorem proving, and intelligent data retrieval. Rather than focusing on the subject matter of the applications, the book is organized around general computational concepts involving the kinds of data structures used, the types of operations performed on the data structures, and the properties of the control strategies used. \"Principles of Artificial Intelligence\"evolved from the author's courses and seminars at Stanford University and University of Massachusetts, Amherst, and is suitable for text use in a senior or graduate AI course, or for individual study."
            },
            "slug": "Principles-of-Artificial-Intelligence-Nilsson",
            "title": {
                "fragments": [],
                "text": "Principles of Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This classic introduction to artificial intelligence describes fundamental AI ideas that underlie applications such as natural language processing, automatic programming, robotics, machine vision, automatic theorem proving, and intelligent data retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7828,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145948621"
                        ],
                        "name": "G. Box",
                        "slug": "G.-Box",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Box",
                            "middleNames": [
                                "E.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Box"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143782658"
                        ],
                        "name": "G. Jenkins",
                        "slug": "G.-Jenkins",
                        "structuredName": {
                            "firstName": "Gwilym",
                            "lastName": "Jenkins",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jenkins"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62556607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "327c99ca844b6915c8303177f031a3ebdd4cf9db",
            "isKey": false,
            "numCitedBy": 12733,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis is a complete revision of a classic, seminal, and authoritative book that has been the model for most books on the topic written since 1970. It focuses on practical techniques throughout, rather than a rigorous mathematical treatment of the subject. It explores the building of stochastic (statistical) models for time series and their use in important areas of application \u0097forecasting, model specification, estimation, and checking, transfer function modeling of dynamic relationships, modeling the effects of intervention events, and process control. Features sections on: recently developed methods for model specification, such as canonical correlation analysis and the use of model selection criteria; results on testing for unit root nonstationarity in ARIMA processes; the state space representation of ARMA models and its use for likelihood estimation and forecasting; score test for model checking; and deterministic components and structural components in time series models and their estimation based on regression-time series model methods."
            },
            "slug": "Time-series-analysis,-forecasting-and-control-Box-Jenkins",
            "title": {
                "fragments": [],
                "text": "Time series analysis, forecasting and control"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This revision of a classic, seminal, and authoritative book explores the building of stochastic models for time series and their use in important areas of application \u0097forecasting, model specification, estimation, and checking, transfer function modeling of dynamic relationships, modeling the effects of intervention events, and process control."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9428697"
                        ],
                        "name": "J. Zurada",
                        "slug": "J.-Zurada",
                        "structuredName": {
                            "firstName": "Jacek",
                            "lastName": "Zurada",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zurada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60602644,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8edd60a3be9a6e09bd4c6c586a109e4f3f7b116",
            "isKey": false,
            "numCitedBy": 3010,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Jacek M. Zurada received his MS and Ph.D. degrees (with distinction) in electrical engineering from the Technical University of Gdansk, Poland. Since 1989 he has been a Professor with the Electrical and Computer Engineering Department at the University of Louisville, Kentucky. He was Department Chair from 2004 to 2006. He has published over 350 journal and conference papers in the areas of neural networks, computational intelligence, data mining, image processing and VLSI circuits. INTRODUCTION TO ARTIFICIAL NEURAL SYSTEMS"
            },
            "slug": "Introduction-to-artificial-neural-systems-Zurada",
            "title": {
                "fragments": [],
                "text": "Introduction to artificial neural systems"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Jacek M. Zurada is a Professor with the Electrical and Computer Engineering Department at the University of Louisville, Kentucky and has published over 350 journal and conference papers in the areas of neural networks, computational intelligence, data mining, image processing and VLSI circuits."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8992604"
                        ],
                        "name": "E. Levin",
                        "slug": "E.-Levin",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145881625"
                        ],
                        "name": "M. Fleisher",
                        "slug": "M.-Fleisher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fleisher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fleisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2024543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "247698d0a716f0d99c0645050d049525e0b08ec2",
            "isKey": false,
            "numCitedBy": 246,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abst ract . Learning in layered neu ral networks is posed as the mini\u00ad miz at ion of an error function defined over t he training set. A proba\u00ad bilistic interpretation of the target act ivities sugges ts th e use of rela\u00ad t ive entro py as an error measure. We investigate t he merits of using this error function over t he traditional quad ratic function for gradient descent learni ng. Com parative numerical sim ulations for the conrf\u00ad guity problem show marked redu ct ion s in learn ing t imes. This im \u00ad provement is explained in terms of the characteristic steepness of the landscape defined by the error function in configuration space."
            },
            "slug": "Accelerated-Learning-in-Layered-Neural-Networks-Solla-Levin",
            "title": {
                "fragments": [],
                "text": "Accelerated Learning in Layered Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work investigates the merits of using this error function over t he traditional quad ratic function for gradient descent for conrf\u00ad guity problem and explains the characteristic steepness of the landscape defined by the error function in configuration space."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145011683"
                        ],
                        "name": "K. R. Rao",
                        "slug": "K.-R.-Rao",
                        "structuredName": {
                            "firstName": "Kamisetty",
                            "lastName": "Rao",
                            "middleNames": [
                                "Ramamohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. R. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49211874"
                        ],
                        "name": "N. Ahmed",
                        "slug": "N.-Ahmed",
                        "structuredName": {
                            "firstName": "Nasir",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ahmed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10776771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d214c032de73d4ad2f403e38b98f338a6549f1c",
            "isKey": false,
            "numCitedBy": 770,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A tutorial-review paper on discrete orthogonal transforms and their applications in digital signal and image (both monochrome and color) processing is presented. Various transforms such as discrete Fourier, discrete cosine, Walsh-Hadamard, slant, Haar, discrete linear basis, Hadamard-Haar, rapid, lower triangular, generalized Haar, slant Haar and Karhunen-Loeve are defined and developed. Pertinent properties of these transforms such as power spectra, cyclic and dyadic convolution and correlation are outlined. Efficient algorithms for fast implementation of these transforms based on matrix partitioning or matrix factoring are presented. The application of these transforms in speech and image processing, spectral analysis, digital filtering (linear, nonlinear, optimal and suboptimal), nonlinear systems analysis, spectrography, digital holography, industrial testing, spectrometric imaging, feature selection, and patter recognition is presented. The utility and effectiveness of these transforms are evaluated in terms of some standard performance criteria such as computational complexity, variance distribution, mean-square error, correlated rms error, rate distortion, data compression, classification error, and digital hardware realization."
            },
            "slug": "Orthogonal-Transforms-for-Digital-Signal-Processing-Rao-Ahmed",
            "title": {
                "fragments": [],
                "text": "Orthogonal Transforms for Digital Signal Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The utility and effectiveness of these transforms are evaluated in terms of some standard performance criteria such as computational complexity, variance distribution, mean-square error, correlated rms error, rate distortion, data compression, classification error, and digital hardware realization."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760896"
                        ],
                        "name": "K. Asanovi\u0107",
                        "slug": "K.-Asanovi\u0107",
                        "structuredName": {
                            "firstName": "Krste",
                            "lastName": "Asanovi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Asanovi\u0107"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145145320"
                        ],
                        "name": "J. Beck",
                        "slug": "J.-Beck",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Beck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Beck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31881134"
                        ],
                        "name": "Brian E. D. Kingsbury",
                        "slug": "Brian-E.-D.-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": [
                                "E.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian E. D. Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143869759"
                        ],
                        "name": "P. Kohn",
                        "slug": "P.-Kohn",
                        "structuredName": {
                            "firstName": "Phil",
                            "lastName": "Kohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762709"
                        ],
                        "name": "J. Wawrzynek",
                        "slug": "J.-Wawrzynek",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wawrzynek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wawrzynek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61012764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d02c76bf500dc7fafec5d19dc3aba63cb3e190f3",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "SPERT (synthetic perceptron testbed) is a fully programmable single chip microprocessor designed for efficient execution of artificial neural network algorithms. The first implementation is in a 1.2 mu m CMOS technology with a 50 MHz clock rate, and a prototype system is being designed to occupy a double SBus slot within a Sun Sparcstation. SPERT sustains over 300*10/sup 6/ connections per second during pattern classification, and around 100*10/sup 6/ connection updates per second while running the popular error backpropagation training algorithm. This represents a speedup of around two orders of magnitude over a Sparcstation-2 for algorithms of interest. An earlier system produced by the group, the Ring Array Processor (RAP), used commercial DSP chips. Compared with a RAP multiprocessor of similar performance, SPERT represents over an order of magnitude reduction in cost for problems where fixed-point arithmetic is satisfactory.<<ETX>>"
            },
            "slug": "SPERT:-a-VLIW/SIMD-microprocessor-for-artificial-Asanovi\u0107-Beck",
            "title": {
                "fragments": [],
                "text": "SPERT: a VLIW/SIMD microprocessor for artificial neural network computations"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "SPERT (synthetic perceptron testbed) is a fully programmable single chip microprocessor designed for efficient execution of artificial neural network algorithms that represents over an order of magnitude reduction in cost for problems where fixed-point arithmetic is satisfactory."
            },
            "venue": {
                "fragments": [],
                "text": "[1992] Proceedings of the International Conference on Application Specific Array Processors"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693333"
                        ],
                        "name": "R. Schafer",
                        "slug": "R.-Schafer",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Schafer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schafer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 110562490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dc3b016bc8973ae3fcfb4596ebb1fa876cf541f",
            "isKey": false,
            "numCitedBy": 1675,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction. 2. Fundamentals of Digital Speech Processing. 3. Digital Models for the Speech Signal. 4. Time-Domain Models for Speech Processing. 5. Digital Representation of the Speech Waveform. 6. Short-Time Fourier Analysis. 7. Homomorphic Speech Processing. 8. Linear Predictive Coding of Speech. 9. Digital Speech Processing for Man-Machine Communication by Voice."
            },
            "slug": "Digital-Processing-of-Speech-Signals-Rabiner-Schafer",
            "title": {
                "fragments": [],
                "text": "Digital Processing of Speech Signals"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a meta-modelling framework for digital Speech Processing for Man-Machine Communication by Voice that automates the very labor-intensive and therefore time-heavy and expensive process of encoding and decoding speech."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111289375"
                        ],
                        "name": "Michael D. Brown",
                        "slug": "Michael-D.-Brown",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brown",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael D. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39515755"
                        ],
                        "name": "R. Chamberlain",
                        "slug": "R.-Chamberlain",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Chamberlain",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chamberlain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5823473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b49fce77d75f671e5f41326e85794501835b0fc",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The principles of an efficient one-pass dynamic programming whole-word pattern matching algorithm for the recognition of spoken sequences of connected words are described. Particular attention is given to the technique for keeping track of word-sequence decisions, which may be constrained by a finite-state syntax. Some extensions of the technique are discussed."
            },
            "slug": "An-algorithm-for-connected-word-recognition-Bridle-Brown",
            "title": {
                "fragments": [],
                "text": "An algorithm for connected word recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "The principles of an efficient one-pass dynamic programming whole-word pattern matching algorithm for the recognition of spoken sequences of connected words are described and some extensions of the technique are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35535410"
                        ],
                        "name": "R. Engle",
                        "slug": "R.-Engle",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Engle",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Engle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18673159,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2ee6cb87fc81ecd78d161c4a92c9dfce00c8961c",
            "isKey": false,
            "numCitedBy": 19632,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional econometric models assume a constant one-period forecast variance. To generalize this implausible assumption, a new class of stochastic processes called autoregressive conditional heteroscedastic (ARCH) processes are introduced in this paper. These are mean zero, serially uncorrelated processes with nonconstant variances conditional on the past, but constant unconditional variances. For such processes, the recent past gives information about the one-period forecast variance. A regression model is then introduced with disturbances following an ARCH process. Maximum likelihood estimators are described and a simple scoring iteration formulated. Ordinary least squares maintains its optimality properties in this set-up, but maximum likelihood is more efficient. The relative efficiency is calculated and can be infinite. To test whether the disturbances follow an ARCH process, the Lagrange multiplier procedure is employed. The test is based simply on the autocorrelation of the squared OLS residuals. This model is used to estimate the means and variances of inflation in the U.K. The ARCH effect is found to be significant and the estimated variances increase substantially during the chaotic seventies."
            },
            "slug": "Autoregressive-conditional-heteroscedasticity-with-Engle",
            "title": {
                "fragments": [],
                "text": "Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103184259"
                        ],
                        "name": "L. B. Lmeida",
                        "slug": "L.-B.-Lmeida",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Lmeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Lmeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123571595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c977f4ae86448166098eb7fa27b79d371878d210",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Backpropagation has shown to be an efficient learning rule for graded perceptrons. However, as initially introduced, it was limited to feedforward structures. Extension of backpropagation to systems with feedback was done by this author, in [4]. In this paper, this extension is presented, and the error propagation circuit is interpreted as the transpose of the linearized perceptron network. The error propagation network is shown to always be stable during training, and a sufficient condition for the stability of the perceptron network is derived. Finally, potentially useful relationships with Hopfield networks and Boltzmann machines are discussed."
            },
            "slug": "Backpropagation-in-perceptrons-with-feedback-Lmeida",
            "title": {
                "fragments": [],
                "text": "Backpropagation in perceptrons with feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The error propagation circuit is interpreted as the transpose of the linearized perceptrons network, and the error propagation network is shown to always be stable during training, and a sufficient condition for the stability of the perceptron network is derived."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2392554"
                        ],
                        "name": "S. M. Peeling",
                        "slug": "S.-M.-Peeling",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Peeling",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. M. Peeling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107422095"
                        ],
                        "name": "R. Moore",
                        "slug": "R.-Moore",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Moore",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Moore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36841121,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ef11dcedb53fbcd0fdcfe456f992630854e28cf",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Isolated-digit-recognition-experiments-using-the-Peeling-Moore",
            "title": {
                "fragments": [],
                "text": "Isolated digit recognition experiments using the multi-layer perceptron"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40221291"
                        ],
                        "name": "A. Kramer",
                        "slug": "A.-Kramer",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Kramer",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kramer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388394865"
                        ],
                        "name": "A. Sangiovanni-Vincentelli",
                        "slug": "A.-Sangiovanni-Vincentelli",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Sangiovanni-Vincentelli",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sangiovanni-Vincentelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8301037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6733d4705a41de1a8f5a5eccd75479b448d5247",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallelizable optimization techniques are applied to the problem of learning in feedforward neural networks. In addition to having superior convergence properties, optimization techniques such as the Polak-Ribiere method are also significantly more efficient than the Backpropagation algorithm. These results are based on experiments performed on small boolean learning problems and the noisy real-valued learning problem of hand-written character recognition."
            },
            "slug": "Efficient-Parallel-Learning-Algorithms-for-Neural-Kramer-Sangiovanni-Vincentelli",
            "title": {
                "fragments": [],
                "text": "Efficient Parallel Learning Algorithms for Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Parallelizable optimization techniques such as the Polak-Ribiere method are significantly more efficient than the Backpropagation algorithm and the noisy real-valued learning problem of hand-written character recognition."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8554430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8f6f1b71fd91a222e1be698bcd038e78e93f275",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Baum's-forward-backward-algorithm-revisited-Devijver",
            "title": {
                "fragments": [],
                "text": "Baum's forward-backward algorithm revisited"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790264"
                        ],
                        "name": "Eduardo Sontag",
                        "slug": "Eduardo-Sontag",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Sontag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduardo Sontag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901890"
                        ],
                        "name": "H. Sussmann",
                        "slug": "H.-Sussmann",
                        "structuredName": {
                            "firstName": "H\u00e9ctor",
                            "lastName": "Sussmann",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sussmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 69947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1943969ee23bf0e7bfe079d76cdd08bcd006d5c4",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We give an example of a neural net without hidden layers and with a sigmoid transfer function, together with a training set of binary vectors, for which the sum of the squared errors, regarded as a function of the weights, has a local minimum which is not a global minimum. The example consists of a set of 125 training instances, with four weights and a threshold to be learnt. We do not know if substantially smaller binary examples exist."
            },
            "slug": "Backpropagation-Can-Give-Rise-to-Spurious-Local-for-Sontag-Sussmann",
            "title": {
                "fragments": [],
                "text": "Backpropagation Can Give Rise to Spurious Local Minima Even for Networks without Hidden Layers"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "An example of a neural net without hidden layers and with a sigmoid transfer function, together with a training set of binary vectors, for which the sum of the squared errors, regarded as a function of the weights, has a local minimum which is not a global minimum."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120780324,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d5f043b89a9b09a4245fd19fee59841c50805af0",
            "isKey": false,
            "numCitedBy": 1129,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Self-Organization-and-Associative-Memory,-Third-Kohonen",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory, Third Edition"
            },
            "venue": {
                "fragments": [],
                "text": "Springer Series in Information Sciences"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48429353"
                        ],
                        "name": "Pineda",
                        "slug": "Pineda",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Pineda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pineda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40994937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6602985bd326d9996c68627b56ed389e2c90fd08",
            "isKey": false,
            "numCitedBy": 905,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "An adaptive neural network with asymmetric connections is introduced. This network is related to the Hopfield network with graded neurons and uses a recurrent generalization of the \\ensuremath{\\delta} rule of Rumelhart, Hinton, and Williams to modify adaptively the synaptic weights. The new network bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler."
            },
            "slug": "Generalization-of-back-propagation-to-recurrent-Pineda",
            "title": {
                "fragments": [],
                "text": "Generalization of back-propagation to recurrent neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An adaptive neural network with asymmetric connections is introduced that bears a resemblance to the master/slave network of Lapedes and Farber but it is architecturally simpler."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18530691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c46799502bebfe6a9ae0f457b7b8b92248ec260",
            "isKey": false,
            "numCitedBy": 7891,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector."
            },
            "slug": "An-Algorithm-for-Vector-Quantizer-Design-Linde-Buzo",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Vector Quantizer Design"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118180516"
                        ],
                        "name": "F. M. Silva",
                        "slug": "F.-M.-Silva",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Silva",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. M. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068289963"
                        ],
                        "name": "L. B. Almeida",
                        "slug": "L.-B.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Almeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59837696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b788aec70b6ddf3ad49a4cccd494beefe8f3142",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speeding-up-Backpropagation-Silva-Almeida",
            "title": {
                "fragments": [],
                "text": "Speeding up Backpropagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34830449"
                        ],
                        "name": "M. Sondhi",
                        "slug": "M.-Sondhi",
                        "structuredName": {
                            "firstName": "Man",
                            "lastName": "Sondhi",
                            "middleNames": [
                                "Mohan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sondhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31558521,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5548693e214f9c7489086c25520f982c6b544be5",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "To use probabilistic functions of a Markov chain to model certain parameterizations of the speech signal, we extend an estimation technique of Liporace to the eases of multivariate mixtures, such as Gaussian sums, and products of mixtures. We also show how these problems relate to Liporace's original framework."
            },
            "slug": "Maximum-likelihood-estimation-for-multivariate-of-Juang-Levinson",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation for multivariate mixture observations of markov chains"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "To use probabilistic functions of a Markov chain to model certain parameterizations of the speech signal, an estimation technique of Liporace is extended to the eases of multivariate mixtures, such as Gaussian sums, and products of mixtures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423281"
                        ],
                        "name": "L. A. Liporace",
                        "slug": "L.-A.-Liporace",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Liporace",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Liporace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30026295,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "664eb4fb59f2ce8f2e019a77653f9ed2cc5df591",
            "isKey": false,
            "numCitedBy": 430,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Parameter estimation for multivariate functions of Markov chains, a class of versatile statistical models for vector random processes, is discussed. The model regards an ordered sequence of vectors as noisy multivariate observations of a Markov chain. Mixture distributions are a special case. The foundations of the theory presented here were established by Baum, Petrie, Soules, and Weiss. A powerful representation theorem by Fan is employed to generalize the analysis of Baum, {\\em et al.} to a larger class of distributions."
            },
            "slug": "Maximum-likelihood-estimation-for-multivariate-of-Liporace",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation for multivariate observations of Markov sources"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "Parameter estimation for multivariate functions of Markov chains, a class of versatile statistical models for vector random processes, is discussed, and a powerful representation theorem by Fan is employed to generalize the analysis of Baum, et al. to a larger class of distributions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34680849"
                        ],
                        "name": "A. Gevins",
                        "slug": "A.-Gevins",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Gevins",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gevins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143909996"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9182120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbd05f1b1f325e4514a3ef20563d9e00a438ec58",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in artificial intelligence and signal processing has suggested that a merger of the two fields would be profitable for both (Kopec et al, 1982). Here we discuss the improvement of decision systems by the use of iterative mathematical techniques. These techniques could be called \"ignorance-based\" since they can be characterized by exhaustive searches for useful combinations of problem-relevant variables in data spaces for which human knowledge is incomplete."
            },
            "slug": "\"Ignorance-based\"-systems-Gevins-Morgan",
            "title": {
                "fragments": [],
                "text": "\"Ignorance-based\" systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work discusses the improvement of decision systems by the use of iterative mathematical techniques that can be characterized by exhaustive searches for useful combinations of problem-relevant variables in data spaces for which human knowledge is incomplete."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688638"
                        ],
                        "name": "E. Ruspini",
                        "slug": "E.-Ruspini",
                        "structuredName": {
                            "firstName": "Enrique",
                            "lastName": "Ruspini",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ruspini"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40825490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4355d140b96314b85782555a3b6848cf41776b26",
            "isKey": false,
            "numCitedBy": 537,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-methods-for-fuzzy-clustering-Ruspini",
            "title": {
                "fragments": [],
                "text": "Numerical methods for fuzzy clustering"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16925,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737945"
                        ],
                        "name": "H. Akaike",
                        "slug": "H.-Akaike",
                        "structuredName": {
                            "firstName": "Hirotugu",
                            "lastName": "Akaike",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Akaike"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123148751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dd98542786c90b7c01b6e44381d9b9c4d81430b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The necessity of using statistical models for the development of efficient statistical signal processing procedures is explained with simple examples of the time series analysis. Recent extensions of the use of the concept of the likelihood of a statistical model are reviewd from the point of view of the entropy maximization principle, Particular emphasis is placed on the proper use of Bayesian models."
            },
            "slug": "Use-of-statistical-models-for-time-series-analysis-Akaike",
            "title": {
                "fragments": [],
                "text": "Use of statistical models for time series analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "The necessity of using statistical models for the development of efficient statistical signal processing procedures is explained with simple examples of the time series analysis, with particular emphasis on the proper use of Bayesian models."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802286"
                        ],
                        "name": "P. Delsarte",
                        "slug": "P.-Delsarte",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Delsarte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Delsarte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2611393"
                        ],
                        "name": "Y. Kamp",
                        "slug": "Y.-Kamp",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Kamp",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kamp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43680529,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e01c3ccf5a59ca224966bd0f1f41f38a0167883a",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Given an $m \\times n$ sign matrix S, an $m \\times n$ real matrix A is said to be a realization of S if the sign of the $(i,j)$-entry of A equals the $(i,j)$-entry of S. This paper deals with the problem of finding low rank realization matrices A. It is motivated by a minimization problem in multilayer perceptrons. The subject is approached by means of the Farkas lemma, which allows characterization of the sign matrices realizable with a given rank. Based on this result and on some other standard techniques of matrix algebra such as the cyclic Fourier transform, low rank realizations are obtained for sign matrices having certain nice combinatorial structures. Furthermore, the paper includes an elementary lower bound on the rank and a counting of realizable sign vectors."
            },
            "slug": "Low-Rank-Matrices-with-a-Given-Sign-Pattern-Delsarte-Kamp",
            "title": {
                "fragments": [],
                "text": "Low Rank Matrices with a Given Sign Pattern"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Based on the Farkas lemma and on some other standard techniques of matrix algebra such as the cyclic Fourier transform, low rank realizations are obtained for sign matrices having certain nice combinatorial structures."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Discret. Math."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741124"
                        ],
                        "name": "L. Valiant",
                        "slug": "L.-Valiant",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Valiant",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Valiant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 59712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10ddb646feddc12337b5a755c72e153e37088c02",
            "isKey": false,
            "numCitedBy": 4184,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans appear to be able to learn new concepts without needing to be programmed explicitly in any conventional sense. In this paper we regard learning as the phenomenon of knowledge acquisition in the absence of explicit programming. We give a precise methodology for studying this phenomenon from a computational viewpoint. It consists of choosing an appropriate information gathering mechanism, the learning protocol, and exploring the class of concepts that can be learnt using it in a reasonable (polynomial) number of steps. We find that inherent algorithmic complexity appears to set serious limits to the range of concepts that can be so learnt. The methodology and results suggest concrete principles for designing realistic learning systems."
            },
            "slug": "A-theory-of-the-learnable-Valiant",
            "title": {
                "fragments": [],
                "text": "A theory of the learnable"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper regards learning as the phenomenon of knowledge acquisition in the absence of explicit programming, and gives a precise methodology for studying this phenomenon from a computational viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7305058,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "ede664196e056b81cc3f9a208d9f207c7fba40e7",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that it is possible to factor a multilayered classification network with a large output layer into a number of smaller networks, where the product of the sizes of the output layers equals the size of the original output layer. No assumptions of statistical independence are required."
            },
            "slug": "Factoring-Networks-by-a-Statistical-Method-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Factoring Networks by a Statistical Method"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is shown that it is possible to factor a multilayered classification network with a large output layer into a number of smaller networks, where the product of the sizes of the output layers equals the size of the original output layer."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913418"
                        ],
                        "name": "B. Widrow",
                        "slug": "B.-Widrow",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Widrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Widrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136588"
                        ],
                        "name": "S. Stearns",
                        "slug": "S.-Stearns",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Stearns",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stearns"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 69353254,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "id": "6c192b91f4b4ac35ae8385fa190fdfc146f419b8",
            "isKey": false,
            "numCitedBy": 3658,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "GENERAL INTRODUCTION. Adaptive Systems. The Adaptive Linear Combiner. THEORY OF ADAPTATION WITH STATIONARY SIGNALS. Properties of the Quadratic Performance Surface. Searching the Performance Surface. Gradient Estimation and Its Effects on Adaptation. ADAPTIVE ALGORITHMS AND STRUCTURES. The LMS Algorithm. The Z-Transform in Adaptive Signal Processing. Other Adaptive Algorithms and Structures. Adaptive Lattice Filters. APPLICATIONS. Adaptive Modeling and System Identification. Inverse Adaptive Modeling, Deconvolution, and Equalization. Adaptive Control Systems. Adaptive Interference Cancelling. Introduction to Adaptive Arrays and Adaptive Beamforming. Analysis of Adaptive Beamformers."
            },
            "slug": "Adaptive-Signal-Processing-Widrow-Stearns",
            "title": {
                "fragments": [],
                "text": "Adaptive Signal Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This chapter discusses Adaptive Arrays and Adaptive Beamforming, as well as other Adaptive Algorithms and Structures, and discusses the Z-Transform in Adaptive Signal Processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5206,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772133"
                        ],
                        "name": "J. Hennessy",
                        "slug": "J.-Hennessy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hennessy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennessy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60693966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890469e625fe728adfa690a3945ebca4c11a8998",
            "isKey": false,
            "numCitedBy": 11525,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today. In this edition, the authors bring their trademark method of quantitative analysis not only to high-performance desktop machine design, but also to the design of embedded and server systems. They have illustrated their principles with designs from all three of these domains, including examples from consumer electronics, multimedia and Web technologies, and high-performance computing."
            },
            "slug": "Computer-Architecture:-A-Quantitative-Approach-Patterson-Hennessy",
            "title": {
                "fragments": [],
                "text": "Computer Architecture: A Quantitative Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48399,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712517"
                        ],
                        "name": "L. Rabiner",
                        "slug": "L.-Rabiner",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rabiner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rabiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13618539,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "8fe2ea0a67954f1380b3387e3262f1cdb9f9b3e5",
            "isKey": false,
            "numCitedBy": 24802,
            "numCiting": 98,
            "paperAbstract": {
                "fragments": [],
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests. The fabric is defined of voids having depth as well as width and length. The fabric is usable as a material from which to form clothing for wear, or bed coverings, or sleeping bags, etc., besides use simply as a netting."
            },
            "slug": "A-Tutorial-on-Hidden-Markov-Models-and-Selected-Rabiner",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Hidden Markov Models and Selected Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The fabric comprises a novel type of netting which will have particular utility in screening out mosquitoes and like insects and pests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4929024"
                        ],
                        "name": "J. Bezdek",
                        "slug": "J.-Bezdek",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bezdek",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bezdek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11698213,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "890c4ec0d37deb73673ca7ab2406c87b1436e2b3",
            "isKey": false,
            "numCitedBy": 938,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper the convergence of a class of clustering procedures, popularly known as the fuzzy ISODATA algorithms, is established. The theory of Zangwill is used to prove that arbitrary sequences generated by these (Picard iteration) procedures always terminates at a local minimum, or at worst, always contains a subsequence which converges to a local minimum of the generalized least squares objective functional which defines the problem."
            },
            "slug": "A-Convergence-Theorem-for-the-Fuzzy-ISODATA-Bezdek",
            "title": {
                "fragments": [],
                "text": "A Convergence Theorem for the Fuzzy ISODATA Clustering Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The theory of Zangwill is used to prove that arbitrary sequences generated by these (Picard iteration) procedures always terminates at a local minimum, or at worst, always contains a subsequence which converges to aLocal minimum of the generalized least squares objective functional which defines the problem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19355,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152591573"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15974963"
                        ],
                        "name": "A. F. Smith",
                        "slug": "A.-F.-Smith",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. F. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580190"
                        ],
                        "name": "U. Makov",
                        "slug": "U.-Makov",
                        "structuredName": {
                            "firstName": "Udi",
                            "lastName": "Makov",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Makov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124992180,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "54a1f6ab4cc6cb749c2b8d15c1dd3449e072362f",
            "isKey": false,
            "numCitedBy": 3447,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical Problems. Applications of Finite Mixture Models. Mathematical Aspects of Mixtures. Learning About the Parameters of a Mixture. Learning About the Components of a Mixture. Sequential Problems and Procedures."
            },
            "slug": "Statistical-analysis-of-finite-mixture-Titterington-Smith",
            "title": {
                "fragments": [],
                "text": "Statistical analysis of finite mixture distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This course discusses Mathematical Aspects of Mixtures, Sequential Problems and Procedures, and Applications of Finite Mixture Models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34641136"
                        ],
                        "name": "J. Bunch",
                        "slug": "J.-Bunch",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bunch",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bunch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428362"
                        ],
                        "name": "C. P. Nielsen",
                        "slug": "C.-P.-Nielsen",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Nielsen",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. P. Nielsen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121597429,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "01a362de9d0a8714f2726f53dba1777513f79c2f",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "SummaryLetA be anm\u00d7n matrix with known singular value decomposition. The computation of the singular value decomposition of a matrix\u00c3 is considered, where\u00c3 is obtained by appending a row or a column toA whenm\u2267n or by deleting a row or a column fromA whenm>n. An algorithm is also presented for solving the updated least squares problem\u00c3 y\u2212b\u2248, obtained from the least squares problemAx\u2212b by appending an equation, deleting an equation, appending an unknown, or deleting an unknown."
            },
            "slug": "Updating-the-singular-value-decomposition-Bunch-Nielsen",
            "title": {
                "fragments": [],
                "text": "Updating the singular value decomposition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086537"
                        ],
                        "name": "S. Greenberg",
                        "slug": "S.-Greenberg",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Greenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Greenberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 59790528,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "7aee0c466db1e3805e28f3524fbf885f5d431c97",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-ear-as-a-speech-analyzer-Greenberg",
            "title": {
                "fragments": [],
                "text": "The ear as a speech analyzer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145257873"
                        ],
                        "name": "G. Stewart",
                        "slug": "G.-Stewart",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Stewart",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stewart"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122814683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36a33485a856dce4f65314bf16fec2365194ae96",
            "isKey": false,
            "numCitedBy": 2034,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preliminaries. Practicalities. The Direct Solution of Linear Systems. Norms, Limits, and Condition Numbers. The Linear Least Squares Problem. Eigenvalues and Eigenvectors. The QR Algorithm. The Greek Alphabet and Latin Notational Correspondents. Determinants. Rounding-Error Analysis of Solution of Triangular Systems and of Gaussian Elimination. Of Things Not Treated. Bibliography. Index."
            },
            "slug": "Introduction-to-matrix-computations-Stewart",
            "title": {
                "fragments": [],
                "text": "Introduction to matrix computations"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Rounding-Error Analysis of Solution of Triangular Systems and of Gaussian Elimination."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693256"
                        ],
                        "name": "D. Sankoff",
                        "slug": "D.-Sankoff",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sankoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sankoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10398168"
                        ],
                        "name": "J. Kruskal",
                        "slug": "J.-Kruskal",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Kruskal",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kruskal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403841706"
                        ],
                        "name": "Time Warps Eds",
                        "slug": "Time-Warps-Eds",
                        "structuredName": {
                            "firstName": "Time",
                            "lastName": "Eds",
                            "middleNames": [
                                "Warps"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Time Warps Eds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52535398"
                        ],
                        "name": "String Edits",
                        "slug": "String-Edits",
                        "structuredName": {
                            "firstName": "String",
                            "lastName": "Edits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "String Edits"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56729381,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "24ff739a7ade6b79ad92440b0f5f2a9a5fb838af",
            "isKey": false,
            "numCitedBy": 1351,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A mudflap assembly for use with a dump vehicle having dual tires at the rear end thereof and including a pair of flexible flap sections one of which is supported by a rigid member adjacent the dual tires and the other is located above and to the rear of the rigid member and is secured at its upper end to the dump body. The rigid member is pivotally connected to the dump body and is combined with a cable which assures that the attached flap section maintains substantially the same position when the dump body is in the lowered-carry-position or raised-dump-position."
            },
            "slug": "Macromolecules:-the-theory-and-practice-of-sequence-Sankoff-Kruskal",
            "title": {
                "fragments": [],
                "text": "Macromolecules: the theory and practice of sequence comparison"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A mudflap assembly for use with a dump vehicle having dual tires at the rear end thereof and including a pair of flexible flap sections that assures that the attached flap section maintains substantially the same position when the dump body is in the lowered-carry-position or raised-dump-position."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3838230"
                        ],
                        "name": "E. Hirschman",
                        "slug": "E.-Hirschman",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Hirschman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hirschman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116213824"
                        ],
                        "name": "R. Bartos",
                        "slug": "R.-Bartos",
                        "structuredName": {
                            "firstName": "Rena",
                            "lastName": "Bartos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bartos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 167458173,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7d5bf3d1ae2573e111a197842a905a77d446b0f4",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Moving-Target-Hirschman-Bartos",
            "title": {
                "fragments": [],
                "text": "The Moving Target"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712211"
                        ],
                        "name": "G. Golub",
                        "slug": "G.-Golub",
                        "structuredName": {
                            "firstName": "Gene",
                            "lastName": "Golub",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Golub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126299280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9efffc63f81bf3f6cb6357ddc15e9cd9da75d16",
            "isKey": false,
            "numCitedBy": 27003,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matrix-computations-Golub",
            "title": {
                "fragments": [],
                "text": "Matrix computations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712211"
                        ],
                        "name": "G. Golub",
                        "slug": "G.-Golub",
                        "structuredName": {
                            "firstName": "Gene",
                            "lastName": "Golub",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Golub"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 125821525,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9b901efe44aa6685048077000c2e2838a21e31bd",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Least-squares,-singular-values-and-matrix-Golub",
            "title": {
                "fragments": [],
                "text": "Least squares, singular values and matrix approximations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499348"
                        ],
                        "name": "J. Cowan",
                        "slug": "J.-Cowan",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Cowan",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cowan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125333261,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "803e17335bd59fa3e3c80ede84be5fdd53b30d47",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-mathematical-theory-of-central-nervous-activity-Cowan",
            "title": {
                "fragments": [],
                "text": "A mathematical theory of central nervous activity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715280"
                        ],
                        "name": "M. Jack",
                        "slug": "M.-Jack",
                        "structuredName": {
                            "firstName": "Mervyn",
                            "lastName": "Jack",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122192242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a84fccb9dafd9c1cc33372d353849972a4794d1e",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semi-continuous-hidden-Markov-models-for-speech-Huang-Jack",
            "title": {
                "fragments": [],
                "text": "Semi-continuous hidden Markov models for speech signals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102329511"
                        ],
                        "name": "George W. Soules",
                        "slug": "George-W.-Soules",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Soules",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George W. Soules"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063108982"
                        ],
                        "name": "Norman Weiss",
                        "slug": "Norman-Weiss",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norman Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 122568650,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4",
            "isKey": false,
            "numCitedBy": 4551,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Maximization-Technique-Occurring-in-the-Analysis-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120208815,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "603bdbb17ba1f909280405a076455ac4f878fbf3",
            "isKey": false,
            "numCitedBy": 2772,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Statistical-Inference-for-Probabilistic-Functions-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "Statistical Inference for Probabilistic Functions of Finite State Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3180815"
                        ],
                        "name": "H. Kesten",
                        "slug": "H.-Kesten",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Kesten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kesten"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120079793,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f27d141b14e825f7d38c489313283c787f92ffd5",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Accelerated-Stochastic-Approximation-Kesten",
            "title": {
                "fragments": [],
                "text": "Accelerated Stochastic Approximation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143701969"
                        ],
                        "name": "M. Priestley",
                        "slug": "M.-Priestley",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Priestley",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Priestley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118665644,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8ff28e76cce06e40fdfbc44c3039a491226ebe22",
            "isKey": false,
            "numCitedBy": 1247,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Non-linear-and-non-stationary-time-series-analysis-Priestley",
            "title": {
                "fragments": [],
                "text": "Non-linear and non-stationary time series analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294095"
                        ],
                        "name": "M. Powell",
                        "slug": "M.-Powell",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Powell",
                            "middleNames": [
                                "J.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Powell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118224933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c71ca26b183025b9f39f940f5e730f2c9a64e414",
            "isKey": false,
            "numCitedBy": 1426,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Radial-basis-functions-for-multivariable-a-review-Powell",
            "title": {
                "fragments": [],
                "text": "Radial basis functions for multivariable interpolation: a review"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125523249,
            "fieldsOfStudy": [],
            "id": "11fbf06e4c1c4eddc91a68e434433a4fc5f7cfc4",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Theory and Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49637194"
                        ],
                        "name": "A. Mullin",
                        "slug": "A.-Mullin",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Mullin",
                            "middleNames": [
                                "A."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mullin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61566132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cccc0a4817fd5f6d8758c66b4065a23897d49f1d",
            "isKey": false,
            "numCitedBy": 2372,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Principles-of-neurodynamics-Mullin-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "Principles of neurodynamics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759195"
                        ],
                        "name": "S. Levinson",
                        "slug": "S.-Levinson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Levinson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61592411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fafcd0a849757d72a78f1204ff5b9a27929c50c",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-unified-theory-of-composite-pattern-analysis-for-Levinson",
            "title": {
                "fragments": [],
                "text": "A unified theory of composite pattern analysis for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62186699,
            "fieldsOfStudy": [],
            "id": "3302a19539ccfa8ed3a8361ace8947ddbba1acf5",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An introduction to computing with neural nets"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5730960"
                        ],
                        "name": "D. Paul",
                        "slug": "D.-Paul",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Paul",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Paul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153201"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145631743"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "Janet",
                            "lastName": "Baker",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62730936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f58126db6cfc552a1a23cc589785c18864bd74c",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "An interaction has been found between the true source language model, the training language model, and the testing language model. This interaction has implications for vocabulary independent modeling, testing methodologies, discriminative training, and the adequacy of many of the current databases for continuous speech recognition development.<<ETX>>"
            },
            "slug": "On-the-interaction-between-true-source,-training,-Paul-Baker",
            "title": {
                "fragments": [],
                "text": "On the interaction between true source, training, and testing language models"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "An interaction has been found between the true source language model, the training language model), and the testing language model that has implications for vocabulary independent modeling, testing methodologies, discriminative training, and the adequacy of many of the current databases for continuous speech recognition development."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843072"
                        ],
                        "name": "S. Austin",
                        "slug": "S.-Austin",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Austin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Austin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354787"
                        ],
                        "name": "G. Zavaliagkos",
                        "slug": "G.-Zavaliagkos",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Zavaliagkos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zavaliagkos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62646843,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4238d28b44af7a6a395127502636247c83b98a65",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the concept of a \"Segmental Neural Net\" (SNN) for phonetic modeling in continuous speech recognition. The SNN takes as input all the frames of a phonetic segment and gives as output an estimate of the probability of each of the phonemes, given the input segment. By taking into account all the frames of a phonetic segment simultaneously, the SNN overcomes the well-known conditional-independence limitation of hidden Markov models (HMM). However, the problem of automatic segmentation with neural nets is a formidable computing task compared to HMMs. Therefore, to take advantage of the training and decoding speed of HMMs, we have developed a novel hybrid SNN/HMM system that combines the advantages of both types of approaches. In this hybrid system, use is made of the N-best paradigm to generate likely phonetic segmentations, which are then scored by the SNN. The HMM and SNN scores are then combined to optimize performance. In this manner, the recognition accuracy is guaranteed to be no worse than the HMM system alone."
            },
            "slug": "Continuous-speech-recognition-using-segmental-nets-Austin-Makhoul",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition using segmental neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel hybrid SNN/HMM system that combines the advantages of both types of approaches is developed, made of the N-best paradigm to generate likely phonetic segmentations, which are then scored by the SNN."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60745007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73ccd50a3fc04e2eb3628305902f7754b123430e",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-theoretical-framework-for-back-propagation-LeCun",
            "title": {
                "fragments": [],
                "text": "A theoretical framework for back-propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922810"
                        ],
                        "name": "P. Devijver",
                        "slug": "P.-Devijver",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Devijver",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Devijver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61074523,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc5a5cf6aa29ae0847dbd88bcc0ac042a9ee71fb",
            "isKey": false,
            "numCitedBy": 3014,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-recognition-:-a-statistical-approach-Devijver-Kittler",
            "title": {
                "fragments": [],
                "text": "Pattern recognition : a statistical approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319833"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 207975157,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "56623a496727d5c71491850e04512ddf4152b487",
            "isKey": false,
            "numCitedBy": 4468,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Beyond-Regression-:-\"New-Tools-for-Prediction-and-Werbos",
            "title": {
                "fragments": [],
                "text": "Beyond Regression : \"New Tools for Prediction and Analysis in the Behavioral Sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913418"
                        ],
                        "name": "B. Widrow",
                        "slug": "B.-Widrow",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Widrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Widrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1976925"
                        ],
                        "name": "M. Hoff",
                        "slug": "M.-Hoff",
                        "structuredName": {
                            "firstName": "Marcian",
                            "lastName": "Hoff",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60830585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e14b2ff9dc2234df94fc24d89fc25e797d0e9e7",
            "isKey": false,
            "numCitedBy": 2623,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-switching-circuits-Widrow-Hoff",
            "title": {
                "fragments": [],
                "text": "Adaptive switching circuits"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145718274"
                        ],
                        "name": "L. Zadeh",
                        "slug": "L.-Zadeh",
                        "structuredName": {
                            "firstName": "Lotfi",
                            "lastName": "Zadeh",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zadeh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60979109,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "c499c9c21a4aebb1a06ab089e3df1e23148be10b",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Phonological-structures-for-speech-recognition-Cohen-Zadeh",
            "title": {
                "fragments": [],
                "text": "Phonological structures for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516142"
                        ],
                        "name": "D. Tank",
                        "slug": "D.-Tank",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tank",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203175244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e570de6e8f260804a673dcb53f13b33c13a3014",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "CONCENTRATION-INFORMATION-IN-TIME:-ANALOG-NEURAL-TO-Tank-Hopfield",
            "title": {
                "fragments": [],
                "text": "CONCENTRATION INFORMATION IN TIME: ANALOG NEURAL NETWORKS WITH APPLICATIONS TO SPEECH RECOGNITION PROBLEMS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50333420"
                        ],
                        "name": "S. Becker",
                        "slug": "S.-Becker",
                        "structuredName": {
                            "firstName": "Suzanna",
                            "lastName": "Becker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Becker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59695337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "589d377b23e2bdae7ad161b36a5d6613bcfccdde",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Improving-the-convergence-of-back-propagation-with-Becker-LeCun",
            "title": {
                "fragments": [],
                "text": "Improving the convergence of back-propagation learning with second-order methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145394227"
                        ],
                        "name": "J. D. Farmer",
                        "slug": "J.-D.-Farmer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Farmer",
                            "middleNames": [
                                "Doyne"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Farmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1452639101"
                        ],
                        "name": "John J. Sidorowichl",
                        "slug": "John-J.-Sidorowichl",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Sidorowichl",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John J. Sidorowichl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59693817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07f3f6d430ffca990dee62cb2649bae40c60b380",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exploiting-Chaos-to-Predict-the-Future-and-Reduce-Farmer-Sidorowichl",
            "title": {
                "fragments": [],
                "text": "Exploiting Chaos to Predict the Future and Reduce Noise"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 56723681,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d76aafbeb54575859441a442376766c597f6bb52",
            "isKey": false,
            "numCitedBy": 1102,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Attractor-dynamics-and-parallelism-in-a-sequential-Jordan",
            "title": {
                "fragments": [],
                "text": "Attractor dynamics and parallelism in a connectionist sequential machine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068289963"
                        ],
                        "name": "L. B. Almeida",
                        "slug": "L.-B.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Almeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58820035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8be3f21ab796bd9811382b560507c1c679fae37f",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-learning-rule-for-asynchronous-perceptrons-with-a-Almeida",
            "title": {
                "fragments": [],
                "text": "A learning rule for asynchronous perceptrons with feedback in a combinatorial environment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145522"
                        ],
                        "name": "F. G\u00fcrgen",
                        "slug": "F.-G\u00fcrgen",
                        "structuredName": {
                            "firstName": "Fikret",
                            "lastName": "G\u00fcrgen",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. G\u00fcrgen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734761"
                        ],
                        "name": "S. Sagayama",
                        "slug": "S.-Sagayama",
                        "structuredName": {
                            "firstName": "Shigeki",
                            "lastName": "Sagayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sagayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699205"
                        ],
                        "name": "S. Furui",
                        "slug": "S.-Furui",
                        "structuredName": {
                            "firstName": "Sadaoki",
                            "lastName": "Furui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Furui"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38300401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb25c737f625b3883c0035ea170cceb99dc5f57a",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Line-spectrum-pair-frequency-based-distance-for-G\u00fcrgen-Sagayama",
            "title": {
                "fragments": [],
                "text": "Line spectrum pair frequency - based distance measures for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699205"
                        ],
                        "name": "S. Furui",
                        "slug": "S.-Furui",
                        "structuredName": {
                            "firstName": "Sadaoki",
                            "lastName": "Furui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Furui"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11112911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9d3ffb3418050848e9621bf971c0a17ed3f82c8",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-advances-in-speech-recognition-Furui",
            "title": {
                "fragments": [],
                "text": "Recent advances in speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859441"
                        ],
                        "name": "Eiichi Tsuboka",
                        "slug": "Eiichi-Tsuboka",
                        "structuredName": {
                            "firstName": "Eiichi",
                            "lastName": "Tsuboka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eiichi Tsuboka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10266228"
                        ],
                        "name": "Y. Takada",
                        "slug": "Y.-Takada",
                        "structuredName": {
                            "firstName": "Yoshihiro",
                            "lastName": "Takada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Takada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778603"
                        ],
                        "name": "H. Wakita",
                        "slug": "H.-Wakita",
                        "structuredName": {
                            "firstName": "Hisashi",
                            "lastName": "Wakita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wakita"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29586588,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b44c147caf1719397d4e9b9a8be2fd0263f534c5",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-predictive-hidden-Markov-model-Tsuboka-Takada",
            "title": {
                "fragments": [],
                "text": "Neural predictive hidden Markov model"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2356015"
                        ],
                        "name": "Marco Saerens",
                        "slug": "Marco-Saerens",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Saerens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Saerens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43154971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0b6cb5257729865958bf5c4df84071da330c33a",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linear-and-nonlinear-prediction-for-speech-with-Saerens-Bourlard",
            "title": {
                "fragments": [],
                "text": "Linear and nonlinear prediction for speech recognition with hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42369035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ffc709e6cc315227f90f1b621085d2185ea85ff",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Continuous-speech-recognition-on-the-resource-using-Morgan-Wooters",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition on the resource management database using connectionist probability estimation"
            },
            "venue": {
                "fragments": [],
                "text": "ICSLP"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122690"
                        ],
                        "name": "X. Aubert",
                        "slug": "X.-Aubert",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Aubert",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Aubert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38188868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6c6ddb031abf44b140c1d0939f6a41653ee29a7",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Supervised-segmentation-with-application-to-speech-Aubert",
            "title": {
                "fragments": [],
                "text": "Supervised segmentation with application to speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "ECST"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145768864"
                        ],
                        "name": "D. Broomhead",
                        "slug": "D.-Broomhead",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Broomhead",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Broomhead"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144159852"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3686496,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b08ba914037af6d88d16e2657a65cd9dc5cf5da1",
            "isKey": false,
            "numCitedBy": 2307,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multivariable-Functional-Interpolation-and-Adaptive-Broomhead-Lowe",
            "title": {
                "fragments": [],
                "text": "Multivariable Functional Interpolation and Adaptive Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 195,
        "totalPages": 20
    },
    "page_url": "https://www.semanticscholar.org/paper/Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan/3d82e058a5c40954b8f5db170a298a889a254c37?sort=total-citations"
}