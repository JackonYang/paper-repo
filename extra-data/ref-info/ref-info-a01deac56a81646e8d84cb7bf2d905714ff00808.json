{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "87531536"
                        ],
                        "name": "A. Panaretos",
                        "slug": "A.-Panaretos",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Panaretos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Panaretos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073684197"
                        ],
                        "name": "Luis Sosa",
                        "slug": "Luis-Sosa",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Sosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis Sosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052189571"
                        ],
                        "name": "Anthony Tang",
                        "slug": "Anthony-Tang",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108862960"
                        ],
                        "name": "Shirley Wong",
                        "slug": "Shirley-Wong",
                        "structuredName": {
                            "firstName": "Shirley",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shirley Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114080648"
                        ],
                        "name": "Robert Young",
                        "slug": "Robert-Young",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6379469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce39eb5cc1049a1060a499d6b6e94c8b2ec11da1",
            "isKey": false,
            "numCitedBy": 591,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the robust reading competitions forICDAR 2003. With the rapid growth in research over thelast few years on recognizing text in natural scenes, thereis an urgent need to establish some common benchmarkdatasets, and gain a clear understanding of the current stateof the art. We use the term robust reading to refer to text imagesthat are beyond the capabilities of current commercialOCR packages. We chose to break down the robust readingproblem into three sub-problems, and run competitionsfor each stage, and also a competition for the best overallsystem. The sub-problems we chose were text locating,character recognition and word recognition.By breaking down the problem in this way, we hope togain a better understanding of the state of the art in eachof the sub-problems. Furthermore, our methodology involvesstoring detailed results of applying each algorithm toeach image in the data sets, allowing researchers to study indepth the strengths and weaknesses of each algorithm. Thetext locating contest was the only one to have any entries.We report the results of this contest, and show cases wherethe leading algorithms succeed and fail."
            },
            "slug": "ICDAR-2003-robust-reading-competitions-Lucas-Panaretos",
            "title": {
                "fragments": [],
                "text": "ICDAR 2003 robust reading competitions"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The robust reading problem was broken down into three sub-problems, and competitions for each stage, and also a competition for the best overall system, which was the only one to have any entries."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680935"
                        ],
                        "name": "J. Jolion",
                        "slug": "J.-Jolion",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Jolion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jolion"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 221082842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07c4bf10fc43029bf4abcd22dd665eeb3673e218",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractThe systems currently available for contentbased image and\nvideo retrieval work without semantic knowledge, i. e. they use\nimage processing methods to extract low level features of the\ndata. The similarity obtained by these approaches does not\nalways correspond to the similarity a human user would expect. A\nway to include more semantic knowledge into the indexing process\nis to use the text included in the images and video sequences.\nIt is rich in information but easy to use, e. g. by key word\nbased queries. In this paper we present an algorithm to localise\nartificial text in images and videos using a measure of\naccumulated gradients and morphological processing. The quality\nof the localised text is improved by robust multiple frame\nintegration. A new technique for the binarisation of the text\nboxes based on a criterion maximizing local contrast is\nproposed. Finally, detection and OCR results for a commercial\nOCR are presented, justifying the choice of the binarisation\ntechnique."
            },
            "slug": "Extraction-and-recognition-of-artificial-text-in-Wolf-Jolion",
            "title": {
                "fragments": [],
                "text": "Extraction and recognition of\nartificial text in multimedia documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm to localise artificial text in images and videos using a measure of accumulated gradients and morphological processing and a new technique for the binarisation of the text boxes based on a criterion maximizing local contrast is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Formal Pattern Analysis & Applications"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48764203"
                        ],
                        "name": "Victor Wu",
                        "slug": "Victor-Wu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3420ab835c1af02071364b1f4e0f69abf733d88c",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many applications in which the automatic detection and recognition of text embedded in images is useful. These applications include digad libraries, multimedia systems, and Geographical Information Systems. When machine generated text is prdnted against clean backgrounds, it can be converted to a computer readable form (ASCII) using current Optical Character Recognition (OCR) technology. However, text is often printed against shaded or textured backgrounds or is embedded in images. Examples include maps, advertisements, photographs, videos and stock certificates. Current document segmentation and recognition technologies cannot handle these situafons well. In this paper, a four-step system which automaticnlly detects and extracts text in images i& proposed. First, a texture segmentation scheme is used to focus attention on regions where text may occur. Second, strokes are extracted from the segmented text regions. Using reasonable heuristics on text strings such as height similarity, spacing and alignment, the extracted strokes are then processed to form rectangular boxes surrounding the corresponding ttzt strings. To detect text over a wide range of font sizes, the above steps are first applied to a pyramid of images generated from the input image, and then the boxes formed at each resolution level of the pyramid are fused at the image in the original resolution level. Third, text is extracted by cleaning up the background and binarizing the detected ted strings. Finally, better text bounding boxes are generated by srsiny the binarized text as strokes. Text is then cleaned and binarized from these new boxes, and can then be passed through a commercial OCR engine for recognition if the text is of an OCR-recognizable font. The system is stable, robust, and works well on imayes (with or without structured layouts) from a wide van\u2019ety of sources, including digitized video frames, photographs, *This material is based on work supported in part by the National Science Foundation, Library of Congress and Department of Commerce under cooperative agreement number EEC9209623, in part by the United States Patent and mademark Office and Defense Advanced Research Projects Agency/IT0 under ARPA order number D468, issued by ESC/AXS contract number F19628-96-C-0235, in part by the National Science Foundation under grant number IF&9619117 and in part by NSF Multimedia CDA-9502639. Any opinions, findings and conclusions or recommendations expressed in this material are the author(s) and do not necessarily reflect those of the sponsors. Prrmission to make digital/hard copies ofall or part oflhis material for personal or clrrssroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage, the copyright notice, the title ofthe publication and its date appear, and notice is given that copyright is by permission of the ACM, Inc. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires specific permission and/or fe DL 97 Philadelphia PA, USA Copyright 1997 AChi 0-89791~868-1197/7..$3.50 newspapers, advertisements, stock certifimtes, and personal checks. All parameters remain the same for-all the experiments."
            },
            "slug": "Finding-text-in-images-Wu-Manmatha",
            "title": {
                "fragments": [],
                "text": "Finding text in images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A four-step system which automaticnlly detects and extracts text in images is proposed and works well on imayes (with or without structured layouts) from a wide range of sources, including digitized video frames, photographs, and personal checks."
            },
            "venue": {
                "fragments": [],
                "text": "DL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739319"
                        ],
                        "name": "R. Lienhart",
                        "slug": "R.-Lienhart",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Lienhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lienhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32544716"
                        ],
                        "name": "Axel Wernicke",
                        "slug": "Axel-Wernicke",
                        "structuredName": {
                            "firstName": "Axel",
                            "lastName": "Wernicke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Axel Wernicke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 143774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8387d4998f810cd2b60bd81545cb993087bc8788",
            "isKey": false,
            "numCitedBy": 467,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Many images, especially those used for page design on Web pages, as well as videos contain visible text. If these text occurrences could be detected, segmented, and recognized automatically, they would be a valuable source of high-level semantics for indexing and retrieval. We propose a novel method for localizing and segmenting text in complex images and videos. Text lines are identified by using a complex-valued multilayer feed-forward network trained to detect text at a fixed scale and position. The network's output at all scales and positions is integrated into a single text-saliency map, serving as a starting point for candidate text lines. In the case of video, these candidate text lines are refined by exploiting the temporal redundancy of text in video. Localized text lines are then scaled to a fixed height of 100 pixels and segmented into a binary image with black characters on white background. For videos, temporal redundancy is exploited to improve segmentation performance. Input images and videos can be of any size due to a true multiresolution approach. Moreover, the system is not only able to locate and segment text occurrences into large binary images, but is also able to track each text line with sub-pixel accuracy over the entire occurrence in a video, so that one text bitmap is created for all instances of that text line. Therefore, our text segmentation results can also be used for object-based video encoding such as that enabled by MPEG-4."
            },
            "slug": "Localizing-and-segmenting-text-in-images-and-videos-Lienhart-Wernicke",
            "title": {
                "fragments": [],
                "text": "Localizing and segmenting text in images and videos"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a novel method for localizing and segmenting text in complex images and videos that is not only able to locate and segment text occurrences into large binary images, but is also able to track each text line with sub-pixel accuracy over the entire occurrence in a video."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144899680"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680935"
                        ],
                        "name": "J. Jolion",
                        "slug": "J.-Jolion",
                        "structuredName": {
                            "firstName": "Jean-Michel",
                            "lastName": "Jolion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jolion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "23341564"
                        ],
                        "name": "F. Chassaing",
                        "slug": "F.-Chassaing",
                        "structuredName": {
                            "firstName": "Fran\u00e7oise",
                            "lastName": "Chassaing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Chassaing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15872163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b4f762d9a5acd964411d8c737073c24ce16a3c8",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The systems currently available for content based image and video retrieval work without semantic knowledge, i.e. they use image processing methods to extract low level features of the data. The similarity obtained by these approaches does not always correspond to the similarity a human user would expect. A way to include more semantic knowledge into the indexing process is to use the text included in the images and video sequences. It is rich in information but easy to use, e.g. by key word based queries. In this paper we present an algorithm to localize artificial text in images and videos using a measure of accumulated gradients and morphological post processing to detect the text. The quality of the localized text is improved by robust multiple frame integration. Anew technique for the binarization of the text boxes is proposed. Finally, detection and OCR results for a commercial OCR are presented."
            },
            "slug": "Text-localization,-enhancement-and-binarization-in-Wolf-Jolion",
            "title": {
                "fragments": [],
                "text": "Text localization, enhancement and binarization in multimedia documents"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An algorithm to localize artificial text in images and videos using a measure of accumulated gradients and morphological post processing to detect the text is presented and the quality of the localized text is improved by robust multiple frame integration."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155703534"
                        ],
                        "name": "Jing Zhang",
                        "slug": "Jing-Zhang",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772547"
                        ],
                        "name": "Xilin Chen",
                        "slug": "Xilin-Chen",
                        "structuredName": {
                            "firstName": "Xilin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xilin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2714754"
                        ],
                        "name": "Andreas Hanneman",
                        "slug": "Andreas-Hanneman",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Hanneman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Hanneman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7832131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b2b1e9755b1ff1fa2df74bd53212e8f0c0113fb",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a robust approach for recognition of text embedded in natural scenes. Instead of using binary information as most other OCR systems do, we extract features from intensity of an image directly. We utilize a local intensity normalization method to effectively handle lighting variations. We then employ Gabor transform to obtain local features, and use the linear discriminant analysis (LDA) for selection and classification of features. The proposed method has been applied to a Chinese sign recognition task. The system can recognize a vocabulary of 3755 level I Chinese characters in the Chinese national standard character set GB2312-80 with various print fonts. We tested the system on 1630 test characters in sign images captured from the natural scenes, and the recognition accuracy was 92.46%. We have integrated the system into our automatic Chinese sign translation system."
            },
            "slug": "A-robust-approach-for-recognition-of-text-embedded-Zhang-Chen",
            "title": {
                "fragments": [],
                "text": "A robust approach for recognition of text embedded in natural scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A robust approach for recognition of text embedded in natural scenes by utilizing a local intensity normalization method to effectively handle lighting variations and using the linear discriminant analysis (LDA) for selection and classification of features."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26648022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf5602a68463c39d46c60dadb76235338535a97e",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The accuracy of today's document recognition algorithms falls abruptly when image quality degrades even slightly. In an effort to surmount this barrier, researchers have in recent years intensified their study of explicit, quantitative, parameterized models of the image defects that occur during printing and scanning. The author reviews the recent literature and discusses the form these models might take. A preview of a large public-domain database of character images, labeled with ground-truth including all defect model parameters, is given. The use of massive pseudo-randomly generated training sets for the construction of high-performance decision trees for preclassification is described. In a more theoretical vein, the author reports preliminary results in the estimation of the intrinsic error of precisely-specified text recognition problems. Finally, the author calls attention to some open problems.<<ETX>>"
            },
            "slug": "Document-image-defect-models-and-their-uses-Baird",
            "title": {
                "fragments": [],
                "text": "Document image defect models and their uses"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The author reviews the recent literature on explicit, quantitative, parameterized models of the image defects that occur during printing and scanning, and reports preliminary results in the estimation of the intrinsic error of precisely-specified text recognition problems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144980901"
                        ],
                        "name": "F. Rahman",
                        "slug": "F.-Rahman",
                        "structuredName": {
                            "firstName": "Fuad",
                            "lastName": "Rahman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rahman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691429"
                        ],
                        "name": "M. Fairhurst",
                        "slug": "M.-Fairhurst",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fairhurst",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fairhurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22719391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83f3176b7bdf6fe5dfcc110161721ab0b90d6903",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 334,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.Two research strands, each identifying an area of markedly increasing importance in the current development of pattern analysis technology, underlie the review covered by this paper, and are drawn together to offer both a task-oriented and a fundamentally generic perspective on the discipline of pattern recognition. The first of these is the concept of decision fusion for high-performance pattern recognition, where (often very diverse) classification technologies, each providing complementary sources of information about class membership, can be integrated to provide more accurate, robust and reliable classification decisions. The second is the rapid expansion in technology for the automated analysis of (especially) handwritten data for OCR applications including document and form processing, pen-based computing, forensic analysis, biometrics and security, and many other areas, especially those which seek to provide online or offline processing of data which is available in a human-oriented medium. Classifier combination/multiple expert processing has a long history, but the sheer volume and diversity of possible strategies now available suggest that it is timely to consider a structured review of the field. Handwritten character processing provides an ideal context for such a review, both allowing engagement with a problem area which lends itself ideally to the performance enhancements offered by multi-classifier configurations, but also allowing a clearer focus to what otherwise, because of the unlimited application horizons, would be a task of unmanageable proportions. Hence, this paper explicitly reviews the field of multiple classifier decision combination strategies for character recognition, from some of its early roots to the present day. In order to give structure and a sense of direction to the review, a new taxonomy for categorising approaches is defined and explored, and this both imposes a discipline on the presentation of the material available and helps to clarify the mechanisms by which multi-classifier configurations deliver performance enhancements. The review incorporates a discussion both of processing structures themselves and a range of important related topics which are essential to maximise an understanding of the potential of such structures. Most importantly, the paper illustrates explicitly how the principles underlying the application of multi-classifier approaches to character recognition can easily generalise to a wide variety of different task domains."
            },
            "slug": "Multiple-classifier-decision-combination-strategies-Rahman-Fairhurst",
            "title": {
                "fragments": [],
                "text": "Multiple classifier decision combination strategies for character recognition: A review"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper explicitly reviews the field of multiple classifier decision combination strategies for character recognition, from some of its early roots to the present day and illustrates explicitly how the principles underlying the application of multi-classifier approaches to character recognition can easily generalise to a wide variety of different task domains."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis and Recognition"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054252"
                        ],
                        "name": "Ashok Popat",
                        "slug": "Ashok-Popat",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Popat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashok Popat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1091156,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40a94e440b9a0556b615491cbbfa6c6129b0cb49",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently initiated and rapidly developing research field of 'human interactive proofs' (HIPs) and its implications for the document image analysis (DIA) research field are described. Over the last five years, efforts to defend Web services against abuse by programs ('bots') have led to a new family of security protocols able to distinguish between human and machine users. AltaVista pioneered this technology in 1997 [Bro01, LBBB01]. By the summer of 2000, Yahoo! and PayPal were using similar methods. In the Fall of 2000, Prof. Manuel Blum of Carnegie-Mellon University and his team, stimulated by Udi Manber of Yahoo!, were studying these and related problems [BAL00]. Soon thereafter a collaboration between the University of California at Berkeley and the Palo Alto Research Center (PARC) built a tool based on systematically generated image degradations [CBF01]. In January 2002, Prof. Blum and the present authors ran the first workshop (at PARC) on HIPs, defined broadly as a class of challenge/response protocols which allow a human to authenticate herself as a member of a given group - e.g. human (vs. machine), herself (vs. anyone else), an adult (vs. a child), etc. All commercial uses of HIPs known to us exploit the gap in ability between human and machine vision systems in reading images of machine printed text. Many technical issues that have been systematically studied by the DIA community are relevant to the HIP research program. This paper describes the evolution of HIP R&D, applications of HIPs now and on the horizon, highlights of the first HIP workshop, and proposals for a DIA research agenda to advance the state of the art of HIPs."
            },
            "slug": "Human-Interactive-Proofs-and-Document-Image-Baird-Popat",
            "title": {
                "fragments": [],
                "text": "Human Interactive Proofs and Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The recently initiated and rapidly developing research field of 'human interactive proofs' (HIPs) and its implications for the document image analysis (DIA) research field are described."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780258"
                        ],
                        "name": "Jisheng Liang",
                        "slug": "Jisheng-Liang",
                        "structuredName": {
                            "firstName": "Jisheng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jisheng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1365695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e44015ab8d9ba89ac004421e3c56bcbeecbd0a47",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A performance evaluation protocol for the layout analysis is discussed in this paper. In the University of Washington English Document Image Database-III, there are 1600 English document images that come with manually edited ground truth of entity bounding boxes. These bounding boxes enclose text and non-text zones, text-lines, and words. We describe a performance metric for the comparison of the detected entities and the ground truth in terms of their bounding boxes. The Document Attribute Format Specification is used as the standard data representation. The protocol is intended to serve as a model for using the UW-III database to evaluate the document analysis algorithms. A set of layout analysis algorithms which detect different entities have been tested based on the data set and the performance metric. The evaluation results are presented in this paper."
            },
            "slug": "Performance-evaluation-of-document-layout-analysis-Liang-Phillips",
            "title": {
                "fragments": [],
                "text": "Performance evaluation of document layout analysis algorithms on the UW data set"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A performance metric is described for the comparison of the detected entities and the ground truth in terms of their bounding boxes and the evaluation results are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15780310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a74fe4e79add9de4803a825b6eae013215dfe7",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example. Binarization of scanned gray scale images is the first step in most document image analysis systems. Selection of an appropriate binarization method for an input image domain is a difficult problem. Typically, a human expert evaluates the binarized images according to his/her visual criteria. However, to conduct an objective evaluation, one needs to investigate how well the subsequent image analysis steps will perform on the binarized image. We call this approach goal-directed evaluation, and it can be used to evaluate other low-level image processing methods as well. Our evaluation of binarization methods is in the context of digit recognition, so we define the performance of the character recognition module as the objective measure. Eleven different locally adaptive binarization methods were evaluated, and Niblack's method gave the best performance."
            },
            "slug": "Goal-Directed-Evaluation-of-Binarization-Methods-Trier-Jain",
            "title": {
                "fragments": [],
                "text": "Goal-Directed Evaluation of Binarization Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example, and defines the performance of the character recognition module as the objective measure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1958744"
                        ],
                        "name": "M. Celenk",
                        "slug": "M.-Celenk",
                        "structuredName": {
                            "firstName": "Mehmet",
                            "lastName": "Celenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Celenk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 47568090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "997f5a236a4a7f26eaf673238d316dcb48e5f681",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-color-clustering-technique-for-image-segmentation-Celenk",
            "title": {
                "fragments": [],
                "text": "A color clustering technique for image segmentation"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Graph. Image Process."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069641275"
                        ],
                        "name": "Paul Clark",
                        "slug": "Paul-Clark",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728108"
                        ],
                        "name": "M. Mirmehdi",
                        "slug": "M.-Mirmehdi",
                        "structuredName": {
                            "firstName": "Majid",
                            "lastName": "Mirmehdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mirmehdi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6107789,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6d90dca820b48d607b9a70386066c5d1c543dc23",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method based on statistical properties of local image pixels for focussing attention on regions of text in arbitrary scenes where the text plane is not necessarily fronto-parallel to the camera. This is particularly useful for desktop or wearable computing applications. The statistical measures are chosen to reveal characteristic properties of text. We combine a number of localised measures using a neural network to classify each pixel as text or non-text. We demonstrate our results on typical images."
            },
            "slug": "Combining-statistical-measures-to-find-image-text-Clark-Mirmehdi",
            "title": {
                "fragments": [],
                "text": "Combining statistical measures to find image text regions"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A method based on statistical properties of local image pixels for focussing attention on regions of text in arbitrary scenes where the text plane is not necessarily fronto-parallel to the camera is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 15th International Conference on Pattern Recognition. ICPR-2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115196978"
                        ],
                        "name": "Huiping Li",
                        "slug": "Huiping-Li",
                        "structuredName": {
                            "firstName": "Huiping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272081"
                        ],
                        "name": "O. Kia",
                        "slug": "O.-Kia",
                        "structuredName": {
                            "firstName": "Omid",
                            "lastName": "Kia",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Kia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15485643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8f5c282dc11937d29183b955dc3e4fbb677571b",
            "isKey": false,
            "numCitedBy": 652,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Text that appears in a scene or is graphically added to video can provide an important supplemental source of index information as well as clues for decoding the video's structure and for classification. In this work, we present algorithms for detecting and tracking text in digital video. Our system implements a scale-space feature extractor that feeds an artificial neural processor to detect text blocks. Our text tracking scheme consists of two modules: a sum of squared difference (SSD)-based module to find the initial position and a contour-based module to refine the position. Experiments conducted with a variety of video sources show that our scheme can detect and track text robustly."
            },
            "slug": "Automatic-text-detection-and-tracking-in-digital-Li-Doermann",
            "title": {
                "fragments": [],
                "text": "Automatic text detection and tracking in digital video"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents algorithms for detecting and tracking text in digital video that implements a scale-space feature extractor that feeds an artificial neural processor to detect text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844464"
                        ],
                        "name": "L. Todoran",
                        "slug": "L.-Todoran",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Todoran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Todoran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7693618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7a5773cf378fe827c22a88825d278f8e93d491e",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Publications on color document image analysis present results on small, non-publicly available datasets. We propose in this paper a well defined and groundtruthed color dataset existing of over 1000 pages, with associated tools for evaluation. The color data groundtruthing and evaluation tools are based on a well defined document model, complexity measures to assess the inherent difficulty of analyzing a page, and well founded evaluation measures. Together they form a suitable basis for evaluating diverse applications in color document analysis."
            },
            "slug": "Data-GroundTruth,-Complexity,-and-Evaluation-for-Todoran-Worring",
            "title": {
                "fragments": [],
                "text": "Data GroundTruth, Complexity, and Evaluation Measures for Color Document Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A well defined and groundtruthed color dataset existing of over 1000 pages, with associated tools for evaluation, is proposed, which form a suitable basis for evaluating diverse applications in color document analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108438071"
                        ],
                        "name": "Jianqing Liu",
                        "slug": "Jianqing-Liu",
                        "structuredName": {
                            "firstName": "Jianqing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianqing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35964920"
                        ],
                        "name": "Yee-Hong Yang",
                        "slug": "Yee-Hong-Yang",
                        "structuredName": {
                            "firstName": "Yee-Hong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yee-Hong Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35812367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4145c995bd7fc3415d8a366a2bf25d100d7b9a9",
            "isKey": false,
            "numCitedBy": 557,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Image segmentation is the process by which an original image is partitioned into some homogeneous regions. In this paper, a novel multiresolution color image segmentation (MCIS) algorithm which uses Markov random fields (MRF's) is proposed. The proposed approach is a relaxation process that converges to the MAP (maximum a posteriori) estimate of the segmentation. The quadtree structure is used to implement the multiresolution framework, and the simulated annealing technique is employed to control the splitting and merging of nodes so as to minimize an energy function and therefore, maximize the MAP estimate. The multiresolution scheme enables the use of different dissimilarity measures at different resolution levels. Consequently, the proposed algorithm is noise resistant. Since the global clustering information of the image is required in the proposed approach, the scale space filter (SSF) is employed as the first step. The multiresolution approach is used to refine the segmentation. Experimental results of both the synthesized and real images are very encouraging. In order to evaluate experimental results of both synthesized images and real images quantitatively, a new evaluation criterion is proposed and developed. >"
            },
            "slug": "Multiresolution-Color-Image-Segmentation-Liu-Yang",
            "title": {
                "fragments": [],
                "text": "Multiresolution Color Image Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel multiresolution color image segmentation (MCIS) algorithm which uses Markov random fields (MRF's) is proposed, a relaxation process that converges to the MAP (maximum a posteriori) estimate of the segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118348443"
                        ],
                        "name": "Sang Ho Park",
                        "slug": "Sang-Ho-Park",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Park",
                            "middleNames": [
                                "Ho"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sang Ho Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785795"
                        ],
                        "name": "I. Yun",
                        "slug": "I.-Yun",
                        "structuredName": {
                            "firstName": "Il",
                            "lastName": "Yun",
                            "middleNames": [
                                "Dong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Yun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153310963"
                        ],
                        "name": "Sang Uk Lee",
                        "slug": "Sang-Uk-Lee",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Lee",
                            "middleNames": [
                                "Uk"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sang Uk Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39807094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09b699b5b43ec6b6aeb9848eaa8fe602e8a72c92",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Color-image-segmentation-based-on-3-D-clustering:-Park-Yun",
            "title": {
                "fragments": [],
                "text": "Color image segmentation based on 3-D clustering: morphological approach"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48764203"
                        ],
                        "name": "Victor Wu",
                        "slug": "Victor-Wu",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1830124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5c342ba0edbebadc7c95c7e59d1bef87d7e4add",
            "isKey": false,
            "numCitedBy": 451,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "A robust system is proposed to automatically detect and extract text in images from different sources, including video, newspapers, advertisements, stock certificates, photographs, and checks. Text is first detected using multiscale texture segmentation and spatial cohesion constraints, then cleaned up and extracted using a histogram-based binarization algorithm. An automatic performance evaluation scheme is also proposed."
            },
            "slug": "TextFinder:-An-Automatic-System-to-Detect-and-Text-Wu-Manmatha",
            "title": {
                "fragments": [],
                "text": "TextFinder: An Automatic System to Detect and Recognize Text In Images"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A robust system is proposed to automatically detect and extract text in images from different sources, including video, newspapers, advertisements, stock certificates, photographs, and checks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747625"
                        ],
                        "name": "D. Maio",
                        "slug": "D.-Maio",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Maio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687735"
                        ],
                        "name": "D. Maltoni",
                        "slug": "D.-Maltoni",
                        "structuredName": {
                            "firstName": "Davide",
                            "lastName": "Maltoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maltoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34592319"
                        ],
                        "name": "R. Cappelli",
                        "slug": "R.-Cappelli",
                        "structuredName": {
                            "firstName": "Raffaele",
                            "lastName": "Cappelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cappelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4348348"
                        ],
                        "name": "J. Wayman",
                        "slug": "J.-Wayman",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wayman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wayman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2896589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3aba7b3c1664d22d87463ff8cfd5f133339a130a",
            "isKey": false,
            "numCitedBy": 825,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Reliable and accurate fingerprint recognition is a challenging pattern recognition problem, requiring algorithms robust in many contexts. FVC2000 competition attempted to establish the first common benchmark, allowing companies and academic institutions to unambiguously compare performance and track improvements in their fingerprint recognition algorithms. Three databases were created using different state-of-the-art sensors and a fourth database was artificially generated; 11 algorithms were extensively tested on the four data sets. We believe that FVC2000 protocol, databases, and results will be useful to all practitioners in the field not only as a benchmark for improving methods, but also for enabling an unbiased evaluation of algorithms."
            },
            "slug": "FVC2000:-Fingerprint-Verification-Competition-Maio-Maltoni",
            "title": {
                "fragments": [],
                "text": "FVC2000: Fingerprint Verification Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This work states that the FVC2000 protocol, databases, and results will be useful to all practitioners in the field not only as a benchmark for improving methods, but also for enabling an unbiased evaluation of algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "LAG feature: The number and average length of path nodes in the LAG (line adjacency graph) [20] constructed for blobs are used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36776269,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c715fd808676921a84f248520925f8f5082cc83e",
            "isKey": false,
            "numCitedBy": 1164,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1: Introduction.- 1.1 Graphics, Image Processing, and Pattern Recognition.- 1.2 Forms of Pictorial Data.- 1.2.1 Class 1: Full Gray Scale and Color Pictures.- 1.2.2 Class 2: Bilevel or \"Few Color\" pictures.- 1.2.3 Class 3: Continuous Curves and Lines.- 1.2.4 Class 4: Points or Polygons.- 1.3 Pictorial Input.- 1.4 Display Devices.- 1.5 Vector Graphics.- 1.6 Raster Graphics.- 1.7 Common Primitive Graphic Instructions.- 1.8 Comparison of Vector and Raster Graphics.- 1.9 Pictorial Editor.- 1.10 Pictorial Transformations.- 1.11 Algorithm Notation.- 1.12 A Few Words on Complexity.- 1.13 Bibliographical Notes.- 1.14 Relevant Literature.- 1.15 Problems.- 2: Digitization of Gray Scale Images.- 2.1 Introduction.- 2.2 A Review of Fourier and other Transforms.- 2.3 Sampling.- 2.3.1 One-dimensional Sampling.- 2.3.2 Two-dimensional Sampling.- 2.4 Aliasing.- 2.5 Quantization.- 2.6 Bibliographical Notes.- 2.7 Relevant Literature.- 2.8 Problems.- Appendix 2.A: Fast Fourier Transform.- 3: Processing of Gray Scale Images.- 3.1 Introduction.- 3.2 Histogram and Histogram Equalization.- 3.3 Co-occurrence Matrices.- 3.4 Linear Image Filtering.- 3.5 Nonlinear Image Filtering.- 3.5.1 Directional Filters.- 3.5.2 Two-part Filters.- 3.5.3 Functional Approximation Filters.- 3.6 Bibliographical Notes.- 3.7 Relevant Literature.- 3.8 Problems.- 4: Segmentation.- 4.1 Introduction.- 4.2 Thresholding.- 4.3 Edge Detection.- 4.4 Segmentation by Region Growing.- 4.4.1 Segmentation by Average Brightness Level.- 4.4.2 Other Uniformity Criteria.- 4.5 Bibliographical Notes.- 4.6 Relevant Literature.- 4.7 Problems.- 5: Projections.- 5.1 Introduction.- 5.2 Introduction to Reconstruction Techniques.- 5.3 A Class of Reconstruction Algorithms.- 5.4 Projections for Shape Analysis.- 5.5 Bibliographical Notes.- 5.6 Relevant Literature.- 5.7 Problems.- Appendix 5.A: An Elementary Reconstruction Program.- 6: Data Structures.- 6.1 Introduction.- 6.2 Graph Traversal Algorithms.- 6.3 Paging.- 6.4 Pyramids or Quad Trees.- 6.4.1 Creating a Quad Tree.- 6.4.2 Reconstructing an Image from a Quad Tree.- 6.4.3 Image Compaction with a Quad Tree.- 6.5 Binary Image Trees.- 6.6 Split-and-Merge Algorithms.- 6.7 Line Encodings and the Line Adjacency Graph.- 6.8 Region Encodings and the Region Adjacency Graph.- 6.9 Iconic Representations.- 6.10 Data Structures for Displays.- 6.11 Bibliographical Notes.- 6.12 Relevant Literature.- 6.13 Problems.- Appendix 6.A: Introduction to Graphs.- 7: Bilevel Pictures.- 7.1 Introduction.- 7.2 Sampling and Topology.- 7.3 Elements of Discrete Geometry.- 7.4 A Sampling Theorem for Class 2 Pictures.- 7.5 Contour Tracing.- 7.5.1 Tracing of a Single Contour.- 7.5.2 Traversal of All the Contours of a Region.- 7.6 Curves and Lines on a Discrete Grid.- 7.6.1 When a Set of Pixels is not a Curve.- 7.6.2 When a Set of Pixels is a Curve.- 7.7 Multiple Pixels.- 7.8 An Introduction to Shape Analysis.- 7.9 Bibliographical Notes.- 7.10 Relevant Literature.- 7.11 Problems.- 8: Contour Filling.- 8.1 Introduction.- 8.2 Edge Filling.- 8.3 Contour Filling by Parity Check.- 8.3.1 Proof of Correctness of Algorithm 8.3.- 8.3.2 Implementation of a Parity Check Algorithm.- 8.4 Contour Filling by Connectivity.- 8.4.1 Recursive Connectivity Filling.- 8.4.2 Nonrecursive Connectivity Filling.- 8.4.3 Procedures used for Connectivity Filling.- 8.4.4 Description of the Main Algorithm.- 8.5 Comparisons and Combinations.- 8.6 Bibliographical Notes.- 8.7 Relevant Literature.- 8.8 Problems.- 9: Thinning Algorithms.- 9.1 Introduction.- 9.2 Classical Thinning Algorithms.- 9.3 Asynchronous Thinning Algorithms.- 9.4 Implementation of an Asynchronous Thinning Algorithm.- 9.5 A Quick Thinning Algorithm.- 9.6 Structural Shape Analysis.- 9.7 Transformation of Bilevel Images into Line Drawings.- 9.8 Bibliographical Notes.- 9.9 Relevant Literature.- 9.10 Problems.- 10: Curve Fitting and Curve Displaying.- 10.1 Introduction.- 10.2 Polynomial Interpolation.- 10.3 Bezier Polynomials.- 10.4 Computation of Bezier Polynomials.- 10.5 Some Properties of Bezier Polynomials.- 10.6 Circular Arcs.- 10.7 Display of Lines and Curves.- 10.7.1 Display of Curves through Differential Equations.- 10.7.2 Effect of Round-off Errors in Displays.- 10.8 A Point Editor.- 10.8.1 A Data Structure for a Point Editor.- 10.8.2 Input and Output for a Point Editor.- 10.9 Bibliographical Notes.- 10.10 Relevant Literature.- 10.11 Problems.- 11: Curve Fitting with Splines.- 11.1 Introduction.- 11.2 Fundamental Definitions.- 11.3 B-Splines.- 11.4 Computation with B-Splines.- 11.5 Interpolating B-Splines.- 11.6 B-Splines in Graphics.- 11.7 Shape Description and B-splines.- 11.8 Bibliographical Notes.- 11.9 Relevant Literature.- 11.10 Problems.- 12: Approximation of Curves.- 12.1 Introduction.- 12.2 Integral Square Error Approximation.- 12.3 Approximation Using B-Splines.- 12.4 Approximation by Splines with Variable Breakpoints.- 12.5 Polygonal Approximations.- 12.5.1 A Suboptimal Line Fitting Algorithm.- 12.5.2 A Simple Polygon Fitting Algorithm.- 12.5.3 Properties of Algorithm 12.2.- 12.6 Applications of Curve Approximation in Graphics.- 12.6.1 Handling of Groups of Points by a Point Editor.- 12.6.2 Finding Some Simple Approximating Curves.- 12.7 Bibliographical Notes.- 12.8 Relevant Literature.- 12.9 Problems.- 13: Surface Fitting and Surface Displaying.- 13.1 Introduction.- 13.2 Some Simple Properties of Surfaces.- 13.3 Singular Points of a Surface.- 13.4 Linear and Bilinear Interpolating Surface Patches.- 13.5 Lofted Surfaces.- 13.6 Coons Surfaces.- 13.7 Guided Surfaces.- 13.7.1 Bezier Surfaces.- 13.7.2 B-Spline Surfaces.- 13.8 The Choice of a Surface Partition.- 13.9 Display of Surfaces and Shading.- 13.10 Bibliographical Notes.- 13.11 Relevant Literature.- 13.12 Problems.- 14: The Mathematics of Two-Dimensional Graphics.- 14.1 Introduction.- 14.2 Two-Dimensional Transformations.- 14.3 Homogeneous Coordinates.- 14.3.1 Equation of a Line Defined by Two Points.- 14.3.2 Coordinates of a Point Defined as the Intersection of Two Lines.- 14.3.3 Duality.- 14.4 Line Segment Problems.- 14.4.1 Position of a Point with respect to a Line.- 14.4.2 Intersection of Line Segments.- 14.4.3 Position of a Point with respect to a Polygon.- 14.4.4 Segment Shadow.- 14.5 Bibliographical Notes.- 14.6 Relevant Literature.- 14.7 Problems.- 15: Polygon Clipping.- 15.1 Introduction.- 15.2 Clipping a Line Segment by a Convex Polygon.- 15.3 Clipping a Line Segment by a Regular Rectangle.- 15.4 Clipping an Arbitrary Polygon by a Line.- 15.5 Intersection of Two Polygons.- 15.6 Efficient Polygon Intersection.- 15.7 Bibliographical Notes.- 15.8 Relevant Literature.- 15.9 Problems.- 16: The Mathematics of Three-Dimensional Graphics.- 16.1 Introduction.- 16.2 Homogeneous Coordinates.- 16.2.1 Position of a Point with respect to a Plane.- 16.2.2 Intersection of Triangles.- 16.3 Three-Dimensional Transformations.- 16.3.1 Mathematical Preliminaries.- 16.3.2 Rotation around an Axis through the Origin.- 16.4 Orthogonal Projections.- 16.5 Perspective Projections.- 16.6 Bibliographical Notes.- 16.7 Relevant Literature.- 16.8 Problems.- 17: Creating Three-Dimensional Graphic Displays.- 17.1 Introduction.- 17.2 The Hidden Line and Hidden Surface Problems.- 17.2.1 Surface Shadow.- 17.2.2 Approaches to the Visibility Problem.- 17.2.3 Single Convex Object Visibility.- 17.3 A Quad Tree Visibility Algorithm.- 17.4 A Raster Line Scan Visibility Algorithm.- 17.5 Coherence.- 17.6 Nonlinear Object Descriptions.- 17.7 Making a Natural Looking Display.- 17.8 Bibliographical Notes.- 17.9 Relevant Literature.- 17.10 Problems.- Author Index.- Algorithm Index."
            },
            "slug": "Algorithms-for-Graphics-and-Image-Processing-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Algorithms for Graphics and Image Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This chapter discusses Graphics, Image Processing, and Pattern Recognition, and the Reconstruction techniques used in this program, as well as some of the problems faced in implementing this program."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2673919"
                        ],
                        "name": "V. Mariano",
                        "slug": "V.-Mariano",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Mariano",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Mariano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3054467"
                        ],
                        "name": "J. Min",
                        "slug": "J.-Min",
                        "structuredName": {
                            "firstName": "Junghye",
                            "lastName": "Min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109375307"
                        ],
                        "name": "J. Park",
                        "slug": "J.-Park",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Park",
                            "middleNames": [
                                "Hyeong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082032608"
                        ],
                        "name": "David Mihalcik",
                        "slug": "David-Mihalcik",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mihalcik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mihalcik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115196978"
                        ],
                        "name": "Huiping Li",
                        "slug": "Huiping-Li",
                        "structuredName": {
                            "firstName": "Huiping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8050430"
                        ],
                        "name": "Thomas Drayer",
                        "slug": "Thomas-Drayer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Drayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Drayer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19509530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fc7be0f43a4fef1ae24420d1a5216f8dfd41d4b",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The continuous development of object detection algorithms is ushering in the need for evaluation tools to quantify algorithm performance. In this paper a set of seven metrics are proposed for quantifying different aspects of a detection algorithm's performance. The strengths and weaknesses of these metrics are described. They are implemented in the Video Performance Evaluation Resource (ViPER) system and will be used to evaluate algorithms for detecting text, faces, moving people and vehicles. Results for running two previous text-detection algorithms on a common data set are presented."
            },
            "slug": "Performance-evaluation-of-object-detection-Mariano-Min",
            "title": {
                "fragments": [],
                "text": "Performance evaluation of object detection algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A set of seven metrics are proposed for quantifying different aspects of a detection algorithm's performance and will be used to evaluate algorithms for detecting text, faces, moving people and vehicles."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815031"
                        ],
                        "name": "S. Lucas",
                        "slug": "S.-Lucas",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Lucas",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lucas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12248961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7863814f31546630422c46a4ecc52ae29cc9737c",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a framework for the automatic Web-based evaluation and deployment of pattern recognizers. Several usage modes are identified and the issues and tradeoffs involved in designing Web-based evaluation systems are discussed. The system operates by exchanging XML messages between a recognition client and an evaluation server. HTTP POST is used for message exchange, which works through most firewalls. To use the system a researcher downloads a simple evaluation client, and then uses this client to invoke their recognizer. The recognizer must implement a simple problem-specific interface. The system is illustrated with the aid of a sequence recognition example."
            },
            "slug": "Web-based-evaluation-and-deployment-of-pattern-Lucas",
            "title": {
                "fragments": [],
                "text": "Web-based evaluation and deployment of pattern recognizers"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A framework for the automatic Web-based evaluation and deployment of pattern recognizers is described, which operates by exchanging XML messages between a recognition client and an evaluation server."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809629"
                        ],
                        "name": "N. Otsu",
                        "slug": "N.-Otsu",
                        "structuredName": {
                            "firstName": "Nobuyuki",
                            "lastName": "Otsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Otsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15326934,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1d4816c612e38dac86f2149af667a5581686cdef",
            "isKey": false,
            "numCitedBy": 32882,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A nonparametric and unsupervised method ofautomatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zerothand the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method."
            },
            "slug": "A-threshold-selection-method-from-gray-level-Otsu",
            "title": {
                "fragments": [],
                "text": "A threshold selection method from gray level histograms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60282629,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2",
            "isKey": false,
            "numCitedBy": 4399,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Disclosed is an improved articulated bar flail having shearing edges for efficiently shredding materials. An improved shredder cylinder is disclosed with a plurality of these flails circumferentially spaced and pivotally attached to the periphery of a rotatable shaft. Also disclosed is an improved shredder apparatus which has a pair of these shredder cylinders mounted to rotate about spaced parallel axes which cooperates with a conveyer apparatus which has a pair of inclined converging conveyer belts with one of the belts mounted to move with respect to the other belt to allow the transport of articles of various sizes therethrough."
            },
            "slug": "The-mnist-database-of-handwritten-digits-LeCun-Cortes",
            "title": {
                "fragments": [],
                "text": "The mnist database of handwritten digits"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An improved articulated bar flail having shearing edges for efficiently shredding materials and an improved shredder cylinder with a plurality of these flails circumferentially spaced and pivotally attached to the periphery of a rotatable shaft are disclosed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4929024"
                        ],
                        "name": "J. Bezdek",
                        "slug": "J.-Bezdek",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bezdek",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bezdek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30806637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24a85e28954871d30ebefac06b459f8c2701e7a0",
            "isKey": false,
            "numCitedBy": 15533,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "New updated! The latest book from a very famous author finally comes out. Book of pattern recognition with fuzzy objective function algorithms, as an amazing reference becomes what you need to get. What's for is this book? Are you still thinking for what the book is? Well, this is what you probably will get. You should have made proper choices for your better life. Book, as a source that may involve the facts, opinion, literature, religion, and many others are the great friends to join with."
            },
            "slug": "Pattern-Recognition-with-Fuzzy-Objective-Function-Bezdek",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition with Fuzzy Objective Function Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Books, as a source that may involve the facts, opinion, literature, religion, and many others are the great friends to join with, becomes what you need to get."
            },
            "venue": {
                "fragments": [],
                "text": "Advanced Applications in Pattern Recognition"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1452625728"
                        ],
                        "name": "G. Bieber",
                        "slug": "G.-Bieber",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Bieber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bieber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In future it would require much less effort if we could run these competitions by using an alternative mode of entry, where each competitor exposes their system as a Web service [ 4 , 15] which they would be responsible for maintaining."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59736370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbf7fc55a97f3c4501b6e7e70c04a0c9b9fb6240",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A new programming paradigm is forming throughout the software industry. This paradigm is driven by the exploitation of networking technology and the need to be able to create more powerful capabilities more quickly. The diversity in languages, middleware, and platforms has prevented larger constructs from being formed and the shortage of qualified software engineers only aggravates the problem. The inception of the Service-Oriented Programming (SOP) paradigm is being defined throughout the industry including: Sun\u2019s JiniTM, OpenwingsTM, Microsoft\u2019s. NETTM, and HP\u2019s CoolTownTM. Much like the early days of Object-Oriented Programming (OOP), certain characteristics of SOP are covered by some implementations, but no one approach covers all of them. Until the key features of OOP (encapsulation, inheritance, and polymorphism) and a design methodology (OOA/OOD) had been defined, consistency in OOP programming models was not achieved. This paper analyzes Service-Oriented technologies to identify the key characteristics and patterns of SOP, and demonstrates the value of SOP to developers and end users."
            },
            "slug": "Introduction-to-Service-Oriented-Programming-Bieber",
            "title": {
                "fragments": [],
                "text": "Introduction to Service-Oriented Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper analyzes Service-Oriented technologies to identify the key characteristics and patterns of Sop, and demonstrates the value of SOP to developers and end users."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Additionally, in order to distinguish character patterns from background ones, we use a Support Vector Machine (SVM) [5,25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1452625728"
                        ],
                        "name": "G. Bieber",
                        "slug": "G.-Bieber",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Bieber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bieber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19005934,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "988eb06972d3dc1335f7b266883b853af7ccbd20",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A new programming paradigm is forming throughout the software industry. This paradigm is driven by the exploitation of networking technology and the need to be able to create more powerful capabilities more quickly. The diversity in languages, middleware, and platforms has prevented larger constructs from being formed and the shortage of qualified software engineers only aggravates the problem. The inception of the Service-Oriented Programming (SOP) paradigm is being defined throughout the industry including: Sun\u2019s JiniTM, OpenwingsTM, Microsoft\u2019s. NETTM, and HP\u2019s CoolTownTM. Much like the early days of Object-Oriented Programming (OOP), certain characteristics of SOP are covered by some implementations, but no one approach covers all of them. Until the key features of OOP (encapsulation, inheritance, and polymorphism) and a design methodology (OOA/OOD) had been defined, consistency in OOP programming models was not achieved. This paper analyzes Service-Oriented technologies to identify the key characteristics and patterns of SOP, and demonstrates the value of SOP to developers and end users."
            },
            "slug": "Introduction-to-Service-Oriented-Programming-(-Rev-Bieber",
            "title": {
                "fragments": [],
                "text": "Introduction to Service-Oriented Programming ( Rev 2 . 1 ) by Guy Bieber , Lead Architect , Motorola ISD Jeff Carpenter , Software Engineer , Motorola ISD"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper analyzes Service-Oriented technologies to identify the key characteristics and patterns of Sop, and demonstrates the value of SOP to developers and end users."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8952183,
            "fieldsOfStudy": [
                "Economics",
                "Education"
            ],
            "id": "7141ea996fc449807b14c071716cecac0999f4ce",
            "isKey": false,
            "numCitedBy": 985,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Keywords: learning Reference EPFL-REPORT-82604 URL: http://publications.idiap.ch/downloads/reports/2000/rr00-17.pdf Record created on 2006-03-10, modified on 2017-05-10"
            },
            "slug": "SVMTorch:-Support-Vector-Machines-for-Large-Scale-Collobert-Bengio",
            "title": {
                "fragments": [],
                "text": "SVMTorch: Support Vector Machines for Large-Scale Regression Problems"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073418410"
                        ],
                        "name": "Christian Wolf",
                        "slug": "Christian-Wolf",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104004920"
                        ],
                        "name": "J.-M. Jolion",
                        "slug": "J.-M.-Jolion",
                        "structuredName": {
                            "firstName": "J.-M.",
                            "lastName": "Jolion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J.-M. Jolion"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 185313516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef2ed6b534d7677d62686e9192acff249244af14",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extraction-d'informations-textuelles-contenues-dans-Wolf-Jolion",
            "title": {
                "fragments": [],
                "text": "Extraction d'informations textuelles contenues dans les images et les s\u00e9quences audio-visuelles par une approche de type machine \u00e0 vecteurs supports"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59904188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f780f4c90e9549abc32abc0e26001e7e048599ba",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithms-for-Graphics-and-Imag-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Algorithms for Graphics and Imag"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34993677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73bf7b2fdb26498c05896d99fee4b8f3608c3bd6",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-text-location-in-images-and-video-frames-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Automatic text location in images and video frames"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The CAPTCHA project"
            },
            "venue": {
                "fragments": [],
                "text": "The CAPTCHA project"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Introduction to service-oriented pro- gramming (rev 2.1)"
            },
            "venue": {
                "fragments": [],
                "text": "Introduction to service-oriented pro- gramming (rev 2.1)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The open mind initiative"
            },
            "venue": {
                "fragments": [],
                "text": "The open mind initiative"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Manber U The CAPTCHA project"
            },
            "venue": {
                "fragments": [],
                "text": "Manber U The CAPTCHA project"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 20
                            }
                        ],
                        "text": "The first algorithm [33, 30] assumes that there is text present in the image and tries to separate the text from the non-text pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc  \u00e9d\u0301e de d\u0301etection de zones de texte dans une image vid\u0301eo"
            },
            "venue": {
                "fragments": [],
                "text": "Patent France T  \u00e9l\u00e9com, Ref.No. FR 01 06776, June"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text detection in images taken from videos sequences for semantic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Institut National de Sciences Appliqu\u00e9es de Lyon Proc\u00e9d\u00e9 de d\u00e9tection de zones de texte dans une image vid\u00e9o. Patent France T\u00e9l\u00e9com, Ref. No. FR 01 06776"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Additionally, we use a conditional morphological operation on the connected components which is based on a CCA (connected component analysis) algorithm [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic text location in images and video frame. Pattern Recog"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 22
                            }
                        ],
                        "text": "2 The first algorithm [28, 31] assumes that there is text present in the image and tries to separate the text from the non-text pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc\u00e9d\u00e9 de d\u00e9tection de zones de texte dans une image vid\u00e9o"
            },
            "venue": {
                "fragments": [],
                "text": "Patent France Te\u0301le\u0301com, Ref. No. FR"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 41,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/ICDAR-2003-robust-reading-competitions:-entries,-Lucas-Panaretos/a01deac56a81646e8d84cb7bf2d905714ff00808?sort=total-citations"
}