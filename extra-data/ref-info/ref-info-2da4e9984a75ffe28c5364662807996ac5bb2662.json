{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "If a supervision signal indicates the invariant properties, or self-supervision between successive time steps is applied, then backpropagation can also give rise to invariant feature detectors without explicit weight sharing ( Hinton 1987 )."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 226
                            }
                        ],
                        "text": "If a supervision signal indicates the invariant properties, or self-supervision between successive time steps is applied, then backpropagation can also give rise to invariant feature detectors without explicit weight sharing (Hinton 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 227369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e6bea2649298c68d17b9421fc7dd19eeacc935e",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "One major goal of research on massively parallel networks of neuron-like processing elements is to discover efficient methods for recognizing patterns. Another goal is to discover general learning procedures that allow networks to construct the internal representations that are required for complex tasks. This paper describes a recently developed procedure that can learn to perform a recognition task. The network is trained on examples in which the input vector represents an instance of a pattern in a particular position and the required output vector represents its name. After prolonged training, the network develops canonical internal representations of the patterns and it uses these canonical representations to identify familiar patterns in novel positions."
            },
            "slug": "Learning-Translation-Invariant-Recognition-in-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning Translation Invariant Recognition in Massively Parallel Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes a recently developed procedure that can learn to perform a recognition task and uses canonical internal representations of the patterns to identify familiar patterns in novel positions."
            },
            "venue": {
                "fragments": [],
                "text": "PARLE"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 82
                            }
                        ],
                        "text": "This idea is consistent with models of complex cells in the primary visual cortex (Hubel and Wiesel 1962; Spitzer and Hochstein 1985) in that they assume that complex cells receive their major inputs from simple cells or simple-cell-like subunits selective for the same orientation in different positions."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 109
                            }
                        ],
                        "text": "Complex cells in the primary visual cortex exhibit approximate invariance to position within a limited range (Hubel and Wiesel 1962), while cells in higher visual areas in the temporal cortex show more complex forms of invariance to rotation, color, size, and distance, and they also have much larger receptive fields (Gross and Mishkin 1977, Perrett et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 110
                            }
                        ],
                        "text": "Complex cells in the primary visual cortex exhibit approximate invariance to position within a limited range (Hubel and Wiesel 1962), while cells in higher visual areas in the temporal cortex show more complex forms of invariance to rotation, color, size, and distance, and they also have much\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 83
                            }
                        ],
                        "text": "This idea is consistent with models of complex cells in the primary visual cortex (Hubel and Wiesel 1962; Spitzer and Hochstein 1985) in that they assume that complex cells receive their major inputs from simple cells or simple-cell-like subunits selective for the same orientation in different\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 17055992,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7",
            "isKey": true,
            "numCitedBy": 12432,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "What chiefly distinguishes cerebral cortex from other parts of the central nervous system is the great diversity of its cell types and interconnexions. It would be astonishing if such a structure did not profoundly modify the response patterns of fibres coming into it. In the cat's visual cortex, the receptive field arrangements of single cells suggest that there is indeed a degree of complexity far exceeding anything yet seen at lower levels in the visual system. In a previous paper we described receptive fields of single cortical cells, observing responses to spots of light shone on one or both retinas (Hubel & Wiesel, 1959). In the present work this method is used to examine receptive fields of a more complex type (Part I) and to make additional observations on binocular interaction (Part II). This approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours. In the past, the technique of recording evoked slow waves has been used with great success in studies of functional anatomy. It was employed by Talbot & Marshall (1941) and by Thompson, Woolsey & Talbot (1950) for mapping out the visual cortex in the rabbit, cat, and monkey. Daniel & Whitteiidge (1959) have recently extended this work in the primate. Most of our present knowledge of retinotopic projections, binocular overlap, and the second visual area is based on these investigations. Yet the method of evoked potentials is valuable mainly for detecting behaviour common to large populations of neighbouring cells; it cannot differentiate functionally between areas of cortex smaller than about 1 mm2. To overcome this difficulty a method has in recent years been developed for studying cells separately or in small groups during long micro-electrode penetrations through nervous tissue. Responses are correlated with cell location by reconstructing the electrode tracks from histological material. These techniques have been applied to"
            },
            "slug": "Receptive-fields,-binocular-interaction-and-in-the-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is used to examine receptive fields of a more complex type and to make additional observations on binocular interaction and this approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48351139"
                        ],
                        "name": "C. J. Webber",
                        "slug": "C.-J.-Webber",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Webber",
                            "middleNames": [
                                "J.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Webber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14149426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "caab93eccadfcb83cbe8a0f0eb33460c75154eda",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of shift tolerance and deformation tolerance in neural representation is discussed with reference to a prototypical paradigm, which summarizes the essential problem of representation of a distribution of input patterns containing features that are distributed uniformly throughout an image space and that are subject to variation in form. A form of sparse, local representation is proposed in which the position of a feature is localized with precision proportional to the extent of the representation's tolerance to deformation of the feature, which in turn reflects the extent to which the form of that feature is subject to variation over the probability distribution of input patterns. A local self-organizing mechanism is described which inevitably generates representations of this form, regardless of the initial configuration of the synaptic strength parameters. The form of the representation established by this mechanism is unaffected by the inclusion of superfluous representation units: the ..."
            },
            "slug": "Self-organization-of-position-and-neural-Webber",
            "title": {
                "fragments": [],
                "text": "Self-organization of position- and deformation-tolerant neural representations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A form of sparse, local representation is proposed in which the position of a feature is localized with precision proportional to the extent of the representation's tolerance to deformation of the feature, which in turn reflects the extent to which the form of that feature is subject to variation over the probability distribution of input patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666307"
                        ],
                        "name": "G. Mitchison",
                        "slug": "G.-Mitchison",
                        "structuredName": {
                            "firstName": "Graeme",
                            "lastName": "Mitchison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mitchison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 111
                            }
                        ],
                        "text": "Where no such detectors are available, other learning rules, based on temporal sequences or variation in form (Mitchison 1991, Webber 1991) may be able to find stable representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13531615,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2eadcb6fb0c285ef361fcec080979dc336e1df79",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "I describe a local synaptic learning rule that can be used to remove the effects of certain types of systematic temporal variation in the inputs to a unit. According to this rule, changes in synaptic weight result from a conjunction of short-term temporal changes in the inputs and the output. Formally, This is like the differential rule proposed by Klopf (1986) and Kosko (1986), except for a change of sign, which gives it an anti-Hebbian character. By itself this rule is insufficient. A weight conservation condition is needed to prevent the weights from collapsing to zero, and some further constraintimplemented here by a biasing termto select particular sets of weights from the subspace of those which give minimal variation. As an example, I show that this rule will generate center-surround receptive fields that remove temporally varying linear gradients from the inputs."
            },
            "slug": "Removing-Time-Variation-with-the-Anti-Hebbian-Mitchison",
            "title": {
                "fragments": [],
                "text": "Removing Time Variation with the Anti-Hebbian Differential Synapse"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A local synaptic learning rule is described that can be used to remove the effects of certain types of systematic temporal variation in the inputs to a unit and will generate center-surround receptive fields that remove temporally varying linear gradients from the inputs."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367447"
                        ],
                        "name": "H. Spitzer",
                        "slug": "H.-Spitzer",
                        "structuredName": {
                            "firstName": "Hedva",
                            "lastName": "Spitzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Spitzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050059"
                        ],
                        "name": "S. Hochstein",
                        "slug": "S.-Hochstein",
                        "structuredName": {
                            "firstName": "Shaul",
                            "lastName": "Hochstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochstein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 118
                            }
                        ],
                        "text": "This idea is consistent with models of complex cells in the primary visual cortex (Hubel and Wiesel 1962; Spitzer and Hochstein 1985) in that they assume that complex cells receive their major inputs from simple cells or simple-cell-like subunits selective for the same orientation in different\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 29608336,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f7fc4715df4bad110af72455d3885b6e35a08c9d",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The time course of the response of a single cortical neuron to counterphase-grating stimulation may vary as a function of stimulation parameters, as shown in the preceding paper (19). The poststimulus-time histograms of the response amplitudes against time are single or double peaked, and where double peaked, the two peaks are of equal or unequal amplitudes. Furthermore, the spatial-phase dependence of cortical complex-cell responses may be a function of spatial frequency, so that the receptive field appears to have linear spatial summation at some spatial frequencies and nonlinear spatial summation at others (19). In the first part of this paper, we analyze a model receptive field that displays this behavior, and in the second part experimental data are presented and analyzed with regard to the model. The model cortical receptive field in its simplest form contains (two rows) of geniculate X-cell-like, DOG (difference-of-Gaussians)-shaped, center-surround antagonistic, circular-input subunits. We propose nonlinear summation between these two subunits, by introducing a half-wave rectification stage before pooling. The model is tested for the responses it predicts for the application of counterphase-grating stimulation. This simple model predicts the appearance of three response forms as a function of counterphase-stimulation parameters. At periodic spatial frequencies the expected-response histogram has a single peak, whose amplitude has a sinusoidal dependence on spatial phase. At spatial frequencies halfway between these, the expected-response histogram has two equal peaks whose amplitudes have a full-wave rectified sinusoidal dependence on spatial phase. At all intermediate spatial frequencies the expected-response histogram has a \"mixed\" form; the histogram appears sometimes with one peak, sometimes with two equal peaks, and generally with two peaks of unequal amplitude, as a function of spatial phase. Null responses are expected to appear at specific spatial phases only for the periodic spatial frequencies that give \"pure\" response time courses as in paragraph 5 above, and not in the more common mixed response case of paragraph 6. The analysis procedure described in the preceding paper (19) is used, separating the odd and even Fourier components of the response histograms reflecting the receptive-field intrasubunit linear summation and intersubunit nonlinear summation, respectively. We propose that this model may be used as a working hypothesis for the analysis of these aspects of the various cortical receptive-field types. Experimental data are described and discussed in terms of the model.(ABSTRACT TRUNCATED AT 400 WORDS)"
            },
            "slug": "A-complex-cell-receptive-field-model.-Spitzer-Hochstein",
            "title": {
                "fragments": [],
                "text": "A complex-cell receptive-field model."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This model may be used as a working hypothesis for the analysis of these aspects of the various cortical receptive-field types as well as for the tests for the responses it predicts for the application of counterphase-grating stimulation."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18100780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb4bad84a2fd896edfa4f5c22061b2913fec500d",
            "isKey": false,
            "numCitedBy": 1446,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-discovery-by-competitive-learning-Rumelhart-Zipser",
            "title": {
                "fragments": [],
                "text": "Feature discovery by competitive learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7833,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 211
                            }
                        ],
                        "text": "A second, decay term is added in order to keep the weight vector bounded:\nAwi$\u2019 = ay!t)(zjt) - +)\nwhere\nA similar trace mechanism has been proposed by Klopf (1982) and used in models of classical conditioning by Sutton and Barto (1981)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar trace mechanism has been proposed by Klopf (1982) and used in models of classical conditioning by  Sutton and Barto (1981) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2831441,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "60944c5243db70a687a320a2622d3bd1610802a8",
            "isKey": false,
            "numCitedBy": 1448,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "Many adaptive neural network theories are based on neuronlike adaptive elements that can behave as single unit analogs of associative conditioning. In this article we develop a similar adaptive element, but one which is more closely in accord with the facts of animal learning theory than elements commonly studied in adaptive network research. We suggest that an essential feature of classical conditioning that has been largely overlooked by adaptive network theorists is its predictive nature. The adaptive element we present learns to increase its response rate in anticipation of increased stimulation, producing a conditioned response before the occurrence of the unconditioned stimulus. The element also is in strong agreement with the behavioral data regarding the effects of stimulus context, since it is a temporally refined extension of the Rescorla-Wagner model. We show by computer simulation that the element becomes sensitive to the most reliable, nonredundant, and earliest predictors of reinforcement . We also point out that the model solves many of the stability and saturation problems encountered in network simulations. Finally, we discuss our model in light of recent advances in the physiology and biochemistry of synaptic mechanisms."
            },
            "slug": "Toward-a-modern-theory-of-adaptive-networks:-and-Sutton-Barto",
            "title": {
                "fragments": [],
                "text": "Toward a modern theory of adaptive networks: expectation and prediction."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The adaptive element presented learns to increase its response rate in anticipation of increased stimulation, producing a conditioned response before the occurrence of the unconditioned stimulus, and is in strong agreement with the behavioral data regarding the effects of stimulus context."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2385092"
                        ],
                        "name": "C. Gross",
                        "slug": "C.-Gross",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gross",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gross"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124503009,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "650e8da386a3e630fb2b6920934cc8b96cbccac6",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "7-\u2013-The-Neural-Basis-of-Stimulus-Equivalence-Across-Gross",
            "title": {
                "fragments": [],
                "text": "7 \u2013 The Neural Basis of Stimulus Equivalence Across Retinal Translation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50040640"
                        ],
                        "name": "J. S. Edwards",
                        "slug": "J.-S.-Edwards",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Edwards",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. S. Edwards"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62179641,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "655135070ffdb6c08d70c74ea7071f8b797764ab",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Hedonistic-Neuron:-A-Theory-of-Memory,-Learning-Edwards",
            "title": {
                "fragments": [],
                "text": "The Hedonistic Neuron: A Theory of Memory, Learning and Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144246983"
                        ],
                        "name": "H. Barlow",
                        "slug": "H.-Barlow",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Barlow",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barlow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858054"
                        ],
                        "name": "P. F\u00f6ldi\u00e1k",
                        "slug": "P.-F\u00f6ldi\u00e1k",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "F\u00f6ldi\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F\u00f6ldi\u00e1k"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60513567,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "7947b19f7d5488b8d76664c8b2d70daff350babd",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptation-and-decorrelation-in-the-cortex-Barlow-F\u00f6ldi\u00e1k",
            "title": {
                "fragments": [],
                "text": "Adaptation and decorrelation in the cortex"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 76
                            }
                        ],
                        "text": "For the sake of clarity, however, the simplest possible competitive scheme (Rumelhart and Zipser 1985) was used in the simulation described here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature discovery by competitive learn"
            },
            "venue": {
                "fragments": [],
                "text": "Cog . Sci ."
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 127
                            }
                        ],
                        "text": "Where no such detectors are available, other learning rules, based on temporal sequences or variation in form (Mitchison 1991, Webber 1991) may be able to find stable representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self - organization of positionand deformationtolerant neural representations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Synchronous bursting activity in ganglion cells of the developing mammalian retina"
            },
            "venue": {
                "fragments": [],
                "text": "Investi . Ophthalmol. Visual Sci"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Biol. Cybernet"
            },
            "venue": {
                "fragments": [],
                "text": "Biol. Cybernet"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Camp"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Camp"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Removing time variation with the anti-Hebbian synapse"
            },
            "venue": {
                "fragments": [],
                "text": "Removing time variation with the anti-Hebbian synapse"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 2,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 18,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Invariance-from-Transformation-Sequences-F\u00f6ldi\u00e1k/2da4e9984a75ffe28c5364662807996ac5bb2662?sort=total-citations"
}