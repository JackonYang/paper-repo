{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144826602"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18649966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11463e2a6ed218e87e22cba2c2f24fb5992d0293",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "THE DIFFICULTIES OF LEARNING IN MULTILAYERED NETWORKS OF COMPUTATIONAL UNITS HAS LIMITED THE USE OF CONNECTIONIST SYSTEMS IN COMPLEX DOMAINS. THIS DISSERTATION ELUCIDATES THE ISSUES OF LEARNING IN A NETWORK''S HIDDEN UNITS, AND REVIEWS METHODS FOR ADDRESSING THESE ISSUES THAT HAVE BEEN DEVELOPED THROUGH THE YEARS. ISSUES OF LEARNING IN HIDDEN UNITS ARE SHOWN TO BE ANALOGOUS TO LEARNING ISSUES FOR MULTILAYER SYSTEMS EMPLOYING SYMBOLIC REPRSENTATIONS. COMPARISONS OF A NUMBER OF ALGORITHMS FOR LEARNING IN HIDDEN UNITS ARE MADE BY APPLYING THEM IN A CONSISTENT MANNER TO SEVERAL TASKS. RECENTLY DEVELOPED ALGORITHMS, INCLUDING RUMELHART, ET AL''S, ERROR BACK-PROPOGATIONS ALGORITHM AND BARTO, ET AL''S, REINFORCEMENT-LEARNING ALGORITHMS, LEARN THE SOLUTIONS TO THE TASKS MUCH MORE SUCCESSFULLY THAN METHODS OF THE PAST. A NOVEL ALGORITHM IS EXAMINED THAT COMBINES ASPECTS OF REINFORCEMENT LEARNING AND A DATA-DIRECTED SEARCH FOR USEFUL WEIGHTS, AND IS SHOWN TO OUT PERFORM REINFORMCEMENT-LEARNING ALGORITHMS. A CONNECTIONIST FRAMEWORK FOR THE LEARNING OF STRATEGIES IS DESCRIBED WHICH COMBINES THE ERROR BACK-PROPOGATION ALGORITHM FOR LEARNING IN HIDDEN UNITS WITH SUTTON''S AHC ALGORITHM TO LEARN EVALUATION FUNCTIONS AND WITH A REINFORCEMENT-LEARNING ALGORITHM TO LEARN SEARCH HEURISTICS. THE GENERAL- ITY OF THIS HYBRID SYSTEM IS DEMONSTRATED THROUGH SUCCESSFUL APPLICATIONS"
            },
            "slug": "Learning-and-problem-solving-with-multilayer-neural-Anderson",
            "title": {
                "fragments": [],
                "text": "Learning and problem-solving with multilayer connectionist systems (adaptive, strategy learning, neural networks, reinforcement learning)"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel algorithm is examined that combines ASPECTS of REINFORCEMENT LEARNING and a DATA-DIRECTED SEARCH for USEFUL WEIGHTS, and is shown to out perform reinFORMCEMENT-LEARNING ALGORITHMS."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2389818"
                        ],
                        "name": "G. Saridis",
                        "slug": "G.-Saridis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Saridis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Saridis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32898586,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68f15a8127ae7ad489a178ac5db9dbdd8a2117d9",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A linear reinforcement learning technique is proposed to provide a memory and thus accelerate the convergence of successive approximation algorithms. The learning scheme is used to update weighting coefficients applied to the components of the correction terms of the algorithm. A direction of the search approaching the direction of a \"ridge\" will result in a gradient peak-seeking method which accelerates considerably the convergence to a neighborhood of the extremum. In a stochastic approximation algorithm the learning scheme provides the required memory to establish a consistent direction or search insensitive to perturbations introduced by the random variables involved. The accelerated algorithms and the respective proofs of convergence are presented. Illustrative examples demonstrate the validity of the proposed algorithms."
            },
            "slug": "Learning-Applied-to-Successive-Approximation-Saridis",
            "title": {
                "fragments": [],
                "text": "Learning Applied to Successive Approximation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A linear reinforcement learning technique is proposed to provide a memory and thus accelerate the convergence of successive approximation algorithms to establish a consistent direction or search insensitive to perturbations introduced by the random variables involved."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Sci. Cybern."
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987887"
                        ],
                        "name": "Mark Derthick",
                        "slug": "Mark-Derthick",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Derthick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Derthick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61403722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92c61d5f45a8c0cee1ef2d638d1957a656061e5c",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Boltzmann Machines learn to model the structure of an environment by modifying internal weights. The algorithm used for changing a weight depends on collecting statistics about the behavior of the two units that the weight connects. The success and speed of the algorithm depends on the accuracy of the statistics, the size of the weight changes, and the way in which the accuracy of the machine's model varies as the weights are changed. This paper presents theoretical analysis and empirical results that can be used to select more effective parameters for the learning algorithm. The Boltzmann Machine learns to make its model of its environment correspond to the actual environment in which it is placed. An environment is a probability distribution of patterns over a subset of the units called the visible units. The environment can be specified explicitly as a list of ordered pairs, giving a pattern, V a' over the visible units, and a probability for the occurrence of the pattern. The machine's model is just the probability distribution it would produce over the visible units if it were allowed to run freely without any environmental input. This probability distribution is not stored directly. Instead, it is specified implicitly by the magnitude of the weights in the machine. For a machine architecture with v visible units, there are 2(v) possible patterns. A machine whose weights were all zero would implicitly specify an environment where each of these patterns had probability 2-v, since the energy of all states would be the same."
            },
            "slug": "Variations-on-the-Boltzmann-Machine-Learning-Derthick",
            "title": {
                "fragments": [],
                "text": "Variations on the Boltzmann Machine Learning Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents theoretical analysis and empirical results that can be used to select more effective parameters for the learning algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58960670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a725e66a9975300512852cffa67938b8fecf2702",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This report assesses the promise of a network approach to adaptive problem solving in which the network components themselves possess considerable adaptive power. We show that components designed with attention to the temporal aspects of reinforcement learning can acquire knowledge about feedback pathways in which they are embedded and can use this knowledge to seek their preferred inputs, thus combining pattern recognition, search, and control functions. A review of adaptive network research shows that networks of components having these capabilities have not been studied previously. We demonstrate that simple networks of these elements can solve types of problems that are beyond the capabilities of networks studied in the past. An associative memory is presented that retains the generalization capabilities and noise resistance of associative memories previously studied but does not require a 'teacher' to provide the desired associations. It conducts active, closed-loop searches for the most rewarding associations. We provide an example in whcih these searches are conducted through the system's external environment and an example in which they are conducted through an internal predictive model of that environment. The latter system is capable of a simple form of latent learning."
            },
            "slug": "Goal-Seeking-Components-for-Adaptive-Intelligence:-Barto-Sutton",
            "title": {
                "fragments": [],
                "text": "Goal Seeking Components for Adaptive Intelligence: An Initial Assessment."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that components designed with attention to the temporal aspects of reinforcement learning can acquire knowledge about feedback pathways in which they are embedded and can use this knowledge to seek their preferred inputs, thus combining pattern recognition, search, and control functions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083623461"
                        ],
                        "name": "David B. Parker",
                        "slug": "David-B.-Parker",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Parker",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David B. Parker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118914993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4d41caaa6e45176d450a145fa56eefbb73b9c23",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many different ways to connect neuron\u2010like cells into large scale learning networks. These different patterns of connections are called architectures. One problem in designing an architecture is deciding what types of neuron\u2010like cells to base it on. By examining the properties of learning networks that are independent of their architectures, this paper proposes that there is at least one type of cell which can be used in any reasonable architecture to give it nearly optimal performance. Cells of this type implement an algorithm called second order least mean square (2nd order LMS, for short)."
            },
            "slug": "A-comparison-of-algorithms-for-neuron-like-cells-Parker",
            "title": {
                "fragments": [],
                "text": "A comparison of algorithms for neuron-like cells"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proposed that there is at least one type of cell which can be used in any reasonable architecture to give it nearly optimal performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2961287"
                        ],
                        "name": "N. Littlestone",
                        "slug": "N.-Littlestone",
                        "structuredName": {
                            "firstName": "Nick",
                            "lastName": "Littlestone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Littlestone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6334230,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1dace286582d91916fe470d08f30381cf453f20",
            "isKey": false,
            "numCitedBy": 1612,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Valiant (1984) and others have studied the problem of learning various classes of Boolean functions from examples. Here we discuss incremental learning of these functions. We consider a setting in which the learner responds to each example according to a current hypothesis. Then the learner updates the hypothesis, if necessary, based on the correct classification of the example. One natural measure of the quality of learning in this setting is the number of mistakes the learner makes. For suitable classes of functions, learning algorithms are available that make a bounded number of mistakes, with the bound independent of the number of examples seen by the learner. We present one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions. The basic method can be expressed as a linear-threshold algorithm. A primary advantage of this algorithm is that the number of mistakes grows only logarithmically with the number of irrelevant attributes in the examples. At the same time, the algorithm is computationally efficient in both time and space."
            },
            "slug": "Learning-Quickly-When-Irrelevant-Attributes-Abound:-Littlestone",
            "title": {
                "fragments": [],
                "text": "Learning Quickly When Irrelevant Attributes Abound: A New Linear-Threshold Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents one such algorithm that learns disjunctive Boolean functions, along with variants for learning other classes of Boolean functions."
            },
            "venue": {
                "fragments": [],
                "text": "28th Annual Symposium on Foundations of Computer Science (sfcs 1987)"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 118205459,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "59a26a2d95db9b713c512d96b2a9e1eafb72d312",
            "isKey": false,
            "numCitedBy": 15053,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Background and Overview. 1. Stochastic Processes and Models. 2. Wiener Filters. 3. Linear Prediction. 4. Method of Steepest Descent. 5. Least-Mean-Square Adaptive Filters. 6. Normalized Least-Mean-Square Adaptive Filters. 7. Transform-Domain and Sub-Band Adaptive Filters. 8. Method of Least Squares. 9. Recursive Least-Square Adaptive Filters. 10. Kalman Filters as the Unifying Bases for RLS Filters. 11. Square-Root Adaptive Filters. 12. Order-Recursive Adaptive Filters. 13. Finite-Precision Effects. 14. Tracking of Time-Varying Systems. 15. Adaptive Filters Using Infinite-Duration Impulse Response Structures. 16. Blind Deconvolution. 17. Back-Propagation Learning. Epilogue. Appendix A. Complex Variables. Appendix B. Differentiation with Respect to a Vector. Appendix C. Method of Lagrange Multipliers. Appendix D. Estimation Theory. Appendix E. Eigenanalysis. Appendix F. Rotations and Reflections. Appendix G. Complex Wishart Distribution. Glossary. Abbreviations. Principal Symbols. Bibliography. Index."
            },
            "slug": "Adaptive-Filter-Theory-Haykin",
            "title": {
                "fragments": [],
                "text": "Adaptive Filter Theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913418"
                        ],
                        "name": "B. Widrow",
                        "slug": "B.-Widrow",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Widrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Widrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136588"
                        ],
                        "name": "S. Stearns",
                        "slug": "S.-Stearns",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Stearns",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Stearns"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 69353254,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "id": "6c192b91f4b4ac35ae8385fa190fdfc146f419b8",
            "isKey": false,
            "numCitedBy": 3657,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "GENERAL INTRODUCTION. Adaptive Systems. The Adaptive Linear Combiner. THEORY OF ADAPTATION WITH STATIONARY SIGNALS. Properties of the Quadratic Performance Surface. Searching the Performance Surface. Gradient Estimation and Its Effects on Adaptation. ADAPTIVE ALGORITHMS AND STRUCTURES. The LMS Algorithm. The Z-Transform in Adaptive Signal Processing. Other Adaptive Algorithms and Structures. Adaptive Lattice Filters. APPLICATIONS. Adaptive Modeling and System Identification. Inverse Adaptive Modeling, Deconvolution, and Equalization. Adaptive Control Systems. Adaptive Interference Cancelling. Introduction to Adaptive Arrays and Adaptive Beamforming. Analysis of Adaptive Beamformers."
            },
            "slug": "Adaptive-Signal-Processing-Widrow-Stearns",
            "title": {
                "fragments": [],
                "text": "Adaptive Signal Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This chapter discusses Adaptive Arrays and Adaptive Beamforming, as well as other Adaptive Algorithms and Structures, and discusses the Z-Transform in Adaptive Signal Processing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3180815"
                        ],
                        "name": "H. Kesten",
                        "slug": "H.-Kesten",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Kesten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kesten"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Parker (1986) has developed an algorithm, called the second-order LMS rule, that uses both first and second derivatives in the update of weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 0
                            }
                        ],
                        "text": "Parker (1986) has developed an algorithm, called the second-order LMS rule, that uses both first and second derivatives in the update of weights. Parker maintains that this rule shows \"nearly optimal performance.\" Derthick (1984) has made several recommendations for learning procedures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 851,
                                "start": 61
                            }
                        ],
                        "text": "This paper is largely a follow-up of techniques developed by Kesten (1958), Saridis (1970), Sutton (1986), and Barto and Sutton ( 1981 ). Kesten proposes that if consecutive changes of a weight (i.e., Awi(t -- 1) and Awi(t)) possess opposite signs, then the weight value is oscillating. Hence, the learning rate for that weight should be decremented. Saridis uses this basic notion to both increase and decrease learning rates. Thus, if consecutive derivatives of a weight possess the same sign, then the learning rate for the weight should be incremented. If consecutive derivatives of a weight possess opposite signs, then the learning rate for the weight should be decremented. In this scheme, the sum of all learning rates for all weights is maintained at a constant. Thus, weights are effectively competing for this fixed quantity. Sutton (1986) discusses why these techniques are particularly pertinent to connectionist networks and makes several alternative suggestions for increasing rates of convergence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 61
                            }
                        ],
                        "text": "This paper is largely a follow-up of techniques developed by Kesten (1958), Saridis (1970), Sutton (1986), and Barto and Sutton ( 1981 )."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1041,
                                "start": 61
                            }
                        ],
                        "text": "This paper is largely a follow-up of techniques developed by Kesten (1958), Saridis (1970), Sutton (1986), and Barto and Sutton ( 1981 ). Kesten proposes that if consecutive changes of a weight (i.e., Awi(t -- 1) and Awi(t)) possess opposite signs, then the weight value is oscillating. Hence, the learning rate for that weight should be decremented. Saridis uses this basic notion to both increase and decrease learning rates. Thus, if consecutive derivatives of a weight possess the same sign, then the learning rate for the weight should be incremented. If consecutive derivatives of a weight possess opposite signs, then the learning rate for the weight should be decremented. In this scheme, the sum of all learning rates for all weights is maintained at a constant. Thus, weights are effectively competing for this fixed quantity. Sutton (1986) discusses why these techniques are particularly pertinent to connectionist networks and makes several alternative suggestions for increasing rates of convergence. In Barto and Sutton (1981), Sutton introduces a learning rule which is very similar to the delta-delta rule discussed below."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120079793,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f27d141b14e825f7d38c489313283c787f92ffd5",
            "isKey": true,
            "numCitedBy": 283,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Accelerated-Stochastic-Approximation-Kesten",
            "title": {
                "fragments": [],
                "text": "Accelerated Stochastic Approximation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913418"
                        ],
                        "name": "B. Widrow",
                        "slug": "B.-Widrow",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Widrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Widrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1976925"
                        ],
                        "name": "M. Hoff",
                        "slug": "M.-Hoff",
                        "structuredName": {
                            "firstName": "Marcian",
                            "lastName": "Hoff",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60830585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e14b2ff9dc2234df94fc24d89fc25e797d0e9e7",
            "isKey": false,
            "numCitedBy": 2603,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-switching-circuits-Widrow-Hoff",
            "title": {
                "fragments": [],
                "text": "Adaptive switching circuits"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35094558"
                        ],
                        "name": "M. Honig",
                        "slug": "M.-Honig",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Honig",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Honig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815712"
                        ],
                        "name": "D. Messerschmitt",
                        "slug": "D.-Messerschmitt",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Messerschmitt",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Messerschmitt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60173371,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a5c6863da46456a353d1f8224be89e8a45578420",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-Filters:-Structures,-Algorithms-and-Honig-Messerschmitt",
            "title": {
                "fragments": [],
                "text": "Adaptive Filters: Structures, Algorithms and Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Goat seeking"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 63
                            }
                        ],
                        "text": "This algorithm, which is a modification of a recommendation by Sutton (1986), can be written"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Two problems with backpropagation and other steepest-descent learning procedures for networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Eighth Annual Conference of the Cognitive Science Society,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A feed - forward memory with decay"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Science ."
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 15,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Increased-rates-of-convergence-through-learning-Jacobs/a9ef2995e8e1bd57a74343073219364811c2ace0?sort=total-citations"
}