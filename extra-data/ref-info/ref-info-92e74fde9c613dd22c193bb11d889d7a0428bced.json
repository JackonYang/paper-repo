{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728727"
                        ],
                        "name": "A. Laurentini",
                        "slug": "A.-Laurentini",
                        "structuredName": {
                            "firstName": "Aldo",
                            "lastName": "Laurentini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Laurentini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73412977"
                        ],
                        "name": "P. Viada",
                        "slug": "P.-Viada",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Viada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Viada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61361377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b22149f09750ef752196a7a31d0adccb762d14f0",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are important components of technical documents. This paper addresses the following problems: (i) identifying a tabular component in a scanned image of a compound document containing text, drawings, diagrams, etc.; (ii) understanding the content of the table in order to convert the table into electronic format. As far as the authors are aware, the problems addressed are new. An algorithm for performing both the above tasks has been studied and implemented. Preliminary experimental results indicate satisfactory performance for many table lay-out styles.<<ETX>>"
            },
            "slug": "Identifying-and-understanding-tabular-material-in-Laurentini-Viada",
            "title": {
                "fragments": [],
                "text": "Identifying and understanding tabular material in compound documents"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper addresses the following problems: identifying a tabular component in a scanned image of a compound document containing text, drawings, diagrams, etc."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol.II. Conference B: Pattern Recognition Methodology and Systems"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27626504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b8ec3847c2cdbb50aca64d310703b5d89c81a4b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework of four-layer recognition processes is proposed for understanding documents, and a knowledge representation method adaptable to the understanding of table-form documents is addressed. Although Y. Nakano et al. (1986) looked upon the recognition of multi-kinds of table-form documents as an important subject from a practical point of view, they could not report any successful approach because their knowledge was based only on the physical coordinate data. In the approach presented, this recognition issue was solved, using both the classification tree based on the physical characteristics and the structure description tree based on the logical characteristics. At least, it is not so difficult to classify various kinds of documents into appropriate document classes since table-form documents are well designed on the basis of vertical and horizontal line segments. However, it is not easy in the case of the other documents because the geometric and spatial characteristics of documents are not well specified. It is necessary to investigate the application techniques for the other documents from the viewpoint of the knowledge representation.<<ETX>>"
            },
            "slug": "Toward-a-practical-document-understanding-of-its-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Toward a practical document understanding of table-form documents: its framework and knowledge representation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A framework of four-layer recognition processes is proposed for understanding documents, and a knowledge representation method adaptable to the understanding of table-form documents is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2775803"
                        ],
                        "name": "A. Pizano",
                        "slug": "A.-Pizano",
                        "structuredName": {
                            "firstName": "Arturo",
                            "lastName": "Pizano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pizano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62278325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c247977a3ad35620f9e929252fc8935deae4205",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Business forms and tables are special document classes typically used to collect or distribute data; they are characterized by the presence of horizontal and vertical lines that delimit the usable space. The paper describes an algorithm that identifies these lines in binary digital images. This algorithm can be used to separate text from graphics before applying optical character recognition, or as a feature extractor in a form classification system. The approach presented differs from exiting vectorization, line extraction, and text-graphics separation methods, in that it focuses exclusively on the recognition of horizontal and vertical lines.<<ETX>>"
            },
            "slug": "Extracting-line-features-from-images-of-business-Pizano",
            "title": {
                "fragments": [],
                "text": "Extracting line features from images of business forms and tables"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm is described that identifies horizontal and vertical lines in binary digital images that can be used to separate text from graphics before applying optical character recognition, or as a feature extractor in a form classification system."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., 11th IAPR International Conference on Pattern Recognition. Vol. III. Conference C: Image, Speech and Signal Analysis,"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111216375"
                        ],
                        "name": "Dacheng Wang",
                        "slug": "Dacheng-Wang",
                        "structuredName": {
                            "firstName": "Dacheng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dacheng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39648401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733a2a9526f5a2bba076605b060c7cf641076e2a",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic analysis of images of forms is a problem of both practical and theoretical interest; due to its importance in office automation, and due to the conceptual challenges posed for document image analysis, respectively. We describe an approach to the extraction of text, both typed and handwritten, from scanned and digitized images of filled-out forms. In decomposing a filled-out form into three basic components of boxes, line segments and the remainder (handwritten and typed characters, words, and logos), the method does not use a priori knowledge of form structure. The input binary image is first segmented into small and large connected components. Complex boxes are decomposed into elementary regions using an approach based on key-point analysis. Handwritten and machine-printed text that touches or overlaps guide lines and boxes are separated by removing lines. Characters broken by line removal are rejoined using a character patching method. Experimental results with filled-out forms, from several different domains (insurance, banking, tax, retail and postal) are given."
            },
            "slug": "Analysis-of-Form-Images-Wang-Srihari",
            "title": {
                "fragments": [],
                "text": "Analysis of Form Images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An approach to the extraction of text, both typed and handwritten, from scanned and digitized images of filled-out forms is described, which does not use a priori knowledge of form structure."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Pattern Recognit. Artif. Intell."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shirihari, Analysis of Form Images"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ICDAR\u201991,"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 5,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Robust-table-form-structure-analysis-based-on-Hori-Doermann/92e74fde9c613dd22c193bb11d889d7a0428bced?sort=total-citations"
}