{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16481278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab4850b6151ca9a9337dbba94115bde342876d50",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "A plausible definition of \u201creasoning\u201d could be \u201calgebraically manipulating previously acquired knowledge in order to answer a new question\u201d. This definition covers firstorder logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text. This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \u201call-purpose\u201d inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up."
            },
            "slug": "From-machine-learning-to-machine-reasoning-An-essay-Bottou",
            "title": {
                "fragments": [],
                "text": "From machine learning to machine reasoning An essay"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Instead of trying to bridge the gap between machine learning systems and sophisticated \u201call-purpose\u201d inference mechanisms, the set of manipulations applicable to training systems can be algebraically enriched, and reasoning capabilities from the ground up are built."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713934"
                        ],
                        "name": "Antoine Bordes",
                        "slug": "Antoine-Bordes",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bordes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Bordes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 55
                            }
                        ],
                        "text": "Both deep learning and multi-task learning show that we can leverage auxiliary tasks to help solving a task of interest."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 715463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f4a4769e4d2fb846e59c2f185e0377190739f18",
            "isKey": false,
            "numCitedBy": 754,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Many Knowledge Bases (KBs) are now readily available and encompass colossal quantities of information thanks to either a long-term funding effort (e.g. WordNet, OpenCyc) or a collaborative process (e.g. Freebase, DBpedia). However, each of them is based on a different rigid symbolic framework which makes it hard to use their data in other systems. It is unfortunate because such rich structured knowledge might lead to a huge leap forward in many other areas of AI like natural language processing (word-sense disambiguation, natural language understanding, ...), vision (scene classification, image semantic annotation, ...) or collaborative filtering. In this paper, we present a learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced. These learnt embeddings would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval. We illustrate our method on WordNet and Freebase and also present a way to adapt it to knowledge extraction from raw text."
            },
            "slug": "Learning-Structured-Embeddings-of-Knowledge-Bases-Bordes-Weston",
            "title": {
                "fragments": [],
                "text": "Learning Structured Embeddings of Knowledge Bases"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A learning process based on an innovative neural network architecture designed to embed any of these symbolic representations into a more flexible continuous vector space in which the original knowledge is kept and enhanced would allow data from any KB to be easily used in recent machine learning methods for prediction and information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Socher et al. (2010) independently trained a similar system in a supervised manner using the WSJ section of the annotated Penn TreeBank corpus."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9923502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81b3b3fe994a9eda6d3f9d2149aa4492d1933975",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language parsing has typically been done with small sets of discrete categories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases only partly address the problem at the cost of huge feature spaces and sparseness. To address this, we introduce a recursive neural network architecture for jointly parsing natural language and learning vector space representations for variable-sized inputs. At the core of our architecture are context-sensitive recursive neural networks (CRNN). These networks can induce distributed feature representations for unseen phrases and provide syntactic information to accurately predict phrase structure trees. Most excitingly, the representation of each phrase also captures semantic information: For instance, the phrases \u201cdecline to comment\u201d and \u201cwould not disclose the terms\u201d are close by in the induced embedding space. Our current system achieves an unlabeled bracketing F-measure of 92.1% on the Wall Street Journal dataset for sentences up to length 15."
            },
            "slug": "Learning-Continuous-Phrase-Representations-and-with-Socher-Manning",
            "title": {
                "fragments": [],
                "text": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A recursive neural network architecture for jointly parsing natural language and learning vector space representations for variable-sized inputs and captures semantic information: For instance, the phrases \u201cdecline to comment\u201d and \u201cwould not disclose the terms\u201d are close by in the induced embedding space."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746034"
                        ],
                        "name": "L. Getoor",
                        "slug": "L.-Getoor",
                        "structuredName": {
                            "firstName": "Lise",
                            "lastName": "Getoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Getoor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 743435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "611dac316bf03112c778cf7365d08e4a9d171876",
            "isKey": false,
            "numCitedBy": 1170,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "A large portion of real-world data is stored in commercial relational database systems. In contrast, most statistical learning methods work only with \"flat\" data representations. Thus, to apply these methods, we are forced to convert our data into a flat form, thereby losing much of the relational structure present in our database. This paper builds on the recent work on probabilistic relational models (PRMs), and describes how to learn them from databases. PRMs allow the properties of an object to depend probabilistically both on other properties of that object and on properties of related objects. Although PRMs are significantly more expressive than standard models, such as Bayesian networks, we show how to extend well-known statistical methods for learning Bayesian networks to learn these models. We describe both parameter estimation and structure learning -- the automatic induction of the dependency structure in a model. Moreover, we show how the learning procedure can exploit standard database retrieval techniques for efficient learning from large datasets. We present experimental results on both real and synthetic relational databases."
            },
            "slug": "Learning-Probabilistic-Relational-Models-Getoor",
            "title": {
                "fragments": [],
                "text": "Learning Probabilistic Relational Models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes both parameter estimation and structure learning -- the automatic induction of the dependency structure in a model and shows how the learning procedure can exploit standard database retrieval techniques for efficient learning from large datasets."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422314"
                        ],
                        "name": "Matthew Richardson",
                        "slug": "Matthew-Richardson",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Richardson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Richardson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12698795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "950a3c89dacbc3e7ddcd43d7ff6f985697e41cdb",
            "isKey": false,
            "numCitedBy": 2803,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a simple approach to combining first-order logic and probabilistic graphical models in a single representation. A Markov logic network (MLN) is a first-order knowledge base with a weight attached to each formula (or clause). Together with a set of constants representing objects in the domain, it specifies a ground Markov network containing one feature for each possible grounding of a first-order formula in the KB, with the corresponding weight. Inference in MLNs is performed by MCMC over the minimal subset of the ground network required for answering the query. Weights are efficiently learned from relational databases by iteratively optimizing a pseudo-likelihood measure. Optionally, additional clauses are learned using inductive logic programming techniques. Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach."
            },
            "slug": "Markov-logic-networks-Richardson-Domingos",
            "title": {
                "fragments": [],
                "text": "Markov logic networks"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach to combining first-order logic and probabilistic graphical models in a single representation."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746048"
                        ],
                        "name": "R. Khardon",
                        "slug": "R.-Khardon",
                        "structuredName": {
                            "firstName": "Roni",
                            "lastName": "Khardon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Khardon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 85
                            }
                        ],
                        "text": "Although there are connectionist and machine learning approaches to variable binding (e.g., Smolensky 1990; Plate 1994; Khardon and Roth 1997), they cannot avoid the computational complexity of first-order logic problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 494561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3096681c103d02d7c59fc936da35a4b03262359",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new framework for the study of reasoning. The Learning (in order) to Reason approach developed here views learning as an integral part of the inference process, and suggests that learning and reasoning should be studied together.\nThe Learning to Reason framework combines the interfaces to the world used by known learning models with the reasoning task and a performance criterion suitable for it. In this framework, the intelligent agent is given access to its favorite learning interface, and is also given a grace period in with it can interact with this interface and construct a representation KB of the world W. The reasoning performance is measured only after this period, when the agent is presented with queries \u03b1 from some query language, relevant to the world, and has to answer whether W implies \u03b1.\nThe approach is meant to overcome the main computational difficulties in the traditional treatment of reasoning which stem from its separation from the \u201cworld\u201d. Since the agent interacts with the world when construction its knowledge representation it can choose a representation that is useful for the task at hand. Moreover, we can now make explicit the dependence of the reasoning performance on the environment the agent interacts with.\nWe show how previous results from learning theory and reasoning fit into this framwork and illustrate the usefulness of the Learning to Reason approach by exhibiting new results that are not possible in the traditional setting. First, we give Learning to Reason algorithms for classes of propositional languages for which there are no efficient reasoning algorithms, when represented as a traditional (formula-based) knowledge base. Second, we exhibit a Learning to Reason algorithm for a class of propositional languages that is not know to be learnable in the traditional sense."
            },
            "slug": "Learning-to-reason-Khardon-Roth",
            "title": {
                "fragments": [],
                "text": "Learning to reason"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This work introduces a new framework for the study of reasoning, and gives Learning to Reason algorithms for classes of propositional languages for which there are no efficient reasoning algorithms, when represented as a traditional (formula-based) knowledge base."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21432929"
                        ],
                        "name": "Michael Karlen",
                        "slug": "Michael-Karlen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Karlen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Karlen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46283650"
                        ],
                        "name": "P. Kuksa",
                        "slug": "P.-Kuksa",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Kuksa",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kuksa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 351666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc1022b031dc6c7019696492e8116598097a8c12",
            "isKey": false,
            "numCitedBy": 6657,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements."
            },
            "slug": "Natural-Language-Processing-(Almost)-from-Scratch-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "Natural Language Processing (Almost) from Scratch"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 124
                            }
                        ],
                        "text": "Computer algorithms for general probabilistic inference (Pearl 1988) still suffer from unfavorable computational properties (Roth 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 126
                            }
                        ],
                        "text": "Computer algorithms for general probabilistic inference (Pearl, 1988) still suffer from unfavorable computational properties (Roth, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1838914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "937c3e93a15cc416af330f9fcbcf447f7ad77e1e",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Hardness-of-Approximate-Reasoning-Roth",
            "title": {
                "fragments": [],
                "text": "On the Hardness of Approximate Reasoning"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815154"
                        ],
                        "name": "G. Bakir",
                        "slug": "G.-Bakir",
                        "structuredName": {
                            "firstName": "G\u00f6khan",
                            "lastName": "Bakir",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bakir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118460398"
                        ],
                        "name": "Taskar B Smola Aj",
                        "slug": "Taskar-B-Smola-Aj",
                        "structuredName": {
                            "firstName": "Taskar",
                            "lastName": "Smola Aj",
                            "middleNames": [
                                "B"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taskar B Smola Aj"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145713874"
                        ],
                        "name": "S. Vishwanathan",
                        "slug": "S.-Vishwanathan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Vishwanathan",
                            "middleNames": [
                                "V.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vishwanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5671144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e75ad22a6865c3402925f12317dd0897c67ebe6",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning develops intelligent computer systems that are able to generalize from previously seen examples. A new domain of machine learning, in which the prediction must satisfy the additional constraints found in structured data, poses one of machine learning's greatest challenges: learning functional dependencies between arbitrary input and output domains. This volume presents and analyzes the state of the art in machine learning algorithms and theory in this novel field. The contributors discuss applications as diverse as machine translation, document markup, computational biology, and information extraction, among others, providing a timely overview of an exciting field. Contributors Yasemin Altun, Gokhan Bakir [no dot over i], Olivier Bousquet, Sumit Chopra, Corinna Cortes, Hal Daume III, Ofer Dekel, Zoubin Ghahramani, Raia Hadsell, Thomas Hofmann, Fu Jie Huang, Yann LeCun, Tobias Mann, Daniel Marcu, David McAllester, Mehryar Mohri, William Stafford Noble, Fernando Perez-Cruz, Massimiliano Pontil, Marc'Aurelio Ranzato, Juho Rousu, Craig Saunders, Bernhard Scholkopf, Matthias W. Seeger, Shai Shalev-Shwartz, John Shawe-Taylor, Yoram Singer, Alexander J. Smola, Sandor Szedmak, Ben Taskar, Ioannis Tsochantaridis, S.V.N Vishwanathan, Jason Weston Gokhan Bakir [no dot over i] is Research Scientist at the Max Planck Institute for Biological Cybernetics in Tubingen, Germany. Thomas Hofmann is a Director of Engineering at Google's Engineering Center in Zurich and Adjunct Associate Professor of Computer Science at Brown University. Bernhard Scholkopf is Director of the Max Planck Institute for Biological Cybernetics and Professor at the Technical University Berlin. Alexander J. Smola is Senior Principal Researcher and Machine Learning Program Leader at National ICT Australia/Australian National University, Canberra. Ben Taskar is Assistant Professor in the Computer and Information Science Department at the University of Pennsylvania. S. V. N. Vishwanathan is Senior Researcher in the Statistical Machine Learning Program, National ICT Australia with an adjunct appointment at the Research School for Information Sciences and Engineering, Australian National University."
            },
            "slug": "Predicting-Structured-Data-Bakir-Hofmann",
            "title": {
                "fragments": [],
                "text": "Predicting Structured Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This volume presents the state of the art in machine learning algorithms and theory in this novel field and discusses applications as diverse as machine translation, document markup, computational biology, and information extraction, providing a timely overview of an exciting field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7376917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03539fc7a0dada577db3fc9bc2b3c8e091877108",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel neural network architecture for the problem of semantic role labeling. Many current solutions are complicated, consist of several stages and handbuilt features, and are too slow to be applied as part of real applications that require such semantic labels, partly because of their use of a syntactic parser (Pradhan et al., 2004; Gildea and Jurafsky, 2002). Our method instead learns a direct mapping from source sentence to semantic tags for a given predicate without the aid of a parser or a chunker. Our resulting system obtains accuracies comparable to the current state-of-the-art at a fraction of the computational cost."
            },
            "slug": "Fast-Semantic-Extraction-Using-a-Novel-Neural-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "Fast Semantic Extraction Using a Novel Neural Network Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel neural network architecture for the problem of semantic role labeling that learns a direct mapping from source sentence to semantic tags for a given predicate without the aid of a parser or a chunker."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859277"
                        ],
                        "name": "T. Plate",
                        "slug": "T.-Plate",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Plate",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plate"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60549146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aad5b4340e4b3b23ad8d292bf9ed8e7f60c53159",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 117,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributed representations are attractive for a number of reasons. They offer the possibility of representing concepts in a continuous space, they degrade gracefully with noise, and they can be processed in a parallel network of simple processing elements. However, the problem of representing nested structure in distributed representations has been for some time a prominent concern of both proponents and critics of connectionism (Fodor and Pylyshyn 1988; Smolensky 1990; Hinton 1990). The lack of connectionist representations for complex structure has held back progress in tackling higher-level cognitive tasks such as language understanding and reasoning. \nIn this thesis I review connectionist representations and propose a method for the distributed representation of nested structure, which I call \"Holographic Reduced Representations\" (HRRs). HRRs provide an implementation of Hinton's (1990) \"reduced descriptions\". HRRs use circular convolution to associate atomic items, which are represented by vectors. Arbitrary variable bindings, short sequences of various lengths, and predicates can be represented in a fixed-width vector. These representations are items in their own right, and can be used in constructing compositional structures. The noisy reconstructions extracted from convolution memories can be cleaned up by using a separate associative memory that has good reconstructive properties. \nCircular convolution, which is the basic associative operator for HRRs, can be built into a recurrent neural network. The network can store and produce sequences. I show that neural network learning techniques can be used with circular convolution in order to learn representations for items and sequences. \nOne of the attractions of connectionist representations of compositional structures is the possibility of computing without decomposing structures. I show that it is possible to use dot-product comparisons of HRRs for nested structures to estimate the analogical similarity of the structures. This demonstrates how the surface form of connectionist representations can reflect underlying structural similarity and alignment."
            },
            "slug": "Distributed-representations-and-nested-structure-Plate-Hinton",
            "title": {
                "fragments": [],
                "text": "Distributed representations and nested compositional structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This thesis proposes a method for the distributed representation of nested structure in connectionist representations and shows that it is possible to use dot-product comparisons of HRRs for nested structures to estimate the analogical similarity of the structures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 128
                            }
                        ],
                        "text": "Such Recursive Auto-Associative Memory (RAAM) were proposed as a connectionist representation of infinite recursive structures (Pollack, 1990)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 112
                            }
                        ],
                        "text": "Auto-Associative Memory (RAAM) were proposed as a connectionist representation of infinite recursive structures (Pollack 1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 770011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Distributed-Representations-Pollack",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585821"
                        ],
                        "name": "Cliff Chiung-Yu Lin",
                        "slug": "Cliff-Chiung-Yu-Lin",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Lin",
                            "middleNames": [
                                "Chiung-Yu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Chiung-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18690358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "isKey": false,
            "numCitedBy": 1320,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%."
            },
            "slug": "Parsing-Natural-Scenes-and-Natural-Language-with-Socher-Lin",
            "title": {
                "fragments": [],
                "text": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152677868"
                        ],
                        "name": "Etter Vincent",
                        "slug": "Etter-Vincent",
                        "structuredName": {
                            "firstName": "Etter",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Etter Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26488571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "750f9ad040db2b1e92898e27b44a426176bf6c0f",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We first present our work in machine translation, during which we used aligned sentences to train a neural network to embed n-grams of different languages into an d-dimensional space, such that n-grams that are the translation of each other are close with respect to some metric. Good n-grams to n-grams translation results were achieved, but full sentences translation is still problematic. We realized that learning semantics of sentences and documents was the key for solving a lot of natural language processing problems, and thus moved to the second part of our work: sentence compression. We introduce a flexible neural network architecture for learning embeddings of words and sentences that extract their semantics, propose an efficient implementation in the Torch framework and present embedding results comparable to the ones obtained with classical neural language models, while being more powerful."
            },
            "slug": "Semantic-Vector-Machines-Vincent",
            "title": {
                "fragments": [],
                "text": "Semantic Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A flexible neural network architecture for learning embeddings of words and sentences that extract their semantics is introduced, an efficient implementation in the Torch framework is proposed and results are presented comparable to the ones obtained with classical neural language models, while being more powerful."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472697"
                        ],
                        "name": "Vincent Etter",
                        "slug": "Vincent-Etter",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Etter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Etter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "Preliminary results have been obtained using a similar procedure (Etter, 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Preliminary results have been obtained using a similar procedure (Etter, 2009). Sentence segments of length five were extracted from a dump of the English Wikipedia (600M words). The vocabulary was restricted to the 1000 most frequent words initialized with the Collobert (2011) embeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33192721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb650df7c1ba7bb3620acac55597d9b5c2c3dad1",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We first present our work in machine translation, during which we used aligned sentences to train a neural network to embed n-grams of different languages into an d-dimensional space, such that n-grams that are the translation of each other are close with respect to some metric. Good n-grams to n-grams translation results were achieved, but full sentences translation is still problematic. We realized that learning semantics of sentences and documents was the key for solving a lot of natural language processing problems, and thus moved to the second part of our work: sentence compression. We introduce a flexible neural network architecture for learning embeddings of words and sentences that extract their semantics, propose an efficient implementation in the Torch framework and present embedding results comparable to the ones obtained with classical neural language models, while being more powerful."
            },
            "slug": "Semantic-Vector-Machines-Etter",
            "title": {
                "fragments": [],
                "text": "Semantic Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A flexible neural network architecture for learning embeddings of words and sentences that extract their semantics is introduced, an efficient implementation in the Torch framework is proposed and results are presented comparable to the ones obtained with classical neural language models, while being more powerful."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 70
                            }
                        ],
                        "text": "Deep learning is therefore intimately related to multi-task learning (Caruana, 1997.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 115
                            }
                        ],
                        "text": "Like the face recognition and the natural language processing examples, most works discussing multi-task learning (Caruana, 1997) construct adhoc combinations justified by a semantic interpretation of the internal representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 114
                            }
                        ],
                        "text": "Like the face recognition and the natural language processing examples, most works discussing multi-task learning (Caruana 1997) construct ad-hoc combinations justified by a semantic interpretation of the internal representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 69
                            }
                        ],
                        "text": "Deep learning is therefore intimately related to multi-task learning (Caruana 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11135765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6d931fe9bfe7223165b14ec85d79d56e406e38a",
            "isKey": true,
            "numCitedBy": 186,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new fast purely discriminative algorithm for natural language parsing, based on a \u201cdeep\u201d recurrent convolutional graph transformer network (GTN). Assuming a decomposition of a parse tree into a stack of \u201clevels\u201d, the network predicts a level of the tree taking into account predictions of previous levels. Using only few basic text features which leverage word representations from Collobert and Weston (2008), we show similar performance (in F1 score) to existing pure discriminative parsers and existing \u201cbenchmark\u201d parsers (like Collins parser, probabilistic context-free grammars based), with a huge speed advantage."
            },
            "slug": "Deep-Learning-for-Efficient-Discriminative-Parsing-Collobert",
            "title": {
                "fragments": [],
                "text": "Deep Learning for Efficient Discriminative Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A new fast purely discriminative algorithm for natural language parsing, based on a \u201cdeep\u201d recurrent convolutional graph transformer network (GTN) and assuming a decomposition of a parse tree into a stack of \"levels\u201d, the network predicts a level of the tree taking into account predictions of previous levels."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143836295"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 485740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0dadb25842ef596a0f676c04cbd3dad4e1876964",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Building visual recognition models that adapt across different domains is a challenging task for computer vision. While feature-learning machines in the form of hierarchial feed-forward models (e.g., convolutional neural networks) showed promise in this direction, they are still difficult to train especially when few training examples are available. In this paper, we present a framework for training hierarchical feed-forward models for visual recognition, using transfer learning from pseudo tasks. These pseudo tasks are automatically constructed from data without supervision and comprise a set of simple pattern-matching operations. We show that these pseudo tasks induce an informative inverse-Wishart prior on the functional behavior of the network, offering an effective way to incorporate useful prior knowledge into the network training. In addition to being extremely simple to implement, and adaptable across different domains with little or no extra tuning, our approach achieves promising results on challenging visual recognition tasks, including object recognition, gender recognition, and ethnicity recognition."
            },
            "slug": "Training-Hierarchical-Feed-Forward-Visual-Models-Ahmed-Yu",
            "title": {
                "fragments": [],
                "text": "Training Hierarchical Feed-Forward Visual Recognition Models Using Transfer Learning from Pseudo-Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a framework for training hierarchical feed-forward models for visual recognition, using transfer learning from pseudo tasks, and shows that these pseudo tasks induce an informative inverse-Wishart prior on the functional behavior of the network, offering an effective way to incorporate useful prior knowledge into the network training."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2309950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "isKey": false,
            "numCitedBy": 13408,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind."
            },
            "slug": "A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero",
            "title": {
                "fragments": [],
                "text": "A Fast Learning Algorithm for Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A fast, greedy algorithm is derived that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32384143"
                        ],
                        "name": "D. Popovici",
                        "slug": "D.-Popovici",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Popovici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Popovici"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14201947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "isKey": false,
            "numCitedBy": 3434,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."
            },
            "slug": "Greedy-Layer-Wise-Training-of-Deep-Networks-Bengio-Lamblin",
            "title": {
                "fragments": [],
                "text": "Greedy Layer-Wise Training of Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145282631"
                        ],
                        "name": "J. A. Robinson",
                        "slug": "J.-A.-Robinson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Robinson",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Robinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14389185,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d2109eba4f160755f0b9a7497b6b691c2fa2d5d8",
            "isKey": false,
            "numCitedBy": 4367,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ":tb.~tract. Theorem-proving on the computer, using procedures based on the fund~mental theorem of Herbrand concerning the first-order predicate etdeulus, is examined with ~ view towards improving the efticieney and widening the range of practical applicability of these procedures. A elose analysis of the process of substitution (of terms for variables), and the process of t ruth-funct ional analysis of the results of such substitutions, reveals that both processes can be combined into a single new process (called resolution), i terating which is vastty more ef[ieient than the older cyclic procedures consisting of substitution stages alternating with truth-functional analysis stages. The theory of the resolution process is presented in the form of a system of first<~rder logic with .just one inference principle (the resolution principle). The completeness of the system is proved; the simplest proof-procedure based oil the system is then the direct implementation of the proof of completeness. Howew~r, this procedure is quite inefficient, ~nd the paper concludes with a discussion of several principles (called search principles) which are applicable to the design of efficient proof-procedures employing resolution as the basle logical process."
            },
            "slug": "A-Machine-Oriented-Logic-Based-on-the-Resolution-Robinson",
            "title": {
                "fragments": [],
                "text": "A Machine-Oriented Logic Based on the Resolution Principle"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The paper concludes with a discussion of several principles which are applicable to the design of efficient proof-procedures employing resolution as the basle logical process."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 57
                            }
                        ],
                        "text": "Computer algorithms for general probabilistic inference (Pearl, 1988) still suffer from unfavorable computational properties (Roth, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 116
                            }
                        ],
                        "text": "This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 90
                            }
                        ],
                        "text": "The dictionary of elementary trainable modules and the composition operators form a simple algebraic system on a space of models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 18
                            }
                        ],
                        "text": "Graphical models (Pearl, 1988) describe the factorization of a joint probability distribution into elementary conditional distributions with specific conditional independence assumptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 60
                            }
                        ],
                        "text": "A potentially surprising consequence of this definition is the arbitrary nature of a reasoning system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 283
                            }
                        ],
                        "text": "\u2026distributions are highly constrained by the algebraic properties of the probability theory: if we know a subset of these conditional distributions, we can apply Bayesian inference to deduct or constrain additional conditional distributions and therefore answer different questions (Pearl, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57437891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bf6f01402e1648b7d1e6c9200ede6cb1af30123",
            "isKey": true,
            "numCitedBy": 4579,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996444"
                        ],
                        "name": "A. Paccanaro",
                        "slug": "A.-Paccanaro",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Paccanaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Paccanaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9962628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088720694feed36064044545f99f618ac620ee99",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Linear Relational Embedding (LRE), a new method of learning a distributed representation of concepts from data consisting of instances of relations between given concepts. Its final goal is to be able to generalize, i.e. infer new instances of these relations among the concepts. On a task involving family relationships we show that LRE can generalize better than any previously published method. We then show how LRE can be used effectively to find compact distributed representations for variable-sized recursive data structures, such as trees and lists."
            },
            "slug": "Learning-Hierarchical-Structures-with-Linear-Paccanaro-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning Hierarchical Structures with Linear Relational Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work presents Linear Relational Embedding, a new method of learning a distributed representation of concepts from data consisting of instances of relations between given concepts, and shows how LRE can be used effectively to find compact distributed representations for variable-sized recursive data structures, such as trees and lists."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35262,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7544770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71dd4d477ca17b4db3b270d25225822ff3a41fac",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mapping-Part-Whole-Hierarchies-into-Connectionist-Hinton",
            "title": {
                "fragments": [],
                "text": "Mapping Part-Whole Hierarchies into Connectionist Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 45998148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47aaeb6dc682162dfe5659c2cad64e5d825ad910",
            "isKey": false,
            "numCitedBy": 3257,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems."
            },
            "slug": "Multitask-Learning-Caruana",
            "title": {
                "fragments": [],
                "text": "Multitask Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Prior work on MTL is reviewed, new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals is presented, and new results for MTL with k-nearest neighbor and kernel regression are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Machine Learning and Data Mining"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050371"
                        ],
                        "name": "Jennifer Neville",
                        "slug": "Jennifer-Neville",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Neville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Neville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144774129"
                        ],
                        "name": "David D. Jensen",
                        "slug": "David-D.-Jensen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jensen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David D. Jensen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11015651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56eb42f079e2b596d6c2e6156a5e4cfc8a48a19f",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Collective classification models exploit the dependencies in a network of objects to improve predictions. For example, in a network of web pages, the topic of a page may depend on the topics of hyperlinked pages. A relational model capable of expressing and reasoning with such dependencies should achieve superior performance to relational models that ignore such dependencies. In this paper, we present relational dependency networks (RDNs), extending recent work in dependency networks to a relational setting. RDNs are a collective classification model that offers simple parameter estimation and efficient structure learning. On two real-world data sets, we compare RDNs to ordinary classification with relational probability trees and show that collective classification improves performance."
            },
            "slug": "Collective-Classification-with-Relational-Networks-Neville-Jensen",
            "title": {
                "fragments": [],
                "text": "Collective Classification with Relational Dependency Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents relational dependency networks (RDNs), a collective classification model that offers simple parameter estimation and efficient structure learning and shows that collective classification improves performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70219052"
                        ],
                        "name": "Wray L. Buntine",
                        "slug": "Wray-L.-Buntine",
                        "structuredName": {
                            "firstName": "Wray",
                            "lastName": "Buntine",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wray L. Buntine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11672931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa7a32d9ce76cd016cf21d4f956e19d90e87b0dc",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a multidisciplinary review of empirical, statistical learning from a graphical model perspective. Well-known examples of graphical models include Bayesian networks, directed graphs representing a Markov chain, and undirected networks representing a Markov field. These graphical models are extended to model data analysis and empirical learning using the notation of plates. Graphical operations for simplifying and manipulating a problem are provided including decomposition, differentiation, andthe manipulation of probability models from the exponential family. Two standard algorithm schemas for learning are reviewed in a graphical framework: Gibbs sampling and the expectation maximizationalgorithm. Using these operations and schemas, some popular algorithms can be synthesized from their graphical specification. This includes versions of linear regression, techniques for feed-forward networks, and learning Gaussian and discrete Bayesian networks from data. The paper concludes by sketching some implications for data analysis and summarizing how some popular algorithms fall within the framework presented. The main original contributions here are the decompositiontechniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms."
            },
            "slug": "Operations-for-Learning-with-Graphical-Models-Buntine",
            "title": {
                "fragments": [],
                "text": "Operations for Learning with Graphical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main original contributions here are the decompositiontechniques and the demonstration that graphical models provide a framework for understanding and developing complex learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 847249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f0ab1dcdc9f405ca90e36a35ea335196464d387",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new machine learning paradigm called Graph Transformer Networks that extends the applicability of gradient-based learning algorithms to systems composed of modules that take graphs as inputs and produce graphs as output. Training is performed by computing gradients of a global objective function with respect to all the parameters in the system using a kind of back-propagation procedure. A complete check reading system based on these concepts is described. The system uses convolutional neural network character recognizers, combined with global training techniques to provide record accuracy on business and personal checks. It is presently deployed commercially and reads million of checks per month."
            },
            "slug": "Global-training-of-document-processing-systems-Bottou-Bengio",
            "title": {
                "fragments": [],
                "text": "Global training of document processing systems using graph transformer networks"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new machine learning paradigm called Graph Transformer Networks is proposed that extends the applicability of gradient-based learning algorithms to systems composed of modules that take graphs as inputs and produce graphs as output."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114422629"
                        ],
                        "name": "G. A. Miller",
                        "slug": "G.-A.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. A. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15654531,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4023ae0ba18eed43a97e8b8c9c8fcc9a671b7aa3",
            "isKey": false,
            "numCitedBy": 21615,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "First, the span of absolute judgment and the span of immediate memory impose severe limitations on the amount of information that we are able to receive, process, and remember. By organizing the stimulus input simultaneously into several dimensions and successively into a sequence or chunks, we manage to break (or at least stretch) this informational bottleneck. Second, the process of recoding is a very important one in human psychology and deserves much more explicit attention than it has received. In particular, the kind of linguistic recoding that people do seems to me to be the very lifeblood of the thought processes. Recoding procedures are a constant concern to clinicians, social psychologists, linguists, and anthropologists and yet, probably because recoding is less accessible to experimental manipulation than nonsense syllables or T mazes, the traditional experimental psychologist has contributed little or nothing to their analysis. Nevertheless, experimental techniques can be used, methods of recoding can be specified, behavioral indicants can be found. And I anticipate that we will find a very orderly set of relations describing what now seems an uncharted wilderness of individual differences. Third, the concepts and measures provided by the theory of information provide a quantitative way of getting at some of these questions. The theory provides us with a yardstick for calibrating our stimulus materials and for measuring the performance of our subjects. In the interests of communication I have suppressed the technical details of information measurement and have tried to express the ideas in more familiar terms; I hope this paraphrase will not lead you to think they are not useful in research. Informational concepts have already proved valuable in the study of discrimination and of language; they promise a great deal in the study of learning and memory; and it has even been proposed that they can be useful in the study of concept formation. A lot of questions that seemed fruitless twenty or thirty years ago may now be worth another look. In fact, I feel that my story here must stop just as it begins to get really interesting. And finally, what about the magical number seven? What about the seven wonders of the world, the seven seas, the seven deadly sins, the seven daughters of Atlas in the Pleiades, the seven ages of man, the seven levels of hell, the seven primary colors, the seven notes of the musical scale, and the seven days of the week? What about the seven-point rating scale, the seven categories for absolute judgment, the seven objects in the span of attention, and the seven digits in the span of immediate memory? For the present I propose to withhold judgment. Perhaps there is something deep and profound behind all these sevens, something just calling out for us to discover it. But I suspect that it is only a pernicious, Pythagorean coincidence."
            },
            "slug": "The-magical-number-seven-plus-or-minus-two:-some-on-Miller",
            "title": {
                "fragments": [],
                "text": "The magical number seven plus or minus two: some limits on our capacity for processing information."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The theory provides us with a yardstick for calibrating the authors' stimulus materials and for measuring the performance of their subjects, and the concepts and measures provided by the theory provide a quantitative way of getting at some of these questions."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3076,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758056"
                        ],
                        "name": "A. Stein",
                        "slug": "A.-Stein",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Stein",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1750601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55f9b470cb7eb91797ab1553cdf9d84a11006a80",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Occlusion reasoning, necessary for tasks such as navigation and object search, is an important aspect of everyday life and a fundamental problem in computer vision. We believe that the amazing ability of humans to reason about occlusions from one image is based on an intrinsically 3D interpretation. In this paper, our goal is to recover the occlusion boundaries and depth ordering of free-standing structures in the scene. Our approach is to learn to identify and label occlusion boundaries using the traditional edge and region cues together with 3D surface and depth cues. Since some of these cues require good spatial support (i.e., a segmentation), we gradually create larger regions and use them to improve inference over the boundaries. Our experiments demonstrate the power of a scene-based approach to occlusion reasoning."
            },
            "slug": "Recovering-Occlusion-Boundaries-from-a-Single-Image-Hoiem-Stein",
            "title": {
                "fragments": [],
                "text": "Recovering Occlusion Boundaries from a Single Image"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The goal is to recover the occlusion boundaries and depth ordering of free-standing structures in the scene using the traditional edge and region cues together with 3D surface and depth cues."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114422629"
                        ],
                        "name": "G. A. Miller",
                        "slug": "G.-A.-Miller",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Miller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. A. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 15
                            }
                        ],
                        "text": "In particular, Miller (1956) argues that the human short-term memory holds seven plus-or-minus two chunks of information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15388016,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "706dd01b56d568d652935b98da1fe7613acaec41",
            "isKey": false,
            "numCitedBy": 812,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "My problem is that I have been persecuted by an integer. For seven years this number has followed me around, has intruded in my most private data, and has assaulted me from the pages of our most public journals. This number assumes a variety of disguises, being sometimes a little larger and sometimes a little smaller than usual, but never changing so much as to be unrecognizable. The persistence with which this number plagues me is far more than a random accident. There is, to quote a famous senator, a design behind it, some pattern governing its appearances. Either there really is something unusual about the number or else I am suffering from delusions of persecution. I shall begin my case history by telling you about some experiments that tested how accurately people can assign numbers to the magnitudes of various aspects of a stimulus. In the traditional language of psychology these would be called experiments in absolute"
            },
            "slug": "The-magical-number-seven,-plus-or-minus-two:-some-Miller",
            "title": {
                "fragments": [],
                "text": "The magical number seven, plus or minus two: some limits on our capacity for processing information. 1956."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The case history is told of some experiments that tested how accurately people can assign numbers to the magnitudes of various aspects of a stimulus, and how this number plagues me."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7296318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ecc15c576b54d17f7900b073e19edb2db2554f1",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep learning strategy for scene parsing, i.e. to asssign a class label to each pixel of an image. We investigate the use of deep convolutional network for modeling the complex scene label structures, relying on a supervised greedy learning strategy. Compared to standard approaches based on CRFs, our strategy does not need hand-crafted features, allows modeling more complex spatial dependencies and has a lower inference cost. Experiments over the MSRC benchmark and the LabelMe dataset show the effectiveness of our approach."
            },
            "slug": "Deep-Convolutional-Networks-for-Scene-Parsing-Grangier-Bottou",
            "title": {
                "fragments": [],
                "text": "Deep Convolutional Networks for Scene Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work proposes a deep learning strategy for scene parsing, i.e. to asssign a class label to each pixel of an image, which does not need hand-crafted features, allows modeling more complex spatial dependencies and has a lower inference cost."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 169
                            }
                        ],
                        "text": "The learning algorithms must then be expressed as stochastic sampling techniques such as Gibbs sampling, MCMC, Contrastive Divergence (Hinton et. al, 2006), or Herding (Welling,\n2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14018161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc58edaacecbcc20b8a54ad4f68648415a7b974a",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A new \"herding\" algorithm is proposed which directly converts observed moments into a sequence of pseudo-samples. The pseudo-samples respect the moment constraints and may be used to estimate (unobserved) quantities of interest. The procedure allows us to sidestep the usual approach of first learning a joint model (which is intractable) and then sampling from that model (which can easily get stuck in a local mode). Moreover, the algorithm is fully deterministic, avoiding random number generation) and does not need expensive operations such as exponentiation."
            },
            "slug": "Herding-dynamical-weights-to-learn-Welling",
            "title": {
                "fragments": [],
                "text": "Herding dynamical weights to learn"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A new \"herding\" algorithm is proposed which directly converts observed moments into a sequence of pseudo-samples which respect the moment constraints and may be used to estimate (unobserved) quantities of interest."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1306,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741426"
                        ],
                        "name": "P. Gallinari",
                        "slug": "P.-Gallinari",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Gallinari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gallinari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 628165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3fa4c1ebd90bf14c55d253806fdf9e69defd729",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a framework for training architectures composed of several modules. This framework, which uses a statistical formulation of learning systems, provides a unique formalism for describing many classical connectionist algorithms as well as complex systems where several algorithms interact. It allows to design hybrid systems which combine the advantages of connectionist algorithms as well as other learning algorithms."
            },
            "slug": "A-Framework-for-the-Cooperation-of-Learning-Bottou-Gallinari",
            "title": {
                "fragments": [],
                "text": "A Framework for the Cooperation of Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This framework, which uses a statistical formulation of learning systems, provides a unique formalism for describing many classical connectionist algorithms as well as complex systems where several algorithms interact."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599292"
                        ],
                        "name": "J. Mairal",
                        "slug": "J.-Mairal",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Mairal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mairal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699339"
                        ],
                        "name": "G. Sapiro",
                        "slug": "G.-Sapiro",
                        "structuredName": {
                            "firstName": "Guillermo",
                            "lastName": "Sapiro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sapiro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 556331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccd1282aea3cc7c3d40300d82472fc5f9f54cb8e",
            "isKey": false,
            "numCitedBy": 2456,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse coding--that is, modelling data vectors as sparse linear combinations of basis elements--is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on the large-scale matrix factorization problem that consists of learning the basis set in order to adapt it to specific data. Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis. In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various matrix factorization formulations, making it suitable for a wide range of learning problems. A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets."
            },
            "slug": "Online-Learning-for-Matrix-Factorization-and-Sparse-Mairal-Bach",
            "title": {
                "fragments": [],
                "text": "Online Learning for Matrix Factorization and Sparse Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new online optimization algorithm is proposed, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various matrix factorization formulations, making it suitable for a wide range of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747132"
                        ],
                        "name": "Marco Aiello",
                        "slug": "Marco-Aiello",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Aiello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Aiello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400949657"
                        ],
                        "name": "I. Pratt-Hartmann",
                        "slug": "I.-Pratt-Hartmann",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Pratt-Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pratt-Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98232539"
                        ],
                        "name": "J. Benthem",
                        "slug": "J.-Benthem",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Benthem",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Benthem"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 56
                            }
                        ],
                        "text": "from the definition of specific algebraic constructions (Aiello et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 140
                            }
                        ],
                        "text": "Spatial reasoning does not require the full logic apparatus but certainly benefits from the definition of specific algebraic constructions (Aiello et al., 2007.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2273499,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "517107af69d17f77bf97579fa7201a39559604b2",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "What is Spatial Logic?.- First-Order Mereotopology.- Axioms, Algebras and Topology.- Qualitative Spatial Reasoning Using Constraint Calculi.- Modal Logics of Space.- Topology and Epistemic Logic.- Logical Theories for Fragments of Elementary Geometry.- Locales and Toposes as Spaces.- Spatial Logic + Temporal Logic = ?.- Dynamic Topological Logic.- Logic of Space-Time and Relativity Theory.- Discrete Spatial Models.- Real Algebraic Geometry and Constraint Databases.- Mathematical Morphology.- Spatial Reasoning and Ontology: Parts, Wholes, and Locations."
            },
            "slug": "Handbook-of-Spatial-Logics-Aiello-Pratt-Hartmann",
            "title": {
                "fragments": [],
                "text": "Handbook of Spatial Logics"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper presents a meta- Logic of Space-Time and Relativity Theory for Spatial Reasoning and Ontology: Parts, Wholes, and Locations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35400286"
                        ],
                        "name": "Z. Harris",
                        "slug": "Z.-Harris",
                        "structuredName": {
                            "firstName": "Zellig",
                            "lastName": "Harris",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32164517,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "99eadd5e29a85f30cafef7f2c915f384715e3b89",
            "isKey": false,
            "numCitedBy": 986,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We may not be able to make you love reading, but mathematical structures of language will lead you to love reading starting from now. Book is the window to open the new world. The world that you want is in the better stage and level. World will always guide you to even the prestige stage of the life. You know, this is some of how reading will give you the kindness. In this case, more books you read more knowledge you know, but it can mean also the bore is full."
            },
            "slug": "Mathematical-structures-of-language-Harris",
            "title": {
                "fragments": [],
                "text": "Mathematical structures of language"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors may not be able to make you love reading, but mathematical structures of language will lead you to love reading starting from now."
            },
            "venue": {
                "fragments": [],
                "text": "Interscience tracts in pure and applied mathematics"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17055992,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7",
            "isKey": false,
            "numCitedBy": 12432,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "What chiefly distinguishes cerebral cortex from other parts of the central nervous system is the great diversity of its cell types and interconnexions. It would be astonishing if such a structure did not profoundly modify the response patterns of fibres coming into it. In the cat's visual cortex, the receptive field arrangements of single cells suggest that there is indeed a degree of complexity far exceeding anything yet seen at lower levels in the visual system. In a previous paper we described receptive fields of single cortical cells, observing responses to spots of light shone on one or both retinas (Hubel & Wiesel, 1959). In the present work this method is used to examine receptive fields of a more complex type (Part I) and to make additional observations on binocular interaction (Part II). This approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours. In the past, the technique of recording evoked slow waves has been used with great success in studies of functional anatomy. It was employed by Talbot & Marshall (1941) and by Thompson, Woolsey & Talbot (1950) for mapping out the visual cortex in the rabbit, cat, and monkey. Daniel & Whitteiidge (1959) have recently extended this work in the primate. Most of our present knowledge of retinotopic projections, binocular overlap, and the second visual area is based on these investigations. Yet the method of evoked potentials is valuable mainly for detecting behaviour common to large populations of neighbouring cells; it cannot differentiate functionally between areas of cortex smaller than about 1 mm2. To overcome this difficulty a method has in recent years been developed for studying cells separately or in small groups during long micro-electrode penetrations through nervous tissue. Responses are correlated with cell location by reconstructing the electrode tracks from histological material. These techniques have been applied to"
            },
            "slug": "Receptive-fields,-binocular-interaction-and-in-the-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is used to examine receptive fields of a more complex type and to make additional observations on binocular interaction and this approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Sperduti (1994) defines and compares various labelling schemes for this purpose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5853754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f03db7ef9cf309561eb02eb317b875deb8817c01",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we propose an extension to the RAAM by Pollack. This extension, the Labeling RAAM (LRAAM), can encode labeled graphs with cycles by representing pointers explicitly. Data encoded in an LRAAM can be accessed by pointer as well as by content. Direct access by content can be achieved by transforming the encoder network of the LRAAM into an analog Hopfield network with hidden units. Different access procedures can be defined depending on the access key. Sufficient conditions on the asymptotical stability of the associated Hopfield network are briefly introduced."
            },
            "slug": "Encoding-Labeled-Graphs-by-Labeling-RAAM-Sperduti",
            "title": {
                "fragments": [],
                "text": "Encoding Labeled Graphs by Labeling RAAM"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The Labeling RAAM (LRAAM), an extension to the RAAM by Pollack, can encode labeled graphs with cycles by representing pointers explicitly by transforming the encoder network of the LRAAM into an analog Hopfield network with hidden units."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": false,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145884505"
                        ],
                        "name": "V. Cherkassky",
                        "slug": "V.-Cherkassky",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Cherkassky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cherkassky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "The statistical nature of learning is now well understood (e.g., Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206755547,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "e64fecbaf4d75e0dd6711f8f335c8a53da9fd360",
            "isKey": false,
            "numCitedBy": 3182,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "If you really want to be smarter, reading can be one of the lots ways to evoke and realize. Many people who like reading will have more knowledge and experiences. Reading can be a way to gain information from economics, politics, science, fiction, literature, religion, and many others. As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book. Many people are absolutely searching for this book. It means that many love to read this kind of book."
            },
            "slug": "The-Nature-Of-Statistical-Learning-Theory-Cherkassky",
            "title": {
                "fragments": [],
                "text": "The Nature Of Statistical Learning Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "As one of the part of book categories, the nature of statistical learning theory always becomes the most wanted book."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799147"
                        ],
                        "name": "F. Ratle",
                        "slug": "F.-Ratle",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Ratle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ratle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232655"
                        ],
                        "name": "H. Mobahi",
                        "slug": "H.-Mobahi",
                        "structuredName": {
                            "firstName": "Hossein",
                            "lastName": "Mobahi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mobahi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 740114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee368e60d0b826e78f965aad8d6c7d406127104",
            "isKey": false,
            "numCitedBy": 611,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques."
            },
            "slug": "Deep-learning-via-semi-supervised-embedding-Weston-Ratle",
            "title": {
                "fragments": [],
                "text": "Deep learning via semi-supervised embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is shown how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5763563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7d60c907426cc69f9db7472df063c6de10f1a2d",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Image understanding involves analyzing many different aspects of the scene. In this paper, we are concerned with how these tasks can be combined in a way that improves the performance of each of them. Inspired by Barrow and Tenenbaum, we present a flexible framework for interfacing scene analysis processes using intrinsic images. Each intrinsic image is a registered map describing one characteristic of the scene. We apply this framework to develop an integrated 3D scene understanding system with estimates of surface orientations, occlusion boundaries, objects, camera viewpoint, and relative depth. Our experiments on a set of 300 outdoor images demonstrate that these tasks reinforce each other, and we illustrate a coherent scene understanding with automatically reconstructed 3D models."
            },
            "slug": "Closing-the-loop-in-scene-interpretation-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Closing the loop in scene interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a flexible framework for interfacing scene analysis processes using intrinsic images, and applies this framework to develop an integrated 3D scene understanding system with estimates of surface orientations, occlusion boundaries, objects, camera viewpoint, and relative depth."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736011"
                        ],
                        "name": "S. Lonardi",
                        "slug": "S.-Lonardi",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Lonardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lonardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678493"
                        ],
                        "name": "A. Starita",
                        "slug": "A.-Starita",
                        "structuredName": {
                            "firstName": "Antonina",
                            "lastName": "Starita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Starita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8792322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "743a540df7e0f35ca882667df9ed1f419e7d12c5",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present preliminary results on the application of Labeling RAAM (LRAAM) for encoding pyramids. The LRAAM is a neural network able to develop reduced representations of labeled directed graphs. The capability of such representations to preserve structural similarities is demonstrated on a pyramid. We suggest to exploit this skill in data compression and/or to discover scale affine auto-similarities.<<ETX>>"
            },
            "slug": "Encoding-pyramids-by-Labeling-RAAM-Lonardi-Sperduti",
            "title": {
                "fragments": [],
                "text": "Encoding pyramids by Labeling RAAM"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The LRAAM is a neural network able to develop reduced representations of labeled directed graphs that preserve structural similarities on a pyramid and it is suggested to exploit this skill in data compression and/or to discover scale affine auto-similarities."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Workshop on Neural Networks for Signal Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 131
                            }
                        ],
                        "text": "In particular, expressing causality with first order logic is very simple, expressing causality with probabilities is challenging (Pearl, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \"all-purpose\" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12575481,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "62064218665ad89f0cb2a44f5b19f7703d9c7e71",
            "isKey": false,
            "numCitedBy": 10949,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction to probabilities, graphs, and causal models 2. A theory of inferred causation 3. Causal diagrams and the identification of causal effects 4. Actions, plans, and direct effects 5. Causality and structural models in the social sciences 6. Simpson's paradox, confounding, and collapsibility 7. Structural and counterfactual models 8. Imperfect experiments: bounds and counterfactuals 9. Probability of causation: interpretation and identification Epilogue: the art and science of cause and effect."
            },
            "slug": "Causality:-Models,-Reasoning-and-Inference-Pearl",
            "title": {
                "fragments": [],
                "text": "Causality: Models, Reasoning and Inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 71
                            }
                        ],
                        "text": "Although there are connectionist approaches to variable binding (e.g., Smolensky, 1990), they cannot avoid the computational complexity of first-order logic problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "itrarily propositional logic expressions. Adding variables and quantifiers would provide an implementation of first order logic. Although there are connectionist approaches to variable binding (e.g., Smolensky, 1990), they cannot avoid the computational complexity of first-order logic problems. Would it be possible instead to identify capabilities that are necessary for the kind of informal and intuitive reasonin"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 125580247,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: 1. Introduction, 2. Connectionist Representation and Tensor Product Binding: Definition and Examples, 3. Tensor Product Representation: Properties, 4. Conclusion"
            },
            "slug": "Tensor-Product-Variable-Binding-and-the-of-Symbolic-Hinton",
            "title": {
                "fragments": [],
                "text": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This chapter contains sections titled connectionist Representation and Tensor Product Binding: Definition and Examples, and tensor Product Representation: Properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11212282,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "212e4bb327cc2e60d8e61867f2122f1e855d9b26",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "A host of experimental data has been accumulating on the properties and mechanisms of object recognition in cortex. We review the main findings, and summarize them using a quantitative, biologically plausible, Standard Model. The model is a tool to interpret and understand the available data, and generate questions and predictions for new experiments."
            },
            "slug": "How-Visual-Cortex-Recognizes-Objects:-The-Tale-of-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "How Visual Cortex Recognizes Objects: The Tale of the Standard Model"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A host of experimental data has been accumulating on the properties and mechanisms of object recognition in cortex, and a quantitative, biologically plausible, Standard Model is used to interpret and understand the available data, and generate questions and predictions for new experiments."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328108"
                        ],
                        "name": "Luis von Ahn",
                        "slug": "Luis-von-Ahn",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ahn",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis von Ahn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3656020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d7488328c0db4dd7deaf9eb3a110fdc6d903594",
            "isKey": false,
            "numCitedBy": 1086,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Through online games, people can collectively solve large-scale computational problems. Such games constitute a general mechanism for using brain power to solve open problems. In fact, designing such a game is much like designing an algorithm - it must be proven correct, its efficiency can be analyzed, a more efficient version can supersede a less efficient one, and so on. \"Games with a purpose\" have a vast range of applications in areas as diverse as security, computer vision, Internet accessibility, adult content filtering, and Internet search. Any game designed to address these and other problems must ensure that game play results in a correct solution and, at the same time, is enjoyable. People will play such games to be entertained, not to solve a problem - no matter how laudable the objective"
            },
            "slug": "Games-with-a-Purpose-Ahn",
            "title": {
                "fragments": [],
                "text": "Games with a Purpose"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "\"Games with a purpose\" have a vast range of applications in areas as diverse as security, computer vision, Internet accessibility, adult content filtering, and Internet search, and any game designed to address these and other problems must ensure that game play results in a correct solution and, at the same time, is enjoyable."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698617"
                        ],
                        "name": "O. Bousquet",
                        "slug": "O.-Bousquet",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Bousquet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Bousquet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7431525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5936754b5762260bf102ac95d7b26cfc9d31956a",
            "isKey": false,
            "numCitedBy": 1485,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms. The analysis shows distinct tradeoffs for the case of small-scale and large-scale learning problems. Small-scale learning problems are subject to the usual approximation-estimation tradeoff. Large-scale learning problems are subject to a qualitatively different tradeoff involving the computational complexity of the underlying optimization algorithms in non-trivial ways."
            },
            "slug": "The-Tradeoffs-of-Large-Scale-Learning-Bottou-Bousquet",
            "title": {
                "fragments": [],
                "text": "The Tradeoffs of Large Scale Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This contribution develops a theoretical framework that takes into account the effect of approximate optimization on learning algorithms and shows distinct tradeoffs for the case of small-scale and large-scale learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070756"
                        ],
                        "name": "D. Povinelli",
                        "slug": "D.-Povinelli",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povinelli",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Povinelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21074313"
                        ],
                        "name": "Theodore J. Povinelli",
                        "slug": "Theodore-J.-Povinelli",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Povinelli",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theodore J. Povinelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53194884,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "28e8c5796be094156d0b926db5a75e1813adfed7",
            "isKey": false,
            "numCitedBy": 1001,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mindblindness.-An-Essay-on-Autism-and-Theory-of-Povinelli-Povinelli",
            "title": {
                "fragments": [],
                "text": "Mindblindness. An Essay on Autism and Theory of Mind \n               \n                  \n                     \n                        Simon\n                        Baron-Cohen\n                     \n                  \n               \n               \n                  \n                     1995\n     "
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Neurosciences"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Sperduti (1994) defines and compares various labelling schemes for this purpose."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60565534,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "69d7086300e7f5322c06f2f242a565b3a182efb5",
            "isKey": false,
            "numCitedBy": 4649,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Bill Baird { Publications References 1] B. Baird. Bifurcation analysis of oscillating neural network model of pattern recognition in the rabbit olfactory bulb. In D. 3] B. Baird. Bifurcation analysis of a network model of the rabbit olfactory bulb with periodic attractors stored by a sequence learning algorithm. 5] B. Baird. Bifurcation theory methods for programming static or periodic attractors and their bifurcations in dynamic neural networks."
            },
            "slug": "In-Advances-in-Neural-Information-Processing-Hanson",
            "title": {
                "fragments": [],
                "text": "In Advances in Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 1990"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1580082333"
                        ],
                        "name": "MairalJulien",
                        "slug": "MairalJulien",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "MairalJulien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "MairalJulien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644095792"
                        ],
                        "name": "BachFrancis",
                        "slug": "BachFrancis",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "BachFrancis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "BachFrancis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643819466"
                        ],
                        "name": "PonceJean",
                        "slug": "PonceJean",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "PonceJean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "PonceJean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643894209"
                        ],
                        "name": "SapiroGuillermo",
                        "slug": "SapiroGuillermo",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "SapiroGuillermo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SapiroGuillermo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 220935013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "290db1d5064f05d3eef03b9c2146a25aba6f570d",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse coding--that is, modelling data vectors as sparse linear combinations of basis elements--is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focus..."
            },
            "slug": "Online-Learning-for-Matrix-Factorization-and-Sparse-MairalJulien-BachFrancis",
            "title": {
                "fragments": [],
                "text": "Online Learning for Matrix Factorization and Sparse Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper focuses on sparse coding of data vectors as sparse linear combinations of basis elements in the context of discrete-time reinforcement learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728216"
                        ],
                        "name": "A. Storkey",
                        "slug": "A.-Storkey",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Storkey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Storkey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 57
                            }
                        ],
                        "text": "Computer algorithms for general probabilistic inference (Pearl, 1988) still suffer from unfavorable computational properties (Roth, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 17
                            }
                        ],
                        "text": "Graphical models (Pearl 1988) describe the factorization of a joint probability distribution into elementary conditional distributions with specific conditional independence assumptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 18
                            }
                        ],
                        "text": "Graphical models (Pearl, 1988) describe the factorization of a joint probability distribution into elementary conditional distributions with specific conditional independence assumptions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "therefore answer different questions (Pearl 1988)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 56
                            }
                        ],
                        "text": "Computer algorithms for general probabilistic inference (Pearl 1988) still suffer from unfavorable computational properties (Roth 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 283
                            }
                        ],
                        "text": "\u2026distributions are highly constrained by the algebraic properties of the probability theory: if we know a subset of these conditional distributions, we can apply Bayesian inference to deduct or constrain additional conditional distributions and therefore answer different questions (Pearl, 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208023192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe95a7a1d66ebdc7d3097ebbe97de60c9630bf84",
            "isKey": true,
            "numCitedBy": 553,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ADVANCES-IN-NEURAL-INFORMATION-PROCESSING-SYSTEMS-Storkey",
            "title": {
                "fragments": [],
                "text": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 16"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70190180"
                        ],
                        "name": "S. Sutherland",
                        "slug": "S.-Sutherland",
                        "structuredName": {
                            "firstName": "Scot",
                            "lastName": "Sutherland",
                            "middleNames": [
                                "McRobert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sutherland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703604"
                        ],
                        "name": "R. Needham",
                        "slug": "R.-Needham",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Needham",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Needham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 54
                            }
                        ],
                        "text": ", with first order logic) did not fulfill these hopes (Lighthill, 1973)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 283
                            }
                        ],
                        "text": "\u2026logical inference (Robinson, 1965) share their roots with the foundations of mathematics, converting ordinary data into a consistent set of logical expressions has proved very challenging: searching the discrete spaces of symbolic formulas often leads to a combinatorial explosion (Lighthill, 1973)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 79
                            }
                        ],
                        "text": "Symbolic reasoning (e.g., with first order logic) did not fulfill these hopes (Lighthill, 1973)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 331,
                                "start": 314
                            }
                        ],
                        "text": "Although computer algorithms for logical inference (Robinson, 1965) share their roots with the foundations of mathematics, converting ordinary data into a consistent set of logical expressions has proved very challenging: searching the discrete spaces of symbolic formulas often leads to a combinatorial explosion (Lighthill, 1973)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11663685,
            "fieldsOfStudy": [],
            "id": "b586d050caa00a827fd2b318742dc80a304a3675",
            "isKey": true,
            "numCitedBy": 61,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Artificial-Intelligence-:-A-General-Survey-Sutherland-Needham",
            "title": {
                "fragments": [],
                "text": "Artificial Intelligence : A General Survey"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ciated with other formulas and therefore representing different tasks. First order logic has very high expressive power because the bulk of mathematics can formalized as first order logic statements (Hilbert and Ackermann, 1928.) This is not sufficient, however, to express the subtleties of natural language: every first order logic formula is easily expressed in natural language; the converse is not true. Finally, first ord"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 222422338,
            "fieldsOfStudy": [],
            "id": "439f147cfe58ff2e34272886bb83738f6367906f",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Grundzuge der Theoretischen Logik"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1928
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3334011"
                        ],
                        "name": "J. Piaget",
                        "slug": "J.-Piaget",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Piaget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Piaget"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Since viewpoint changes can also reveal or hide entire objects, such modules could conceivably provide a tool for constructing a vision system that implements object permanence (Piaget, 1937)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 142752531,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "83455995117e23a9f2823be2985414fdefbe227d",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "La-construction-du-r\u00e9el-chez-l'enfant-Piaget",
            "title": {
                "fragments": [],
                "text": "La construction du r\u00e9el chez l'enfant"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103862143"
                        ],
                        "name": "G. Jason",
                        "slug": "G.-Jason",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Jason",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jason"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60275120,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "21ac70b681c534cd6e7cd2a5155a0789828451f7",
            "isKey": false,
            "numCitedBy": 7789,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Logic-of-Scientific-Discovery-Jason",
            "title": {
                "fragments": [],
                "text": "The Logic of Scientific Discovery"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2712002"
                        ],
                        "name": "Kam-Chuen Jim",
                        "slug": "Kam-Chuen-Jim",
                        "structuredName": {
                            "firstName": "Kam-Chuen",
                            "lastName": "Jim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kam-Chuen Jim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35216199"
                        ],
                        "name": "B. Horne",
                        "slug": "B.-Horne",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Horne",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59881027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6d1d314786e40a552f1902d0da9b7c128accc91",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Information-Processing-Systems-7-Jim-Horne",
            "title": {
                "fragments": [],
                "text": "Neural Information Processing Systems 7"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "The statistical nature of learning is now well understood (e.g., Vapnik, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59752996,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "5451278e1a11cf3f1be28a05f38d36c8641e68f7",
            "isKey": false,
            "numCitedBy": 4580,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Nature-of-Statistical-Learning-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457047"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sohan",
                            "lastName": "Seth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1664514563"
                        ],
                        "name": "Park Il",
                        "slug": "Park-Il",
                        "structuredName": {
                            "firstName": "Park",
                            "lastName": "Il",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Park Il"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323960"
                        ],
                        "name": "A. Brockmeier",
                        "slug": "A.-Brockmeier",
                        "structuredName": {
                            "firstName": "Austin",
                            "lastName": "Brockmeier",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Brockmeier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47564876"
                        ],
                        "name": "Mulugeta Semework",
                        "slug": "Mulugeta-Semework",
                        "structuredName": {
                            "firstName": "Mulugeta",
                            "lastName": "Semework",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mulugeta Semework"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2769302"
                        ],
                        "name": "John S. Choi",
                        "slug": "John-S.-Choi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Choi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John S. Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32645462"
                        ],
                        "name": "J. Francis",
                        "slug": "J.-Francis",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Francis",
                            "middleNames": [
                                "Thachil"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Francis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143961030"
                        ],
                        "name": "J. Pr\u00edncipe",
                        "slug": "J.-Pr\u00edncipe",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Pr\u00edncipe",
                            "middleNames": [
                                "Carlos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pr\u00edncipe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59187253,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52c78f4a492ec4165a643bb14365746da858dec6",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Advances-in-Neural-Information-Processing-Systems-Seth-Il",
            "title": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems 23 (NIPS 2010)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5628684"
                        ],
                        "name": "R. Lazarus",
                        "slug": "R.-Lazarus",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lazarus",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lazarus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28928264,
            "fieldsOfStudy": [
                "Psychology",
                "Medicine"
            ],
            "id": "c77f7176a090d076340e012b7c9521af714228b2",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Subception:-fact-or-artifact-A-reply-to-Eriksen.-Lazarus",
            "title": {
                "fragments": [],
                "text": "Subception: fact or artifact? A reply to Eriksen."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52625678"
                        ],
                        "name": "L. M.-T.",
                        "slug": "L.-M.-T.",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "M.-T.",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. M.-T."
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4018018,
            "fieldsOfStudy": [],
            "id": "03c1d33a92f21e143d3568b6f76a55c01c9ae794",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Grundz\u00fcge-der-theoretischen-Logik-M.-T.",
            "title": {
                "fragments": [],
                "text": "Grundz\u00fcge der theoretischen Logik"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1929
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "This document presents an idea that results from a long maturation (Bottou, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artificial intelligence in seven years? Seminar presentation, University of Montreal, http://www.iro.umontreal.ca/~lisa/seminaires/26-06-2008.html"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "Preliminary results have been obtained using a similar procedure (Etter, 2009)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semantic vector machines. Master's thesis, EPFL"
            },
            "venue": {
                "fragments": [],
                "text": "Semantic vector machines. Master's thesis, EPFL"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "This document presents an idea that results from a long maturation (Bottou, 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \"all-purpose\" inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artificial intelligence in seven years? Seminar presentation"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial intelligence in seven years? Seminar presentation"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online Learning for Matrix Factorization"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efros , Martial Hebert . Closing the Loop on Scene Interpretation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 169
                            }
                        ],
                        "text": "The learning algorithms must then be expressed as stochastic sampling techniques such as Gibbs sampling, MCMC, Contrastive Divergence (Hinton et. al, 2006), or Herding (Welling,\n2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Herding dynamic weights to learn"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 26th international conference on machine learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pollack . Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Causality : Models , Reasoning , and Inference"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Advances in neural processing information systems"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Herding dynamic weights to learn"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . 26 th international conference on machine learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wiesel . Receptive fields , binocular interaction and functional architecture in the cat \u2019 s visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "J . Physiol ."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 283
                            }
                        ],
                        "text": "\u2026logical inference (Robinson, 1965) share their roots with the foundations of mathematics, converting ordinary data into a consistent set of logical expressions has proved very challenging: searching the discrete spaces of symbolic formulas often leads to a combinatorial explosion (Lighthill, 1973)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 79
                            }
                        ],
                        "text": "Symbolic reasoning (e.g., with first order logic) did not fulfill these hopes (Lighthill, 1973)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artificial intelligence: a general survey In Artificial intelligence: a paper symposium"
            },
            "venue": {
                "fragments": [],
                "text": "Science Research Council"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recovering Occlusion Boundaries"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 178
                            }
                        ],
                        "text": "Since viewpoint changes can also reveal or hide entire objects, such modules could conceivably provide a tool for constructing a vision system that implements object permanence (Piaget, 1937)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "La construction du r\u00e9el chez l'enfant. Neuchatel: Delachaux et Niestl\u00e9"
            },
            "venue": {
                "fragments": [],
                "text": "La construction du r\u00e9el chez l'enfant. Neuchatel: Delachaux et Niestl\u00e9"
            },
            "year": 1937
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Herding Dynamic Weights to Learn"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 26th International Conference on Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syntactic Parsing with Recursive Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS Deep Learning workshop presentation,"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 133
                            }
                        ],
                        "text": "Just like non-falsifiable statistical models, non-falsifiable reasoning systems are unlikely to have useful predictive capabilities (Popper, 1959; Vapnik, 1994.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The logic of scientific discovery. Stroudsburg: Dowden"
            },
            "venue": {
                "fragments": [],
                "text": "The logic of scientific discovery. Stroudsburg: Dowden"
            },
            "year": 1959
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 23,
            "methodology": 8
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 81,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/From-machine-learning-to-machine-reasoning-Bottou/cb7853c5d609081ea12cd4db3863a87da2d51808?sort=total-citations"
}