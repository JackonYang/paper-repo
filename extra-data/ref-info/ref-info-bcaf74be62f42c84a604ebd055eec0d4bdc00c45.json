{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143570879"
                        ],
                        "name": "Yue Xu",
                        "slug": "Yue-Xu",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820427"
                        ],
                        "name": "Fei Yin",
                        "slug": "Fei-Yin",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145274329"
                        ],
                        "name": "Zhaoxiang Zhang",
                        "slug": "Zhaoxiang-Zhang",
                        "structuredName": {
                            "firstName": "Zhaoxiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaoxiang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689269"
                        ],
                        "name": "Cheng-Lin Liu",
                        "slug": "Cheng-Lin-Liu",
                        "structuredName": {
                            "firstName": "Cheng-Lin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng-Lin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 51606465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff423f519938a32f669798edb7c1e0e80f0cfcb5",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Layout analysis is a fundamental process in document image analysis and understanding.\u00a0It consists of several sub-processes such as page segmentation, text line segmentation, baseline detection and so on.\u00a0In this work, we propose a multi-task layout analysis method that use a single FCN model to solve the above three problems simultaneously.\u00a0The FCN is trained to segment the document image into different regions and detect the center line of each text line by classifying pixels into different categories.\u00a0By supervised learning on document images with pixel-wise labels, the FCN can extract discriminative features and perform pixel-wise classification accurately.\u00a0After pixel-wise classification, post-processing steps are taken to reduce noises, correct wrong segmentations and find out overlapping regions.\u00a0Experimental results on the public dataset DIVA-HisDB containing challenging medieval manuscripts demonstrate the effectiveness and superiority of the proposed method."
            },
            "slug": "Multi-task-Layout-Analysis-for-Historical-Documents-Xu-Yin",
            "title": {
                "fragments": [],
                "text": "Multi-task Layout Analysis for Historical Handwritten Documents Using Fully Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results on the public dataset DIVA-HisDB containing challenging medieval manuscripts demonstrate the effectiveness and superiority of the proposed multi-task layout analysis method."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 76
                            }
                        ],
                        "text": "2, Section 1) of this work, we utilize depth-separable convolutional blocks [Howard et al., 2017; Sandler et al., 2018] with inverted residual connections (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 98
                            }
                        ],
                        "text": "2, Section 1) of this work, we utilize depth-separable convolutional blocks [Howard et al., 2017; Sandler et al., 2018] with inverted residual connections (i.e., skip-connections joining two bottleneck layers) to construct a fast and memory-efficient network for this purpose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 76
                            }
                        ],
                        "text": "We closely followed the parameter settings of the MobileNetV2 architecture [Sandler et al., 2018] in our implementation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4555207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4",
            "isKey": false,
            "numCitedBy": 7177,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters."
            },
            "slug": "MobileNetV2:-Inverted-Residuals-and-Linear-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new mobile architecture, MobileNetV2, is described that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes and allows decoupling of the input/output domains from the expressiveness of the transformation."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3245784"
                        ],
                        "name": "Ritesh Sarkhel",
                        "slug": "Ritesh-Sarkhel",
                        "structuredName": {
                            "firstName": "Ritesh",
                            "lastName": "Sarkhel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ritesh Sarkhel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723341"
                        ],
                        "name": "N. Das",
                        "slug": "N.-Das",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50317213"
                        ],
                        "name": "Aritra Das",
                        "slug": "Aritra-Das",
                        "structuredName": {
                            "firstName": "Aritra",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aritra Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143995288"
                        ],
                        "name": "M. Kundu",
                        "slug": "M.-Kundu",
                        "structuredName": {
                            "firstName": "Mahantapas",
                            "lastName": "Kundu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kundu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729425"
                        ],
                        "name": "M. Nasipuri",
                        "slug": "M.-Nasipuri",
                        "structuredName": {
                            "firstName": "Mita",
                            "lastName": "Nasipuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nasipuri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27630106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b400a042732ffa02c0677753dd4cc42868f1b97",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-multi-scale-deep-quad-tree-based-feature-method-Sarkhel-Das",
            "title": {
                "fragments": [],
                "text": "A multi-scale deep quad tree based feature extraction method for the recognition of isolated handwritten characters of popular indic scripts"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47316088"
                        ],
                        "name": "Priya Goyal",
                        "slug": "Priya-Goyal",
                        "structuredName": {
                            "firstName": "Priya",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Priya Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 116
                            }
                        ],
                        "text": "To address the issue of imbalanced class distribution in the training corpus, we trained LadderNet on a focal-loss [Lin et al., 2018] based learning objective."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47252984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72564a69bf339ff1d16a639c86a764db2321caab",
            "isKey": false,
            "numCitedBy": 8230,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron."
            },
            "slug": "Focal-Loss-for-Dense-Object-Detection-Lin-Goyal",
            "title": {
                "fragments": [],
                "text": "Focal Loss for Dense Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to address the extreme foreground-background class imbalance encountered during training of dense detectors by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples, and develops a novel Focal Loss, which focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113239725"
                        ],
                        "name": "Arindam Das",
                        "slug": "Arindam-Das",
                        "structuredName": {
                            "firstName": "Arindam",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arindam Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47115629"
                        ],
                        "name": "Saikat Roy",
                        "slug": "Saikat-Roy",
                        "structuredName": {
                            "firstName": "Saikat",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saikat Roy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2435807"
                        ],
                        "name": "U. Bhattacharya",
                        "slug": "U.-Bhattacharya",
                        "structuredName": {
                            "firstName": "Ujjwal",
                            "lastName": "Bhattacharya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Bhattacharya"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 124
                            }
                        ],
                        "text": "To ensure fair comparison, we follow similar experimental designs as suggested by previous researchers [Kumar et al., 2014; Das et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "[Das et al., 2018] have shown that an ensemble of region-based classifiers can also be employed for this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 27
                            }
                        ],
                        "text": "More recently, Das et al. [Das et al., 2018] have shown that an ensemble of region-based classifiers can also be employed for this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "The final baseline method (A4) [Das et al., 2018] in our experimental setup is an ensemble of region-specific CNN\u2019s, combining individual predictions to infer the final class-label."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9888225,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af8785b368ed988b8dbd4cb34f52dd36eb535c3d",
            "isKey": true,
            "numCitedBy": 45,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, a region-based Deep Convolutional Neural Network framework is presented for document structure learning. The contribution of this work involves efficient training of region based classifiers and effective ensembling for document image classification. A primary level of \u2018inter-domain\u2019 transfer learning is used by exporting weights from a pre-trained VGG16 architecture on the ImageNet dataset to train a document classifier on whole document images. Exploiting the nature of region based influence modelling, a secondary level of \u2018intra-domain\u2019 transfer learning is used for rapid training of deep learning models for image segments. Finally, a stacked generalization based ensembling is utilized for combining the predictions of the base deep neural network models. The proposed method achieves state-of-the-art accuracy of 92.21% on the popular RVL-CDIP document image dataset, exceeding the benchmarks set by the existing algorithms."
            },
            "slug": "Document-Image-Classification-with-Intra-Domain-and-Das-Roy",
            "title": {
                "fragments": [],
                "text": "Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The proposed region-based Deep Convolutional Neural Network framework for document structure learning achieves state-of-the-art accuracy of 92.21% on the popular RVL-CDIP document image dataset, exceeding the benchmarks set by the existing algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2018 24th International Conference on Pattern Recognition (ICPR)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052874785"
                        ],
                        "name": "Chaojie Mao",
                        "slug": "Chaojie-Mao",
                        "structuredName": {
                            "firstName": "Chaojie",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chaojie Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47001714"
                        ],
                        "name": "Yingming Li",
                        "slug": "Yingming-Li",
                        "structuredName": {
                            "firstName": "Yingming",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yingming Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116565742"
                        ],
                        "name": "Yaqing Zhang",
                        "slug": "Yaqing-Zhang",
                        "structuredName": {
                            "firstName": "Yaqing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaqing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720488"
                        ],
                        "name": "Zhongfei Zhang",
                        "slug": "Zhongfei-Zhang",
                        "structuredName": {
                            "firstName": "Zhongfei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhongfei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116226546"
                        ],
                        "name": "Xi Li",
                        "slug": "Xi-Li",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 95
                            }
                        ],
                        "text": "It has been established in recent past [Gordo et al., 2013; Lazebnik et al., 2006; Lowe, 2004; Mao et al., 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al., 2013; Bagdanov and Worring, 2001; Afzal et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 39
                            }
                        ],
                        "text": "It has been established in recent past [Gordo et al., 2013; Lazebnik et al., 2006; Lowe, 2004; Mao et al., 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3727304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c572562a906f6c94d8f2e91895c161cbb0fa4cc",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n In this work, we present a Multi-Channel deep convolutional Pyramid Person Matching Network (MC-PPMN) based on the combination of the semantic-components and the color-texture distributions to address the problem of person re-identification. In particular, we learn separate deep representations for semantic-components and color-texture distributions from two person images and then employ pyramid person matching network (PPMN) to obtain correspondence representations. These correspondence representations are fused to perform the re-identification task. Further, the proposed framework is optimized via a unified end-to-end deep learning scheme. Extensive experiments on several benchmark datasets demonstrate the effectiveness of our approach against the state-of-the-art literature, especially on the rank-1 recognition rate.\n \n"
            },
            "slug": "Multi-Channel-Pyramid-Person-Matching-Network-for-Mao-Li",
            "title": {
                "fragments": [],
                "text": "Multi-Channel Pyramid Person Matching Network for Person Re-Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A Multi-Channel deep convolutional Pyramid Person Matching Network (MC-PPMN) based on the combination of the semantic-components and the color-texture distributions to address the problem of person re-identification is presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145181206"
                        ],
                        "name": "Muhammad Zeshan Afzal",
                        "slug": "Muhammad-Zeshan-Afzal",
                        "structuredName": {
                            "firstName": "Muhammad",
                            "lastName": "Afzal",
                            "middleNames": [
                                "Zeshan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muhammad Zeshan Afzal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285356"
                        ],
                        "name": "Samuele Capobianco",
                        "slug": "Samuele-Capobianco",
                        "structuredName": {
                            "firstName": "Samuele",
                            "lastName": "Capobianco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuele Capobianco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49012494"
                        ],
                        "name": "M. I. Malik",
                        "slug": "M.-I.-Malik",
                        "structuredName": {
                            "firstName": "Muhammad",
                            "lastName": "Malik",
                            "middleNames": [
                                "Imran"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36241428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec65a13db7e387971ec017c721da4c26aeee29c0",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a deep Convolutional Neural Network (CNN) based approach for document image classification. One of the main requirement of deep CNN architecture is that they need huge number of samples for training. To overcome this problem we adopt a deep CNN which is trained using big image dataset containing millions of samples i.e., ImageNet. The proposed work outperforms both the traditional structure similarity methods and the CNN based approaches proposed earlier. The accuracy of the proposed approach with merely 20 images per class outperforms the state-of-the-art by achieving classification accuracy of 68.25%. The best results on Tobbacoo-3428 dataset show that our proposed method outperforms the state-of-the-art method by a significant margin and achieved a median accuracy of 77.6% with 100 samples per class used for training and validation."
            },
            "slug": "Deepdocclassifier:-Document-classification-with-Afzal-Capobianco",
            "title": {
                "fragments": [],
                "text": "Deepdocclassifier: Document classification with deep Convolutional Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A deep Convolutional Neural Network (CNN) based approach for document image classification which is trained using big image dataset containing millions of samples and outperforms both the traditional structure similarity methods and the CNN based approaches proposed earlier."
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on Document Analysis and Recognition (ICDAR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115301179"
                        ],
                        "name": "Sheng He",
                        "slug": "Sheng-He",
                        "structuredName": {
                            "firstName": "Sheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799278"
                        ],
                        "name": "Lambert Schomaker",
                        "slug": "Lambert-Schomaker",
                        "structuredName": {
                            "firstName": "Lambert",
                            "lastName": "Schomaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lambert Schomaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 89
                            }
                        ],
                        "text": "Generating highquality transcription of real-world documents is also not a trivial task [He and Schomaker, 2017; Sarkhel et al., 2016; 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10048990,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e382c7407aaafab92bd399d815153a37988ac326",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Beyond-OCR:-Multi-faceted-understanding-of-document-He-Schomaker",
            "title": {
                "fragments": [],
                "text": "Beyond OCR: Multi-faceted understanding of handwritten document characteristics"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 60
                            }
                        ],
                        "text": "It has been established in recent past [Gordo et al., 2013; Lazebnik et al., 2006; Lowe, 2004; Mao et al., 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al., 2013; Bagdanov and Worring, 2001; Afzal et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 39
                            }
                        ],
                        "text": "It has been established in recent past [Gordo et al., 2013; Lazebnik et al., 2006; Lowe, 2004; Mao et al., 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": false,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 76
                            }
                        ],
                        "text": "2, Section 1) of this work, we utilize depth-separable convolutional blocks [Howard et al., 2017; Sandler et al., 2018] with inverted residual connections (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 143
                            }
                        ],
                        "text": "Once the feature descriptors corresponding to the selected level have been computed, classification is performed using a depth-wise separable [Howard et al., 2017] multi-column convolutional network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 77
                            }
                        ],
                        "text": "2, Section 1) of this work, we utilize depth-separable convolutional blocks [Howard et al., 2017; Sandler et al., 2018] with inverted residual connections (i.e., skip-connections joining two bottleneck layers) to construct a fast and memory-efficient network for this purpose."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10142,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449660"
                        ],
                        "name": "Peng Ye",
                        "slug": "Peng-Ye",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 211
                            }
                        ],
                        "text": "\u2026[Harley et al., 2015] (scanned images from the IIT-CDIP [Lewis et al., 2006] collection, containing document categories such as \u2018letter\u2019, \u2018memo\u2019, \u2018email\u2019, \u2018form\u2019, \u2018invoice\u2019 etc.) and the Tobacco litigation dataset (D4) [Kumar et al., 2014] (a sample of 3482 documents from the IITCDIP collection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 104
                            }
                        ],
                        "text": "To ensure fair comparison, we follow similar experimental designs as suggested by previous researchers [Kumar et al., 2014; Das et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 26
                            }
                        ],
                        "text": "Our second baseline (A2) [Kumar et\nal., 2014] utilizes vertical and horizontal pooling operations to compute multi-scale SURF descriptors [Bay et al., 2006] for encoding each document."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 21
                            }
                        ],
                        "text": "Later, Kumar et al. [Kumar et al., 2014] proposed a static zoning scheme, recursively partitioning each document using vertical and horizontal grids and aggregating features extracted from each zone to encode a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "Few\n1the one-to-one mapping between structural components of two documents such that the parallel connectivity [Forbus et al., 1995] is preserved [Kumar et al., 2014]\nworks have explored this approach to classify visually rich documents by extracting multi-scale feature descriptors in recent past."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207329118,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7ae643f8c1f987e6ba61f177a340e879a8644e0",
            "isKey": true,
            "numCitedBy": 71,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Structural-similarity-for-document-image-and-Kumar-Ye",
            "title": {
                "fragments": [],
                "text": "Structural similarity for document image classification and retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746914"
                        ],
                        "name": "Sinno Jialin Pan",
                        "slug": "Sinno-Jialin-Pan",
                        "structuredName": {
                            "firstName": "Sinno",
                            "lastName": "Pan",
                            "middleNames": [
                                "Jialin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sinno Jialin Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 740063,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a25fbcbbae1e8f79c4360d26aa11a3abf1a11972",
            "isKey": false,
            "numCitedBy": 13492,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research."
            },
            "slug": "A-Survey-on-Transfer-Learning-Pan-Yang",
            "title": {
                "fragments": [],
                "text": "A Survey on Transfer Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 21
                            }
                        ],
                        "text": ", 1995] is preserved [Kumar et al., 2014] Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 211
                            }
                        ],
                        "text": "\u2026[Harley et al., 2015] (scanned images from the IIT-CDIP [Lewis et al., 2006] collection, containing document categories such as \u2018letter\u2019, \u2018memo\u2019, \u2018email\u2019, \u2018form\u2019, \u2018invoice\u2019 etc.) and the Tobacco litigation dataset (D4) [Kumar et al., 2014] (a sample of 3482 documents from the IITCDIP collection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "[Kumar et al., 2014] proposed a static zoning scheme, recursively partitioning each document using vertical and horizontal grids and aggregating features extracted from each zone to encode a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 104
                            }
                        ],
                        "text": "To ensure fair comparison, we follow similar experimental designs as suggested by previous researchers [Kumar et al., 2014; Das et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 26
                            }
                        ],
                        "text": "Our second baseline (A2) [Kumar et\nal., 2014] utilizes vertical and horizontal pooling operations to compute multi-scale SURF descriptors [Bay et al., 2006] for encoding each document."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 21
                            }
                        ],
                        "text": "Later, Kumar et al. [Kumar et al., 2014] proposed a static zoning scheme, recursively partitioning each document using vertical and horizontal grids and aggregating features extracted from each zone to encode a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 42
                            }
                        ],
                        "text": ") and the Tobacco litigation dataset (D4) [Kumar et al., 2014] (a sample of 3482 documents from the IITCDIP collection)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 147
                            }
                        ],
                        "text": "Few\n1the one-to-one mapping between structural components of two documents such that the parallel connectivity [Forbus et al., 1995] is preserved [Kumar et al., 2014]\nworks have explored this approach to classify visually rich documents by extracting multi-scale feature descriptors in recent past."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207771766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22d8fed235451886670cd8756e4df9788cfc519c",
            "isKey": true,
            "numCitedBy": 729,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning, Specifically, Representation Learning, Semi-Supervised Learning, Self-Supervised Learning, Domain Adaptation, Incremental Learning Deep Texture object Abstract A concise and factual abstract is required. The abstract should state briefly the purpose of the research, the principal results and major conclusions. An abstract is often presented separately from the article, so it must be able to stand alone. For this reason, References should be avoided, but if essential, then cite the author(s) and year(s). Also, non-standard or uncommon abbreviations should be avoided, but if essential they must be defined at their first mention in the abstract itself."
            },
            "slug": "PATTERN-RECOGNITION-LETTERS",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition Letters"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A concise and factual abstract is required that state briefly the purpose of the research, the principal results and major conclusions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068255843"
                        ],
                        "name": "Christopher Hunt",
                        "slug": "Christopher-Hunt",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Hunt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Hunt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 139
                            }
                        ],
                        "text": "Our second baseline (A2) [Kumar et\nal., 2014] utilizes vertical and horizontal pooling operations to compute multi-scale SURF descriptors [Bay et al., 2006] for encoding each document."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 100
                            }
                        ],
                        "text": ", 2014] utilizes vertical and horizontal pooling operations to compute multi-scale SURF descriptors [Bay et al., 2006] for encoding each document."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 161878,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c7cf406a47048730c1a08d46cb0166b16566524",
            "isKey": false,
            "numCitedBy": 6212,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this document, the SURF detector-descriptor scheme used in the OpenSURF library is discussed in detail. First the algorithm is analysed from a theoretical standpoint to provide a detailed overview of how and why it works. Next the design and development choices for the implementation of the library are discussed and justified. During the implementation of the library, it was found that some of the finer details of the algorithm had been omitted or overlooked, so Section 1.5 serves to make clear the concepts which are not explicitly defined in the SURF paper [1]."
            },
            "slug": "SURF:-Speeded-Up-Robust-Features-Hunt",
            "title": {
                "fragments": [],
                "text": "SURF: Speeded-Up Robust Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "In this document, the SURF detector-descriptor scheme used in the OpenSURF library is discussed in detail and the algorithm is analysed from a theoretical standpoint to provide a detailed overview of how and why it works."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713121"
                        ],
                        "name": "Kenneth D. Forbus",
                        "slug": "Kenneth-D.-Forbus",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Forbus",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth D. Forbus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704065"
                        ],
                        "name": "D. Gentner",
                        "slug": "D.-Gentner",
                        "structuredName": {
                            "firstName": "Dedre",
                            "lastName": "Gentner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gentner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30867581"
                        ],
                        "name": "K. Law",
                        "slug": "K.-Law",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Law",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Law"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 106
                            }
                        ],
                        "text": "the one-to-one mapping between structural components of two documents such that the parallel connectivity [Forbus et al., 1995] is preserved [Kumar et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 112
                            }
                        ],
                        "text": "Few\n1the one-to-one mapping between structural components of two documents such that the parallel connectivity [Forbus et al., 1995] is preserved [Kumar et al., 2014]\nworks have explored this approach to classify visually rich documents by extracting multi-scale feature descriptors in recent past."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5606121,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "a0fea0e9514f6d62ab91b522e94a1be46839c1d9",
            "isKey": false,
            "numCitedBy": 862,
            "numCiting": 185,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model of similarity-based retrieval that attempts to capture three seemingly contradictory psychological phenomena: (a) structural commonalities are weighed more heavily than surface commonalities in similarity judgments for items in working memory; (b) in retrieval, superficial similarity is more important than structural similarity; and yet (c) purely structural (analogical) remindings e sometimes experienced. Our model, MAC/FAC, explains these phenomena in terms of a two-stage process. The first stage uses a computationally cheap, non-structural matcher to filter candidate long-term memory items. It uses content vectors, a redundant encoding of structured representations whose dot product estimates how well the corresponding structural representations will match. The second stage uses SME (structure-mapping engine) to compute structural matches on the handful of items found by the first stage. We show the utility of the MAC/FAC model through a series of computational experiments: (a) We demonstrate that MAC/FAC can model patterns of access found in psychological data; (b) we argue via sensitivity analyses that these simulation results rely on the theory; and (c) we compare the performance of MAC/FAC with ARCS, an alternate model of similarity-based retrieval, and demonstrate that MAC/FAC explains the data better than ARCS. Finally, we discuss limitations and possible extensions of the model, relationships with other recent retrieval models, and place MAC/FAC in the context of other recent work on the nature of similarity."
            },
            "slug": "MAC/FAC:-A-Model-of-Similarity-Based-Retrieval-Forbus-Gentner",
            "title": {
                "fragments": [],
                "text": "MAC/FAC: A Model of Similarity-Based Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A model of similarity-based retrieval that attempts to capture three seemingly contradictory psychological phenomena, showing that structural commonalities are weighed more heavily than surface commonalities in similarity judgments for items in working memory and that MAC/FAC can model patterns of access found in psychological data."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409864786"
                        ],
                        "name": "Lilong Jiang",
                        "slug": "Lilong-Jiang",
                        "structuredName": {
                            "firstName": "Lilong",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lilong Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40367147"
                        ],
                        "name": "Protiva Rahman",
                        "slug": "Protiva-Rahman",
                        "structuredName": {
                            "firstName": "Protiva",
                            "lastName": "Rahman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Protiva Rahman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145781033"
                        ],
                        "name": "Arnab Nandi",
                        "slug": "Arnab-Nandi",
                        "structuredName": {
                            "firstName": "Arnab",
                            "lastName": "Nandi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnab Nandi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44108519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77b429da0537b2428f929b96cae9512f1bd13924",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Highly interactive query interfaces have become a popular tool for ad-hoc data analysis and exploration, posing a new kind of workload to the underlying data infrastructure. Compared with traditional systems that are optimized for throughput or batched performance, ad-hoc and interactive data exploration systems focus more on user-centric interactivity, which raises a new class of performance challenges. Further, with the advent of new interaction devices~(e.g., touch, gesture) and different query interface paradigms~(e.g., sliders), maintaining interactive performance becomes even more challenging. Thus, when building interactive data systems, there is a clear need to articulate the design space. In this tutorial, we will describe unique characteristics of interactive workloads for a variety of user input devices and query interfaces. We will catalog popular metrics based on an extensive survey of current literature. Through two case studies, we will not only walk through previously defined metrics using real-world user traces but also highlight where these defined metrics are inadequate. Further, we will introduce some new metrics that are required to capture a complete picture of interactivity. In each case study, we also demonstrate how the behavior analyses on users' trace and performance experiments can provide guidelines to help researchers and developers design better interactive data systems."
            },
            "slug": "Evaluating-Interactive-Data-Systems:-Workloads,-and-Jiang-Rahman",
            "title": {
                "fragments": [],
                "text": "Evaluating Interactive Data Systems: Workloads, Metrics, and Guidelines"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This tutorial describes unique characteristics of interactive workloads for a variety of user input devices and query interfaces and introduces some new metrics that are required to capture a complete picture of interactivity."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3245784"
                        ],
                        "name": "Ritesh Sarkhel",
                        "slug": "Ritesh-Sarkhel",
                        "structuredName": {
                            "firstName": "Ritesh",
                            "lastName": "Sarkhel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ritesh Sarkhel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723341"
                        ],
                        "name": "N. Das",
                        "slug": "N.-Das",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47162530"
                        ],
                        "name": "Amit K. Saha",
                        "slug": "Amit-K.-Saha",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Saha",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit K. Saha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729425"
                        ],
                        "name": "M. Nasipuri",
                        "slug": "M.-Nasipuri",
                        "structuredName": {
                            "firstName": "Mita",
                            "lastName": "Nasipuri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nasipuri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 113
                            }
                        ],
                        "text": "Generating highquality transcription of real-world documents is also not a trivial task [He and Schomaker, 2017; Sarkhel et al., 2016; 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8463541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f6321eb3d3e10887701db43a066c6d3cc9e2b8",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-multi-objective-approach-towards-cost-effective-Sarkhel-Das",
            "title": {
                "fragments": [],
                "text": "A multi-objective approach towards cost effective isolated handwritten Bangla character and digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35151749"
                        ],
                        "name": "G. Agam",
                        "slug": "G.-Agam",
                        "structuredName": {
                            "firstName": "Gady",
                            "lastName": "Agam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Agam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741208"
                        ],
                        "name": "O. Frieder",
                        "slug": "O.-Frieder",
                        "structuredName": {
                            "firstName": "Ophir",
                            "lastName": "Frieder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Frieder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693690"
                        ],
                        "name": "D. Grossman",
                        "slug": "D.-Grossman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grossman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Grossman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20833434"
                        ],
                        "name": "J. Heard",
                        "slug": "J.-Heard",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Heard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Heard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19516087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47c6d10fe8a29fcd1727e805a2b9f804c12e0d4d",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Research and development of information access technology for scanned paper documents has been hampered by the lack of public test collections of realistic scope and complexity. As part of a project to create a prototype system for search and mining of masses of document images, we are assembling a 1.5 terabyte dataset to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution."
            },
            "slug": "Building-a-test-collection-for-complex-document-Lewis-Agam",
            "title": {
                "fragments": [],
                "text": "Building a test collection for complex document information processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A 1.5 terabyte dataset is assembled to support evaluation of both end-to-end complex document information processing (CDIP) tasks (e.g., text retrieval and data mining) as well as component technologies such as optical character recognition (OCR), document structure analysis, signature matching, and authorship attribution."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157708855"
                        ],
                        "name": "R. Smith",
                        "slug": "R.-Smith",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7038773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89d9aae7e0c8b6edd56d0d79b277c07b7ab66fda",
            "isKey": false,
            "numCitedBy": 1509,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier."
            },
            "slug": "An-Overview-of-the-Tesseract-OCR-Engine-Smith",
            "title": {
                "fragments": [],
                "text": "An Overview of the Tesseract OCR Engine"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 83
                            }
                        ],
                        "text": "It has been established in recent past [Gordo et al., 2013; Lazebnik et al., 2006; Lowe, 2004; Mao et al., 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al., 2013; Bagdanov and Worring, 2001; Afzal et al.,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25500,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777046"
                        ],
                        "name": "V. Sadaphal",
                        "slug": "V.-Sadaphal",
                        "structuredName": {
                            "firstName": "Vaishali",
                            "lastName": "Sadaphal",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sadaphal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724642"
                        ],
                        "name": "J. Haritsa",
                        "slug": "J.-Haritsa",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Haritsa",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Haritsa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725067"
                        ],
                        "name": "U. Dayal",
                        "slug": "U.-Dayal",
                        "structuredName": {
                            "firstName": "Umeshwar",
                            "lastName": "Dayal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Dayal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143722566"
                        ],
                        "name": "Prasad Deshpande",
                        "slug": "Prasad-Deshpande",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Deshpande",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Deshpande"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 94
                            }
                        ],
                        "text": "Along with traditional linguistic cues, these documents also use a number of visual modifiers [Sarkhel and Nandi, 2019] to augment/highlight the semantics of different visual areas appearing in them."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 86606410,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfadbe2cc48051ef240f1044fc1d329ae0d49e9b",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "For close to two decades, the International Conference on Management of Data (COMAD), modeled along the lines of ACM SIGMOD, has been the premier international database conference hosted in India. The first COMAD was held in Hyderabad in 1989, and the most recent version was hosted in Nagpur during December 2010. The 17th edition in the COMAD series will be held at the International Institute of Information Technology, Bangalore (IIITB), during December 19-21, 2011. Bangalore, also called Bengaluru, is nicknamed the Garden City, and was once called a pensioner's paradise. Today, it is better known as the primary hub for India's Information Technology sector. \n \nCOMAD seeks to provide the community of researchers, practitioners, developers and users of data management technologies, a forum to present and discuss problems, solutions, innovations, experiences and emerging trends. During the past few years, the scope of COMAD 2011 has expanded to include, in addition to traditional database areas, topics in Web, Information Retrieval and Data Mining."
            },
            "slug": "Proceedings-of-the-2019-International-Conference-on-Sadaphal-Haritsa",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 2019 International Conference on Management of Data"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The 17th edition in the COMAD series will be held at the International Institute of Information Technology, Bangalore (IIITB), during December 19-21, 2011, and will include topics in Web, Information Retrieval and Data Mining."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062976420"
                        ],
                        "name": "W. McLeod",
                        "slug": "W.-McLeod",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "McLeod",
                            "middleNames": [
                                "H.",
                                "Dennis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. McLeod"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 76
                            }
                        ],
                        "text": "It is initialized with pre-trained ImageNet weights (L1-transfer of weights [Pan and Yang, 2010])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61300822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed163f11318db2f29e0036277868159c61bcf47b",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "With the advent of the Internet, we are seeing more sophisticated techniques being developed to support e-Iearning. The rapid developme nt of Web-based learning and new concepts like virtual classrooms, virtual laboratories and virtual universities introduces many new issues to be addressed. On the technical side, we need to develop effective e-technologies for supporting distance education. On the learning and management side, we need to consider issues such as new style of learning and different system set-u p requirements. Finally, the issue of standardization of e-Iearning systems should also be considered. In this special issue, our focus will be on the technical side, although other issues related to knowledge and data engineering for e-Iearning may also be considered. Topics: In this special issue, we call for original papers describing novel knowledge and data engineering techniques that support e-Iearning. Preference will be given to papers that include an evaluation of users' experience in using the proposed methods. Areas of interests include, but are not limited to: \u2022 Semantic Web technology for e-Iearning \u2022 Data modeling (eg., XML) for efficient management of course materials \u2022 Searching and indexing techniques to suppo rt effective course notes retrieval \u2022 User-centric e-Iearning systems and user interaction management \u2022 Profiling techniques to support grading and learning recommendation \u2022 Data and knowledge base suppo rt for pervasive e-Iearning \u2022 Course material analysis and understanding \u2022 Automatic generation of questions and answers \u2022 Collaborative communities for e-Iearning"
            },
            "slug": "Knowledge-and-Data-Engineering-for-e-Learning-Issue-McLeod",
            "title": {
                "fragments": [],
                "text": "Knowledge and Data Engineering for e-Learning Special Issue of IEEE Transactions on Knowledge and Data Engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "In this special issue, the focus will be on the technical side, although other issues related to knowledge and data engineering for e-Iearning may also be considered."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2184331"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Rosenfeld",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "Each convolutional block is followed by batch-normalization [LeCun et al., 2015] and a Rectified Linear Unit [LeCun et al., 2015]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 49
                            }
                        ],
                        "text": "Replacing this with a traditional convolutional [LeCun et al., 2015] architecture results in a significant decrease in accuracy for D2, D3, and D4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 60
                            }
                        ],
                        "text": "Each convolutional block is followed by batch-normalization [LeCun et al., 2015] and a Rectified Linear Unit [LeCun et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 9
                            }
                        ],
                        "text": "RMSProp [LeCun et al., 2015] is used for parameter training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": ", 2015] and a Rectified Linear Unit [LeCun et al., 2015]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209344565,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "794c364f77621bee08b7985c51ef5c9169f4442c",
            "isKey": true,
            "numCitedBy": 60380,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Nature-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Nature"
            },
            "venue": {
                "fragments": [],
                "text": "Otolaryngology--head and neck surgery : official journal of American Academy of Otolaryngology-Head and Neck Surgery"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143673416"
                        ],
                        "name": "Anthony Axon",
                        "slug": "Anthony-Axon",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Axon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Axon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097924696"
                        ],
                        "name": "S. Hewitt",
                        "slug": "S.-Hewitt",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Hewitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hewitt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 85
                            }
                        ],
                        "text": "We construct TD recursively, using a popular open-source page segmentation algorithm [Smith, 2007]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 239779663,
            "fieldsOfStudy": [],
            "id": "32e98773056f9a9e3ba5d87afe19ca77eb1f7a6f",
            "isKey": false,
            "numCitedBy": 1162,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "2007-Axon-Hewitt",
            "title": {
                "fragments": [],
                "text": "2007"
            },
            "venue": {
                "fragments": [],
                "text": "Syria 1975/76-2018"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122942"
                        ],
                        "name": "B. Ripley",
                        "slug": "B.-Ripley",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Ripley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ripley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107314775"
                        ],
                        "name": "C. C. Taylor",
                        "slug": "C.-C.-Taylor",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Taylor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. C. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 113
                            }
                        ],
                        "text": "Generating highquality transcription of real-world documents is also not a trivial task [He and Schomaker, 2017; Sarkhel et al., 2016; 2017]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1625830,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "ca23e7a71ace53d6a5b2a553ff37c63365d22b8a",
            "isKey": false,
            "numCitedBy": 5721,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-Recognition-Ripley-Taylor",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113979381"
                        ],
                        "name": "Xing Hao",
                        "slug": "Xing-Hao",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Hao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Hao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8273966"
                        ],
                        "name": "Guigang Zhang",
                        "slug": "Guigang-Zhang",
                        "structuredName": {
                            "firstName": "Guigang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guigang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118869556"
                        ],
                        "name": "Shang Ma",
                        "slug": "Shang-Ma",
                        "structuredName": {
                            "firstName": "Shang",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1779661,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "4f8d648c52edf74e41b0996128aa536e13cc7e82",
            "isKey": false,
            "numCitedBy": 30722,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deep-Learning-Hao-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Semantic Comput."
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 43
                            }
                        ],
                        "text": "These are: the NIST special dataset-6 (D1) [NIST, 2018] (filled tax-forms from the IRS-1040 package, 1988), the Medical Article Records Groundtruth (MARG) dataset (D2) [Thoma, 2003] (front pages of scanned biomedical journals from the National Library of Medicine), the RVLCDIP dataset (D3) [Harley et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 44
                            }
                        ],
                        "text": "These are: the NIST special dataset-6 (D1) [NIST, 2018] (filled tax-forms from the IRS-1040 package, 1988), the Medical Article Records Groundtruth (MARG) dataset (D2) [Thoma, 2003] (front pages of scanned biomedical journals from the National Library of Medicine), the RVLCDIP dataset (D3) [Harley\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nist special database 6"
            },
            "venue": {
                "fragments": [],
                "text": "https://www.nist.gov/ srd/nist-special-database-6,"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 74
                            }
                        ],
                        "text": "The first work to utilize this approach successfully was Cesarini et al. [Cesarini et al., 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 27
                            }
                        ],
                        "text": "Our first competitor (A1) [Cesarini et al., 2001] proposes a modified XY-tree based encoding technique to represent each document using carefully designed handcrafted features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "pages 1131\u2013 1136"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "\u2026(MARG) dataset (D2) [Thoma, 2003] (front pages of scanned biomedical journals from the National Library of Medicine), the RVLCDIP dataset (D3) [Harley et al., 2015] (scanned images from the IIT-CDIP [Lewis et al., 2006] collection, containing document categories such as \u2018letter\u2019, \u2018memo\u2019,\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 312,
                                "start": 291
                            }
                        ],
                        "text": "These are: the NIST special dataset-6 (D1) [NIST, 2018] (filled tax-forms from the IRS-1040 package, 1988), the Medical Article Records Groundtruth (MARG) dataset (D2) [Thoma, 2003] (front pages of scanned biomedical journals from the National Library of Medicine), the RVLCDIP dataset (D3) [Harley et al., 2015] (scanned images from the IIT-CDIP [Lewis et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Document Analysis and Recognition (ICDAR)"
            },
            "venue": {
                "fragments": [],
                "text": "2015 13th International Conference on, pages 991\u2013995. IEEE,"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 39
                            }
                        ],
                        "text": "It has been established in recent past [Gordo et al., 2013; Lazebnik et al., 2006; Lowe, 2004; Mao et al., 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "International journal of computer vision"
            },
            "venue": {
                "fragments": [],
                "text": "60(2):91\u2013110,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 168
                            }
                        ],
                        "text": "These are: the NIST special dataset-6 (D1) [NIST, 2018] (filled tax-forms from the IRS-1040 package, 1988), the Medical Article Records Groundtruth (MARG) dataset (D2) [Thoma, 2003] (front pages of scanned biomedical journals from the National Library of Medicine), the RVLCDIP dataset (D3) [Harley et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 150
                            }
                        ],
                        "text": "\u2026special dataset-6 (D1) [NIST, 2018] (filled tax-forms from the IRS-1040 package, 1988), the Medical Article Records Groundtruth (MARG) dataset (D2) [Thoma, 2003] (front pages of scanned biomedical journals from the National Library of Medicine), the RVLCDIP dataset (D3) [Harley et al., 2015]\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ground truth data for document image analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Symposium on document image understanding and technology (SDIUT), pages 199\u2013205"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 271
                            }
                        ],
                        "text": "\u2026is marginal compared to the overhead in end-to-end inference turnaround, making it impractical to deploy them in scenarios where the average inference time is constrained (e.g. augmented reality applications, gesture-based interactive workflows) by a threshold (\u2248500ms) [Jiang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 93
                            }
                        ],
                        "text": "augmented reality applications, gesture-based interactive workflows) by a threshold (\u2248500ms) [Jiang et al., 2018]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evaluating interactive data systems: Workloads"
            },
            "venue": {
                "fragments": [],
                "text": "metrics, and guidelines. In Proceedings of the 2018 International Conference on Management of Data, pages 1637\u20131644. ACM,"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 128
                            }
                        ],
                        "text": ", 2018] that scale-invariant local patterns encoded by multi-scale feature descriptors outperform its single-scale counterparts [Gordo et al., 2013; Bagdanov and Worring, 2001; Afzal et al., 2015] in this scenario."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "pages 79\u201383,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 86
                            }
                        ],
                        "text": "We define five levels of layout hierarchy using a standard specification format (hOCR [Breuel, 2007])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "venue": {
                "fragments": [],
                "text": "volume 2, pages 1063\u20131067, Sept"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 123
                            }
                        ],
                        "text": "Each of the five columns in our multi-column architecture is trained in parallel, on separate, morphologically intersected [Patin, 2003] versions of the training corpus at l level of layout abstraction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "online]: http://www"
            },
            "venue": {
                "fragments": [],
                "text": "programmersheaven. com/articles/patin/ImageProc. pdf,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "[Xu et al., 2018] took a similar approach for layout analysis of historical documents in a multi-task setting using an ensemble of fully-connected convolutional neural networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 44
                            }
                        ],
                        "text": "Although not for classification, Xu et al. [Xu et al., 2018] took a similar approach for layout analysis of historical documents in a multi-task setting using an ensemble of fully-connected convolutional neural networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "In Proceedings of the 27th International Joint Conference on Artificial Intelligence"
            },
            "venue": {
                "fragments": [],
                "text": "pages 1057\u20131063. AAAI Press,"
            },
            "year": 2018
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 18
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Deterministic-Routing-between-Layout-Abstractions-Sarkhel-Nandi/bcaf74be62f42c84a604ebd055eec0d4bdc00c45?sort=total-citations"
}