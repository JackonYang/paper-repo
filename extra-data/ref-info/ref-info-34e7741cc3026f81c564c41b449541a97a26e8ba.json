{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3349120"
                        ],
                        "name": "Tom\u00e1s Voj\u00edr",
                        "slug": "Tom\u00e1s-Voj\u00edr",
                        "structuredName": {
                            "firstName": "Tom\u00e1s",
                            "lastName": "Voj\u00edr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom\u00e1s Voj\u00edr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 197680336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcba52c59e8537e48e747207837cefd04786bd3d",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents contributions to the design of the Flock of Trackers (FoT). The FoT trackers estimate the pose of the tracked object by robustly combining displacement estimates from local trackers that cover the object. The first contribution, called the Cell FoT, allows local trackers to drift to points good to track. The Cell FoT was compared with the Kalal et al. Grid FoT [4] and outperformed it on all sequences but one and for all local failure prediction methods. As a second contribution, we introduce two new predictors of local tracker failure the neighbourhood consistency predictor (Nh) and the Markov predictor (Mp) and show that the new predictors combined with the NCC predictor are more powerful than the Kalal et al. [4] predictor based on NCC and FB. The resulting tracker equipped with the new predictors combined with the NCC predictor was compared with state-of-the-art tracking algorithms and surpassed them in terms of the number of sequences where a given tracking algorithm performed best."
            },
            "slug": "Robustifying-the-Flock-of-Trackers-Voj\u00edr-Matas",
            "title": {
                "fragments": [],
                "text": "Robustifying the Flock of Trackers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Two new predictors of local tracker failure the neighbourhood consistency predictor (Nh) and the Markov predictor (Mp) are introduced and it is shown that the new predictor combined with the NCC predictor are more powerful than the Kalal et al."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2314629"
                        ],
                        "name": "M. K\u00f6lsch",
                        "slug": "M.-K\u00f6lsch",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "K\u00f6lsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. K\u00f6lsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 951751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36b4ed1c2cdcd5acff711eb7d1fe712d4a7d2854",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces \"Flocks of Features,\" a fast tracking method for non-rigid and highly articulated objects such as hands. It combines KLT features and a learned foreground color distribution to facilitate 2D position tracking from a monocular view. The tracker's benefits lie in its speed, its robustness against background noise, and its ability to track objects that undergo arbitrary rotations and vast and rapid deformations. We demonstrate tracker performance on hand tracking with a non-stationary camera in unconstrained indoor and outdoor environments. The tracker yields over threefold improvement over a CamShift tracker in terms of the number of frames tracked before the target was lost, and often more than one order of magnitude improvement in terms of the fractions of particular test sequences tracked successfully."
            },
            "slug": "Fast-2D-Hand-Tracking-with-Flocks-of-Features-and-K\u00f6lsch-Turk",
            "title": {
                "fragments": [],
                "text": "Fast 2D Hand Tracking with Flocks of Features and Multi-Cue Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "This paper introduces \"Flocks of Features,\" a fast tracking method for non-rigid and highly articulated objects such as hands that combines KLT features and a learned foreground color distribution to facilitate 2D position tracking from a monocular view."
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2791125"
                        ],
                        "name": "Zdenek Kalal",
                        "slug": "Zdenek-Kalal",
                        "structuredName": {
                            "firstName": "Zdenek",
                            "lastName": "Kalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zdenek Kalal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 208933582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c63a34ac6a4e049118070e707ca7679fbb132d33",
            "isKey": false,
            "numCitedBy": 2782,
            "numCiting": 153,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning, and detection. The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates the detector's errors and updates it to avoid these errors in the future. We study how to identify the detector's errors and learn from them. We develop a novel learning method (P-N learning) which estimates the errors by a pair of \u201cexperts\u201d: (1) P-expert estimates missed detections, and (2) N-expert estimates false alarms. The learning process is modeled as a discrete dynamical system and the conditions under which the learning guarantees improvement are found. We describe our real-time implementation of the TLD framework and the P-N learning. We carry out an extensive quantitative evaluation which shows a significant improvement over state-of-the-art approaches."
            },
            "slug": "Tracking-Learning-Detection-Kalal",
            "title": {
                "fragments": [],
                "text": "Tracking-Learning-Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning, and detection, and develops a novel learning method (P-N learning) which estimates the errors by a pair of \u201cexperts\u201d: P-expert estimates missed detections, and N-ex Expert estimates false alarms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089588"
                        ],
                        "name": "S. Shahed",
                        "slug": "S.-Shahed",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Shahed",
                            "middleNames": [
                                "M.",
                                "Nejhum"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shahed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144850973"
                        ],
                        "name": "J. Ho",
                        "slug": "J.-Ho",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715634"
                        ],
                        "name": "Ming-Hsuan Yang",
                        "slug": "Ming-Hsuan-Yang",
                        "structuredName": {
                            "firstName": "Ming-Hsuan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Hsuan Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5918425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4397ec32d628f54ea70a8921026fa0c01258c993",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm for accurate tracking of (articulated) objects using online update of appearance and shape. The challenge here is to model foreground appearance with histograms in a way that is both efficient and accurate. In this algorithm, the constantly changing foreground shape is modeled as a small number of rectangular blocks, whose positions within the tracking window are adaptively determined. Under the general assumption of stationary foreground appearance, we show that robust object tracking is possible by adaptively adjusting the locations of these blocks. Implemented in MATLAB without substantial optimization, our tracker runs already at 3.7 frames per second on a 3 GHz machine. Experimental results have demonstrated that the algorithm is able to efficiently track articulated objects undergoing large variation in appearance and shape."
            },
            "slug": "Visual-tracking-with-histograms-and-articulating-Shahed-Ho",
            "title": {
                "fragments": [],
                "text": "Visual tracking with histograms and articulating blocks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Under the general assumption of stationary foreground appearance, it is shown that robust object tracking is possible by adaptively adjusting the locations of these blocks, whose positions within the tracking window are adaptively determined."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 559739,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2cfa006b33084abe8160b001f9a24944cda25d05",
            "isKey": false,
            "numCitedBy": 3282,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences."
            },
            "slug": "Real-time-tracking-of-non-rigid-objects-using-mean-Comaniciu-Ramesh",
            "title": {
                "fragments": [],
                "text": "Real-time tracking of non-rigid objects using mean shift"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution for real time tracking of non-rigid objects seen from a moving camera."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2791125"
                        ],
                        "name": "Zdenek Kalal",
                        "slug": "Zdenek-Kalal",
                        "structuredName": {
                            "firstName": "Zdenek",
                            "lastName": "Kalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zdenek Kalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13175840,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "719b816653c43cd0b0298d1092bb1479a1049fdb",
            "isKey": false,
            "numCitedBy": 772,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a novel method for tracking failure detection. The detection is based on the Forward-Backward error, i.e. the tracking is performed forward and backward in time and the discrepancies between these two trajectories are measured. We demonstrate that the proposed error enables reliable detection of tracking failures and selection of reliable trajectories in video sequences. We demonstrate that the approach is complementary to commonly used normalized cross-correlation (NCC). Based on the error, we propose a novel object tracker called Median Flow. State-of-the-art performance is achieved on challenging benchmark video sequences which include non-rigid objects."
            },
            "slug": "Forward-Backward-Error:-Automatic-Detection-of-Kalal-Mikolajczyk",
            "title": {
                "fragments": [],
                "text": "Forward-Backward Error: Automatic Detection of Tracking Failures"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated that the proposed error enables reliable detection of tracking failures and selection of reliable trajectories in video sequences and is complementary to commonly used normalized cross-correlation (NCC)."
            },
            "venue": {
                "fragments": [],
                "text": "2010 20th International Conference on Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31982493"
                        ],
                        "name": "Amit Adam",
                        "slug": "Amit-Adam",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amit Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782918"
                        ],
                        "name": "I. Shimshoni",
                        "slug": "I.-Shimshoni",
                        "structuredName": {
                            "firstName": "Ilan",
                            "lastName": "Shimshoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Shimshoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206590783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15cd7d675e499d6e53014916d7cf4a1714341f6a",
            "isKey": false,
            "numCitedBy": 1532,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel algorithm (which we call \"Frag- Track\") for tracking an object in a video sequence. The template object is represented by multiple image fragments or patches. The patches are arbitrary and are not based on an object model (in contrast with traditional use of modelbased parts e.g. limbs and torso in human tracking). Every patch votes on the possible positions and scales of the object in the current frame, by comparing its histogram with the corresponding image patch histogram. We then minimize a robust statistic in order to combine the vote maps of the multiple patches. A key tool enabling the application of our algorithm to tracking is the integral histogram data structure [18]. Its use allows to extract histograms of multiple rectangular regions in the image in a very efficient manner. Our algorithm overcomes several difficulties which cannot be handled by traditional histogram-based algorithms [8, 6]. First, by robustly combining multiple patch votes, we are able to handle partial occlusions or pose change. Second, the geometric relations between the template patches allow us to take into account the spatial distribution of the pixel intensities - information which is lost in traditional histogram-based algorithms. Third, as noted by [18], tracking large targets has the same computational cost as tracking small targets. We present extensive experimental results on challenging sequences, which demonstrate the robust tracking achieved by our algorithm (even with the use of only gray-scale (noncolor) information)."
            },
            "slug": "Robust-Fragments-based-Tracking-using-the-Integral-Adam-Rivlin",
            "title": {
                "fragments": [],
                "text": "Robust Fragments-based Tracking using the Integral Histogram"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel algorithm for tracking an object in a video sequence represented by multiple image fragments or patches, which is able to handle partial occlusions or pose change and overcomes several difficulties which cannot be handled by traditional histogram-based algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145551629"
                        ],
                        "name": "H. Grabner",
                        "slug": "H.-Grabner",
                        "structuredName": {
                            "firstName": "Helmut",
                            "lastName": "Grabner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Grabner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692368"
                        ],
                        "name": "P. Cattin",
                        "slug": "P.-Cattin",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Cattin",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cattin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6028758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c02589e0b99a1759036daecce355ee50fefb0e2e",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Objects are usually embedded into context. Visual context has been successfully used in object detection tasks, however, it is often ignored in object tracking. We propose a method to learn supporters which are, be it only temporally, useful for determining the position of the object of interest. Our approach exploits the General Hough Transform strategy. It couples the supporters with the target and naturally distinguishes between strongly and weakly coupled motions. By this, the position of an object can be estimated even when it is not seen directly (e.g., fully occluded or outside of the image region) or when it changes its appearance quickly and significantly. Experiments show substantial improvements in model-free tracking as well as in the tracking of \u201cvirtual\u201d points, e.g., in medical applications."
            },
            "slug": "Tracking-the-invisible:-Learning-where-the-object-Grabner-Matas",
            "title": {
                "fragments": [],
                "text": "Tracking the invisible: Learning where the object might be"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a method to learn supporters which are, be it only temporally, useful for determining the position of the object of interest and exploits the General Hough Transform strategy."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110140"
                        ],
                        "name": "Junseok Kwon",
                        "slug": "Junseok-Kwon",
                        "structuredName": {
                            "firstName": "Junseok",
                            "lastName": "Kwon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junseok Kwon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2135837"
                        ],
                        "name": "Kyoung Mu Lee",
                        "slug": "Kyoung-Mu-Lee",
                        "structuredName": {
                            "firstName": "Kyoung",
                            "lastName": "Lee",
                            "middleNames": [
                                "Mu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyoung Mu Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5864474,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eb5c1e094e8ca47a74395044262e2235e0803ba",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel tracking algorithm for the target of which geometric appearance changes drastically over time. To track it, we present a local patch-based appearance model and provide an efficient scheme to evolve the topology between local patches by on-line update. In the process of on-line update, the robustness of each patch in the model is estimated by a new method of measurement which analyzes the landscape of local mode of the patch. This patch can be moved, deleted or newly added, which gives more flexibility to the model. Additionally, we introduce the Basin Hopping Monte Carlo (BHMC) sampling method to our tracking problem to reduce the computational complexity and deal with the problem of getting trapped in local minima. The BHMC method makes it possible for our appearance model to consist of enough numbers of patches. Since BHMC uses the same local optimizer that is used in the appearance modeling, it can be efficiently integrated into our tracking framework. Experimental results show that our approach tracks the object whose geometric appearance is drastically changing, accurately and robustly."
            },
            "slug": "Tracking-of-a-non-rigid-object-via-patch-based-and-Kwon-Lee",
            "title": {
                "fragments": [],
                "text": "Tracking of a non-rigid object via patch-based dynamic appearance modeling and adaptive Basin Hopping Monte Carlo sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel tracking algorithm for the target of which geometric appearance changes drastically over time is proposed and the Basin Hopping Monte Carlo (BHMC) sampling method is introduced to reduce the computational complexity and deal with the problem of getting trapped in local minima."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": false,
            "numCitedBy": 15951,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700928"
                        ],
                        "name": "O. Chum",
                        "slug": "O.-Chum",
                        "structuredName": {
                            "firstName": "Ond\u0159ej",
                            "lastName": "Chum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15181392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "11bec3f6e2318f334d58bf6d9d80b67ab41355b4",
            "isKey": false,
            "numCitedBy": 677,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A new enhancement of ransac, the locally optimized ransac (lo-ransac), is introduced. It has been observed that, to find an optimal solution (with a given probability), the number of samples drawn in ransac is significantly higher than predicted from the mathematical model. This is due to the incorrect assumption, that a model with parameters computed from an outlier-free sample is consistent with all inliers. The assumption rarely holds in practice. The locally optimized ransac makes no new assumptions about the data, on the contrary \u2013 it makes the above-mentioned assumption valid by applying local optimization to the solution estimated from the random sample."
            },
            "slug": "Locally-Optimized-RANSAC-Chum-Matas",
            "title": {
                "fragments": [],
                "text": "Locally Optimized RANSAC"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The locally optimized ransac makes no new assumptions about the data, on the contrary \u2013 it makes the above-mentioned assumption valid by applying local optimization to the solution estimated from the random sample."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30613168"
                        ],
                        "name": "Craig W. Reynolds",
                        "slug": "Craig-W.-Reynolds",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Reynolds",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig W. Reynolds"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 546350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0800357049444fb80588f264d68e0c23f9b12a19",
            "isKey": false,
            "numCitedBy": 6782,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "The aggregate motion of a flock of birds, a herd of land animals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle systems, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natural flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates according to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the \"animator.\" The aggregate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds."
            },
            "slug": "Flocks,-herds-and-schools:-A-distributed-behavioral-Reynolds",
            "title": {
                "fragments": [],
                "text": "Flocks, herds and schools: A distributed behavioral model"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually, an elaboration of a particle systems, with the simulated birds being the particles."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2791125"
                        ],
                        "name": "Zdenek Kalal",
                        "slug": "Zdenek-Kalal",
                        "structuredName": {
                            "firstName": "Zdenek",
                            "lastName": "Kalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zdenek Kalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1991688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2ea318fa9a6c56aac5aef133e16ce3307bb02af",
            "isKey": false,
            "numCitedBy": 1162,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows that the performance of a binary classifier can be significantly improved by the processing of structured unlabeled data, i.e. data are structured if knowing the label of one example restricts the labeling of the others. We propose a novel paradigm for training a binary classifier from labeled and unlabeled examples that we call P-N learning. The learning process is guided by positive (P) and negative (N) constraints which restrict the labeling of the unlabeled set. P-N learning evaluates the classifier on the unlabeled data, identifies examples that have been classified in contradiction with structural constraints and augments the training set with the corrected samples in an iterative process. We propose a theory that formulates the conditions under which P-N learning guarantees improvement of the initial classifier and validate it on synthetic and real data. P-N learning is applied to the problem of on-line learning of object detector during tracking. We show that an accurate object detector can be learned from a single example and an unlabeled video sequence where the object may occur. The algorithm is compared with related approaches and state-of-the-art is achieved on a variety of objects (faces, pedestrians, cars, motorbikes and animals)."
            },
            "slug": "P-N-learning:-Bootstrapping-binary-classifiers-by-Kalal-Matas",
            "title": {
                "fragments": [],
                "text": "P-N learning: Bootstrapping binary classifiers by structural constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "It is shown that the performance of a binary classifier can be significantly improved by the processing of structured unlabeled data, and a theory that formulates the conditions under which P-N learning guarantees improvement of the initial classifier is proposed and validated on synthetic and real data."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40588702"
                        ],
                        "name": "B. D. Lucas",
                        "slug": "B.-D.-Lucas",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lucas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2121536,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "a06547951c97b2a32f23a6c2b5f79c8c75c9b9bd",
            "isKey": false,
            "numCitedBy": 13327,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Image registration finds a variety of applications in computer vision. Unfortunately, traditional image registration techniques tend to be costly. We present a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration. Our technique is taster because it examines far fewer potential matches between the images than existing techniques Furthermore, this registration technique can be generalized to handle rotation, scaling and shearing. We show how our technique can be adapted tor use in a stereo vision system."
            },
            "slug": "An-Iterative-Image-Registration-Technique-with-an-Lucas-Kanade",
            "title": {
                "fragments": [],
                "text": "An Iterative Image Registration Technique with an Application to Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents a new image registration technique that makes use of the spatial intensity gradient of the images to find a good match using a type of Newton-Raphson iteration, and can be generalized to handle rotation, scaling and shearing."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mean 0.874\u00b10.033 0.890\u00b10.043"
            },
            "venue": {
                "fragments": [],
                "text": "Mean 0.874\u00b10.033 0.890\u00b10.043"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bootstrapping Binary Classifiers by Structural Constraints. CVPR"
            },
            "venue": {
                "fragments": [],
                "text": "Bootstrapping Binary Classifiers by Structural Constraints. CVPR"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 16,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/The-Enhanced-Flock-of-Trackers-Voj\u00edr-Matas/34e7741cc3026f81c564c41b449541a97a26e8ba?sort=total-citations"
}