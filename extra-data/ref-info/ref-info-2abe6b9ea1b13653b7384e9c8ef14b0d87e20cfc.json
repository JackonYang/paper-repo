{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 123
                            }
                        ],
                        "text": "Weighted k-NN (k-nearest neighbor) classifiers have been consistently strong performers in text categorization evaluations (Yang, 1999; Yang and Liu, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 14
                            }
                        ],
                        "text": "While useful, OHSUMED has disadvantages: it does not contain the full text of documents, its medical language is hard for non-experts to understand, and its category hierarchy (MeSH) is huge and structurally complex."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 239
                            }
                        ],
                        "text": "This partly reflects the importance of text categorization as an application area for machine learning, but also results from the availability of text categorization test collections (Lewis, Schapire, Callan, and Papka, 1996; Lewis, 1997; Yang, 1999; Sebastiani, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 210
                            }
                        ],
                        "text": "Indeed, the only widely available text categorization test collection of comparable size is OHSUMED (Hersh, Buckley, Leone, and Hickman, 1994; Lewis, Schapire, Callan, and Papka, 1996; Yang and Pedersen, 1997; Yang, 1999) at 348,566 documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 133
                            }
                        ],
                        "text": "6.2 k-NN\nWeighted k-NN (k-nearest neighbor) classifiers have been consistently strong performers in text categorization evaluations (Yang, 1999; Yang and Liu, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 93891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890c16ca29a781a7b793c603822ffd57aee9f57f",
            "isKey": false,
            "numCitedBy": 2034,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on a comparative evaluation of a wide-range of text categorization methods, including previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration variations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that exclude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performance; except for a Naive Bayes approach, the other learning algorithms also performed relatively well."
            },
            "slug": "An-Evaluation-of-Statistical-Approaches-to-Text-Yang",
            "title": {
                "fragments": [],
                "text": "An Evaluation of Statistical Approaches to Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2255753"
                        ],
                        "name": "D. Khmelev",
                        "slug": "D.-Khmelev",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Khmelev",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Khmelev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1869302"
                        ],
                        "name": "W. Teahan",
                        "slug": "W.-Teahan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Teahan",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Teahan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7316639,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9bccdbb61e07b0d0630ceb0ddaad8cf5219d2df1",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We suggest a way for locating duplicates and plagiarisms in a text collection using an R-measure, which is the normalized sum of the lengths of all suffixes of the text repeated in other documents of the collection. The R-measure can be effectively computed using the suffix array data structure. Additionally, the computation procedure can be improved to locate the sets of duplicate or plagiarised documents. We applied the technique to several standard text collections and found that they contained a significant number of duplicate and plagiarised documents. Another reformulation of the method leads to an algorithm that can be applied to supervised multi-class categorization. We illustrate the approach using the recently available Reuters Corpus Volume 1 (RCV1). The results show that the method outperforms SVM at multi-class categorization, and interestingly, that results correlate strongly with compression-based methods."
            },
            "slug": "A-repetition-based-measure-for-verification-of-text-Khmelev-Teahan",
            "title": {
                "fragments": [],
                "text": "A repetition based measure for verification of text collections and for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show that the method outperforms SVM at multi-class categorization, and interestingly, that results correlate strongly with compression-based methods."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32440409"
                        ],
                        "name": "T. Rose",
                        "slug": "T.-Rose",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Rose",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Rose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144795097"
                        ],
                        "name": "Mark Stevenson",
                        "slug": "Mark-Stevenson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Stevenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Stevenson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068521476"
                        ],
                        "name": "Miles Whitehead",
                        "slug": "Miles-Whitehead",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Whitehead",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miles Whitehead"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9239414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590cfa38094122f42412d747350229f79b7e6412",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Reuters, the global information, news and technology group, has for the first time made available free of charge, large quantities of archived Reuters news stories for use by research communities around the world. The Reuters Corpus Volume 1 (RCV1) includes over 800,000 news stories typical of the annual English language news output of Reuters. This paper describes the origins of RCV1, the motivations behind its creation, and how it differs from previous corpora. In addition we discuss the system of category coding, whereby each story is annotated for topic, region and industry sector. We also discuss the process by which these codes were applied, and examine the issues involved in maintaining quality and consistency of coding in an operational, commercial environment."
            },
            "slug": "The-Reuters-Corpus-Volume-1-from-Yesterday\u2019s-News-Rose-Stevenson",
            "title": {
                "fragments": [],
                "text": "The Reuters Corpus Volume 1 -from Yesterday\u2019s News to Tomorrow\u2019s Language Resources"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The origins of RCV1, the motivations behind its creation, and how it differs from previous corpora are described, and the system of category coding, whereby each story is annotated for topic, region and industry sector is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845150"
                        ],
                        "name": "Monica Rogati",
                        "slug": "Monica-Rogati",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Rogati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Monica Rogati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 129
                            }
                        ],
                        "text": "The feature set for a combination was chosen by first ranking the 47,152 features by their \u03c72 max score (Yang and Pedersen, 1997; Rogati and Yang, 2002) with respect to the category set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7098682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e792a3353996dd43f2e0744baadf6b7157ace6ac",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports a controlled study on a large number of filter feature selection methods for text classification. Over 100 variants of five major feature selection criteria were examined using four well-known classification algorithms: a Naive Bayesian (NB) approach, a Rocchio-style classifier, a k-nearest neighbor (kNN) method and a Support Vector Machine (SVM) system. Two benchmark collections were chosen as the testbeds: Reuters-21578 and small portion of Reuters Corpus Version 1 (RCV1), making the new results comparable to published results. We found that feature selection methods based on chi2 statistics consistently outperformed those based on other criteria (including information gain) for all four classifiers and both data collections, and that a further increase in performance was obtained by combining uncorrelated and high-performing feature selection methods.The results we obtained using only 3% of the available features are among the best reported, including results obtained with the full feature set."
            },
            "slug": "High-performing-feature-selection-for-text-Rogati-Yang",
            "title": {
                "fragments": [],
                "text": "High-performing feature selection for text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is found that feature selection methods based on chi2 statistics consistently outperformed those based on other criteria (including information gain) for all four classifiers and both data collections, and that a further increase in performance was obtained by combining uncorrelated and high-performing feature selection Methods."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "To use these models for classification, we use the SCut strategy (Yang, 2001), i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 74
                            }
                        ],
                        "text": "The core SCutFBR algorithm can be used with other fallback ranks as well (Yang, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 121
                            }
                        ],
                        "text": "Thresholds for those scoring models were found by wrapping the core training algorithm within Yang\u2019s SCutFBR.1 algorithm (Yang, 2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 38
                            }
                        ],
                        "text": "Other category assignment strategies (Yang, 2001) besides SCut were evaluated on the training data, but Scut was consistently superior so only it was used to produce classifiers evaluated on the test data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1 algorithm (Yang, 2001)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 66
                            }
                        ],
                        "text": "To use these models for classification, we use the SCut strategy (Yang, 2001), i.e., simply associating a threshold value with each category, and assigning the category to a document when the score for that category exceeds the threshold."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3342722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01f3a2d40a748fdd571f9cdb6fc402118919307e",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Thresholding strategies in automated text categorization are an underexplored area of research. This paper presents an examination of the effect of thresholding strategies on the performance of a classifier under various conditions. Using k-Nearest Neighbor (kNN) as the classifier and five evaluation benchmark collections as the testbets, three common thresholding methods were investigated, including rank-based thresholding (RCut), proportion-based assignments (PCut) and score-based local optimization (SCut); in addition, new variants of these methods are proposed to overcome significant problems in the existing approaches. Experimental results show that the choice of thresholding strategy can significantly influence the performance of kNN, and that the ``optimal'' strategy may vary by application. SCut is potentially better for fine-tuning but risks overfitting. PCut copes better with rare categories and exhibits a smoother trade-off in recall versus precision, but is not suitable for online decision making. RCut is most natural for online response but is too coarse-grained for global or local optimization. RTCut, a new method combining the strength of category ranking and scoring, outperforms both PCut and RCut significantly."
            },
            "slug": "A-study-of-thresholding-strategies-for-text-Yang",
            "title": {
                "fragments": [],
                "text": "A study of thresholding strategies for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results show that the choice of thresholding strategy can significantly influence the performance of kNN, and that the ``optimal'' strategy may vary by application."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 239
                            }
                        ],
                        "text": "The problem has been particularly severe for researchers interested in hierarchical text categorization who, due to the lack of good collections and good documentation, have often been forced to impose their own hierarchies on categories (Koller and Sahami, 1997; Weigend, Wiener and Pedersen, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2112467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23354987095a8a9a283ce4c9a690522d6b11e2dd",
            "isKey": false,
            "numCitedBy": 1089,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The proliferation of topic hierarchies for text documents has resulted in a need for tools that automatically classify new documents within such hierarchies. One can use existing classifiers by ignoring the hierarchical structure, treating the topics as separate classes. Unfortunately, in the context of text categorization, we are faced with a large number of classes and a huge number of relevant features needed to distinguish between them. Consequently, we are restricted to using only very simple classifiers, both because of computational cost and the tendency of complex models to overfit. We propose an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree. As we show, each of these smaller problems can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand. This set of relevant features varies widely throughout the hierarchy, so that, while the overall relevant feature set may be large, each classifier only examines a small subset. The use of reduced feature sets allows us to utilize more complex (probabilistic) models, without encountering the computational and robustness difficulties described above."
            },
            "slug": "Hierarchically-Classifying-Documents-Using-Very-Few-Koller-Sahami",
            "title": {
                "fragments": [],
                "text": "Hierarchically Classifying Documents Using Very Few Words"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree, which can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889602"
                        ],
                        "name": "Erik D. Wiener",
                        "slug": "Erik-D.-Wiener",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Wiener",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik D. Wiener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14603963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acf17f7365669ab9aceabc5f1760ef20898254fa",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "With the recent dramatic increase in electronic access to documents, text categorization\u2014the task of assigning topics to a given document\u2014has moved to the center of the information sciences and knowledge management. This article uses the structure that is present in the semantic space of topics in order to improve performance in text categorization: according to their meaning, topics can be grouped together into \u201cmeta-topics\u201d, e.g., gold, silver, and copper are all metals. The proposed architecture matches the hierarchical structure of the topic space, as opposed to a flat model that ignores the structure. It accommodates both single and multiple topic assignments for each document. Its probabilistic interpretation allows its predictions to be combined in a principled way with information from other sources. The first level of the architecture predicts the probabilities of the meta-topic groups. This allows the individual models for each topic on the second level to focus on finer discriminations within the group. Evaluating the performance of a two-level implementation on the Reuters-22173 testbed of newswire articles shows the most significant improvement for rare classes."
            },
            "slug": "Exploiting-Hierarchy-in-Text-Categorization-Weigend-Wiener",
            "title": {
                "fragments": [],
                "text": "Exploiting Hierarchy in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The structure that is present in the semantic space of topics is used in order to improve performance in text categorization: according to their meaning, topics can be grouped together into \u201cmeta-topics\u201d, e.g., gold, silver, and copper are all metals."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 526032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6160d37a7871cef2d6450832507b53201aa66682",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "While certain standard procedures are widely used for evaluating text retrieval systems and algorithms, the same is not true for text categorization. Omission of important data from reports is common and methods of measuring effectiveness vary widely. This has made judging the relative merits of techniques for text categorization difficult and has disguised important research issues.In this paper I discuss a variety of ways of evaluating the effectiveness of text categorization systems, drawing both on reported categorization experiments and on methods used in evaluating query-driven retrieval. I also consider the extent to which the same evaluation methods may be used with systems for text extraction, a more complex task. In evaluating either kind of system, the purpose for which the output is to be used is crucial in choosing appropriate evaluation methods."
            },
            "slug": "Evaluating-Text-Categorization-I-Lewis",
            "title": {
                "fragments": [],
                "text": "Evaluating Text Categorization I"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A variety of ways of evaluating the effectiveness of text categorization systems are discussed, drawing both on reported categorization experiments and on methods used in evaluating query-driven retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 36
                            }
                        ],
                        "text": "0 instead, or possibly other values (Lewis, 1995)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 91
                            }
                        ],
                        "text": "We measure the effectiveness of a text classifier on a single category with the F\u03b2 measure (van Rijsbergen, 1972, 1979; Lewis, 1995):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 119
                            }
                        ],
                        "text": "We measure the effectiveness of a text classifier on a single category with the F\u03b2 measure (van Rijsbergen, 1972, 1979; Lewis, 1995):\nF\u03b2 = (\u03b22 +1)A\n(\u03b22 +1)A+B+\u03b22C ,\nwhere A is the number of documents a system correctly assigns to the category (true positives), B is the number of documents a system\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 125
                            }
                        ],
                        "text": "0 as equal to 0.0 in this case, though a strong argument could be made for a value of 1.0 instead, or possibly other values (Lewis, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17260485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91cbbe24c807473b7b935d39b63df5b15da9bb32",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Text retrieval systems typically produce a ranking of documents and let a user decide how far down that ranking to go. In contrast, programs that filter text streams, software that categorizes documents, agents which alert users, and many other IR systems must make decisions without human input or supervision. It is important to define what constitutes good effectiveness for these autonomous systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed. We show how to do this for binary text classification systems, emphasizing that different goals for the system le ad to different optimal behaviors. Optimizing and estimating effectiveness is greatly aided if classifiers that explicitly estimate the probability of class membership are used. Ranked retrieval is the information retrieval (IR) researc her\u2019s favorite tool for dealing with information overload. Ranked retrieval systems display documents in order of probability of releva nce or some similar measure. Users see the best documents first, anddecide how far down the ranking to go in examining the available information. The central role played by ranking in this appr oach has led researchers to evaluate IR systems primarily, often exclusively, on the quality of their rankings. (See, for instance , the TREC evaluations [1].) In some IR applications, however, ranking is not enough: A company provides an SDI (selective dissemination of information) service which filters newswire feeds. Relevant articles are faxed each morning to clients. Interaction between customer and system takes place infrequently. The cost of resources (tying up phone lines, fax machine paper, etc.) is a factor to consider in operating the system. A text categorization system assigns controlled vocabulary categories to incoming documents as they are stored in a text database. Cost cutting has eliminated manual checking of category assignments."
            },
            "slug": "Evaluating-and-optimizing-autonomous-text-systems-Lewis",
            "title": {
                "fragments": [],
                "text": "Evaluating and optimizing autonomous text classification systems"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work shows how to define what constitutes good effectiveness for binary text classification systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 251
                            }
                        ],
                        "text": "This partly reflects the importance of text categorization as an application area for machine learning, but also results from the availability of text categorization test collections (Lewis, Schapire, Callan, and Papka, 1996; Lewis, 1997; Yang, 1999; Sebastiani, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3091,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b20af22b0734757d9ead382b201a65f9dd637cc",
            "isKey": false,
            "numCitedBy": 8450,
            "numCiting": 224,
            "paperAbstract": {
                "fragments": [],
                "text": "The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation."
            },
            "slug": "Machine-learning-in-automated-text-categorization-Sebastiani",
            "title": {
                "fragments": [],
                "text": "Machine learning in automated text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This survey discusses the main approaches to text categorization that fall within the machine learning paradigm and discusses in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053034118"
                        ],
                        "name": "S. P. Weinstein",
                        "slug": "S.-P.-Weinstein",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Weinstein",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Weinstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 191
                            }
                        ],
                        "text": "Stories first passed through a rule-based text categorization system known as TIS (Topic Identification System), a descendant of the system originally developed for Reuters by Carnegie Group (Hayes and Weinstein, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 209
                            }
                        ],
                        "text": "2.4.1 AUTOCODING\nStories first passed through a rule-based text categorization system known as TIS (Topic Identification System), a descendant of the system originally developed for Reuters by Carnegie Group (Hayes and Weinstein, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18312939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01d6d53fce6fac2a33d92ddf096290d6b99c2d13",
            "isKey": true,
            "numCitedBy": 230,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The Construe news story categorization system assigns indexing terms to news stories according to their content using knowledge-based techniques. An initial deployment of Construe in Reuters Ltd. topic identification system (TIS) has replaced human indexing for Reuters Country Reports, an online information service based on news stories indexed by country and type of news. TIS indexing is comparable to human indexing in overall accuracy but costs much less, is more consistent, and is available much more rapidly. TIS can be justified in terms of cost savings alone, but Reuters also expects the speed and consistency of TIS to provide significant competitive advantage and, hence, an increased market share for Country Reports and other products from Reuters Historical Information Products Division."
            },
            "slug": "CONSTRUE/TIS:-A-System-for-Content-Based-Indexing-a-Hayes-Weinstein",
            "title": {
                "fragments": [],
                "text": "CONSTRUE/TIS: A System for Content-Based Indexing of a Database of News Stories"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The Construe news story categorization system assigns indexing terms to news stories according to their content using knowledge-based techniques and Reuters expects the speed and consistency of TIS to provide significant competitive advantage and, hence, an increased market share for Country Reports and other products from Reuters Historical Information Products Division."
            },
            "venue": {
                "fragments": [],
                "text": "IAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39295595"
                        ],
                        "name": "Tom Ault",
                        "slug": "Tom-Ault",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Ault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Ault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13584016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfe8ca04d91c2660805615993ee1eb58d3134cff",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We compared a multi-class k-nearest neighbor (kNN) approach and a standard Rocchio method in the filtering tasks of TREC-10. Empirically, we found kNN more effective in batch filtering, and Rocchio better in adaptive filtering. For threshold adjustment based on relevance feedback, we developed a new strategy that updates a local regression over time based on a sliding window over positive examples and a sliding window over negative examples in the history. Applying this strategy to Rocchio and comparing its results to those by the same method with a fixed threshold, the recall was improved by 37-39% while the precision was improved by as much as 9%. Motivated by the extremely low performance of all systems on the T10S metric, we also analyzed this metric, and found that it favors more frequently occurring categories over rare ones and is somewhat inconsistent with its most straightforward interpretation. We propose a change to this metric which fixes these problems and brings it closer to the C trk metric used to evaluate the TDT tracking task."
            },
            "slug": "kNN,-Rocchio-and-Metrics-for-Information-Filtering-Ault-Yang",
            "title": {
                "fragments": [],
                "text": "kNN, Rocchio and Metrics for Information Filtering at TREC-10"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work compared a multi-class k-nearest neighbor (kNN) approach and a standard Rocchio method in the filtering tasks of TREC-10 and found kNN more effective in batch filtering, and Rocchio better in adaptive filtering."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120100599"
                        ],
                        "name": "Xin Liu",
                        "slug": "Xin-Liu",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 145
                            }
                        ],
                        "text": "6.2 k-NN\nWeighted k-NN (k-nearest neighbor) classifiers have been consistently strong performers in text categorization evaluations (Yang, 1999; Yang and Liu, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 152
                            }
                        ],
                        "text": "\u2026that have been widely studied in text categorization experiments: support vector machines (SVMs) (Joachims, 1998), weighted k-Nearest Neighbor (k-NN) (Yang and Liu, 1999), and Rocchio-style algorithms (Ittner, Lewis, and Ahn, 1995; Yang, Ault, Pierce, and Lattimer, 2000; Ault and Yang, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 123
                            }
                        ],
                        "text": "Weighted k-NN (k-nearest neighbor) classifiers have been consistently strong performers in text categorization evaluations (Yang, 1999; Yang and Liu, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 202
                            }
                        ],
                        "text": "We benchmarked three supervised learning approaches that have been widely studied in text categorization experiments: support vector machines (SVMs) (Joachims, 1998), weighted k-Nearest Neighbor (k-NN) (Yang and Liu, 1999), and Rocchio-style algorithms (Ittner, Lewis, and Ahn, 1995; Yang, Ault, Pierce, and Lattimer, 2000; Ault and Yang, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6465383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43015e9790c812bdc25bf0539b2ee4055a1882a7",
            "isKey": false,
            "numCitedBy": 2969,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports a controlled study with statistical signi cance tests on ve text categorization methods: the Support Vector Machines (SVM), a k-Nearest Neighbor (kNN) classi er, a neural network (NNet) approach, the Linear Leastsquares Fit (LLSF) mapping and a Naive Bayes (NB) classier. We focus on the robustness of these methods in dealing with a skewed category distribution, and their performance as function of the training-set category frequency. Our results show that SVM, kNN and LLSF signi cantly outperform NNet and NB when the number of positive training instances per category are small (less than ten), and that all the methods perform comparably when the categories are su ciently common (over 300 instances)."
            },
            "slug": "A-re-examination-of-text-categorization-methods-Yang-Liu",
            "title": {
                "fragments": [],
                "text": "A re-examination of text categorization methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results show that SVM, kNN and LLSF signi cantly outperform NNet and NB when the number of positive training instances per category are small, and that all the methods perform comparably when the categories are over 300 instances."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 146
                            }
                        ],
                        "text": "RCV1 contains 35 times as many documents (806,791 for RCV1-v1, and 804,414 for RCV1-v2) as the popular Reuters-21578 collection and its variants (Lewis, 1992, 1997), and 60 times as many with reliable coding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16644750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07f0f4553cfb42c0ed2bd6b07c9b22777b313d8",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented."
            },
            "slug": "An-evaluation-of-phrasal-and-clustered-on-a-text-Lewis",
            "title": {
                "fragments": [],
                "text": "An evaluation of phrasal and clustered representations on a text categorization task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 185
                            }
                        ],
                        "text": "Indeed, the only widely available text categorization test collection of comparable size is OHSUMED (Hersh, Buckley, Leone, and Hickman, 1994; Lewis, Schapire, Callan, and Papka, 1996; Yang and Pedersen, 1997; Yang, 1999) at 348,566 documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 14
                            }
                        ],
                        "text": "While useful, OHSUMED has disadvantages: it does not contain the full text of documents, its medical language is hard for non-experts to understand, and its category hierarchy (MeSH) is huge and structurally complex."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 104
                            }
                        ],
                        "text": "The feature set for a combination was chosen by first ranking the 47,152 features by their \u03c72 max score (Yang and Pedersen, 1997; Rogati and Yang, 2002) with respect to the category set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5083193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3ebcef26c22a373b6f26a67934213eb0582804e",
            "isKey": false,
            "numCitedBy": 5555,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a comparative study of feature selection methods in statistical learning of text categorization The focus is on aggres sive dimensionality reduction Five meth ods were evaluated including term selection based on document frequency DF informa tion gain IG mutual information MI a test CHI and term strength TS We found IG and CHI most e ective in our ex periments Using IG thresholding with a k nearest neighbor classi er on the Reuters cor pus removal of up to removal of unique terms actually yielded an improved classi cation accuracy measured by average preci sion DF thresholding performed similarly Indeed we found strong correlations between the DF IG and CHI values of a term This suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive TS compares favorably with the other methods with up to vocabulary reduction but is not competitive at higher vo cabulary reduction levels In contrast MI had relatively poor performance due to its bias towards favoring rare terms and its sen sitivity to probability estimation errors"
            },
            "slug": "A-Comparative-Study-on-Feature-Selection-in-Text-Yang-Pedersen",
            "title": {
                "fragments": [],
                "text": "A Comparative Study on Feature Selection in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper finds strong correlations between the DF IG and CHI values of a term and suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39295595"
                        ],
                        "name": "Tom Ault",
                        "slug": "Tom-Ault",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Ault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Ault"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153467769"
                        ],
                        "name": "Thomas Pierce",
                        "slug": "Thomas-Pierce",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Pierce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Pierce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096863"
                        ],
                        "name": "Charles W. Lattimer",
                        "slug": "Charles-W.-Lattimer",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Lattimer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles W. Lattimer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6002635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df767f719bf4cfe064fd867fb50b863ac39282c6",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Automated tracking of events from chronologically ordered document streams is a new challenge for statistical text classification. Existing learning techniques must be adapted or improved in order to effectively handle difficult situations where the number of positive training instances per event is extremely small, the majority of training documents are unlabelled, and most of the events have a short duration in time. We adapted several supervised text categorization methods, specifically several new variants of the k-Nearest Neighbor (kNN) algorithm and a Rocchio approach, to track events. All of these methods showed significant improvement (up to 71% reduction in weighted error rates) over the performance of the original kNN algorithm on TDT benchmark collections, making kNN among the top-performing systems in the recent TDT3 official evaluation. Furthermore, by combining these methods, we significantly reduced the variance in performance of our event tracking system over different data collections, suggesting a robust solution for parameter optimization."
            },
            "slug": "Improving-text-categorization-methods-for-event-Yang-Ault",
            "title": {
                "fragments": [],
                "text": "Improving text categorization methods for event tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work adapted several supervised text categorization methods, specifically several new variants of the k-Nearest Neighbor (kNN) algorithm and a Rocchio approach, to track events, and significantly reduced the variance in performance of the event tracking system over different data collections, suggesting a robust solution for parameter optimization."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66629494"
                        ],
                        "name": "J. Tague",
                        "slug": "J.-Tague",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Tague",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tague"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17126228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03d792ec97ff9d42791e8ea44227f2681e100c57",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The novice information scientist, though he or she may have thoroughly studied the design and results of previous information retrieval tests and clearly described the purpose of his/her own test, may still, when faced with its implementation, have great difficulty in proceeding. Early information retrieval experiments were of necessity ad hoc, and it is only in recent years that a body of practice, based on the experiences of Cleverdon and later investigators, has made possible a few recommendations on the pragmatics of conducting information retrieval experiments. The following remarks, though based to some extent on a study of the major tests, including those described in later chapters of this book, are heavily dependent on the author's own trials, tribulations, and mistakes. If there is one lesson to be learned from experience, it is that the theoretically optimum design can never be achieved, and the art of information retrieval experimentation is to make the compromises that will least detract from the usefulness of the results. In determining experimental procedures, three aspects must be kept in mind:"
            },
            "slug": "The-pragmatics-of-information-retrieval-Tague",
            "title": {
                "fragments": [],
                "text": "The pragmatics of information retrieval experimentation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "If there is one lesson to be learned from experience, it is that the theoretically optimum design can never be achieved, and the art of information retrieval experimentation is to make the compromises that will least detract from the usefulness of the results."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "SVM Light was used to produce scoring models, but the SVM Light thresholds were replaced with ones chosen by the SCutFBR.1 algorithm (Section 6.4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 24
                            }
                        ],
                        "text": "The threshold chosen by SVM Light based on the selected setting of -j was used as is for that category (SCutFBR.1 was not used)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 33
                            }
                        ],
                        "text": "SVM training used the SVM Light (Joachims, 1998, 1999, 2002) package, version 3.50."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "Leave-one-out cross-validation (LOO) (turned on by SVM Light\u2019s -x 1 parameter) was used to compute a training set contingency table corresponding to each setting of -j."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "\u2022 SVM.2: In this approach (Lewis, 2002), SVM Light, version 3.50, was run multiple times for each category, once for each of these settings of its -j parameter: 0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0, 1.25, 1.5, 2.0, 3.0, 4.0, 6.0, 8.0, 10.0, and 15.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 10
                            }
                        ],
                        "text": "All other SVM Light parameters were left at their default values."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14591650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8",
            "isKey": true,
            "numCitedBy": 3047,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more."
            },
            "slug": "Transductive-Inference-for-Text-Classification-Joachims",
            "title": {
                "fragments": [],
                "text": "Transductive Inference for Text Classification using Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An analysis of why Transductive Support Vector Machines are well suited for text classi cation is presented, and an algorithm for training TSVMs, handling 10,000 examples and more is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 761952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a7d40ba2e553ab481526b2b6e6df5bd2cd9952f",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Given the large training set available for batch filtering, choosing a supervised learning algorithm that would make effective use of this data was critical. The support vector machine approach (SVM) to training linear classifiers has outperformed competing approaches in a number of recent text categorization studies, particularly for categories with substantial numbers of positive training examples. SVMs require little or no feature selection, since they avoid overfitting by optimizing a margin-based criterion rather than one based on number of features. This minimizes the complexity of the software and processing. Finally, Thorsten Joachims has made publicly available an efficient implementation of SVMs, SVM_Light [Joachims 1999]: http://www.joachims.org/svm_light/"
            },
            "slug": "Applying-Support-Vector-Machines-to-the-TREC-2001-Lewis",
            "title": {
                "fragments": [],
                "text": "Applying Support Vector Machines to the TREC-2001 Batch Filtering and Routing Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The support vector machine approach (SVM) to training linear classifiers has outperformed competing approaches in a number of recent text categorization studies, particularly for categories with substantial numbers of positive training examples."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3099493"
                        ],
                        "name": "F. J. Oles",
                        "slug": "F.-J.-Oles",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Oles",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. Oles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 276
                            }
                        ],
                        "text": "\u2026of recent text categorization studies, but there has been some suggestion that they choose a poor decision threshold when the numbers of positive and negative examples are very different, as they are for low frequency categories in random or systematic samples of documents (Zhang and Oles, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 352,
                                "start": 330
                            }
                        ],
                        "text": "SVMs have outperformed competing approaches in a number of recent text categorization studies, but there has been some suggestion that they choose a poor decision threshold when the numbers of positive and negative examples are very different, as they are for low frequency categories in random or systematic samples of documents (Zhang and Oles, 2001)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17426982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d49bfad00101a03ac3e964bea3717c75a5bb3210",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of linear classification methods such as the linear least squares fit (LLSF), logistic regression, and support vector machines (SVM's) have been applied to text categorization problems. These methods share the similarity by finding hyperplanes that approximately separate a class of document vectors from its complement. However, support vector machines are so far considered special in that they have been demonstrated to achieve the state of the art performance. It is therefore worthwhile to understand whether such good performance is unique to the SVM design, or if it can also be achieved by other linear classification methods. In this paper, we compare a number of known linear classification methods as well as some variants in the framework of regularized linear systems. We will discuss the statistical and numerical properties of these algorithms, with a focus on text categorization. We will also provide some numerical experiments to illustrate these algorithms on a number of datasets."
            },
            "slug": "Text-Categorization-Based-on-Regularized-Linear-Zhang-Oles",
            "title": {
                "fragments": [],
                "text": "Text Categorization Based on Regularized Linear Classification Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A number of known linear classification methods as well as some variants in the framework of regularized linear systems are compared to discuss the statistical and numerical properties of these algorithms, with a focus on text categorization."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144526707"
                        ],
                        "name": "I. Soboroff",
                        "slug": "I.-Soboroff",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Soboroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Soboroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 750278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d4ea370556b0d9f6f13af54ec634557e78e53da",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The TREC-10 filtering track measures the ability of systems to build persistent user profiles which successfully separate relevant and non-relevant documents. It consists of three major subtasks: adaptive filtering, batch filtering, and routing. In adaptive filtering, the system begins with only a topic statement and a small number of positive examples, and must learn a better profile from on-line feedback. Batch filtering and routing are more traditional machine learning tasks where the system begins with a large sample of evaluated training documents. This report describes the track, presents some evaluation results, and provides a general commentary on lessons learned from this year's track."
            },
            "slug": "The-TREC-2002-Filtering-Track-Report-Robertson-Soboroff",
            "title": {
                "fragments": [],
                "text": "The TREC 2002 Filtering Track Report"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This report describes the TREC-10 filtering track, presents some evaluation results, and provides a general commentary on lessons learned from this year's track."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688124"
                        ],
                        "name": "W. Hersh",
                        "slug": "W.-Hersh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hersh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hersh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089238953"
                        ],
                        "name": "T. J. Leone",
                        "slug": "T.-J.-Leone",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Leone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. J. Leone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760869"
                        ],
                        "name": "D. Hickam",
                        "slug": "D.-Hickam",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hickam",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hickam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15094383,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "e91fc6cba8b23688d02b0dc3ead69ed05210bf33",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users. Using a commercial MEDLINE product based on the vector space model, these physicians searched just as effectively as more experienced searchers using Boolean searching. The results of this experiment were subsequently used to create a new large medical test collection, which was used in experiments with the SMART retrieval system to obtain baseline performance data as well as compare SMART with the other searchers."
            },
            "slug": "OHSUMED:-an-interactive-retrieval-evaluation-and-Hersh-Buckley",
            "title": {
                "fragments": [],
                "text": "OHSUMED: an interactive retrieval evaluation and new large test collection for research"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users using a commercial MEDLINE product based on the vector space model, finding that these physicians searched just as effectively as more experienced searchers using Boolean searching."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7913028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5a4f203dcc8ee607a3d41c1f96c5e91f4a66117",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss two learning algorithms for text filtering: modified Rocchio and a boosting algorithm called AdaBoost. We show how both algorithms can be adapted to maximize any general utility matrix that associates cost (or gain) for each pair of machine prediction and correct label. We first show that AdaBoost significantly outperforms another highly effective text filtering algorithm. We then compare AdaBoost and Rocchio over three large text filtering tasks. Overall both algorithms are comparable and are quite effective. AdaBoost produces better classifiers than Rocchio when the training collection contains a very large number of relevant documents. However, on these tasks, Rocchio runs much faster than AdaBoost."
            },
            "slug": "Boosting-and-Rocchio-applied-to-text-filtering-Schapire-Singer",
            "title": {
                "fragments": [],
                "text": "Boosting and Rocchio applied to text filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper discusses two learning algorithms for text filtering: modified Rocchio and a boosting algorithm called AdaBoost, and shows how both algorithms can be adapted to maximize any general utility matrix that associates cost for each pair of machine prediction and correct label."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055160"
                        ],
                        "name": "David J. Ittner",
                        "slug": "David-J.-Ittner",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ittner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Ittner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053105315"
                        ],
                        "name": "David D. Ahn",
                        "slug": "David-D.-Ahn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ahn",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David D. Ahn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 203
                            }
                        ],
                        "text": "\u2026that have been widely studied in text categorization experiments: support vector machines (SVMs) (Joachims, 1998), weighted k-Nearest Neighbor (k-NN) (Yang and Liu, 1999), and Rocchio-style algorithms (Ittner, Lewis, and Ahn, 1995; Yang, Ault, Pierce, and Lattimer, 2000; Ault and Yang, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 147
                            }
                        ],
                        "text": "Applied to text classification, it computes a prototype\nvector for each category as a weighted average of positive and negative training examples (Ittner, Lewis, and Ahn, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16611584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72fe75228c198854d4c43cc70a381643a28deca6",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Categorization of text images into content oriented classes would be a useful capability in a variety of document handling systems Many methods can be used to cat egorize texts once their words are known but OCR can garble a large proportion of words particularly when low quality images are used Despite this we show for one data set that fax quality images can be cat egorized with nearly the same accuracy as the original text Further the categoriza tion system can be trained on noisy OCR output without need for the true text of any image or for editing of OCR output The use of a vector space classi er and train ing method robust to large feature sets com bined with discarding of low frequency OCR output strings are the key to our approach"
            },
            "slug": "Text-categorization-of-low-quality-images-Ittner-Lewis",
            "title": {
                "fragments": [],
                "text": "Text categorization of low quality images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown for one data set that fax quality images can be catgorized with nearly the same accuracy as the original text and the categoriza tion system can be trained on noisy OCR output without need for the true text of any image or for editing of O CR output."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144987107"
                        ],
                        "name": "Jamie Callan",
                        "slug": "Jamie-Callan",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Callan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Callan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47394834"
                        ],
                        "name": "R. Papka",
                        "slug": "R.-Papka",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Papka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Papka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1650587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dc36b8d0c08613fb213ad419973d379a2264765",
            "isKey": false,
            "numCitedBy": 620,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems for text retrieval, routing, categorization and other IR tasks rely heavily on linear classifiers. We propose that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers. In contrast to most IR methods, theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms. Experimental data is presented showing Widrow-Hoff and EG to be more effective than the widely used Rocchio algorithm on several categorization and routing tasks."
            },
            "slug": "Training-algorithms-for-linear-text-classifiers-Lewis-Schapire",
            "title": {
                "fragments": [],
                "text": "Training algorithms for linear text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work proposes that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers for IR tasks, and theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144890574"
                        ],
                        "name": "James Allan",
                        "slug": "James-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Allan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 80
                            }
                        ],
                        "text": "The weight of a term in a vector was computed using Cornell ltc term weighting (Buckley, Salton, and Allan, 1994), a form of TF \u00d7 idf weighting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17522959,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "c972982771aeaaafdbdfbbcc7fe205bdecb3cf24",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The effects of adding information from relevant documents are examined in the TREC routing environment. A modified Rocchio relevance feedback approach is used, with a varying number of relevant documents retrieved by an initial SMART search, and a varying number of terms from those relevant documents used to expand the initial query. Recall-precision evaluation reveals that as the amount of expansion of the query due to adding terms from relevant documents increases, so does the effectiveness. There appears to be a linear relationship between the log of the number of terms added and the recall-precision effectiveness. There also appears to be a linear relationship between the log of the number of known relevant documents and the recall-precision effectiveness."
            },
            "slug": "The-effect-of-adding-relevance-information-in-a-Buckley-Salton",
            "title": {
                "fragments": [],
                "text": "The effect of adding relevance information in a relevance feedback environment"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recall-precision evaluation reveals that as the amount of expansion of the query due to adding terms from relevant documents increases, so does the effectiveness, and there appears to be a linear relationship between the log of the number of terms added and the recall- Precision effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "SVM Light was used to produce scoring models, but the SVM Light thresholds were replaced with ones chosen by the SCutFBR.1 algorithm (Section 6.4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 24
                            }
                        ],
                        "text": "The threshold chosen by SVM Light based on the selected setting of -j was used as is for that category (SCutFBR.1 was not used)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 155
                            }
                        ],
                        "text": "SVM algorithms find a linear decision surface (hyperplane) with maximum margin between it and the positive and the negative training examples for a class (Joachims, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 33
                            }
                        ],
                        "text": "SVM training used the SVM Light (Joachims, 1998, 1999, 2002) package, version 3.50."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 150
                            }
                        ],
                        "text": "We benchmarked three supervised learning approaches that have been widely studied in text categorization experiments: support vector machines (SVMs) (Joachims, 1998), weighted k-Nearest Neighbor (k-NN) (Yang and Liu, 1999), and Rocchio-style algorithms (Ittner, Lewis, and Ahn, 1995; Yang, Ault,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "Leave-one-out cross-validation (LOO) (turned on by SVM Light\u2019s -x 1 parameter) was used to compute a training set contingency table corresponding to each setting of -j."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We benchmarked three supervised learning approaches that have been widely studied in text categorization experiments: support vector machines (SVMs) (Joachims, 1998), weighted k-Nearest Neighbor (k-NN) (Yang and Liu, 1999), and Rocchio-style algorithms (Ittner, Lewis, and Ahn, 1995; Yang, Ault, Pierce, and Lattimer, 2000; Ault and Yang, 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "\u2022 SVM.2: In this approach (Lewis, 2002), SVM Light, version 3.50, was run multiple times for each category, once for each of these settings of its -j parameter: 0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0, 1.25, 1.5, 2.0, 3.0, 4.0, 6.0, 8.0, 10.0, and 15.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 10
                            }
                        ],
                        "text": "All other SVM Light parameters were left at their default values."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": true,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "SVM Light was used to produce scoring models, but the SVM Light thresholds were replaced with ones chosen by the SCutFBR.1 algorithm (Section 6.4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 24
                            }
                        ],
                        "text": "The threshold chosen by SVM Light based on the selected setting of -j was used as is for that category (SCutFBR.1 was not used)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 33
                            }
                        ],
                        "text": "SVM training used the SVM Light (Joachims, 1998, 1999, 2002) package, version 3.50."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "Leave-one-out cross-validation (LOO) (turned on by SVM Light\u2019s -x 1 parameter) was used to compute a training set contingency table corresponding to each setting of -j."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 40
                            }
                        ],
                        "text": "\u2022 SVM.2: In this approach (Lewis, 2002), SVM Light, version 3.50, was run multiple times for each category, once for each of these settings of its -j parameter: 0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 1.0, 1.25, 1.5, 2.0, 3.0, 4.0, 6.0, 8.0, 10.0, and 15.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 10
                            }
                        ],
                        "text": "All other SVM Light parameters were left at their default values."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59831582,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "552d3cf6e713c7c98f6c1e3bdfcae748f91e4384",
            "isKey": true,
            "numCitedBy": 150,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Overview SVM light is an implementation of Support Vector Machines (SVMs) in C. The main features of the program are the following: fast optimization algorithm working set selection based on steepest feasible descent \"shrinking\" heuristic caching of kernel evaluations use of folding in the linear case solves classification and regression problems. For multivariate and structured outputs use SVM struct. solves ranking problems (e. g. learning retrieval functions in STRIVER search engine). computes XiAlpha-estimates of the error rate, the precision, and the recall efficiently computes Leave-One-Out estimates of the error rate, the precision, and the recall includes algorithm for approximately training large transductive SVMs (TSVMs) (see also Spectral Graph Transducer) can train SVMs with cost models and example dependent costs allows restarts from specified vector of dual variables handles many thousands of support vectors handles several hundred-thousands of training examples supports standard kernel functions and lets you define your own uses sparse vector representation SVM struct : SVM learning for multivariate and structured outputs like trees, sequences, and sets (available here)."
            },
            "slug": "SVM-Light:-Support-Vector-Machine-Joachims",
            "title": {
                "fragments": [],
                "text": "SVM Light: Support Vector Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "SVM light is an implementation of Support Vector Machines (SVMs) in C that fast optimization algorithm working set selection based on steepest feasible descent \"shrinking\" heuristic caching of kernel evaluations use of folding in the linear case solves classification and regression problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2620384"
                        ],
                        "name": "B. Sundheim",
                        "slug": "B.-Sundheim",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Sundheim",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sundheim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 136
                            }
                        ],
                        "text": "Whether assigning RCV1 Region codes is a good test of text categorization capability as opposed to named entity recognition capability (Grishman and Sundheim, 1995), is debatable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5188467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c15e77db04ed210e263181a31cd384a549316967",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The sixth in a series of \"Message Understanding Conferences\", which are designed to promote and evaluate research in information extraction, was held last fall. MUC-6 introduced several innovations over prior MUCs, most notably in the range of different tasks for which evaluations were conducted. We describe the development of the \"message understanding\" task over the course of the prior MUCs, some of the motivations for the new format, and the steps which led up to the formal evaluation."
            },
            "slug": "Design-of-the-MUC-6-Evaluation-Grishman-Sundheim",
            "title": {
                "fragments": [],
                "text": "Design of the MUC-6 Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The development of the \"message understanding\" task over the course of the prior MUCs, some of the motivations for the new format, and the steps which led up to the formal evaluation are described."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134211067"
                        ],
                        "name": "J. Rocchio",
                        "slug": "J.-Rocchio",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rocchio",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rocchio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61859400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4083ad1066cfa2ff0d65866ef4b011399d6873d1",
            "isKey": false,
            "numCitedBy": 3242,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Relevance-feedback-in-information-retrieval-Rocchio",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in information retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724728"
                        ],
                        "name": "R. Tong",
                        "slug": "R.-Tong",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Tong",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 197
                            }
                        ],
                        "text": "Further, some of the decrease in variation at the right of the graph results from the fact that even a poor classification on a high frequency category can yield a moderately high F-measure value (Lewis and Tong, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16878719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24fa715e09917dfafb77aca5aaa65bc788ac10f8",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the changes from the Third (MUC-3) to the Fourth (MUC-4) Message Understanding Conference was the emergence of text filtering as an explicit topic of discussion. In this paper we examine text filtering in MUC systems with three goals in mind. First, we clarify the difference between two uses of the term \"text filtering\" in the context of data extraction systems, and put these phenomena in the context of prior research on information retrieval (IR)."
            },
            "slug": "Text-filtering-in-MUC-3-and-MUC-4-Lewis-Tong",
            "title": {
                "fragments": [],
                "text": "Text filtering in MUC-3 and MUC-4"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The difference between two uses of the term \"text filtering\" in the context of data extraction systems is clarified, and these phenomena are put in thecontext of prior research on information retrieval (IR)."
            },
            "venue": {
                "fragments": [],
                "text": "MUC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16200857"
                        ],
                        "name": "V. A. Lingle",
                        "slug": "V.-A.-Lingle",
                        "structuredName": {
                            "firstName": "Virginia",
                            "lastName": "Lingle",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. A. Lingle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 126
                            }
                        ],
                        "text": "They were instructed to use the most specific code applicable to a particular aspect of a story, a common indexing principle (Lancaster, 1998, pp. 28-30)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "Explicit policies on code assignment presumedly increase consistency and usefulness of coding, though coming up with precise policies is difficult (Lancaster, 1998, pp. 30-32)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60715143,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfba22b1017c14feeaad062ca3bb64664373337e",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This third edition of what has become a classic among textbooks in schools of library and information science (and related programs) has been thoroughly updated to reflect the evolving technological advancements in the field. Focusing on indexing of the subject matter of material, the beginning chapters review the literature and discuss various principles and practices such as \u201cexhaustivity or depth of indexing,\u201d \u201cspecificity,\u201d \u201cchecktags,\u201d \u201cpre- and post-coordinate indexes,\u201d and \u201cconsistency and quality of indexing.\u201d Discussions on abstracting cover such concepts as the different types of abstracts, purpose of an abstract, structured versus narrative abstracts, informative versus indicative abstracts, subject slanting, modular abstracts, and writing and evaluating an abstract."
            },
            "slug": "Indexing-and-Abstracting-in-Theory-and-Practice-Lingle",
            "title": {
                "fragments": [],
                "text": "Indexing and Abstracting in Theory and Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This third edition of what has become a classic among textbooks in schools of library and information science has been thoroughly updated to reflect the evolving technological advancements in the field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057287718"
                        ],
                        "name": "M. Porter",
                        "slug": "M.-Porter",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Porter",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Porter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 85
                            }
                        ],
                        "text": "The remaining tokens were stemmed with our own implementation of the Porter stemmer (Porter, 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6093716,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "a651bb7cc7fc68ece0cc66ab921486d163373385",
            "isKey": false,
            "numCitedBy": 6533,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic removal of suffixes from words in English is of particular interest in the field of information retrieval. An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL. Although simple, it performs slightly better than a much more elaborate system with which it has been compared. It effectively works by treating complex suffixes as compounds made up of simple suffixes, and removing the simple suffixes in a number of steps. In each step the removal of the suffix is made to depend upon the form of the remaining stem, which usually involves a measure of its syllable length."
            },
            "slug": "An-algorithm-for-suffix-stripping-Porter",
            "title": {
                "fragments": [],
                "text": "An algorithm for suffix stripping"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL and performs slightly better than a much more elaborate system with which it has been compared."
            },
            "venue": {
                "fragments": [],
                "text": "Program"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 112
                            }
                        ],
                        "text": "The Rocchio method was developed for query expansion using relevance feedback in text retrieval (Rocchio, 1971; Salton and Buckley, 1990)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17637032,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "2ebb3dd597bbd7028d8c68bcf509e5bb09ea1e78",
            "isKey": false,
            "numCitedBy": 1442,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback is an automatic process, introduced over 20 years ago, designed to produce query formulations following an initial retrieval operation. The principal relevance feedback methods described over the years are examined briefly, and evaluation data are included to demonstrate the effectiveness of the various methods. Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback."
            },
            "slug": "Improving-retrieval-performance-by-relevance-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Improving retrieval performance by relevance feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Prescriptions are given for conducting text retrieval operations iteratively using relevance feedback, and evaluation data are included to demonstrate the effectiveness of the various methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144117798"
                        ],
                        "name": "D. Altman",
                        "slug": "D.-Altman",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Altman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Altman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "To compute this score, we first separately compute the \u03c72 statistic (Altman, 1991, Section 10.7) for the feature with respect to each category in the category set:\n\u03c72 = n(ad \u2212bc)\n(a+b)(a+ c)(b+d)(c+d) ,\nwhere n is the total number of examples used in calculating the statistic, a is the number of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62683118,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "a0b2f25195269092afe516ce68caec8dfad33ac9",
            "isKey": true,
            "numCitedBy": 17773,
            "numCiting": 165,
            "paperAbstract": {
                "fragments": [],
                "text": "Most medical researchers, whether clinical or non-clinical, receive some background in statistics as undergraduates. However, it is most often brief, a long time ago, and largely forgotten by the time it is needed. Furthermore, many introductory texts fall short of adequately explaining the underlying concepts of statistics, and often are divorced from the reality of conducting and assessing medical research. \n \nPractical Statistics for Medical Research is a problem-based text for medical researchers, medical students, and others in the medical arena who need to use statistics but have no specialized mathematics background. \n \nThe author draws on twenty years of experience as a consulting medical statistician to provide clear explanations to key statistical concepts, with a firm emphasis on practical aspects of designing and analyzing medical research. The text gives special attention to the presentation and interpretation of results and the many real problems that arise in medical research"
            },
            "slug": "Practical-statistics-for-medical-research-Altman",
            "title": {
                "fragments": [],
                "text": "Practical statistics for medical research"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Practical Statistics for Medical Research is a problem-based text for medical researchers, medical students, and others in the medical arena who need to use statistics but have no specialized mathematics background."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458655"
                        ],
                        "name": "William Stafford Noble",
                        "slug": "William-Stafford-Noble",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Noble",
                            "middleNames": [
                                "Stafford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William Stafford Noble"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6589884,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3ee73f2bf6cd154efd65783be0761cb6b7478196",
            "isKey": false,
            "numCitedBy": 2776,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) are becoming popular in a wide variety of biological applications. But, what exactly are SVMs and how do they work? And what are their most promising applications in the life sciences?"
            },
            "slug": "What-is-a-support-vector-machine-Noble",
            "title": {
                "fragments": [],
                "text": "What is a support vector machine?"
            },
            "venue": {
                "fragments": [],
                "text": "Nature Biotechnology"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222817"
                        ],
                        "name": "C. Cleverdon",
                        "slug": "C.-Cleverdon",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Cleverdon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cleverdon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 101
                            }
                        ],
                        "text": "Studies have shown considerable variation in interindexer consistency rates for different data sets (Cleverdon, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1066940,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3ccdda9e2b4e270dd4b3b5db4aaefa5724c9fb1e",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "s Co F().w"
            },
            "slug": "The-significance-of-the-Cranfield-tests-on-index-Cleverdon",
            "title": {
                "fragments": [],
                "text": "The significance of the Cranfield tests on index languages"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121352283"
                        ],
                        "name": "Van Rijsbergen",
                        "slug": "Van-Rijsbergen",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Rijsbergen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Rijsbergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 95
                            }
                        ],
                        "text": "We measure the effectiveness of a text classifier on a single category with the F\u03b2 measure (van Rijsbergen, 1972, 1979; Lewis, 1995):\nF\u03b2 = (\u03b22 +1)A\n(\u03b22 +1)A+B+\u03b22C ,\nwhere A is the number of documents a system correctly assigns to the category (true positives), B is the number of documents a system\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62453120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f9b81f1901dd021d0a5c16bc6d9e04de014b98b",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-information-structuring-and-retrieval.-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "Automatic information structuring and retrieval."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61113802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "939d409a615d4b88c0a84e1f9b99ed67a9053208",
            "isKey": false,
            "numCitedBy": 3147,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-SMART-Retrieval-System\u2014Experiments-in-Automatic-Salton",
            "title": {
                "fragments": [],
                "text": "The SMART Retrieval System\u2014Experiments in Automatic Document Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 109
                            }
                        ],
                        "text": "One is that a portion of the corpus might have been missed during coding, as was the case with Reuters21578 (Lewis, 1997)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 226
                            }
                        ],
                        "text": "This partly reflects the importance of text categorization as an application area for machine learning, but also results from the availability of text categorization test collections (Lewis, Schapire, Callan, and Papka, 1996; Lewis, 1997; Yang, 1999; Sebastiani, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 146
                            }
                        ],
                        "text": "RCV1 contains 35 times as many documents (806,791 for RCV1-v1, and 804,414 for RCV1-v2) as the popular Reuters-21578 collection and its variants (Lewis, 1992, 1997), and 60 times as many with reliable coding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56516393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5833aa3ab163bf57a969b74ff3c3a66babe19fa1",
            "isKey": false,
            "numCitedBy": 493,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reuters-21578-Text-Categorization-Test-Collection,-Lewis",
            "title": {
                "fragments": [],
                "text": "Reuters-21578 Text Categorization Test Collection, Distribution 1.0"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "UK Standard Industrial Classification of Economic Activities UK SIC(92)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "RCV1: A NEW BENCHMARK COLLECTION"
            },
            "venue": {
                "fragments": [],
                "text": "RCV1: A NEW BENCHMARK COLLECTION"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 91
                            }
                        ],
                        "text": "We measure the effectiveness of a text classifier on a single category with the F\u03b2 measure (van Rijsbergen, 1972, 1979; Lewis, 1995):\nF\u03b2 = (\u03b22 +1)A\n(\u03b22 +1)A+B+\u03b22C ,\nwhere A is the number of documents a system correctly assigns to the category (true positives), B is the number of documents a system\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval. Butterworths"
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 20
                            }
                        ],
                        "text": "Reuters has agreed (Rose, 2002; Whitehead, 2002) to our distribution of these token and vector files without a license agreement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Electronic mail message to ReutersCorpora@yahoogroups.com"
            },
            "venue": {
                "fragments": [],
                "text": "June 11,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "As the author of the Porter stemmer has discussed (Porter, 2003) it is very rare for two implementations of the Porter stemmer to behave identically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "http://www.tartarus.org/ \u0303martin/PorterStemmer"
            },
            "venue": {
                "fragments": [],
                "text": "The Porter Stemming Algorithm,"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 32
                            }
                        ],
                        "text": "Reuters has agreed (Rose, 2002; Whitehead, 2002) to our distribution of these token and vector files without a license agreement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Electronic mail message to ReutersCorpora@yahoogroups.com"
            },
            "venue": {
                "fragments": [],
                "text": "November 14,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Indexes to UK Standard Industrial Classification of Economic Activities 1992 UK SIC(92)"
            },
            "venue": {
                "fragments": [],
                "text": "Office for National Statistics"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "We hope that by documenting the data production process, the nature of the coding, and the impact of these on the resulting test collection, we have contributed to the usefulness of the collection"
            },
            "venue": {
                "fragments": [],
                "text": "We hope that by documenting the data production process, the nature of the coding, and the impact of these on the resulting test collection, we have contributed to the usefulness of the collection"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 129
                            }
                        ],
                        "text": "The feature set for a combination was chosen by first ranking the 47,152 features by their \u03c72 max score (Yang and Pedersen, 1997; Rogati and Yang, 2002) with respect to the category set."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High performing and scalable feature selection for text classification"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Eleventh International Conference on Information and Knowledge Management,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 51
                            }
                        ],
                        "text": "As the author of the Porter stemmer has discussed (Porter, 2003) it is very rare for two implementations of the Porter stemmer to behave identically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Porter Stemming Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The TREC 2001 filtering track report National Institute of Standards and Technology"
            },
            "venue": {
                "fragments": [],
                "text": "The Tenth Text REtrieval Conference"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rocchio and metrics for information filtering at TREC-10 National Institute of Standards and Technology"
            },
            "venue": {
                "fragments": [],
                "text": "The Tenth Text REtrieval Conference"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 91
                            }
                        ],
                        "text": "We measure the effectiveness of a text classifier on a single category with the F\u03b2 measure (van Rijsbergen, 1972, 1979; Lewis, 1995):\nF\u03b2 = (\u03b22 +1)A\n(\u03b22 +1)A+B+\u03b22C ,\nwhere A is the number of documents a system correctly assigns to the category (true positives), B is the number of documents a system\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Information Structuring and Retrieval. PhD thesis, King's College"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic Information Structuring and Retrieval. PhD thesis, King's College"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cleverdon. The significance of the Cranfield tests of index languages"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the Fourteenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 19,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 54,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/RCV1:-A-New-Benchmark-Collection-for-Text-Research-Lewis-Yang/2abe6b9ea1b13653b7384e9c8ef14b0d87e20cfc?sort=total-citations"
}