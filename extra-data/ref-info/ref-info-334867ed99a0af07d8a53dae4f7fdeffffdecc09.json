{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209630"
                        ],
                        "name": "Behzad M. Shahshahani",
                        "slug": "Behzad-M.-Shahshahani",
                        "structuredName": {
                            "firstName": "Behzad",
                            "lastName": "Shahshahani",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Behzad M. Shahshahani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122806782,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d4924b0271f443cd601d6b4e012b1ab79f41583c",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we address the problem of estimating the parameters of a normal mixture density when in addition to the unlabeled samples, sets of partially labeled samples are available.We model the density of the multi-dimensional feature space with a normal mixture and assume that the set of components of the mixture can be partitioned into several classes and that training samples are available from each class. Each class can contain one or more components. Since for any training sample the class of origin is known but the exact component of origin within the corresponding class is unknown, we refer to the training samples as partially labeled. We have derived the EM iterative equations for estimating the parameters of the normal mixture in presence of partially labeled samples. These equations can be used to combine the supervised and non-supervised learning processes."
            },
            "slug": "Using-Partially-Labeled-Data-For-Normal-Mixture-To-Shahshahani-Landgrebe",
            "title": {
                "fragments": [],
                "text": "Using Partially Labeled Data For Normal Mixture Identification With Application To Class Definition"
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] IGARSS '92 International Geoscience and Remote Sensing Symposium"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2789496"
                        ],
                        "name": "Chulhee Lee",
                        "slug": "Chulhee-Lee",
                        "structuredName": {
                            "firstName": "Chulhee",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chulhee Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17201479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0efe9f8af5df7a30dee1076af2a824e820f7419",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Through a series of specific examples, some characteristics encountered in analyzing high-dimensional multispectral data are illustrated. The increased importance of the second-order statistics in analyzing high-dimensional data is shown, as is the shortcoming of classifiers such as the minimum distance classifier, which rely on first-order variations alone. It is also shown how inaccurate estimation of first- and second-order statistics, e.g., from use of training sets which are too small, affects the performance of a classifier. Recognizing the importance of second-order statistics on the one hand, but the increased difficulty in perceiving and comprehending information present in statistics derived from high-dimensional data on the other, the authors propose a method to aid visualization of high-dimensional statistics using a color coding scheme. >"
            },
            "slug": "Analyzing-high-dimensional-multispectral-data-Lee-Landgrebe",
            "title": {
                "fragments": [],
                "text": "Analyzing high-dimensional multispectral data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Recognizing the importance of second-order statistics on the one hand, but the increased difficulty in perceiving and comprehending information present in statistics derived from high-dimensional data on the other, the authors propose a method to aid visualization of high- dimensional statistics using a color coding scheme."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Geosci. Remote. Sens."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32588087"
                        ],
                        "name": "R. Redner",
                        "slug": "R.-Redner",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Redner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Redner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145221576"
                        ],
                        "name": "H. Walker",
                        "slug": "H.-Walker",
                        "structuredName": {
                            "firstName": "Homer",
                            "lastName": "Walker",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2611600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54323bf565cea5d2aaee88a03ec9d1d3444a9bfd",
            "isKey": false,
            "numCitedBy": 2829,
            "numCiting": 158,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of estimating the parameters which determine a mixture density has been the subject of a large, diverse body of literature spanning nearly ninety years. During the last two decades, the method of maximum likelihood has become the most widely followed approach to this problem, thanks primarily to the advent of high speed electronic computers. Here, we first offer a brief survey of the literature directed toward this problem and review maximum-likelihood estimation for it. We then turn to the subject of ultimate interest, which is a particular iterative procedure for numerically approximating maximum-likelihood estimates for mixture density problems. This procedure, known as the EM algorithm, is a specialization to the mixture density context of a general algorithm of the same name used to approximate maximum-likelihood estimates for incomplete data problems. We discuss the formulation and theoretical and practical properties of the EM algorithm for mixture densities, focussing in particular on ..."
            },
            "slug": "Mixture-densities,-maximum-likelihood,-and-the-EM-Redner-Walker",
            "title": {
                "fragments": [],
                "text": "Mixture densities, maximum likelihood, and the EM algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work discusses the formulation and theoretical and practical properties of the EM algorithm, a specialization to the mixture density context of a general algorithm used to approximate maximum-likelihood estimates for incomplete data problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2295441"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Keinosuke",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16614627"
                        ],
                        "name": "D. Kessell",
                        "slug": "D.-Kessell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kessell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kessell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27704857,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c19873f06e403a9b09a10d89546aa6b0a171939",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The key measure of performance in a pattern recognition problem is the cost of making a decision. For the special case in which the relative cost of a correct decision is zero and the relative cost of an incorrect decision is unity, this cost is equal to the probability of an incorrect decision or error. A pattern recognition system may be viewed as a decision rule which transforms measurements into class assignments. The Bayes error is the minimum achievable error, where the minimization is with respect to all decision rules. The Bayes error is a function of the prior probabilities and the probability density functions of the respective classes. Unfortunately, in many applications, the probability density functions are unknown and therefore the Bayes error is unknown."
            },
            "slug": "Nonparametric-Bayes-error-estimation-using-samples-Fukunaga-Kessell",
            "title": {
                "fragments": [],
                "text": "Nonparametric Bayes error estimation using unclassified samples"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A pattern recognition system may be viewed as a decision rule which transforms measurements into class assignments and the Bayes error is the minimum achievable error, where the minimization is with respect to all decision rules."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2789496"
                        ],
                        "name": "Chulhee Lee",
                        "slug": "Chulhee-Lee",
                        "structuredName": {
                            "firstName": "Chulhee",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chulhee Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2045747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b56634bc0cad05e7adffd48aa0609616c3c10b2e",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach to feature extraction for classification based directly on the decision boundaries is proposed. It is shown how discriminantly redundant features and discriminantly informative features are related to decision boundaries. A procedure to extract discriminantly informative features based on a decision boundary is proposed. The proposed feature extraction algorithm has several desirable properties: (1) it predicts the minimum number of features necessary to achieve the same classification accuracy as in the original space for a given pattern recognition problem; and (2) it finds the necessary feature vectors. The proposed algorithm does not deteriorate under the circumstances of equal class means or equal class covariances as some previous algorithms do. Experiments show that the performance of the proposed algorithm compares favorably with those of previous algorithms. >"
            },
            "slug": "Feature-Extraction-Based-on-Decision-Boundaries-Lee-Landgrebe",
            "title": {
                "fragments": [],
                "text": "Feature Extraction Based on Decision Boundaries"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The proposed feature extraction algorithm has several desirable properties: it predicts the minimum number of features necessary to achieve the same classification accuracy as in the original space for a given pattern recognition problem; and it finds the necessary feature vectors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066539"
                        ],
                        "name": "G. Hughes",
                        "slug": "G.-Hughes",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Hughes",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hughes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206729491,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3e3ec72e932d7205a541e67e0f9a1fde5235eefd",
            "isKey": false,
            "numCitedBy": 2543,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and numerically plotted as a function of the pattern measurement complexity n and design data set size m . Utilized is the well-known probabilistic model of a two-class, discrete-measurement pattern environment (no Gaussian or statistical independence assumptions are made). The minimum-error recognition rule (Bayes) is used, with the unknown pattern environment probabilities estimated from the data relative frequencies. In calculating the mean accuracy over all such environments, only three parameters remain in the final equation: n, m , and the prior probability p_{c} of either of the pattern classes. With a fixed design pattern sample, recognition accuracy can first increase as the number of measurements made on a pattern increases, but decay with measurement complexity higher than some optimum value. Graphs of the mean accuracy exhibit both an optimal and a maximum acceptable value of n for fixed m and p_{c} . A four-place tabulation of the optimum n and maximum mean accuracy values is given for equally likely classes and m ranging from 2 to 1000 . The penalty exacted for the generality of the analysis is the use of the mean accuracy itself as a recognizer optimality criterion. Namely, one necessarily always has some particular recognition problem at hand whose Bayes accuracy will be higher or lower than the mean over all recognition problems having fixed n, m , and p_{c} ."
            },
            "slug": "On-the-mean-accuracy-of-statistical-pattern-Hughes",
            "title": {
                "fragments": [],
                "text": "On the mean accuracy of statistical pattern recognizers"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "The overall mean recognition probability (mean accuracy) of a pattern classifier is calculated and numerically plotted as a function of the pattern measurement complexity n and design data set size m, using the well-known probabilistic model of a two-class, discrete-measurement pattern environment."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173152186"
                        ],
                        "name": "D. Moore",
                        "slug": "D.-Moore",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Moore",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3026266"
                        ],
                        "name": "S. J. Whitsitt",
                        "slug": "S.-J.-Whitsitt",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Whitsitt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. J. Whitsitt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3945973,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c48945266459c7430aed6287f10875b466727c04",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Variance relationships among certain count estimators and posterior probability estimators of probability of correct classification are investigated. An estimator using posterior probabilities is presented for use in stratified sampling designs. A test case involving three normal classes is examined."
            },
            "slug": "Variance-comparisons-for-unbiased-estimators-of-of-Moore-Whitsitt",
            "title": {
                "fragments": [],
                "text": "Variance comparisons for unbiased estimators of probability of correct classification (Corresp.)"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An estimator using posterior probabilities is presented for use in stratified sampling designs and a test case involving three normal classes is examined."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48777170"
                        ],
                        "name": "V. Salomonson",
                        "slug": "V.-Salomonson",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Salomonson",
                            "middleNames": [
                                "V."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Salomonson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144139248"
                        ],
                        "name": "W. Barnes",
                        "slug": "W.-Barnes",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Barnes",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Barnes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97625233"
                        ],
                        "name": "P. W. Maymon",
                        "slug": "P.-W.-Maymon",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Maymon",
                            "middleNames": [
                                "William"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. W. Maymon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41212731"
                        ],
                        "name": "H. Montgomery",
                        "slug": "H.-Montgomery",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Montgomery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Montgomery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6292686"
                        ],
                        "name": "H. Ostrow",
                        "slug": "H.-Ostrow",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Ostrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ostrow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "I. Introduction An important problem in pattern recognition is the effect of small training sample size in classification performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120265424,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "8ea9f811b5bff70b1df14fa9c362be43175f9020",
            "isKey": false,
            "numCitedBy": 963,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The moderate resolution imaging spectrometer (MODIS) is discussed as an Earth-viewing sensor that is planned as a facility instrument for the Earth Observing System (Eos) scheduled to begin functioning in the mid-1990s. The MODIS is composed of two mutually supporting sensors that cover a swath width sufficient to provide nearly complete two-day global coverage from a polar-orbiting, sun-synchronous, serviceable platform. High signal-to-noise ratios are to be provided, e.g. 500 to 1 or greater with 10-12-bit quantization over the dynamic ranges of the spectral bands. MODIS' lifetime is expected to be about ten years. One of the MODIS sensors is termed MODIS-N, where N signifies nadir-viewing. The companion to MODIS-N is MODIS-T, where T signifies a tiltable field-of-view. The development of the MODIS facility from conceptual design studies (Phase-A) into detailed design studies (Phase-B) is discussed. >"
            },
            "slug": "MODIS:-advanced-facility-instrument-for-studies-of-Salomonson-Barnes",
            "title": {
                "fragments": [],
                "text": "MODIS: advanced facility instrument for studies of the Earth as a system"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101354899"
                        ],
                        "name": "G. Vane",
                        "slug": "G.-Vane",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Vane",
                            "middleNames": [
                                "W.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Vane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803761"
                        ],
                        "name": "R. Green",
                        "slug": "R.-Green",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Green",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2002440"
                        ],
                        "name": "T. Chrien",
                        "slug": "T.-Chrien",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Chrien",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Chrien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104438969"
                        ],
                        "name": "Harry T. Enmark",
                        "slug": "Harry-T.-Enmark",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Enmark",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harry T. Enmark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684074"
                        ],
                        "name": "E. G. Hansen",
                        "slug": "E.-G.-Hansen",
                        "structuredName": {
                            "firstName": "Earl",
                            "lastName": "Hansen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. G. Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103329867"
                        ],
                        "name": "Wallace M. Porter",
                        "slug": "Wallace-M.-Porter",
                        "structuredName": {
                            "firstName": "Wallace",
                            "lastName": "Porter",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wallace M. Porter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "sensor produces data in about 50 bands [1], whereas the AVIRIS sensor produces as many as 200 spectral bands [ 2 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 140616264,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "8918666bc963dfdd70d2d40bf0aafe15ebb5f00b",
            "isKey": false,
            "numCitedBy": 580,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-airborne-visible/infrared-imaging-spectrometer-Vane-Green",
            "title": {
                "fragments": [],
                "text": "The airborne visible/infrared imaging spectrometer (AVIRIS)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2134514"
                        ],
                        "name": "J. Schmee",
                        "slug": "J.-Schmee",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Schmee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120364387,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fda402ea4d34ca4014fca69a31318ce98c0b1910",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Prerequisite matrix theory. Prerequisite vector theory. Linear transformations and characteristic roots. Geometric interpretations. Algebra of vector spaces. Generalized inverse. Conditional inverse. Systems of linear equations. Patterned matrices and certain other special matrices. Trace of a matrix, vector of a matrix, commutation matrices. Integration and differentiation. Positive matrices and matrices with non-positive off-diagonal elements. Non-negative matrices, idempotent and tripotent matrices, projections."
            },
            "slug": "Matrices-with-Applications-in-Statistics-Schmee",
            "title": {
                "fragments": [],
                "text": "Matrices with Applications in Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117268564"
                        ],
                        "name": "G. Thomas",
                        "slug": "G.-Thomas",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Thomas",
                            "middleNames": [
                                "Erik",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6006539"
                        ],
                        "name": "F. Graybill",
                        "slug": "F.-Graybill",
                        "structuredName": {
                            "firstName": "Franklin",
                            "lastName": "Graybill",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Graybill"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126130737,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "11b05de56887170bee6f66a11f3fc1507e5d9c1f",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matrices-with-Applications-in-Statistics.-Thomas-Graybill",
            "title": {
                "fragments": [],
                "text": "Matrices with Applications in Statistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143971171"
                        ],
                        "name": "P. Hall",
                        "slug": "P.-Hall",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742419"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125786200,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cd711636058bce727e8b61456ed44b8c9ceea3fd",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Use-of-Uncategorized-Data-to-Improve-the-of-a-a-Hall-Titterington",
            "title": {
                "fragments": [],
                "text": "The Use of Uncategorized Data to Improve the Performance of a Nonparametric Estimator of a Mixture Density"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2389818"
                        ],
                        "name": "G. Saridis",
                        "slug": "G.-Saridis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Saridis",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Saridis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44971114,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "02a5b16c129be3708a6c40e9918d0e5a9ccec02d",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Parameter-estimation:-Principles-and-problems-Saridis",
            "title": {
                "fragments": [],
                "text": "Parameter estimation: Principles and problems"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effect of Unlabeled Samples"
            },
            "venue": {
                "fragments": [],
                "text": "Effect of Unlabeled Samples"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Geoscience & Remote Sensing"
            },
            "venue": {
                "fragments": [],
                "text": "Geoscience & Remote Sensing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Airborne Visible"
            },
            "venue": {
                "fragments": [],
                "text": "Infrared Imaging Spectrometer (AVIRIS) Remote Sens. Environ"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An Introduction to MultiSpec"
            },
            "venue": {
                "fragments": [],
                "text": "An Introduction to MultiSpec"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "If training samples are randomly drawn from the data set, equation (3) must be modified [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "The EM equations for approximating the ML estimates of the parameters of the mixture density are the following3 [9]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mixture Densities"
            },
            "venue": {
                "fragments": [],
                "text": "Maximum Likelihood and the EM Algorithm,\" SIAM Review, Vol. 26, No. 2, pp 195-239"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "Similarly, in the Decision Boundary Feature Extraction method [14], training samples are used to obtain a decision boundary in the original high dimensional space and then features that are relevant to this boundary are kept."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Extraction Based on Decision Boundaries,"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell.,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Estimation from Incomplete Data via EM Algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "J. R. Statist. Soc., B"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE Geos. & Remote Sensing Trans"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Geos. & Remote Sensing Trans"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/The-effect-of-unlabeled-samples-in-reducing-the-and-Shahshahani-Landgrebe/334867ed99a0af07d8a53dae4f7fdeffffdecc09?sort=total-citations"
}