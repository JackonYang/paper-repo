{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093086"
                        ],
                        "name": "Stephen Wan",
                        "slug": "Stephen-Wan",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795294"
                        ],
                        "name": "M. Dras",
                        "slug": "M.-Dras",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144301565"
                        ],
                        "name": "R. Dale",
                        "slug": "R.-Dale",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Dale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145212976"
                        ],
                        "name": "C\u00e9cile Paris",
                        "slug": "C\u00e9cile-Paris",
                        "structuredName": {
                            "firstName": "C\u00e9cile",
                            "lastName": "Paris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C\u00e9cile Paris"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "Instead of comparing only single words [21] adds features from dependency parses."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12813043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6afe8a8aa13de8e3f2710ef07b22ce86a005419",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "As research in text-to-text paraphrase generation progresses, it has the potential to improve the quality of generated text. However, the use of paraphrase generation methods creates a secondary problem. We must ensure that generated novel sentences are not inconsistent with the text from which it was generated. We propose a machine learning approach be used to filter out inconsistent novel sentences, or False Paraphrases. To train such a filter, we use the Microsoft Research Paraphrase corpus and investigate whether features based on syntactic dependencies can aid us in this task. Like Finch et al. (2005), we obtain a classification accuracy of 75.6%, the best known performance for this corpus. We also examine the strengths and weaknesses of dependency based features and conclude that they may be useful in more accurately classifying cases of False Paraphrase."
            },
            "slug": "Using-Dependency-Based-Features-to-Take-the-out-of-Wan-Dras",
            "title": {
                "fragments": [],
                "text": "Using Dependency-Based Features to Take the \u2019Para-farce\u2019 out of Paraphrase"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A machine learning approach is proposed to be used to filter out inconsistent novel sentences, or False Paraphrases, using the Microsoft Research Paraphrase corpus and investigating whether features based on syntactic dependencies can aid in this task."
            },
            "venue": {
                "fragments": [],
                "text": "ALTA"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "83415753"
                        ],
                        "name": "W. Dolan",
                        "slug": "W.-Dolan",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dolan",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dolan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596310"
                        ],
                        "name": "Chris Quirk",
                        "slug": "Chris-Quirk",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Quirk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Quirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125776"
                        ],
                        "name": "Chris Brockett",
                        "slug": "Chris-Brockett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Brockett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Brockett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "For all paraphrase experiments we used the Microsoft Research paraphrase corpus (MSRP) introduced by Dolan et al. [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 191
                            }
                        ],
                        "text": "In experiments we show qualitative comparisons of different RAE models and describe our state-of-the-art results on the Microsoft Research Paraphrase (MSRP) Corpus introduced by Dolan et al. [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10181753,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7acfdc905f734abf966aed58abb983bc015ff7fe",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources. Two techniques are employed: (1) simple string edit distance, and (2) a heuristic strategy that pairs initial (presumably summary) sentences from different news stories in the same cluster. We evaluate both datasets using a word alignment algorithm and a metric borrowed from machine translation. Results show that edit distance data is cleaner and more easily-aligned than the heuristic data, with an overall alignment error rate (AER) of 11.58% on a similarly-extracted test set. On test data extracted by the heuristic strategy, however, performance of the two training sets is similar, with AERs of 13.2% and 14.7% respectively. Analysis of 100 pairs of sentences from each set reveals that the edit distance data lacks many of the complex lexical and syntactic alternations that characterize monolingual paraphrase. The summary sentences, while less readily alignable, retain more of the non-trivial alternations that are of greatest interest learning paraphrase relationships."
            },
            "slug": "Unsupervised-Construction-of-Large-Paraphrase-News-Dolan-Quirk",
            "title": {
                "fragments": [],
                "text": "Unsupervised Construction of Large Paraphrase Corpora: Exploiting Massively Parallel News Sources"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Investigation of unsupervised techniques for acquiring monolingual sentence-level paraphrases from a corpus of temporally and topically clustered news articles collected from thousands of web-based news sources shows that edit distance data is cleaner and more easily-aligned than the heuristic data."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49889670"
                        ],
                        "name": "Yitao Zhang",
                        "slug": "Yitao-Zhang",
                        "structuredName": {
                            "firstName": "Yitao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yitao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748789"
                        ],
                        "name": "J. Patrick",
                        "slug": "J.-Patrick",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Patrick",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Patrick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Early approaches were based purely on lexical matching techniques [22, 23, 19, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10351213,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "6d1792f1871a99cb89dcf713abd24592630f32b7",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes an approach to sentencelevel paraphrase identification by text canonicalization. The source sentence pairs are first converted into surface text that approximates canonical forms. A decision tree learning module which employs simple lexical matching features then takes the output canonicalized texts as its input for a supervised learning process. Experiments on the Microsoft Research (MSR) Paraphrase Corpus give comparable performance to other systems that are equipped with more sophisticated lexical semantic and syntactic matching components, with a Confidence-weighted Score of 0.791. An ancillary experiment using the occurrence of nominalizations suggests that the MSR Paraphrase Corpus might not be a rich source for learning paraphrasing patterns."
            },
            "slug": "Paraphrase-Identification-by-Text-Canonicalization-Zhang-Patrick",
            "title": {
                "fragments": [],
                "text": "Paraphrase Identification by Text Canonicalization"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper proposes an approach to sentencelevel paraphrase identification by text canonicalization that employs simple lexical matching features and takes the output canonicalized texts as its input for a supervised learning process."
            },
            "venue": {
                "fragments": [],
                "text": "ALTA"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741283"
                        ],
                        "name": "R. Barzilay",
                        "slug": "R.-Barzilay",
                        "structuredName": {
                            "firstName": "Regina",
                            "lastName": "Barzilay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barzilay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Early approaches were based purely on lexical matching techniques [22, 23, 19, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6387310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10b8f21e57b3392ce623c374c2c039f811ce5f69",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the text-to-text generation problem of sentence-level paraphrasing --- a phenomenon distinct from and more difficult than word- or phrase-level paraphrasing. Our approach applies multiple-sequence alignment to sentences gathered from unannotated comparable corpora: it learns a set of paraphrasing patterns represented by word lattice pairs and automatically determines how to apply these patterns to rewrite new sentences. The results of our evaluation experiments show that the system derives accurate paraphrases, outperforming baseline systems."
            },
            "slug": "Learning-to-Paraphrase:-An-Unsupervised-Approach-Barzilay-Lee",
            "title": {
                "fragments": [],
                "text": "Learning to Paraphrase: An Unsupervised Approach Using Multiple-Sequence Alignment"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work applies multiple-sequence alignment to sentences gathered from unannotated comparable corpora: it learns a set of paraphrasing patterns represented by word lattice pairs and automatically determines how to apply these patterns to rewrite new sentences."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9923502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81b3b3fe994a9eda6d3f9d2149aa4492d1933975",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language parsing has typically been done with small sets of discrete categories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases only partly address the problem at the cost of huge feature spaces and sparseness. To address this, we introduce a recursive neural network architecture for jointly parsing natural language and learning vector space representations for variable-sized inputs. At the core of our architecture are context-sensitive recursive neural networks (CRNN). These networks can induce distributed feature representations for unseen phrases and provide syntactic information to accurately predict phrase structure trees. Most excitingly, the representation of each phrase also captures semantic information: For instance, the phrases \u201cdecline to comment\u201d and \u201cwould not disclose the terms\u201d are close by in the induced embedding space. Our current system achieves an unlabeled bracketing F-measure of 92.1% on the Wall Street Journal dataset for sentences up to length 15."
            },
            "slug": "Learning-Continuous-Phrase-Representations-and-with-Socher-Manning",
            "title": {
                "fragments": [],
                "text": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A recursive neural network architecture for jointly parsing natural language and learning vector space representations for variable-sized inputs and captures semantic information: For instance, the phrases \u201cdecline to comment\u201d and \u201cwould not disclose the terms\u201d are close by in the induced embedding space."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50682544"
                        ],
                        "name": "Long Qiu",
                        "slug": "Long-Qiu",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Early approaches were based purely on lexical matching techniques [22, 23, 19, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1028939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f65a57f4511629109544a9ff7d326e03e56c35e",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a supervised, two-phase framework to address the problem of paraphrase recognition (PR). Unlike most PR systems that focus on sentence similarity, our framework detects dissimilarities between sentences and makes its paraphrase judgment based on the significance of such dissimilarities. The ability to differentiate significant dissimilarities not only reveals what makes two sentences a non-paraphrase, but also helps to recall additional paraphrases that contain extra but insignificant information. Experimental results show that while being accurate at discerning non-paraphrasing dissimilarities, our implemented system is able to achieve higher paraphrase recall (93%), at an overall performance comparable to the alternatives."
            },
            "slug": "Paraphrase-Recognition-via-Dissimilarity-Qiu-Kan",
            "title": {
                "fragments": [],
                "text": "Paraphrase Recognition via Dissimilarity Significance Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results show that while being accurate at discerning non-paraphrasing dissimilarities, the implemented system is able to achieve higher paraphrase recall (93%), at an overall performance comparable to the alternatives."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763608"
                        ],
                        "name": "Chris Callison-Burch",
                        "slug": "Chris-Callison-Burch",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Callison-Burch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Callison-Burch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 191
                            }
                        ],
                        "text": "Identifying paraphrases is an important task that is used in information retrieval, question answering [1], text summarization, plagiarism detection [2] and evaluation of machine translation [3], among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2755801,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "cadc3dbd73f0cbbe04b2a66f832c3cf34c877b41",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We improve the quality of paraphrases extracted from parallel corpora by requiring that phrases and their paraphrases be the same syntactic type. This is achieved by parsing the English side of a parallel corpus and altering the phrase extraction algorithm to extract phrase labels alongside bilingual phrase pairs. In order to retain broad coverage of non-constituent phrases, complex syntactic labels are introduced. A manual evaluation indicates a 19% absolute improvement in paraphrase quality over the baseline method."
            },
            "slug": "Syntactic-Constraints-on-Paraphrases-Extracted-from-Callison-Burch",
            "title": {
                "fragments": [],
                "text": "Syntactic Constraints on Paraphrases Extracted from Parallel Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This work improves the quality of paraphrases extracted from parallel corpora by requiring that phrases and their paraphrasing be the same syntactic type and altering the phrase extraction algorithm to extract phrase labels alongside bilingual phrase pairs."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40150953"
                        ],
                        "name": "E. Huang",
                        "slug": "E.-Huang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Huang",
                            "middleNames": [
                                "Hsin-Chun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Lastly, [12] introduced the standard recursive autoencoder as mentioned in Sect."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "2 (left) shows an instance of a recursive autoencoder (RAE) applied to a given parse tree as introduced by [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3116311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfa2646776405d50533055ceb1b7f050e9014dcb",
            "isKey": false,
            "numCitedBy": 1245,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines."
            },
            "slug": "Semi-Supervised-Recursive-Autoencoders-for-Socher-Pennington",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions that outperform other state-of-the-art approaches on commonly used datasets, without using any pre-defined sentiment lexica or polarity shifting rules."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "For initial word embeddings we used the 100-dimensional vectors computed via the unsupervised method of Collobert and Weston [6] and provided by Turian et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 21
                            }
                        ],
                        "text": "Collobert and Weston [6] introduced a new neural network model to compute such an embedding."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 104
                            }
                        ],
                        "text": "For initial word embeddings we used the 100-dimensional vectors computed via the unsupervised method of Collobert and Weston [6] and provided by Turian et al. [8]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 61
                            }
                        ],
                        "text": "For further details and evaluations of these embeddings, see [5, 6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": true,
            "numCitedBy": 5024,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585821"
                        ],
                        "name": "Cliff Chiung-Yu Lin",
                        "slug": "Cliff-Chiung-Yu-Lin",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Lin",
                            "middleNames": [
                                "Chiung-Yu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Chiung-Yu Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18690358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c0ddf74f87d154db88d79c640578c1610451eec",
            "isKey": false,
            "numCitedBy": 1320,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recursive structure is commonly found in the inputs of different modalities such as natural scene images or natural language sentences. Discovering this recursive structure helps us to not only identify the units that an image or sentence contains but also how they interact to form a whole. We introduce a max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences. The same algorithm can be used both to provide a competitive syntactic parser for natural language sentences from the Penn Treebank and to outperform alternative approaches for semantic scene segmentation, annotation and classification. For segmentation and annotation our algorithm obtains a new level of state-of-the-art performance on the Stanford background dataset (78.1%). The features from the image parse tree outperform Gist descriptors for scene classification by 4%."
            },
            "slug": "Parsing-Natural-Scenes-and-Natural-Language-with-Socher-Lin",
            "title": {
                "fragments": [],
                "text": "Parsing Natural Scenes and Natural Language with Recursive Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A max-margin structure prediction architecture based on recursive neural networks that can successfully recover such structure both in complex scene images as well as sentences is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2164679"
                        ],
                        "name": "Samuel Fernando",
                        "slug": "Samuel-Fernando",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Fernando",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Fernando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144795097"
                        ],
                        "name": "Mark Stevenson",
                        "slug": "Mark-Stevenson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Stevenson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Stevenson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "6 Fernando and Stevenson (2008) [20] 74."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Fernando and Stevenson [20] improved upon this idea by computing a similarity matrix that captures all pair-wise similarities of single words in the two sentences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18379579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d020eb83f03a9f9c97e728355c4a9010fa65d8ef",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach to the problem of paraphrase identification. Although paraphrases often make use of synonymous or near synonymous terms, many previous approaches have either ignored or made limited use of information about similarities between word meanings. We present an algorithm for paraphrase identification which makes extensive use of word similarity information derived from WordNet (Fellbaum, 1998). The approach is evaluated using the Microsoft Research Paraphrase Corpus (Dolan et al., 2004), a standard resource for this task, and found to outperform previously published methods."
            },
            "slug": "A-Semantic-Similarity-Approach-to-Paraphrase-Fernando-Stevenson",
            "title": {
                "fragments": [],
                "text": "A Semantic Similarity Approach to Paraphrase Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "An algorithm for paraphrase identification is presented which makes extensive use of word similarity information derived from WordNet (Fellbaum, 1998), and is found to outperform previously published methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 248
                            }
                        ],
                        "text": "This word representation is better suited for autoencoders than the binary number representations used in previous related autoencoder models such as the recursive autoassociative memory (RAAM) model of Pollack [9, 10] or recurrent neural networks [11] since the activations are inherently continuous."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7069311,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "605d738a39df3c5e596613ab0ca6925f0eecdf35",
            "isKey": false,
            "numCitedBy": 465,
            "numCiting": 114,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractIn this paper three problems for a connectionist account of language are considered1.What is the nature of linguistic representations?2.How can complex structural relationships such as constituent be represented?3.How can the apparently open-ended nature of language be accommodated by a fixed-resource system?\nUsing a prediction task, a simple recurrent network (SRN) is trained on multiclausal sentences which contain multiply-embedded relative clauses. Principal component analysis of the hidden unit activation patterns reveals that the network solves the task by developing complex distributed representations which encode the relevant grammatical relations and hierarchical constituent structure. Differences between the SRN state representations and the more traditional pushdown store are discussed in the final section."
            },
            "slug": "Distributed-representations,-simple-recurrent-and-Elman",
            "title": {
                "fragments": [],
                "text": "Distributed representations, simple recurrent networks, and grammatical structure"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153160559"
                        ],
                        "name": "Joseph P. Turian",
                        "slug": "Joseph-P.-Turian",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Turian",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph P. Turian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2335225"
                        ],
                        "name": "Lev-Arie Ratinov",
                        "slug": "Lev-Arie-Ratinov",
                        "structuredName": {
                            "firstName": "Lev-Arie",
                            "lastName": "Ratinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lev-Arie Ratinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 629094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dac72f2c509aee67524d3321f77e97e8eff51de6",
            "isKey": false,
            "numCitedBy": 2163,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/"
            },
            "slug": "Word-Representations:-A-Simple-and-General-Method-Turian-Ratinov",
            "title": {
                "fragments": [],
                "text": "Word Representations: A Simple and General Method for Semi-Supervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work evaluates Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeds of words on both NER and chunking, and finds that each of the three word representations improves the accuracy of these baselines."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759124"
                        ],
                        "name": "C. Goller",
                        "slug": "C.-Goller",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Goller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Goller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34940447"
                        ],
                        "name": "A. K\u00fcchler",
                        "slug": "A.-K\u00fcchler",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "K\u00fcchler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K\u00fcchler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "We compute the gradient efficiently via backpropagation through structure [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6536466,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c58dd287a476b4722c5b6b1316629e2874682219",
            "isKey": false,
            "numCitedBy": 578,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "While neural networks are very successfully applied to the processing of fixed-length vectors and variable-length sequences, the current state of the art does not allow the efficient processing of structured objects of arbitrary shape (like logical terms, trees or graphs). We present a connectionist architecture together with a novel supervised learning scheme which is capable of solving inductive inference tasks on complex symbolic structures of arbitrary size. The most general structures that can be handled are labeled directed acyclic graphs. The major difference of our approach compared to others is that the structure-representations are exclusively tuned for the intended inference task. Our method is applied to tasks consisting in the classification of logical terms. These range from the detection of a certain subterm to the satisfaction of a specific unification pattern. Compared to previously known approaches we obtained superior results in that domain."
            },
            "slug": "Learning-task-dependent-distributed-representations-Goller-K\u00fcchler",
            "title": {
                "fragments": [],
                "text": "Learning task-dependent distributed representations by backpropagation through structure"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A connectionist architecture together with a novel supervised learning scheme which is capable of solving inductive inference tasks on complex symbolic structures of arbitrary size is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Neural Networks (ICNN'96)"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145154896"
                        ],
                        "name": "V. Rus",
                        "slug": "V.-Rus",
                        "structuredName": {
                            "firstName": "Vasile",
                            "lastName": "Rus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Rus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31418055"
                        ],
                        "name": "Philip M. McCarthy",
                        "slug": "Philip-M.-McCarthy",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "McCarthy",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip M. McCarthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803651"
                        ],
                        "name": "Mihai C. Lintean",
                        "slug": "Mihai-C.-Lintean",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Lintean",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mihai C. Lintean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801516"
                        ],
                        "name": "D. McNamara",
                        "slug": "D.-McNamara",
                        "structuredName": {
                            "firstName": "Danielle",
                            "lastName": "McNamara",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McNamara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769251"
                        ],
                        "name": "A. Graesser",
                        "slug": "A.-Graesser",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Graesser",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graesser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(2008) [16] 70."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3126646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4662eea99a7850dc742cf02cee5a8e06d1b029d2",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper presents a new approach to the problem of paraphrase identification. The new approach extends a previously proposed method for the task of textual entailment. The relationship between paraphrases and entailment is discussed to theoretically justify the new approach. The proposed approach is useful because it uses relatively few resources compared to similar systems yet it produces results similar or better than other approaches to paraphrase identification. The approach also offers significantly better results than two baselines. We report results on a standard data set as well as on a new, balanced data set."
            },
            "slug": "Paraphrase-Identification-with-Lexico-Syntactic-Rus-McCarthy",
            "title": {
                "fragments": [],
                "text": "Paraphrase Identification with Lexico-Syntactic Graph Subsumption"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The paper presents a new approach to the problem of paraphrase identification that extends a previously proposed method for the task of textual entailment and offers significantly better results than two baselines."
            },
            "venue": {
                "fragments": [],
                "text": "FLAIRS Conference"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36037226"
                        ],
                        "name": "R\u00e9jean Ducharme",
                        "slug": "R\u00e9jean-Ducharme",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Ducharme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9jean Ducharme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909943744"
                        ],
                        "name": "Christian Janvin",
                        "slug": "Christian-Janvin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Janvin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Janvin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 61
                            }
                        ],
                        "text": "For further details and evaluations of these embeddings, see [5, 6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] is to jointly learn an embedding of words into an n-dimensional vector space and to use these vectors to predict how likely a word is given its context."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221275765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c2b28f9354f667cd5bd07afc0471d8334430da7",
            "isKey": false,
            "numCitedBy": 6011,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts."
            },
            "slug": "A-Neural-Probabilistic-Language-Model-Bengio-Ducharme",
            "title": {
                "fragments": [],
                "text": "A Neural Probabilistic Language Model"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "We used the Stanford parser [14] to create the parse trees for all sentences."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11495042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "isKey": false,
            "numCitedBy": 3370,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize."
            },
            "slug": "Accurate-Unlexicalized-Parsing-Klein-Manning",
            "title": {
                "fragments": [],
                "text": "Accurate Unlexicalized Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is demonstrated that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2408604"
                        ],
                        "name": "T. Voegtlin",
                        "slug": "T.-Voegtlin",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Voegtlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Voegtlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9094493"
                        ],
                        "name": "Peter Ford Dominey",
                        "slug": "Peter-Ford-Dominey",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dominey",
                            "middleNames": [
                                "Ford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Ford Dominey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Pollack\u2019s recursive auto-associative memories are similar to ours in that they are a connectionist, feedforward model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 211
                            }
                        ],
                        "text": "This word representation is better suited for autoencoders than the binary number representations used in previous related autoencoder models such as the recursive autoassociative memory (RAAM) model of Pollack [9, 10] or recurrent neural networks [11] since the activations are inherently continuous."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "The idea of applying an autoencoder in a recursive setting was introduced by Pollack [9] and extended recently by [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18295508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcd6791de4a6d2d90c620048f37b2831cc574ac6",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linear-recursive-distributed-representations-Voegtlin-Dominey",
            "title": {
                "fragments": [],
                "text": "Linear recursive distributed representations"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Pollack\u2019s recursive auto-associative memories are similar to ours in that they are a connectionist, feedforward model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 211
                            }
                        ],
                        "text": "This word representation is better suited for autoencoders than the binary number representations used in previous related autoencoder models such as the recursive autoassociative memory (RAAM) model of Pollack [9, 10] or recurrent neural networks [11] since the activations are inherently continuous."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "The idea of applying an autoencoder in a recursive setting was introduced by Pollack [9] and extended recently by [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 770011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a835df43fdc2f79126319f6fa033bb42147c6f6",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recursive-Distributed-Representations-Pollack",
            "title": {
                "fragments": [],
                "text": "Recursive Distributed Representations"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1067591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb7853c5d609081ea12cd4db3863a87da2d51808",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "A\u00a0plausible definition of \u201creasoning\u201d could be \u201calgebraically manipulating previously acquired knowledge in order to answer a new question\u201d. This definition covers first-order logical inference or probabilistic inference. It also includes much simpler manipulations commonly used to build large learning systems. For instance, we can build an optical character recognition system by first training a character segmenter, an isolated character recognizer, and a language model, using appropriate labelled training sets. Adequately concatenating these modules and fine tuning the resulting system can be viewed as an algebraic operation in a space of models. The resulting model answers a new question, that is, converting the image of a text page into a computer readable text.This observation suggests a conceptual continuity between algebraically rich inference systems, such as logical or probabilistic inference, and simple manipulations, such as the mere concatenation of trainable learning systems. Therefore, instead of trying to bridge the gap between machine learning systems and sophisticated \u201call-purpose\u201d inference mechanisms, we can instead algebraically enrich the set of manipulations applicable to training systems, and build reasoning capabilities from the ground up."
            },
            "slug": "From-machine-learning-to-machine-reasoning-Bottou",
            "title": {
                "fragments": [],
                "text": "From machine learning to machine reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Instead of trying to bridge the gap between machine learning systems and sophisticated \u201call-purpose\u201d inference mechanisms, the set of manipulations applicable to training systems can be algebraically enriched, and reasoning capabilities from the ground up are built."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714932"
                        ],
                        "name": "Zornitsa Kozareva",
                        "slug": "Zornitsa-Kozareva",
                        "structuredName": {
                            "firstName": "Zornitsa",
                            "lastName": "Kozareva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zornitsa Kozareva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9259337"
                        ],
                        "name": "A. Montoyo",
                        "slug": "A.-Montoyo",
                        "structuredName": {
                            "firstName": "Andr\u00e9s",
                            "lastName": "Montoyo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Montoyo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 66
                            }
                        ],
                        "text": "Early approaches were based purely on lexical matching techniques [22, 23, 19, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9203818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a108514efc67a62a170ebaf485be22144553d3c",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a machine learning approach for paraphrase identification which uses lexical and semantic similarity information. In the experimental studies, we examine the limitations of the designed attributes and the behavior of three machine learning classifiers. With the objective to increase the final performance of the system, we scrutinize the influence of the combination of lexical and semantic information, as well as techniques for classifier combination."
            },
            "slug": "Paraphrase-Identification-on-the-Basis-of-Machine-Kozareva-Montoyo",
            "title": {
                "fragments": [],
                "text": "Paraphrase Identification on the Basis of Supervised Machine Learning Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The objective to increase the final performance of the system is to scrutinize the influence of the combination of lexical and semantic information, as well as techniques for classifier combination."
            },
            "venue": {
                "fragments": [],
                "text": "FinTAL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145557251"
                        ],
                        "name": "Rada Mihalcea",
                        "slug": "Rada-Mihalcea",
                        "structuredName": {
                            "firstName": "Rada",
                            "lastName": "Mihalcea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rada Mihalcea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1947728"
                        ],
                        "name": "C. Corley",
                        "slug": "C.-Corley",
                        "structuredName": {
                            "firstName": "Courtney",
                            "lastName": "Corley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Corley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723976"
                        ],
                        "name": "C. Strapparava",
                        "slug": "C.-Strapparava",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Strapparava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Strapparava"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 19
                            }
                        ],
                        "text": "Several approaches [17, 18] overcome this problem by using Wordnet- and corpus-based semantic similarity measures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2785490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6633814eb1e066d146bdae16d0c1c8344c60778c",
            "isKey": false,
            "numCitedBy": 1319,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for measuring the semantic similarity of texts, using corpus-based and knowledge-based measures of similarity. Previous work on this problem has focused mainly on either large documents (e.g. text classification, information retrieval) or individual words (e.g. synonymy tests). Given that a large fraction of the information available today, on the Web and elsewhere, consists of short text snippets (e.g. abstracts of scientific documents, imagine captions, product descriptions), in this paper we focus on measuring the semantic similarity of short texts. Through experiments performed on a paraphrase data set, we show that the semantic similarity method out-performs methods based on simple lexical matching, resulting in up to 13% error rate reduction with respect to the traditional vector-based similarity metric."
            },
            "slug": "Corpus-based-and-Knowledge-based-Measures-of-Text-Mihalcea-Corley",
            "title": {
                "fragments": [],
                "text": "Corpus-based and Knowledge-based Measures of Text Semantic Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows that the semantic similarity method out-performs methods based on simple lexical matching, resulting in up to 13% error rate reduction with respect to the traditional vector-based similarity metric."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704149"
                        ],
                        "name": "Paul D. Clough",
                        "slug": "Paul-D.-Clough",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Clough",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul D. Clough"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718590"
                        ],
                        "name": "R. Gaizauskas",
                        "slug": "R.-Gaizauskas",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gaizauskas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gaizauskas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5483672"
                        ],
                        "name": "S. Piao",
                        "slug": "S.-Piao",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Piao",
                            "middleNames": [
                                "Songlin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Piao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2971978"
                        ],
                        "name": "Y. Wilks",
                        "slug": "Y.-Wilks",
                        "structuredName": {
                            "firstName": "Yorick",
                            "lastName": "Wilks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Wilks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 159685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80e23d2e7b81dcf3fc50690de9b244cee4a5a6f3",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present results from the METER (MEasuring TExt Reuse) project whose aim is to explore issues pertaining to text reuse and derivation, especially in the context of newspapers using newswire sources. Although the reuse of text by journalists has been studied in linguistics, we are not aware of any investigation using existing computational methods for this particular task. We investigate the classification of newspaper articles according to their degree of dependence upon, or derivation from, a newswire source using a simple 3-level scheme designed by journalists. Three approaches to measuring text similarity are considered: n-gram overlap, Greedy String Tiling, and sentence alignment. Measured against a manually annotated corpus of source and derived news text, we show that a combined classifier with features automatically selected performs best overall for the ternary classification achieving an average F1-measure score of 0.664 across all three categories."
            },
            "slug": "METER:-MEasuring-TExt-Reuse-Clough-Gaizauskas",
            "title": {
                "fragments": [],
                "text": "METER: MEasuring TExt Reuse"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a combined classifier with features automatically selected performs best overall for the ternary classification achieving an average F1-measure score of 0.664 across all three categories."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373952"
                        ],
                        "name": "J. Louradour",
                        "slug": "J.-Louradour",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Louradour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Louradour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Larochelle [26] investigated autoencoders with an unfolded \u201cdeep objective\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 996073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05fd1da7b2e34f86ec7f010bef068717ae964332",
            "isKey": false,
            "numCitedBy": 1027,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms."
            },
            "slug": "Exploring-Strategies-for-Training-Deep-Neural-Larochelle-Bengio",
            "title": {
                "fragments": [],
                "text": "Exploring Strategies for Training Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "These experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144446565"
                        ],
                        "name": "Aminul Islam",
                        "slug": "Aminul-Islam",
                        "structuredName": {
                            "firstName": "Aminul",
                            "lastName": "Islam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aminul Islam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697366"
                        ],
                        "name": "D. Inkpen",
                        "slug": "D.-Inkpen",
                        "structuredName": {
                            "firstName": "Diana",
                            "lastName": "Inkpen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Inkpen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 19
                            }
                        ],
                        "text": "Several approaches [17, 18] overcome this problem by using Wordnet- and corpus-based semantic similarity measures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11959932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "082ee254cf5444639ed43633ebcd275de381639b",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for measuring the semantic similarity of texts using a corpus based measure of semantic word similarity and a normalized and modified versions of the Longest Common Subsequence (LCS) string matching algorithm. Existing methods for computing text similarity have focused mainly on either large documents or individual words. In this paper, we focus on computing the similarity between two sentence or between two short paragraphs. The proposed method can be exploited in a variety of applications involving textual knowledge representation and knowledge discovery. Evaluation results on two different data sets show that our method outperforms several competing methods."
            },
            "slug": "Semantic-similarity-of-short-texts-Islam-Inkpen",
            "title": {
                "fragments": [],
                "text": "Semantic similarity of short texts"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper presents a method for measuring the semantic similarity of texts using a corpus based measure of semantic word similarity and a normalized and modified versions of the Longest Common Subsequence string matching algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373952"
                        ],
                        "name": "J. Louradour",
                        "slug": "J.-Louradour",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Louradour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Louradour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 61
                            }
                        ],
                        "text": "For further details and evaluations of these embeddings, see [5, 6, 7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 873046,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "8de174ab5419b9d3127695405efd079808e956e8",
            "isKey": false,
            "numCitedBy": 3193,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them \"curriculum learning\". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions)."
            },
            "slug": "Curriculum-learning-Bengio-Louradour",
            "title": {
                "fragments": [],
                "text": "Curriculum learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is hypothesized that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748039"
                        ],
                        "name": "E. Marsi",
                        "slug": "E.-Marsi",
                        "structuredName": {
                            "firstName": "Erwin",
                            "lastName": "Marsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Marsi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145210073"
                        ],
                        "name": "E. Krahmer",
                        "slug": "E.-Krahmer",
                        "structuredName": {
                            "firstName": "Emiel",
                            "lastName": "Krahmer",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Krahmer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Identifying paraphrases is an important task that is used in information retrieval, question answering [1], text summarization, plagiarism detection [2] and evaluation of machine translation [3], among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2293515,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "76adea263c4bb5b8641488c169a91aed1c30aa50",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The invention provides methods and compositions for expressing a recombinant gene in eukaryotic cells, especially fungi, preferably yeast. The invention provides transcriptional regulating elements having a novel nucleotide sequence which are capable of trancriptionally regulating the expression of a cis joined gene, typically in response to the availability of certain nutrients to the host cell. Preferred regulatory elements are responsive to nutrient depletion, particulary glucose, ethanol, phosphate or a nitrogen source. Nucleic acid constructs comprising such regulatory elements operably linked to recombinant genes, cells comprising such regulatory elements, and methods of producing recombinant protein in such cells are also provided. The invention discloses regulatory elements which are induced through the ras gene product. Accordingly, the disclosed expression systems also provide a convenient marker for ras gene function. Finally, the invention also provides methods and compositions for the diagnosis and treatment of fungal infection. In particular, the invention provides gp37-derived peptides encoded by YGP1 and gp37- selective binding agents, such as antibodies."
            },
            "slug": "Explorations-in-Sentence-Fusion-Marsi-Krahmer",
            "title": {
                "fragments": [],
                "text": "Explorations in Sentence Fusion"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The invention provides transcriptional regulating elements having a novel nucleotide sequence which are capable of trancriptionally regulating the expression of a cis joined gene, typically in response to the availability of certain nutrients to the host cell."
            },
            "venue": {
                "fragments": [],
                "text": "ENLG"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143790066"
                        ],
                        "name": "Dipanjan Das",
                        "slug": "Dipanjan-Das",
                        "structuredName": {
                            "firstName": "Dipanjan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dipanjan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Most recently, Das and Smith [15] adopted the idea that paraphrases have related syntactic structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52817936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d9a795cc4f90a7c9385baa1fc05cd5c7b291926",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to deciding whether two sentences hold a paraphrase relationship. We employ a generative model that generates a paraphrase of a given sentence, and we use probabilistic inference to reason about whether two sentences share the paraphrase relationship. The model cleanly incorporates both syntax and lexical semantics using quasi-synchronous dependency grammars (Smith and Eisner, 2006). Furthermore, using a product of experts (Hinton, 2002), we combine the model with a complementary logistic regression model based on state-of-the-art lexical overlap features. We evaluate our models on the task of distinguishing true paraphrase pairs from false ones on a standard corpus, giving competitive state-of-the-art performance."
            },
            "slug": "Paraphrase-Identification-as-Probabilistic-Das-Smith",
            "title": {
                "fragments": [],
                "text": "Paraphrase Identification as Probabilistic Quasi-Synchronous Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A generative model is employed that generates a paraphrase of a given sentence, and probabilistic inference is used to reason about whether two sentences share the paraphrase relationship."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Marsi and E . Krahmer . Explorations in sentence fusion"
            },
            "venue": {
                "fragments": [],
                "text": "European Workshop on Natural Language Generation"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "Identifying paraphrases is an important task that is used in information retrieval, question answering [1], text summarization, plagiarism detection [2] and evaluation of machine translation [3], among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "METER: MEasuring TExt Reuse. In ACL"
            },
            "venue": {
                "fragments": [],
                "text": "METER: MEasuring TExt Reuse. In ACL"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 10,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Dynamic-Pooling-and-Unfolding-Recursive-for-Socher-Huang/ae5e6c6f5513613a161b2c85563f9708bf2e9178?sort=total-citations"
}