{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17374833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66126ec1fe61b833ae695db9c5bac54641fab482",
            "isKey": false,
            "numCitedBy": 451,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise. Niblack's method (1986) with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) added performed the best and was also one of the fastest binarization methods. >"
            },
            "slug": "Evaluation-of-Binarization-Methods-for-Document-Trier-Taxt",
            "title": {
                "fragments": [],
                "text": "Evaluation of Binarization Methods for Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This paper presents an evaluation of eleven locally adaptive binarization methods for gray scale images with low contrast, variable background intensity and noise and Niblack's method with the addition of the postprocessing step of Yanowitz and Bruckstein's method (1989) performed the best and was also one of the fastest binarized methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971263"
                        ],
                        "name": "K. Etemad",
                        "slug": "K.-Etemad",
                        "structuredName": {
                            "firstName": "Kamran",
                            "lastName": "Etemad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etemad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9215658"
                        ],
                        "name": "R. Chellappa",
                        "slug": "R.-Chellappa",
                        "structuredName": {
                            "firstName": "Rama",
                            "lastName": "Chellappa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chellappa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27678281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95dffcc92bda88d9f4f5b112d100f43951745b8c",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information. Multiscale feature vectors are classified locally using a neural network to allow soft/fuzzy multi-class membership assignments. Segmentation is performed by integrating soft local decision vectors to reduce their \"ambiguities\"."
            },
            "slug": "Multiscale-Segmentation-of-Unstructured-Document-Etemad-Doermann",
            "title": {
                "fragments": [],
                "text": "Multiscale Segmentation of Unstructured Document Pages Using Soft Decision Integration"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "An algorithm for layout-independent document page segmentation based on document texture using multiscale feature vectors and fuzzy local decision information is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499975"
                        ],
                        "name": "J. Kanai",
                        "slug": "J.-Kanai",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Kanai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kanai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688357"
                        ],
                        "name": "S. V. Rice",
                        "slug": "S.-V.-Rice",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Rice",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. V. Rice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688975"
                        ],
                        "name": "T. Nartker",
                        "slug": "T.-Nartker",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Nartker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nartker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30733052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5bd99ebf0bbe9a8513350d9eae4f3570c99d559b",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Many current optical character recognition (OCR) systems attempt to decompose printed pages into a set of zones, each containing a single column of text, before converting the characters into coded form. The authors present a methodology for automatically assessing the accuracy of such decompositions, and demonstrate its use in evaluating six OCR systems. >"
            },
            "slug": "Automated-Evaluation-of-OCR-Zoning-Kanai-Rice",
            "title": {
                "fragments": [],
                "text": "Automated Evaluation of OCR Zoning"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A methodology for automatically assessing the accuracy of optical character recognition decompositions is presented, and its use in evaluating six OCR systems is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31446769"
                        ],
                        "name": "M. Sawaki",
                        "slug": "M.-Sawaki",
                        "structuredName": {
                            "firstName": "Minako",
                            "lastName": "Sawaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sawaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781078"
                        ],
                        "name": "N. Hagita",
                        "slug": "N.-Hagita",
                        "structuredName": {
                            "firstName": "Norihiro",
                            "lastName": "Hagita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hagita"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6442560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b49571e9dfc0f217ab9ff9be445d4451f4f5cb3b",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for recognizing characters on graphical designs is proposed. A new projection feature that separates text-line regions from backgrounds, and adaptive thresholding in displacement matching are introduced. Experimental results for newspaper headlines with graphical designs show a recognition rate of 97.7 percent."
            },
            "slug": "Text-Line-Extraction-and-Character-Recognition-of-Sawaki-Hagita",
            "title": {
                "fragments": [],
                "text": "Text-Line Extraction and Character Recognition of Document Headlines With Graphical Designs Using Complementary Similarity Measure"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A method for recognizing characters on graphical designs and a new projection feature that separates text-line regions from backgrounds, and adaptive thresholding in displacement matching are introduced are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950475"
                        ],
                        "name": "Zhaoyang Lu",
                        "slug": "Zhaoyang-Lu",
                        "structuredName": {
                            "firstName": "Zhaoyang",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaoyang Lu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6192673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4732d06f10440f980a0af8758db17819ad88ba6",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for text/graphics separation is presented in this paper. The basic principle of the algorithm is to erase nontext regions from mixed text and graphics engineering drawings, rather than extract text regions directly. This algorithm can be used to extract both Chinese and Western characters, dimensions, and symbols and has few limitations on the kind of engineering drawings and noise level. It is robust to text-graphics touching, text fonts, and written orientations."
            },
            "slug": "Detection-of-Text-Regions-From-Digital-Engineering-Lu",
            "title": {
                "fragments": [],
                "text": "Detection of Text Regions From Digital Engineering Drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "An algorithm for text/graphics separation is presented that can be used to extract both Chinese and Western characters, dimensions, and symbols and has few limitations on the kind of engineering drawings and noise level."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2174856"
                        ],
                        "name": "S. Zenzo",
                        "slug": "S.-Zenzo",
                        "structuredName": {
                            "firstName": "Silvano",
                            "lastName": "Zenzo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zenzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729018"
                        ],
                        "name": "L. Cinque",
                        "slug": "L.-Cinque",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Cinque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cinque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990702"
                        ],
                        "name": "S. Levialdi",
                        "slug": "S.-Levialdi",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Levialdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levialdi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37894930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef8ded12323a0a79fb55c79383d8174eb1821b10",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we suggest a variant of a binary image representation based on run length encoding. This variant allows one to build a \"graph representation\" for a number of computing tasks like component labeling, computations of Euler number, diameter and convex hull, and the detection of local extrema and multiple points. Finally, a running application in the raster-to-vector conversion of digital maps is provide."
            },
            "slug": "Run-Based-Algorithms-for-Binary-Image-Analysis-and-Zenzo-Cinque",
            "title": {
                "fragments": [],
                "text": "Run-Based Algorithms for Binary Image Analysis and Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A variant of a binary image representation based on run length encoding is suggested, which allows one to build a \"graph representation\" for a number of computing tasks like component labeling, computations of Euler number, diameter and convex hull, and the detection of local extrema and multiple points."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144530706"
                        ],
                        "name": "J. Hochberg",
                        "slug": "J.-Hochberg",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Hochberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hochberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35206821"
                        ],
                        "name": "P. Kelly",
                        "slug": "P.-Kelly",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Kelly",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068996812"
                        ],
                        "name": "Timothy Thomas",
                        "slug": "Timothy-Thomas",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145607454"
                        ],
                        "name": "L. Kerns",
                        "slug": "L.-Kerns",
                        "structuredName": {
                            "firstName": "Lila",
                            "lastName": "Kerns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kerns"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37476217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea8ef4bda4b7c9f659b7cb8ea378ed758015dcde",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an automated script identification system for typeset document images. Templates for each script are created by clustering textual symbols from a training set. Symbols from new images are compared to the templates to find the best script. Our current system processes thirteen scripts with minimal preprocessing and high accuracy."
            },
            "slug": "Automatic-Script-Identification-From-Document-Using-Hochberg-Kelly",
            "title": {
                "fragments": [],
                "text": "Automatic Script Identification From Document Images Using Cluster-Based Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An automated script identification system for typeset document images that processes thirteen scripts with minimal preprocessing and high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39702442"
                        ],
                        "name": "Y. Tang",
                        "slug": "Y.-Tang",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Tang",
                            "middleNames": [
                                "Yan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143607634"
                        ],
                        "name": "Hong Ma",
                        "slug": "Hong-Ma",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hong Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144128094"
                        ],
                        "name": "Jiming Liu",
                        "slug": "Jiming-Liu",
                        "structuredName": {
                            "firstName": "Jiming",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiming Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46708490"
                        ],
                        "name": "B. Li",
                        "slug": "B.-Li",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Li",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2310605"
                        ],
                        "name": "Dihua Xi",
                        "slug": "Dihua-Xi",
                        "structuredName": {
                            "firstName": "Dihua",
                            "lastName": "Xi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dihua Xi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62003646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c871f41c0885caf21e75d4726b1319667d91a499",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on wavelets, a theoretical method has been developed to process multi-gray level documents. In this method, two-dimensional multiresolution analysis, a wavelet decomposition algorithm, and compactly supported orthonormal wavelets are used to transform a document image into sub-images. According to these sub-images, the reference lines of a multi-gray level document can be extracted, and knowledge about the geometric structure of the document can be acquired. Particularly, this approach is more efficient to process form documents with gray level background. Experiments indicate that this new method can be applied to process documents with promising results."
            },
            "slug": "Multiresolution-analysis-in-extraction-of-reference-Tang-Ma",
            "title": {
                "fragments": [],
                "text": "Multiresolution analysis in extraction of reference lines from documents with gray level background"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experiments indicate that this new method based on wavelets can be applied to process documents with promising results, and is more efficient to process form documents with gray level background."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2201799"
                        ],
                        "name": "A. Kam",
                        "slug": "A.-Kam",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Kam",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333419"
                        ],
                        "name": "G. Kopec",
                        "slug": "G.-Kopec",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kopec",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kopec"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15860728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87c9557ef6567e9801b1ef4c54f651a6f12b5640",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This correspondence describes an approach to reducing the computational cost of document image decoding by viewing it as a heuristic search problem. The kernel of the approach is a modified dynamic programming (DP) algorithm, called the iterated complete path (ICP) algorithm, that is intended for use with separable source models. A set of heuristic functions are presented for decoding formatted text with ICP. Speedups of 3-25 over DP have been observed when decoding text columns and telephone yellow pages using ICP and the proposed heuristics."
            },
            "slug": "Document-Image-Decoding-by-Heuristic-Search-Kam-Kopec",
            "title": {
                "fragments": [],
                "text": "Document Image Decoding by Heuristic Search"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "An approach to reducing the computational cost of document image decoding by viewing it as a heuristic search problem by using a modified dynamic programming algorithm, called the iterated complete path (ICP) algorithm, intended for use with separable source models."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46138594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b39beea0f761152e65fac0e498af387821d887f1",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Transforming a paper document to its electronic version in a form suitable for efficient storage, retrieval, and interpretation continues to be a challenging problem. An efficient representation scheme for document images is necessary to solve this problem. Document representation involves techniques of thresholding, skew detection, geometric layout analysis, and logical layout analysis. The derived representation can then be used in document storage and retrieval. Page segmentation is an important stage in representing document images obtained by scanning journal pages. The performance of a document understanding system greatly depends on the correctness of page segmentation and labeling of different regions such as text, tables, images, drawings, and rulers. We use the traditional bottom-up approach based on the connected component extraction to efficiently implement page segmentation and region identification. A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis. Our algorithm has a high accuracy and takes approximately 1.4 seconds on a SGI Indy workstation for model creation, including orientation estimation, segmentation, and labeling (text, table, image, drawing, and ruler) for a 2550/spl times/3300 image of a typical journal page scanned at 300 dpi. This method is applicable to documents from various technical journals and can accommodate moderate amounts of skew and noise."
            },
            "slug": "Document-Representation-and-Its-Application-to-Page-Jain-Yu",
            "title": {
                "fragments": [],
                "text": "Document Representation and Its Application to Page Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new document model which preserves top-down generation information is proposed based on which a document is logically represented for interactive editing, storage, retrieval, transfer, and logical analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704876"
                        ],
                        "name": "P. Flynn",
                        "slug": "P.-Flynn",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Flynn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11165034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9b1e7801c61164e559bccd225ae4866a8740ec1",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Several methods for segmentation of document images (maps, drawings, etc.) are explored. The segmentation operation is posed as a statistical classification task with two pattern classes: print and background. A number of classification strategies are available. All require some prior information about the distribution of gray levels for the two classes. Training (either supervised or unsupervised) is employed to form these initial density estimates. Automatic updating of the class-conditional densities is performed within subregions in the image to adapt these global density estimates to the local image area. After local class-conditional densities have been obtained, each pixel is classified within the window using several techniques: a noncontextual Bayes classifier, Besag's classifier, relaxation, Owen and Switzer's classifier, and Haslett's classifier. Four test images were processed. In two of these, the relaxation method performed best, and in the other two, the noncontextual method performed best. Automatic updating improved the results for both classifiers. >"
            },
            "slug": "Segmentation-of-Document-Images-Taxt-Flynn",
            "title": {
                "fragments": [],
                "text": "Segmentation of Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Several methods for segmentation of document images (maps, drawings, etc.) are explored and a noncontextual Bayes classifier performed best, and automatic updating improved the results for both classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064653407"
                        ],
                        "name": "Edward Cohen",
                        "slug": "Edward-Cohen",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1386112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e678c4d61c7c189e9831956b5599ffb824b8849c",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes the control structure for an intelligent handwritten address interpretation system. The system takes a grey-level address image, segments the address into lines and words, parses the address into meaningful syntactic categories, recognizes words using dynamically generated lexicons, and determines the destination code with the aid of postal directories. >"
            },
            "slug": "Control-Structure-for-Interpreting-Handwritten-Cohen-Hull",
            "title": {
                "fragments": [],
                "text": "Control Structure for Interpreting Handwritten Addresses"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Describes the control structure for an intelligent handwritten address interpretation system that takes a grey-level address image, segments the address into lines and words, parses the addresses into meaningful syntactic categories, recognizes words using dynamically generated lexicons, and determines the destination code with the aid of postal directories."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1948846"
                        ],
                        "name": "S. Yajima",
                        "slug": "S.-Yajima",
                        "structuredName": {
                            "firstName": "Shuzo",
                            "lastName": "Yajima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yajima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40231143"
                        ],
                        "name": "Jan L. Goodsell",
                        "slug": "Jan-L.-Goodsell",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Goodsell",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan L. Goodsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075536175"
                        ],
                        "name": "Takao Ichida",
                        "slug": "Takao-Ichida",
                        "structuredName": {
                            "firstName": "Takao",
                            "lastName": "Ichida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takao Ichida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432862"
                        ],
                        "name": "H. Hiraishi",
                        "slug": "H.-Hiraishi",
                        "structuredName": {
                            "firstName": "Hiromi",
                            "lastName": "Hiraishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hiraishi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18535926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1845d4debc7405dbb9eebd88ff9cba4b3b3ea8ae",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This correspondence describes new two-stage data compression algorithms of Kanji character patterns digitized on the hexagonal mesh. One third of the pattern elements are stored, and an additional small amount of data is used to correct effors in the recovered pattern. A data reduction of 60 percent has been achieved."
            },
            "slug": "Data-Compression-of-the-Kanji-Character-Patterns-on-Yajima-Goodsell",
            "title": {
                "fragments": [],
                "text": "Data Compression of the Kanji Character Patterns Digitized on the Hexagonal Mesh"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "New two-stage data compression algorithms of Kanji character patterns digitized on the hexagonal mesh with a data reduction of 60 percent have been described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152718968"
                        ],
                        "name": "Li Wang",
                        "slug": "Li-Wang",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32554888,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "658f7d47c1d268c7e676906892826ae2f8bcbab8",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for feature extraction directly from gray-scale images of scanned documents without the usual step of binarization is presented. This approach eliminates binarization by extracting features directly from gray-scale images. In this method, a digitized gray-scale image is treated as a noisy sampling of the underlying continuous surface and desired features are obtained by extracting and assembling topographic characteristics of this surface. The advantages and effectiveness of the approach are both shown theoretically and demonstrated through preliminary experiments of the proposed method. >"
            },
            "slug": "Direct-Gray-Scale-Extraction-of-Features-for-Wang-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Direct Gray-Scale Extraction of Features for Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A method for feature extraction directly from gray-scale images of scanned documents without the usual step of binarization is presented and the advantages and effectiveness are both shown theoretically and demonstrated through preliminary experiments of the proposed method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2251336"
                        ],
                        "name": "D. Burr",
                        "slug": "D.-Burr",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Burr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17709775,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "60b3fe8fa86d3e8e6d74c917f38877e2e88bca07",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently a dynamic elastic model [1] was proposed for automatic image matching. Examples were shown applying the model to dot patterns and gray scale pictures. This paper extends the model to line drawings. Examples are shown on handprint and animation, suggesting the use of dynamic matching for shape recognition and for motion correspondence."
            },
            "slug": "Elastic-Matching-of-Line-Drawings-Burr",
            "title": {
                "fragments": [],
                "text": "Elastic Matching of Line Drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Examples are shown on handprint and animation, suggesting the use of dynamic matching for shape recognition and for motion correspondence, and extending the model to line drawings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49420283"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22489408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ce3051ddbba33f77e109841de10a7e699f78607",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Binarization has been difficult for document images with poor contrast, strong noise, complex patterns, and/or variable modalities in gray-scale histograms. We developed a texture feature based thresholding algorithm to address this problem. Our algorithm consists of three steps: 1) candidate thresholds are produced through iterative use of Otsu's algorithm (1978); 2) texture features associated with each candidate threshold are extracted from the run-length histogram of the accordingly binarized image; 3) the optimal threshold is selected so that desirable document texture features are preserved. Experiments with 9,000 machine printed address blocks from an unconstrained US mail stream demonstrated that over 99.6 percent of the images were successfully binarized by the new thresholding method, appreciably better than those obtained by typical existing thresholding techniques. Also, a system run with 500 troublesome mail address blocks showed that an 8.1 percent higher character recognition rate was achieved with our algorithm as compared with Otsu's algorithm."
            },
            "slug": "Document-Image-Binarization-Based-on-Texture-Liu-Srihari",
            "title": {
                "fragments": [],
                "text": "Document Image Binarization Based on Texture Features"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A texture feature based thresholding algorithm that is appreciably better than those obtained by typical existing thresholding techniques for document images with poor contrast, strong noise, complex patterns, and/or variable modalities in gray-scale histograms is developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22995244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d85097da36118fbccfeb7802abf89bf4b4c63a3e",
            "isKey": false,
            "numCitedBy": 728,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Page layout analysis is a document processing technique used to determine the format of a page. This paper describes the document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components. The method yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks. It is advantageous over many other methods in three main ways: independence from skew angle, independence from different text spacings, and the ability to process local regions of different text orientations within the same image. Results of the method shown for several different page formats and for randomly oriented subpages on the same image illustrate the versatility of the method. We also discuss the differences, advantages, and disadvantages of the docstrum with respect to other lay-out methods. >"
            },
            "slug": "The-Document-Spectrum-for-Page-Layout-Analysis-O'Gorman",
            "title": {
                "fragments": [],
                "text": "The Document Spectrum for Page Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The document spectrum (or docstrum), which is a method for structural page layout analysis based on bottom-up, nearest-neighbor clustering of page components, yields an accurate measure of skew, within-line, and between-line spacings and locates text lines and text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15780310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3a74fe4e79add9de4803a825b6eae013215dfe7",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example. Binarization of scanned gray scale images is the first step in most document image analysis systems. Selection of an appropriate binarization method for an input image domain is a difficult problem. Typically, a human expert evaluates the binarized images according to his/her visual criteria. However, to conduct an objective evaluation, one needs to investigate how well the subsequent image analysis steps will perform on the binarized image. We call this approach goal-directed evaluation, and it can be used to evaluate other low-level image processing methods as well. Our evaluation of binarization methods is in the context of digit recognition, so we define the performance of the character recognition module as the objective measure. Eleven different locally adaptive binarization methods were evaluated, and Niblack's method gave the best performance."
            },
            "slug": "Goal-Directed-Evaluation-of-Binarization-Methods-Trier-Jain",
            "title": {
                "fragments": [],
                "text": "Goal-Directed Evaluation of Binarization Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This paper presents a methodology for evaluation of low-level image analysis methods, using binarization (two-level thresholding) as an example, and defines the performance of the character recognition module as the objective measure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358278"
                        ],
                        "name": "A. Spitz",
                        "slug": "A.-Spitz",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Spitz",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Spitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18996947,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "74b55587563c5c3bac91bdb3b3f0ffe219614f5f",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Most document recognition work to date has been performed on English text. Because of the large overlap of the character sets found in English and major Western European languages such as French and German, some extensions of the basic English capability to those languages have taken place. However, automatic language identification prior to optical character recognition is not commonly available and adds utility to such systems. Languages and their scripts have attributes that make it possible to determine the language of a document automatically. Detection of the values of these attributes requires the recognition of particular features of the document image and, in the case of languages using Latin-based symbols, the character syntax of the underlying language. We have developed techniques for distinguishing which language is represented in an image of text. This work is restricted to a small but important subset of the world's languages. The method first classifies the script into two broad classes: Han-based and Latin-based. This classification is based on the spatial relationships of features related to the upward concavities in character structures. Language identification within the Han script class (Chinese, Japanese, Korean) is performed by analysis of the distribution of optical density in the text images. We handle 23 Latin-based languages using a technique based on character shape codes, a representation of Latin text that is inexpensive to compute."
            },
            "slug": "Determination-of-the-Script-and-Language-Content-of-Spitz",
            "title": {
                "fragments": [],
                "text": "Determination of the Script and Language Content of Document Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work has developed techniques for distinguishing which language is represented in an image of text using a technique based on character shape codes, a representation of Latin text that is inexpensive to compute."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110540359"
                        ],
                        "name": "Yanhong Li",
                        "slug": "Yanhong-Li",
                        "structuredName": {
                            "firstName": "Yanhong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanhong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49365095"
                        ],
                        "name": "A. Tomkins",
                        "slug": "A.-Tomkins",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Tomkins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tomkins"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15330691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06bdec625a05a41d1428c146cecca6d55a5aaf33",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Considers the problem of evaluating character image generators that model distortions encountered in optical character recognition (OCR). While a number of such defect models have been proposed, the contention that they produce the desired result is typically argued in an ad hoc and informal way. The authors introduce a rigorous and more pragmatic definition of when a model is accurate: they say a defect model is validated if the OCR errors induced by the model are indistinguishable from the errors encountered when using real scanned documents. The authors describe four measures to quantify this similarity, and compare and contrast them using over ten million scanned and synthesized characters in three fonts. The measures differentiate effectively between different fonts and different scans of the same font regardless of the underlying text."
            },
            "slug": "Validation-of-Image-Defect-Models-for-Optical-Li-Lopresti",
            "title": {
                "fragments": [],
                "text": "Validation of Image Defect Models for Optical Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A defect model is validated if the OCR errors induced by the model are indistinguishable from the errors encountered when using real scanned documents, as well as four measures to quantify this similarity."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266621"
                        ],
                        "name": "M. Viswanathan",
                        "slug": "M.-Viswanathan",
                        "structuredName": {
                            "firstName": "Mahesh",
                            "lastName": "Viswanathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Viswanathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16107554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "717a4ae91ad20667f7ac03ce5538eff36313c299",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for extracting alternating horizontal and vertical projection profiles are from nested sub-blocks of scanned page images of technical documents is discussed. The thresholded profile strings are parsed using the compiler utilities Lex and Yacc. The significant document components are demarcated and identified by the recursive application of block grammars. Backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs. Results of the segmentation and labeling process are stored in a labeled x-y tree. It is shown that families of technical documents that share the same layout conventions can be readily analyzed. Results from experiments in which more than 20 types of document entities were identified in sample pages from two journals are presented. >"
            },
            "slug": "Syntactic-Segmentation-and-Labeling-of-Digitized-Krishnamoorthy-Nagy",
            "title": {
                "fragments": [],
                "text": "Syntactic Segmentation and Labeling of Digitized Pages from Technical Journals"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that families of technical documents that share the same layout conventions can be readily analyzed and backtracking for error recovery and branch and bound for maximum-area labeling are implemented with Unix Shell programs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2350752"
                        ],
                        "name": "C. Cabrelli",
                        "slug": "C.-Cabrelli",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Cabrelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cabrelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3304588"
                        ],
                        "name": "U. Molter",
                        "slug": "U.-Molter",
                        "structuredName": {
                            "firstName": "Ursula",
                            "lastName": "Molter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Molter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35176685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cebbb72e98edb6a98efc808e08959b8a8b9348b1",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of representing black and white images through the description of the boundaries of the objects that define such images is proposed. In order to obtain such a representation, this method uses several algorithms which perform boundary extraction, contour following, segmentation, pattern classification, and curve fitting. One of the advantages of this method is that the image can be reconstructed at any size. It can also be rotated or translated without losing any quality. In addition to achieving a good data-compression rate, the coding-decoding process is computationally very efficient. Also shown is the application of these algorithms to characters in order to obtain fonts that may be downloaded for modern laser printers. >"
            },
            "slug": "Automatic-Representation-of-Binary-Images-Cabrelli-Molter",
            "title": {
                "fragments": [],
                "text": "Automatic Representation of Binary Images"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This method uses several algorithms which perform boundary extraction, contour following, segmentation, pattern classification, and curve fitting to obtain black and white images through the description of the boundaries of the objects that define such images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794025"
                        ],
                        "name": "\u00c9. Lecolinet",
                        "slug": "\u00c9.-Lecolinet",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Lecolinet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Lecolinet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2762290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef143fd02fc50dd93dacf1a805dd072bf3a0d71f",
            "isKey": false,
            "numCitedBy": 923,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "Character segmentation has long been a critical area of the OCR process. The higher recognition rates for isolated characters vs. those obtained for words and connected character strings well illustrate this fact. A good part of recent progress in reading unconstrained printed and written text may be ascribed to more insightful handling of segmentation. This paper provides a review of these advances. The aim is to provide an appreciation for the range of techniques that have been developed, rather than to simply list sources. Segmentation methods are listed under four main headings. What may be termed the \"classical\" approach consists of methods that partition the input image into subimages, which are then classified. The operation of attempting to decompose the image into classifiable units is called \"dissection.\" The second class of methods avoids dissection, and segments the image either explicitly, by classification of prespecified windows, or implicitly by classification of subsets of spatial features collected from the image as a whole. The third strategy is a hybrid of the first two, employing dissection together with recombination rules to define potential segments, but using classification to select from the range of admissible segmentation possibilities offered by these subimages. Finally, holistic approaches that avoid segmentation by recognizing entire character strings as units are described."
            },
            "slug": "A-Survey-of-Methods-and-Strategies-in-Character-Casey-Lecolinet",
            "title": {
                "fragments": [],
                "text": "A Survey of Methods and Strategies in Character Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "H holistic approaches that avoid segmentation by recognizing entire character strings as units are described, including methods that partition the input image into subimages, which are then classified."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11600798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96d71f8e76960fd5a7f64de59c84909675fcb043",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "The binary n-gram and Viterbi algorithms have been suggested as alternative approaches to contextual postprocessing for text produced by a noisy channel such as an optical character recognizer. This correspondence describes the underlying theory of each approach in unified terminology, and presents new implementation algorithms for each approach. In particular, a storage efficient data structure is proposed for the binary n-gram algorithm and a recursive formulation is given for the Viterbi algorithm. Results of extensive experiments with each algorithm are described."
            },
            "slug": "Experiments-in-Text-Recognition-with-Binary-n-Gram-Hull-Srihari",
            "title": {
                "fragments": [],
                "text": "Experiments in Text Recognition with Binary n-Gram and Viterbi Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This correspondence describes the underlying theory of each approach in unified terminology, and presents new implementation algorithms for each approach, including a storage efficient data structure for the binary n-gram algorithm and a recursive formulation for the Viterbi algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2286155"
                        ],
                        "name": "S. Bow",
                        "slug": "S.-Bow",
                        "structuredName": {
                            "firstName": "Sing",
                            "lastName": "Bow",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096811189"
                        ],
                        "name": "Wassim El-Masri",
                        "slug": "Wassim-El-Masri",
                        "structuredName": {
                            "firstName": "Wassim",
                            "lastName": "El-Masri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wassim El-Masri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152370889"
                        ],
                        "name": "Jayesh Shah",
                        "slug": "Jayesh-Shah",
                        "structuredName": {
                            "firstName": "Jayesh",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jayesh Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2835781"
                        ],
                        "name": "J. Gattiker",
                        "slug": "J.-Gattiker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Gattiker",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gattiker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2863494"
                        ],
                        "name": "Umesh B. Mokate",
                        "slug": "Umesh-B.-Mokate",
                        "structuredName": {
                            "firstName": "Umesh",
                            "lastName": "Mokate",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Umesh B. Mokate"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5386529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd0a8a45545521058b53f717f75146c1bf088ea0",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A system for interpretation of images of paper-based line drawings is described. Since a typical drawing contains both text strings and graphics, an algorithm has been developed to locate and separate text strings of various font sizes, styles, and orientations. This is accomplished by applying the Hough transform to the centroids of connected components in the image. The graphics in the segmented image are processed to represent thin entities by their core-lines and thick objects by their boundaries. The core-lines and boundaries are segmented into straight line segments and curved lines. The line segments and their interconnections are analyzed to locate minimum redundancy loops which are adequate to generate a succinct description of the graphics. Such a description includes the location and attributes of simple polygonal shapes, circles, and interconnecting lines, and a description of the spatial relationships and occlusions among them. Hatching and filling patterns are also identified. The performance of the system is evaluated using several test images, and the results are presented. The superiority of these algorithms in generating meaningful interpretations of graphics, compared to conventional data compression schemes, is clear from these results. >"
            },
            "slug": "A-System-for-Interpretation-of-Line-Drawings-Kasturi-Bow",
            "title": {
                "fragments": [],
                "text": "A System for Interpretation of Line Drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm has been developed to locate and separate text strings of various font sizes, styles, and orientations by applying the Hough transform to the centroids of connected components in the image."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863322"
                        ],
                        "name": "Anik\u00f3 Simon",
                        "slug": "Anik\u00f3-Simon",
                        "structuredName": {
                            "firstName": "Anik\u00f3",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anik\u00f3 Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1907819"
                        ],
                        "name": "Jean-Christophe Pret",
                        "slug": "Jean-Christophe-Pret",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Pret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Christophe Pret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406054409"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29276706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7094063edf765c44dcce4aada3ed0ca725b74d96",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new bottom-up method for document layout analysis. The algorithm was implemented in the CLIDE (Chemical Literature Data Extraction) system, but the method described here is suitable for a broader range of documents. It is based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure. The method has all the major advantages of bottom-up systems: independence from different text spacing and independence from different block alignments. The algorithms computational complexity is reduced to linear by using heuristics and path-compression."
            },
            "slug": "A-Fast-Algorithm-for-Bottom-Up-Document-Layout-Simon-Pret",
            "title": {
                "fragments": [],
                "text": "A Fast Algorithm for Bottom-Up Document Layout Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new bottom-up method for document layout analysis based on Kruskal's algorithm and uses a special distance-metric between the components to construct the physical page structure."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23198522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa208b677239912cb394e5dbc6e7483a75f16ea4",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches have reported that knowledge-based layout recognition methods are very successful in classifying the meaningful data from document images automatically. However, these approaches are applicable to only the same kind of documents because they are based on the paradigm that specifies the structure definition information in advance so as to be able to analyze a particular class of documents intelligently. In this paper, the authors propose a method to recognize the layout structures of multi-kinds of table-form document images. For this purpose, the authors introduce a classification tree to manage the relationships among different classes of layout structures. The authors' recognition system has two modes: layout knowledge acquisition and layout structure recognition. In the layout knowledge acquisition mode, table-form document images are distinguished according to this. Classification tree and then the structure description trees which specify the logical structures of table-form documents are generated automatically. While, in the layout structure recognition mode, individual item fields in the table-form document images are extracted and classified successfully by searching the classification tree and interpreting the structure description tree. >"
            },
            "slug": "Layout-Recognition-of-Multi-Kinds-of-Table-Form-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Layout Recognition of Multi-Kinds of Table-Form Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors introduce a classification tree to manage the relationships among different classes of layout structures and propose a method to recognize the layout structures of multi-kinds of table-form document images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47981374"
                        ],
                        "name": "Ramesh Choudhari",
                        "slug": "Ramesh-Choudhari",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Choudhari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramesh Choudhari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2547660,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f5d81693c0a1d213531986feb86b852bcf8214b",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of diverse knowledge sources in text recognition and in correction of letter substitution errors in words of text is considered. Three knowledge sources are defined: channel characteristics as probabilities that observed letters are corruptions of other letters, bottom-up context as letter conditional probabilities (when the previous letters of the word are known), and top-down context as a lexicon. Two algorithms, one based on integrating the knowledge sources in a single step and the other based on sequentially cascading bottom-up and top-down processes, are compared in terms of computational/storage requirements and results of experimentation."
            },
            "slug": "An-Integrated-Algorithm-for-Text-Recognition:-with-Hull-Srihari",
            "title": {
                "fragments": [],
                "text": "An Integrated Algorithm for Text Recognition: Comparison with a Cascaded Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Two algorithms, one based on integrating the knowledge sources in a single step and the other based on sequentially cascading bottom-up and top-down processes, are compared in terms of computational/storage requirements and results of experimentation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759420"
                        ],
                        "name": "B. Chaudhuri",
                        "slug": "B.-Chaudhuri",
                        "structuredName": {
                            "firstName": "Bidyut.",
                            "lastName": "Chaudhuri",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chaudhuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144167309"
                        ],
                        "name": "U. Pal",
                        "slug": "U.-Pal",
                        "structuredName": {
                            "firstName": "Umapada",
                            "lastName": "Pal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Pal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20386099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b091dcf95f296fbdb61ce95920e8a7592f92dae",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Skew angle detection of scanned documents containing most popular Indian scripts (Devnagari and Bangla) is considered. Most characters in these scripts have horizontal lines at the top, called head lines. The character head lines mostly join one another in a word and the word appears as a single component. In the proposed method the components are at first labeled. The upper envelope of a component is found by columnwise scanning from an imaginary line above the component. Portions of upper envelope satisfying the properties of digital straight line are detected. They are clustered as belonging to single text lines. Estimates from individual clusters are combined to get the skew angle. Apart from accuracy and efficiency, an advantage of the method is that character segmentation and zone detection can be readily done from head line information, which is useful in optical character recognition approaches of these scripts."
            },
            "slug": "Skew-Angle-Detection-of-Digitized-Indian-Script-Chaudhuri-Pal",
            "title": {
                "fragments": [],
                "text": "Skew Angle Detection of Digitized Indian Script Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "Skew angle detection of scanned documents containing most popular Indian scripts (Devnagari and Bangla) is considered and it is found that character segmentation and zone detection can be readily done from head line information, which is useful in optical character recognition approaches of these scripts."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3163684"
                        ],
                        "name": "Abdel Wahab Zramdini",
                        "slug": "Abdel-Wahab-Zramdini",
                        "structuredName": {
                            "firstName": "Abdel",
                            "lastName": "Zramdini",
                            "middleNames": [
                                "Wahab"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel Wahab Zramdini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10014767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2097d07a289e65c4d676a502756726b75f24af80",
            "isKey": false,
            "numCitedBy": 174,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A new statistical approach based on global typographical features is proposed to the widely neglected problem of font recognition. It aims at the identification of the typeface, weight, slope and size of the text from an image block without any knowledge of the content of that text. The recognition is based on a multivariate Bayesian classifier and operates on a given set of known fonts. The effectiveness of the adopted approach has been experimented on a set of 280 fonts. Font recognition accuracies of about 97 percent were reached on high-quality images. In addition, rates higher than 99.9 percent were obtained for weight and slope detection. Experiments have also shown the system robustness to document language and text content and its sensitivity to text length."
            },
            "slug": "Optical-Font-Recognition-Using-Typographical-Zramdini-Ingold",
            "title": {
                "fragments": [],
                "text": "Optical Font Recognition Using Typographical Features"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A new statistical approach based on global typographical features is proposed to the widely neglected problem of font recognition that aims at the identification of the typeface, weight, slope and size of the text from an image block without any knowledge of the content of that text."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143874948"
                        ],
                        "name": "T. Tan",
                        "slug": "T.-Tan",
                        "structuredName": {
                            "firstName": "Tieniu",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23824412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b1e339ecda8704ce28315706ace62fe39d66f29",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Concerns the extraction of rotation invariant texture features and the use of such features in script identification from document images. Rotation invariant texture features are computed based on an extension of the popular multi-channel Gabor filtering technique, and their effectiveness is tested with 300 randomly rotated samples of 15 Brodatz textures. These features are then used in an attempt to solve a practical but hitherto mostly overlooked problem in document image processing-the identification of the script of a machine printed document. Automatic script and language recognition is an essential front-end process for the efficient and correct use of OCR and language translation products in a multilingual environment. Six languages (Chinese, English, Greek, Russian, Persian, and Malayalam) are chosen to demonstrate the potential of such a texture-based approach in script identification."
            },
            "slug": "Rotation-Invariant-Texture-Features-and-Their-Use-Tan",
            "title": {
                "fragments": [],
                "text": "Rotation Invariant Texture Features and Their Use in Automatic Script Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Rotation invariant texture features are computed based on an extension of the popular multi-channel Gabor filtering technique, and their effectiveness is tested with 300 randomly rotated samples of 15 Brodatz textures to solve a practical but hitherto mostly overlooked problem in document image processing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52322585"
                        ],
                        "name": "T. Gotoh",
                        "slug": "T.-Gotoh",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Gotoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gotoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783505"
                        ],
                        "name": "T. Toriu",
                        "slug": "T.-Toriu",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Toriu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Toriu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144909403"
                        ],
                        "name": "S. Sasaki",
                        "slug": "S.-Sasaki",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Sasaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sasaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107828741"
                        ],
                        "name": "M. Yoshida",
                        "slug": "M.-Yoshida",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Yoshida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yoshida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1943061,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d417988c7b5d8cd089ada273842f0bd25e45ffa",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A flexible vision-based algorithm for a book sorting system is presented. The algorithm is based on a discrimination model that is adaptively generated for the current object classes by learning. The algorithm consists of an image normalization process, a feature element extraction process, a learning process, and a recognition process. The image normalization process extracts the contour of the object in an image, and geometrically normalizes the image. The feature extraction process converts the normalized image to the pyramidal representation, and the feature element is extracted from each resolution level. The learning process generates a discrimination model, which represents the differences between classes, based on hierarchical clustering. In the recognition process, the input images are hierarchically discriminated under the control of the decision tree. To evaluate the algorithm, a simulation system was implemented on a general-purpose computer and an image processor was developed. >"
            },
            "slug": "A-Flexible-Vision-Based-Algorithm-for-a-Book-System-Gotoh-Toriu",
            "title": {
                "fragments": [],
                "text": "A Flexible Vision-Based Algorithm for a Book Sorting System"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A flexible vision-based algorithm for a book sorting system that is adaptively generated for the current object classes by learning is presented, based on a discrimination model based on hierarchical clustering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402942759"
                        ],
                        "name": "H. Avi-Itzhak",
                        "slug": "H.-Avi-Itzhak",
                        "structuredName": {
                            "firstName": "Hadar",
                            "lastName": "Avi-Itzhak",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Avi-Itzhak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32530891"
                        ],
                        "name": "Thanh A. Diep",
                        "slug": "Thanh-A.-Diep",
                        "structuredName": {
                            "firstName": "Thanh",
                            "lastName": "Diep",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thanh A. Diep"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145303511"
                        ],
                        "name": "Harry Garland",
                        "slug": "Harry-Garland",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Garland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harry Garland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5165951,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44f36c76f47996fa66a3379c9f642b2e02f6b41c",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical character recognition (OCR) refers to a process whereby printed documents are transformed into ASCII files for the purpose of compact storage, editing, fast retrieval, and other file manipulations through the use of a computer. The recognition stage of an OCR process is made difficult by added noise, image distortion, and the various character typefaces, sizes, and fonts that a document may have. In this study a neural network approach is introduced to perform high accuracy recognition on multi-size and multi-font characters; a novel centroid-dithering training process with a low noise-sensitivity normalization procedure is used to achieve high accuracy results. The study consists of two parts. The first part focuses on single size and single font characters, and a two-layered neural network is trained to recognize the full set of 94 ASCII character images in 12-pt Courier font. The second part trades accuracy for additional font and size capability, and a larger two-layered neural network is trained to recognize the full set of 94 ASCII character images for all point sizes from 8 to 32 and for 12 commonly used fonts. The performance of these two networks is evaluated based on a database of more than one million character images from the testing data set. >"
            },
            "slug": "High-Accuracy-Optical-Character-Recognition-Using-Avi-Itzhak-Diep",
            "title": {
                "fragments": [],
                "text": "High Accuracy Optical Character Recognition Using Neural Networks with Centroid Dithering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A neural network approach is introduced to perform high accuracy recognition on multi-size and multi-font characters; a novel centroid-dithering training process with a low noise-sensitivity normalization procedure is used to achieve high accuracy results."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696998"
                        ],
                        "name": "A. Soffer",
                        "slug": "A.-Soffer",
                        "structuredName": {
                            "firstName": "Aya",
                            "lastName": "Soffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Soffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1496886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad8d680932a5994a66af0844349431b42fd7dcfe",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A system named MARCO (denoting map retrieval by content) that is used for the acquisition, storage, indexing, and retrieval of map images is presented. The input to MARCO are raster images of separate map layers and raster images of map composites. A legend-driven map interpretation system converts map layer images from their physical representation to their logical representation. This logical representation is then used to automatically index both the composite and the layer images. Methods for incorporating logical and physical layer images as well as composite images into the framework of a relational database management system are described. Indices are constructed on both the contextual and the spatial data thereby enabling efficient retrieval of layer and composite images based on contextual as well as spatial specifications. Example queries and query processing strategies using these indices are described. The user interface is demonstrated via the execution of an example query. Results of an experimental study on a large amount of data are presented. The system is evaluated in terms of accuracy and in terms of query execution time."
            },
            "slug": "MARCO:-MAp-Retrieval-by-COntent-Samet-Soffer",
            "title": {
                "fragments": [],
                "text": "MARCO: MAp Retrieval by COntent"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Methods for incorporating logical and physical layer images as well as composite images into the framework of a relational database management system are described and results of an experimental study on a large amount of data are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39692564"
                        ],
                        "name": "Simon Kahan",
                        "slug": "Simon-Kahan",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Kahan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Kahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17307726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0de98bd19065702bb44b8aa5ad43ef6923fdacb0",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the current state of a system that recognizes printed text of various fonts and sizes for the Roman alphabet. The system combines several techniques in order to improve the overall recognition rate. Thinning and shape extraction are performed directly on a graph of the run-length encoding of a binary image. The resulting strokes and other shapes are mapped, using a shape-clustering approach, into binary features which are then fed into a statistical Bayesian classifier. Large-scale trials have shown better than 97 percent top choice correct performance on mixtures of six dissimilar fonts, and over 99 percent on most single fonts, over a range of point sizes. Certain remaining confusion classes are disambiguated through contour analysis, and characters suspected of being merged are broken and reclassified. Finally, layout and linguistic context are applied. The results are illustrated by sample pages."
            },
            "slug": "On-the-Recognition-of-Printed-Characters-of-Any-and-Kahan-Pavlidis",
            "title": {
                "fragments": [],
                "text": "On the Recognition of Printed Characters of Any Font and Size"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The current state of a system that recognizes printed text of various fonts and sizes for the Roman alphabet is described, which combines several techniques in order to improve the overall recognition rate."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778108"
                        ],
                        "name": "R. Shinghal",
                        "slug": "R.-Shinghal",
                        "structuredName": {
                            "firstName": "Rajjan",
                            "lastName": "Shinghal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shinghal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145822375"
                        ],
                        "name": "G. Toussaint",
                        "slug": "G.-Toussaint",
                        "structuredName": {
                            "firstName": "Godfried",
                            "lastName": "Toussaint",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toussaint"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17552590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a69d20b53ba8b78e48e7c72477c3fe32bd0463a",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a modification of the Viterbi algorithm is formally described, and a measure of its complexity is derived. The modified algorithm uses aheuristic to limit the search through a directed graph or trellis. The effectiveness of the algorithm is investigated via exhaustive experimentation on an input of machine-printed text. The algorithm assumes language to be a Markov chain and uses transition probabilities between characters. The results empirically answer the long-standing question of what is the benefit, if any, of using transition probabilities that depend on the length of a word and their position in it."
            },
            "slug": "Experiments-in-Text-Recognition-with-the-Modified-Shinghal-Toussaint",
            "title": {
                "fragments": [],
                "text": "Experiments in Text Recognition with the Modified Viterbi Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The results empirically answer the long-standing question of what is the benefit, if any, of using transition probabilities that depend on the length of a word and their position in it."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145579940"
                        ],
                        "name": "R. Ulichney",
                        "slug": "R.-Ulichney",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Ulichney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ulichney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1988937"
                        ],
                        "name": "D. Troxel",
                        "slug": "D.-Troxel",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Troxel",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Troxel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15206116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40a3083a15892f64ba3f94442a974e036c8633e3",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The importance of enlarging and reducing two-level images such as graphical and documentary matter by digital means continues to grow as more such images are digitally represented. A nonlinear scaling scheme is devised which exploits the simplicity of this binary nature, treating images logically instead of arithmetically; a convolution-like effect is achieved without a single addition or multiplication! This method yields high-fidelity digital scaling and meets the objectives of being fast, conducive to hardware realization, and void of special pre-encoding requirements."
            },
            "slug": "Scaling-Binary-Images-with-the-Telescoping-Template-Ulichney-Troxel",
            "title": {
                "fragments": [],
                "text": "Scaling Binary Images with the Telescoping Template"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700830"
                        ],
                        "name": "A. Namane",
                        "slug": "A.-Namane",
                        "structuredName": {
                            "firstName": "Abderrahmane",
                            "lastName": "Namane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Namane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1394544662"
                        ],
                        "name": "M. Sid-Ahmed",
                        "slug": "M.-Sid-Ahmed",
                        "structuredName": {
                            "firstName": "Maher",
                            "lastName": "Sid-Ahmed",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sid-Ahmed"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22233053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d1f5363b547d0633e60baadfaca5fa970a98258",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Advancement in digital-image processing hardware has given the printing industry novel facilities for capturing fonts and has provided new grounds for character scaling, which is an important issue in typesetting and graphical text. An algorithm for digital character scaling by a contour method is developed and implemented. The algorithm is based on scaling the contour of the character through a transformation. Cubic splines are used to interpolate the discrete samples of the contour character. Final results show no jaggies. The algorithm is applied to Arabic fonts and compared to two other algorithms: replication and telescoping template. The superior performance of the contour method is attributed to the cubic spline fitting, which gives better smoothness to the edge of the character. >"
            },
            "slug": "Character-Scaling-by-Contour-Method-Namane-Sid-Ahmed",
            "title": {
                "fragments": [],
                "text": "Character Scaling by Contour Method"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An algorithm for digital character scaling by a contour method, based on scaling the contour of the character through a transformation, is developed and implemented and compared to two other algorithms: replication and telescoping template."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102213388"
                        ],
                        "name": "K. Thompson",
                        "slug": "K.-Thompson",
                        "structuredName": {
                            "firstName": "Kendall",
                            "lastName": "Thompson",
                            "middleNames": [
                                "Milar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26523155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5298e5b0a3c18f4ef4b3f09eb8bdc2f7e5f3e22f",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy. Although carefully proofread, the books were poorly printed and posed a severe challenge to conventional page-layout analysis and character-recognition methods. An experimental page-reader system performed strictly top-down layout analysis for identification of columns, lines, words, and characters. This proceeded rapidly and reliably thanks to a recently developed skew-estimation technique. Resegmentation of broken, touching, and dirty characters was handled in an efficient and integrated manner by a heuristic search operating on isolated words. By analyzing the syntax of game descriptions and applying the rules of chess, the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone. Several computer vision systems integration issues suggested by this experience are discussed. >"
            },
            "slug": "Reading-Chess-Baird-Thompson",
            "title": {
                "fragments": [],
                "text": "Reading Chess"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "By applying semantic analysis to images of extended passages of text, several volumes of a chess encyclopedia have been read with high accuracy and the error rate was reduced by a factor of 30 from what was achievable through shape analysis alone."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34796646"
                        ],
                        "name": "J. K. Mullin",
                        "slug": "J.-K.-Mullin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Mullin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. K. Mullin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 314861,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "71ccf7f15d6dce839c7ff284f8d7079542e82fc6",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is described and tested for using an unreliable character recognition device to produce a reliable index for a collection of documents. All highly likely substitution errors of the recognition device are handled by transforming characters which confuse readily into the same pseudocharacter. An analysis of the method is done showing the expected precision (fraction of words correctly found to words present) and recall (fraction of words retrieved properly to those which were retrieved). Published substitution error matrices were employed, along with a large file of words and word frequencies to evaluate the method. Performance was surprisingly good. Suggestions for further enhancements are given."
            },
            "slug": "Reliable-Indexing-Using-Unreliable-Recognition-Mullin",
            "title": {
                "fragments": [],
                "text": "Reliable Indexing Using Unreliable Recognition Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A new method is described and tested for using an unreliable character recognition device to produce a reliable index for a collection of documents by transforming characters which confuse readily into the same pseudocharacter."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726152"
                        ],
                        "name": "E. Kawaguchi",
                        "slug": "E.-Kawaguchi",
                        "structuredName": {
                            "firstName": "Eiji",
                            "lastName": "Kawaguchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kawaguchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13101790"
                        ],
                        "name": "T. Endo",
                        "slug": "T.-Endo",
                        "structuredName": {
                            "firstName": "Tsutomu",
                            "lastName": "Endo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Endo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1953670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c080087e943e3370ec57b24a9893c7f75323a7",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A method of representing a binary pictorial pattern is developed. Its original idea comes from a sequence of terminal symbols of a context-free grammar. It is a promising technique of data compression for ordinary binary-valued pictures such as texts, documents, charts, etc. Fundamental notions like complexity, primitives, simplifications, and other items about binary-valued pictures are introduced at the beginning. A simple context-free grammar G is also introduced. It is shown that every binary-valued picture is interpretable as a terminal sequence of that G. The DF-expression is defined as the reduced terminal sequence of G. It represents the original picture in every detail and contains no surplus data for reproducing it. A quantitative discussion about the total data of a DF-expression leads to the conclusion that any binary-valued picture with complexity less than 0.47 is expressed by the DF-expression with fewer data than the original ones. The coding algorithm of original data into the DF-expression is developed. It is very simple and recursively executable. Experiments were carried out using a PDS (photo digitizing system), where test pictures were texts, charts, diagrams, etc. with 20 cm \u00d7 20 cm size. Data compression techniques in facsimile were also simulated on the same test pictures. Throughout these studies it was made clear that the DF-expression is a very effective technique as a data compression for binary pictorial patterns not only because it yields high data compression but also because its coding and decoding algorithms are very feasible."
            },
            "slug": "On-a-Method-of-Binary-Picture-Representation-and-to-Kawaguchi-Endo",
            "title": {
                "fragments": [],
                "text": "On a Method of Binary-Picture Representation and Its Application to Data Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It was made clear that the DF-expression is a very effective technique as a data compression for binary pictorial patterns not only because it yields high data compression but also because its coding and decoding algorithms are very feasible."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2574173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b461df5c5f21ca67a9f787e646d78f51fcefbbf",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Character groundtruth for real, scanned document images is crucial for evaluating the performance of OCR systems, training OCR algorithms, and validating document degradation models. Unfortunately, manual collection of accurate groundtruth for characters in a real (scanned) document image is not practical because (i) accuracy in delineating groundtruth character bounding boxes is not high enough, (ii) it is extremely laborious and time consuming, and (iii) the manual labor required for this task is prohibitively expensive. Ee describe a closed-loop methodology for collecting very accurate groundtruth for scanned documents. We first create ideal documents using a typesetting language. Next we create the groundtruth for the ideal document. The ideal document is then printed, photocopied and then scanned. A registration algorithm estimates the global geometric transformation and then performs a robust local bitmap match to register the ideal document image to the scanned document image. Finally, groundtruth associated with the ideal document image is transformed using the estimated geometric transformation to create the groundtruth for the scanned document image. This methodology is very general and can be used for creating groundtruth for documents in typeset in any language, layout, font, and style. We have demonstrated the method by generating groundtruth for English, Hindi, and FAX document images. The cost of creating groundtruth using our methodology is minimal. If character, word or zone groundtruth is available for any real document, the registration algorithm can be used to generate the corresponding groundtruth for a rescanned version of the document."
            },
            "slug": "An-Automatic-Closed-Loop-Methodology-for-Generating-Kanungo-Haralick",
            "title": {
                "fragments": [],
                "text": "An Automatic Closed-Loop Methodology for Generating Character Groundtruth for Scanned Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A closed-loop methodology for collecting very accurate groundtruth for characters in a real (scanned) document image and can be used for creating ground truth for documents in typeset in any language, layout, font, and style."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741916"
                        ],
                        "name": "M. Garris",
                        "slug": "M.-Garris",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garris",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2702646"
                        ],
                        "name": "D. Dimmick",
                        "slug": "D.-Dimmick",
                        "structuredName": {
                            "firstName": "Darrin",
                            "lastName": "Dimmick",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dimmick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11056260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3eb1f07f54aac50d967e1914c3e8931712fcf17",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "To successfully apply character recognition technology most of the forms currently hand-keyed will need to be redesigned. This paper presents results from a comprehensive study of three versions of a redesigned tax form. Analyses show that using separately spaced character boxes provides superior machine readability over fields containing combs and adjoining character boxes. It is shown that character boxes containing two vertically stacked ovals cause writers much more difficulty. Analyses provide proof that writer idiosyncratic responses on forms are the major source of errors, and proper form design can reduce these errors."
            },
            "slug": "Form-Design-for-High-Accuracy-Optical-Character-Garris-Dimmick",
            "title": {
                "fragments": [],
                "text": "Form Design for High Accuracy Optical Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results from a comprehensive study of three versions of a redesigned tax form are presented, providing proof that writer idiosyncratic responses on forms are the major source of errors, and proper form design can reduce these errors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13645895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d107bde84fb889b5c30435ad51fd2cfda45425dd",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of a statistical language model to improve the performance of an algorithm for recognizing digital images of handwritten or machine-printed text is discussed. A word recognition algorithm first determines a set of words (called a neighborhood) from a lexicon that are visually similar to each input word image. Syntactic classifications for the words and the transition probabilities between those classifications are input to the Viterbi algorithm. The Viterbi algorithm determines the sequence of syntactic classes (the states of an underlying Markov process) for each sentence that have the maximum a posteriori probability, given the observed neighborhoods. The performance of the word recognition algorithm is improved by removing words from neighborhoods with classes that are not included on the estimated state sequence. An experimental application is demonstrated with a neighborhood generation algorithm that produces a number of guesses about the identity of each word in a running text. The use of zero, first and second order transition probabilities and different levels of noise in estimating the neighborhood are explored."
            },
            "slug": "Incorporating-Language-Syntax-in-Visual-Text-with-a-Hull",
            "title": {
                "fragments": [],
                "text": "Incorporating Language Syntax in Visual Text Recognition with a Statistical Model"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The use of a statistical language model to improve the performance of an algorithm for recognizing digital images of handwritten or machine-printed text is discussed and an experimental application is demonstrated with a neighborhood generation algorithm that produces a number of guesses about the identity of each word in a running text."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2274798"
                        ],
                        "name": "F. Stentiford",
                        "slug": "F.-Stentiford",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Stentiford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Stentiford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8128640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63eebfee8c6b0f19fddb34e069bbfd8e0a55cc5d",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "An automatic evolutionary search is applied to the problem of feature extraction in an OCR application. A performance measure based on feature independence is used to generate features which do not appear to suffer from peaking effects [17]. Features are extracted from a training set of 30 600 machine printed 34 class alphanumeric characters derived from British mail. Classification results on the training set and a test set of 10 200 characters are reported for an increasing number of features. A 1.01 percent forced decision error rate is obtained on the test data using 316 features. The hardware implementation should be cheap and fast to operate. The performance compares favorably with current low cost OCR page readers."
            },
            "slug": "Automatic-Feature-Design-for-Optical-Character-an-Stentiford",
            "title": {
                "fragments": [],
                "text": "Automatic Feature Design for Optical Character Recognition Using an Evolutionary Search Procedure"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An automatic evolutionary search is applied to the problem of feature extraction in an OCR application and a performance measure based on feature independence is used to generate features which do not appear to suffer from peaking effects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333419"
                        ],
                        "name": "G. Kopec",
                        "slug": "G.-Kopec",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kopec",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kopec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2197166"
                        ],
                        "name": "Mauricio Lomelin",
                        "slug": "Mauricio-Lomelin",
                        "structuredName": {
                            "firstName": "Mauricio",
                            "lastName": "Lomelin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mauricio Lomelin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15953429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ccbd3fa3d2e2635d58596838ecbccac1f60d65d",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to supervised training of character templates from page images and unaligned transcriptions is proposed. The template training problem is formulated as one of constrained maximum likelihood parameter estimation within the document image decoding framework. This leads to a three-phase iterative training algorithm consisting of transcription alignment, aligned template estimation (ATE), and channel estimation steps. The maximum likelihood ATE problem is shown to be NP-complete and, thus, an approximate solution approach is developed. An evaluation of the training procedure in a document-specific decoding task, using the University of Washington UW-II database of scanned technical journal articles, is described."
            },
            "slug": "Supervised-Template-Estimation-for-Document-Image-Kopec-Lomelin",
            "title": {
                "fragments": [],
                "text": "Supervised Template Estimation for Document Image Decoding"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An approach to supervised training of character templates from page images and unaligned transcriptions using the University of Washington UW-II database of scanned technical journal articles and an approximate solution approach is developed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333419"
                        ],
                        "name": "G. Kopec",
                        "slug": "G.-Kopec",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Kopec",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kopec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720816"
                        ],
                        "name": "P. Chou",
                        "slug": "P.-Chou",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Chou",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17899690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "944db1fc7f65d13a77cf9c70679ee2ff4ef5fba8",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors describe a communication theory approach to document image reconstruction, patterned after the use of hidden Markov models in speech recognition. A document recognition problem is viewed as consisting of three elements-an image generator, a noisy channel, and an image decoder. A document image generator is a Markov source which combines a message source with an imager. The message source produces a string of symbols which contains the information to be transmitted. The imager is modeled as a finite-state transducer, which converts the message into an ideal bitmap. The channel transforms the ideal image into a noisy observed image. The decoder estimates the message from the observed image by finding the a posteriori most probable path through the combined source and channel models using a Viterbi-like algorithm. Application of the proposed method to decoding telephone yellow pages is described.<<ETX>>"
            },
            "slug": "Document-image-decoding-using-Markov-source-models-Kopec-Chou",
            "title": {
                "fragments": [],
                "text": "Document Image Decoding Using Markov Source Models"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A communication theory approach to document image reconstruction, patterned after the use of hidden Markov models in speech recognition, is described, and application of the proposed method to decoding telephone yellow pages is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820992"
                        ],
                        "name": "J. Rocha",
                        "slug": "J.-Rocha",
                        "structuredName": {
                            "firstName": "Jairo",
                            "lastName": "Rocha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rocha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2746449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73d76b5676e654cadb966aa859a5265f7b2731ac",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A segmentation-free approach to OCR is presented as part of a knowledge-based word interpretation model. It is based on the recognition of subgraphs homeomorphic to previously defined prototypes of characters. Gaps are identified as potential parts of characters by implementing a variant of the notion of relative neighborhood used in computational perception. Each subgraph of strokes that matches a previously defined character prototype is recognized anywhere in the word even if it corresponds to a broken character or to a character touching another one. The characters are detected in the order defined by the matching quality. Each subgraph that is recognized is introduced as a node in a directed net that compiles different alternatives of interpretation of the features in the feature graph. A path in the net represents a consistent succession of characters. A final search for the optimal path under certain criteria gives the best interpretation of the word features. Broken characters are recognized by looking for gaps between features that may be interpreted as part of a character. Touching characters are recognized because the matching allows nonmatched adjacent strokes. The recognition results for over 24,000 printed numeral characters belonging to a USPS database and on some hand-printed words confirmed the method's high robustness level. >"
            },
            "slug": "Character-Recognition-Without-Segmentation-Rocha-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Character Recognition Without Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A segmentation-free approach to OCR is presented as part of a knowledge-based word interpretation model based on the recognition of subgraphs homeomorphic to previously defined prototypes of characters based on a variant of the notion of relative neighborhood used in computational perception."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768769"
                        ],
                        "name": "F. Cesarini",
                        "slug": "F.-Cesarini",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Cesarini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Cesarini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285734"
                        ],
                        "name": "S. Marinai",
                        "slug": "S.-Marinai",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Marinai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Marinai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5595658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abc89e4eee4efc4d7b682b9bad6ba7cf118f168d",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a flexible form-reader system capable of extracting textual information from accounting documents, like invoices and bills of service companies. In this kind of document, the extraction of some information fields cannot take place without having detected the corresponding instruction fields, which are only constrained to range in given domains. We propose modeling the document's layout by means of attributed relational graphs, which turn out to be very effective for form registration, as well as for performing a focused search for instruction fields. This search is carried out by means of a hybrid model, where proper algorithms, based on morphological operations and connected components, are integrated with connectionist models. Experimental results are given in order to assess the actual performance of the system."
            },
            "slug": "INFORMys:-A-Flexible-Invoice-Like-Form-Reader-Cesarini-Gori",
            "title": {
                "fragments": [],
                "text": "INFORMys: A Flexible Invoice-Like Form-Reader System"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A flexible form-reader system capable of extracting textual information from accounting documents, like invoices and bills of service companies, is described by means of attributed relational graphs, which turn out to be very effective for form registration, as well as for performing a focused search for instruction fields."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071412"
                        ],
                        "name": "S. Kuo",
                        "slug": "S.-Kuo",
                        "structuredName": {
                            "firstName": "Shyh-shiaw",
                            "lastName": "Kuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752802"
                        ],
                        "name": "O. Agazzi",
                        "slug": "O.-Agazzi",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Agazzi",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Agazzi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34954518,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "9843988a09a4cabe54009e410ab65ca18eaf70a0",
            "isKey": false,
            "numCitedBy": 291,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for robust machine recognition of keywords embedded in a poorly printed document is presented. For each keyword, two statistical models, called pseudo 2-D hidden Markov models, are created for representing the actual keyword and all the other extraneous words, respectively. Dynamic programming is then used for matching an unknown input word with the two models and for making a maximum likelihood decision. Although the models are pseudo 2-D in the sense that they are not fully connected 2-D networks, they are shown to be general enough in characterizing printed words efficiently. These models facilitate a nice \"elastic matching\" property in both horizontal and vertical directions, which makes the recognizer not only independent of size and slant but also tolerant of highly deformed and noisy words. The system is evaluated on a synthetically created database that contains about 26000 words. Currently, the authors achieve a recognition accuracy of 99% when words in testing and training sets are of the same font size, and 96% when they are in different sizes. In the latter case, the conventional 1-D HMM achieves only a 70% accuracy rate. >"
            },
            "slug": "Keyword-Spotting-in-Poorly-Printed-Documents-using-Kuo-Agazzi",
            "title": {
                "fragments": [],
                "text": "Keyword Spotting in Poorly Printed Documents using Pseudo 2-D Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An algorithm for robust machine recognition of keywords embedded in a poorly printed document is presented, where two statistical models, called pseudo 2-D hidden Markov models, are created for representing the actual keyword and all the other extraneous words, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2509780"
                        ],
                        "name": "Dz-Mou Jung",
                        "slug": "Dz-Mou-Jung",
                        "structuredName": {
                            "firstName": "Dz-Mou",
                            "lastName": "Jung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dz-Mou Jung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143939221"
                        ],
                        "name": "A. Shapira",
                        "slug": "A.-Shapira",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Shapira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Shapira"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41990072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bf93865292def67f96fda71045a947ca20408af",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "N-tuple features for optical character recognition have received only scattered attention since the 1960s. Our main purpose is to show that advances in computer technology and computer science compel renewed interest. N-tuple features are useful for printed character classification because they indicate the presence or absence of a given rigid configuration of n black and white pixels in a pattern. Desirable n-tuples fit each pattern of a specified (positive) training set of characters in at least p different shift positions, and fail to fit each pattern of a specified (negative) training set by at least n-q pixels in each shift position. We prove that the problem of finding a distinguishing n-tuple is NP-complete, by examining a natural subproblem with binary strings called the missing configuration problem. The NP-completeness result notwithstanding, distinguishing n-tuples are found automatically in a few seconds on contemporary workstations. We exhibit a practical search algorithm for generating, from a small training set, a collection of n-tuples with low class-conditional correlation and with specified design parameters n, p, and q. The generator, which is available on the Internet, is empirically shown to be effective through a comparison with a benchmark generator. We show experimentally that the design parameters provide a useful tradeoff between distinguishing power and generation time, and also between the conditional probabilities for the positive and negative classes. We explore the feature probabilities obtainable for various dichotomies, and show that the design parameters control the feature probabilities."
            },
            "slug": "N-Tuple-Features-for-OCR-Revisited-Jung-Krishnamoorthy",
            "title": {
                "fragments": [],
                "text": "N-Tuple Features for OCR Revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proves that the problem of finding a distinguishing n-tuple is NP-complete, by examining a natural subproblem with binary strings called the missing configuration problem, and exhibits a practical search algorithm for generating a collection of n-tuples with low class-conditional correlation and with specified design parameters n, p, and q."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258400"
                        ],
                        "name": "\u00d8. Trier",
                        "slug": "\u00d8.-Trier",
                        "structuredName": {
                            "firstName": "\u00d8ivind",
                            "lastName": "Trier",
                            "middleNames": [
                                "Due"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00d8. Trier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48717516"
                        ],
                        "name": "T. Taxt",
                        "slug": "T.-Taxt",
                        "structuredName": {
                            "firstName": "Torfinn",
                            "lastName": "Taxt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Taxt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17335271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e029d1a5daffbb88b932ccd27752c8c293547cb",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Compares the performance of topographic analysis and binary analysis for recognition of digits in hydrographic maps. The performance of each method was measured by the correct classification rate of the final symbol recognition step when processing a complete hydrographic map of size 0.45/spl times/0.6 m/sup 2/ with about 35000 digits. The experimental results indicated that binary analysis had a better performance than topographic analysis. Overall, the performance of the binary analysis was acceptable."
            },
            "slug": "Recognition-of-Digits-in-Hydrographic-Maps:-Binary-Trier-Taxt",
            "title": {
                "fragments": [],
                "text": "Recognition of Digits in Hydrographic Maps: Binary Versus Topographic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The experimental results indicated that binary analysis had a better performance than topographic analysis, and overall, the performance of the binary analysis was acceptable."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778108"
                        ],
                        "name": "R. Shinghal",
                        "slug": "R.-Shinghal",
                        "structuredName": {
                            "firstName": "Rajjan",
                            "lastName": "Shinghal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shinghal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145822375"
                        ],
                        "name": "G. Toussaint",
                        "slug": "G.-Toussaint",
                        "structuredName": {
                            "firstName": "Godfried",
                            "lastName": "Toussaint",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toussaint"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17403591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cad14eb683ff99d2005505b5ace211a1b745b0aa",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The modified Viterbi algorithm is a powerful, and increasingly used, tool for using contextual information in text recognition in its various forms. As yet, no known studies have been published concerning its robustness with respect to source statistics. This paper describes experiments performed to determine the sensitivity of the algorithm to variations in source statistics. The results of the experiments show that a character-recognition machine incorporating the modified Viterbi algorithm, using N-gram statistics estimated from source A does not deteriorate in performance when operating on a passage from source B even if A and B differ significantly in N-gram distributions or entropy."
            },
            "slug": "The-Sensitivity-of-the-Modified-Viterbi-Algorithm-Shinghal-Toussaint",
            "title": {
                "fragments": [],
                "text": "The Sensitivity of the Modified Viterbi Algorithm to the Source Statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results of the experiments show that a character-recognition machine incorporating the modified Viterbi algorithm, using N-gram statistics estimated from source A does not deteriorate in performance when operating on a passage from source B even if A and B differ significantly in N- gram distributions or entropy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38916969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c41d71ca5ae222ab72d16f254edb5fbd4e2de93",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in intelligent character recognition are enabling us to address many challenging problems in document image analysis. One of them is intelligent form analysis. This paper describes a generic system for form dropout when the filled-in characters or symbols are either touching or crossing the form frames. We propose a method to separate these characters from form frames whose locations are unknown. Since some of the character strokes are either touching or crossing the form frames, we need to address the following three issues: 1) localization of form frames; 2) separation of characters and form frames; and 3) reconstruction of broken strokes introduced during separation. The form frame is automatically located by finding long straight lines based on the block adjacency graph. Form frame separation and character reconstruction are implemented by means of this graph. The proposed system includes form structure learning and form dropout. First, a form structure-based template is automatically generated from a blank form which includes form frames, preprinted data areas and skew angle. With this form template, our system can then extract both handwritten and machine-typed filled-in data. Experimental results on three different types of forms show the performance of our system. Further, the proposed method is robust to noise and skew that is introduced during scanning."
            },
            "slug": "A-Generic-System-for-Form-Dropout-Yu-Jain",
            "title": {
                "fragments": [],
                "text": "A Generic System for Form Dropout"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A generic system for form dropout when the filled-in characters or symbols are either touching or crossing the form frames and a method to separate these characters from form frames whose locations are unknown is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144817390"
                        ],
                        "name": "E. Joseph",
                        "slug": "E.-Joseph",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Joseph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Joseph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17041460,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cda0fd9f622926cca7f8a2c75170832ea7426dbe",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditionally, zero crossings of the second derivative provide edge features for the classification of blurred waveforms. The accuracy of these edge features deteriorates in the case of severely blurred images. In this paper, a new feature is presented that is more resistant to the blurring process, the image, and waveform peaks. In addition, an estimate of the standard deviation /spl sigma/ of the blurring kernel is used to perform minor deblurring of the waveform. Statistical pattern recognition is used to classify the peaks as bar code characters. The noise tolerance of this recognition algorithm is increased by using an adaptive, histogram-based technique to remove the noise. In a bar code environment that requires a misclassification rate of less than one in a million, the recognition algorithm showed a 43% performance improvement over current commercial bar code reading equipment. >"
            },
            "slug": "Bar-Code-Waveform-Recognition-Using-Peak-Locations-Joseph-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Bar Code Waveform Recognition Using Peak Locations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new feature is presented that is more resistant to the blurring process, the image, and waveform peaks, and the recognition algorithm showed a 43% performance improvement over current commercial bar code reading equipment."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43147662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b06db544708285de691dbb2cc7d0f1b193117cf",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Arcs are important primitives in engineering drawings. Extracting these primitives during the lexical analysis phase is a prerequisite to syntactic and semantic understanding of engineering drawings within the machine drawing understanding system. Bars are detected by the orthogonal zig-zag vectorization algorithm. Some of the detected bars are linear approximations of arcs. As such, they provide the basis for arc segmentation. An arc is detected by finding a chain of bars and a triplet of points along the chain. The arc center is first approximated as the center of mass of the triangle formed by the intersection of the perpendicular bisectors of the chords these points define. The location of the center is refined by recursively finding more such triplets and converging to within no more than a few pixels from the actual arc center after two or three iterations. The high performance of the algorithm, demonstrated on a set of real engineering drawings, is due to the fact that it avoids both raster-to-vector and massive pixel-level operations, as well as any space transformations. >"
            },
            "slug": "Vector-Based-Arc-Segmentation-in-the-Machine-System-Dori",
            "title": {
                "fragments": [],
                "text": "Vector-Based Arc Segmentation in the Machine Drawing Understanding System Environment"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The high performance of the algorithm, demonstrated on a set of real engineering drawings, is due to the fact that it avoids both raster-to-vector and massive pixel-level operations, as well as any space transformations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10639741"
                        ],
                        "name": "H. Yamada",
                        "slug": "H.-Yamada",
                        "structuredName": {
                            "firstName": "Hiromitsu",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3311358"
                        ],
                        "name": "Katsumi Hosokawa",
                        "slug": "Katsumi-Hosokawa",
                        "structuredName": {
                            "firstName": "Katsumi",
                            "lastName": "Hosokawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katsumi Hosokawa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2021171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afec2f4735c87568e12029e8854b6798db0bf8f5",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the most difficult and important problems encountered in the automatic digitizing of graphical topographic maps is the identification and separate digitizing of different kinds of features. Essentially, in topographic maps, there are two kinds of geometric features: linear features, such as roads and railways that have an arbitrary length, and symbols, which indicate a type of building or area of land usage or even numerical information. These two types of features are extracted and recognized by using methods based on multiangled parallelism (MAP). The MAP operation method performs parallel calculation on directional feature planes. The linear features are extracted using erosion-dilation operations on the directional feature planes, and the symbols are extracted using a reformalized and parallel version of the generalized Hough transformation on the same directional planes, which is called the MAP matching method. The methods have been applied to a 1/25000 scale map. >"
            },
            "slug": "Directional-Mathematical-Morphology-and-Hough-for-Yamada-Yamamoto",
            "title": {
                "fragments": [],
                "text": "Directional Mathematical Morphology and Reformalized Hough Transformation for the Analysis of Topographic Maps"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper presents a method for extracting linear features and symbols from topographic maps using a reformalized and parallel version of the generalized Hough transformation on the same directional planes, which is called the MAP matching method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064264135"
                        ],
                        "name": "A. Hoover",
                        "slug": "A.-Hoover",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Hoover",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hoover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403999652"
                        ],
                        "name": "G. Jean-Baptiste",
                        "slug": "G.-Jean-Baptiste",
                        "structuredName": {
                            "firstName": "Gillian",
                            "lastName": "Jean-Baptiste",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Jean-Baptiste"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103801794"
                        ],
                        "name": "Xiao-Yue Jiang",
                        "slug": "Xiao-Yue-Jiang",
                        "structuredName": {
                            "firstName": "Xiao-Yue",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao-Yue Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704876"
                        ],
                        "name": "P. Flynn",
                        "slug": "P.-Flynn",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Flynn",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698267"
                        ],
                        "name": "D. Goldgof",
                        "slug": "D.-Goldgof",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Goldgof",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goldgof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996470"
                        ],
                        "name": "D. Eggert",
                        "slug": "D.-Eggert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Eggert",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eggert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843592"
                        ],
                        "name": "Robert B. Fisher",
                        "slug": "Robert-B.-Fisher",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fisher",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 836587,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "91d31a1e9619749051761341e6ac110962475fdf",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented, missed, and noise regions, over- and under-segmentation, and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches."
            },
            "slug": "An-Experimental-Comparison-of-Range-Image-Hoover-Jean-Baptiste",
            "title": {
                "fragments": [],
                "text": "An Experimental Comparison of Range Image Segmentation Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A methodology for evaluating range image segmentation algorithms and four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847486"
                        ],
                        "name": "R. Sinha",
                        "slug": "R.-Sinha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Sinha",
                            "middleNames": [
                                "Mahesh",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511209"
                        ],
                        "name": "B. Prasada",
                        "slug": "B.-Prasada",
                        "structuredName": {
                            "firstName": "Birendra",
                            "lastName": "Prasada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Prasada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48365989"
                        ],
                        "name": "G. Houle",
                        "slug": "G.-Houle",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Houle",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Houle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145834077"
                        ],
                        "name": "M. Sabourin",
                        "slug": "M.-Sabourin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Sabourin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sabourin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 837126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c6f1f0b3b0b74a37def6648ecc83dc6b24c53a5",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The hybrid contextural algorithm for reading real-life documents printed in varying fonts of any size is presented. Text is recognized progressively in three passes. The first pass is used to generate character hypothesis, the second to generate word hypothesis, and the third to verify the word hypothesis. During the first pass, isolated characters are recognized using a dynamic contour warping classifier. Transient statistical information is collected to accelerate the recognition process and to verify hypotheses in later processing. A transient dictionary consisting of high confidence nondictionary words is constructed in this pass. During the second pass, word-level hypotheses are generated using hybrid contextual text processing. Nondictionary words are recognized using a modified Viterbi algorithm, a string matching algorithm utilizing n grams, special handlers for touching characters, and pragmatic handlers for numerals, punctuation, hyphens, apostrophes, and a prefix/suffix handler. This processing usually generates several word hypothesis. During the third pass, word-level verification occurs. >"
            },
            "slug": "Hybrid-Contextural-Text-Recognition-with-String-Sinha-Prasada",
            "title": {
                "fragments": [],
                "text": "Hybrid Contextural Text Recognition with String Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The hybrid contextural algorithm for reading real-life documents printed in varying fonts of any size is presented and word-level hypotheses are generated using hybrid contextual text processing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120640002"
                        ],
                        "name": "Wenyin Liu",
                        "slug": "Wenyin-Liu",
                        "structuredName": {
                            "firstName": "Wenyin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyin Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7576746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fd350bebc797e965bd9cf0aa20a34603bff7c3d",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an incremental arc segmentation algorithm, which recovers the vectorized arc fragments obtained by the vectorization of a piece of arc image in a stepwise fashion. Due to proper threshold selection and consistent checking of cocircularity of the assumed arc pieces, the algorithm accurately constructs arcs from the vector input. Nearly 200 synthetic arcs, ranging in radius from five to 50 pixels, in open angle from 1/8/spl pi/ to 2/spl pi/, and in thickness from one to nine pixels, are used in the experiments and evaluation. Parts of six real drawings, containing about 200 arcs, are also processed. The algorithm works well for arc segments greater than 10 pixels in radius, /spl pi//4 in angle, and one pixel in width."
            },
            "slug": "Incremental-Arc-Segmentation-Algorithm-and-Its-Liu-Dori",
            "title": {
                "fragments": [],
                "text": "Incremental Arc Segmentation Algorithm and Its Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "An incremental arc segmentation algorithm, which recovers the vectorized arc fragments obtained by the vectorization of a piece of arc image in a stepwise fashion, which accurately constructs arcs from the vector input."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398550688"
                        ],
                        "name": "L. O'Gorman",
                        "slug": "L.-O'Gorman",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "O'Gorman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. O'Gorman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144819419"
                        ],
                        "name": "Irina Rabinovich",
                        "slug": "Irina-Rabinovich",
                        "structuredName": {
                            "firstName": "Irina",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irina Rabinovich"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43214715,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d52e599cfd7994db3128d40db2b541ed5ce0a90",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to authenticating photo-ID documents that relies on pattern recognition and public-key cryptography and has security advantages over physical mechanisms that currently safeguard cards, such as optical laminates and holograms. The pattern-recognition component of this approach is based on a photo signature that is a concise representation of the photo image on the document. This photo signature is stored in a database for remote authentication or in encrypted form on the card for stand-alone authentication. Verification of the ID document entails scanning both the photo image and a machine-readable form of the text information, determining the photo signature, and comparing this information against the reference. In this paper, we describe the method and present results of testing a large database of images for photo-signature match in the presence of noise."
            },
            "slug": "Secure-Identification-Documents-Via-Pattern-and-O'Gorman-Rabinovich",
            "title": {
                "fragments": [],
                "text": "Secure Identification Documents Via Pattern Recognition and Public-Key Cryptography"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "An approach to authenticating photo-ID documents that relies on pattern recognition and public-key cryptography and has security advantages over physical mechanisms that currently safeguard cards, such as optical laminates and holograms is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768752"
                        ],
                        "name": "H. Aghajan",
                        "slug": "H.-Aghajan",
                        "structuredName": {
                            "firstName": "Hamid",
                            "lastName": "Aghajan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Aghajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720911"
                        ],
                        "name": "T. Kailath",
                        "slug": "T.-Kailath",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kailath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kailath"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21588787,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "f33a755ff373852fdbfc87c000396fe698174ba9",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The SLIDE (subspace-based line detection) algorithm, a technique for estimating parameters of multiple straight lines in an image, is described. By reformulating the line fitting problem into a spectral estimation framework, SLID exploits subspace-based techniques of sensor array processing to obtain high resolution and closed-form estimates for the line parameters. The computational complexity of SLIDE is an order of magnitude less than that of the Hough transform method, and, unlike the Hough transform, SLIDE does not require a search procedure to estimate the parameters. Potential application areas of this technique include road tracing in robotic vision, aerial image analysis, mask-wafer alignment and linewidth measurement in semiconductor manufacturing, and text alignment in document analysis.<<ETX>>"
            },
            "slug": "SLIDE:-subspace-based-line-detection-Aghajan-Kailath",
            "title": {
                "fragments": [],
                "text": "SLIDE: subspace-based line detection"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The new so-called SLIDE (subspace-based line detection) algorithm then exploits the spatial coherence between the contributions of each line in different rows of the image to enhance and distinguish a signal subspace that is defined by the desired line parameters."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399449175"
                        ],
                        "name": "H. Al-Yousefi",
                        "slug": "H.-Al-Yousefi",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Al-Yousefi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Al-Yousefi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2663659"
                        ],
                        "name": "S. Upda",
                        "slug": "S.-Upda",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Upda",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Upda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12071943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "035d59afcaf141061a99e539ad3501133290c3cf",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A statistical approach for the recognition of Arabic characters is introduced. As a first step, the character is segmented into primary and secondary parts (dots and zigzags). The secondary parts of the character are then isolated and identified separately, thereby reducing the number of classes from 28 to 18. The moments of the horizontal and vertical projections of the remaining primary characters are then calculated and normalized with respect to the zero-order moment. Simple measures of the shape are obtained from the normalized moments. A 9-D feature vector is obtained for each character. Classification is accomplished using quadratic discriminant functions. The approach was evaluated using isolated, handwritten, and printed characters from a database established for this purpose. The results indicate that the technique offers better classification rates in comparison with existing methods. >"
            },
            "slug": "Recognition-of-Arabic-Characters-Al-Yousefi-Upda",
            "title": {
                "fragments": [],
                "text": "Recognition of Arabic Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The results indicate that the statistical approach for the recognition of Arabic characters offers better classification rates in comparison with existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112677491"
                        ],
                        "name": "Yu Gu",
                        "slug": "Yu-Gu",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013580"
                        ],
                        "name": "Q. Wang",
                        "slug": "Q.-Wang",
                        "structuredName": {
                            "firstName": "Qing",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14741452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd096263851f4bb7661129b9c6135cd90f2df662",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "A multistage classifier with general tree structure has been developed to recognize a large number of Chinese characters. A simple and efficient method of classifying the characters was achieved by choosing the best feature at each stage of the tree. The features used are Walsh coefficients obtained from two profiles of a character projected onto the X-Y orthogonal axes. Some algorithms for aligning the characters were compared and one of them was adopted in this recognition scheme. A high recognition rate of about 99.5 percent was obtained in an experiment with more than 3000 different Chinese characters."
            },
            "slug": "Application-of-a-Multilayer-Decision-Tree-in-of-Gu-Wang",
            "title": {
                "fragments": [],
                "text": "Application of a Multilayer Decision Tree in Computer Recognition of Chinese Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A multistage classifier with general tree structure has been developed to recognize a large number of Chinese characters and a high recognition rate of about 99.5 percent was obtained in an experiment with more than 3000 different Chinese characters."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717829"
                        ],
                        "name": "S. Joseph",
                        "slug": "S.-Joseph",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Joseph",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Joseph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762670"
                        ],
                        "name": "T. Pridmore",
                        "slug": "T.-Pridmore",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Pridmore",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pridmore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38297323,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d23c5945371b9d50612d64fabc4ecb9b67688dd",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "A methodology for the interpretation of images of engineering drawings is presented. The approach is based on the combination of schemata describing prototypical drawing constructs with a library of low-level image analysis routines and a set of explicit control rules applied by an LR(1) parser. The resulting system (Anon) integrates bottom-up and top-down processing strategies within a single, flexible framework modeled on the human perceptual cycle. Anon's structure and operation are described and discussed, and examples of its interpretation of real mechanical drawings are shown. >"
            },
            "slug": "Knowledge-Directed-Interpretation-of-Mechanical-Joseph-Pridmore",
            "title": {
                "fragments": [],
                "text": "Knowledge-Directed Interpretation of Mechanical Engineering Drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The resulting system (Anon) integrates bottom-up and top-down processing strategies within a single, flexible framework modeled on the human perceptual cycle."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2466701"
                        ],
                        "name": "Kyoon-Ha Lee",
                        "slug": "Kyoon-Ha-Lee",
                        "structuredName": {
                            "firstName": "Kyoon-Ha",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyoon-Ha Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890903"
                        ],
                        "name": "K. Eom",
                        "slug": "K.-Eom",
                        "structuredName": {
                            "firstName": "Kie",
                            "lastName": "Eom",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Eom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32583901"
                        ],
                        "name": "R. Kashyap",
                        "slug": "R.-Kashyap",
                        "structuredName": {
                            "firstName": "Rangasami",
                            "lastName": "Kashyap",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kashyap"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40297818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d6cc884719d57aa7cd1f12669fa31f053b25220",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of Korean characters by a syntactic method is considered. Korean characters are composed of phonetic symbols in two dimensions and contain very little redundancy. In addition, the phonetic symbols in each character are different in shape and number depending on how they are composed. Thus, attribute information is important. A Korean character recognition algorithm based on an attribute-dependent programmed grammar is presented. The preprocessing and primitive extraction algorithm is also described. The algorithm was implemented and tested with more than 9600 Korean characters in pages randomly selected from children's story books. The algorithm based on the attribute-dependent programmed grammar recognized characters reasonably quickly, with more than 95.1% accuracy. >"
            },
            "slug": "Character-Recognition-Based-on-Attribute-Dependent-Lee-Eom",
            "title": {
                "fragments": [],
                "text": "Character Recognition Based on Attribute-Dependent Programmed Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A Korean character recognition algorithm based on an attribute-dependent programmed grammar is presented and the preprocessing and primitive extraction algorithm is also described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120640002"
                        ],
                        "name": "Wenyin Liu",
                        "slug": "Wenyin-Liu",
                        "structuredName": {
                            "firstName": "Wenyin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46663811,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fe43e104a138709d059f163e4d173f4adb61e6a",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Accurate and efficient vectorization of line drawings is essential for their higher level processing. We present a thinningless sparse pixel vectorization (SPV) algorithm. Rather than visiting all the points along the wire's black area, SPV sparsely visits selected medial axis points. The result is a crude polyline, which is refined through polygonal approximation by removing redundant points. Due to the sparseness of pixel examination and the use of a specialized data structure, SPV is both time efficient and accurate, as evaluated by our proposed performance evaluation criteria."
            },
            "slug": "Sparse-Pixel-Vectorization:-An-Algorithm-and-Its-Dori-Liu",
            "title": {
                "fragments": [],
                "text": "Sparse Pixel Vectorization: An Algorithm and Its Performance Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work presents a thinningless sparse pixel vectorization (SPV) algorithm, which is both time efficient and accurate, as evaluated by the proposed performance evaluation criteria."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311113"
                        ],
                        "name": "D. Havelock",
                        "slug": "D.-Havelock",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Havelock",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Havelock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20714260,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c99a6d5bd5f48e5c1fc96e45e2a1a97bca5ddbd3",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A basis for determining the best possible precision for the position of a given object in a digital image is developed. The approach is general, being independent of object-form and providing a performance bound on all position estimation schemes. The central concepts in the development are the locale and total variation of the image function. An easily computed bound for the smallest attainable RSM position estimation error is developed. The best possible estimate is given by the centroids of the locales. The analysis of geometric precision using locales shows how object position-uncertainty depends on the object's position. Visual inspection of the easily generated locale pattern gives a qualitative impression of the spatial distribution of geometric precision. The analytic techniques developed provide avenues for both qualitative and quantitative evaluation of target forms and position estimation schemes in terms of their precision mensuration capabilities. >"
            },
            "slug": "Geometric-Precision-in-Noise-Free-Digital-Images-Havelock",
            "title": {
                "fragments": [],
                "text": "Geometric Precision in Noise-Free Digital Images"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A basis for determining the best possible precision for the position of a given object in a digital image is developed, being independent of object-form and providing a performance bound on all position estimation schemes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32129023"
                        ],
                        "name": "L. Stringa",
                        "slug": "L.-Stringa",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Stringa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Stringa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29642823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d51fdd19338a2541576382607d93dcb344c160f2",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A general pattern-recognition procedure for application to unconstrained alphanumeric characters is presented. The procedure is designed to allow hierarchical redescription of the input images in terms of significant elements only, and formal developments are given within the framework of elementary phrase-structure grammars. The extraction of the primitives associated with the terminal vocabularies of the grammars is always deterministic, and the productions of the parsers are characterized by a significant degree of topological fidelity. Preliminary experimental results indicate recognition rates comparable to the state of the art, but with a considerable reduction in computing time. >"
            },
            "slug": "A-New-Set-of-Constraint-Free-Character-Recognition-Stringa",
            "title": {
                "fragments": [],
                "text": "A New Set of Constraint-Free Character Recognition Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A general pattern-recognition procedure for application to unconstrained alphanumeric characters is presented, and preliminary experimental results indicate recognition rates comparable to the state of the art, but with a considerable reduction in computing time."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803621"
                        ],
                        "name": "A. Khotanzad",
                        "slug": "A.-Khotanzad",
                        "structuredName": {
                            "firstName": "Alireza",
                            "lastName": "Khotanzad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khotanzad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3354183"
                        ],
                        "name": "Yaw Hua Hong",
                        "slug": "Yaw-Hua-Hong",
                        "structuredName": {
                            "firstName": "Yaw",
                            "lastName": "Hong",
                            "middleNames": [
                                "Hua"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaw Hua Hong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2176918,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f12b2b698d586e219bfa07a56615d1cefb8557e1",
            "isKey": false,
            "numCitedBy": 2005,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of rotation-, scale-, and translation-invariant recognition of images is discussed. A set of rotation-invariant features are introduced. They are the magnitudes of a set of orthogonal complex moments of the image known as Zernike moments. Scale and translation invariance are obtained by first normalizing the image with respect to these parameters using its regular geometrical moments. A systematic reconstruction-based method for deciding the highest-order Zernike moments required in a classification problem is developed. The quality of the reconstructed image is examined through its comparison to the original one. The orthogonality property of the Zernike moments, which simplifies the process of image reconstruction, make the suggest feature selection approach practical. Features of each order can also be weighted according to their contribution to the reconstruction process. The superiority of Zernike moment features over regular moments and moment invariants was experimentally verified. >"
            },
            "slug": "Invariant-Image-Recognition-by-Zernike-Moments-Khotanzad-Hong",
            "title": {
                "fragments": [],
                "text": "Invariant Image Recognition by Zernike Moments"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A systematic reconstruction-based method for deciding the highest-order ZERNike moments required in a classification problem is developed and the superiority of Zernike moment features over regular moments and moment invariants was experimentally verified."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700821"
                        ],
                        "name": "F. Esposito",
                        "slug": "F.-Esposito",
                        "structuredName": {
                            "firstName": "Floriana",
                            "lastName": "Esposito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Esposito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738657"
                        ],
                        "name": "D. Malerba",
                        "slug": "D.-Malerba",
                        "structuredName": {
                            "firstName": "Donato",
                            "lastName": "Malerba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Malerba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467353"
                        ],
                        "name": "G. Semeraro",
                        "slug": "G.-Semeraro",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Semeraro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Semeraro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15737721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cef878ca79403fc28d1456e96a5a62e969a72d16",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A definition of distance measure between structural descriptions that is based on a probabilistic interpretation of the matching predicate is proposed. It aims at coping with the problem of classification when noise causes both local and structural deformations. The distance measure is defined according to a top-down evaluation scheme: distance between disjunctions of conjuncts, conjunctions, and literals. At the lowest level, the similarity between a feature value in the pattern model (G) and the corresponding value in the observation (Ex) is defined as the probability of observing a greater distortion. The classification problem is approached by means of a multilayered framework in which the cases of single perfect match, no perfect match, and multiple perfect match are treated differently. A plausible solution for the problem of completing the attribute and structure spaces, based on the probabilistic approach, is also given. A comparison with other related works and an application in the domain of layout-based document recognition are presented. >"
            },
            "slug": "Classification-in-Noisy-Environments-Using-a-Esposito-Malerba",
            "title": {
                "fragments": [],
                "text": "Classification in Noisy Environments Using a Distance Measure Between Structural Symbolic Descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A definition of distance measure between structural descriptions that is based on a probabilistic interpretation of the matching predicate is proposed, aimed at coping with the problem of classification when noise causes both local and structural deformations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795578"
                        ],
                        "name": "T. Ho",
                        "slug": "T.-Ho",
                        "structuredName": {
                            "firstName": "Tin",
                            "lastName": "Ho",
                            "middleNames": [
                                "Kam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694191"
                        ],
                        "name": "J. Hull",
                        "slug": "J.-Hull",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hull",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8412354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d6d5cfa8e99dd53e50bf870e24e72b0be7f7aeb",
            "isKey": false,
            "numCitedBy": 1676,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A multiple classifier system is a powerful solution to difficult pattern recognition problems involving large class sets and noisy input because it allows simultaneous use of arbitrary feature descriptors and classification procedures. Decisions by the classifiers can be represented as rankings of classifiers and different instances of a problem. The rankings can be combined by methods that either reduce or rerank a given set of classes. An intersection method and union method are proposed for class set reduction. Three methods based on the highest rank, the Borda count, and logistic regression are proposed for class set reranking. These methods have been tested in applications of degraded machine-printed characters and works from large lexicons, resulting in substantial improvement in overall correctness. >"
            },
            "slug": "Decision-Combination-in-Multiple-Classifier-Systems-Ho-Hull",
            "title": {
                "fragments": [],
                "text": "Decision Combination in Multiple Classifier Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes three methods based on the highest rank, the Borda count, and logistic regression for class set reranking that have been tested in applications of degraded machine-printed characters and works from large lexicons, resulting in substantial improvement in overall correctness."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402942759"
                        ],
                        "name": "H. Avi-Itzhak",
                        "slug": "H.-Avi-Itzhak",
                        "structuredName": {
                            "firstName": "Hadar",
                            "lastName": "Avi-Itzhak",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Avi-Itzhak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745862"
                        ],
                        "name": "J. V. Mieghem",
                        "slug": "J.-V.-Mieghem",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Mieghem",
                            "middleNames": [
                                "A.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. V. Mieghem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46487083"
                        ],
                        "name": "Leonardo Rub",
                        "slug": "Leonardo-Rub",
                        "structuredName": {
                            "firstName": "Leonardo",
                            "lastName": "Rub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leonardo Rub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2741540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "85215b37a1f09b3c884a9a58bebd45cca4614472",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses a correlation based nearest neighbor pattern recognition problem where each class is given as a collection of subclass templates. The recognition is performed in two stages. In the first stage the class is determined. Templates for this stage are created using the subclass templates. Assignment into subclasses occurs in the second stage. This two stage approach may be used to accelerate template matching. In particular, the second stage may be omitted when only the class needs to be determined. The authors present a method for optimal aggregation of subclass templates into class templates. For each class, the new template is optimal in that it maximizes the worst case (i.e. minimum) correlation with its subclass templates. An algorithm which solves this maximin optimization problem is presented and its correctness is proved. In addition, test results are provided, indicating that the algorithm's execution time is polynomial in the number of subclass templates. The authors show tight bounds on the maximin correlation. The bounds are functions only of the number of original subclass templates and the minimum element in their correlation matrix. The algorithm is demonstrated on a multifont optical character recognition problem. >"
            },
            "slug": "Multiple-Subclass-Pattern-Recognition:-A-Maximin-Avi-Itzhak-Mieghem",
            "title": {
                "fragments": [],
                "text": "Multiple Subclass Pattern Recognition: A Maximin Correlation Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm which solves this maximin optimization problem is presented and its correctness is proved and test results are provided, indicating that the algorithm's execution time is polynomial in the number of subclass templates."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145950"
                        ],
                        "name": "R. Bergevin",
                        "slug": "R.-Bergevin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bergevin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bergevin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3631473"
                        ],
                        "name": "M. Levine",
                        "slug": "M.-Levine",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Levine",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Levine"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36101542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82ad0e7c850c38953d2e2aaaa05c60be3f05330e",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Primal access recognition of visual objects (PARVO), a computer vision system that addresses the problem of fast and generic recognition of unexpected 3D objects from single 2D views, is considered. Recently, recognition by components (RBC), which is a new human image understanding theory, based on some psychological results, has been proposed as an explanation of how PARVO works. However, no systematic computational evaluation of its many aspects has yet been reported. The PARVO system discussed is a first step toward this goal, since its design respects and makes explicit the main assumptions of the proposed theory. It analyzes single-view 2D line drawings of 3D objects typical of the ones used in human image understanding studies. It is designed to handle partially occluded objects of different shape and dimension in various spatial orientations and locations in the image plane. The system is shown to successfully compute generic descriptions and then recognize many common man-made objects. >"
            },
            "slug": "Generic-Object-Recognition:-Building-and-Matching-Bergevin-Levine",
            "title": {
                "fragments": [],
                "text": "Generic Object Recognition: Building and Matching Coarse Descriptions from Line Drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The PARVO system discussed is a first step toward this goal, since its design respects and makes explicit the main assumptions of the proposed theory, and is shown to successfully compute generic descriptions and then recognize many common man-made objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2311113"
                        ],
                        "name": "D. Havelock",
                        "slug": "D.-Havelock",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Havelock",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Havelock"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45086337,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "aae8b981a3848047617ba1efb6964ac4a66a0e2c",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The precision to which the position of a target in a digital image can be estimated may be analyzed by considering the possible digital representations of the target. Such an analysis leads to regions of indistinguishable target position, referred to as locales. By considering the density, distribution, and shape of these locales, the available precision can be estimated. Previously, such analyses have presumed an absence of noise in the digital image. It is shown how the noise tolerance for position estimation is affected by the topological properties of locales, such as locale connectivity, adjacency, and clustering. >"
            },
            "slug": "The-Topology-of-Locales-and-Its-Effects-on-Position-Havelock",
            "title": {
                "fragments": [],
                "text": "The Topology of Locales and Its Effects on Position Uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how the noise tolerance for position estimation is affected by the topological properties of locales, such as locale connectivity, adjacency, and clustering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35126187"
                        ],
                        "name": "Prateek Sarkar",
                        "slug": "Prateek-Sarkar",
                        "structuredName": {
                            "firstName": "Prateek",
                            "lastName": "Sarkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prateek Sarkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12109046,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3a1d867140b87ed9c481446937e1f8a30b2b8b10",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The bitmap obtained by scanning a printed pattern depends on the exact location of the scanning grid relative to the pattern. We consider ideal sampling with a regular lattice of delta functions. The displacement of the lattice relative to the pattern is random and obeys a uniform probability density function defined over a unit cell of the lattice. Random-phase sampling affects the edge-pixels of sampled patterns. The resulting number of distinct bitmaps and their relative frequencies can be predicted from a mapping of the original pattern boundary to the unit cell (called a module-grid diagram). The theory is supported by both simulated and experimental results. The module-grid diagram may be useful in helping to understand the effects of edge-pixel variation on optical character recognition."
            },
            "slug": "Spatial-Sampling-of-Printed-Patterns-Sarkar-Nagy",
            "title": {
                "fragments": [],
                "text": "Spatial Sampling of Printed Patterns"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The bitmap obtained by scanning a printed pattern depends on the exact location of the scanning grid relative to the pattern, and the resulting number of distinct bitmaps can be predicted from a mapping of the original pattern boundary to the unit cell (called a module-grid diagram)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2977230"
                        ],
                        "name": "A. Okazaki",
                        "slug": "A.-Okazaki",
                        "structuredName": {
                            "firstName": "Akio",
                            "lastName": "Okazaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Okazaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49083900"
                        ],
                        "name": "Takashi Kondo",
                        "slug": "Takashi-Kondo",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Kondo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takashi Kondo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113702972"
                        ],
                        "name": "Kazuhiro Mori",
                        "slug": "Kazuhiro-Mori",
                        "structuredName": {
                            "firstName": "Kazuhiro",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiro Mori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48009929"
                        ],
                        "name": "S. Tsunekawa",
                        "slug": "S.-Tsunekawa",
                        "structuredName": {
                            "firstName": "Shou",
                            "lastName": "Tsunekawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsunekawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075751609"
                        ],
                        "name": "Eiji Kawamoto",
                        "slug": "Eiji-Kawamoto",
                        "structuredName": {
                            "firstName": "Eiji",
                            "lastName": "Kawamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eiji Kawamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5399182,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d721325272c1fa8eaafe8d90a4dbf9fc2f7125ef",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A high-performance logic circuit diagram reader was developed for VLSI-CAD data input. Almost all logic circuit symbols include one or more loop structures. A description is given of an efficient method for recognition of these loop-structured symbols. The proposed method consists of two processes: symbol segmentation and symbol identification. Symbol identification is achieved by a powerful hybrid method which uses heuristics to mediate between template matching and feature extraction. The entire symbol recognition process is carried out under a decision-tree control strategy. The entire recognition system for circuit diagrams is briefly explained, including character string recognition and connecting line analysis. >"
            },
            "slug": "An-Automatic-Circuit-Diagram-Reader-with-Symbol-Okazaki-Kondo",
            "title": {
                "fragments": [],
                "text": "An Automatic Circuit Diagram Reader with Loop-Structure-Based Symbol Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A high-performance logic circuit diagram reader was developed for VLSI-CAD data input and the entire recognition system for circuit diagrams is briefly explained, including character string recognition and connecting line analysis."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107902836"
                        ],
                        "name": "Xiaofei Huang",
                        "slug": "Xiaofei-Huang",
                        "structuredName": {
                            "firstName": "Xiaofei",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofei Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144097161"
                        ],
                        "name": "Jun Gu",
                        "slug": "Jun-Gu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115859002"
                        ],
                        "name": "Youshou Wu",
                        "slug": "Youshou-Wu",
                        "structuredName": {
                            "firstName": "Youshou",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Youshou Wu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26896766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "761c94559ab8f13e061f9be7ed59363e801de27f",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The constraint graph is introduced as a general character representation framework for recognizing multifont, multiple-size Chinese characters. Each character class is described by a constraint graph model. Sampling points on a character skeleton are taken as nodes in the graph. Connection constraints and position constraints are taken as arcs in the graph. For patterns of the same character class, the model captures both the topological invariance and the geometrical invariance in a general and uniform way. Character recognition is then formulated as a constraint-based optimization problem. A cooperative relaxation matching algorithm that solves this optimization problem is developed. A practical optical character recognition (OCR) system that is able to recognize multifont, multiple-size Chinese characters with a satisfactory performance was implemented. >"
            },
            "slug": "A-Constrained-Approach-to-Multifont-Chinese-Huang-Gu",
            "title": {
                "fragments": [],
                "text": "A Constrained Approach to Multifont Chinese Character Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A practical optical character recognition (OCR) system that is able to recognize multifont, multiple-size Chinese characters with a satisfactory performance was implemented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2744969"
                        ],
                        "name": "K. L. Einspahr",
                        "slug": "K.-L.-Einspahr",
                        "structuredName": {
                            "firstName": "Kent",
                            "lastName": "Einspahr",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. L. Einspahr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16502468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d66e0881695efdef8356d02bd011023bdc24506a",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A substitution cipher consists of a block of natural language text where each letter of the alphabet has been replaced by a distinct symbol. As a problem in cryptography, the substitution cipher is of limited interest, but it has an important application in optical character recognition. Recent advances render it quite feasible to scan documents with a fairly complex layout and to classify (cluster) the printed characters into distinct groups according to their shape. However, given the immense variety of type styles and forms in current use, it is not possible to assign alphabetical identities to characters of arbitrary size and typeface. This gap can be bridged by solving the equivalent of a substitution cipher problem, thereby opening up the possibility of automatic translation of a scanned document into a standard character code, such as ASCII. Earlier methods relying on letter n-gram frequencies require a substantial amount of ciphertext for accurate n-gram estimates. A dictionary-based approach solves the problem using relatively small ciphertext samples and a dictionary of fewer than 500 words. Our heuristic backtrack algorithm typically visits only a few hundred among the 26! possible nodes on sample texts ranging from 100 to 600 words."
            },
            "slug": "Decoding-Substitution-Ciphers-by-Means-of-Word-with-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "Decoding Substitution Ciphers by Means of Word Matching with Application to OCR"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The heuristic backtrack algorithm typically visits only a few hundred among the 26! possible nodes on sample texts ranging from 100 to 600 words, thereby opening up the possibility of automatic translation of a scanned document into a standard character code, such as ASCII."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1866105"
                        ],
                        "name": "E. Yannakoudakis",
                        "slug": "E.-Yannakoudakis",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Yannakoudakis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Yannakoudakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48449117"
                        ],
                        "name": "G. Angelidakis",
                        "slug": "G.-Angelidakis",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Angelidakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Angelidakis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21078481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb5aad8c0afcc37e5f245987f846ce5232c9aa6e",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The inherent statistical characteristics, including the economy, entropy, and redundancy, of a very large set containing 93681 words from the Shorter Oxford English Dictionary is investigated. Analytical n-gram statistics are also presented for applications in natural language understanding, text processing, test compression, error detection and correction, and speech synthesis and recognition. Experimental results show how the distribution of n-grams in the dictionary varies from the ideal as n increases from 2 to 5, that is, from bigrams to pentagrams; it is shown that the corresponding redundancy increases from 0.1067 to 0.3409. The results are of interest because, (1) the dictionary provides a finite list for deterministic analyses, (2) each entry (word) appears once, compared to free-running text where words are repeated, and (3) all entries, even rarely occurring ones, have equal weight. >"
            },
            "slug": "An-Insight-into-the-Entropy-and-Redundancy-of-the-Yannakoudakis-Angelidakis",
            "title": {
                "fragments": [],
                "text": "An Insight into the Entropy and Redundancy of the English Dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results show how the distribution of n-grams in the dictionary varies from the ideal as n increases from 2 to 5, that is, from bigrams to pentagrams; it is shown that the corresponding redundancy increases from 0.1067 to 0.3409."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013580"
                        ],
                        "name": "Q. Wang",
                        "slug": "Q.-Wang",
                        "structuredName": {
                            "firstName": "Qing",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16172821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b343361ceecb7bd67185f10a9721dfc410daafb",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on a recursive process of reducing the entropy, the general decision tree classifier with overlap has been analyzed. Several theorems have been proposed and proved. When the number of pattern classes is very large, the theorems can reveal both the advantages of a tree classifier and the main difficulties in its implementation. Suppose H is Shannon's entropy measure of the given problem. The theoretical results indicate that the tree searching time can be minimized to the order O(H), but the error rate is also in the same order O(H) due to error accumulation. However, the memory requirement is in the order 0(H exp(H)) which poses serious problems in the implementation of a tree classifier for a large number of classes. To solve these problems, several theorems related to the bounds on the search time, error rate, memory requirement and overlap factor in the design of a decision tree have been proposed and some principles have been established to analyze the behaviors of the decision tree. When applied to classify sets of 64, 450, and 3200 Chinese characters, respectively, the experimental results support the theoretical predictions. For 3200 classes, a very high recognition rate of 99.88 percent was achieved at a high speed of 873 samples/s when the experiment was conducted on a Cyber 172 computer using a high-level language."
            },
            "slug": "Analysis-and-Design-of-a-Decision-Tree-Based-on-and-Wang-Suen",
            "title": {
                "fragments": [],
                "text": "Analysis and Design of a Decision Tree Based on Entropy Reduction and Its Application to Large Character Set Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Several theorems related to the bounds on the search time, error rate, memory requirement and overlap factor in the design of a decision tree have been proposed and some principles have been established to analyze the behaviors of the decision tree."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056931359"
                        ],
                        "name": "J. A. Mulder",
                        "slug": "J.-A.-Mulder",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Mulder",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Mulder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690624"
                        ],
                        "name": "Alan K. Mackworth",
                        "slug": "Alan-K.-Mackworth",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Mackworth",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan K. Mackworth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7830772"
                        ],
                        "name": "W. Havens",
                        "slug": "W.-Havens",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Havens",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Havens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16996490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22f65c4ef5751629e4c09c359ef53993d42dcb5a",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Schema-based representations for visual knowledge are integrated with constraint satisfaction techniques. This integration is discussed in a progression of three sketch map interpretation programs: Mapsee-1, Mapsee-2, and Mapsee-3. The programs are evaluated by the criteria of descriptive and procedural adequacy. The evaluation indicates that a schema-based representation used in combination with a hierarchical arc-consistency algorithm constitutes a modular, efficient, and effective approach to the structured representation of visual knowledge. The schemata used in this representation are embedded in composition and specialization hierarchies. Specialization hierarchies are further expanded into discrimination graphs. >"
            },
            "slug": "Knowledge-Structuring-and-Constraint-Satisfaction:-Mulder-Mackworth",
            "title": {
                "fragments": [],
                "text": "Knowledge Structuring and Constraint Satisfaction: The Mapsee Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The evaluation indicates that a schema-based representation used in combination with a hierarchical arc-consistency algorithm constitutes a modular, efficient, and effective approach to the structured representation of visual knowledge."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17283658,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cd1d1353dbc8d788996b819e21d312309b7bc792",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "n-gram (n = 1 to 5) statistics and other properties of the English language were derived for applications in natural language understanding and text processing. They were computed from a well-known corpus composed of 1 million word samples. Similar properties were also derived from the most frequent 1000 words of three other corpuses. The positional distributions of n-grams obtained in the present study are discussed. Statistical studies on word length and trends of n-gram frequencies versus vocabulary are presented. In addition to a survey of n-gram statistics found in the literature, a collection of n-gram statistics obtained by other researchers is reviewed and compared."
            },
            "slug": "n-Gram-Statistics-for-Natural-Language-and-Text-Suen",
            "title": {
                "fragments": [],
                "text": "n-Gram Statistics for Natural Language Understanding and Text Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The positional distributions of n-grams obtained in the present study are discussed and statistical studies on word length and trends ofn-gram frequencies versus vocabulary are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10488995,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a63c0561ade044b68907aa6c92c5fb7355bc7640",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Attributed programmed graph grammars are introduced in this paper and their application to the interpretation of schematic diagrams is proposed. In contrast with most of the approaches to syntactic pattern recognition, where the grammar controls a parser, the grammar in our system is used as a generative tool. Two classes of diagrams are studied, namely circuit diagrams and flowcharts. The task is in either case to extract a description from an input diagram."
            },
            "slug": "Attributed-Programmed-Graph-Grammars-and-Their-to-Bunke",
            "title": {
                "fragments": [],
                "text": "Attributed Programmed Graph Grammars and Their Application to Schematic Diagram Interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Attributed programmed graph grammars are introduced in this paper and their application to the interpretation of schematic diagrams is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909274"
                        ],
                        "name": "V. S. Nalwa",
                        "slug": "V.-S.-Nalwa",
                        "structuredName": {
                            "firstName": "Vishvjit",
                            "lastName": "Nalwa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. S. Nalwa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 31128528,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8b60691dd32f53c702d7c570d6f4b2c7d2635485",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Line drawings of man-made scenes often exhibit instances of straight lines and conic sections, i.e. ellipses, parabolas, and hyperbolas. Constraints imposed on the scene by such instances are investigated, under the assumption of general viewpoint, i.e. the mapping of the viewed surface onto the line drawing is stable under perturbation of the viewpoint within some open set. Both orthographic and perspective projection are considered. The viewed surfaces are assumed to be piecewise C/sup 3/. It is shown that straight lines and conic sections in line drawings are projections of scene edges which are also straight lines and conic sections, respectively. It is also shown that scene events which project onto straight lines or conic sections cannot be combinations of view-point-independent and viewpoint-dependent edges. Further, continuous-surface-normal depth discontinuities which project onto straight lines can be locally described by developable surfaces, and those which project onto conic sections can be locally described by nondevelopable quadric surfaces. Each of these quadric surfaces is determined up to four degrees-of-freedom by its projection. >"
            },
            "slug": "Line-Drawing-Interpretation:-Straight-Lines-and-Nalwa",
            "title": {
                "fragments": [],
                "text": "Line-Drawing Interpretation: Straight Lines and Conic Sections"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that scene events which project onto straight lines or conic sections cannot be combinations of view-point-independent and viewpoint-dependent edges, and that continuous-surface-normal depth discontinuities which project on straight lines can be locally described by developable surfaces, and those which project upon conic Sections can be local described by nondevelopable quadric surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777663"
                        ],
                        "name": "H. Nagahashi",
                        "slug": "H.-Nagahashi",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Nagahashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagahashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2180870"
                        ],
                        "name": "M. Nakatsuyama",
                        "slug": "M.-Nakatsuyama",
                        "structuredName": {
                            "firstName": "Mikio",
                            "lastName": "Nakatsuyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nakatsuyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15790210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41c5c15b49d5813a81d8f46f16eb964772e2dbf4",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We report a pattern description and generation method of structural characters, and show some examples of Chinese and Korean character patterns actually generated. We also consider its educational and graphical applications. In this method, any character is regarded as a composite pattern constructed by several simpler subpatterns, and is described in terms of them by introducing three kinds of positional relationships among them. A composite pattern can become a subpattern, too. We call these patterns blocks. Syntactic grammar is defined to encode a pattern expression by two code strings, that is, a string of blocks and a string of production rules. They are used in generating patterns, namely, derivation of pattern expression from the code strings is defined as a process of pattern generation. By this description and generation method, we can encode structural characters without much memory, and generate natural shapes of patterns."
            },
            "slug": "A-Pattern-Description-and-Generation-Method-of-Nagahashi-Nakatsuyama",
            "title": {
                "fragments": [],
                "text": "A Pattern Description and Generation Method of Structural Characters"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "By this description and generation method, this paper can encode structural characters without much memory, and generate natural shapes of patterns, and consider its educational and graphical applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554435"
                        ],
                        "name": "Issam Bazzi",
                        "slug": "Issam-Bazzi",
                        "structuredName": {
                            "firstName": "Issam",
                            "lastName": "Bazzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Issam Bazzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11815403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6272317b62292deb6f342f499f36e6ecf7b9c1b",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an omnifont, unlimited-vocabulary OCR system for English and Arabic. The system is based on hidden Markov models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition. We focus on two aspects of the OCR system. First, we address the issue of how to perform OCR on omnifont and multi-style data, such as plain and italic, without the need to have a separate model for each style. The amount of training data from each style, which is used to train a single model, becomes an important issue in the face of the conditional independence assumption inherent in the use of HMMs. We demonstrate mathematically and empirically how to allocate training data among the different styles to alleviate this problem. Second, we show how to use a word-based HMM system to perform character recognition with unlimited vocabulary. The method includes the use of a trigram language model on character sequences. Using all these techniques, we have achieved character error rates of 1.1 percent on data from the University of Washington English Document Image Database and 3.3 percent on data from the DARPA Arabic OCR Corpus."
            },
            "slug": "An-Omnifont-Open-Vocabulary-OCR-System-for-English-Bazzi-Schwartz",
            "title": {
                "fragments": [],
                "text": "An Omnifont Open-Vocabulary OCR System for English and Arabic"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "An omnifont, unlimited-vocabulary OCR system for English and Arabic based on hidden Markov models (HMM), an approach that has proven to be very successful in the area of automatic speech recognition, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072921373"
                        ],
                        "name": "E. Tanaka",
                        "slug": "E.-Tanaka",
                        "structuredName": {
                            "firstName": "Eiichi",
                            "lastName": "Tanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Tanaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40077765"
                        ],
                        "name": "Yurie Kojima",
                        "slug": "Yurie-Kojima",
                        "structuredName": {
                            "firstName": "Yurie",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yurie Kojima"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14773191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d870f68c29882f345385fbb34297e879aabffad",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a high speed string correction method using a hierarchical file. After reviewing a string correction method based on the Levenshtein distance, a hierarchical file construction method is introduced. A multistage string correction method using this file is proposed. The lower bound of computational complexity is estimated, and it is shown that a multistage method using a special type of a hierarchical file can reduce computational labor greatly. The larger the number of strings considered is, the more efficient the method becomes. The results of computer simulations on 5374 phoneme sequences using two and three stage correction methods are stated. The condition for a multistage string correction method to obtain higher correction rates than an ordinary dictionary method is included."
            },
            "slug": "A-High-Speed-String-Correction-Method-Using-a-File-Tanaka-Kojima",
            "title": {
                "fragments": [],
                "text": "A High Speed String Correction Method Using a Hierarchical File"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that a multistage method using a special type of a hierarchical file can reduce computational labor greatly and the larger the number of strings considered is, the more efficient the method becomes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013580"
                        ],
                        "name": "Q. Wang",
                        "slug": "Q.-Wang",
                        "structuredName": {
                            "firstName": "Qing",
                            "lastName": "Wang",
                            "middleNames": [
                                "Ren"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713795"
                        ],
                        "name": "C. Suen",
                        "slug": "C.-Suen",
                        "structuredName": {
                            "firstName": "Ching",
                            "lastName": "Suen",
                            "middleNames": [
                                "Yee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Suen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18964819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fca5bce860135f8a9d4ba6aaf1f594b97b5877a0",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In the tree classifier with top-down search, a global decision is made via a series of local decisions. Although this approach gains in classification efficiency, it also gives rise to error accumulation which can be very harmful when the number of classes is very large. To overcome this difficulty, a new tree classifier with the following characteristics is proposed: 1) fuzzy logic search is used to find all ``possible correct classes,'' and some similarity measures are used to determine the ``most probable class''; 2) global training is applied to generate extended terminals in order to enhance the recognition rate; 3) both the training and search algorithms have been given a lot of flexibility, to provide tradeoffs between error and rejection rates, and between the recognition rate and speed. A computer simulation of the decision trees for the recognition of 3200 Chinese character categories yielded a very high recognition rate of 99.93 percent and a very high speed of 861 samples/s, when the program was written in a high level language and run on a large multiuser time-sharing computer."
            },
            "slug": "Large-Tree-Classifier-with-Heuristic-Search-and-Wang-Suen",
            "title": {
                "fragments": [],
                "text": "Large Tree Classifier with Heuristic Search and Global Training"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new tree classifier with the following characteristics is proposed: fuzzy logic search is used to find all ``possible correct classes,'' and some similarity measures are used to determine the ``most probable class''."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144896182"
                        ],
                        "name": "B. Oommen",
                        "slug": "B.-Oommen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Oommen",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Oommen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2715321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab0e53536eb436d64032821b8aeab8160fbc5171",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Let X* be any unknown word from a finite dictionary H. Let U be any arbitrary subsequence of X*. We consider the problem of estimating X* by processing Y, which is a noisy version of U. We do this by defining the constrained edit distance between XH and Y subject to any arbitrary edit constraint involving the number and type of edit operations to be performed. An algorithm to compute this constrained edit distance has been presented. Although in general the algorithm has a cubic time complexity, within the framework of our solution the algorithm possesses a quadratic time complexity. Recognition using the constrained edit distance as a criterion demonstrates remarkable accuracy. Experimental results which involve strings of lengths between 40 and 80 and which contain an average of 26.547 errors per string demonstrate that the scheme has about 99.5 percent accuracy."
            },
            "slug": "Recognition-of-Noisy-Subsequences-Using-Constrained-Oommen",
            "title": {
                "fragments": [],
                "text": "Recognition of Noisy Subsequences Using Constrained Edit Distances"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm to compute the constrained edit distance subject to any arbitrary edit constraint involving the number and type of edit operations to be performed has been presented and demonstrates remarkable accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909274"
                        ],
                        "name": "V. S. Nalwa",
                        "slug": "V.-S.-Nalwa",
                        "structuredName": {
                            "firstName": "Vishvjit",
                            "lastName": "Nalwa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. S. Nalwa"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30768700,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "7681ad6a8b5c7ec1214fe29238f336fb5e42e008",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Results previously derived by the author are used to investigate the implication of bilateral symmetry in line drawings. It is shown that the line drawing of an orthographically protected surface of revolution exhibits bilateral symmetry about the projection of its axis of revolution irrespective of the viewing direction. Barring one exception, a bilaterally symmetric line drawing is necessarily the orthographic projection of a local surface of revolution whenever its symmetry axis continues to be the projection of a fixed line in space under perturbation of viewpoint; the axis of revolution is the invariant preimage of the symmetry axis. Various line-drawing causes are detailed which facilitate the deduction of invariant preimages of symmetry axes, and consequently of local surfaces of revolution. >"
            },
            "slug": "Line-Drawing-Interpretation:-Bilateral-Symmetry-Nalwa",
            "title": {
                "fragments": [],
                "text": "Line-Drawing Interpretation: Bilateral Symmetry"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the line drawing of an orthographically protected surface of revolution exhibits bilateral symmetry about the projection of its axis of revolution irrespective of the viewing direction."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115658132"
                        ],
                        "name": "Yujiun P. Wang",
                        "slug": "Yujiun-P.-Wang",
                        "structuredName": {
                            "firstName": "Yujiun",
                            "lastName": "Wang",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujiun P. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145820949"
                        ],
                        "name": "T. Pavlidis",
                        "slug": "T.-Pavlidis",
                        "structuredName": {
                            "firstName": "Theodosios",
                            "lastName": "Pavlidis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pavlidis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8455893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af82fc19d0f359172b7e4899535a3d7813066304",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The definition of optimal correspondent subsequence (OCS), which extends the finite alphabet editing error minimization matching to infinite alphabet penalty minimization matching, is given. The authors prove that the string distance derived from OCS is a metric. An algorithm to compute the string-to-string OCS is given. The computational complexity of OCS is analyzed. OCS is more efficient than relaxation and elastic matching for 1D problems. An algorithm combining syntactic information in template matching is given to show the ease of integrating regular grammar into the OCS technique. Since in different applications different penalty functions may be required, two of them are discussed: one pointwise and the other piecewise. The pointwise application consists of a stereo epipolar line matching problem solved by using string-to-string OCS. The feasibility of applying OCS to UPC bar-code recognition is investigated, showing the elegance of string-to-regular-expression OCS compared to the relaxation and elastic matching techniques. >"
            },
            "slug": "Optimal-Correspondence-of-String-Subsequences-Wang-Pavlidis",
            "title": {
                "fragments": [],
                "text": "Optimal Correspondence of String Subsequences"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors prove that the string distance derived from OCS is a metric and the feasibility of applying OCS to UPC bar-code recognition is investigated, showing the elegance of string-to-regular-expression OCS compared to the relaxation and elastic matching techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32098619"
                        ],
                        "name": "B. Messmer",
                        "slug": "B.-Messmer",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Messmer",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Messmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2286724,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "847e6ad384f8957922dbcc050dec724e29d80a01",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new algorithm for error-correcting subgraph isomorphism detection from a set of model graphs to an unknown input graph. The algorithm is based on a compact representation of the model graphs. This representation is derived from the set of model graphs in an off-line preprocessing step. The main advantage of the proposed representation is that common subgraphs of different model graphs are represented only once. Therefore, at run time, given an unknown input graph, the computational effort of matching the common subgraphs for each model graph onto the input graph is done only once. Consequently, the new algorithm is only sublinearly dependent on the number of model graphs. Furthermore, the new algorithm can be combined with a future cost estimation method that greatly improves its run-time performance."
            },
            "slug": "A-New-Algorithm-for-Error-Tolerant-Subgraph-Messmer-Bunke",
            "title": {
                "fragments": [],
                "text": "A New Algorithm for Error-Tolerant Subgraph Isomorphism Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new algorithm for error-correcting subgraph isomorphism detection from a set of model graphs to an unknown input graph is proposed based on a compact representation of the model graphs that can be combined with a future cost estimation method that greatly improves its run-time performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48623337"
                        ],
                        "name": "Yuhong Yu",
                        "slug": "Yuhong-Yu",
                        "structuredName": {
                            "firstName": "Yuhong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuhong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144013393"
                        ],
                        "name": "A. Samal",
                        "slug": "A.-Samal",
                        "structuredName": {
                            "firstName": "Ashok",
                            "lastName": "Samal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Samal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 62537055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27b7f011a214a90fafedda954c36b8b2ee20cabd",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for recognizing a large class of engineering drawings characterized by alternating instances of symbols and connection lines. The class includes domains such as flowcharts, logic and electrical circuits, and chemical plant diagrams. The output of the system, a netlist identifying the symbol types and interconnections, may be used for design simulation or as a compact portable representation of the drawing. The automatic recognition task is divided into two stages: 1) domain-independent rules are used to segment symbols from connection lines in the drawing image that has been thinned, vectorized, and preprocessed in routine ways; 2) a drawing understanding subsystem works in concert with a set of domain-specific matchers to classify symbols and correct errors automatically. A graphical user interface is provided to correct residual errors interactively and to log data for reporting errors objectively. The system has been tested on a database of 64 printed images drawn from text books and handbooks in different domains and scanned at 150 and 300 dpi resolution."
            },
            "slug": "A-system-for-recognizing-a-large-class-of-drawings-Yu-Samal",
            "title": {
                "fragments": [],
                "text": "A system for recognizing a large class of engineering drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A system for recognizing a large class of engineering drawings characterized by alternating instances of symbols and connection lines, which includes domains such as flowcharts, logic and electrical circuits, and chemical plant diagrams, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47469232"
                        ],
                        "name": "C. Lai",
                        "slug": "C.-Lai",
                        "structuredName": {
                            "firstName": "Chan",
                            "lastName": "Lai",
                            "middleNames": [
                                "Pyng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43429059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ccf87542d57874f7370361e798dee22be8f386f",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This correspondence presents a system for detecting dimension sets in engineering drawings that are drawn to ANSI drafting standards. A new rule-based text/graphics separation algorithm and a model-based procedure for detecting arrowheads in any orientation have been developed. Arrowhead tracking and search methods are used to extract leaders, tails, and witness lines from segmented images containing only graphics. Text blocks and feature control frames extracted from the segmented images are than associated with their corresponding leaders to obtain complete dimension sets. Experimental results are presented. >"
            },
            "slug": "Detection-of-Dimension-Sets-in-Engineering-Drawings-Lai-Kasturi",
            "title": {
                "fragments": [],
                "text": "Detection of Dimension Sets in Engineering Drawings"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A new rule-based text/graphics separation algorithm and a model-based procedure for detecting arrowheads in any orientation have been developed for detecting dimension sets in engineering drawings drawn to ANSI drafting standards."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34435085,
            "fieldsOfStudy": [],
            "id": "29a98da1ded1b7d8e849b95c0490013490b1b306",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A New Methodology for Gray-Scale Character Segmentation and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795578"
                        ],
                        "name": "T. Ho",
                        "slug": "T.-Ho",
                        "structuredName": {
                            "firstName": "Tin",
                            "lastName": "Ho",
                            "middleNames": [
                                "Kam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41999996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f4a9dbf89fc0e71c05196504af7b0649867bc5a",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Many obstacles to progress in image pattern recognition result from the fact that per-class distributions are often too irregular to be well-approximated by simple analytical functions. Simulation studies offer one way to circumvent these obstacles. We present three closely related studies of machine-printed character recognition that rely on synthetic data generated pseudo-randomly in accordance with an explicit stochastic model of document image degradations. The unusually large scale of experiments - involving several million samples that makes this methodology possible have allowed us to compute sharp estimates of the intrinsic difficulty (Bayes risk) of concrete image recognition problems, as well as the asymptotic accuracy and domain of competency of classifiers."
            },
            "slug": "Large-Scale-Simulation-Studies-in-Image-Pattern-Ho-Baird",
            "title": {
                "fragments": [],
                "text": "Large-Scale Simulation Studies in Image Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Three closely related studies of machine-printed character recognition that rely on synthetic data generated pseudo-randomly in accordance with an explicit stochastic model of document image degradations are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 98,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Twenty-Years-of-Document-Image-Analysis-in-PAMI-Nagy/ce3b569e18670f6c10e61aa9a8bda7c30fd37411?sort=total-citations"
}