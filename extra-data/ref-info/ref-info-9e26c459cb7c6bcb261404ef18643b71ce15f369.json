{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3168007"
                        ],
                        "name": "Egyul Kim",
                        "slug": "Egyul-Kim",
                        "structuredName": {
                            "firstName": "Egyul",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Egyul Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641611"
                        ],
                        "name": "Seonghun Lee",
                        "slug": "Seonghun-Lee",
                        "structuredName": {
                            "firstName": "Seonghun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seonghun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152672892"
                        ],
                        "name": "J. H. Kim",
                        "slug": "J.-H.-Kim",
                        "structuredName": {
                            "firstName": "Jin",
                            "lastName": "Kim",
                            "middleNames": [
                                "Hyung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H. Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "We adopt a color distance measure called hue, chroma, and luminance (HCL) distance (DHCL) to express color difference in HCL color space [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18084451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "736cb6c7c7ba99cb61c4bf6754ede65d7a6f3f5c",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Robust extraction of text from scene images is essential for successful scene text recognition. Scene images usually have non-uniform illumination, complex background, and existence of text-like objects. The common assumption of a homogeneous text region on a nearly uniform background cannot be maintained in real applications. We proposed a text extraction method that utilizes user's hint on the location of the text within the image. A resizable square rim in the viewfinder of the mobile camera, referred to here as a 'focus', is the interface used to help the user indicate the target text. With the hint from the focus, the color of the target text is easily estimated by clustering colors only within the focused section. Image binarization with the estimated color is performed to extract connected components. After obtaining the text region within the focused section, the text region is expanded iteratively by searching neighboring regions with the updated text color. Such an iterative method would prevent the problem of one text region being separated into more than one component due to non-uniform illumination and reflection. A text verification process is conducted on the extracted components to determine the true text region. It is demonstrated that the proposed method achieved high accuracy of text extraction for moderately difficult examples from the ICDAR 2003 database."
            },
            "slug": "Scene-Text-Extraction-Using-Focus-of-Mobile-Camera-Kim-Lee",
            "title": {
                "fragments": [],
                "text": "Scene Text Extraction Using Focus of Mobile Camera"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A text extraction method that utilizes user's hint on the location of the text within the image to achieve high accuracy of text extraction for moderately difficult examples from the ICDAR 2003 database."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108641611"
                        ],
                        "name": "Seonghun Lee",
                        "slug": "Seonghun-Lee",
                        "structuredName": {
                            "firstName": "Seonghun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seonghun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2875555"
                        ],
                        "name": "Jae-Hyun Seok",
                        "slug": "Jae-Hyun-Seok",
                        "structuredName": {
                            "firstName": "Jae-Hyun",
                            "lastName": "Seok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jae-Hyun Seok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48327771"
                        ],
                        "name": "Kyungmin Min",
                        "slug": "Kyungmin-Min",
                        "structuredName": {
                            "firstName": "Kyungmin",
                            "lastName": "Min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyungmin Min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52289773"
                        ],
                        "name": "Jinhyung Kim",
                        "slug": "Jinhyung-Kim",
                        "structuredName": {
                            "firstName": "Jinhyung",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhyung Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "The features of the components such as their locations, sizes, and shapes for the one-node potential and two-node potential are the same as those used in the our previous system [6]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 11643583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d4f23bda14837177c2b14862a0be4960dd16fce",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Robust extraction of text from scene images is essential for successful scene text recognition. Scene images usually have non- uniform illumination, complex background, and text-like objects. In this paper, we propose a text extraction algorithm by combining the adaptive binarization and perceptual color clustering method. Adaptive binarization method can handle gradual illumination changes on character regions, so it can extract whole character regions even though shadows and/or light variations affect the image quality. However, image binarization on gray-scale images cannot distinguish different color components having the same luminance. Perceptual color clustering method complementary can extract text regions which have similar color distances, so that it can prevent the problem of the binarization method. Text verification based on local information of a single component and global relationship between multiple components is used to determine the true text components. It is demonstrated that the proposed method achieved reasonabe accuracy of the text extraction for the moderately difficult examples from the ICDAR 2003 database."
            },
            "slug": "Scene-Text-Extraction-Using-Image-Intensity-and-Lee-Seok",
            "title": {
                "fragments": [],
                "text": "Scene Text Extraction Using Image Intensity and Color Information"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a text extraction algorithm by combining the adaptive binarization and perceptual color clustering method, and demonstrates that the proposed method achieved reasonabe accuracy of the text extraction for the moderately difficult examples from the ICDAR 2003 database."
            },
            "venue": {
                "fragments": [],
                "text": "2009 Chinese Conference on Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109191421"
                        ],
                        "name": "Jonghyun Park",
                        "slug": "Jonghyun-Park",
                        "structuredName": {
                            "firstName": "Jonghyun",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonghyun Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2147746"
                        ],
                        "name": "Soonyoung Park",
                        "slug": "Soonyoung-Park",
                        "structuredName": {
                            "firstName": "Soonyoung",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soonyoung Park"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "Determining optimal K value is still an open problem [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5350933,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ea93f30d8cc836a6b4a1b14d804985eb630c4e6",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an approach to the segmentation and detection of text region from natural scenes. Clustering-based natural scene segmentation is first considered based on the histogram of hue and intensity components separately. Secondly, text region extraction method is proposed by using wavelet-based features for representing the input patterns and neural network architecture for the classifier. The effectiveness and reliability of the proposed method is demonstrated through various natural scene images. The experimental results have proven that the proposed method is effective."
            },
            "slug": "Detection-of-Text-Region-and-Segmentation-from-Park-Park",
            "title": {
                "fragments": [],
                "text": "Detection of Text Region and Segmentation from Natural Scene Images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents an approach to the segmentation and detection of text region from natural scenes by using wavelet-based features for representing the input patterns and neural network architecture for the classifier."
            },
            "venue": {
                "fragments": [],
                "text": "ISVC"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331461"
                        ],
                        "name": "S. Hanif",
                        "slug": "S.-Hanif",
                        "structuredName": {
                            "firstName": "Shehzad",
                            "lastName": "Hanif",
                            "middleNames": [
                                "Muhammad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanif"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554802"
                        ],
                        "name": "L. Prevost",
                        "slug": "L.-Prevost",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Prevost",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Prevost"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29439090"
                        ],
                        "name": "Pablo Negri",
                        "slug": "Pablo-Negri",
                        "structuredName": {
                            "firstName": "Pablo",
                            "lastName": "Negri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pablo Negri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "The text localizer makes determinations based on the combination of three texture features of multi-scale segments: mean difference, standard deviation, and histogram of gradient [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15480487,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dc8be7a356184357178a03fdf03a71e710f52b3",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a text detection and localization method. Our detection technique is based on a cascade of boosted ensemble and localizer uses standard image processing techniques. We propose a small set of features (39 in total) capable of detecting various type of text in grey level natural scene images. Two weak learners, linear discriminant function and log likelihood-ratio test under gaussian assumption, are evaluated. Single features and combination of features are used to form weak classifiers. The proposed scheme is evaluated on ICDAR 2003 robust reading and text locating database. The results are encouraging and the detector can process an images of 640 times 480 pixels in less than 2 seconds."
            },
            "slug": "A-cascade-detector-for-text-detection-in-natural-Hanif-Prevost",
            "title": {
                "fragments": [],
                "text": "A cascade detector for text detection in natural scene images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A small set of features capable of detecting various type of text in grey level natural scene images is proposed, and the detector can process an images of 640 times 480 pixels in less than 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "2008 19th International Conference on Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109552014"
                        ],
                        "name": "Dong-Qing Zhang",
                        "slug": "Dong-Qing-Zhang",
                        "structuredName": {
                            "firstName": "Dong-Qing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong-Qing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "Compared to the higher-order MRF model [10], our proposed method considers the geometric relationships between up to four components while maintaining low computational complexity of the lower-order MRF framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14341205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df6e78f220d598fb961aab165a68697f67be7d30",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting text in natural 3D scenes is a challenging problem due to background clutter and photometric/gemetric variations of scene text. Most prior systems adopt approaches based on deterministic rules, lacking a systematic and scalable framework. In this paper, we present a parts-based approach for 3D scene text detection using a higher-order MRF model. The higher-order structure is used to capture the spatial-feature relations among multiple parts in scene text. The use of higher-order structure and the feature-dependent potential function represents significant departure from the conventional pairwise MRF, which has been successfully applied in several low-level applications. We further develop a variational approximation method, in the form of belief propagation, for inference in the higher-order model. Our experiments using the ICDAR'03 benchmark showed promising results in detecting scene text with significant geometric variations, background clutter on planar surfaces or non-planar surfaces with limited angles."
            },
            "slug": "Learning-to-Detect-Scene-Text-Using-a-Higher-Order-Zhang-Chang",
            "title": {
                "fragments": [],
                "text": "Learning to Detect Scene Text Using a Higher-Order MRF with Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A parts-based approach for 3D scene text detection using a higher-order MRF model that captures the spatial-feature relations among multiple parts in scene text and develops a variational approximation method, in the form of belief propagation, for inference in the higher- order model."
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40019398"
                        ],
                        "name": "T. Kasar",
                        "slug": "T.-Kasar",
                        "structuredName": {
                            "firstName": "Thotreingam",
                            "lastName": "Kasar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kasar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145677714"
                        ],
                        "name": "A. Ramakrishnan",
                        "slug": "A.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ramakrishnan",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ramakrishnan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Lists of two-color pairs in edge constraints are obtained from the normal vectors of edge contour pixels [4] (Figure 1(c))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13832509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89ca6d40831343c9a77b98a05d22785b080a2565",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes COCOCLUST, a contour-based color clustering method which robustly segments and binarizes colored text from complex images. Rather than operating on the entire image, a \u2018small\u2019 representative set of color pixels is first identified using the contour information. The method involves the following steps: (i) Identification of prototype colors (ii) A one-pass algorithm to identify color clusters that serve as seeds for the refining step using kmeans clustering (iii) Assignment of pixels in the original image to the nearest color cluster (iv) Identification of potential candidate text regions in individual color layer and (v) Adaptive binarization. We propose a robust binarization technique to threshold the identified text regions, taking into account the presence of inverse texts, such that the output image always has black text on a white background. Experiments on several complex images having large variations in font, size, color, orientation and script illustrate the robustness of the method."
            },
            "slug": "COCOCLUST-:-Contour-based-Color-Clustering-for-of-Kasar-Ramakrishnan",
            "title": {
                "fragments": [],
                "text": "COCOCLUST : Contour-based Color Clustering for Robust Binarization of Colored Text"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A robust binarization technique is proposed to threshold the identified text regions, taking into account the presence of inverse texts, such that the output image always has black text on a white background."
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16388265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "515966ebc3adec9a7740526fbee997937aaa234f",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A variety of computer vision problems can be optimally posed as Bayesian labeling in which the solution of a problem is defined as the maximum a posteriori (MAP) probability estimate of the true labeling. The posterior probability is usually derived from a prior model and a likelihood model. The latter relates to how data is observed and is problem domain dependent. The former depends on how various prior constraints are expressed. Markov Random Field Models (MRF) theory is a tool to encode contextual constraints into the prior probability. This paper presents a unified approach for MRF modeling in low and high level computer vision. The unification is made possible due to a recent advance in MRF modeling for high level object recognition. Such unification provides a systematic approach for vision modeling based on sound mathematical principles."
            },
            "slug": "Markov-Random-Field-Models-in-Computer-Vision-Li",
            "title": {
                "fragments": [],
                "text": "Markov Random Field Models in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A unified approach for Markov Random Field Models modeling in low and high level computer vision is presented, made possible due to a recent advance in MRF modeling for high level object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47695762"
                        ],
                        "name": "M. Bilenko",
                        "slug": "M.-Bilenko",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Bilenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bilenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40632403"
                        ],
                        "name": "Sugato Basu",
                        "slug": "Sugato-Basu",
                        "structuredName": {
                            "firstName": "Sugato",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sugato Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "The formula for CVQE is given below:\nCVQE j = 1 2 { K\u2211 j=1 \u2211 s\u2208C j\n\u03c9iDHCL(c\u0304 j, s) +\u2211 (si,s j)\u2208EC DHCL(c\u0304y(xi), c\u0304\u2217i j)\u2206(y(si), y(s j))},\nDHCL(p, q) =0.1(lp \u2212 lq)2 + {0.2 + (hp \u2212 hq)} \u2217 ACH{c2p + c2q \u2212 2cpcq cos(hp \u2212 hq)},\n(1)\nWe adopt a color distance measure called hue, chroma, and luminance (HCL) distance (DHCL) to express color difference in HCL color space [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 126
                            }
                        ],
                        "text": "Constraint K-means clustering is regarded as finding the solution minimizing the constrained vector quantization error (CVQE) [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "By iteratively updating centroids of clusters to minimize CVQE, K dominant colors are obtained."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16157513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "197e3a315c57c9278876d95b7e522700aa112886",
            "isKey": true,
            "numCitedBy": 908,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Semi-supervised clustering employs a small amount of labeled data to aid unsupervised learning. Previous work in the area has utilized supervised data in one of two approaches: 1) constraint-based methods that guide the clustering algorithm towards a better grouping of the data, and 2) distance-function learning methods that adapt the underlying similarity metric used by the clustering algorithm. This paper provides new methods for the two approaches as well as presents a new semi-supervised clustering algorithm that integrates both of these techniques in a uniform, principled framework. Experimental results demonstrate that the unified approach produces better clusters than both individual approaches as well as previously proposed semi-supervised clustering algorithms."
            },
            "slug": "Integrating-constraints-and-metric-learning-in-Bilenko-Basu",
            "title": {
                "fragments": [],
                "text": "Integrating constraints and metric learning in semi-supervised clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results demonstrate that the unified approach produces better clusters than both individual approaches as well as previously proposed semi-supervised clustering algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 50
                            }
                        ],
                        "text": "By using the collinearity weighting scheme in the Belief Propagation approach, the influence from aligned neighbors is stronger than that from non-aligned neighbors in determining the label of a component."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "The probability of a configuration of the components in the MRF model can be calculated by the Belief Propagation [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121439686,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05a281df21f4cb2b01e7751c50a4cba3ae0b992f",
            "isKey": false,
            "numCitedBy": 1568,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "\"Inference\" problems arise in statistical physics, computer vision, error-correcting coding theory, and AI. We explain the principles behind the belief propagation (BP) algorithm, which is an efficient way to solve inference problems based on passing local messages. We develop a unified approach, with examples, notation, and graphical models borrowed from the relevant disciplines.We explain the close connection between the BP algorithm and the Bethe approximation of statistical physics. In particular, we show that BP can only converge to a fixed point that is also a stationary point of the Bethe approximation to the free energy. This result helps explaining the successes of the BP algorithm and enables connections to be made with variational approaches to approximate inference.The connection of BP with the Bethe approximation also suggests a way to construct new message-passing algorithms based on improvements to Bethe's approximation introduced Kikuchi and others. The new generalized belief propagation (GBP) algorithms are significantly more accurate than ordinary BP for some problems. We illustrate how to construct GBP algorithms with a detailed example."
            },
            "slug": "Understanding-belief-propagation-and-its-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Understanding belief propagation and its generalizations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that BP can only converge to a fixed point that is also a stationary point of the Bethe approximation to the free energy, which enables connections to be made with variational approaches to approximate inference."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959271"
                        ],
                        "name": "J. Hartigan",
                        "slug": "J.-Hartigan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hartigan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hartigan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52043702"
                        ],
                        "name": "M. A. Wong",
                        "slug": "M.-A.-Wong",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Wong",
                            "middleNames": [
                                "Anthony."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Wong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "A K-means clustering algorithm [3] is used to find the most dominant K colors from the image and assign each pixel in the image into one of the K colors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53880671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e99603b5b524485bcf1afb2f01acadc34dfb033c",
            "isKey": false,
            "numCitedBy": 9090,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-k-means-clustering-algorithm-Hartigan-Wong",
            "title": {
                "fragments": [],
                "text": "A k-means clustering algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "The Markov Random Field (MRF) model provides a convenient way to model spatial relationships among components as an undirected graphical model [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Markov random field models in computer"
            },
            "venue": {
                "fragments": [],
                "text": "vision. LNCS,"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 3,
            "methodology": 6,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Scene-Text-Extraction-with-Edge-Constraint-and-Text-Lee-Cho/9e26c459cb7c6bcb261404ef18643b71ce15f369?sort=total-citations"
}