{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 163
                            }
                        ],
                        "text": "The resulting naive Bayes parameter estimates often give significantly improved classification accuracy on the test set when the pool of labeled examples is small [Nigam et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 102
                            }
                        ],
                        "text": "In previous work, we show that EM with unlabeled data reduces text classification error by one-third [Nigam et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 18
                            }
                        ],
                        "text": "In previous work [Nigam et al. 1998] we show that combining the evidence of labeled and unlabeled documents via EM can reduce text classification error by one-third."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 164
                            }
                        ],
                        "text": "The resulting naive Bayes parameter estimates often give significantly improved classification accuracy on the test set when the pool of labeled examples is small [Nigam et al. 1998].1 This use of EM is a special case of a more general missing values formulation [Ghahramani & Jordan 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 5
                            }
                        ],
                        "text": "See [Nigam et al. 1998] for more details."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1460876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63287d3220fe96d5cbf73067545abbb88cc180a6",
            "isKey": false,
            "numCitedBy": 426,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "In many important text classification problems, acquiring class labels for training documents is costly, while gathering large quantities of unlabeled data is cheap. This paper shows that the accuracy of text classifiers trained with a small number of labeled documents can be improved by augmenting this small training set with a large pool of unlabeled documents. We present a theoretical argument showing that, under common assumptions, unlabeled data contain information about the target function. We then introduce an algorithm for learning from labeled and unlabeled text based on the combination of Expectation-Maximization with a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents; it then trains a new classifier using the labels for all the documents, and iterates to convergence. Experimental results, obtained using text from three different realworld tasks, show that the use of unlabeled data reduces classification error by up to 33%."
            },
            "slug": "Learning-to-Classify-Text-from-Labeled-and-Nigam-McCallum",
            "title": {
                "fragments": [],
                "text": "Learning to Classify Text from Labeled and Unlabeled Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the accuracy of text classifiers trained with a small number of labeled documents can be improved by augmenting this small training set with a large pool of unlabeled documents, and an algorithm is introduced based on the combination of Expectation-Maximization with a naive Bayes classifier."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2255318"
                        ],
                        "name": "R. Liere",
                        "slug": "R.-Liere",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Liere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Liere"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729906"
                        ],
                        "name": "Prasad Tadepalli",
                        "slug": "Prasad-Tadepalli",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Tadepalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Tadepalli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 48
                            }
                        ],
                        "text": "Following several other studies [Joachims 1998; Liere & Tadepalli 1997] we build binary classifiers for each of the 10 most populous classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "Some previous applications of QBC [Dagan & Engelson 1995; Liere & Tadepalli 1997] use a simulated stream of unlabeled documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 101
                            }
                        ],
                        "text": "In comparison to previous active learning studies in text classification domains [Lewis & Gale 1994; Liere & Tadepalli 1997], the magnitude of our classification accuracy increase is relatively modest."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 144
                            }
                        ],
                        "text": "\u2026in which queries must be generated [Cohn 1994], and previous work in which the unlabeled data is available as a stream [Dagan & Engelson 1995; Liere & Tadepalli 1997; Freund et al. 1997], our assumption about the availability of a pool of unlabeled data makes the improvements to active\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7530337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80ef14d2a1b8c7efbf45bedae9d001fe5446c7de",
            "isKey": true,
            "numCitedBy": 183,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real-world domains, supervised learning requires a large number of training examples. In this paper, we describe an active learning method that uses a committee of learners to reduce the number of training examples required for learning. Our approach is similar to the Query by Committee framework, where disagreement among the committee members on the predicted label for the input part of the example is used to signal the need for knowing the actual value of the label. Our experiments are conducted in the text categorization domain, which is characterized by a large number of features, many of which are irrelevant. We report here on experiments using a committee of Winnowbased learners and demonstrate that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude. 1. Hntroduction"
            },
            "slug": "Active-Learning-with-Committees-for-Text-Liere-Tadepalli",
            "title": {
                "fragments": [],
                "text": "Active Learning with Committees for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper reports on experiments using a committee of Winnowbased learners and demonstrates that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 57
                            }
                        ],
                        "text": "Several previous implementations [Dagan & Engelson 1995; Lewis & Gale 1994; Lewis 1995] suppose that the learner is provided with a collection of labeled examples at the beginning of active learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "Lewis and Gale examine uncertainty sampling and relevance sampling in a pool-based setting [Lewis & Gale 1994; Lewis 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "In comparison to previous active learning studies in text classification domains [Lewis & Gale 1994; Liere & Tadepalli 1997], the magnitude of our classification accuracy increase is relatively modest."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 915058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5194b668c67aa83c037e71599a087f63c98eb713",
            "isKey": false,
            "numCitedBy": 2405,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "slug": "A-sequential-algorithm-for-training-text-Lewis-Gale",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task and reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144628595"
                        ],
                        "name": "S. Argamon",
                        "slug": "S.-Argamon",
                        "structuredName": {
                            "firstName": "Shlomo",
                            "lastName": "Argamon",
                            "middleNames": [
                                "Engelson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Argamon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 38
                            }
                        ],
                        "text": "The previously employed vote entropy [Dagan & Engelson 1995] is the entropy of the class label distribution resulting from having each committee member \u201cvote\u201d with probability mass 1/k for its winning class."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 35
                            }
                        ],
                        "text": "Some previous applications of QBC [Dagan & Engelson 1995; Liere & Tadepalli 1997] use a simulated stream of unlabeled documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 55
                            }
                        ],
                        "text": "In contrast to earlier work on part-of-speech tagging [Dagan & Engelson 1995], vote entropy does not perform well on document classification."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 34
                            }
                        ],
                        "text": "Several previous implementations [Dagan & Engelson 1995; Lewis & Gale 1994; Lewis 1995] suppose that the learner is provided with a collection of labeled examples at the beginning of active learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 136
                            }
                        ],
                        "text": "Unlike settings in which queries must be generated [Cohn 1994], and previous work in which the unlabeled data is available as a stream [Dagan & Engelson 1995; Liere & Tadepalli 1997; Freund et al. 1997], our assumption about the availability of a pool of unlabeled data makes the improvements to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17288818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f78d6f79b3ef103cb2d8d170632eb74d9496412",
            "isKey": true,
            "numCitedBy": 501,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Committee-Based-Sampling-For-Training-Probabilistic-Dagan-Argamon",
            "title": {
                "fragments": [],
                "text": "Committee-Based Sampling For Training Probabilistic Classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 76
                            }
                        ],
                        "text": "Several previous implementations [Dagan & Engelson 1995; Lewis & Gale 1994; Lewis 1995] suppose that the learner is provided with a collection of labeled examples at the beginning of active learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 111
                            }
                        ],
                        "text": "Lewis and Gale examine uncertainty sampling and relevance sampling in a pool-based setting [Lewis & Gale 1994; Lewis 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15704538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33c1f29dbc73cc4d0f787d6b048b465649b2d92b",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "At ACM SIGIR '94, I compared the effectiveness of uncertainty sampling with that of random sampling and relevance sampling in choosing training data for a text categorization data set [1]. (Relevance sampling is the application of relevance feedback [3] to producing a training sample.) I have discovered a bug in my experimental software which caused the relevance sampling results reported in the SIGIR '94 paper to be incorrect. (The uncertainty sampling and random sampling results in that paper were correct.) I have since fixed the bug and rerun the experiments. This note presents the corrected results, along with additional data supporting the original claim that uncertainty sampling has an advantage over relevance sampling in most training situations."
            },
            "slug": "A-sequential-algorithm-for-training-text-and-data-Lewis",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training text classifiers: corrigendum and additional data"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A bug in my experimental software caused the relevance sampling results reported in the SIGIR '94 paper to be incorrect, and this note presents the corrected results, along with additional data supporting the original claim that uncertainty sampling has an advantage over relevance sampling in most training situations."
            },
            "venue": {
                "fragments": [],
                "text": "SIGF"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697855"
                        ],
                        "name": "M. Ringuette",
                        "slug": "M.-Ringuette",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Ringuette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ringuette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 175
                            }
                        ],
                        "text": "Note that our assumptions about the generation of text documents are all violated in practice, and yet empirically, naive Bayes does a good job of classifying text documents [Lewis & Ringuette 1994; Craven et al. 1998; Joachims 1997]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16894634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "isKey": false,
            "numCitedBy": 745,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the use of inductive learning to categorize natural language documents into predeened content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it diicult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classiier and a decision tree learning algorithm on two text categorization data sets. We nd that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial preeltering of features, connrming the results found by Almuallim and Dietterich on artiicial data sets. We also demonstrate the impact of the time-varying nature of category deenitions."
            },
            "slug": "A-comparison-of-two-learning-algorithms-for-text-Lewis-Ringuette",
            "title": {
                "fragments": [],
                "text": "A comparison of two learning algorithms for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives, and the stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145780619"
                        ],
                        "name": "David J. Miller",
                        "slug": "David-J.-Miller",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Miller",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2309473"
                        ],
                        "name": "H. S. Uyar",
                        "slug": "H.-S.-Uyar",
                        "structuredName": {
                            "firstName": "Hasan",
                            "lastName": "Uyar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. S. Uyar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 136
                            }
                        ],
                        "text": "Two other studies have used EM to combine labeled and unlabeled data without active learning for classification, but on non-text tasks [Miller & Uyar 1997; Shahshahani & Landgrebe 1994]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17425751,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c608ec27a937361122d178b38b6b7387440b58eb",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We address statistical classifier design given a mixed training set consisting of a small labelled feature set and a (generally larger) set of unlabelled features. This situation arises, e.g., for medical images, where although training features may be plentiful, expensive expertise is required to extract their class labels. We propose a classifier structure and learning algorithm that make effective use of unlabelled data to improve performance. The learning is based on maximization of the total data likelihood, i.e. over both the labelled and unlabelled data subsets. Two distinct EM learning algorithms are proposed, differing in the EM formalism applied for unlabelled data. The classifier, based on a joint probability model for features and labels, is a \"mixture of experts\" structure that is equivalent to the radial basis function (RBF) classifier, but unlike RBFs, is amenable to likelihood-based training. The scope of application for the new method is greatly extended by the observation that test data, or any new data to classify, is in fact additional, unlabelled data - thus, a combined learning/classification operation - much akin to what is done in image segmentation - can be invoked whenever there is new data to classify. Experiments with data sets from the UC Irvine database demonstrate that the new learning algorithms and structure achieve substantial performance gains over alternative approaches."
            },
            "slug": "A-Mixture-of-Experts-Classifier-with-Learning-Based-Miller-Uyar",
            "title": {
                "fragments": [],
                "text": "A Mixture of Experts Classifier with Learning Based on Both Labelled and Unlabelled Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A classifier structure and learning algorithm that make effective use of unlabelled data to improve performance and is a \"mixture of experts\" structure that is equivalent to the radial basis function (RBF) classifier, but unlike RBFs, is amenable to likelihood-based training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 33
                            }
                        ],
                        "text": "Following several other studies [Joachims 1998; Liere & Tadepalli 1997] we build binary classifiers for each of the 10 most populous classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 152
                            }
                        ],
                        "text": "Results are reported on the complete test set as precision-recall breakeven points, a standard information retrieval measure for binary classification [Joachims 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": false,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 220
                            }
                        ],
                        "text": "Also note that our formulation of naive Bayes assumes a multinomial event model for documents; this generally produces better text classification accuracy than another formulation that assumes a multi-variate Bernoulli [McCallum & Nigam 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7311285,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04ce064505b1635583fa0d9cc07cac7e9ea993cc",
            "isKey": false,
            "numCitedBy": 3834,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in text classification has used two different first-order probabilistic models for classification, both of which make the naive Bayes assumption. Some use a multi-variate Bernoulli model, that is, a Bayesian Network with no dependencies between words and binary word features (e.g. Larkey and Croft 1996; Koller and Sahami 1997). Others use a multinomial model, that is, a uni-gram language model with integer word counts (e.g. Lewis and Gale 1994; Mitchell 1997). This paper aims to clarify the confusion by describing the differences and details of these two models, and by empirically comparing their classification performance on five text corpora. We find that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi-variate Bernoulli model at any vocabulary size."
            },
            "slug": "A-comparison-of-event-models-for-naive-bayes-text-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "A comparison of event models for naive bayes text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is found that the multi-variate Bernoulli performs well with small vocabulary sizes, but that the multinomial performs usually performs even better at larger vocabulary sizes--providing on average a 27% reduction in error over the multi -variateBernoulli model at any vocabulary size."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI 1998"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144557047"
                        ],
                        "name": "M. Craven",
                        "slug": "M.-Craven",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Craven",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Craven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2922396"
                        ],
                        "name": "Dan DiPasquo",
                        "slug": "Dan-DiPasquo",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "DiPasquo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan DiPasquo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682522"
                        ],
                        "name": "Se\u00e1n Slattery",
                        "slug": "Se\u00e1n-Slattery",
                        "structuredName": {
                            "firstName": "Se\u00e1n",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Se\u00e1n Slattery"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 199
                            }
                        ],
                        "text": "Note that our assumptions about the generation of text documents are all violated in practice, and yet empirically, naive Bayes does a good job of classifying text documents [Lewis & Ringuette 1994; Craven et al. 1998; Joachims 1997]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2312137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8446830f3c05b97c4d12a0751c022d1ae6a5115b",
            "isKey": false,
            "numCitedBy": 800,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "The World Wide Web is a vast source of information accessible to computers, but understandable only to humans. The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web. Such a knowledge base would enable much more effective retrieval of Web information, and promote new uses of the Web to support knowledge-based inference and problem solving. Our approach is to develop a trainable information extraction system that takes two inputs: an ontology defining the classes and relations of interest, and a set of training data consisting of labeled regions of hypertext representing instances of these classes and relations. Given these inputs, the system learns to extract information from other pages and hyperlinks on the Web. This paper describes our general approach, several machine learning algorithms for this task, and promising initial results with a prototype system."
            },
            "slug": "Learning-to-Extract-Symbolic-Knowledge-from-the-Web-Craven-DiPasquo",
            "title": {
                "fragments": [],
                "text": "Learning to Extract Symbolic Knowledge from the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "The goal of the research described here is to automatically create a computer understandable world wide knowledge base whose content mirrors that of the World Wide Web, and several machine learning algorithms for this task are described."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209630"
                        ],
                        "name": "Behzad M. Shahshahani",
                        "slug": "Behzad-M.-Shahshahani",
                        "structuredName": {
                            "firstName": "Behzad",
                            "lastName": "Shahshahani",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Behzad M. Shahshahani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773449"
                        ],
                        "name": "D. Landgrebe",
                        "slug": "D.-Landgrebe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Landgrebe",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Landgrebe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 156
                            }
                        ],
                        "text": "Two other studies have used EM to combine labeled and unlabeled data without active learning for classification, but on non-text tasks [Miller & Uyar 1997; Shahshahani & Landgrebe 1994]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11081015,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "334867ed99a0af07d8a53dae4f7fdeffffdecc09",
            "isKey": false,
            "numCitedBy": 581,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the use of unlabeled sam- ples in reducing the problem of small training sample size that can severely affect the recognition rate of classifiers when the dimensionality of the multispectral data is high. We show that by using additional unlabeled samples that are available at no extra cost, the performance may be improved, and therefore the Hughes phenomenon can be mitigated. Furthermore, by ex- periments, we show that by using additional unlabeled samples more representative estimates can be obtained. We also pro- pose a semiparametric method for incorporating the training (Le., labeled) and unlabeled samples simultaneously into the parameter estimation process."
            },
            "slug": "The-effect-of-unlabeled-samples-in-reducing-the-and-Shahshahani-Landgrebe",
            "title": {
                "fragments": [],
                "text": "The effect of unlabeled samples in reducing the small sample size problem and mitigating the Hughes phenomenon"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "By using additional unlabeled samples that are available at no extra cost, the performance may be improved, and therefore the Hughes phenomenon can be mitigated and therefore more representative estimates can be obtained."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Geosci. Remote. Sens."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 219
                            }
                        ],
                        "text": "Note that our assumptions about the generation of text documents are all violated in practice, and yet empirically, naive Bayes does a good job of classifying text documents [Lewis & Ringuette 1994; Craven et al. 1998; Joachims 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 129
                            }
                        ],
                        "text": "The Newsgroups data set, collected by Ken Lang, contains about 20,000 articles evenly divided among 20 UseNet discussion groups [Joachims 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 97
                            }
                        ],
                        "text": "Our parametric model is naive Bayes, which is based on commonly used assumptions [Friedman 1997; Joachims 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5842708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "094fc15bc058b0d62a661a1460885a9490bdb1bd",
            "isKey": false,
            "numCitedBy": 1533,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A probabilistic analysis of the Rocchio relevance feedback algorithm, one of the most popular learning methods from information retrieval, is presented in a text categorization framework. The analysis results in a probabilistic version of the Rocchio classifier and offers an explanation for the TFIDF word weighting heuristic. The Rocchio classifier, its probabilistic variant and a standard naive Bayes classifier are compared on three text categorization tasks. The results suggest that the probabilistic algorithms are preferable to the heuristic Rocchio classifier."
            },
            "slug": "A-Probabilistic-Analysis-of-the-Rocchio-Algorithm-Joachims",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A Probabilistic analysis of the Rocchio relevance feedback algorithm, one of the most popular learning methods from information retrieval, is presented in a text categorization framework and suggests that the probabilistic algorithms are preferable to the heuristic Rocchio classifier."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 264
                            }
                        ],
                        "text": "The resulting naive Bayes parameter estimates often give significantly improved classification accuracy on the test set when the pool of labeled examples is small [Nigam et al. 1998].1 This use of EM is a special case of a more general missing values formulation [Ghahramani & Jordan 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18086786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5db7dc2239f820eae498b07a955f31b3d113179f",
            "isKey": false,
            "numCitedBy": 634,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Real-world learning tasks may involve high-dimensional data sets with arbitrary patterns of missing data. In this paper we present a framework based on maximum likelihood density estimation for learning from such data set.s. We use mixture models for the density estimates and make two distinct appeals to the Expectation-Maximization (EM) principle (Dempster et al., 1977) in deriving a learning algorithm--EM is used both for the estimation of mixture components and for coping with missing data. The resulting algorithm is applicable to a wide range of supervised as well as unsupervised learning problems. Results from a classification benchmark--the iris data set--are presented."
            },
            "slug": "Supervised-learning-from-incomplete-data-via-an-EM-Ghahramani-Jordan",
            "title": {
                "fragments": [],
                "text": "Supervised learning from incomplete data via an EM approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A framework based on maximum likelihood density estimation for learning from high-dimensional data sets with arbitrary patterns of missing data is presented and results from a classification benchmark--the iris data set--are presented."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777660"
                        ],
                        "name": "Naftali Tishby",
                        "slug": "Naftali-Tishby",
                        "structuredName": {
                            "firstName": "Naftali",
                            "lastName": "Tishby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naftali Tishby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145810617"
                        ],
                        "name": "Lillian Lee",
                        "slug": "Lillian-Lee",
                        "structuredName": {
                            "firstName": "Lillian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lillian Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6713452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5eb328cf7e94995199e4c82a1f4d0696430a80b5",
            "isKey": false,
            "numCitedBy": 1193,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and evaluate experimentally a method for clustering words according to their distribution in particular syntactic contexts. Words are represented by the relative frequency distributions of contexts in which they appear, and relative entropy between those distributions is used as the similarity measure for clustering. Clusters are represented by average context distributions derived from the given words according to their probabilities of cluster membership. In many cases, the clusters can be thought of as encoding coarse sense distinctions. Deterministic annealing is used to find lowest distortion sets of clusters: as the annealing parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data. Clusters are used as the basis for class models of word coocurrence, and the models evaluated with respect to held-out test data."
            },
            "slug": "Distributional-Clustering-of-English-Words-Pereira-Tishby",
            "title": {
                "fragments": [],
                "text": "Distributional Clustering of English Words"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deterministic annealing is used to find lowest distortion sets of clusters: as the annealed parameter increases, existing clusters become unstable and subdivide, yielding a hierarchical \"soft\" clustering of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 52
                            }
                        ],
                        "text": "Unlike settings in which queries must be generated [Cohn 1994], and previous work in which the unlabeled data is available as a stream [Dagan & Engelson 1995; Liere & Tadepalli 1997; Freund et al. 1997], our assumption about the availability of a pool of unlabeled data makes the improvements to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 51
                            }
                        ],
                        "text": "Unlike settings in which queries must be generated [Cohn 1994], and previous work in which the unlabeled data is available as a stream [Dagan & Engelson 1995; Liere & Tadepalli 1997; Freund et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6170752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08627b368e6b7d142cfcece74d52d21d48cc64a6",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Network-Exploration-Using-Optimal-Experiment-Cohn",
            "title": {
                "fragments": [],
                "text": "Neural Network Exploration Using Optimal Experiment Design"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976268"
                        ],
                        "name": "D. Cohn",
                        "slug": "D.-Cohn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cohn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9242771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1150f9289c6151506e3f7cf0e6ebbcfd49f1dace",
            "isKey": false,
            "numCitedBy": 2057,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "For many types of learners one can compute the statistically \"optimal\" way to select data. We review how these techniques have been used with feedforward neural networks [MacKay, 1992; Cohn, 1994]. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate."
            },
            "slug": "Active-Learning-with-Statistical-Models-Cohn-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Active Learning with Statistical Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work shows how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143188751"
                        ],
                        "name": "H. Johnson",
                        "slug": "H.-Johnson",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Johnson",
                            "middleNames": [
                                "Louise"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 220
                            }
                        ],
                        "text": "Also note that our formulation of naive Bayes assumes a multinomial event model for documents; this generally produces better text classification accuracy than another formulation that assumes a multi-variate Bernoulli [McCallum & Nigam 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 116096508,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "78f749705501e89fd953e9683f7cee464caca687",
            "isKey": false,
            "numCitedBy": 4866,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Turkish Ministry of National Education established special field competencies for secondary education teachers in 2011. Special field competences are field-specific knowledge, skills, and attitudes necessary for effective and productive conduct of teaching profession. The aim of the present article is to compare the opinions of Geography Education Department, and Geography Department students regarding the field knowledge, one of the special field competences of geography teaching. The study was based on survey method aimed to reveal an existing situation. However, face-to-face interviews were conducted with 20 students from the Faculty of Education in order to find the origin of results. The study was performed in the spring semester of 2014-2015 academic year with a total of 160 students from 3rd, 4th, and 5th grades of Geography Education Department and 3rd and 4th grades of Geography Department. Significant differences between the opinions of students were compared by ChiSquare analysis by their educational programs. The expressions of Faculty of Education students suggested that they were competent in 7 out of 13 fields, creating a significant difference. There was no significant difference in the opinions of Geography Department students regarding the geography field competences."
            },
            "slug": "A-Comparison-of-the-Johnson",
            "title": {
                "fragments": [],
                "text": "A Comparison of the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 150
                            }
                        ],
                        "text": "Results are reported on the complete test set as precision-recall breakeven points, a standard information retrieval measure for binary classi cation [Joachims 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 33
                            }
                        ],
                        "text": "Following several other studies [Joachims 1998; Liere & Tadepalli 1997] we build binary classifiers for each of the 10 most populous classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 152
                            }
                        ],
                        "text": "Results are reported on the complete test set as precision-recall breakeven points, a standard information retrieval measure for binary classification [Joachims 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 32
                            }
                        ],
                        "text": "Following several other studies [Joachims 1998; Liere & Tadepalli 1997] we build binary classi ers for each of the 10 most populous classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text categorization with Support"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 52
                            }
                        ],
                        "text": "Unlike settings in which queries must be generated [Cohn 1994], and previous work in which the unlabeled data is available as a stream [Dagan & Engelson 1995; Liere & Tadepalli 1997; Freund et al. 1997], our assumption about the availability of a pool of unlabeled data makes the improvements to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 51
                            }
                        ],
                        "text": "Unlike settings in which queries must be generated [Cohn 1994], and previous work in which the unlabeled data is available as a stream [Dagan & Engelson 1995; Liere & Tadepalli 1997; Freund et al."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural network exploration using optimal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 76
                            }
                        ],
                        "text": "Several previous implementations [Dagan & Engelson 1995; Lewis & Gale 1994; Lewis 1995] suppose that the learner is provided with a collection of labeled examples at the beginning of active learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 111
                            }
                        ],
                        "text": "Lewis and Gale examine uncertainty sampling and relevance sampling in a pool-based setting [Lewis & Gale 1994; Lewis 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 175
                            }
                        ],
                        "text": "Note that our assumptions about the generation of text documents are all violated in practice, and yet empirically, naive Bayes does a good job of classifying text documents [Lewis & Ringuette 1994; Craven et al. 1998; Joachims 1997]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A comparison of two"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Committee-based sampling for training probabilistic classiiers Maximum likelihood from incomplete data via the EM. algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "ICML-95"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 199
                            }
                        ],
                        "text": "Note that our assumptions about the generation of text documents are all violated in practice, and yet empirically, naive Bayes does a good job of classifying text documents [Lewis & Ringuette 1994; Craven et al. 1998; Joachims 1997]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learningto extract symbolic knowledge from theWorld WideWeb"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 57
                            }
                        ],
                        "text": "Several previous implementations [Dagan & Engelson 1995; Lewis & Gale 1994; Lewis 1995] suppose that the learner is provided with a collection of labeled examples at the beginning of active learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "Lewis and Gale examine uncertainty sampling and relevance sampling in a pool-based setting [Lewis & Gale 1994; Lewis 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "In comparison to previous active learning studies in text classification domains [Lewis & Gale 1994; Liere & Tadepalli 1997], the magnitude of our classification accuracy increase is relatively modest."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm fortraining text classi ers"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ACM SIGIR"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Distributionalclustering of English words"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 57
                            }
                        ],
                        "text": "Several previous implementations [Dagan & Engelson 1995; Lewis & Gale 1994; Lewis 1995] suppose that the learner is provided with a collection of labeled examples at the beginning of active learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 92
                            }
                        ],
                        "text": "Lewis and Gale examine uncertainty sampling and relevance sampling in a pool-based setting [Lewis & Gale 1994; Lewis 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "In comparison to previous active learning studies in text classification domains [Lewis & Gale 1994; Liere & Tadepalli 1997], the magnitude of our classification accuracy increase is relatively modest."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 8,
            "result": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Employing-EM-and-Pool-Based-Active-Learning-for-McCallum-Nigam/3b3b54848c1bc6ffea2625ce79302abed8e8deb9?sort=total-citations"
}