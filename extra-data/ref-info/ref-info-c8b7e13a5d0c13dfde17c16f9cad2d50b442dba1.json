{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717629"
                        ],
                        "name": "Yansong Feng",
                        "slug": "Yansong-Feng",
                        "structuredName": {
                            "firstName": "Yansong",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yansong Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 65
                            }
                        ],
                        "text": "Our experiments made use of the probabilistic model presented in Feng and Lapata (2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12547672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60be767a255fd13f73ed4e64d9901b30cf6081e8",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Image annotation, the task of automatically generating description words for a picture, is a key component in various image search and retrieval applications. Creating image databases for model development is, however, costly and time consuming, since the keywords must be hand-coded and the process repeated for new collections. In this work we exploit the vast resource of images and documents available on the web for developing image annotation models without any human involvement. We describe a probabilistic model based on the assumption that images and their co-occurring textual data are generated by mixtures of latent topics. We show that this model outperforms previously proposed approaches when applied to image annotation and the related task of text illustration despite the noisy nature of our dataset."
            },
            "slug": "Topic-Models-for-Image-Annotation-and-Text-Feng-Lapata",
            "title": {
                "fragments": [],
                "text": "Topic Models for Image Annotation and Text Illustration"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A probabilistic model based on the assumption that images and their co-occurring textual data are generated by mixtures of latent topics is described, which outperforms previously proposed approaches when applied to image annotation and the related task of text illustration despite the noisy nature of the dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717629"
                        ],
                        "name": "Yansong Feng",
                        "slug": "Yansong-Feng",
                        "structuredName": {
                            "firstName": "Yansong",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yansong Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747893"
                        ],
                        "name": "Mirella Lapata",
                        "slug": "Mirella-Lapata",
                        "structuredName": {
                            "firstName": "Mirella",
                            "lastName": "Lapata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mirella Lapata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16408584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6ffc5d4e234c0f4f37b00492ae33cb5dfe65765",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The availability of databases of images labeled with keywords is necessary for developing and evaluating image annotation models. Dataset collection is however a costly and time consuming task. In this paper we exploit the vast resource of images available on the web. We create a database of pictures that are naturally embedded into news articles and propose to use their captions as a proxy for annotation keywords. Experimental results show that an image annotation model can be developed on this dataset alone without the overhead of manual annotation. We also demonstrate that the news article associated with the picture can be used to boost image annotation performance."
            },
            "slug": "Automatic-Image-Annotation-Using-Auxiliary-Text-Feng-Lapata",
            "title": {
                "fragments": [],
                "text": "Automatic Image Annotation Using Auxiliary Text Information"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper creates a database of pictures that are naturally embedded into news articles and proposes to use their captions as a proxy for annotation keywords, showing that an image annotation model can be developed on this dataset alone without the overhead of manual annotation."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791802"
                        ],
                        "name": "J. Jeon",
                        "slug": "J.-Jeon",
                        "structuredName": {
                            "firstName": "Jiwoon",
                            "lastName": "Jeon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jeon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 249
                            }
                        ],
                        "text": "\u2026(Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information retrieval (Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 575890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18f8820e2a5ca6273a39123c27c0745870cda057",
            "isKey": false,
            "numCitedBy": 798,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries. We do this using a formalism that models the generation of annotated images. We assume that every image is divided into regions, each described by a continuous-valued feature vector. Given a training set of images with annotations, we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions. This may be used to automatically annotate and retrieve images given a word as a query. Experiments show that our model significantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval."
            },
            "slug": "A-Model-for-Learning-the-Semantics-of-Pictures-Lavrenko-Manmatha",
            "title": {
                "fragments": [],
                "text": "A Model for Learning the Semantics of Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries using a formalism that models the generation of annotated images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2339397"
                        ],
                        "name": "Michele Banko",
                        "slug": "Michele-Banko",
                        "structuredName": {
                            "firstName": "Michele",
                            "lastName": "Banko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michele Banko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751139"
                        ],
                        "name": "V. Mittal",
                        "slug": "V.-Mittal",
                        "structuredName": {
                            "firstName": "Vibhu",
                            "lastName": "Mittal",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Mittal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2819135"
                        ],
                        "name": "M. Witbrock",
                        "slug": "M.-Witbrock",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Witbrock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Witbrock"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Banko et al. (2000) propose a bag-of-words model for headline generation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "The caption generation task bears some resemblance to headline generation (Dorr et al., 2003; Banko et al., 2000; Jin and Hauptmann, 2002) where the aim is to create a very short summary for a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 124
                            }
                        ],
                        "text": "Word-based Model Our first abstractive model builds on and extends a well-known probabilistic model of headline generation (Banko et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 10
                            }
                        ],
                        "text": "Following Banko et al. (2000), we approximated the length distribution with a Gaussian."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 74
                            }
                        ],
                        "text": "The caption generation task bears some resemblance to headline generation (Dorr et al., 2003; Banko et al., 2000; Jin and Hauptmann, 2002) where the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9952653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d08213ede54c4e205d18b4400288831af918ec8",
            "isKey": true,
            "numCitedBy": 240,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Extractive summarization techniques cannot generate document summaries shorter than a single sentence, something that is often required. An ideal summarization system would understand each document and generate an appropriate summary directly from the results of that understanding. A more practical approach to this problem results in the use of an approximation: viewing summarization as a problem analogous to statistical machine translation. The issue then becomes one of generating a target document in a more concise language from a source document in a more verbose language. This paper presents results on experiments using this approach, in which statistical models of the term selection and term ordering are jointly applied to produce summaries in a style learned from a training corpus."
            },
            "slug": "Headline-Generation-Based-on-Statistical-Banko-Mittal",
            "title": {
                "fragments": [],
                "text": "Headline Generation Based on Statistical Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents results on experiments using this approach, in which statistical models of the term selection and term ordering are jointly applied to produce summaries in a style learned from a training corpus."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490678"
                        ],
                        "name": "P. H\u00e8de",
                        "slug": "P.-H\u00e8de",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "H\u00e8de",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e8de"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3070099"
                        ],
                        "name": "Pierre-Alain Mo\u00ebllic",
                        "slug": "Pierre-Alain-Mo\u00ebllic",
                        "structuredName": {
                            "firstName": "Pierre-Alain",
                            "lastName": "Mo\u00ebllic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Alain Mo\u00ebllic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086126207"
                        ],
                        "name": "Jo\u00ebl Bourgeoys",
                        "slug": "Jo\u00ebl-Bourgeoys",
                        "structuredName": {
                            "firstName": "Jo\u00ebl",
                            "lastName": "Bourgeoys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00ebl Bourgeoys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285512"
                        ],
                        "name": "M. Joint",
                        "slug": "M.-Joint",
                        "structuredName": {
                            "firstName": "Magali",
                            "lastName": "Joint",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Joint"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115821781"
                        ],
                        "name": "Corinne Thomas",
                        "slug": "Corinne-Thomas",
                        "structuredName": {
                            "firstName": "Corinne",
                            "lastName": "Thomas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinne Thomas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15063863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "832d7e11abe08644922018dd00c31004a0744fc8",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Image annotation is frequently used in image base management. Unfortunately, manual keyword indexing is costly and not exempt of errors for large image bases. In this article, we present a method for automatic image description in natural language for images without problems of occlusion. This method relies on a double expertise in image indexation and natural language processing and generation."
            },
            "slug": "Automatic-generation-of-natural-language-for-images-H\u00e8de-Mo\u00ebllic",
            "title": {
                "fragments": [],
                "text": "Automatic generation of natural language description for images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents a method for automatic image description in natural language for images without problems of occlusion that relies on a double expertise in image indexation and natural language processing and generation."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1824057"
                        ],
                        "name": "Florent Monay",
                        "slug": "Florent-Monay",
                        "structuredName": {
                            "firstName": "Florent",
                            "lastName": "Monay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florent Monay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403029865"
                        ],
                        "name": "D. G\u00e1tica-P\u00e9rez",
                        "slug": "D.-G\u00e1tica-P\u00e9rez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "G\u00e1tica-P\u00e9rez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. G\u00e1tica-P\u00e9rez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15084283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c79b3086598da24bb26f7da043741666b03d9b9",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "To go beyond the query-by-example paradigm in image retrieval, there is a need for semantic indexing of large image collections for intuitive text-based image search. Different models have been proposed to learn the dependencies between the visual content of an image set and the associated text captions, then allowing for the automatic creation of semantic indexes for unannotated images. The task, however, remains unsolved. In this paper, we present three alternatives to learn a probabilistic latent semantic analysis (PLSA) model for annotated images and evaluate their respective performance for automatic image indexing. Under the PLSA assumptions, an image is modeled as a mixture of latent aspects that generates both image features and text captions, and we investigate three ways to learn the mixture of aspects. We also propose a more discriminative image representation than the traditional Blob histogram, concatenating quantized local color information and quantized local texture descriptors. The first learning procedure of a PLSA model for annotated images is a standard expectation-maximization (EM) algorithm, which implicitly assumes that the visual and the textual modalities can be treated equivalently. The other two models are based on an asymmetric PLSA learning, allowing to constrain the definition of the latent space on the visual or on the textual modality. We demonstrate that the textual modality is more appropriate to learn a semantically meaningful latent space, which translates into improved annotation performance. A comparison of our learning algorithms with respect to recent methods on a standard data set is presented, and a detailed evaluation of the performance shows the validity of our framework."
            },
            "slug": "Modeling-Semantic-Aspects-for-Cross-Media-Image-Monay-G\u00e1tica-P\u00e9rez",
            "title": {
                "fragments": [],
                "text": "Modeling Semantic Aspects for Cross-Media Image Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents three alternatives to learn a probabilistic latent semantic analysis (PLSA) model for annotated images and evaluates their respective performance for automatic image indexing, and proposes a more discriminative image representation than the traditional Blob histogram."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068300013"
                        ],
                        "name": "Rong Jin",
                        "slug": "Rong-Jin",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7661726"
                        ],
                        "name": "Alexander Hauptmann",
                        "slug": "Alexander-Hauptmann",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Hauptmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Hauptmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1db1bcb9edf9d166a566beb01bb8af83998c0add",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Title generation is a complex task involving both natural language understanding and natural language synthesis. In this paper, we propose a new probabilistic model for title generation. Different from the previous statistical models for title generation, which treat title generation as a generation process that converts the 'document representation' of information directly into a 'title representation' of the same information, this model introduces a hidden state called 'information source' and divides title generation into two steps, namely the step of distilling the 'information source' from the observation of a document and the step of generating a title from the estimated 'information source'. In our experiment, the new probabilistic model outperforms the previous model for title generation in terms of both automatic evaluations and human judgments."
            },
            "slug": "A-New-Probabilistic-Model-for-Title-Generation-Jin-Hauptmann",
            "title": {
                "fragments": [],
                "text": "A New Probabilistic Model for Title Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new probabilistic model is proposed for title generation that introduces a hidden state called 'information source' and divides title generation into two steps, namely the step of distilling the ' information source' from the observation of a document and the stepof generating a title from the estimated 'information sources'."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 34
                            }
                        ],
                        "text": "Latent Dirichlet Allocation (LDA, Blei et al. 2003) is used to infer the latent topics assumed to have generated dMix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207561477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473f4b7f8ae2b03dda2593f54b316ff7d55db26b",
            "isKey": false,
            "numCitedBy": 1214,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of modeling annotated data---data with multiple types where the instance of one type (such as a caption) serves as a description of the other type (such as an image). We describe three hierarchical probabilistic mixture models which aim to describe such data, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type. We conduct experiments on the Corel database of images and captions, assessing performance in terms of held-out likelihood, automatic annotation, and text-based image retrieval."
            },
            "slug": "Modeling-annotated-data-Blei-Jordan",
            "title": {
                "fragments": [],
                "text": "Modeling annotated data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Three hierarchical probabilistic mixture models which aim to describe annotated data with multiple types, culminating in correspondence latent Dirichlet allocation, a latent variable model that is effective at modeling the joint distribution of both types and the conditional distribution of the annotation given the primary type."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49693392"
                        ],
                        "name": "A. Kojima",
                        "slug": "A.-Kojima",
                        "structuredName": {
                            "firstName": "Atsuhiro",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114145871"
                        ],
                        "name": "Takeshi Tamura",
                        "slug": "Takeshi-Tamura",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Tamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Tamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950023"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Kunio",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Kojima et al. (2002, 2008) create descriptions for human activities in office scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16139212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d53a97a3dd7760b193c0d9a5293b60feff239059",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method for describing human activities from video images based on concept hierarchies of actions. Major difficulty in transforming video images into textual descriptions is how to bridge a semantic gap between them, which is also known as inverse Hollywood problem. In general, the concepts of events or actions of human can be classified by semantic primitives. By associating these concepts with the semantic features extracted from video images, appropriate syntactic components such as verbs, objects, etc. are determined and then translated into natural language sentences. We also demonstrate the performance of the proposed method by several experiments."
            },
            "slug": "Natural-Language-Description-of-Human-Activities-on-Kojima-Tamura",
            "title": {
                "fragments": [],
                "text": "Natural Language Description of Human Activities from Video Images Based on Concept Hierarchy of Actions"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A method for describing human activities from video images based on concept hierarchies of actions based on semantic primitives, which demonstrates the performance of the proposed method by several experiments."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47713710"
                        ],
                        "name": "Benjamin Z. Yao",
                        "slug": "Benjamin-Z.-Yao",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Yao",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Z. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112063737"
                        ],
                        "name": "Xiong Yang",
                        "slug": "Xiong-Yang",
                        "structuredName": {
                            "firstName": "Xiong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiong Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110901865"
                        ],
                        "name": "Liang Lin",
                        "slug": "Liang-Lin",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2649483"
                        ],
                        "name": "M. Lee",
                        "slug": "M.-Lee",
                        "structuredName": {
                            "firstName": "Mun",
                            "lastName": "Lee",
                            "middleNames": [
                                "Wai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Yao et al. (2009) present a general framework for generating text descriptions of image and video content based on image parsing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6023198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05e074abddd3fe987b9bebd46f6cf4bf8465c37e",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an image parsing to text description (I2T) framework that generates text descriptions of image and video content based on image understanding. The proposed I2T framework follows three steps: 1) input images (or video frames) are decomposed into their constituent visual patterns by an image parsing engine, in a spirit similar to parsing sentences in natural language; 2) the image parsing results are converted into semantic representation in the form of Web ontology language (OWL), which enables seamless integration with general knowledge bases; and 3) a text generation engine converts the results from previous steps into semantically meaningful, human readable, and query-able text reports. The centerpiece of the I2T framework is an and-or graph (AoG) visual knowledge representation, which provides a graphical representation serving as prior knowledge for representing diverse visual patterns and provides top-down hypotheses during the image parsing. The AoG embodies vocabularies of visual elements including primitives, parts, objects, scenes as well as a stochastic image grammar that specifies syntactic relations (i.e., compositional) and semantic relations (e.g., categorical, spatial, temporal, and functional) between these visual elements. Therefore, the AoG is a unified model of both categorical and symbolic representations of visual knowledge. The proposed I2T framework has two objectives. First, we use semiautomatic method to parse images from the Internet in order to build an AoG for visual knowledge representation. Our goal is to make the parsing process more and more automatic using the learned AoG model. Second, we use automatic methods to parse image/video in specific domains and generate text reports that are useful for real-world applications. In the case studies at the end of this paper, we demonstrate two automatic I2T systems: a maritime and urban scene video surveillance system and a real-time automatic driving scene understanding system."
            },
            "slug": "I2T:-Image-Parsing-to-Text-Description-Yao-Yang",
            "title": {
                "fragments": [],
                "text": "I2T: Image Parsing to Text Description"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "An image parsing to text description (I2T) framework that generates text descriptions of image and video content based on image understanding and uses automatic methods to parse image/video in specific domains and generate text reports that are useful for real-world applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1857558"
                        ],
                        "name": "Shaolei Feng",
                        "slug": "Shaolei-Feng",
                        "structuredName": {
                            "firstName": "Shaolei",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaolei Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758550"
                        ],
                        "name": "R. Manmatha",
                        "slug": "R.-Manmatha",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Manmatha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manmatha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757708"
                        ],
                        "name": "V. Lavrenko",
                        "slug": "V.-Lavrenko",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lavrenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lavrenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 272
                            }
                        ],
                        "text": "\u2026(Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information retrieval (Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 54
                            }
                        ],
                        "text": ", 2009), and models inspired by information retrieval (Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3829888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba4e1089e2c5a1c12e9f6c2686e9c8d1870c718e",
            "isKey": false,
            "numCitedBy": 912,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieving images in response to textual queries requires some knowledge of the semantics of the picture. Here, we show how we can do both automatic image annotation and retrieval (using one word queries) from images and videos using a multiple Bernoulli relevance model. The model assumes that a training set of images or videos along with keyword annotations is provided. Multiple keywords are provided for an image and the specific correspondence between a keyword and an image is not provided. Each image is partitioned into a set of rectangular regions and a real-valued feature vector is computed over these regions. The relevance model is a joint probability distribution of the word annotations and the image feature vectors and is computed using the training set. The word probabilities are estimated using a multiple Bernoulli model and the image feature probabilities using a non-parametric kernel density estimate. The model is then used to annotate images in a test set. We show experiments on both images from a standard Corel data set and a set of video key frames from NIST's video tree. Comparative experiments show that the model performs better than a model based on estimating word probabilities using the popular multinomial distribution. The results also show that our model significantly outperforms previously reported results on the task of image and video annotation."
            },
            "slug": "Multiple-Bernoulli-relevance-models-for-image-and-Feng-Manmatha",
            "title": {
                "fragments": [],
                "text": "Multiple Bernoulli relevance models for image and video annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work shows how it can do both automatic image annotation and retrieval (using one word queries) from images and videos using a multiple Bernoulli relevance model, which significantly outperforms previously reported results on the task of image and video annotation."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752326"
                        ],
                        "name": "B. Dorr",
                        "slug": "B.-Dorr",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Dorr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dorr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3192273"
                        ],
                        "name": "David M. Zajic",
                        "slug": "David-M.-Zajic",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zajic",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Zajic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 75
                            }
                        ],
                        "text": "The caption generation task bears some resemblance to headline generation (Dorr et al., 2003; Banko et al., 2000; Jin and Hauptmann, 2002) where the aim is to create a very short summary for a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 74
                            }
                        ],
                        "text": "The caption generation task bears some resemblance to headline generation (Dorr et al., 2003; Banko et al., 2000; Jin and Hauptmann, 2002) where the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1729177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb56d57d9e64fb2c0af7f19120aae94485df59e2",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents Hedge Trimmer, a HEaDline GEneration system that creates a headline for a newspaper story using linguistically-motivated heuristics to guide the choice of a potential headline. We present feasibility tests used to establish the validity of an approach that constructs a headline by selecting words in order from a story. In addition, we describe experimental results that demonstrate the effectiveness of our linguistically-motivated approach over a HMM-based model, using both human evaluation and automatic metrics for comparing the two approaches."
            },
            "slug": "Hedge-Trimmer:-A-Parse-and-Trim-Approach-to-Dorr-Zajic",
            "title": {
                "fragments": [],
                "text": "Hedge Trimmer: A Parse-and-Trim Approach to Headline Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "Hedge Trimmer is presented, a HEaDline GEneration system that creates a headline for a newspaper story using linguistically-motivated heuristics to guide the choice of a potential headline."
            },
            "venue": {
                "fragments": [],
                "text": "HLT-NAACL 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059257793"
                        ],
                        "name": "Jo\u00e3o Freitas",
                        "slug": "Jo\u00e3o-Freitas",
                        "structuredName": {
                            "firstName": "Jo\u00e3o",
                            "lastName": "Freitas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jo\u00e3o Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "\u2026image features and words using supervised classification (Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 50
                            }
                        ],
                        "text": ", 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent vari-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12561212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d9f55b445f36578802e7eef4393cfa914b11620",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model of object recognition as machine translation. In this model, recognition is a process of annotating image regions with words. Firstly, images are segmented into regions, which are classified into region types using a variety of features. A mapping between region types and keywords supplied with the images, is then learned, using a method based around EM. This process is analogous with learning a lexicon from an aligned bitext. For the implementation we describe, these words are nouns taken from a large vocabulary. On a large test set, the method can predict numerous words with high accuracy. Simple methods identify words that cannot be predicted well. We show how to cluster words that individually are difficult to predict into clusters that can be predicted well -- for example, we cannot predict the distinction between train and locomotive using the current set of features, but we can predict the underlying concept. The method is trained on a substantial collection of images. Extensive experimental results illustrate the strengths and weaknesses of the approach."
            },
            "slug": "Object-Recognition-as-Machine-Translation:-Learning-Sahin-Barnard",
            "title": {
                "fragments": [],
                "text": "Object Recognition as Machine Translation: Learning a Lexicon for a Fixed Image Vocabulary"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows how to cluster words that individually are difficult to predict into clusters that can be predicted well, and cannot predict the distinction between train and locomotive using the current set of features, but can predict the underlying concept."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446509"
                        ],
                        "name": "P. D. Sahin",
                        "slug": "P.-D.-Sahin",
                        "structuredName": {
                            "firstName": "Pinar",
                            "lastName": "Sahin",
                            "middleNames": [
                                "Duygulu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Sahin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 12
                            }
                        ],
                        "text": "able models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information retrieval (Lavrenko et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 161
                            }
                        ],
                        "text": "\u2026(Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information retrieval (Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 868535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e",
            "isKey": false,
            "numCitedBy": 1760,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data."
            },
            "slug": "Matching-Words-and-Pictures-Barnard-Sahin",
            "title": {
                "fragments": [],
                "text": "Matching Words and Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text, is presented, and a number of models for the joint distribution of image regions and words are developed, including several which explicitly learn the correspondence between regions and Words."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113355660"
                        ],
                        "name": "M. Corio",
                        "slug": "M.-Corio",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Corio",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Corio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806207"
                        ],
                        "name": "G. Lapalme",
                        "slug": "G.-Lapalme",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Lapalme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lapalme"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14723110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6885c80317cb7b134baec0cc8063aac6caa08e4e",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describeSelTex a text generation system for producing short texts and captions to accomp any information graphics that are generated according to the writer\u2019s intentio ns.SelTex uses rules that were extracted from a corpus study of more than 400 text excerpts. This corp us study shows that text and graphics play complementary roles in transmitting information from th e writer to the reader. We then derive some observations for the automatic generation of texts associat ed with graphics many of which were implemented inSelTex. For the past few years, we have studied the automatic generat ion of graphics from statistical data in the context of thePostGraphe system [5, 6].PostGraphe is given data in tabular form as might be found in a spreadsheet; also input is a declaration of the types of val ues in the columns of the table. The user then indicates the intentions to be conveyed in the graphics (e.g . compare two variables or show the evolution of a set of variables) and the system generates a report in L ATEX with the appropriate PostScript graphic files. PostGraphe also generates an accompanying text for only a few simple tex t schemas. Although PostGraphe has shown the potential of graphic generation, its text gene ration capabilities are well below its level of graphic competence. So we decided to redesign th e text generation module to better capture the subtle nature of the interaction between text and graphics. Before designingSelTex, the new text module to be integrated inPostGraphe, we did a corpus study of more than 400 texts associated with g raphics. The preliminary findings were presented in [3]. They will be r eviewed here briefly before describing the text generation rules that were deduced from this corpus stu dy. We will focus on the selection criteria for relevant facts that are expressed in the text that accompani es graphic. 1 Overview ofPostGraphe Many sophisticated tools can be used to create presentation s usi g statistical graphs. However, most of them focus on producing professional-looking graphics without trying to help the user to organize the presentation. To help in this aspect, we have built PostGraphe which generates a report integrating graphics and text from a set of writer\u2019s intentions. In figure 1, the writer\u2019s intentions have an important effect on the way information is presented. Indeed, the figure shows the same data presented in two different ways according to what the writer wants to convey. One part of the example shows how to present the evolution of t he data and the other part shows how to compare its various elements. The writer\u2019s intentions can be classified according to two ba sic criteria: structural differences and contents differences. Figure 1 illustrates the structural dif ference between evolution and comparison. We refer 1971 1972 1973 1974 1975 1976 0 6 12 18"
            },
            "slug": "Generation-of-texts-for-information-graphics-Corio-Lapalme",
            "title": {
                "fragments": [],
                "text": "Generation of texts for information graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "SelTex a text generation system for producing short texts and captions to accomp any information graphics that are generated according to the writer\u2019s intentio ns is described and it is shown that text and graphics play complementary roles in transmitting information from th e writer to the reader."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32278254"
                        ],
                        "name": "Matthew G. Snover",
                        "slug": "Matthew-G.-Snover",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Snover",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew G. Snover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752326"
                        ],
                        "name": "B. Dorr",
                        "slug": "B.-Dorr",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Dorr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dorr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152901366"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333779"
                        ],
                        "name": "L. Micciulla",
                        "slug": "L.-Micciulla",
                        "structuredName": {
                            "firstName": "Linnea",
                            "lastName": "Micciulla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Micciulla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 66
                            }
                        ],
                        "text": "Our automatic evaluation was based on Translation Edit Rate (TER, Snover et al. 2006), a measure commonly used to evaluate the quality of machine translation output."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8938789,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "51951073580f6995e55be873db9a7f6a9736ca86",
            "isKey": false,
            "numCitedBy": 2219,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We examine a new, intuitive measure for evaluating machine-translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments. Translation Edit Rate (TER) measures the amount of editing that a human would have to perform to change a system output so it exactly matches a reference translation. We show that the single-reference variant of TER correlates as well with human judgments of MT quality as the four-reference variant of BLEU. We also define a human-targeted TER (or HTER) and show that it yields higher correlations with human judgments than BLEU\u2014even when BLEU is given human-targeted references. Our results indicate that HTER correlates with human judgments better than HMETEOR and that the four-reference variants of TER and HTER correlate with human judgments as well as\u2014or better than\u2014a second human judgment does."
            },
            "slug": "A-Study-of-Translation-Edit-Rate-with-Targeted-Snover-Dorr",
            "title": {
                "fragments": [],
                "text": "A Study of Translation Edit Rate with Targeted Human Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new, intuitive measure for evaluating machine-translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments is examined, which indicates that HTER correlates with human judgments better than HMETEOR and that the four-reference variants of TER and HTER correlate withhuman judgments as well as\u2014or better than\u2014a second human judgment does."
            },
            "venue": {
                "fragments": [],
                "text": "AMTA"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795942"
                        ],
                        "name": "Reinhard Kneser",
                        "slug": "Reinhard-Kneser",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Kneser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reinhard Kneser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40293552"
                        ],
                        "name": "J. Peters",
                        "slug": "J.-Peters",
                        "structuredName": {
                            "firstName": "Jochen",
                            "lastName": "Peters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561225"
                        ],
                        "name": "D. Klakow",
                        "slug": "D.-Klakow",
                        "structuredName": {
                            "firstName": "Dietrich",
                            "lastName": "Klakow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klakow"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3027407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2854e19e23a0987d0989cd8dfadebec3692e3a60",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method is presented to quickly adapt a given language model to local text characteristics. The basic approach is to choose the adaptive models as close as possible to the background estimates while constraining them to respect the locally estimated unigram probabilities. Several means are investigated to speed up the calculations. We measure both perplexity and word error rate to gauge the quality of our model."
            },
            "slug": "Language-model-adaptation-using-dynamic-marginals-Kneser-Peters",
            "title": {
                "fragments": [],
                "text": "Language model adaptation using dynamic marginals"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new method is presented to quickly adapt a given language model to local text characteristics by choosing the adaptive models as close as possible to the background estimates while constraining them to respect the locally estimated unigram probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 753304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7314be5cd836c8f06bd1ecab565b00b65259eac6",
            "isKey": false,
            "numCitedBy": 3888,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called \"topics\" because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process (HDP). We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis."
            },
            "slug": "Probabilistic-Topic-Models-Blei",
            "title": {
                "fragments": [],
                "text": "Probabilistic topic models"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "Surveying a suite of algorithms that offer a solution to managing large document archives suggests they are well-suited to handle large amounts of data."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 34
                            }
                        ],
                        "text": "Latent Dirichlet Allocation (LDA, Blei et al. 2003) is used to infer the latent topics assumed to have generated dMix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3177797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f198043a866e9187925a8d8db9a55e3bfdd47f2c",
            "isKey": false,
            "numCitedBy": 30947,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Latent-Dirichlet-Allocation-Blei-Ng",
            "title": {
                "fragments": [],
                "text": "Latent Dirichlet Allocation"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638781"
                        ],
                        "name": "A. Smeulders",
                        "slug": "A.-Smeulders",
                        "structuredName": {
                            "firstName": "Arnold",
                            "lastName": "Smeulders",
                            "middleNames": [
                                "W.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeulders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717056"
                        ],
                        "name": "M. Worring",
                        "slug": "M.-Worring",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Worring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Worring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747647"
                        ],
                        "name": "S. Santini",
                        "slug": "S.-Santini",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Santini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Santini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938740"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 140
                            }
                        ],
                        "text": "The literature is littered with various attempts to learn the associations between image features and words using supervised classification (Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "\u2026is littered with various attempts to learn the associations between image features and words using supervised classification (Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003; Barnard et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2827898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b7c4096ed697696a5f4fc8f3a6a750dc0cdecfe",
            "isKey": false,
            "numCitedBy": 6727,
            "numCiting": 410,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a review of 200 references in content-based image retrieval. The paper starts with discussing the working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps for image retrieval systems. Step one of the review is image processing for retrieval sorted by color, texture, and local geometry. Features for retrieval are discussed next, sorted by: accumulative and global features, salient points, object and shape features, signs, and structural combinations thereof. Similarity of pictures and objects in pictures is reviewed for each of the feature types, in close connection to the types and means of feedback the user of the systems is capable of giving by interaction. We briefly discuss aspects of system engineering: databases, system architecture, and evaluation. In the concluding section, we present our view on: the driving force of the field, the heritage from computer vision, the influence on computer vision, the role of similarity and of interaction, the need for databases, the problem of evaluation, and the role of the semantic gap."
            },
            "slug": "Content-Based-Image-Retrieval-at-the-End-of-the-Smeulders-Worring",
            "title": {
                "fragments": [],
                "text": "Content-Based Image Retrieval at the End of the Early Years"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The working conditions of content-based retrieval: patterns of use, types of pictures, the role of semantics, and the sensory gap are discussed, as well as aspects of system engineering: databases, system architecture, and evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32278254"
                        ],
                        "name": "Matthew G. Snover",
                        "slug": "Matthew-G.-Snover",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Snover",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew G. Snover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752326"
                        ],
                        "name": "B. Dorr",
                        "slug": "B.-Dorr",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Dorr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dorr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35442155"
                        ],
                        "name": "R. Schwartz",
                        "slug": "R.-Schwartz",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3333779"
                        ],
                        "name": "L. Micciulla",
                        "slug": "L.-Micciulla",
                        "structuredName": {
                            "firstName": "Linnea",
                            "lastName": "Micciulla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Micciulla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732071"
                        ],
                        "name": "R. Weischedel",
                        "slug": "R.-Weischedel",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Weischedel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Weischedel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14226,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a5899f1ec92af7d01f35225161430116a6eabbea",
            "isKey": false,
            "numCitedBy": 1633,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a new, intuitive measure for evaluating machine translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments. Translation Error Rate (TER) measures the amount of editing that a human would have to perform to change a system output so it exactly matches a reference translation. We also compute a human-targeted TER (or HTER), where the minimum TER of the translation is computed against a human \u2018targeted reference\u2019 that preserves the meaning (provided by the reference translations) and is fluent, but is chosen to minimize the TER score for a particular system output. We show that: (1) The single-reference variant of TER correlates as well with human judgments of MT quality as the four-reference variant of BLEU; (2) The human-targeted HTER yields a 33% error-rate reduction and is shown to be very well correlated with human judgments; (3) The four-reference variant of TER and the single-reference variant of HTER yield higher correlations with human judgments than BLEU; (4) HTER yields higher correlations with human judgments than METEOR or its human-targeted variant (HMETEOR); and (5) The four-reference variant of TER correlates as well with a single human judgment as a second human judgment does, while HTER, HBLEU, and HMETEOR correlate significantly better with a human judgment than a second human judgment does."
            },
            "slug": "A-STUDY-OF-TRANSLATION-ERROR-RATE-WITH-TARGETED-Snover-Dorr",
            "title": {
                "fragments": [],
                "text": "A STUDY OF TRANSLATION ERROR RATE WITH TARGETED HUMAN ANNOTATION"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new, intuitive measure for evaluating machine translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments is defined."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12605,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3328108"
                        ],
                        "name": "Luis von Ahn",
                        "slug": "Luis-von-Ahn",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ahn",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luis von Ahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784365"
                        ],
                        "name": "Laura A. Dabbish",
                        "slug": "Laura-A.-Dabbish",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Dabbish",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laura A. Dabbish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 338469,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2d4a6e4900ec0f096c87bb2b1272eeceaa584a6",
            "isKey": false,
            "numCitedBy": 2386,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained."
            },
            "slug": "Labeling-images-with-a-computer-game-Ahn-Dabbish",
            "title": {
                "fragments": [],
                "text": "Labeling images with a computer game"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new interactive system: a game that is fun and can be used to create valuable output that addresses the image-labeling problem and encourages people to do the work by taking advantage of their desire to be entertained."
            },
            "venue": {
                "fragments": [],
                "text": "CHI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751139"
                        ],
                        "name": "V. Mittal",
                        "slug": "V.-Mittal",
                        "structuredName": {
                            "firstName": "Vibhu",
                            "lastName": "Mittal",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Mittal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47147237"
                        ],
                        "name": "Johanna D. Moore",
                        "slug": "Johanna-D.-Moore",
                        "structuredName": {
                            "firstName": "Johanna",
                            "lastName": "Moore",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johanna D. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825424"
                        ],
                        "name": "G. Carenini",
                        "slug": "G.-Carenini",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Carenini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carenini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697331"
                        ],
                        "name": "S. Roth",
                        "slug": "S.-Roth",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Roth",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 139
                            }
                        ],
                        "text": "Within natural language processing most previous efforts have focused on generating captions to accompany complex graphical presentations (Mittal et al., 1998; Corio and Lapalme, 1999; Fasciano and Lapalme, 2000; Feiner and McKeown, 1990) or on using the captions accompanying information graphics\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 138
                            }
                        ],
                        "text": "Within natural language processing most previous efforts have focused on generating captions to accompany complex graphical presentations (Mittal et al., 1998; Corio and Lapalme, 1999; Fasciano and Lapalme, 2000; Feiner and McKeown, 1990) or on using the captions accompanying information graphics to infer their intended message, e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6375093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f569c8bcddfbfb57ab03b5a74c794fb95fa16f9b",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphical presentations can be used to communicate information in relational data sets succinctly and effectively. However, novel graphical presentations that represent many attributes and relationships are often difficult to understand completely until explained. Automatically generated graphical presentations must therefore either be limited to generating simple, conventionalized graphical presentations, or risk incomprehensibility. A possible solution to this problem would be to extend automatic graphical presentation systems to generate explanatory captions in natural language, to enable users to understand the information expressed in the graphic. This paper presents a system to do so. It uses a text planner to determine the content and structure of the captions based on: (1) a representation of the structure of the graphical presentation and its mapping to the data it depicts, (2) a framework for identifying the perceptual complexity of graphical elements, and (3) the structure of the data expressed in the graphic. The output of the planner is further processed regarding issues such as ordering, aggregation, centering, generating referring expressions, and lexical choice. We discuss the architecture of our system and its strengths and limitations. Our implementation is currently limited to 2-D charts and maps, but, except for lexical information, it is completely domain independent. We illustrate our discussion with figures and generated captions about housing sales in Pittsburgh."
            },
            "slug": "Describing-Complex-Charts-in-Natural-Language:-A-Mittal-Moore",
            "title": {
                "fragments": [],
                "text": "Describing Complex Charts in Natural Language: A Caption Generation System"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A system to extend automatic graphical presentation systems to generate explanatory captions in natural language, to enable users to understand the information expressed in the graphic, and is currently limited to 2-D charts and maps."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108881999"
                        ],
                        "name": "Chong Wang",
                        "slug": "Chong-Wang",
                        "structuredName": {
                            "firstName": "Chong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796335"
                        ],
                        "name": "D. Blei",
                        "slug": "D.-Blei",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Blei",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 12
                            }
                        ],
                        "text": "able models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information retrieval (Lavrenko et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 183
                            }
                        ],
                        "text": "\u2026(Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003; Barnard et al., 2002; Wang et al., 2009), and models inspired by information retrieval (Lavrenko et al., 2003; Feng et al., 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14362511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7fdf31d5ebdd293b3027e6555e256a936ff5515a",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Image classification and annotation are important problems in computer vision, but rarely considered together. Intuitively, annotations provide evidence for the class label, and the class label provides evidence for annotations. For example, an image of class highway is more likely annotated with words \u201croad,\u201d \u201ccar,\u201d and \u201ctraffic\u201d than words \u201cfish,\u201d \u201cboat,\u201d and \u201cscuba.\u201d In this paper, we develop a new probabilistic model for jointly modeling the image, its class label, and its annotations. Our model treats the class label as a global description of the image, and treats annotation terms as local descriptions of parts of the image. Its underlying probabilistic assumptions naturally integrate these two sources of information. We derive an approximate inference and estimation algorithms based on variational methods, as well as efficient approximations for classifying and annotating new images. We examine the performance of our model on two real-world image data sets, illustrating that a single model provides competitive annotation performance, and superior classification performance."
            },
            "slug": "Simultaneous-image-classification-and-annotation-Wang-Blei",
            "title": {
                "fragments": [],
                "text": "Simultaneous image classification and annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new probabilistic model for jointly modeling the image, its class label, and its annotations is developed, which derives an approximate inference and estimation algorithms based on variational methods, as well as efficient approximations for classifying and annotating new images."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277853"
                        ],
                        "name": "A. Vailaya",
                        "slug": "A.-Vailaya",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Vailaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vailaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34659351"
                        ],
                        "name": "M\u00e1rio A. T. Figueiredo",
                        "slug": "M\u00e1rio-A.-T.-Figueiredo",
                        "structuredName": {
                            "firstName": "M\u00e1rio",
                            "lastName": "Figueiredo",
                            "middleNames": [
                                "A.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M\u00e1rio A. T. Figueiredo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 140
                            }
                        ],
                        "text": "The literature is littered with various attempts to learn the associations between image features and words using supervised classification (Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "The literature is littered with various attempts to learn the associations between image features and words using supervised classification (Vailaya et al., 2001; Smeulders et al., 2000), instantiations of the noisychannel model (Duygulu et al., 2002), latent variable models (Blei and Jordan, 2003;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9140319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "142f056a365dccd029c0897fcfa7833aecf2212f",
            "isKey": false,
            "numCitedBy": 868,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Grouping images into (semantically) meaningful categories using low-level visual features is a challenging and important problem in content-based image retrieval. Using binary Bayesian classifiers, we attempt to capture high-level concepts from low-level image features under the constraint that the test image does belong to one of the classes. Specifically, we consider the hierarchical classification of vacation images; at the highest level, images are classified as indoor or outdoor; outdoor images are further classified as city or landscape; finally, a subset of landscape images is classified into sunset, forest, and mountain classes. We demonstrate that a small vector quantizer (whose optimal size is selected using a modified MDL criterion) can be used to model the class-conditional densities of the features, required by the Bayesian methodology. The classifiers have been designed and evaluated on a database of 6931 vacation photographs. Our system achieved a classification accuracy of 90.5% for indoor/outdoor, 95.3% for city/landscape, 96.6% for sunset/forest and mountain, and 96% for forest/mountain classification problems. We further develop a learning method to incrementally train the classifiers as additional data become available. We also show preliminary results for feature reduction using clustering techniques. Our goal is to combine multiple two-class classifiers into a single hierarchical classifier."
            },
            "slug": "Image-classification-for-content-based-indexing-Vailaya-Figueiredo",
            "title": {
                "fragments": [],
                "text": "Image classification for content-based indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The goal is to combine multiple two-class classifiers into a single hierarchical classifier, and it is demonstrated that a small vector quantizer can be used to model the class-conditional densities of the features, required by the Bayesian methodology."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897400"
                        ],
                        "name": "S. Schwartz",
                        "slug": "S.-Schwartz",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "Elzer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3326473"
                        ],
                        "name": "S. Carberry",
                        "slug": "S.-Carberry",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "Carberry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carberry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48127057"
                        ],
                        "name": "Ingrid Zukerman",
                        "slug": "Ingrid-Zukerman",
                        "structuredName": {
                            "firstName": "Ingrid",
                            "lastName": "Zukerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ingrid Zukerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3021168"
                        ],
                        "name": "D. Chester",
                        "slug": "D.-Chester",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Chester",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143752493"
                        ],
                        "name": "N. Green",
                        "slug": "N.-Green",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Green",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Green"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10109293"
                        ],
                        "name": "Seniz Demir",
                        "slug": "Seniz-Demir",
                        "structuredName": {
                            "firstName": "Seniz",
                            "lastName": "Demir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seniz Demir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 88
                            }
                        ],
                        "text": ", the author\u2019s goal to convey ostensible increase or decrease of a quantity of interest (Elzer et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 278
                            }
                        ],
                        "text": "\u2026et al., 1998; Corio and Lapalme, 1999; Fasciano and Lapalme, 2000; Feiner and McKeown, 1990) or on using the captions accompanying information graphics to infer their intended message, e.g., the author\u2019s goal to convey ostensible increase or decrease of a quantity of interest (Elzer et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2623140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5fc1848866e4c446f143ac54bba808dd883265e",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper extends language understanding and plan inference to information graphics. We identify the kinds of communicative signals that appear in information graphics, describe how we utilize them in a Bayesian network that hypothesizes the graphic's intended message, and discuss the performance of our implemented system. This work is part of a larger project aimed at making information graphics accessible to individuals with sight impairments."
            },
            "slug": "A-Probabilistic-Framework-for-Recognizing-Intention-Schwartz-Carberry",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Framework for Recognizing Intention in Information Graphics"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The kinds of communicative signals that appear in information graphics are identified, how they are utilized in a Bayesian network that hypothesizes the graphic's intended message is described, and the performance of the implemented system is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2332212"
                        ],
                        "name": "Massimo Fasciano",
                        "slug": "Massimo-Fasciano",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Fasciano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Massimo Fasciano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806207"
                        ],
                        "name": "G. Lapalme",
                        "slug": "G.-Lapalme",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Lapalme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lapalme"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9535039,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69d62978c66ef9c4b94ab86e97238e1087576db6",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. To use graphics efficiently in an automatic report generation system, one has to model messages and how they go from the writer (intention) to the reader (interpretation). This paper describes PostGraphe, a system which generates a report integrating graphics and text from a set of writer's intentions. The system is given the data in tabular form as might be found in a spreadsheet; also input is a declaration of the types of values in the columns of the table. The user then indicates the intentions to be conveyed in the graphics (e.g., compare two variables or show the evolution of a set of variables) and the system generates a report in LATEX with the appropriate PostScript graphic files. PostGraphe uses the same information to generate the accompanying text that helps the reader to focus on the important points of the graphics. We also describe how these ideas have been embedded to create a new Chart Wizard for Microsoft Excel."
            },
            "slug": "Intentions-in-the-Coordinated-Generation-of-and-Fasciano-Lapalme",
            "title": {
                "fragments": [],
                "text": "Intentions in the Coordinated Generation of Graphics and Text from Tabular Data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "PostGraphe, a system which generates a report integrating graphics and text from a set of writer's intentions, is described, which has been embedded to create a new Chart Wizard for Microsoft Excel."
            },
            "venue": {
                "fragments": [],
                "text": "Knowledge and Information Systems"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809403"
                        ],
                        "name": "S. Feiner",
                        "slug": "S.-Feiner",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Feiner",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Feiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145590324"
                        ],
                        "name": "K. McKeown",
                        "slug": "K.-McKeown",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "McKeown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKeown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5496468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5458838502b70f00cb69cc5885d0ab3ab032a299",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "To generate multimedia explanations, a system must be able to coordinate the use of different media in a single explanation. In this paper, we present the architecture that we have developed for COMET (COordinated Multimedia Explanation Testbed), a system that generates directions for equipment maintenance and repair, and we show how it addresses the coordination problem. COMET includes a single content planner that produces a common content description used by multiple media-specific generators, and a media coordinator that performs a fine-grained division of information among media. Bidirectional interaction between media-specific generators allows influence across media. We describe COMET's current capabilities and provide an overview of our plans for extending the system."
            },
            "slug": "Coordinating-Text-and-Graphics-in-Explanation-Feiner-McKeown",
            "title": {
                "fragments": [],
                "text": "Coordinating Text and Graphics in Explanation Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The architecture that is developed for COMET (COordinated Multimedia Explanation Testbed), a system that generates directions for equipment maintenance and repair, is presented and it is shown how it addresses the coordination problem."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11495042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a600850ac0120cb09a0b7de7da80bb6a7a76de06",
            "isKey": false,
            "numCitedBy": 3370,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize."
            },
            "slug": "Accurate-Unlexicalized-Parsing-Klein-Manning",
            "title": {
                "fragments": [],
                "text": "Accurate Unlexicalized Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is demonstrated that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752967"
                        ],
                        "name": "L. Ferres",
                        "slug": "L.-Ferres",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Ferres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ferres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542085"
                        ],
                        "name": "A. Parush",
                        "slug": "A.-Parush",
                        "structuredName": {
                            "firstName": "Avi",
                            "lastName": "Parush",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parush"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145736297"
                        ],
                        "name": "Shelley Roberts",
                        "slug": "Shelley-Roberts",
                        "structuredName": {
                            "firstName": "Shelley",
                            "lastName": "Roberts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shelley Roberts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796956"
                        ],
                        "name": "G. Lindgaard",
                        "slug": "G.-Lindgaard",
                        "structuredName": {
                            "firstName": "Gitte",
                            "lastName": "Lindgaard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lindgaard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16192929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80c8c6e1ca57cec1adc93040a6279b039ad1c42f",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Much numerical information is visualized in graphs. However, this is a medium that is problematic for people with visual impairments. We have developed a system called iGraph which provides short verbal descriptions of the information usually depicted in graphs. This system was used as a preliminary solution that was validated through a process of User Needs Analysis (UNA). This process provided some basic data on the needs of people with visual impairments in terms of the components and the language to be used for graph comprehension and also validated our initial approach. The UNA provided important directions for the further development of iGraph particularly in terms of interactive querying of graphs"
            },
            "slug": "Helping-People-with-Visual-Impairments-Gain-Access-Ferres-Parush",
            "title": {
                "fragments": [],
                "text": "Helping People with Visual Impairments Gain Access to Graphical Information Through Natural Language: The iGraph System"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "iGraph is a system which provides short verbal descriptions of the information usually depicted in graphs which was used as a preliminary solution that was validated through a process of User Needs Analysis (UNA)."
            },
            "venue": {
                "fragments": [],
                "text": "ICCHP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49693392"
                        ],
                        "name": "A. Kojima",
                        "slug": "A.-Kojima",
                        "structuredName": {
                            "firstName": "Atsuhiro",
                            "lastName": "Kojima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kojima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2899347"
                        ],
                        "name": "M. Takaya",
                        "slug": "M.-Takaya",
                        "structuredName": {
                            "firstName": "Mamoru",
                            "lastName": "Takaya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Takaya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50686092"
                        ],
                        "name": "S. Aoki",
                        "slug": "S.-Aoki",
                        "structuredName": {
                            "firstName": "Shigeki",
                            "lastName": "Aoki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aoki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056934504"
                        ],
                        "name": "T. Miyamoto",
                        "slug": "T.-Miyamoto",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Miyamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Miyamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950023"
                        ],
                        "name": "K. Fukunaga",
                        "slug": "K.-Fukunaga",
                        "structuredName": {
                            "firstName": "Kunio",
                            "lastName": "Fukunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Kojima et al. (2002, 2008) create descriptions for human activities in office scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11647837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7806ba91eade96c025bdb2cb8d0c0cdfddb8587",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method for recognizing human actions and objects and translating them into natural language text. First, 3D environmental map is constructed by accumulating range maps captured from a 3D range sensor mounted on a mobile robot. Then, pose of a person in the scene is estimated by fitting articulated cylindrical model and also object is recognized by matching 3D models. On condition that the person handles some objects, interaction with the object is classified. Finally, using conceptual model representing human actions and related objects, a natural language expression which is most suitable to explain the person's action is generated."
            },
            "slug": "Recognition-and-Textual-Description-of-Human-by-Kojima-Takaya",
            "title": {
                "fragments": [],
                "text": "Recognition and Textual Description of Human Activities by Mobile Robot"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "3D environmental map is constructed by accumulating range maps captured from a 3D range sensor mounted on a mobile robot, and conceptual model representing human actions and related objects are represented."
            },
            "venue": {
                "fragments": [],
                "text": "2008 3rd International Conference on Innovative Computing Information and Control"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16257,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143985595"
                        ],
                        "name": "A. Parry",
                        "slug": "A.-Parry",
                        "structuredName": {
                            "firstName": "Anne",
                            "lastName": "Parry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parry"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 71320488,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "2fea8adac8326278f5bf9ee076328f40985b2b3d",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Helping-People-with-AIDS-Parry",
            "title": {
                "fragments": [],
                "text": "Helping People with AIDS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "Specifically, we use an adaptive language model (Kneser et al., 1997) that modifies an\nn-gram model with local unigram probabilities:\nP(w1,w2, ...,wn) = n \u220f i=1 P(wi \u2208C|wi \u2208 D) (8)\n\u00b7P(len(C) = n) \u00b7 n \u220f i"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Manning . 2003 . Accurate unlexicalized parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 41 st Annual Meeting of the Association of Computational Linguistics"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 1
                            }
                        ],
                        "text": "For example, we may use the KL divergence to measure the difference between the distributions p and q:\nD(p,q) = K\n\u2211 j=1 p j log2 p j q j\n(4)\nwhere p and q are shorthand for the image topic distribution PdMix and sentence topic distribution PSd , respectively."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 157
                            }
                        ],
                        "text": "Under this framework, the similarity between an im-\nage and a sentence can be broadly measured by the extent to which they share the same topic distributions (Steyvers and Griffiths, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabilistic topic models A Handbook of Latent Semantic Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Probabilistic topic models A Handbook of Latent Semantic Analysis"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Helping people with"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/How-Many-Words-Is-a-Picture-Worth-Automatic-Caption-Feng-Lapata/c8b7e13a5d0c13dfde17c16f9cad2d50b442dba1?sort=total-citations"
}