{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12982013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8afc676c5f2ee8090b67b4c60ab2d8a9e3ebd4a",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Genericity in structured document recognition is a difficult challenge. We therefore propose a new generic document recognition method, called DMOS (Description and MOdification of Segmentation), that is made up of a new grammatical formalism, called EPF (Enhanced Position Formalism) and an associated parser which is able to introduce context in segmentation. We implement this method to obtain a generator of document recognition systems. This generator can automatically produce new recognition systems. It is only necessary to describe the document with an EPF grammar, which is then simply compiled. In this way, we have developed various recognition systems: one on musical scores, one on mathematical formulae and one on recursive table structures. We have also defined a specific application to damaged military forms of the 19th Century. We have been able to test the generated system on 5,000 of these military forms. This has permitted us to validate the DMOS method on a real-world application."
            },
            "slug": "DMOS:-a-generic-document-recognition-method,-to-an-Co\u00fcasnon",
            "title": {
                "fragments": [],
                "text": "DMOS: a generic document recognition method, application to an automatic generator of musical scores, mathematical formulae and table structures recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new generic document recognition method, called DMOS (Description and MOdification of Segmentation), that is made up of a new grammatical formalism, called EPF (Enhanced Position Formalism), and an associated parser which is able to introduce context in segmentation is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 254
                            }
                        ],
                        "text": "By only changing the EPF grammar, and by training a classifier when needed, we produced automatically by compilation various recognition systems: one for musical scores [3], one for mathematical formulae [5], and one to recognize tennis courts in videos [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 43
                            }
                        ],
                        "text": "To do so, we propose to work on two levels [1]:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 241
                            }
                        ],
                        "text": "With EPF and its associated parser, we have already been able to produce various recognition systems on different kinds of document: one for musical scores [3], one for mathematical formulae [5], and one to recognize tennis courts in videos [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42700901,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eda5f84fdcd2ec8dad98ec2d1f0a337c5f7e96ad",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "To develop a generic method for document recognition, it is necessary to build a system with a generic approach for dealing with noise. Indeed, a lot of noise is present in an image and a recognizer needs to find the right information in the middle of noise to make a recognition. We describe in this paper the parser we develop in DMOS, a generic method for structured document recognition. This method use EPF, a grammatical language for describing documents. From an EPF description, a new recognition system is automatically build by compilation. DMOS had been successfully used for musical scores, mathematical formulae, table structure and old forms recognition (tested on 60,000 documents)."
            },
            "slug": "Dealing-with-Noise-in-DMOS,-a-Generic-Method-for-An-Co\u00fcasnon",
            "title": {
                "fragments": [],
                "text": "Dealing with Noise in DMOS, a Generic Method for Structured Document Recognition: An Example on a Complete Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The parser the authors develop in DMOS, a generic method for structured document recognition, uses EPF, a grammatical language for describing documents to build a system with a generic approach for dealing with noise."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578743"
                        ],
                        "name": "L. Pasquer",
                        "slug": "L.-Pasquer",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Pasquer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pasquer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "We have first successfully tested this recognition system on 5,268 images [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30186146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e796eb564c1f2a091fc3817614d410afff36a8a6",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a real-world evaluation of DMOS, a new generic document recognition method. This method uses a new grammatical formalism (EPF) and an associated parser able to introduce context in segmentation. We have implemented this DMOS method to build an automatic generator of structured document recognition systems. We already produced three recognition systems by only changing the EPF grammar: one on musical scores, one on mathematical formulae and one on recursive table structures. We present here a specific light grammar to automatically recognize quite damaged 19th century military forms. The quality of those forms is far from perfect: table lines are not well printed, paper is so thin that there are transparency problems (the forms are two-sided) but the biggest problem comes from small paper sheets hiding part of the structure. The evaluation of this system has been made onto 5268 images and the results show that the system did not make any mistake. Moreover it can recognize the entire structure in 97.2% of the forms (the other 2.8% are automatically set apart)."
            },
            "slug": "A-real-world-evaluation-of-a-generic-document-to-a-Co\u00fcasnon-Pasquer",
            "title": {
                "fragments": [],
                "text": "A real-world evaluation of a generic document recognition method applied to a military form of the 19th century"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A specific light grammar is presented to automatically recognize quite damaged 19th century military forms to build an automatic generator of structured document recognition systems."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73133324"
                        ],
                        "name": "C. Brisset",
                        "slug": "C.-Brisset",
                        "structuredName": {
                            "firstName": "Corinne",
                            "lastName": "Brisset",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Brisset"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "Moreover, the parser produced by compilation of an EPF description is written in LambdaProlog [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10213034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7da7b3b4cb4ff262691863e5104c975d3f67b1b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Optical Music Recognition is a particular form of document analysis in which there is much knowledge about document structure. Indeed there exists an important set of rules for musical notation, but current systems do not fully use them. We propose a new solution using a grammar to guide the segmentation of the graphical objects and their recognition. The grammar is essentially a description of the relations (relative position and size, adjacency, etc) between the graphical objects. Inspired by Deenite Clause Grammar techniques, the grammar can be directly implemented in Prolog, a higher-order dialect of Prolog. Moreover, the translation from the grammar into Prolog code can be done automatically. Our approach is justiied by the rst encouraging results obtained with a prototype for music score recognition."
            },
            "slug": "Using-Logic-Programming-Languages-For-Optical-Music-Brisset",
            "title": {
                "fragments": [],
                "text": "Using Logic Programming Languages For Optical Music Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new solution using a grammar to guide the segmentation of the graphical objects and their recognition, inspired by Deenite Clause Grammar techniques and directly implemented in Prolog, a higher-order dialect of Prolog."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 227
                            }
                        ],
                        "text": "Various systems have been proposed to detect columns, lines and headers: graph representation of cells relationship [28, 31], probability optimisation on distance between text blocks [32], heuristics on block text organization [30], three different approach for each element in [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14091058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "971af881cefc0bccb7f47046095d0a92f0de3152",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a prototype system for assigning table cells to their proper place in the logical structure of the table, based on a simple model of table structure combined with a number of measures of cohesion between cells. A framework is presented for examining the effect of particular variables on the performance of the system, and preliminary results are presented showing the effect of cohesion measures based on the simplest domain-independent analyses, with the aim allowing future comparison with more knowledge-intensive analyses based on natural language processing. These baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as we require. Future work will pursue the aim of more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells."
            },
            "slug": "Layout-and-language:-preliminary-investigations-in-Hurst-Douglas",
            "title": {
                "fragments": [],
                "text": "Layout and language: preliminary investigations in recognizing the structure of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "B baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as it is suggested that more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells are needed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072955333"
                        ],
                        "name": "Pascal Garcia",
                        "slug": "Pascal-Garcia",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 204
                            }
                        ],
                        "text": "By only changing the EPF grammar, and by training a classifier when needed, we produced automatically by compilation various recognition systems: one for musical scores [3], one for mathematical formulae [5], and one to recognize tennis courts in videos [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 191
                            }
                        ],
                        "text": "With EPF and its associated parser, we have already been able to produce various recognition systems on different kinds of document: one for musical scores [3], one for mathematical formulae [5], and one to recognize tennis courts in videos [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 447079,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccac6f5abc46289d5f4a8cf344f3fc048f292d60",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present in this paper how to apply to mathematical formulae a generic recognition method already used for musical scores, table structure and old forms recognition. We propose to use this method to recognize the structure of formulae and also to recognize some symbols made of line segments. This offers two possibilities: improving the symbol recognition when there is a lot of symbols like in mathematics; and overcoming segmentation problems we usually find in old mathematical formulae."
            },
            "slug": "Using-a-Generic-Document-Recognition-Method-for-Garcia-Co\u00fcasnon",
            "title": {
                "fragments": [],
                "text": "Using a Generic Document Recognition Method for Mathematical Formulae Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper proposes to use a generic recognition method already used for musical scores, table structure and old forms recognition to recognize the structure of formulae and also to recognize some symbols made of line segments."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "Some methods (for example [22, 23]) use a lowlevel detection of specific points like crossings, corners, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27626504,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b8ec3847c2cdbb50aca64d310703b5d89c81a4b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework of four-layer recognition processes is proposed for understanding documents, and a knowledge representation method adaptable to the understanding of table-form documents is addressed. Although Y. Nakano et al. (1986) looked upon the recognition of multi-kinds of table-form documents as an important subject from a practical point of view, they could not report any successful approach because their knowledge was based only on the physical coordinate data. In the approach presented, this recognition issue was solved, using both the classification tree based on the physical characteristics and the structure description tree based on the logical characteristics. At least, it is not so difficult to classify various kinds of documents into appropriate document classes since table-form documents are well designed on the basis of vertical and horizontal line segments. However, it is not easy in the case of the other documents because the geometric and spatial characteristics of documents are not well specified. It is necessary to investigate the application techniques for the other documents from the viewpoint of the knowledge representation.<<ETX>>"
            },
            "slug": "Toward-a-practical-document-understanding-of-its-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Toward a practical document understanding of table-form documents: its framework and knowledge representation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A framework of four-layer recognition processes is proposed for understanding documents, and a knowledge representation method adaptable to the understanding of table-form documents is addressed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145470231"
                        ],
                        "name": "Kwan Y. Wong",
                        "slug": "Kwan-Y.-Wong",
                        "structuredName": {
                            "firstName": "Kwan",
                            "lastName": "Wong",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwan Y. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34896449"
                        ],
                        "name": "R. Casey",
                        "slug": "R.-Casey",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Casey",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Casey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1880661"
                        ],
                        "name": "F. Wahl",
                        "slug": "F.-Wahl",
                        "structuredName": {
                            "firstName": "Friedrich",
                            "lastName": "Wahl",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wahl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15921038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7abca302c74d2f5adfd323a28e26d40b019df2b5",
            "isKey": false,
            "numCitedBy": 594,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines the requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing. Several critical functions have been investigated and the technical approaches are discussed. The first is the segmentation and classification of digitized printed documents into regions of text and images. A nonlinear, run-length smoothing algorithm has been used for this purpose. By using the regular features of text lines, a linear adaptive classification scheme discriminates text regions from others. The second technique studied is an adaptive approach to the recognition of the hundreds of font styles and sizes that can occur on printed documents. A preclassifier is constructed during the input process and used to speed up a well-known pattern-matching method for clustering characters from an arbitrary print source into a small sample of prototypes. Experimental results are included."
            },
            "slug": "Document-Analysis-System-Wong-Casey",
            "title": {
                "fragments": [],
                "text": "Document Analysis System"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The requirements and components for a proposed Document Analysis System, which assists a user in encoding printed documents for computer processing, are outlined and several critical functions have been investigated and the technical approaches are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IBM J. Res. Dev."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700821"
                        ],
                        "name": "F. Esposito",
                        "slug": "F.-Esposito",
                        "structuredName": {
                            "firstName": "Floriana",
                            "lastName": "Esposito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Esposito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738657"
                        ],
                        "name": "D. Malerba",
                        "slug": "D.-Malerba",
                        "structuredName": {
                            "firstName": "Donato",
                            "lastName": "Malerba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Malerba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145091756"
                        ],
                        "name": "Francesca A. Lisi",
                        "slug": "Francesca-A.-Lisi",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Lisi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesca A. Lisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "WISDOM++ [8] is a learning system for logical and physical structure of a document."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1542143,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f23b61f04d450ffc49ec6371bb5b30d198cdc5b",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A paper document processing system is an information system component which transforms information on printed or handwritten documents into a computer-revisable form. In intelligent systems for paper document processing this information capture process is based on knowledge of the specific layout and logical structures of the documents. This article proposes the application of machine learning techniques to acquire the specific knowledge required by an intelligent document processing system, named WISDOM++, that manages printed documents, such as letters and journals. Knowledge is represented by means of decision trees and first-order rules automatically generated from a set of training documents. In particular, an incremental decision tree learning system is applied for the acquisition of decision trees used for the classification of segmented blocks, while a first-order learning system is applied for the induction of rules used for the layout-based classification and understanding of documents. Issues concerning the incremental induction of decision trees and the handling of both numeric and symbolic data in first-order rule learning are discussed, and the validity of the proposed solutions is empirically evaluated by processing a set of real printed documents."
            },
            "slug": "Machine-Learning-for-Intelligent-Processing-of-Esposito-Malerba",
            "title": {
                "fragments": [],
                "text": "Machine Learning for Intelligent Processing of Printed Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This article proposes the application of machine learning techniques to acquire the specific knowledge required by an intelligent document processing system, named WISDOM++, that manages printed documents, such as letters and journals."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Intelligent Information Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3044309"
                        ],
                        "name": "M. Middendorf",
                        "slug": "M.-Middendorf",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Middendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Middendorf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059933492"
                        ],
                        "name": "Carsten Peust",
                        "slug": "Carsten-Peust",
                        "structuredName": {
                            "firstName": "Carsten",
                            "lastName": "Peust",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carsten Peust"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075517169"
                        ],
                        "name": "J. Schacht",
                        "slug": "J.-Schacht",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "Schacht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schacht"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Frameworks for document analysis have been presented in [9] (DocMining) or in [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8052958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df8de47abbcce54328e2910f0dd4f4ec00aa0f73",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The advantages of component-based software design have often been emphasized during the last years. This article describes the design and implementation of an object-oriented framework for document recognition systems. We use an operator-workitem-model for integrating numerous software components of various origins and written in different programming languages. This is done by defining two standardized interfaces, namely an operator-interface for the integrated recognition algorithms and a workitem-interface for all in- and output objects of the recognition algorithms. These conditions allow to arrange the operators in any successive order and any complexity to build a complete recognition system. For any choice and relative position of operators integrated, the framework provides facilities for parametrizing, testing and running."
            },
            "slug": "A-Component-Based-Framework-for-Recognition-Systems-Middendorf-Peust",
            "title": {
                "fragments": [],
                "text": "A Component-Based Framework for Recognition Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The design and implementation of an object-oriented framework for document recognition systems using an operator-workitem-model for integrating numerous software components of various origins and written in different programming languages is described."
            },
            "venue": {
                "fragments": [],
                "text": "Reading and Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2602600"
                        ],
                        "name": "Serdar G\u00f6kkus",
                        "slug": "Serdar-G\u00f6kkus",
                        "structuredName": {
                            "firstName": "Serdar",
                            "lastName": "G\u00f6kkus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serdar G\u00f6kkus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42252433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea049d0fc3995977b52c10be08fc288789b86ac1",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents. Searching for a set of known table headers (approach 1) works rather well in a significant number of documents. But this approach (though it is implemented tolerant to OCR errors) is not tolerant enough towards some kinds of even minor aberrations. This not only decreases the recognition results, but also, even worse, makes users feel uncomfortable. Pragmatically trying to mimic for what the human eyes might key, leads to our two further, complementary approaches: searching for layout structures which resemble parts of columns (approach 2), and searching for groupings of similar lines (approach 3). The suitability of the approaches for our system requires them to be very simple to implement and simple to explain to users, computationally cheap, and combinable. In the domain of health insurances who receive huge amounts of so called medical liquidations on a daily basis we obtain very good results. On document samples representative for the every day practice of five customers-health insurance companies-tables were spotted as good and as fast as the customers expected the system to be. We thus consider our current approaches as a step towards cognitive adequacy."
            },
            "slug": "Three-approaches-to-\"industrial\"-table-spotting-Klein-G\u00f6kkus",
            "title": {
                "fragments": [],
                "text": "Three approaches to \"industrial\" table spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper introduces three approaches for an industrial, comprehensive document analysis system to enable it to spot tables in documents, and considers the current approaches as a step towards cognitive adequacy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143826881"
                        ],
                        "name": "J. Llad\u00f3s",
                        "slug": "J.-Llad\u00f3s",
                        "structuredName": {
                            "firstName": "Josep",
                            "lastName": "Llad\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Llad\u00f3s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727972"
                        ],
                        "name": "Young-Bin Kwon",
                        "slug": "Young-Bin-Kwon",
                        "structuredName": {
                            "firstName": "Young-Bin",
                            "lastName": "Kwon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Young-Bin Kwon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31083320,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a99e32ee1aebf0b2b0812495f2e70ea306a8557a",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present different strategies for localization and recognition of graphical entities in line drawings. Most systems include first a segmentation step of the document followed by a sequential extraction of the graphical entities. Some other systems try to recognize symbols directly on the bitmap image using more or less sophisticated techniques. In our system, an intermediate representation of the document provides a precise description of all the shapes present in the initial image. Thereafter, this representation constitutes the main part of a shared resource that will be used by different processes achieving the interpretation of the drawings. The actions (recognition) done by these different specialists are scheduled in order to read and understand the content of the document. The knowledge that is provided by the shared representation is used instead of the bitmap image material to drive the interpretation process. In the current system, the specialists are trying, during several cycles to interpret the drawings in an intelligent way by interpreting the simplest parts of a drawing first and making the shared representation evolve until the total understanding of the document."
            },
            "slug": "Graphics-Recognition.-Recent-Advances-and-Llad\u00f3s-Kwon",
            "title": {
                "fragments": [],
                "text": "Graphics Recognition. Recent Advances and Perspectives"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "In this system, an intermediate representation of the document provides a precise description of all the shapes present in the initial image that constitutes the main part of a shared resource that will be used by different processes achieving the interpretation of the drawings."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133943"
                        ],
                        "name": "Ann Grbavec",
                        "slug": "Ann-Grbavec",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Grbavec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann Grbavec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "They have been used for example on musical scores and mathematical formulae recognition [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33241949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0826c4264d6f20e871b1c9e7298e4fbaf4cb7799",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates graph rewriting as a tool for high-level recognition of two-dimensional mathematical notation. \"High-level recognition\" is the process of determining the meaning of a diagram from the output of a symbol recognizer. Characteristic problems of high-level mathematics recognition include: determining the groupings of symbols into recursive subexpressions and resolving ambiguities that depend upon global context. Our graph-rewriting approach uses knowledge of the notational conventions of mathematics, such as operator precedence and operator range, more effectively than syntactic or previous structural methods. Graph rewriting offers a flexible formalism with a strong theoretical foundation for manipulating two-dimensional patterns. It has been shown to be a useful technique for high-level recognition of circuit diagrams and musical scores. By demonstrating a graph-rewriting strategy for mathematics recognition, this paper provides further evidence for graph rewriting as a general tool for diagram recognition, and identifies some of the issues that must be considered as this potential is explored."
            },
            "slug": "Mathematics-recognition-using-graph-rewriting-Grbavec-Blostein",
            "title": {
                "fragments": [],
                "text": "Mathematics recognition using graph rewriting"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper provides further evidence for graph rewriting as a general tool for diagram recognition, and identifies some of the issues that must be considered as this potential is explored."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686714"
                        ],
                        "name": "Kazuhiko Yamamoto",
                        "slug": "Kazuhiko-Yamamoto",
                        "structuredName": {
                            "firstName": "Kazuhiko",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazuhiko Yamamoto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20661771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ceaabecf9e51ea41133eee63abea62f5e469200",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Document image analysis is the automatic computer interpretation of images of printed and handwritten documents, including text, drawings, maps, music scores, etc. Research in this field supports a rapidly growing international industry. This is the first book to offer a broad selection of state-of-the-art research papers, including authoritative critical surveys of the literature, and parallel studies of the architectureof complete high-performance printed-document reading systems. A unique feature is the extended section on music notation, an ideal vehicle for international sharing of basic research. Also, the collection includes important new work on line drawings, handwriting, character and symbol recognition, and basic methodological issues. The IAPR 1990 Workshop on Syntactic and Structural Pattern Recognition is summarized,including the reports of its expert working groups, whose debates provide a fascinating perspective on the field. The book is an excellent text for a first-year graduate seminar in document image analysis,and is likely to remain a standard reference in the field for years."
            },
            "slug": "Structured-Document-Image-Analysis-Baird-Bunke",
            "title": {
                "fragments": [],
                "text": "Structured Document Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This is the first book to offer a broad selection of state-of-the-art research papers, including authoritative critical surveys of the literature, and parallel studies of the architecture of complete high-performance printed-document reading systems."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060810463"
                        ],
                        "name": "Akira Amano",
                        "slug": "Akira-Amano",
                        "structuredName": {
                            "firstName": "Akira",
                            "lastName": "Amano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akira Amano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2406896"
                        ],
                        "name": "Naoki Asada",
                        "slug": "Naoki-Asada",
                        "structuredName": {
                            "firstName": "Naoki",
                            "lastName": "Asada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naoki Asada"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "A graph grammar has been proposed in [34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7044142,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62018285f077a277c77d58c1e5732c71be58a98d",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Structure analysis of table form document is importantbecause printed documents and also electronical documentsonly provide geometrical layout and lexical information explicitly.To handle these documents automatically, logicalstructure information is necessary. In this paper, we firstpropose a general representation of table form documentbased on XML, which contains both structure and layoutinformation. Next, we present structure analysis systembased on graph grammar which represents document structureknowledge. As the relation between adjacent fields intable form documents become two dimensional, two dimensionalnotation is necessary to denote structural knowledge.Therefore, we adopt two dimensional graph grammar to denotethem. By using grammar notation, we can easily modifyand keep consistency of it, as the rules are relatively simple.Another advantage of using grammar notation is that,it can be used for generating documents only from logicalstructure. Experimental results have shown that the systemsuccessfully analyzed several kinds of table forms."
            },
            "slug": "Graph-grammar-based-analysis-system-of-complex-form-Amano-Asada",
            "title": {
                "fragments": [],
                "text": "Graph grammar based analysis system of complex table form document"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A general representation of table form document based on XML, which contains both structure and layout information and a structure analysis system based on graph grammar which represents document structureknowledge is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879397"
                        ],
                        "name": "D. Warren",
                        "slug": "D.-Warren",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warren",
                            "middleNames": [
                                "H.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Warren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2133116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbc04a1951003ba164303b2898fb7f3c6b4e9083",
            "isKey": false,
            "numCitedBy": 1034,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Definite-Clause-Grammars-for-Language-Analysis-A-of-Pereira-Warren",
            "title": {
                "fragments": [],
                "text": "Definite Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 99
                            }
                        ],
                        "text": "If we have a look in the literature, we can find many methods for analysing table-forms structures [20, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30699745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd207fa19e51db1d6eadb0e5e70f1c5b8d1ecd0",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are the only acceptable means of communicating certain types of structured data. A precise definition of \"tabularity\" remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Although most research to date has addressed the extraction of low-level geometric information from scanned raster images of paper tables, the recent trend toward the analysis of tables in electronic form may pave the way to a higherl evel of table understanding. \n \nRecent research on table composition and table analysis has improved ourunde rstanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display. \n \nAlthough tables are not a conventional format for conveying the primary content of technical papers, here we attempt to subdue our natural garrulity by adopting this genre to communicate what we have to say about tables entirely in tabular form."
            },
            "slug": "A-Tabular-Survey-of-Automated-Table-Processing-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "A Tabular Survey of Automated Table Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719698"
                        ],
                        "name": "M. Crucianu",
                        "slug": "M.-Crucianu",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Crucianu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Crucianu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145645182"
                        ],
                        "name": "N. Vincent",
                        "slug": "N.-Vincent",
                        "structuredName": {
                            "firstName": "Nicole",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38138508"
                        ],
                        "name": "C. Faure",
                        "slug": "C.-Faure",
                        "structuredName": {
                            "firstName": "Claudie",
                            "lastName": "Faure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 116
                            }
                        ],
                        "text": "Various systems have been proposed to detect columns, lines and headers: graph representation of cells relationship [28, 31], probability optimisation on distance between text blocks [32], heuristics on block text organization [30], three different approach for each element in [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18293386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "275d79256336a53141e6602d5fdf736139e90b8f",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We are concerned with the extraction of tables from exchange format representations of very diverse composite documents. We put forward a flexible representation scheme for complex tables, based on a clear distinction between the physical layout of a table and its logical structure. Relying on this scheme, we develop a new method for the detection and the extraction of tables by an analysis of the graphic lines. To deal with tables that lack all or most of the graphic marks, one must focus on the regularities of the text elements alone. We propose such a method, based on a multi-level analysis of the layout of text components on a page. A general graph representation of the relative positions of blocks of text is exploited."
            },
            "slug": "Detection,-extraction-and-representation-of-tables-Ramel-Crucianu",
            "title": {
                "fragments": [],
                "text": "Detection, extraction and representation of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A flexible representation scheme for complex tables is put forward, based on a clear distinction between the physical layout of a table and its logical structure, and a new method for the detection and the extraction of tables by an analysis of the graphic lines is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143772136"
                        ],
                        "name": "O. Hori",
                        "slug": "O.-Hori",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Hori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Hori"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Some authors, like in [24], proposed to work on a reduced image to be able to deal with those broken rulings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2750254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92e74fde9c613dd22c193bb11d889d7a0428bced",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Table form document structure analysis is an important problem in the document processing domain. The paper presents a method called Box Driven Reasoning (BDR) to robustly analyze the structure of table form documents which include touching characters and broken lines. Most previous methods employ a line oriented approach. Real documents are copied repeatedly and overlaid with printed data, resulting in characters which touch cells and lines which are broken. BDR deals with regions directly, in contrast with other previous methods. Experimental tests show that BDR reliably recognizes cells and strings in document images with touching characters and broken lines."
            },
            "slug": "Robust-table-form-structure-analysis-based-on-Hori-Doermann",
            "title": {
                "fragments": [],
                "text": "Robust table-form structure analysis based on box-driven reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method called Box Driven Reasoning (BDR) is presented to robustly analyze the structure of table form documents which include touching characters and broken lines."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2203954"
                        ],
                        "name": "Markus Junker",
                        "slug": "Markus-Junker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Junker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Junker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2933102"
                        ],
                        "name": "A. Weisbecker",
                        "slug": "A.-Weisbecker",
                        "structuredName": {
                            "firstName": "Anette",
                            "lastName": "Weisbecker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weisbecker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60747020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29627201626f084d3d99ddf8b5fa7d63b812aa61",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Error Tolerant Color Deskew.- Adaptive Threshold.- Neighbourhood Related Color Segmentation Based on a Fuzzy Color Classification TooL.- Improving Image Processing Systems by Artificial Neural Networks.- Adaptive Segmentation of Multicoloured Documents without a Marked Background.- Recognition of Short Handwritten Texts.- Handwritten Address Recognition Using Hidden Markov Models.- Adaptive Combination of Commercial OCR Systems.- Component-Based Software Engineering Methods for Systems in Document Recognition, Analysis, and Understanding.- A Component-Based Framework for Recognition Systems.- smartFIX: An Adaptive System for Document Analysis and Understanding.- How Postal Address Readers Are Made Adaptive.- A Tool for Semi-automatic Document Reengineering.- Inspecting Document Collections.- Introducing Query Expansion Methods for Collaborative Information Retrieval.- Improving Document Transformation Techniques with Collaborative Learned Term-Based Concepts.- Passage Retrieval Based on Density Distributions of Terms and Its Applications to Document Retrieval and Question Answering.- Results of a Survey about the Use of Tools in the Area of Document Management."
            },
            "slug": "Reading-and-Learning:-Adaptive-Content-Recognition-Dengel-Junker",
            "title": {
                "fragments": [],
                "text": "Reading and Learning: Adaptive Content Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work discusses Adaptive Segmentation of Multicoloured Documents without a Marked Background, and Improving Document Transformation Techniques with Collaborative Learned Term-Based Concepts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789181"
                        ],
                        "name": "Bertrand Co\u00fcasnon",
                        "slug": "Bertrand-Co\u00fcasnon",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Co\u00fcasnon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bertrand Co\u00fcasnon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126026"
                        ],
                        "name": "I. Leplumey",
                        "slug": "I.-Leplumey",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Leplumey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Leplumey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Moreover, we defined a platform for managing all annotations produced by document image analysis [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 281
                            }
                        ],
                        "text": "The genericity of this method has been validated by the number of kinds of documents it has been applied on: musical scores, mathematical formulae, recursive table structures, archives documents like military forms of the 19th century or naturalization decrees of the 19th century [36], and even tennis courts in videos."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 278
                            }
                        ],
                        "text": "Various systems have been proposed to detect columns, lines and headers: graph representation of cells relationship [28, 31], probability optimisation on distance between text blocks [32], heuristics on block text organization [30], three different approach for each element in [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12428873,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd2acea5b2e9a57874ccfaf75b773facec6af266",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present annotations needed for handwritten archive document retrieval by content. We propose two complementary ways of producing those annotations: automatically by using document image analysis and collectively by using Internet and a manual input by users. A platform for managing those annotations is presented as well as examples of automatic annotations on civil status registers, military forms (tested on 60000 pages) and naturalization decrees, using a generic document recognition method. Examples of collective annotations built on automatic annotations are also given. This platform will be officially open to public on Internet and inside the new building of the Archives departementales des Yvelines in December 2003. 1200000 images of civil status registers will be available for collective annotation as well as 35000 pages of military forms with automatic annotation of handwritten names."
            },
            "slug": "Making-handwritten-archives-documents-accessible-to-Co\u00fcasnon-Camillerapp",
            "title": {
                "fragments": [],
                "text": "Making handwritten archives documents accessible to public with a generic system of document image analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A platform for managing annotations needed for handwritten archive document retrieval by content is presented as well as examples of automatic annotations on civil status registers, military forms and naturalization decrees, using a generic document recognition method."
            },
            "venue": {
                "fragments": [],
                "text": "First International Workshop on Document Image Analysis for Libraries, 2004. Proceedings."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809138"
                        ],
                        "name": "D. Searls",
                        "slug": "D.-Searls",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Searls",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Searls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144799688"
                        ],
                        "name": "S. Taylor",
                        "slug": "S.-Taylor",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Liebowitz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Taylor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "If we compare these backup operators with the position operator (@) in Prolog (used for example in [18]), they are much more powerful thanks to two elements:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60244805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cf9658b78d3c63404026c7b4c47ea52342a0636",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Logic grammars such as Definite Clause Grammars \u2014 linguistic formalisms closely associated with the Prolog language \u2014 are powerful and highly versatile systems for specifying and detecting patterns not only in natural language, but in any suitably organized string, signal, or image. This paper reviews several such prototypes we have developed, which demonstrate the characteristics that make logic grammars a good vehicle for many Syntactic Pattern Recognition applications."
            },
            "slug": "Document-Image-Analysis-Using-Logic-Grammar-Based-Searls-Taylor",
            "title": {
                "fragments": [],
                "text": "Document Image Analysis Using Logic-Grammar-Based Syntactic Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Several prototypes of Definite Clause Grammars are reviewed, which demonstrate the characteristics that make logic grammars a good vehicle for many Syntactic Pattern Recognition applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072254465"
                        ],
                        "name": "John L. Pfaltz",
                        "slug": "John-L.-Pfaltz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Pfaltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John L. Pfaltz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056010918"
                        ],
                        "name": "Azriel Rosenfeld",
                        "slug": "Azriel-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Azriel Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "Trees and Web grammars [13, 14] offer a limited expressiveness with a quite complex syntax as production rules have to be build with trees."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 46687960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1dcbd450fc6b2b49c733125d9bda578df0537f77",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Classes of \"phrase-structure grammars\" are defined whose \"languages\" consist, not of strings of symbols, but of directed graphs with symbols at their vertices (\"webs\"). Examples of such \"web grammars\" are given, having languages consisting of trees, of two-terminal series-parallel networks, and of \"triangular\" networks. It is shown that if the graphs permitted in a \"context-sensitive\" web grammar are required to be acyclic, and the parsing rules are assumed to be graph homomorphisms, then any sub-graph which is parsed by a rule must be \"convex\", and any rule is a composite of rules each of which parses a subgraph having just two points. Foreword Since the early 1960's, considerable effort has been devoted to the problem of developing formal \"picture languages\" whose \"sentences\" are pictures of various types. This work (see^ for a recent survey) can be thought of as generalizing the concepts and methods of mathematical linguistics from conventional languages, in which sentences are strings formed by concatenating symbols, to \"languages\" in which \"sentences\" are formed by combining symbols in more general ways. The present paper describes a method of defining \"languages\" whose \"sentences\" are directed graphs with symbols at their vertices."
            },
            "slug": "Web-Grammars-Pfaltz-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Web Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A method of defining \"languages\" whose \"sentences\" are directed graphs with symbols at their vertices is described, showing that if the graphs permitted in a \"context-sensitive\" web grammar are required to be acyclic, and the parsing rules are assumed to be graph homomorphisms, then any sub-graph which is parsed by a rule must be \"convex\"."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143680806"
                        ],
                        "name": "S\u00e9bastien Adam",
                        "slug": "S\u00e9bastien-Adam",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36697096"
                        ],
                        "name": "M. Rigamonti",
                        "slug": "M.-Rigamonti",
                        "structuredName": {
                            "firstName": "Maurizio",
                            "lastName": "Rigamonti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rigamonti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47793609"
                        ],
                        "name": "E. Clavier",
                        "slug": "E.-Clavier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Clavier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Clavier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35863204"
                        ],
                        "name": "\u00c9. Trupin",
                        "slug": "\u00c9.-Trupin",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Trupin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Trupin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695766"
                        ],
                        "name": "J. Ogier",
                        "slug": "J.-Ogier",
                        "structuredName": {
                            "firstName": "Jean-Marc",
                            "lastName": "Ogier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ogier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795288"
                        ],
                        "name": "K. Tombre",
                        "slug": "K.-Tombre",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Tombre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tombre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3337129"
                        ],
                        "name": "J. Gardes",
                        "slug": "J.-Gardes",
                        "structuredName": {
                            "firstName": "Jo\u00ebl",
                            "lastName": "Gardes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gardes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Frameworks for document analysis have been presented in [9] (DocMining) or in [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26908097,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e80e441025ba0e4aea87a022a1ed9752d9884f8",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present DocMining, a general framework that allows the construction of scenarios dedicated to document image processing. The framework is the result of the collaboration between four academic partners and one industrial partner. The main issues of DocMining are the description and the execution of document analysis scenarios. The explicit declaration of scenarios and the plug-ins oriented approach of the framework allow to integrate easily new Document Processing Units and to create new application prototypes. Moreover, this paper highlights the interest of the platform to solve the problem of performance evaluation."
            },
            "slug": "DocMining:-A-Document-Analysis-System-Builder-Adam-Rigamonti",
            "title": {
                "fragments": [],
                "text": "DocMining: A Document Analysis System Builder"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "DocMining is a general framework that allows the construction of scenarios dedicated to document image processing and the description and the execution of document analysis scenarios that allow to integrate easily new Document Processing Units and to create new application prototypes."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145695526"
                        ],
                        "name": "S. Mao",
                        "slug": "S.-Mao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] consider that document structure analysis systems have been limited mainly because:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6128200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "633fd1e2bd089c2c402244037876e879861d6739",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Document structure analysis can be regarded as a syntactic analysis problem. The order and containment relations among the physical or logical components of a document page can be described by an ordered tree structure and can be modeled by a tree grammar which describes the page at the component level in terms of regions or blocks. This paper provides a detailed survey of past work on document structure analysis algorithms and summarize the limitations of past approaches. In particular, we survey past work on document physical layout representations and algorithms, document logical structure representations and algorithms, and performance evaluation of document structure analysis algorithms. In the last section, we summarize this work and point out its limitations."
            },
            "slug": "Document-structure-analysis-algorithms:-a-survey-Mao-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Document structure analysis algorithms: a literature survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper provides a detailed survey of past work on document structure analysis algorithms and summarize the limitations of past approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34996245"
                        ],
                        "name": "B. Klein",
                        "slug": "B.-Klein",
                        "structuredName": {
                            "firstName": "Bertin",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710090"
                        ],
                        "name": "Andreas Fordan",
                        "slug": "Andreas-Fordan",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fordan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fordan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "We can find some examples like smartFix [6], which offers an industrial framework for designing new recognition systems through a graphical interface."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40170629,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f71d3b73757f19ce6be1fcc7c236b5ff2bce795",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The internet is certainly a wide-spread platform for information interchange today and the semantic web actually seems to become more and more real. However, day-to-day work in companies still necessitates the laborious, manual processing of huge amounts of printed documents. This article presents the system smartFIX, a document analysis and understanding system developed by the DFKI spin-off insiders. During the research project \u201cadaptive Read\u201d, funded by the German ministry for research, BMBF, smartFIX was fundamentally developed to a higher maturity level, with a focus on adaptivity. The system is able to extract information from documents \u2013 documents ranging from fixed format forms to unstructured letters of many formats. Apart from the architecture, the main components and the system characteristics, we also show some results from the application of smartFIX to representative samples of medical bills and prescriptions."
            },
            "slug": "smartFIX:-An-Adaptive-System-for-Document-Analysis-Klein-Dengel",
            "title": {
                "fragments": [],
                "text": "smartFIX: An Adaptive System for Document Analysis and Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The system smartFIX, a document analysis and understanding system developed by the DFKI spin-off insiders, is presented, able to extract information from documents \u2013 documents ranging from fixed format forms to unstructured letters of many formats."
            },
            "venue": {
                "fragments": [],
                "text": "Reading and Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 99
                            }
                        ],
                        "text": "If we have a look in the literature, we can find many methods for analysing table-forms structures [20, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14319498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e4c5aa32fd8180d336ce2b6ea8bf3194678636",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables, and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-Survey-of-Table-Recognition-:-Models-,-,-,-and-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A Survey of Table Recognition : Models , Observations , Transformations , and Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054387644"
                        ],
                        "name": "Hartmut Sch\u00e4fer",
                        "slug": "Hartmut-Sch\u00e4fer",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Sch\u00e4fer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartmut Sch\u00e4fer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47530341"
                        ],
                        "name": "T. Bayer",
                        "slug": "T.-Bayer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145109567"
                        ],
                        "name": "Klaus-Peter Kreuzer",
                        "slug": "Klaus-Peter-Kreuzer",
                        "structuredName": {
                            "firstName": "Klaus-Peter",
                            "lastName": "Kreuzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus-Peter Kreuzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711285"
                        ],
                        "name": "U. Miletzki",
                        "slug": "U.-Miletzki",
                        "structuredName": {
                            "firstName": "Udo",
                            "lastName": "Miletzki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Miletzki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792378"
                        ],
                        "name": "M. Schambach",
                        "slug": "M.-Schambach",
                        "structuredName": {
                            "firstName": "Marc-Peter",
                            "lastName": "Schambach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schambach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403234644"
                        ],
                        "name": "Matthias Schulte-Austum",
                        "slug": "Matthias-Schulte-Austum",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schulte-Austum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Schulte-Austum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [7] is presented a way a postal address readers is made adaptive."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 45587414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "045e3cd15ea636f8394b4429418b1a8391aac6b2",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In the following chapter we describe how a postal address reader is made adaptive. A postal address reader is a huge application, so we concentrate on technologies used to adapt it to a few important tasks. In particular, we describe adaptation strategies for the detectors and classifiers of regions of interest (ROI), for the classifiers for single character recognition, for a hidden Markov recogniser for hand written words and for the address dictionary of the reader. The described techniques have been deployed in all postal address reading applications, including parcel, flat, letter and in-house mail sorting."
            },
            "slug": "How-Postal-Address-Readers-Are-Made-Adaptive-Sch\u00e4fer-Bayer",
            "title": {
                "fragments": [],
                "text": "How Postal Address Readers Are Made Adaptive"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The following chapter describes adaptation strategies for the detectors and classifiers of regions of interest (ROI), for the classifiers for single character recognition, for a hidden Markov recogniser for hand written words and for the address dictionary of the reader."
            },
            "venue": {
                "fragments": [],
                "text": "Reading and Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1813168"
                        ],
                        "name": "Heath E. Nielson",
                        "slug": "Heath-E.-Nielson",
                        "structuredName": {
                            "firstName": "Heath",
                            "lastName": "Nielson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heath E. Nielson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144055367"
                        ],
                        "name": "W. Barrett",
                        "slug": "W.-Barrett",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Barrett",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Barrett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "On old documents, we only found work done on British and US census [26], but the proposed method is limited to forms with no variation in cells size according to a model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16384589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8098fd7ed3ba9374986339b8da837bababb6e4e1",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Zoning documents increases the resolution of indexingfrom the image level to the field level. A line-delimited tabulardocument forms a well defined series of regions. However,as image quality decreases, accurate zoning becomesincreasingly difficult. Given a sequence of documents withthe same layout, we present a robust zoning method whichexploits both intra- and inter-document consensus to forma more accurate combined result (template) that can be appliedto any other document with the same layout."
            },
            "slug": "Consensus-based-table-form-recognition-Nielson-Barrett",
            "title": {
                "fragments": [],
                "text": "Consensus-based table form recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A robust zoning method is presented that combines both intra- and inter-document consensus to form a more accurate combined result (template) that can be applied to any other document with the same layout."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744200"
                        ],
                        "name": "I. T. Phillips",
                        "slug": "I.-T.-Phillips",
                        "structuredName": {
                            "firstName": "Ihsin",
                            "lastName": "Phillips",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. T. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710238"
                        ],
                        "name": "R. Haralick",
                        "slug": "R.-Haralick",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Haralick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Haralick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 183
                            }
                        ],
                        "text": "Various systems have been proposed to detect columns, lines and headers: graph representation of cells relationship [28, 31], probability optimisation on distance between text blocks [32], heuristics on block text organization [30], three different approach for each element in [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3331857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc8d85dec47348c81d894ff9ea729b28aef88650",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we define the table detection problem as a probability optimization problem. We begin, as we do in our previous algorithm, finding and validating each detected table candidates. We proceed to compute a set of probability measurements for each of the table entities. The computation of the probability measurements takes into consideration tables, table text separators and table neighboring text blocks. Then, an iterative updating method is used to optimize the page segmentation probability to obtain the final result. This new algorithm shows a great improvement over our previous algorithm. The training and testing data set for the algorithm include 1, 125 document pages having 518 table entities and a total of 10, 934 cell entities. Compared with our previous work, it raised the accuracy rate to 95.67% from 90.32% and to 97.05% from 92.04%."
            },
            "slug": "Table-Detection-via-Probability-Optimization-Wang-Phillips",
            "title": {
                "fragments": [],
                "text": "Table Detection via Probability Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper defines the table detection problem as a probability optimization problem, and proceeds to compute a set of probability measurements for each of the table entities, taking into consideration tables, table text separators and table neighboring text blocks."
            },
            "venue": {
                "fragments": [],
                "text": "Document Analysis Systems"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47793609"
                        ],
                        "name": "E. Clavier",
                        "slug": "E.-Clavier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Clavier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Clavier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863336"
                        ],
                        "name": "G. Masini",
                        "slug": "G.-Masini",
                        "structuredName": {
                            "firstName": "G\u00e9rald",
                            "lastName": "Masini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Masini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2313892"
                        ],
                        "name": "Mathieu Delalandre",
                        "slug": "Mathieu-Delalandre",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Delalandre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathieu Delalandre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36697096"
                        ],
                        "name": "M. Rigamonti",
                        "slug": "M.-Rigamonti",
                        "structuredName": {
                            "firstName": "Maurizio",
                            "lastName": "Rigamonti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rigamonti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795288"
                        ],
                        "name": "K. Tombre",
                        "slug": "K.-Tombre",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Tombre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Tombre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3337129"
                        ],
                        "name": "J. Gardes",
                        "slug": "J.-Gardes",
                        "structuredName": {
                            "firstName": "Jo\u00ebl",
                            "lastName": "Gardes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gardes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[11] pointed out, very little work has been done to build really generic tools."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 446529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "580ce57538656aabd2b11eb3229c960b8acdfe39",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The DocMining platform is aimed at providing a general framework for document interpretation. It integrates document processing units coming from different sources and communicating through the document being interpreted. A task to be performed is represented by a scenario that describes the units to be run, and each unit is associated with a contract that describes the parameters, data and results of the unit as well as the way to run it. A controller interprets the scenario and triggers each required document processing unit at its turn. Documents, scenarios and contracts are all represented in XML, to make data manipulation and communications easier."
            },
            "slug": "DocMining:-A-Cooperative-Platform-for-Heterogeneous-Clavier-Masini",
            "title": {
                "fragments": [],
                "text": "DocMining: A Cooperative Platform for Heterogeneous Document Interpretation According to User-Defined Scenarios"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The DocMining platform is aimed at providing a general framework for document interpretation that integrates document processing units coming from different sources and communicating through the document being interpreted."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31743562"
                        ],
                        "name": "Jerome Feder",
                        "slug": "Jerome-Feder",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Feder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jerome Feder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Plex grammars [15] have a less limited expressiveness, as they are a generalization of Tree and Web grammars."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37456288,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "38174f465527ef2140eb5a23e3d2b2d750595b03",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Plex-languages-Feder",
            "title": {
                "fragments": [],
                "text": "Plex languages"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2727972"
                        ],
                        "name": "Young-Bin Kwon",
                        "slug": "Young-Bin-Kwon",
                        "structuredName": {
                            "firstName": "Young-Bin",
                            "lastName": "Kwon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Young-Bin Kwon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19058117,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "0fae6ed25e0e1a38399125e6ab3fa41a6fb03314",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Engineering solutions are generally documented in assembly and part drawings and bill of materials. A great benefit, qualitatively and commercially, can be achieved if these paper based storages can be transformed into digital information archives. The process of this transformation is called reconstruction. The reconstruction process of paper based assembly drawings consists of four steps: digitization; vectorization/interpretation; 3D reconstruction of the parts and the 3D reconstruction of the assembly. This paper evaluates existing commercial systems worldwide for interpretation of paper based mechanical engineering drawings. For a complete reconstruction process a 3D reconstruction is needed. This functionality is already supported by some CAD systems to a certain extent, but it still remains a major topic of research work. One CAD system which converts 2D CAD models into 3D CAD models is presented. Finally, after the reconstruction of the parts the whole assembly can be reconstructed. Until now, no system for the automatic reconstruction of assemblies is available. In our paper we present a general approach for automatic reconstruction of 3D assembly model data by interpretation of mechanical engineering 2D assembly drawings, their part drawings, and the bill of materials."
            },
            "slug": "Graphics-Recognition-Algorithms-and-Applications-Blostein-Kwon",
            "title": {
                "fragments": [],
                "text": "Graphics Recognition Algorithms and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper evaluates existing commercial systems worldwide for interpretation of paper based mechanical engineering drawings and presents a general approach for automatic reconstruction of 3D assembly model data by interpretation of mechanical engineering 2D assembly drawings, their part drawings, and the bill of materials."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144799688"
                        ],
                        "name": "S. Taylor",
                        "slug": "S.-Taylor",
                        "structuredName": {
                            "firstName": "Suzanne",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Liebowitz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1910723"
                        ],
                        "name": "R. Fritzson",
                        "slug": "R.-Fritzson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Fritzson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fritzson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053009875"
                        ],
                        "name": "J. A. Pastor",
                        "slug": "J.-A.-Pastor",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Pastor",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Pastor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "Some methods (for example [22, 23]) use a lowlevel detection of specific points like crossings, corners, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 30846697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e2f122cefaaac07009361797583b41795db6ec3",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The widespread use of printed forms for data acquisition makes the ability to automatically read and analyze their contents desirable. The components of a forms analysis system include conversion from paper to an image through scanning, image enhancement, document identification, data extraction, and data interpretation. This paper describes techniques for manipulating electronic images of forms in preparation for data interpretation. A combination feature extraction/model-based approach is used for forms identification, registration, and field extraction. Forms identification is implemented with a neural network. The system is demonstrated on United States Internal Revenue Service forms."
            },
            "slug": "Extraction-of-data-from-preprinted-forms-Taylor-Fritzson",
            "title": {
                "fragments": [],
                "text": "Extraction of data from preprinted forms"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A combination feature extraction/model-based approach is used for forms identification, registration, and field extraction, and the system is demonstrated on United States Internal Revenue Service forms."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Vision and Applications"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50080463"
                        ],
                        "name": "Xingyuan Li",
                        "slug": "Xingyuan-Li",
                        "structuredName": {
                            "firstName": "Xingyuan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingyuan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153577962"
                        ],
                        "name": "Wen Gao",
                        "slug": "Wen-Gao",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687988"
                        ],
                        "name": "W. Oh",
                        "slug": "W.-Oh",
                        "structuredName": {
                            "firstName": "Weon-Geun",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Oh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[25] proposed a rule-based approach, but this method cannot deal with a partial hiding of the table-form structure like we can have in the military forms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32671429,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "297de7f7bde77cec077eeb691248f2778a63ef07",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a strategy for analyzing unknown, filled forms. First, horizontal and vertical line segments are detected, extracted and filtered. A recursive splitting and merging algorithm eliminates overlapping segments, filters false segments, and groups the segments into lines. Based on the extracted lines, an algorithm for rectangle extraction is proposed. We define the constraints between rectangles and edges. In a process of scanning the horizontal and vertical lines, candidate edges are validated and rectangles are generated if its surrounding edges and their combination are all valid. The process is recursively applied. It can tolerate large breaks in form lines, ignore irrelevant segments and deal with embedded rectangles. Experiments on a collection of forms show that our approach works well on poor quality images."
            },
            "slug": "A-robust-method-for-unknown-forms-analysis-Li-Gao",
            "title": {
                "fragments": [],
                "text": "A robust method for unknown forms analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper proposes a strategy for analyzing unknown, filled forms that can tolerate large breaks in form lines, ignore irrelevant segments and deal with embedded rectangles, and works well on poor quality images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401920887"
                        ],
                        "name": "V. P. d'Andecy",
                        "slug": "V.-P.-d'Andecy",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "d'Andecy",
                            "middleNames": [
                                "Poulain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. P. d'Andecy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760753"
                        ],
                        "name": "J. Camillerapp",
                        "slug": "J.-Camillerapp",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Camillerapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Camillerapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126026"
                        ],
                        "name": "I. Leplumey",
                        "slug": "I.-Leplumey",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Leplumey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Leplumey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "Broken rulings are correctly detected with the help of the line segments extractor [4] at the image level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "\u2022 The equivalent of lexical parsers to detect in the image the terminals: \u2013 for line segments (this extractor [4] uses a Kalman filtering method)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46943912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eec88738b07790df771fd17344ce1d464c348f97",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Many symbols in music scores are linear segments. In this context, we designed an extractor of segments. It is robust towards problems of quality within binary images (scale factor, curvature, bias and noises). It is based on Kalman filtering technique. By splitting music scores into layers of detectable symbols and by applying methodically to the defined layers both this extractor and simple rules of classification for the detected segments, we were able to recognize staves, stems, slurs, beams, bar lines, black note heads and then quarters and note groups."
            },
            "slug": "Kalman-filtering-for-segment-detection:-application-d'Andecy-Camillerapp",
            "title": {
                "fragments": [],
                "text": "Kalman filtering for segment detection: application to music scores analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An extractor of segments based on Kalman filtering technique was able to recognize staves, stems, slurs, beams, bar lines, black note heads and then quarters and note groups in music scores."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34817063"
                        ],
                        "name": "A. Chhabra",
                        "slug": "A.-Chhabra",
                        "structuredName": {
                            "firstName": "Atul",
                            "lastName": "Chhabra",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chhabra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144964966"
                        ],
                        "name": "D. Dori",
                        "slug": "D.-Dori",
                        "structuredName": {
                            "firstName": "Dov",
                            "lastName": "Dori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dori"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10328124,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02bff69bace0e9e2056c50c195693f4fb8d63875",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "As a complement to quantitative evaluation methods for raster\u2013to\u2013graphics conversion, we discuss in this paper some qualitative elements which should be taken into account when choosing the different steps of one\u2019s vectorization method. We stress the importance of having robust methods and stable implementations, and we base ourselves extensively on our own implementations and tests, concentrating on methods designed to have few, if any, parameters."
            },
            "slug": "Graphics-Recognition-Recent-Advances-Chhabra-Dori",
            "title": {
                "fragments": [],
                "text": "Graphics Recognition Recent Advances"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Some qualitative elements which should be taken into account when choosing the different steps of one\u2019s vectorization method are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727287"
                        ],
                        "name": "W. Brainerd",
                        "slug": "W.-Brainerd",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Brainerd",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Brainerd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 23
                            }
                        ],
                        "text": "Trees and Web grammars [13, 14] offer a limited expressiveness with a quite complex syntax as production rules have to be build with trees."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39850406,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0bc5d902e442fcbfacbde541dbee3ddb9c27a5d7",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Tree-Generating-Regular-Systems-Brainerd",
            "title": {
                "fragments": [],
                "text": "Tree Generating Regular Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 116
                            }
                        ],
                        "text": "Various systems have been proposed to detect columns, lines and headers: graph representation of cells relationship [28, 31], probability optimisation on distance between text blocks [32], heuristics on block text organization [30], three different approach for each element in [36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1649340,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a7be096a4ed48b143691bdd2deeae585afebc4d6",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an approach to deriving an abstractgeometric model of a table from a physical representation.The technique developed uses a graph of constraints betweencells which must be satisfied in order to determinetheir relative horizontal and vertical position. The methodis evaluated with a test set of tables drawn from US Securitiesand Exchange Commission (SEC) filings."
            },
            "slug": "A-constraint-based-approach-to-table-structure-Hurst",
            "title": {
                "fragments": [],
                "text": "A constraint-based approach to table structure derivation"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An approach to deriving an abstractgeometric model of a table from a physical representation using a graph of constraints which must be satisfied in order to determinate the relative horizontal and vertical position."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "System for understanding and reformulating tables"
            },
            "venue": {
                "fragments": [],
                "text": "Fourth IAPR International Workshop on Document Analysis Systems, pp. 361\u2013372. Rio de Janeiro, Brazil"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "We choose to extend Definite Clause Grammars (DCG) [17], a formalism for mono-dimensional grammars which can be translated in the Prolog language."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "Moreover, as EPF is an extension of DCG (used for natural language analysis), it is possible to use its ability to define syntactical or semantical knowledge."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Definite clauses for language analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell. 13, 231\u2013278"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "By only changing the EPF grammar, and by training a classifier when needed, we produced automatically by compilation various recognition systems: one for musical scores [3], one for mathematical formulae [5], and one to recognize tennis courts in videos [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 156
                            }
                        ],
                        "text": "With EPF and its associated parser, we have already been able to produce various recognition systems on different kinds of document: one for musical scores [3], one for mathematical formulae [5], and one to recognize tennis courts in videos [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Using grammars to segment and recognize music scores"
            },
            "venue": {
                "fragments": [],
                "text": "Spitz, L., Dengel, A. (eds.) Document Analysis Systems. World Scientific, Singapore"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 18
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/DMOS,-a-generic-document-recognition-method:-to-in-Co\u00fcasnon/72b708230bb11b28682ad55587f960f3a892cfc6?sort=total-citations"
}