{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152736800"
                        ],
                        "name": "M. Smith",
                        "slug": "M.-Smith",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15525071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94c4141cdd7615e8e6fccbfa864abd518a62efd8",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video is rapidly becoming an important source for information, entertainment and a host of multimedia applications. With the size of these collections growing to thousands of hours, technology is needed to effectively browse segments in a short time without losing the content of the video. We propose a method to extract the significant audio and video information and create a \u201cskim\u201d video which represents a short synopsis of the original. The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding. The resulting skim is much smaller, and retains the essential content of the original segment. This research is sponsored by the National Science Foundation under grant no. IRI9411299, the National Space and Aeronautics Administration, and the Advanced Research Projects Agency. The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements, either expressed or implied, of the United States Government."
            },
            "slug": "Video-Skimming-for-Quick-Browsing-based-on-Audio-Smith",
            "title": {
                "fragments": [],
                "text": "Video Skimming for Quick Browsing based on Audio and Image Characterization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The extraction of significant information, such as specific objects, audio keywords and relevant video structure, is made possible through the integration of techniques in image and language understanding and a \u201cskim\u201d video is proposed which represents a short synopsis of the original."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692339"
                        ],
                        "name": "B. Yeo",
                        "slug": "B.-Yeo",
                        "structuredName": {
                            "firstName": "Boon-Lock",
                            "lastName": "Yeo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yeo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108661679"
                        ],
                        "name": "Bede Liu",
                        "slug": "Bede-Liu",
                        "structuredName": {
                            "firstName": "Bede",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bede Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36611702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04142ae104d552672620c88cb9cdbcee33ceb7bc",
            "isKey": false,
            "numCitedBy": 853,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Several rapid scene analysis algorithms for detecting scene changes and flashlight scenes directly on compressed video are proposed. These algorithms operate on the DC sequence which can be readily extracted from video compressed using Motion JPEG or MPEG without full-frame decompression. The DC images occupy only a small fraction of the original data size while retaining most of the essential \"global\" information. Operating on these images offers a significant computation saving. Experimental results show that the proposed algorithms are fast and effective in detecting abrupt scene changes, gradual transitions including fade-ins and fade-outs, flashlight scenes and in deriving intrashot variations."
            },
            "slug": "Rapid-scene-analysis-on-compressed-video-Yeo-Liu",
            "title": {
                "fragments": [],
                "text": "Rapid scene analysis on compressed video"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Experimental results show that the proposed rapid scene analysis algorithms are fast and effective in detecting abrupt scene changes, gradual transitions including fade-ins and fade-outs, flashlight scenes and in deriving intrashot variations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2211839"
                        ],
                        "name": "D. L. Gall",
                        "slug": "D.-L.-Gall",
                        "structuredName": {
                            "firstName": "Didier",
                            "lastName": "Gall",
                            "middleNames": [
                                "J.",
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. L. Gall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 652286,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bafe1e3aba293f978ec0f44599d7d62eca9206c",
            "isKey": false,
            "numCitedBy": 2458,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The Moving Picture Experts Group (MPEG) standard addresses compression of video signals at approximately 1.5M-bits. MPEG is a generic standard and is independent of any particular applications. Applications of compressed video on digital storage media include asymmetric applications such as electronic publishing, games and entertainment. Symmetric applications of digital video include video mail, video conferencing, videotelephone and production of electronic publishing. Design of the MPEG algorithm presents a difficult challenge since quality requirements demand high compression that cannot be achieved with only intraframe coding. The algorithm\u2019s random access requirement, however, is best satisfied with pure intraframe coding. MPEG uses predictive and interpolative coding techniques to answer this challenge. Extensive details are presented."
            },
            "slug": "MPEG:-a-video-compression-standard-for-multimedia-Gall",
            "title": {
                "fragments": [],
                "text": "MPEG: a video compression standard for multimedia applications"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Design of the MPEG algorithm presents a difficult challenge since quality requirements demand high compression that cannot be achieved with only intraframe coding, and the algorithm\u2019s random access requirement is best satisfied with pure intraframes coding."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759584"
                        ],
                        "name": "P. Aigrain",
                        "slug": "P.-Aigrain",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Aigrain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Aigrain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46335846"
                        ],
                        "name": "P. Joly",
                        "slug": "P.-Joly",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Joly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Joly"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205033055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "921164e2a7868dff163789a8b459971266fa91f6",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-automatic-real-time-analysis-of-film-editing-Aigrain-Joly",
            "title": {
                "fragments": [],
                "text": "The automatic real-time analysis of film editing and transition effects and its applications"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph."
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 4,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Visual-content-highlighting-via-automatic-of-on-Yeo-Liu/ac83336e50496b9a75714f1024531fe7d698d33b?sort=total-citations"
}