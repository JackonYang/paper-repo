{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 103
                            }
                        ],
                        "text": "For example, in S \u2192 <NP VP>, S gets its head-word, announced,\n3The rules are essentially the same as in (Magerman 95; Jelinek et al. 94)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "This paper describes a new parser which is much simpler than SPATTER, yet performs at least as well when trained and tested on the same Wall Street Journal data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 203
                            }
                        ],
                        "text": "For a constituent to be \u2018correct\u2019 it must span the same set of words (ignoring punctuation, i.e. all tokens tagged as commas, colons or quotes) and have the same label10 as a constituent in the treebank\n10SPATTER collapses ADVP and PRT to the same label, for comparison we also removed this distinction when\nparse."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 20
                            }
                        ],
                        "text": "The SPATTER parser (Magerman 95; Jelinek et al. 94) does use lexical information, and recovers labeled constituents in Wall Street Journal text with above 84% accuracy \u2013 as far as we know the best published results on this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 68
                            }
                        ],
                        "text": "I would also like to thank David Magerman for his help with testing SPATTER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "For comparison SPATTER (Magerman 95; Jelinek et al. 94) was also tested on section 23."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 608,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0a14be7e7f5614b91d0f648ae5f2baafc6d7036",
            "isKey": true,
            "numCitedBy": 717,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic natural language parsers have shown themselves to be inadequate for processing highly-ambiguous large-vocabulary text, as is evidenced by their poor performance on domains like the Wall Street Journal, and by the movement away from parsing-based approaches to text-processing in general. In this paper, I describe SPATTER, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result. This work is based on the following premises: (1) grammars are too complex and detailed to develop manually for most interesting domains; (2) parsing models must rely heavily on lexical and contextual information to analyze sentences accurately; and (3) existing n-gram modeling techniques are inadequate for parsing models. In experiments comparing SPATTER with IBM's computer manuals parser, SPATTER significantly outperforms the grammar-based parser. Evaluating SPATTER against the Penn Treebank Wall Street Journal corpus using the PARSEVAL measures, SPATTER achieves 86% precision, 86% recall, and 1.3 crossing brackets per sentence for sentences of 40 words or less, and 91% precision, 90% recall, and 0.5 crossing brackets for sentences between 10 and 20 words in length."
            },
            "slug": "Statistical-Decision-Tree-Models-for-Parsing-Magerman",
            "title": {
                "fragments": [],
                "text": "Statistical Decision-Tree Models for Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "SPATTER is described, a statistical parser based on decision-tree learning techniques which constructs a complete parse for every sentence and achieves accuracy rates far better than any published result."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 76
                            }
                        ],
                        "text": "However, early approaches to probabilistic parsing (Pereira and Schabes 92; Magerman and Marcus 91; Briscoe and Carroll 93) conditioned probabilities on non-terminal labels and part of speech tags alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2376935,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da838db79e7593018894ada44db35eee670941d6",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a natural language parsing algorithm for unrestricted text which uses a probability-based scoring function to select the \"best\" parse of a sentence. The parser, Pearl, is a time-asynchronous bottom-up chart parser with Earley-type top-down prediction which pursues the highest-scoring theory in the chart, where the score of a theory represents the extent to which the context of the sentence predicts that interpretation. This parser differs from previous attempts at stochastic parsers in that it uses a richer form of conditional probabilities based on context to predict likelihood. Pearl also provides a framework for incorporating the results of previous work in part-of-speech assignment, unknown word models, and other probabilistic models of linguistic features into one parsing tool, interleaving these techniques instead of using the traditional pipeline architecture. In preliminary tests, Pearl has been successful at resolving part-of-speech and word (in speech processing) ambiguity, determining categories for unknown words, and selecting correct parses first using a very loosely fitting covering grammar."
            },
            "slug": "Pearl:-A-Probabilistic-Chart-Parser-Magerman-Marcus",
            "title": {
                "fragments": [],
                "text": "Pearl: A Probabilistic Chart Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A natural language parsing algorithm for unrestricted text which uses a probability-based scoring function to select the \"best\" parse of a sentence and provides a framework for incorporating the results of previous work in part-of-speech assignment, unknown word models, and other probabilistic models of linguistic features into one parsing tool, interleaving these techniques instead of using the traditional pipeline architecture."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721040"
                        ],
                        "name": "D. Sleator",
                        "slug": "D.-Sleator",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sleator",
                            "middleNames": [
                                "Dominic"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sleator"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335864"
                        ],
                        "name": "D. Temperley",
                        "slug": "D.-Temperley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Temperley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Temperley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 15
                            }
                        ],
                        "text": "Link grammars (Lafferty et al. 92), and dependency grammars in general."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6208015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d3a863b71f093e1cbc9304a3287c1ddc48c6f31",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a new class of language models. This class derives from link grammar, a context-free formalism for the description of natural language. We describe an algorithm for determining maximum-likelihood estimates of the parameters of these models. The language models which we present differ from previous models based on stochastic context-free grammars in that they are highly lexical. In particular, they include the familiar $n$-gram models as a natural subclass. The motivation for considering this class is to estimate the contribution which grammar can make to reducing the relative entropy of natural language."
            },
            "slug": "Grammatical-Trigrams:-A-Probabilistic-Model-of-Link-Lafferty-Sleator",
            "title": {
                "fragments": [],
                "text": "Grammatical Trigrams: A Probabilistic Model of Link Grammar"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An algorithm for determining maximum-likelihood estimates of the parameters of these language models, which include the familiar $n$-gram models as a natural subclass, are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145693410"
                        ],
                        "name": "Ted Briscoe",
                        "slug": "Ted-Briscoe",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Briscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ted Briscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144708726"
                        ],
                        "name": "John A. Carroll",
                        "slug": "John-A.-Carroll",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Carroll",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John A. Carroll"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 100
                            }
                        ],
                        "text": "However, early approaches to probabilistic parsing (Pereira and Schabes 92; Magerman and Marcus 91; Briscoe and Carroll 93) conditioned probabilities on non-terminal labels and part of speech tags alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2220955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ad8e98574a275930bf04a477ce3532fd13c503c",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe work toward the construction of a very wide-coverage probabilistic parsing system for natural language (NL), based on LR parsing techniques. The system is intended to rank the large number of syntactic analyses produced by NL grammars according to the frequency of occurrence of the individual rules deployed in each analysis. We discuss a fully automatic procedure for constructing an LR parse table from a unification-based grammar formalism, and consider the suitability of alternative LALR(1) parse table construction methods for large grammars. The parse table is used as the basis for two parsers; a user-driven interactive system that provides a computationally tractable and labor-efficient method of supervised training of the statistical information required to drive the probabilistic parser. The latter is constructed by associating probabilities with the LR parse table directly. This technique is superior to parsers based on probabilistic lexical tagging or probabilistic context-free grammar because it allows for a more context-dependent probabilistic language model, as well as use of a more linguistically adequate grammar formalism. We compare the performance of an optimized variant of Tomita's (1987) generalized LR parsing algorithm to an (efficiently indexed and optimized) chart parser. We report promising results of a pilot study training on 150 noun definitions from the Longman Dictionary of Contemporary English (LDOCE) and retesting on these plus a further 55 definitions. Finally, we discuss limitations of the current system and possible extensions to deal with lexical (syntactic and semantic) frequency of occurrence."
            },
            "slug": "Generalized-Probabilistic-LR-Parsing-of-Natural-Briscoe-Carroll",
            "title": {
                "fragments": [],
                "text": "Generalized Probabilistic LR Parsing of Natural Language (Corpora) with Unification-Based Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "The construction of a very wide-coverage probabilistic parsing system for natural language (NL) based on LR parsing techniques, intended to rank the large number of syntactic analyses produced by NL grammars according to the frequency of occurrence of the individual rules deployed in each analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067634566"
                        ],
                        "name": "James Brooks",
                        "slug": "James-Brooks",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Brooks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Brooks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc9e5bf851dc95369e26f1869c2637b1d8919e6c",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has considered corpus-based or statistical approaches to the problem of prepositional phrase attachment ambiguity. Typically, ambiguous verb phrases of the form v np1 p np2 are resolved through a model which considers values of the four head words (v, n1, p and n2). This paper shows that the problem is analogous to n-gram language models in speech recognition, and that one of the most common methods for language modeling, the backed-off estimate, is applicable. Results on Wall Street Journal data of 84.5% accuracy are obtained using this method. A surprising result is the importance of low-count events \u2014 ignoring events which occur less than 5 times in training data reduces performance to 81.6%."
            },
            "slug": "Prepositional-Phrase-Attachment-through-a-Model-Collins-Brooks",
            "title": {
                "fragments": [],
                "text": "Prepositional Phrase Attachment through a Backed-off Model"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This paper shows that the problem of prepositional phrase attachment ambiguity is analogous to n-gram language models in speech recognition, and that one of the most common methods for language modeling, the backed-off estimate, is applicable."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2580777"
                        ],
                        "name": "David M. Magerman",
                        "slug": "David-M.-Magerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Magerman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David M. Magerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 37
                            }
                        ],
                        "text": "For comparison SPATTER (Magerman 95; Jelinek et al. 94) was also tested on section 23."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 116
                            }
                        ],
                        "text": "For example, in S \u2192 <NP VP>, S gets its head-word, announced,\n3The rules are essentially the same as in (Magerman 95; Jelinek et al. 94)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 33
                            }
                        ],
                        "text": "The SPATTER parser (Magerman 95; Jelinek et al. 94) does use lexical information, and recovers labeled constituents in Wall Street Journal text with above 84% accuracy \u2013 as far as we know the best published results on this task."
                    },
                    "intents": []
                }
            ],
            "corpusId": 936966,
            "fieldsOfStudy": [
                "Linguistics",
                "Computer Science"
            ],
            "id": "5bfa91e7ec19c6401a763c73f2a2007c04836609",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Parser development is generally viewed as a primarily linguistic enterprise. A grammarian examines sentences, skillfully extracts the linguistic generalizations evident in the data, and writes grammar rules which cover the language. The grammarian then evaluates the performance of the grammar, and upon analysis of the errors made by the grammar-based parser, carefully refines the rules, repeating this process, typically over a period of several years."
            },
            "slug": "Decision-Tree-Parsing-using-a-Hidden-Derivation-Jelinek-Lafferty",
            "title": {
                "fragments": [],
                "text": "Decision Tree Parsing using a Hidden Derivation Model"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The grammarian then evaluates the performance of the grammar, and upon analysis of the errors made by the grammar-based parser, carefully refines the rules, repeating this process, typically over a period of several years."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 139
                            }
                        ],
                        "text": "The tagger performs at around 97% accuracy on Wall Street Journal Text, and is trained on the first 40,000 sentences of the Penn Treebank (Marcus et al. 93)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 100
                            }
                        ],
                        "text": "The parser was trained on sections 02 - 21 of the Wall Street Journal portion of the Penn Treebank (Marcus et al. 93) (approximately 40,000 sentences), and tested on section 23 (2,416 sentences)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 117
                            }
                        ],
                        "text": "Section 2.5 then describes the baseNP model, which uses bigram tagging techniques similar to (Ramshaw and Marcus 95; Church 88)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 67
                            }
                        ],
                        "text": "The method is similar to that described in (Ramshaw and Marcus 95; Church 88), where baseNP detection is also framed as a tagging problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3166885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7e084fe51a40eeaaf79bf0b78e837d5bc4a8e10",
            "isKey": true,
            "numCitedBy": 1058,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written. The program uses a linear-time dynamic programming algorithm to find an assignment of parts of speech to words that optimizes the product of (a) lexical probabilities (probability of observing part of speech i given word i) and (b) contextual probabilities (probability of observing part of speech i given n following parts of speech). Program performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct.<<ETX>>"
            },
            "slug": "A-Stochastic-Parts-Program-and-Noun-Phrase-Parser-Church",
            "title": {
                "fragments": [],
                "text": "A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A program that tags each word in an input sentence with the most likely part of speech has been written and performance is encouraging; a 400-word sample is presented and is judged to be 99.5% correct."
            },
            "venue": {
                "fragments": [],
                "text": "ANLP"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725500"
                        ],
                        "name": "Yves Schabes",
                        "slug": "Yves-Schabes",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Schabes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yves Schabes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "However, early approaches to probabilistic parsing (Pereira and Schabes 92; Magerman and Marcus 91; Briscoe and Carroll 93) conditioned probabilities on non-terminal labels and part of speech tags alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 696805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c0eab87d4855c42ae6395bf2e27eefe55003b4a",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus. Experiments on formal and natural language parsed corpora show that the new algorithm can achieve faster convergence and better modelling of hierarchical structure than the original one. In particular, over 90% of the constituents in the most likely analyses of a test set are compatible with test set constituents for a grammar trained on a corpus of 700 hand-parsed part-of-speech strings for ATIS sentences."
            },
            "slug": "Inside-Outside-Reestimation-From-Partially-Corpora-Pereira-Schabes",
            "title": {
                "fragments": [],
                "text": "Inside-Outside Reestimation From Partially Bracketed Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The inside-outside algorithm for inferring the parameters of a stochastic context-free grammar is extended to take advantage of constituent information in a partially parsed corpus to achieve faster convergence and better modelling of hierarchical structure than the original one."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 94
                            }
                        ],
                        "text": "Section 2.5 then describes the baseNP model, which uses bigram tagging techniques similar to (Ramshaw and Marcus 95; Church 88)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 28
                            }
                        ],
                        "text": "The term was first used in (Ramshaw and Marcus 95)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 44
                            }
                        ],
                        "text": "The method is similar to that described in (Ramshaw and Marcus 95; Church 88), where baseNP detection is also framed as a tagging problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 725590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9c71db75046473f0e3d3229950d7c84c09afd5e",
            "isKey": true,
            "numCitedBy": 1530,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Transformation-based learning, a technique introduced by Eric Brill (1993b), has been shown to do part-of-speech tagging with fairly high accuracy. This same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks. For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word. In automatic tests using Treebank-derived data, this technique achieved recall and precision rates of roughly 93% for baseNP chunks (trained on 950K words) and 88% for somewhat more complex chunks that partition the sentence (trained on 200K words). Working in this new application and with larger template and training sets has also required some interesting adaptations to the transformation-based learning approach."
            },
            "slug": "Text-Chunking-using-Transformation-Based-Learning-Ramshaw-Marcus",
            "title": {
                "fragments": [],
                "text": "Text Chunking using Transformation-Based Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work has shown that the transformation-based learning approach can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \u201cbaseNP\u201d chunks."
            },
            "venue": {
                "fragments": [],
                "text": "VLC@ACL"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416786"
                        ],
                        "name": "Mats Rooth",
                        "slug": "Mats-Rooth",
                        "structuredName": {
                            "firstName": "Mats",
                            "lastName": "Rooth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mats Rooth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 131
                            }
                        ],
                        "text": "Lexical information has been shown to be crucial for many parsing decisions, such as prepositional-phrase attachment (for example (Hindle and Rooth 93))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5410054,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "bdaf232c561f1f50e88b1d24097e214890b37e8b",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose that many ambiguous prepositional phrase attachments can be resolved on the basis of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus. This suggests that a distributional approach can provide an approximate solution to parsing problems that, in the worst case, call for complex reasoning."
            },
            "slug": "Structural-Ambiguity-and-Lexical-Relations-Hindle-Rooth",
            "title": {
                "fragments": [],
                "text": "Structural Ambiguity and Lexical Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "It is proposed that many ambiguous prepositional phrase attachments can be resolved on the based of the relative strength of association of the preposition with verbal and nominal heads, estimated on the basis of distribution in an automatically parsed corpus."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "For POS tagging we use a maximum-entropy tagger described in (Ratnaparkhi 96)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5914287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a574e320d899e7e82e341eb64baef7dfe8a24642",
            "isKey": false,
            "numCitedBy": 1545,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy The model can be classi ed as a Maximum Entropy model and simultaneously uses many contextual features to predict the POS tag Furthermore this paper demonstrates the use of specialized fea tures to model di cult tagging decisions discusses the corpus consistency problems discovered during the implementation of these features and proposes a training strategy that mitigates these problems"
            },
            "slug": "A-Maximum-Entropy-Model-for-Part-Of-Speech-Tagging-Ratnaparkhi",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Model for Part-Of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy and discusses the corpus consistency problems discovered during the implementation of these features."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1818123"
                        ],
                        "name": "E. Black",
                        "slug": "E.-Black",
                        "structuredName": {
                            "firstName": "Ezra",
                            "lastName": "Black",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35551590"
                        ],
                        "name": "Steven P. Abney",
                        "slug": "Steven-P.-Abney",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Abney",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven P. Abney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277328"
                        ],
                        "name": "D. Flickenger",
                        "slug": "D.-Flickenger",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Flickenger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Flickenger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1929125"
                        ],
                        "name": "C. Gdaniec",
                        "slug": "C.-Gdaniec",
                        "structuredName": {
                            "firstName": "Claudia",
                            "lastName": "Gdaniec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gdaniec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788050"
                        ],
                        "name": "R. Grishman",
                        "slug": "R.-Grishman",
                        "structuredName": {
                            "firstName": "Ralph",
                            "lastName": "Grishman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Grishman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143878270"
                        ],
                        "name": "P. Harrison",
                        "slug": "P.-Harrison",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Harrison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Harrison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21169546"
                        ],
                        "name": "Donald Hindle",
                        "slug": "Donald-Hindle",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hindle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald Hindle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2319612"
                        ],
                        "name": "R. Ingria",
                        "slug": "R.-Ingria",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Ingria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761739"
                        ],
                        "name": "Judith L. Klavans",
                        "slug": "Judith-L.-Klavans",
                        "structuredName": {
                            "firstName": "Judith",
                            "lastName": "Klavans",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judith L. Klavans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144173823"
                        ],
                        "name": "M. Liberman",
                        "slug": "M.-Liberman",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Liberman",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781292"
                        ],
                        "name": "S. Roukos",
                        "slug": "S.-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791072"
                        ],
                        "name": "T. Strzalkowski",
                        "slug": "T.-Strzalkowski",
                        "structuredName": {
                            "firstName": "Tomek",
                            "lastName": "Strzalkowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Strzalkowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17643319,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "7689778171dc100bb636fc0e4e2ce4063967d3c9",
            "isKey": false,
            "numCitedBy": 554,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of quantitatively comparing the performance of different broad-coverage grammars of English has to date resisted solution. Prima facie, known English grammars appear to disagree strongly with each other as to the elements of even the simplest sentences. For instance, the grammars of Steve Abney (Bellcore), Ezra Black (IBM), Dan Flickinger (Hewlett Packard), Claudia Gdaniec (Logos), Ralph Grishman and Tomek Strzalkowski (NYU), Phil Harrison (Boeing), Don Hindle (AT&T), Bob Ingria (BBN), and Mitch Marcus (U. of Pennsylvania) recognize in common only the following constituents, when each grammarian provides the single parse which he/she would ideally want his/her grammar to specify for three sample Brown Corpus sentences:The famed Yankee Clipper, now retired, has been assisting (as (a batting coach)).One of those capital-gains ventures, in fact, has saddled him (with Gore Court).He said this constituted a (very serious) misuse (of the (Criminal court) processes)."
            },
            "slug": "A-Procedure-for-Quantitatively-Comparing-the-of-Black-Abney",
            "title": {
                "fragments": [],
                "text": "A Procedure for Quantitatively Comparing the Syntactic Coverage of English Grammars"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The problem of quantitatively comparing the performance of different broad-coverage grammars of English has to date resisted solution."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48892185"
                        ],
                        "name": "J. Teahan",
                        "slug": "J.-Teahan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Teahan",
                            "middleNames": [
                                "K"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Teahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752317"
                        ],
                        "name": "J. Cleary",
                        "slug": "J.-Cleary",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cleary",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cleary"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 226
                            }
                        ],
                        "text": "\u2026of combining them, which favours the estimate appearing more often in training data:\nE23 = \u03b72 + \u03b73 \u03b42 + \u03b43\n(14)\nThis gives three estimates: E1, E23 and E4, a similar situation to trigram language modeling for speech recognition (Jelinek 90), where there are trigram, bigram and unigram estimates."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 1
                            }
                        ],
                        "text": "(Jelinek 90) describes a deleted interpolation method which combines these estimates to give a \u2018smooth\u2019 estimate, and the model uses a variation of this idea:\nIf E1 exists, i.e. \u03b41 > 0\nF\u0302 (Rj | \u3008w\u0304j , t\u0304j\u3009 , \u3008w\u0304hj , t\u0304hj \u3009 , \u2206j,hj ) =\n\u03bb1 \u00d7 E1 + (1 \u2212 \u03bb1) \u00d7 E23 (15)\nElse If E23 exists, i.e. \u03b42 + \u03b43 >\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 150
                            }
                        ],
                        "text": "\u2026+ (1 \u2212 \u03bb1) \u00d7 E23 (15)\nElse If E23 exists, i.e. \u03b42 + \u03b43 > 0\nF\u0302 (Rj | \u3008w\u0304j , t\u0304j\u3009 , \u3008w\u0304hj , t\u0304hj \u3009 , \u2206j,hj ) =\n\u03bb2 \u00d7 E23 + (1 \u2212 \u03bb2) \u00d7 E4 (16)\nElse\nF\u0302 (Rj | \u3008w\u0304j , t\u0304j\u3009 , \u3008w\u0304hj , t\u0304hj \u3009 , \u2206j,hj ) = E4 (17)\n(Jelinek 90) describes how to find \u03bb values in (15) and (16) which maximise the likelihood of\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6633939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d36910319d11359b995ff5413696aa9e9995e163",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "\\A new data structure for cumulative probability tables\". Soft-\\The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression\"."
            },
            "slug": "\\self-organized-Language-Modeling-for-Speech-In-Teahan-Cleary",
            "title": {
                "fragments": [],
                "text": "\\self-organized Language Modeling for Speech Recognition\". In"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The zero-frequency problem: estimating the probabilities of novel events in adaptive text compression and a new data structure for cumulative probability tables are studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 103
                            }
                        ],
                        "text": "For example, in S \u2192 <NP VP>, S gets its head-word, announced,\n3The rules are essentially the same as in (Magerman 95; Jelinek et al. 94)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "This paper describes a new parser which is much simpler than SPATTER, yet performs at least as well when trained and tested on the same Wall Street Journal data."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 203
                            }
                        ],
                        "text": "For a constituent to be \u2018correct\u2019 it must span the same set of words (ignoring punctuation, i.e. all tokens tagged as commas, colons or quotes) and have the same label10 as a constituent in the treebank\n10SPATTER collapses ADVP and PRT to the same label, for comparison we also removed this distinction when\nparse."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 20
                            }
                        ],
                        "text": "The SPATTER parser (Magerman 95; Jelinek et al. 94) does use lexical information, and recovers labeled constituents in Wall Street Journal text with above 84% accuracy \u2013 as far as we know the best published results on this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 68
                            }
                        ],
                        "text": "I would also like to thank David Magerman for his help with testing SPATTER."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "For comparison SPATTER (Magerman 95; Jelinek et al. 94) was also tested on section 23."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Decision-Tree Mod"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 117
                            }
                        ],
                        "text": "Section 2.5 then describes the baseNP model, which uses bigram tagging techniques similar to (Ramshaw and Marcus 95; Church 88)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 67
                            }
                        ],
                        "text": "The method is similar to that described in (Ramshaw and Marcus 95; Church 88), where baseNP detection is also framed as a tagging problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Stochastic Parts Program and"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 64
                            }
                        ],
                        "text": "This is particularly apparent in Categorial Grammar formalisms (Wood 93), which make an explicit link between dependencies and functional application."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorial Grammars, Routledge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Decision Tree Pars"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Procedure for Quantita"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 100
                            }
                        ],
                        "text": "However, early approaches to probabilistic parsing (Pereira and Schabes 92; Magerman and Marcus 91; Briscoe and Carroll 93) conditioned probabilities on non-terminal labels and part of speech tags alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized LR Parsing of Natural Language (Corpora) with Uniication-Based Grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 100
                            }
                        ],
                        "text": "However, early approaches to probabilistic parsing (Pereira and Schabes 92; Magerman and Marcus 91; Briscoe and Carroll 93) conditioned probabilities on non-terminal labels and part of speech tags alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generalized LR Parsing of Natural Language (Corpora) with Unification-Based Grammars"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "For POS tagging we use a maximum-entropy tagger described in (Ratnaparkhi 96)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 64
                            }
                        ],
                        "text": "This is particularly apparent in Categorial Grammar formalisms (Wood 93), which make an explicit link between dependencies and functional application."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorial Grammars, Rout- ledge"
            },
            "venue": {
                "fragments": [],
                "text": "Categorial Grammars, Rout- ledge"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 226
                            }
                        ],
                        "text": "\u2026of combining them, which favours the estimate appearing more often in training data:\nE23 = \u03b72 + \u03b73 \u03b42 + \u03b43\n(14)\nThis gives three estimates: E1, E23 and E4, a similar situation to trigram language modeling for speech recognition (Jelinek 90), where there are trigram, bigram and unigram estimates."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 1
                            }
                        ],
                        "text": "(Jelinek 90) describes a deleted interpolation method which combines these estimates to give a \u2018smooth\u2019 estimate, and the model uses a variation of this idea:\nIf E1 exists, i.e. \u03b41 > 0\nF\u0302 (Rj | \u3008w\u0304j , t\u0304j\u3009 , \u3008w\u0304hj , t\u0304hj \u3009 , \u2206j,hj ) =\n\u03bb1 \u00d7 E1 + (1 \u2212 \u03bb1) \u00d7 E23 (15)\nElse If E23 exists, i.e. \u03b42 + \u03b43 >\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 150
                            }
                        ],
                        "text": "\u2026+ (1 \u2212 \u03bb1) \u00d7 E23 (15)\nElse If E23 exists, i.e. \u03b42 + \u03b43 > 0\nF\u0302 (Rj | \u3008w\u0304j , t\u0304j\u3009 , \u3008w\u0304hj , t\u0304hj \u3009 , \u2206j,hj ) =\n\u03bb2 \u00d7 E23 + (1 \u2212 \u03bb2) \u00d7 E4 (16)\nElse\nF\u0302 (Rj | \u3008w\u0304j , t\u0304j\u3009 , \u3008w\u0304hj , t\u0304hj \u3009 , \u2206j,hj ) = E4 (17)\n(Jelinek 90) describes how to find \u03bb values in (15) and (16) which maximise the likelihood of\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Self-organized Language Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 76
                            }
                        ],
                        "text": "However, early approaches to probabilistic parsing (Pereira and Schabes 92; Magerman and Marcus 91; Briscoe and Carroll 93) conditioned probabilities on non-terminal labels and part of speech tags alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pearl: A Prob"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 13,
            "methodology": 9,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-New-Statistical-Parser-Based-on-Bigram-Lexical-Collins/3764baa7465201f054083d02b58fa75f883c4461?sort=total-citations"
}