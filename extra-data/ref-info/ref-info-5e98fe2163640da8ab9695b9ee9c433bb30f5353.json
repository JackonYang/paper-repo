{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093348519"
                        ],
                        "name": "Jeremy Howard",
                        "slug": "Jeremy-Howard",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Howard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884561"
                        ],
                        "name": "Sebastian Ruder",
                        "slug": "Sebastian-Ruder",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Ruder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Ruder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 138
                            }
                        ],
                        "text": "We finetune for 2 to 5 epochs using a batch size of 32 and a learning rate of 5e-6, 1e5, 2e-5, or 5e-5 with a slanted triangular schedule (Howard and Ruder, 2018) which is equivalent to the linear warmup followed by linear decay (Devlin et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40100965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e077413b25c4d34945cc2707e17e46ed4fe784a",
            "isKey": false,
            "numCitedBy": 2251,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code."
            },
            "slug": "Universal-Language-Model-Fine-tuning-for-Text-Howard-Ruder",
            "title": {
                "fragments": [],
                "text": "Universal Language Model Fine-tuning for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduces techniques that are key for fine- Tuning a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50229020"
                        ],
                        "name": "Emily Alsentzer",
                        "slug": "Emily-Alsentzer",
                        "structuredName": {
                            "firstName": "Emily",
                            "lastName": "Alsentzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emily Alsentzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149336949"
                        ],
                        "name": "John R. Murphy",
                        "slug": "John-R.-Murphy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Murphy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31809608"
                        ],
                        "name": "Willie Boag",
                        "slug": "Willie-Boag",
                        "structuredName": {
                            "firstName": "Willie",
                            "lastName": "Boag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Willie Boag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088565"
                        ],
                        "name": "W. Weng",
                        "slug": "W.-Weng",
                        "structuredName": {
                            "firstName": "Wei-Hung",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Weng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068347799"
                        ],
                        "name": "Di Jin",
                        "slug": "Di-Jin",
                        "structuredName": {
                            "firstName": "Di",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Di Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40466858"
                        ],
                        "name": "Tristan Naumann",
                        "slug": "Tristan-Naumann",
                        "structuredName": {
                            "firstName": "Tristan",
                            "lastName": "Naumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tristan Naumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41153596"
                        ],
                        "name": "Matthew B. A. McDermott",
                        "slug": "Matthew-B.-A.-McDermott",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "McDermott",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew B. A. McDermott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 71
                            }
                        ],
                        "text": "BIOBERT is trained on PubMed abstracts and PMC full text articles, and CLINICALBERT is trained on clinical text from the MIMIC-III database (Johnson et al., 2016)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 95
                            }
                        ],
                        "text": "Recent work on domain adaptation of BERT includes BIOBERT (Lee et al., 2019) and CLINICALBERT (Alsentzer et al., 2019; Huang et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "domain vocabulary is helpful, SCIBERT bene\ufb01ts most from the scienti\ufb01c corpus pretraining. 6 Related Work Recent work on domain adaptation of BERT includes BIOBERT (Lee et al., 2019) and CLINICALBERT (Alsentzer et al., 2019; Huang et al., 2019). BIOBERT is trained on PubMed abstracts and PMC full text articles, and CLINICALBERT is trained on clinical text from the MIMIC-III database (Johnson et al., 2016). In contrast, "
                    },
                    "intents": []
                }
            ],
            "corpusId": 102352093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a567ebd78939d0861d788f0fedff8d40ae62bf2",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Contextual word embedding models such as ELMo and BERT have dramatically improved performance for many natural language processing (NLP) tasks in recent months. However, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained BERT models yet exist. In this work, we address this need by exploring and releasing BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically. We demonstrate that using a domain-specific model yields performance improvements on 3/5 clinical NLP tasks, establishing a new state-of-the-art on the MedNLI dataset. We find that these domain-specific models are not as performant on 2 clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text."
            },
            "slug": "Publicly-Available-Clinical-BERT-Embeddings-Alsentzer-Murphy",
            "title": {
                "fragments": [],
                "text": "Publicly Available Clinical BERT Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work explores and releases two BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically, and demonstrates that using a domain-specific model yields performance improvements on 3/5 clinical NLP tasks, establishing a new state-of-the-art on the MedNLI dataset."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2nd Clinical Natural Language Processing Workshop"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40695489"
                        ],
                        "name": "Joel Grus",
                        "slug": "Joel-Grus",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Grus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Grus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50043859"
                        ],
                        "name": "Mark Neumann",
                        "slug": "Mark-Neumann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3385516"
                        ],
                        "name": "Oyvind Tafjord",
                        "slug": "Oyvind-Tafjord",
                        "structuredName": {
                            "firstName": "Oyvind",
                            "lastName": "Tafjord",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oyvind Tafjord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697425"
                        ],
                        "name": "Pradeep Dasigi",
                        "slug": "Pradeep-Dasigi",
                        "structuredName": {
                            "firstName": "Pradeep",
                            "lastName": "Dasigi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pradeep Dasigi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22243769"
                        ],
                        "name": "Nelson F. Liu",
                        "slug": "Nelson-F.-Liu",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Liu",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nelson F. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144874222"
                        ],
                        "name": "Michael Schmitz",
                        "slug": "Michael-Schmitz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schmitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Schmitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3994096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93b4cc549a1bc4bc112189da36c318193d05d806",
            "isKey": false,
            "numCitedBy": 893,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern natural language processing (NLP) research requires writing code. Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research. However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten. This paper describes AllenNLP, a library for applying deep learning methods to NLP research that addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions. AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field."
            },
            "slug": "AllenNLP:-A-Deep-Semantic-Natural-Language-Platform-Gardner-Grus",
            "title": {
                "fragments": [],
                "text": "AllenNLP: A Deep Semantic Natural Language Processing Platform"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "AllenNLP is described, a library for applying deep learning methods to NLP research that addresses issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144958935"
                        ],
                        "name": "Karthik Narasimhan",
                        "slug": "Karthik-Narasimhan",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Narasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karthik Narasimhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 13
                            }
                        ],
                        "text": ", 2018), GPT (Radford et al., 2018) and BERT (Devlin et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 50
                            }
                        ],
                        "text": "As shown through ELMo (Peters et al., 2018), GPT (Radford et al., 2018) and BERT (Devlin et al., 2019), unsupervised pretraining of language models on large corpora significantly improves performance on many NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49313245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd18800a0fe0b668a1cc19f2ec95b5003d0a5035",
            "isKey": false,
            "numCitedBy": 3536,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classi\ufb01cation. Although large unlabeled text corpora are abundant, labeled data for learning these speci\ufb01c tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative \ufb01ne-tuning on each speci\ufb01c task. In contrast to previous approaches, we make use of task-aware input transformations during \ufb01ne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, signi\ufb01cantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on question answering (RACE), and 1.5% on textual entailment (MultiNLI)."
            },
            "slug": "Improving-Language-Understanding-by-Generative-Radford-Narasimhan",
            "title": {
                "fragments": [],
                "text": "Improving Language Understanding by Generative Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The general task-agnostic model outperforms discriminatively trained models that use architectures speci\ufb01cally crafted for each task, improving upon the state of the art in 9 out of the 12 tasks studied."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 89
                            }
                        ],
                        "text": "We mostly follow the same architecture, optimization, and hyperparameter choices used in Devlin et al. (2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "Background The BERT model architecture (Devlin et al., 2019) is based on a multilayer bidirectional Transformer (Vaswani et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 82
                            }
                        ],
                        "text": "As shown through ELMo (Peters et al., 2018), GPT (Radford et al., 2018) and BERT (Devlin et al., 2019), unsupervised pretraining of language models on large corpora significantly improves performance on many NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 17
                            }
                        ],
                        "text": ", 2018) and BERT (Devlin et al., 2019), unsupervised pretraining of language models on large corpora significantly improves performance on many NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "BERT-Base We use the pretrained weights for BERT-Base (Devlin et al., 2019) released with the original BERT code."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 55
                            }
                        ],
                        "text": "BERT-Base We use the pretrained weights for BERT-Base (Devlin et al., 2019) released with the original BERT code.4 The vocabulary is BASEVOCAB."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 39
                            }
                        ],
                        "text": "Background The BERT model architecture (Devlin et al., 2019) is based on a multilayer bidirectional Transformer (Vaswani et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 71
                            }
                        ],
                        "text": "6https://github.com/huggingface/ pytorch-transformers\nCasing We follow Devlin et al. (2019) in using the cased models for NER and the uncased models for all other tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 62
                            }
                        ],
                        "text": "We release SCIBERT, a pretrained language model based on BERT (Devlin et al., 2019) to address the lack of highquality, large-scale labeled scientific data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 230
                            }
                        ],
                        "text": "We finetune for 2 to 5 epochs using a batch size of 32 and a learning rate of 5e-6, 1e5, 2e-5, or 5e-5 with a slanted triangular schedule (Howard and Ruder, 2018) which is equivalent to the linear warmup followed by linear decay (Devlin et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": true,
            "numCitedBy": 33777,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959414"
                        ],
                        "name": "Nils Reimers",
                        "slug": "Nils-Reimers",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Reimers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nils Reimers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730400"
                        ],
                        "name": "Iryna Gurevych",
                        "slug": "Iryna-Gurevych",
                        "structuredName": {
                            "firstName": "Iryna",
                            "lastName": "Gurevych",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iryna Gurevych"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 90
                            }
                        ],
                        "text": "We did not find changing the depth or size of the BiLSTMs to significantly impact results (Reimers and Gurevych, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 25934949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1929540803b36222b406cc0aeaa549789e7eba56",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Selecting optimal parameters for a neural network architecture can often make the difference between mediocre and state-of-the-art performance. However, little is published which parameters and design choices should be evaluated or selected making the correct hyperparameter optimization often a \"black art that requires expert experiences\" (Snoek et al., 2012). In this paper, we evaluate the importance of different network design choices and hyperparameters for five common linguistic sequence tagging tasks (POS, Chunking, NER, Entity Recognition, and Event Detection). We evaluated over 50.000 different setups and found, that some parameters, like the pre-trained word embeddings or the last layer of the network, have a large impact on the performance, while other parameters, for example the number of LSTM layers or the number of recurrent units, are of minor importance. We give a recommendation on a configuration that performs well among different tasks."
            },
            "slug": "Optimal-Hyperparameters-for-Deep-LSTM-Networks-for-Reimers-Gurevych",
            "title": {
                "fragments": [],
                "text": "Optimal Hyperparameters for Deep LSTM-Networks for Sequence Labeling Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper evaluates the importance of different network design choices and hyperparameters for five common linguistic sequence tagging tasks and found, that some parameters, like the pre-trained word embeddings or the last layer of the network, have a large impact on the performance, while other parameters, for example the number of LSTM layers or theNumber of recurrent units, are of minor importance."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378954"
                        ],
                        "name": "Xuezhe Ma",
                        "slug": "Xuezhe-Ma",
                        "structuredName": {
                            "firstName": "Xuezhe",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuezhe Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144547315"
                        ],
                        "name": "E. Hovy",
                        "slug": "E.-Hovy",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Hovy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hovy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "multilayer BiLSTM to token embeddings. For text classi\ufb01cation, we apply a multilayer perceptron on the \ufb01rst and last BiLSTM states. For sequence tagging, weuse a CRF on top of the BiLSTM, as done in (Ma and Hovy, 2016). For dependency parsing we use the biaf\ufb01ne attention model from Dozat and Manning (2017). 3.5 Task-speci\ufb01c Training Forsimplicity, experiments are performed without any hyperparameter tuning and with"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10489017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8dd6aae51e31a72752c4be5cddbdd76dfdc6cda4",
            "isKey": true,
            "numCitedBy": 1994,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art sequence labeling systems traditionally require large amounts of task-specific knowledge in the form of hand-crafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both word- and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data pre-processing, thus making it applicable to a wide range of sequence labeling tasks. We evaluate our system on two data sets for two sequence labeling tasks --- Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain state-of-the-art performance on both the two data --- 97.55\\% accuracy for POS tagging and 91.21\\% F1 for NER."
            },
            "slug": "End-to-end-Sequence-Labeling-via-Bi-directional-Ma-Hovy",
            "title": {
                "fragments": [],
                "text": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel neutral network architecture is introduced that benefits from both word- and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF, thus making it applicable to a wide range of sequence labeling tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277385"
                        ],
                        "name": "Timothy Dozat",
                        "slug": "Timothy-Dozat",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Dozat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy Dozat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The SOTA result for GENIA is in Nguyen and Verspoor (2019) which uses the model from Dozat and Manning (2017) with partof-speech (POS) features, which we do not use."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7942973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8cbef23c9ee2ae7c35cc691a0c1d713a6377c9f2",
            "isKey": false,
            "numCitedBy": 795,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper builds off recent work from Kiperwasser & Goldberg (2016) using neural attention in a simple graph-based dependency parser. We use a larger but more thoroughly regularized parser than other recent BiLSTM-based approaches, with biaffine classifiers to predict arcs and labels. Our parser gets state of the art or near state of the art performance on standard treebanks for six different languages, achieving 95.7% UAS and 94.1% LAS on the most popular English PTB dataset. This makes it the highest-performing graph-based parser on this benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and 2.2%---and comparable to the highest performing transition-based parser (Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show which hyperparameter choices had a significant effect on parsing accuracy, allowing us to achieve large gains over other graph-based approaches."
            },
            "slug": "Deep-Biaffine-Attention-for-Neural-Dependency-Dozat-Manning",
            "title": {
                "fragments": [],
                "text": "Deep Biaffine Attention for Neural Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper uses a larger but more thoroughly regularized parser than other recent BiLSTM-based approaches, with biaffine classifiers to predict arcs and labels, and shows which hyperparameter choices had a significant effect on parsing accuracy, allowing it to achieve large gains over other graph-based approach."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50043859"
                        ],
                        "name": "Mark Neumann",
                        "slug": "Mark-Neumann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136562"
                        ],
                        "name": "Mohit Iyyer",
                        "slug": "Mohit-Iyyer",
                        "structuredName": {
                            "firstName": "Mohit",
                            "lastName": "Iyyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohit Iyyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40642935"
                        ],
                        "name": "Matt Gardner",
                        "slug": "Matt-Gardner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Gardner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143997772"
                        ],
                        "name": "Christopher Clark",
                        "slug": "Christopher-Clark",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1982950"
                        ],
                        "name": "Luke Zettlemoyer",
                        "slug": "Luke-Zettlemoyer",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Zettlemoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Zettlemoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 22
                            }
                        ],
                        "text": "As shown through ELMo (Peters et al., 2018), GPT (Radford et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Yet while both BERT and ELMo have released pretrained models, they are still trained on general domain corpora such as news articles and Wikipedia."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 91
                            }
                        ],
                        "text": "We also explore the usage of BERT as pretrained contextualized word embeddings, like ELMo (Peters et al., 2018), by training simple task-specific models atop frozen BERT embeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "As shown through ELMo (Peters et al., 2018), GPT (Radford et al., 2018) and BERT (Devlin et al., 2019), unsupervised pretraining of language models on large corpora significantly improves performance on many NLP tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3626819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3febb2bed8865945e7fddc99efd791887bb7e14f",
            "isKey": true,
            "numCitedBy": 7988,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals."
            },
            "slug": "Deep-Contextualized-Word-Representations-Peters-Neumann",
            "title": {
                "fragments": [],
                "text": "Deep Contextualized Word Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new type of deep contextualized word representation is introduced that models both complex characteristics of word use and how these uses vary across linguistic contexts, allowing downstream models to mix different types of semi-supervision signals."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50043859"
                        ],
                        "name": "Mark Neumann",
                        "slug": "Mark-Neumann",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145104486"
                        ],
                        "name": "Daniel King",
                        "slug": "Daniel-King",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46181066"
                        ],
                        "name": "Iz Beltagy",
                        "slug": "Iz-Beltagy",
                        "structuredName": {
                            "firstName": "Iz",
                            "lastName": "Beltagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iz Beltagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585097"
                        ],
                        "name": "Waleed Ammar",
                        "slug": "Waleed-Ammar",
                        "structuredName": {
                            "firstName": "Waleed",
                            "lastName": "Ammar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Waleed Ammar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 35
                            }
                        ],
                        "text": "We split sentences using ScispaCy (Neumann et al., 2019),2 which is optimized for scientific text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67788603,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de28ec1d7bd38c8fc4e8ac59b6133800818b4e29",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent advances in natural language processing, many statistical models for processing text perform extremely poorly under domain shift. Processing biomedical and clinical text is a critically important application area of natural language processing, for which there are few robust, practical, publicly available models. This paper describes scispaCy, a new Python library and models for practical biomedical/scientific text processing, which heavily leverages the spaCy library. We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets. Models and code are available at https://allenai.github.io/scispacy/."
            },
            "slug": "ScispaCy:-Fast-and-Robust-Models-for-Biomedical-Neumann-King",
            "title": {
                "fragments": [],
                "text": "ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "ScispaCy, a new Python library and models for practical biomedical/scientific text processing, which heavily leverages the spaCy library is described, which detail the performance of two packages of models released in scispa Cy and demonstrate their robustness on several tasks and datasets."
            },
            "venue": {
                "fragments": [],
                "text": "BioNLP@ACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081697"
                        ],
                        "name": "Yi Luan",
                        "slug": "Yi-Luan",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2265599"
                        ],
                        "name": "Luheng He",
                        "slug": "Luheng-He",
                        "structuredName": {
                            "firstName": "Luheng",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luheng He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144339506"
                        ],
                        "name": "Mari Ostendorf",
                        "slug": "Mari-Ostendorf",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Ostendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mari Ostendorf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2548384"
                        ],
                        "name": "Hannaneh Hajishirzi",
                        "slug": "Hannaneh-Hajishirzi",
                        "structuredName": {
                            "firstName": "Hannaneh",
                            "lastName": "Hajishirzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hannaneh Hajishirzi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52118895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b21b927c251c415b601b6d7f785a42cc5c292635",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a multi-task setup of identifying entities, relations, and coreference clusters in scientific articles. We create SciERC, a dataset that includes annotations for all three tasks and develop a unified framework called SciIE with shared span representations. The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links. Experiments show that our multi-task model outperforms previous models in scientific information extraction without using any domain-specific features. We further show that the framework supports construction of a scientific knowledge graph, which we use to analyze information in scientific literature."
            },
            "slug": "Multi-Task-Identification-of-Entities,-Relations,-Luan-He",
            "title": {
                "fragments": [],
                "text": "Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The multi-task setup reduces cascading errors between tasks and leverages cross-sentence relations through coreference links and supports construction of a scientific knowledge graph, which is used to analyze information in scientific literature."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2959414"
                        ],
                        "name": "Nils Reimers",
                        "slug": "Nils-Reimers",
                        "structuredName": {
                            "firstName": "Nils",
                            "lastName": "Reimers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nils Reimers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730400"
                        ],
                        "name": "Iryna Gurevych",
                        "slug": "Iryna-Gurevych",
                        "structuredName": {
                            "firstName": "Iryna",
                            "lastName": "Gurevych",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iryna Gurevych"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 91
                            }
                        ],
                        "text": "We did not find changing the depth or size of the BiLSTMs to significantly impact results (Reimers and Gurevych, 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "nce intervals) except for ACL-ARC and ScienceCite datasets. All results are the average of multiple runs with different random seeds to control potential non-determinismassociated with neural models (Reimers and Gurevych, 2017). Most results are macro F1 scores (span-level for NER, sentencelevel for REL and CLS, and token-level for PICO), except ChemProt and PubMed 20k RCT (micro F1 scores). Parsing is evaluated using label"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23678406,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "235e255462446d7364d9a5df7dc6fe736a7249ad",
            "isKey": false,
            "numCitedBy": 352,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we show that reporting a single performance score is insufficient to compare non-deterministic approaches. We demonstrate for common sequence tagging tasks that the seed value for the random number generator can result in statistically significant (p < 10^{-4}) differences for state-of-the-art systems. For two recent systems for NER, we observe an absolute difference of one percentage point F\u2081-score depending on the selected seed value, making these systems perceived either as state-of-the-art or mediocre. Instead of publishing and reporting single performance scores, we propose to compare score distributions based on multiple executions. Based on the evaluation of 50.000 LSTM-networks for five sequence tagging tasks, we present network architectures that produce both superior performance as well as are more stable with respect to the remaining hyperparameters."
            },
            "slug": "Reporting-Score-Distributions-Makes-a-Difference:-Reimers-Gurevych",
            "title": {
                "fragments": [],
                "text": "Reporting Score Distributions Makes a Difference: Performance Study of LSTM-networks for Sequence Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "It is shown that reporting a single performance score is insufficient to compare non-deterministic approaches and proposed to compare score distributions based on multiple executions, and network architectures are presented that produce both superior performance as well as are more stable with respect to the remaining hyperparameters."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46664096"
                        ],
                        "name": "Jinhyuk Lee",
                        "slug": "Jinhyuk-Lee",
                        "structuredName": {
                            "firstName": "Jinhyuk",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhyuk Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51433082"
                        ],
                        "name": "Wonjin Yoon",
                        "slug": "Wonjin-Yoon",
                        "structuredName": {
                            "firstName": "Wonjin",
                            "lastName": "Yoon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wonjin Yoon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2829848"
                        ],
                        "name": "Sungdong Kim",
                        "slug": "Sungdong-Kim",
                        "structuredName": {
                            "firstName": "Sungdong",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sungdong Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145183568"
                        ],
                        "name": "Donghyeon Kim",
                        "slug": "Donghyeon-Kim",
                        "structuredName": {
                            "firstName": "Donghyeon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donghyeon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144247125"
                        ],
                        "name": "Sunkyu Kim",
                        "slug": "Sunkyu-Kim",
                        "structuredName": {
                            "firstName": "Sunkyu",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunkyu Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51435068"
                        ],
                        "name": "Chan Ho So",
                        "slug": "Chan-Ho-So",
                        "structuredName": {
                            "firstName": "Chan",
                            "lastName": "So",
                            "middleNames": [
                                "Ho"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chan Ho So"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144323862"
                        ],
                        "name": "Jaewoo Kang",
                        "slug": "Jaewoo-Kang",
                        "structuredName": {
                            "firstName": "Jaewoo",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaewoo Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 58
                            }
                        ],
                        "text": "Recent work on domain adaptation of BERT includes BIOBERT (Lee et al., 2019) and CLINICALBERT (Alsentzer et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "BC5CDR and ChemProt, and performs similarly on JNLPBA despite being trained on a substantially smaller biomedical corpus."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 142
                            }
                        ],
                        "text": "SCIBERT significantly outperformed BERT-Base and achieves new SOTA results on several of these tasks, even compared to some reported BIOBERT (Lee et al., 2019) results on biomedical tasks."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 44
                            }
                        ],
                        "text": "The SOTA model for NCBI-disease is BIOBERT (Lee et al., 2019), which is BERT-Base finetuned on 18B tokens from biomedical papers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 71
                            }
                        ],
                        "text": "In addition, SCIBERT achieves new SOTA results on BC5CDR and ChemProt (Lee et al., 2019), and EBM-NLP (Nye et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 108
                            }
                        ],
                        "text": "In Table 2, we compare SCIBERT results with reported BIOBERT results on the subset of datasets included in (Lee et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 70
                            }
                        ],
                        "text": "In addition, SCIBERT achieves new SOTA results on BC5CDR and ChemProt (Lee et al., 2019), and EBM-NLP (Nye et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 59
                            }
                        ],
                        "text": "Recent work on domain adaptation of BERT includes BIOBERT (Lee et al., 2019) and CLINICALBERT (Alsentzer et al., 2019; Huang et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59291975,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "1e43c7084bdcb6b3102afaf301cce10faead2702",
            "isKey": true,
            "numCitedBy": 1980,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Motivation Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora. Results We introduce BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora. With almost the same architecture across tasks, BioBERT largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre-trained on biomedical corpora. While BERT obtains performance comparable to that of previous state-of-the-art models, BioBERT significantly outperforms them on the following three representative biomedical text mining tasks: biomedical named entity recognition (0.62% F1 score improvement), biomedical relation extraction (2.80% F1 score improvement) and biomedical question answering (12.24% MRR improvement). Our analysis results show that pre-training BERT on biomedical corpora helps it to understand complex biomedical texts. Availability and implementation We make the pre-trained weights of BioBERT freely available at https://github.com/naver/biobert-pretrained, and the source code for fine-tuning BioBERT available at https://github.com/dmis-lab/biobert."
            },
            "slug": "BioBERT:-a-pre-trained-biomedical-language-model-Lee-Yoon",
            "title": {
                "fragments": [],
                "text": "BioBERT: a pre-trained biomedical language representation model for biomedical text mining"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This article introduces BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora that largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre- trained on biomedical Corpora."
            },
            "venue": {
                "fragments": [],
                "text": "Bioinform."
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34691913"
                        ],
                        "name": "Dat Quoc Nguyen",
                        "slug": "Dat-Quoc-Nguyen",
                        "structuredName": {
                            "firstName": "Dat",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "Quoc"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dat Quoc Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144765178"
                        ],
                        "name": "Karin M. Verspoor",
                        "slug": "Karin-M.-Verspoor",
                        "structuredName": {
                            "firstName": "Karin",
                            "lastName": "Verspoor",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karin M. Verspoor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 103
                            }
                        ],
                        "text": "In addition, SCIBERT achieves new SOTA results on BC5CDR and ChemProt (Lee et al., 2019), and EBM-NLP (Nye et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 9
                            }
                        ],
                        "text": "EBM-NLP (Nye et al., 2018) annotates PICO spans in clinical trial abstracts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51981761,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "7f03ef6f2ac8adca835571986e6f75468893e255",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "BackgroundGiven the importance of relation or event extraction from biomedical research publications to support knowledge capture and synthesis, and the strong dependency of approaches to this information extraction task on syntactic information, it is valuable to understand which approaches to syntactic processing of biomedical text have the highest performance.ResultsWe perform an empirical study comparing state-of-the-art traditional feature-based and neural network-based models for two core natural language processing tasks of part-of-speech (POS) tagging and dependency parsing on two benchmark biomedical corpora, GENIA and CRAFT. To the best of our knowledge, there is no recent work making such comparisons in the biomedical context; specifically no detailed analysis of neural models on this data is available. Experimental results show that in general, the neural models outperform the feature-based models on two benchmark biomedical corpora GENIA and CRAFT. We also perform a task-oriented evaluation to investigate the influences of these models in a downstream application on biomedical event extraction, and show that better intrinsic parsing performance does not always imply better extrinsic event extraction performance.ConclusionWe have presented a detailed empirical study comparing traditional feature-based and neural network-based models for POS tagging and dependency parsing in the biomedical context, and also investigated the influence of parser selection for a biomedical event extraction downstream task.Availability of data and materialsWe make the retrained models available at https://github.com/datquocnguyen/BioPosDep."
            },
            "slug": "From-POS-tagging-to-dependency-parsing-for-event-Nguyen-Verspoor",
            "title": {
                "fragments": [],
                "text": "From POS tagging to dependency parsing for biomedical event extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A detailed empirical study comparing traditional feature-based and neural network-based models for POS tagging and dependency parsing in the biomedical context is presented, and the influence of parser selection for a biomedical event extraction downstream task is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48607963"
                        ],
                        "name": "Yonghui Wu",
                        "slug": "Yonghui-Wu",
                        "structuredName": {
                            "firstName": "Yonghui",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonghui Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144927151"
                        ],
                        "name": "M. Schuster",
                        "slug": "M.-Schuster",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545358"
                        ],
                        "name": "Z. Chen",
                        "slug": "Z.-Chen",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739074"
                        ],
                        "name": "Mohammad Norouzi",
                        "slug": "Mohammad-Norouzi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Norouzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Norouzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3153147"
                        ],
                        "name": "Wolfgang Macherey",
                        "slug": "Wolfgang-Macherey",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Macherey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Macherey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048712"
                        ],
                        "name": "M. Krikun",
                        "slug": "M.-Krikun",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Krikun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krikun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145144022"
                        ],
                        "name": "Yuan Cao",
                        "slug": "Yuan-Cao",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145312180"
                        ],
                        "name": "Qin Gao",
                        "slug": "Qin-Gao",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qin Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113439369"
                        ],
                        "name": "Klaus Macherey",
                        "slug": "Klaus-Macherey",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Macherey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Macherey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367620"
                        ],
                        "name": "J. Klingner",
                        "slug": "J.-Klingner",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Klingner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Klingner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145825976"
                        ],
                        "name": "Apurva Shah",
                        "slug": "Apurva-Shah",
                        "structuredName": {
                            "firstName": "Apurva",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Apurva Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145657834"
                        ],
                        "name": "Melvin Johnson",
                        "slug": "Melvin-Johnson",
                        "structuredName": {
                            "firstName": "Melvin",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melvin Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109059862"
                        ],
                        "name": "Xiaobing Liu",
                        "slug": "Xiaobing-Liu",
                        "structuredName": {
                            "firstName": "Xiaobing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2776283"
                        ],
                        "name": "Stephan Gouws",
                        "slug": "Stephan-Gouws",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Gouws",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephan Gouws"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739610"
                        ],
                        "name": "Y. Kato",
                        "slug": "Y.-Kato",
                        "structuredName": {
                            "firstName": "Yoshikiyo",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765329"
                        ],
                        "name": "Taku Kudo",
                        "slug": "Taku-Kudo",
                        "structuredName": {
                            "firstName": "Taku",
                            "lastName": "Kudo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taku Kudo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754386"
                        ],
                        "name": "H. Kazawa",
                        "slug": "H.-Kazawa",
                        "structuredName": {
                            "firstName": "Hideto",
                            "lastName": "Kazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144077726"
                        ],
                        "name": "K. Stevens",
                        "slug": "K.-Stevens",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Stevens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Stevens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753079661"
                        ],
                        "name": "George Kurian",
                        "slug": "George-Kurian",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Kurian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George Kurian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056800684"
                        ],
                        "name": "Nishant Patil",
                        "slug": "Nishant-Patil",
                        "structuredName": {
                            "firstName": "Nishant",
                            "lastName": "Patil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nishant Patil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49337181"
                        ],
                        "name": "Wei Wang",
                        "slug": "Wei-Wang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39660914"
                        ],
                        "name": "C. Young",
                        "slug": "C.-Young",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119125158"
                        ],
                        "name": "Jason R. Smith",
                        "slug": "Jason-R.-Smith",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909504"
                        ],
                        "name": "Jason Riesa",
                        "slug": "Jason-Riesa",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Riesa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Riesa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29951847"
                        ],
                        "name": "Alex Rudnick",
                        "slug": "Alex-Rudnick",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Rudnick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Rudnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48342565"
                        ],
                        "name": "Macduff Hughes",
                        "slug": "Macduff-Hughes",
                        "structuredName": {
                            "firstName": "Macduff",
                            "lastName": "Hughes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Macduff Hughes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 29
                            }
                        ],
                        "text": "We construct SCIVOCAB, a new WordPiece vocabulary on our scientific corpus using the SentencePiece1 library."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 32
                            }
                        ],
                        "text": "Vocabulary BERT uses WordPiece (Wu et al., 2016) for unsupervised tokenization of the input text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3603249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbde7dfa6cae81df8ac19ef500c42db96c3d1edd",
            "isKey": false,
            "numCitedBy": 4645,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system."
            },
            "slug": "Google's-Neural-Machine-Translation-System:-the-Gap-Wu-Schuster",
            "title": {
                "fragments": [],
                "text": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "GNMT, Google's Neural Machine Translation system, is presented, which attempts to address many of the weaknesses of conventional phrase-based translation systems and provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delicited models."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785622"
                        ],
                        "name": "Jin-Dong Kim",
                        "slug": "Jin-Dong-Kim",
                        "structuredName": {
                            "firstName": "Jin-Dong",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-Dong Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095533089"
                        ],
                        "name": "Tomoko Ohta",
                        "slug": "Tomoko-Ohta",
                        "structuredName": {
                            "firstName": "Tomoko",
                            "lastName": "Ohta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomoko Ohta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529659"
                        ],
                        "name": "Yuka Tateisi",
                        "slug": "Yuka-Tateisi",
                        "structuredName": {
                            "firstName": "Yuka",
                            "lastName": "Tateisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuka Tateisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737901"
                        ],
                        "name": "Junichi Tsujii",
                        "slug": "Junichi-Tsujii",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Tsujii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junichi Tsujii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "t al., 2016) Bio 15,030 JNLPBA (Collier and Kim, 2004) Bio 24,806 NCBI-disease (Dogan et al., 2014) Bio 7,287 SciERC (Luan et al., 2018) CS 3,187 PICO EBM-NLP (Nye et al., 2018) Bio 50,362 DEP GENIA (Kim et al., 2003) Bio 17,047 CLS RCT-20k (Dernoncourt and Lee, 2017) Bio 240,387 ACL-ARC (Jurgens et al., 2018) CS 1,941 Paper Field Multi 111,998 ScienceCite (Cohan et al., 2019) Multi 10,104 REL ChemProt (Kringelum "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11522524,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da6c3fdf8ef9aae979a5dd156e074ba6691b2e2c",
            "isKey": false,
            "numCitedBy": 1102,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "MOTIVATION\nNatural language processing (NLP) methods are regarded as being useful to raise the potential of text mining from biological literature. The lack of an extensively annotated corpus of this literature, however, causes a major bottleneck for applying NLP techniques. GENIA corpus is being developed to provide reference materials to let NLP techniques work for bio-textmining.\n\n\nRESULTS\nGENIA corpus version 3.0 consisting of 2000 MEDLINE abstracts has been released with more than 400,000 words and almost 100,000 annotations for biological terms."
            },
            "slug": "GENIA-corpus-a-semantically-annotated-corpus-for-Kim-Ohta",
            "title": {
                "fragments": [],
                "text": "GENIA corpus - a semantically annotated corpus for bio-textmining"
            },
            "venue": {
                "fragments": [],
                "text": "ISMB"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51433082"
                        ],
                        "name": "Wonjin Yoon",
                        "slug": "Wonjin-Yoon",
                        "structuredName": {
                            "firstName": "Wonjin",
                            "lastName": "Yoon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wonjin Yoon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51435068"
                        ],
                        "name": "Chan Ho So",
                        "slug": "Chan-Ho-So",
                        "structuredName": {
                            "firstName": "Chan",
                            "lastName": "So",
                            "middleNames": [
                                "Ho"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chan Ho So"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46664096"
                        ],
                        "name": "Jinhyuk Lee",
                        "slug": "Jinhyuk-Lee",
                        "structuredName": {
                            "firstName": "Jinhyuk",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhyuk Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144323862"
                        ],
                        "name": "Jaewoo Kang",
                        "slug": "Jaewoo-Kang",
                        "structuredName": {
                            "firstName": "Jaewoo",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaewoo Kang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 101
                            }
                        ],
                        "text": "The SOTA model for JNLPBA is a BiLSTM-CRF ensemble trained on multiple NER datasets not just JNLPBA (Yoon et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "BC5CDR and ChemProt, and performs similarly on JNLPBA despite being trained on a substantially smaller biomedical corpus."
                    },
                    "intents": []
                }
            ],
            "corpusId": 52338869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14ad9d060c1e8f0449e697ee189ac346353fbfbc",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "BackgroundFinding biomedical named entities is one of the most essential tasks in biomedical text mining. Recently, deep learning-based approaches have been applied to biomedical named entity recognition (BioNER) and showed promising results. However, as deep learning approaches need an abundant amount of training data, a lack of data can hinder performance. BioNER datasets are scarce resources and each dataset covers only a small subset of entity types. Furthermore, many bio entities are polysemous, which is one of the major obstacles in named entity recognition.ResultsTo address the lack of data and the entity type misclassification problem, we propose CollaboNet which utilizes a combination of multiple NER models. In CollaboNet, models trained on a different dataset are connected to each other so that a target model obtains information from other collaborator models to reduce false positives. Every model is an expert on their target entity type and takes turns serving as a target and a collaborator model during training time. The experimental results show that CollaboNet can be used to greatly reduce the number of false positives and misclassified entities including polysemous words. CollaboNet achieved state-of-the-art performance in terms of precision, recall and F1 score.ConclusionsWe demonstrated the benefits of combining multiple models for BioNER. Our model has successfully reduced the number of misclassified entities and improved the performance by leveraging multiple datasets annotated for different entity types. Given the state-of-the-art performance of our model, we believe that CollaboNet can improve the accuracy of downstream biomedical text mining applications such as bio-entity relation extraction."
            },
            "slug": "CollaboNet:-collaboration-of-deep-neural-networks-Yoon-So",
            "title": {
                "fragments": [],
                "text": "CollaboNet: collaboration of deep neural networks for biomedical named entity recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The experimental results show that CollaboNet can be used to greatly reduce the number of false positives and misclassified entities including polysemous words and improve the accuracy of downstream biomedical text mining applications such as bio-entity relation extraction."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2527954"
                        ],
                        "name": "Arman Cohan",
                        "slug": "Arman-Cohan",
                        "structuredName": {
                            "firstName": "Arman",
                            "lastName": "Cohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arman Cohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585097"
                        ],
                        "name": "Waleed Ammar",
                        "slug": "Waleed-Ammar",
                        "structuredName": {
                            "firstName": "Waleed",
                            "lastName": "Ammar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Waleed Ammar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15292561"
                        ],
                        "name": "Madeleine van Zuylen",
                        "slug": "Madeleine-van-Zuylen",
                        "structuredName": {
                            "firstName": "Madeleine",
                            "lastName": "van Zuylen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Madeleine van Zuylen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48915850"
                        ],
                        "name": "Field Cady",
                        "slug": "Field-Cady",
                        "structuredName": {
                            "firstName": "Field",
                            "lastName": "Cady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Field Cady"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 58
                            }
                        ],
                        "text": "In addition, SCIBERT achieves new SOTA results on ACLARC (Cohan et al., 2019), and the NER part of SciERC (Luan et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": "In addition, SCIBERT achieves new SOTA results on ACLARC (Cohan et al., 2019), and the NER part of SciERC (Luan et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 54
                            }
                        ],
                        "text": "In addition, SCIBERT outperforms the SOTA on SciCite (Co-\nhan et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 123
                            }
                        ],
                        "text": "1https://github.com/google/ sentencepiece\n2https://github.com/allenai/SciSpaCy\nACL-ARC (Jurgens et al., 2018) and SciCite (Cohan et al., 2019) assign intent labels (e.g. Comparison, Extension, etc.) to sentences from scientific papers that cite other papers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 53
                            }
                        ],
                        "text": "In addition, SCIBERT outperforms the SOTA on SciCite (Cohan et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": ", 2018) and SciCite (Cohan et al., 2019) assign intent labels (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102483154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95ebe37c856e914b760bc5db63561f461ec444cc",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Identifying the intent of a citation in scientific papers (e.g., background information, use of methods, comparing results) is critical for machine reading of individual publications and automated analysis of the scientific literature. We propose structural scaffolds, a multitask model to incorporate structural information of scientific papers into citations for effective classification of citation intents. Our model achieves a new state-of-the-art on an existing ACL anthology dataset (ACL-ARC) with a 13.3% absolute increase in F1 score, without relying on external linguistic resources or hand-engineered features as done in existing methods. In addition, we introduce a new dataset of citation intents (SciCite) which is more than five times larger and covers multiple scientific domains compared with existing datasets. Our code and data are available at: https://github.com/allenai/scicite."
            },
            "slug": "Structural-Scaffolds-for-Citation-Intent-in-Cohan-Ammar",
            "title": {
                "fragments": [],
                "text": "Structural Scaffolds for Citation Intent Classification in Scientific Publications"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes structural scaffolds, a multitask model to incorporate structural information of scientific papers into citations for effective classification of citation intents, which achieves a new state-of-the-art on an existing ACL anthology dataset with a 13.3% absolute increase in F1 score."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3877127"
                        ],
                        "name": "Niki Parmar",
                        "slug": "Niki-Parmar",
                        "structuredName": {
                            "firstName": "Niki",
                            "lastName": "Parmar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niki Parmar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39328010"
                        ],
                        "name": "Jakob Uszkoreit",
                        "slug": "Jakob-Uszkoreit",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Uszkoreit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Uszkoreit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145024664"
                        ],
                        "name": "Llion Jones",
                        "slug": "Llion-Jones",
                        "structuredName": {
                            "firstName": "Llion",
                            "lastName": "Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llion Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19177000"
                        ],
                        "name": "Aidan N. Gomez",
                        "slug": "Aidan-N.-Gomez",
                        "structuredName": {
                            "firstName": "Aidan",
                            "lastName": "Gomez",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aidan N. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40527594"
                        ],
                        "name": "Lukasz Kaiser",
                        "slug": "Lukasz-Kaiser",
                        "structuredName": {
                            "firstName": "Lukasz",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lukasz Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3443442"
                        ],
                        "name": "Illia Polosukhin",
                        "slug": "Illia-Polosukhin",
                        "structuredName": {
                            "firstName": "Illia",
                            "lastName": "Polosukhin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Illia Polosukhin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 113
                            }
                        ],
                        "text": "Background The BERT model architecture (Devlin et al., 2019) is based on a multilayer bidirectional Transformer (Vaswani et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 59
                            }
                        ],
                        "text": ", 2019) is based on a multilayer bidirectional Transformer (Vaswani et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13756489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204e3073870fae3d05bcbc2f6a8e263d9b72e776",
            "isKey": false,
            "numCitedBy": 35186,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "slug": "Attention-is-All-you-Need-Vaswani-Shazeer",
            "title": {
                "fragments": [],
                "text": "Attention is All you Need"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely is proposed, which generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736741380"
                        ],
                        "name": "Su Nam Kim",
                        "slug": "Su-Nam-Kim",
                        "structuredName": {
                            "firstName": "Su Nam",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Su Nam Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143696281"
                        ],
                        "name": "David Mart\u00ednez",
                        "slug": "David-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mart\u00ednez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mart\u00ednez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788025"
                        ],
                        "name": "L. Cavedon",
                        "slug": "L.-Cavedon",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Cavedon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cavedon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264004"
                        ],
                        "name": "Lars Yencken",
                        "slug": "Lars-Yencken",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Yencken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lars Yencken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 197
                            }
                        ],
                        "text": "Dependency Parsing (DEP)\nPICO, like NER, is a sequence labeling task where the model extracts spans describing the Participants, Interventions, Comparisons, and Outcomes in a clinical trial paper (Kim et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 171
                            }
                        ],
                        "text": "PICO, like NER, is a sequence labeling task where the model extracts spans describing the Participants, Interventions, Comparisons, and Outcomes in a clinical trial paper (Kim et al., 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13339227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a80b29a0c5229e518206b9b5683487f0d9d41e20",
            "isKey": false,
            "numCitedBy": 167,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "AimGiven a set of pre-defined medical categories used in Evidence Based Medicine, we aim to automatically annotate sentences in medical abstracts with these labels.MethodWe constructed a corpus of 1,000 medical abstracts annotated by hand with specified medical categories (e.g. Intervention, Outcome). We explored the use of various features based on lexical, semantic, structural, and sequential information in the data, using Conditional Random Fields (CRF) for classification.ResultsFor the classification tasks over all labels, our systems achieved micro-averaged f-scores of 80.9% and 66.9% over datasets of structured and unstructured abstracts respectively, using sequential features. In labeling only the key sentences, our systems produced f-scores of 89.3% and 74.0% over structured and unstructured abstracts respectively, using the same sequential features. The results over an external dataset were lower (f-scores of 63.1% for all labels, and 83.8% for key sentences).ConclusionsOf the features we used, the best for classifying any given sentence in an abstract were based on unigrams, section headings, and sequential information from preceding sentences. These features resulted in improved performance over a simple bag-of-words approach, and outperformed feature sets used in previous work."
            },
            "slug": "Automatic-classification-of-sentences-to-support-Kim-Mart\u00ednez",
            "title": {
                "fragments": [],
                "text": "Automatic classification of sentences to support Evidence Based Medicine"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Of the features used, the best for classifying any given sentence in an abstract were based on unigrams, section headings, and sequential information from preceding sentences, which resulted in improved performance over a simple bag-of-words approach, and outperformed feature sets used in previous work."
            },
            "venue": {
                "fragments": [],
                "text": "BMC Bioinformatics"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145795474"
                        ],
                        "name": "Benjamin E. Nye",
                        "slug": "Benjamin-E.-Nye",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Nye",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin E. Nye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22319255"
                        ],
                        "name": "Junyi Jessy Li",
                        "slug": "Junyi-Jessy-Li",
                        "structuredName": {
                            "firstName": "Junyi",
                            "lastName": "Li",
                            "middleNames": [
                                "Jessy"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junyi Jessy Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48322149"
                        ],
                        "name": "Roma Patel",
                        "slug": "Roma-Patel",
                        "structuredName": {
                            "firstName": "Roma",
                            "lastName": "Patel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roma Patel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2781059"
                        ],
                        "name": "Yinfei Yang",
                        "slug": "Yinfei-Yang",
                        "structuredName": {
                            "firstName": "Yinfei",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinfei Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808775"
                        ],
                        "name": "I. Marshall",
                        "slug": "I.-Marshall",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Marshall",
                            "middleNames": [
                                "James"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Marshall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3115414"
                        ],
                        "name": "A. Nenkova",
                        "slug": "A.-Nenkova",
                        "structuredName": {
                            "firstName": "Ani",
                            "lastName": "Nenkova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nenkova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912476"
                        ],
                        "name": "Byron C. Wallace",
                        "slug": "Byron-C.-Wallace",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Wallace",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byron C. Wallace"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 103
                            }
                        ],
                        "text": "In addition, SCIBERT achieves new SOTA results on BC5CDR and ChemProt (Lee et al., 2019), and EBM-NLP (Nye et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 9
                            }
                        ],
                        "text": "EBM-NLP (Nye et al., 2018) annotates PICO spans in clinical trial abstracts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 48353672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a78873e41615798d09391d9f40d41666b8c9beb",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a corpus of 5,000 richly annotated abstracts of medical articles describing clinical randomized controlled trials. Annotations include demarcations of text spans that describe the Patient population enrolled, the Interventions studied and to what they were Compared, and the Outcomes measured (the \u2018PICO\u2019 elements). These spans are further annotated at a more granular level, e.g., individual interventions within them are marked and mapped onto a structured medical vocabulary. We acquired annotations from a diverse set of workers with varying levels of expertise and cost. We describe our data collection process and the corpus itself in detail. We then outline a set of challenging NLP tasks that would aid searching of the medical literature and the practice of evidence-based medicine."
            },
            "slug": "A-Corpus-with-Multi-Level-Annotations-of-Patients,-Nye-Li",
            "title": {
                "fragments": [],
                "text": "A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support Language Processing for Medical Literature"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A corpus of 5,000 richly annotated abstracts of medical articles describing clinical randomized controlled trials is presented and a set of challenging NLP tasks that would aid searching of the medical literature and the practice of evidence-based medicine are outlined."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117970351"
                        ],
                        "name": "Jiao Li",
                        "slug": "Jiao-Li",
                        "structuredName": {
                            "firstName": "Jiao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116969756"
                        ],
                        "name": "Yueping Sun",
                        "slug": "Yueping-Sun",
                        "structuredName": {
                            "firstName": "Yueping",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yueping Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000280"
                        ],
                        "name": "Robin J. Johnson",
                        "slug": "Robin-J.-Johnson",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Johnson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robin J. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160494"
                        ],
                        "name": "D. Sciaky",
                        "slug": "D.-Sciaky",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Sciaky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sciaky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252035"
                        ],
                        "name": "Chih-Hsuan Wei",
                        "slug": "Chih-Hsuan-Wei",
                        "structuredName": {
                            "firstName": "Chih-Hsuan",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Hsuan Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277706"
                        ],
                        "name": "Robert Leaman",
                        "slug": "Robert-Leaman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Leaman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Leaman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "108109364"
                        ],
                        "name": "A. P. Davis",
                        "slug": "A.-P.-Davis",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Davis",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. P. Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3283642"
                        ],
                        "name": "C. Mattingly",
                        "slug": "C.-Mattingly",
                        "structuredName": {
                            "firstName": "Carolyn",
                            "lastName": "Mattingly",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mattingly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1922749"
                        ],
                        "name": "Thomas C. Wiegers",
                        "slug": "Thomas-C.-Wiegers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Wiegers",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas C. Wiegers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144202084"
                        ],
                        "name": "Zhiyong Lu",
                        "slug": "Zhiyong-Lu",
                        "structuredName": {
                            "firstName": "Zhiyong",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyong Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 88817,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "61322ec6cfc54fe9723d4637239b8fb9938dc501",
            "isKey": false,
            "numCitedBy": 376,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Community-run, formal evaluations and manually annotated text corpora are critically important for advancing biomedical text-mining research. Recently in BioCreative V, a new challenge was organized for the tasks of disease named entity recognition (DNER) and chemical-induced disease (CID) relation extraction. Given the nature of both tasks, a test collection is required to contain both disease/chemical annotations and relation annotations in the same set of articles. Despite previous efforts in biomedical corpus construction, none was found to be sufficient for the task. Thus, we developed our own corpus called BC5CDR during the challenge by inviting a team of Medical Subject Headings (MeSH) indexers for disease/chemical entity annotation and Comparative Toxicogenomics Database (CTD) curators for CID relation annotation. To ensure high annotation quality and productivity, detailed annotation guidelines and automatic annotation tools were provided. The resulting BC5CDR corpus consists of 1500 PubMed articles with 4409 annotated chemicals, 5818 diseases and 3116 chemical-disease interactions. Each entity annotation includes both the mention text spans and normalized concept identifiers, using MeSH as the controlled vocabulary. To ensure accuracy, the entities were first captured independently by two annotators followed by a consensus annotation: The average inter-annotator agreement (IAA) scores were 87.49% and 96.05% for the disease and chemicals, respectively, in the test set according to the Jaccard similarity coefficient. Our corpus was successfully used for the BioCreative V challenge tasks and should serve as a valuable resource for the text-mining research community. Database URL: http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/"
            },
            "slug": "BioCreative-V-CDR-task-corpus:-a-resource-for-Li-Sun",
            "title": {
                "fragments": [],
                "text": "BioCreative V CDR task corpus: a resource for chemical disease relation extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The BC5CDR corpus was successfully used for the BioCreative V challenge tasks and should serve as a valuable resource for the text-mining research community."
            },
            "venue": {
                "fragments": [],
                "text": "Database J. Biol. Databases Curation"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34619326"
                        ],
                        "name": "R. Dogan",
                        "slug": "R.-Dogan",
                        "structuredName": {
                            "firstName": "Rezarta",
                            "lastName": "Dogan",
                            "middleNames": [
                                "Islamaj"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dogan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2277706"
                        ],
                        "name": "Robert Leaman",
                        "slug": "Robert-Leaman",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Leaman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Leaman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144202084"
                        ],
                        "name": "Zhiyong Lu",
                        "slug": "Zhiyong-Lu",
                        "structuredName": {
                            "firstName": "Zhiyong",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiyong Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 234064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "696753d59185436ec95ecf3021c413f353be4874",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "NCBI-disease-corpus:-A-resource-for-disease-name-Dogan-Leaman",
            "title": {
                "fragments": [],
                "text": "NCBI disease corpus: A resource for disease name recognition and concept normalization"
            },
            "venue": {
                "fragments": [],
                "text": "J. Biomed. Informatics"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "We optimize cross entropy loss using Adam, but holding BERT weights frozen and applying a dropout of 0.5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 45
                            }
                        ],
                        "text": "1 and optimize cross entropy loss using Adam (Kingma and Ba, 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "In all settings, we apply a dropout of 0.1 and optimize cross entropy loss using Adam (Kingma and Ba, 2015)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 90091,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145585097"
                        ],
                        "name": "Waleed Ammar",
                        "slug": "Waleed-Ammar",
                        "structuredName": {
                            "firstName": "Waleed",
                            "lastName": "Ammar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Waleed Ammar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3458736"
                        ],
                        "name": "Dirk Groeneveld",
                        "slug": "Dirk-Groeneveld",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Groeneveld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dirk Groeneveld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1857797"
                        ],
                        "name": "Chandra Bhagavatula",
                        "slug": "Chandra-Bhagavatula",
                        "structuredName": {
                            "firstName": "Chandra",
                            "lastName": "Bhagavatula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chandra Bhagavatula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46181066"
                        ],
                        "name": "Iz Beltagy",
                        "slug": "Iz-Beltagy",
                        "structuredName": {
                            "firstName": "Iz",
                            "lastName": "Beltagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iz Beltagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46230609"
                        ],
                        "name": "Miles Crawford",
                        "slug": "Miles-Crawford",
                        "structuredName": {
                            "firstName": "Miles",
                            "lastName": "Crawford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miles Crawford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145612610"
                        ],
                        "name": "Doug Downey",
                        "slug": "Doug-Downey",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Downey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Downey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38092776"
                        ],
                        "name": "Jason Dunkelberger",
                        "slug": "Jason-Dunkelberger",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Dunkelberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Dunkelberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143718836"
                        ],
                        "name": "Ahmed Elgohary",
                        "slug": "Ahmed-Elgohary",
                        "structuredName": {
                            "firstName": "Ahmed",
                            "lastName": "Elgohary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ahmed Elgohary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46411828"
                        ],
                        "name": "Sergey Feldman",
                        "slug": "Sergey-Feldman",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4480314"
                        ],
                        "name": "Vu A. Ha",
                        "slug": "Vu-A.-Ha",
                        "structuredName": {
                            "firstName": "Vu",
                            "lastName": "Ha",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vu A. Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143967880"
                        ],
                        "name": "Rodney Michael Kinney",
                        "slug": "Rodney-Michael-Kinney",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Kinney",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodney Michael Kinney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41018147"
                        ],
                        "name": "Sebastian Kohlmeier",
                        "slug": "Sebastian-Kohlmeier",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Kohlmeier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Kohlmeier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46258841"
                        ],
                        "name": "Kyle Lo",
                        "slug": "Kyle-Lo",
                        "structuredName": {
                            "firstName": "Kyle",
                            "lastName": "Lo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyle Lo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144240185"
                        ],
                        "name": "Tyler C. Murray",
                        "slug": "Tyler-C.-Murray",
                        "structuredName": {
                            "firstName": "Tyler",
                            "lastName": "Murray",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tyler C. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46256862"
                        ],
                        "name": "Hsu-Han Ooi",
                        "slug": "Hsu-Han-Ooi",
                        "structuredName": {
                            "firstName": "Hsu-Han",
                            "lastName": "Ooi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsu-Han Ooi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39139825"
                        ],
                        "name": "Matthew E. Peters",
                        "slug": "Matthew-E.-Peters",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Peters",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew E. Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39561369"
                        ],
                        "name": "Joanna L. Power",
                        "slug": "Joanna-L.-Power",
                        "structuredName": {
                            "firstName": "Joanna",
                            "lastName": "Power",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joanna L. Power"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46181683"
                        ],
                        "name": "Sam Skjonsberg",
                        "slug": "Sam-Skjonsberg",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Skjonsberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam Skjonsberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31860505"
                        ],
                        "name": "Lucy Lu Wang",
                        "slug": "Lucy-Lu-Wang",
                        "structuredName": {
                            "firstName": "Lucy",
                            "lastName": "Wang",
                            "middleNames": [
                                "Lu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucy Lu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46212260"
                        ],
                        "name": "Christopher Wilhelm",
                        "slug": "Christopher-Wilhelm",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wilhelm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Wilhelm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112339497"
                        ],
                        "name": "Zheng Yuan",
                        "slug": "Zheng-Yuan",
                        "structuredName": {
                            "firstName": "Zheng",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zheng Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15292561"
                        ],
                        "name": "Madeleine van Zuylen",
                        "slug": "Madeleine-van-Zuylen",
                        "structuredName": {
                            "firstName": "Madeleine",
                            "lastName": "van Zuylen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Madeleine van Zuylen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741101"
                        ],
                        "name": "Oren Etzioni",
                        "slug": "Oren-Etzioni",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Etzioni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Etzioni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 82
                            }
                        ],
                        "text": "Corpus We train SCIBERT on a random sample of 1.14M papers from Semantic Scholar (Ammar et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "AB is 42%, illustrating a substantial difference in frequently used words between scienti\ufb01c and general domain texts. Corpus We train SCIBERT on a random sample of 1.14M papers from Semantic Scholar (Ammar et al., 2018). This corpus consists of 18% papers from the computer science domain and 82% from the broad biomedical domain. We use the full text of the papers, not just the abstracts. The average paper length is "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "on clinical text from the MIMIC-III database (Johnson et al., 2016). In contrast, SCIBERT is trained on the full text of 1.14M biomedical and computer science papers from the Semantic Scholar corpus (Ammar et al., 2018). Furthermore, SCIBERT uses an in-domain vocabulary (SCIVOCAB) while the other abovementioned models use the original BERT vocabulary (BASEVOCAB). 7 Conclusion and Future Work We released SCIBERT, a p"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 131
                            }
                        ],
                        "text": "In contrast, SCIBERT is trained on the full text of 1.14M biomedical and computer science papers from the Semantic Scholar corpus (Ammar et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19170988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "649def34f8be52c8b66281af98ae884c09aef38b",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a deployed scalable system for organizing published scientific literature into a heterogeneous graph to facilitate algorithmic manipulation and discovery. The resulting literature graph consists of more than 280M nodes, representing papers, authors, entities and various interactions between them (e.g., authorships, citations, entity mentions). We reduce literature graph construction into familiar NLP tasks (e.g., entity extraction and linking), point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task. The methods described in this paper are used to enable semantic features in www.semanticscholar.org."
            },
            "slug": "Construction-of-the-Literature-Graph-in-Semantic-Ammar-Groeneveld",
            "title": {
                "fragments": [],
                "text": "Construction of the Literature Graph in Semantic Scholar"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper reduces literature graph construction into familiar NLP tasks, point out research challenges due to differences from standard formulations of these tasks, and report empirical results for each task."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3046220"
                        ],
                        "name": "David Jurgens",
                        "slug": "David-Jurgens",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jurgens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Jurgens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39703734"
                        ],
                        "name": "Srijan Kumar",
                        "slug": "Srijan-Kumar",
                        "structuredName": {
                            "firstName": "Srijan",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srijan Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26155126"
                        ],
                        "name": "Raine Hoover",
                        "slug": "Raine-Hoover",
                        "structuredName": {
                            "firstName": "Raine",
                            "lastName": "Hoover",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raine Hoover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100525940"
                        ],
                        "name": "Daniel A. McFarland",
                        "slug": "Daniel-A.-McFarland",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "McFarland",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel A. McFarland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 88
                            }
                        ],
                        "text": "1https://github.com/google/ sentencepiece\n2https://github.com/allenai/SciSpaCy\nACL-ARC (Jurgens et al., 2018) and SciCite (Cohan et al., 2019) assign intent labels (e.g. Comparison, Extension, etc.) to sentences from scientific papers that cite other papers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 29
                            }
                        ],
                        "text": "com/allenai/SciSpaCy ACL-ARC (Jurgens et al., 2018) and SciCite (Cohan et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 51917388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16be95fd3f9b635e9ede5812cc223deebf0142bc",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "Citations have long been used to characterize the state of a scientific field and to identify influential works. However, writers use citations for different purposes, and this varied purpose influences uptake by future scholars. Unfortunately, our understanding of how scholars use and frame citations has been limited to small-scale manual citation analysis of individual papers. We perform the largest behavioral study of citations to date, analyzing how scientific works frame their contributions through different types of citations and how this framing affects the field as a whole. We introduce a new dataset of nearly 2,000 citations annotated for their function, and use it to develop a state-of-the-art classifier and label the papers of an entire field: Natural Language Processing. We then show how differences in framing affect scientific uptake and reveal the evolution of the publication venues and the field as a whole. We demonstrate that authors are sensitive to discourse structure and publication venue when citing, and that how a paper frames its work through citations is predictive of the citation count it will receive. Finally, we use changes in citation framing to show that the field of NLP is undergoing a significant increase in consensus."
            },
            "slug": "Measuring-the-Evolution-of-a-Scientific-Field-Jurgens-Kumar",
            "title": {
                "fragments": [],
                "text": "Measuring the Evolution of a Scientific Field through Citation Frames"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work performs the largest behavioral study of citations to date, analyzing how scientific works frame their contributions through different types of citations and how this framing affects the field as a whole and changes in citation framing are used to show that the field of NLP is undergoing a significant increase in consensus."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3072167"
                        ],
                        "name": "Nigel Collier",
                        "slug": "Nigel-Collier",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Collier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel Collier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785622"
                        ],
                        "name": "Jin-Dong Kim",
                        "slug": "Jin-Dong-Kim",
                        "structuredName": {
                            "firstName": "Jin-Dong",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-Dong Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "01 JNLPBA (Collier and Kim, 2004) 78."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7985741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bd4d2de49d8a092abb295b845dba14874f8787d",
            "isKey": false,
            "numCitedBy": 558,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe here the JNLPBA shared task of bio-entity recognition using an extended version of the GENIA version 3 named entity corpus of MEDLINE abstracts. We provide background information on the task and present a general discussion of the approaches taken by participating systems."
            },
            "slug": "Introduction-to-the-Bio-entity-Recognition-Task-at-Collier-Kim",
            "title": {
                "fragments": [],
                "text": "Introduction to the Bio-entity Recognition Task at JNLPBA"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The JNLPBA shared task of bio-entity recognition using an extended version of the GENIA version 3 named entity corpus of MEDLINE abstracts is described and a general discussion of the approaches taken by participating systems is presented."
            },
            "venue": {
                "fragments": [],
                "text": "NLPBA/BioNLP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89080903"
                        ],
                        "name": "Jens Vindahl",
                        "slug": "Jens-Vindahl",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Vindahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Vindahl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 88650050,
            "fieldsOfStudy": [
                "Biology",
                "Chemistry"
            ],
            "id": "575b0b9e3996097962510191e3da186d7a32d56d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "ChemProt is a publicly available compilation of chemical-protein-disease annotation resources that enables the study of systems pharmacology for a small molecule across multiple layers of complexity from molecular to clinical levels. In this third version, ChemProt has been updated to more than 1.7 million compounds with 7.8 million bioactivity measurements for 19 504 proteins. Here, we report the implementation of global pharmacological heatmap, supporting a user-friendly navigation of chemogenomics space. This facilitates the visualization and selection of chemicals that share similar structural properties. In addition, the user has the possibility to search by compound, target, pathway, disease and clinical effect. Genetic variations associated to target proteins were integrated, making it possible to plan pharmacogenetic studies and to suggest human response variability to drug. Finally, Quantitative Structure\u2013Activity Relationship models for 850 proteins having sufficient data were implemented, enabling secondary pharmacological profiling predictions from molecular structure. Database URL: http://potentia.cbs.dtu.dk/ChemProt/"
            },
            "slug": "ChemProt-3.0:-a-global-chemical-biology-diseases-Vindahl",
            "title": {
                "fragments": [],
                "text": "ChemProt-3.0: a global chemical biology diseases mapping"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The implementation of global pharmacological heatmap is reported, supporting a user-friendly navigation of chemogenomics space and enabling secondary pharmacological profiling predictions from molecular structure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39753024"
                        ],
                        "name": "Arnab Sinha",
                        "slug": "Arnab-Sinha",
                        "structuredName": {
                            "firstName": "Arnab",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnab Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303634"
                        ],
                        "name": "Zhihong Shen",
                        "slug": "Zhihong-Shen",
                        "structuredName": {
                            "firstName": "Zhihong",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhihong Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144404428"
                        ],
                        "name": "Yang Song",
                        "slug": "Yang-Song",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144988795"
                        ],
                        "name": "Hao Ma",
                        "slug": "Hao-Ma",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40329918"
                        ],
                        "name": "Darrin Eide",
                        "slug": "Darrin-Eide",
                        "structuredName": {
                            "firstName": "Darrin",
                            "lastName": "Eide",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darrin Eide"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10171248"
                        ],
                        "name": "B. Hsu",
                        "slug": "B.-Hsu",
                        "structuredName": {
                            "firstName": "Bo-June",
                            "lastName": "Hsu",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748169"
                        ],
                        "name": "Kuansan Wang",
                        "slug": "Kuansan-Wang",
                        "structuredName": {
                            "firstName": "Kuansan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuansan Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 68
                            }
                        ],
                        "text": "The Paper Field dataset is built from the Microsoft Academic Graph (Sinha et al., 2015)3 and maps paper titles to one of 7 fields of study."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14761112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ebc4145aef6a575cbaffcfeec56b20586db573a",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new release of a Web scale entity graph that serves as the backbone of Microsoft Academic Service (MAS), a major production effort with a broadened scope to the namesake vertical search engine that has been publicly available since 2008 as a research prototype. At the core of MAS is a heterogeneous entity graph comprised of six types of entities that model the scholarly activities: field of study, author, institution, paper, venue, and event. In addition to obtaining these entities from the publisher feeds as in the previous effort, we in this version include data mining results from the Web index and an in-house knowledge base from Bing, a major commercial search engine. As a result of the Bing integration, the new MAS graph sees significant increase in size, with fresh information streaming in automatically following their discoveries by the search engine. In addition, the rich entity relations included in the knowledge base provide additional signals to disambiguate and enrich the entities within and beyond the academic domain. The number of papers indexed by MAS, for instance, has grown from low tens of millions to 83 million while maintaining an above 95% accuracy based on test data sets derived from academic activities at Microsoft Research. Based on the data set, we demonstrate two scenarios in this work: a knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation."
            },
            "slug": "An-Overview-of-Microsoft-Academic-Service-(MAS)-and-Sinha-Shen",
            "title": {
                "fragments": [],
                "text": "An Overview of Microsoft Academic Service (MAS) and Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A knowledge driven, highly interactive dialog that seamlessly combines reactive search and proactive suggestion experience, and a proactive heterogeneous entity recommendation are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49454094"
                        ],
                        "name": "Kexin Huang",
                        "slug": "Kexin-Huang",
                        "structuredName": {
                            "firstName": "Kexin",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kexin Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124555"
                        ],
                        "name": "Jaan Altosaar",
                        "slug": "Jaan-Altosaar",
                        "structuredName": {
                            "firstName": "Jaan",
                            "lastName": "Altosaar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaan Altosaar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 119
                            }
                        ],
                        "text": "Recent work on domain adaptation of BERT includes BIOBERT (Lee et al., 2019) and CLINICALBERT (Alsentzer et al., 2019; Huang et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119308351,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "b3c2c9f53ab130f3eb76eaaab3afa481c5a405eb",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Clinical notes contain information about patients that goes beyond structured data like lab values and medications. However, clinical notes have been underused relative to structured data, because notes are high-dimensional and sparse. This work develops and evaluates representations of clinical notes using bidirectional transformers (ClinicalBERT). ClinicalBERT uncovers high-quality relationships between medical concepts as judged by humans. ClinicalBert outperforms baselines on 30-day hospital readmission prediction using both discharge summaries and the first few days of notes in the intensive care unit. Code and model parameters are available."
            },
            "slug": "ClinicalBERT:-Modeling-Clinical-Notes-and-Hospital-Huang-Altosaar",
            "title": {
                "fragments": [],
                "text": "ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "ClinicalBERT uncovers high-quality relationships between medical concepts as judged by humans and outperforms baselines on 30-day hospital readmission prediction using both discharge summaries and the first few days of notes in the intensive care unit."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28972636"
                        ],
                        "name": "A. Johnson",
                        "slug": "A.-Johnson",
                        "structuredName": {
                            "firstName": "Alistair",
                            "lastName": "Johnson",
                            "middleNames": [
                                "E.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40541154"
                        ],
                        "name": "T. Pollard",
                        "slug": "T.-Pollard",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Pollard",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pollard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115648970"
                        ],
                        "name": "Lu Shen",
                        "slug": "Lu-Shen",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771337"
                        ],
                        "name": "Li-wei H. Lehman",
                        "slug": "Li-wei-H.-Lehman",
                        "structuredName": {
                            "firstName": "Li-wei",
                            "lastName": "Lehman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-wei H. Lehman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2773476"
                        ],
                        "name": "M. Feng",
                        "slug": "M.-Feng",
                        "structuredName": {
                            "firstName": "Mengling",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143811844"
                        ],
                        "name": "M. Ghassemi",
                        "slug": "M.-Ghassemi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ghassemi",
                            "middleNames": [
                                "Mahdi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ghassemi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39934542"
                        ],
                        "name": "Benjamin Moody",
                        "slug": "Benjamin-Moody",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Moody",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Moody"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679873"
                        ],
                        "name": "Peter Szolovits",
                        "slug": "Peter-Szolovits",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Szolovits",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Szolovits"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143605744"
                        ],
                        "name": "L. Celi",
                        "slug": "L.-Celi",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Celi",
                            "middleNames": [
                                "Anthony"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Celi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1978710"
                        ],
                        "name": "R. Mark",
                        "slug": "R.-Mark",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mark",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "BIOBERT is trained on PubMed abstracts and PMC full text articles, and CLINICALBERT is trained on clinical text from the MIMIC-III database (Johnson et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "CLINICALBERT (Alsentzer et al., 2019; Huang et al., 2019). BIOBERT is trained on PubMed abstracts and PMC full text articles, and CLINICALBERT is trained on clinical text from the MIMIC-III database (Johnson et al., 2016). In contrast, SCIBERT is trained on the full text of 1.14M biomedical and computer science papers from the Semantic Scholar corpus (Ammar et al., 2018). Furthermore, SCIBERT uses an in-domain vocabul"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33285731,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "95cd83603a0d2b6918a8e34a5637a8f382da96f5",
            "isKey": false,
            "numCitedBy": 3589,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "MIMIC-III (\u2018Medical Information Mart for Intensive Care\u2019) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital. Data includes vital signs, medications, laboratory measurements, observations and notes charted by care providers, fluid balance, procedure codes, diagnostic codes, imaging reports, hospital length of stay, survival data, and more. The database supports applications including academic and industrial research, quality improvement initiatives, and higher education coursework."
            },
            "slug": "MIMIC-III,-a-freely-accessible-critical-care-Johnson-Pollard",
            "title": {
                "fragments": [],
                "text": "MIMIC-III, a freely accessible critical care database"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "MIMIC-III (\u2018Medical Information Mart for Intensive Care\u2019) is a large, single-center database comprising information relating to patients admitted to critical care units at a large tertiary care hospital."
            },
            "venue": {
                "fragments": [],
                "text": "Scientific data"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 21
                            }
                        ],
                        "text": "Expected 40-70 days (Dettmers, 2019) on an 8-GPU machine."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TPUs vs GPUs for Transformers (BERT)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 18,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/SciBERT:-A-Pretrained-Language-Model-for-Scientific-Beltagy-Lo/5e98fe2163640da8ab9695b9ee9c433bb30f5353?sort=total-citations"
}