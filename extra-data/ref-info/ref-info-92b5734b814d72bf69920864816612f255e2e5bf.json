{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65810283"
                        ],
                        "name": "R. Ohlander",
                        "slug": "R.-Ohlander",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Ohlander",
                            "middleNames": [
                                "Bert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ohlander"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 65
                            }
                        ],
                        "text": "The system also uses Shafer\u2019s version of Ohlander\u2019s segmentation (Ohlander 1975; Shafer and Kanade 1980)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 40
                            }
                        ],
                        "text": "an Ohlander-like region analysis system (Ohlander 1975) that forms regions by splitting, using thresholds selected from histograms of the new color parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60833117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b30de454c99b8006db60cd53bea5f9f2d6fc8cd4",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : This report describes work performed on two aspects of the scene analysis process. These are segmentation, and the treatment of occlusions, shadows, and highlights. The eventual goal of the research is the formulation of knowledge sources which play an important role in a model for a general vision system. The model is based on the hypothesize-and-test paradigm and consists of a number of independent knowledge sources which cooperate through a global data base."
            },
            "slug": "Analysis-of-natural-scenes.-Ohlander",
            "title": {
                "fragments": [],
                "text": "Analysis of natural scenes."
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Work performed on two aspects of the scene analysis process are segmentation, and the treatment of occlusions, shadows, and highlights, which play an important role in a model for a general vision system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48726084"
                        ],
                        "name": "Christopher M. Brown",
                        "slug": "Christopher-M.-Brown",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Brown",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher M. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48171588"
                        ],
                        "name": "J. M. Feldman",
                        "slug": "J.-M.-Feldman",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Feldman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Feldman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8279450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c791b6c00e779bb75f84ba827ef98e2b4af14e4",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Document describes a vision system which uses a semantic network model and a distributed control structure to accomplish the image analysis process. The system is an attempt to bring together many current ideas in artificial intelligence and vision programming and thereby to cast some light on fundamental problems of computer perception. The semantic network facilities the interplay between geometric and other relational constraints which are used to direct and limit search."
            },
            "slug": "An-Approach-to-Knowledge-Directed-Image-Analysis-Ballard-Brown",
            "title": {
                "fragments": [],
                "text": "An Approach to Knowledge-Directed Image Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A vision system which uses a semantic network model and a distributed control structure to accomplish the image analysis process to cast some light on fundamental problems of computer perception."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69973347"
                        ],
                        "name": "C. Parma",
                        "slug": "C.-Parma",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Parma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Parma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733922"
                        ],
                        "name": "A. Hanson",
                        "slug": "A.-Hanson",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31338632"
                        ],
                        "name": "E. Riseman",
                        "slug": "E.-Riseman",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Riseman",
                            "middleNames": [
                                "M."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riseman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60670137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "457f8408f4ea5905c7c3f0d9d5e7c6614e2d1372",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The system under development, VISIONS, is an investigation into general issues in the construction of computer vision systems. The goal is to provide an analysis of color images of outdoor scenes, from segmentation (or partitioning) of an image through the final stages of symbolic interpretation of that image. The output of the system is intended to be a symbolic representation of the three-dimensional world depicted in the two-dimensional image, including the naming of objects, their placement in three-dimensional space, and the ability to predict from this representation the rough appearance of the scene from other points of view. Research in segmentation and interpretation has been separated into the development of two major subsystems with quite different methodologies and considerations."
            },
            "slug": "Experiments-in-Schema-Driven-Interpretation-of-a-Parma-Hanson",
            "title": {
                "fragments": [],
                "text": "Experiments in Schema-Driven Interpretation of a Natural Scene"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "The system under development, VISIONS, is an investigation into general issues in the construction of computer vision systems, to provide an analysis of color images of outdoor scenes, from segmentation (or partitioning) of an image through the final stages of symbolic interpretation of that image."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123067218"
                        ],
                        "name": "K. Price",
                        "slug": "K.-Price",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Price",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Price"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17649243,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d9a5eb3d65baad7e59033d5f15ba21bee338ce02",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the application of stochastic labeling to a general symbolic image description problem. A method used to compute initial likelihoods and compatibilities is described. It was derived from an earlier symbolic matching procedure, but was modified to provide the data needed for application of the labeling method. This labeling procedure differs from simpler ones, in that it minimizes a global criterion at each iteration. This technique is compared to other matching methods, and results on two scenes are presented."
            },
            "slug": "Semantic-Description-of-Aerial-Images-Using-Faugeras-Price",
            "title": {
                "fragments": [],
                "text": "Semantic Description of Aerial Images Using Stochastic Labeling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method used to compute initial likelihoods and compatibilities is described, derived from an earlier symbolic matching procedure, but was modified to provide the data needed for application of the labeling method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2162080"
                        ],
                        "name": "M. Nagao",
                        "slug": "M.-Nagao",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Nagao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nagao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143658244"
                        ],
                        "name": "T. Matsuyama",
                        "slug": "T.-Matsuyama",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Matsuyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Matsuyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115183735"
                        ],
                        "name": "Hisayuki Mori",
                        "slug": "Hisayuki-Mori",
                        "structuredName": {
                            "firstName": "Hisayuki",
                            "lastName": "Mori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hisayuki Mori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41965371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54a3b83fe1116e04405362bb2c51ff9e6ba0ac69",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A new system for the structural analysis of complex aerial photographs is presented. This system has the ability of focussing its attention of the analysis on the limited local areas where objects are highly supposed to exist. Several kinds of strong and typical features are extracted, and these primary features of objects are combined to extract rough areas of the objects. This focussing mechanism saves the total processing time and facilitates the detailed analysis. The recognition process of the system is Implemented according to the 'production system'. The knowledge sources in this system are object-detection subsystems which analyse their individually focussed local areas and recognize specific objects respectively. All the results of the analysis are written in the common blackboard, and the system finds out conflicts and recovers errors by backtracking to feature extractions and low level processings. This architecture enables us to organize smoothly the diverse knowledge required to describe the complex structure on the ground surface."
            },
            "slug": "A-Structural-Analysis-of-Complex-Aerial-Photographs-Nagao-Matsuyama",
            "title": {
                "fragments": [],
                "text": "A Structural Analysis of Complex Aerial Photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A new system for the structural analysis of complex aerial photographs is presented, which has the ability of focussing its attention of the analysis on the limited local areas where objects are highly supposed to exist."
            },
            "venue": {
                "fragments": [],
                "text": "Advanced Applications in Pattern Recognition"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2162080"
                        ],
                        "name": "M. Nagao",
                        "slug": "M.-Nagao",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Nagao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nagao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143658244"
                        ],
                        "name": "T. Matsuyama",
                        "slug": "T.-Matsuyama",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Matsuyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Matsuyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46630188"
                        ],
                        "name": "Y. Ikeda",
                        "slug": "Y.-Ikeda",
                        "structuredName": {
                            "firstName": "Yoshio",
                            "lastName": "Ikeda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ikeda"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 2
                            }
                        ],
                        "text": "tions that are manifestly viewpoint-dependent. The systems &dquo;use&dquo; image models. In Ohta\u2019s system (1980), the model includes the following relations : the sky touches the upper edge of the picture; the road touches the lower edge of the picture; trees are in the middle of the picture; and buildings have a linear upper boundary with the sky."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 140573540,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "1ab8bb065721116a174d48f4ca0d3612191d70e8",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Region-extraction-and-shape-analysis-in-aerial-Nagao-Matsuyama",
            "title": {
                "fragments": [],
                "text": "Region extraction and shape analysis in aerial photographs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107218307"
                        ],
                        "name": "A. J. Thomas",
                        "slug": "A.-J.-Thomas",
                        "structuredName": {
                            "firstName": "A",
                            "lastName": "Thomas",
                            "middleNames": [
                                "Judge"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60200548,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4b66deb80b4ed1b7e7f61676a92420df4c5de229",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : It is suggested that recent advances in the construction of artificial vision systems provide the beginnings of a framework for an information processing analysis of human visual perception. A review is made of some pertinent investigations which have appeared in the psychological literature, along with some of the salient and potentially useful theoretical concepts which have resulted from the attempts to build computer vision systems. An attempt is made to integrate these two sources of ideas to suggest some desirable structural and behavioral concepts which apply to both the natural and the artificial systems."
            },
            "slug": "Information-Processing-Analysis-of-Visual-A-Review-Thomas-Binford",
            "title": {
                "fragments": [],
                "text": "Information Processing Analysis of Visual Perception: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is suggested that recent advances in the construction of artificial vision systems provide the beginnings of a framework for an information processing analysis of human visual perception."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122614592,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "e966178de4f8ade134ad31e42d9b33117ab30598",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "General constraints on the interpretation of image boundaries are described and implemented. We illustrate the use of these constraints to carry out geometric interpretation of images up to the volumetric level. A general coincidence assumption is used to derive suggestive but incomplete interpretations for local features. A reasoning system is described which can use these suggestive hypotheses to derive consistent global interpretations, while maintaining the ability to remove the implications of hypotheses which are disproved in the face of further evidence. An important aspect of interpretation is the classification of image boundaries (intensity discontinuities) into those caused by geometric, reflectance, or illumination discontinuities. These interact with other hypotheses regarding occlusion by solid objects, the direction of illumination, aspects of object geometry, and the production of illumination discontinuities by geometric discontinuities. Although only a subset of the constraints and system design features have been implemented to date, we demonstrate the successful interpretation of some simulated image boundaries up to the volumetric level, including the construction of a three-space model."
            },
            "slug": "Interpretation-Of-Geometric-Structure-From-Image-Lowe-Binford",
            "title": {
                "fragments": [],
                "text": "Interpretation Of Geometric Structure From Image Boundaries"
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144862593"
                        ],
                        "name": "R. Nevatia",
                        "slug": "R.-Nevatia",
                        "structuredName": {
                            "firstName": "Ramakant",
                            "lastName": "Nevatia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nevatia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 22
                            }
                        ],
                        "text": "and linear features (roads, rivers, rail). ACRONYM has models of generic wide-bodied passenger aircraft, Lockheed\u2019s L-10I1, and Boeing\u2019s 747-B and 747-SP. Shirai\u2019s (1978) includes a few objects found"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 26
                            }
                        ],
                        "text": "20 systems take advantage of the limited set of objects by using predominantly top-down interpretation of images, and relying heavily on prediction. The systems use models of specific objects. For example, Ohta\u2019s (1980) uses a model in which a car is darker"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 364,
                                "start": 1
                            }
                        ],
                        "text": "not distinguish many objects in a complex visual environment. Humans may occasionally hallucinate in the same way, but usually they have strong evidence for interpretation. The primary limitation in seeking stronger evidence for interpretation is weak segmentation capability and weak implementation of observation primitives. For example, in Ohta\u2019s system (1980), shadows are identified as having low intensity; black objects would be confused with shadows in typical scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 2
                            }
                        ],
                        "text": "ground-level photographs also. Ohta (1980) demonstrated some success with a set of similar scenes"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 11
                            }
                        ],
                        "text": "Parma, Hanson, and Riseman (1980) take a color image of an outdoor scene and an image model with three-dimensional relations and build a symbolic model of the three-dimensional world shown in the image, in the form of names of objects and weak relations in three space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 995,
                                "start": 1
                            }
                        ],
                        "text": "no unique inverse, only very high orders of continuous infinities of projectively equivalent surfaces. Depth can be inferred from sequences of images (stereo, observer motion, object motion, photometric stereo). A primary problem is determining corresponding elements in the sequence. Direct depth measurement avoids the correspondence problems of reconstructing depth data from image sequences. There are much greater problems in inferring surface structure and depth relations from single images. One key to performance of systems is in their use of measurements that are simply related to characteristic properties of surfaces and to three-space relations of surfaces. Surface reflectivity and surface material are often characteristic (e.g., concrete and asphalt roads, or vegetation). Surface material can be partially inferred from color and texture. Intrinsic properties such as color, texture, and shape thus provide powerful and simple clues to interpretation. In Rubin\u2019s system (1978), 44% identification of pixels was achieved with the intensity of the blue channel alone."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 11
                            }
                        ],
                        "text": "Ballard, Brown, and Feldman (1978) use image models in locating ships at docks and in locating ribs in chest x-rays."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1201,
                                "start": 1
                            }
                        ],
                        "text": "no unique inverse, only very high orders of continuous infinities of projectively equivalent surfaces. Depth can be inferred from sequences of images (stereo, observer motion, object motion, photometric stereo). A primary problem is determining corresponding elements in the sequence. Direct depth measurement avoids the correspondence problems of reconstructing depth data from image sequences. There are much greater problems in inferring surface structure and depth relations from single images. One key to performance of systems is in their use of measurements that are simply related to characteristic properties of surfaces and to three-space relations of surfaces. Surface reflectivity and surface material are often characteristic (e.g., concrete and asphalt roads, or vegetation). Surface material can be partially inferred from color and texture. Intrinsic properties such as color, texture, and shape thus provide powerful and simple clues to interpretation. In Rubin\u2019s system (1978), 44% identification of pixels was achieved with the intensity of the blue channel alone. Remote sensing has depended on pixel classification based on spectral properties. Nagao, Matsuyama, and Ikeda (1978) use spectral properties of vegetation; shape descriptors, including elongation and straight boundary; and a simple texture descriptor."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1348,
                                "start": 1
                            }
                        ],
                        "text": "no unique inverse, only very high orders of continuous infinities of projectively equivalent surfaces. Depth can be inferred from sequences of images (stereo, observer motion, object motion, photometric stereo). A primary problem is determining corresponding elements in the sequence. Direct depth measurement avoids the correspondence problems of reconstructing depth data from image sequences. There are much greater problems in inferring surface structure and depth relations from single images. One key to performance of systems is in their use of measurements that are simply related to characteristic properties of surfaces and to three-space relations of surfaces. Surface reflectivity and surface material are often characteristic (e.g., concrete and asphalt roads, or vegetation). Surface material can be partially inferred from color and texture. Intrinsic properties such as color, texture, and shape thus provide powerful and simple clues to interpretation. In Rubin\u2019s system (1978), 44% identification of pixels was achieved with the intensity of the blue channel alone. Remote sensing has depended on pixel classification based on spectral properties. Nagao, Matsuyama, and Ikeda (1978) use spectral properties of vegetation; shape descriptors, including elongation and straight boundary; and a simple texture descriptor. Ohta (1980) uses color, simple texture, straight boundary, and hole, in addition to nonin-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 431,
                                "start": 8
                            }
                        ],
                        "text": "ments shown are with hand-drawn segments. The system also uses Shafer\u2019s version of Ohlander\u2019s segmentation (Ohlander 1975; Shafer and Kanade 1980). View angle is determined to 51\u00b0. ARGOS uses &dquo;adjacency first-order&dquo; Markov evaluation, which relates all surrounding nodes to the node under consideration. ARGOS has units called primitive picture elements (PPES) that may be segments from Shafer and Kanade\u2019s system (1980) or that may be individual pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10878162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dd5ad87ccf9b8493625e38514e2f37ab9ce99cb",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Description-and-Recognition-of-Curved-Objects-Nevatia-Binford",
            "title": {
                "fragments": [],
                "text": "Description and Recognition of Curved Objects"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2760919"
                        ],
                        "name": "S. Rubin",
                        "slug": "S.-Rubin",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Rubin",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60526133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7d1d6259e93f727458a5d08986101cb333c2999",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : ARGOS is an image understanding system. It builds a three-dimensional model of the task domain and uses hypothesized two-dimensional views of the model to label images. It currently achieves less than 20% error by area when labeling real-world (city of Pittsburgh) photographs with a knowledge base of over fifty objects. In addition, the system can determine the angle of view around the city with approximately 40 degrees of error. The labeling technique used by ARGOS is called Locus search. Locus is a non-backtracking graph search technique in which a beam of near-miss alternatives around the best path are extended in parallel through the graph. After the graph has been searched in breadth-first order, the beam of possibilities is examined in reverse order to extract a near-optimal path. This path defines a labeling of the image and is only sub-optimal because of the pruning heuristics used in the beam creation. This thesis formulates image understanding as a problem of search; shows how Locus search can be used to label images; describes the many sources of knowledge used in the interpretation; shows how knowledge represented as a network can be used to constrain the search; explores extensions to the use of knowledge; and presents the experimental results of ARGOS. Its main contributions are the demonstration that Locus search can be used for image understanding and the exploration of issues involved in this use."
            },
            "slug": "The-argos-image-understanding-system.-Rubin",
            "title": {
                "fragments": [],
                "text": "The argos image understanding system."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The demonstration that Locus search can be used for image understanding and the exploration of issues involved in this use are the main contributions of this thesis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16993897"
                        ],
                        "name": "Manfred H. Hueckel",
                        "slug": "Manfred-H.-Hueckel",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Hueckel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manfred H. Hueckel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 330
                            }
                        ],
                        "text": "Two types of features were studied: (1) cornerlike features obtained by an interest operator and matched by a binary-search correlator (Moravec 1980) and (2) curve features predicted by a geometric model of the object (Miyamoto and Binford 1975) and determined by a curve-verification procedure based on the Hueckel edge operator (Hueckel 1973)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c00ff22f6923943da0d2c3b2de95c1c33186b93",
            "isKey": false,
            "numCitedBy": 276,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "An earlier published edge operator is generalized so as to include line recognition. The linear projection space as well as the nonlinear pattern space is extended. The recognition principle of the old operator is further investigated and put to use for \"edge-line\" recognition. A new Solution Theorem presolves the recognition problem in generality and thus leaves only final evaluations to the computer. The speed of the operator is 23 arithmetic operations per picture point. A description of the edge or line and a reliability assessment accompany every recognition process. The operator program and a computer experiment are presented."
            },
            "slug": "A-Local-Visual-Operator-Which-Recognizes-Edges-and-Hueckel",
            "title": {
                "fragments": [],
                "text": "A Local Visual Operator Which Recognizes Edges and Lines"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An earlier published edge operator is generalized so as to include line recognition, and a new Solution Theorem presolves the recognition problem in generality and thus leaves only final evaluations to the computer."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4688361"
                        ],
                        "name": "E. Land",
                        "slug": "E.-Land",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Land",
                            "middleNames": [
                                "Herbert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Land"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144495967"
                        ],
                        "name": "J. McCann",
                        "slug": "J.-McCann",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McCann",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McCann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14430259,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a2f9c78b094ccd50cbb175193d2993735d39c6a6",
            "isKey": false,
            "numCitedBy": 3175,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Sensations of color show a strong correlation with reflectance, even though the amount of visible light reaching the eye depends on the product of reflectance and illumination. The visual system must achieve this remarkable result by a scheme that does not measure flux. Such a scheme is described as the basis of retinex theory. This theory assumes that there are three independent cone systems, each starting with a set of receptors peaking, respectively, in the long-, middle-, and short-wavelength regions of the visible spectrum. Each system forms a separate image of the world in terms of lightness that shows a strong correlation with reflectance within its particular band of wavelengths. These images are not mixed, but rather are compared to generate color sensations. The problem then becomes how the lightness of areas in these separate images can be independent of flux. This article describes the mathematics of a lightness scheme that generates lightness numbers, the biologic correlate of reflectance, independent of the flux from objects"
            },
            "slug": "Lightness-and-retinex-theory.-Land-McCann",
            "title": {
                "fragments": [],
                "text": "Lightness and retinex theory."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The mathematics of a lightness scheme that generates lightness numbers, the biologic correlate of reflectance, independent of the flux from objects is described."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America"
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059732530"
                        ],
                        "name": "T. G. Evans",
                        "slug": "T.-G.-Evans",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Evans",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. G. Evans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18984792,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f395c0b69dc0da249fd9c6a2a964ddc3bb79babd",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this paper is to describe a program now in existence which is capable of solving a wide class of the so-called 'geometric-analogy' problems frequently encountered on intelligence tests. Each member of this class of problems consists of a set of labeled line drawings. The task to be performed can be concisely described by the question: 'figure A is to figure B as figure C is to which of the given answer figures?' For example, given the problem illustrated as Fig. 1, the geometric-analogy program (which we shall subsequently call ANALOGY, for brevity) selected the problem figure labeled 4 as its answer. It seems safe to say that most people would agree with ANALOGY's answer to this problem (which, incidentally, is taken from the 1942 edition of the Psychological Test for College Freshmen of the American Council on Education). Furthermore, if one were required to make explicit the reasoning by which he arrived at his answer, prospects are good that the results would correspond closely to the description of its 'reasoning' produced by ANALOGY."
            },
            "slug": "A-heuristic-program-to-solve-geometric-analogy-Evans",
            "title": {
                "fragments": [],
                "text": "A heuristic program to solve geometric-analogy problems"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A program now in existence which is capable of solving a wide class of the so-called 'geometric-analogy' problems frequently encountered on intelligence tests, which consists of a set of labeled line drawings."
            },
            "venue": {
                "fragments": [],
                "text": "AFIPS '64 (Spring)"
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066894"
                        ],
                        "name": "Hans P. Moravec",
                        "slug": "Hans-P.-Moravec",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Moravec",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hans P. Moravec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 128525458,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "93b376bd451db8ed94a18c556da16f25a3e7961b",
            "isKey": false,
            "numCitedBy": 1053,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The Stanford AI Lab cart is a card-table sized mobile robot controlled remotely through a radio link, and equipped with a TV camera and transmitter. A computer has been programmed to drive the cart through cluttered indoor and outdoor spaces, gaining its knowledge of the world entirely from images broadcast by the onboard TV system. The cart uses several kinds of stereo to locate objects around it in 3D and to deduce its own motion. It plans an obstacle avoiding path to a desired destination on the basis of a model built with this information. The plan changes as the cart perceives new obstacles on its journey. The system is reliable for short runs, but slow. The cart moves one meter every ten to fifteen minutes, in lurches. After rolling a meter it stops, takes some pictures and thinks about them for a long time. Then it plans a new path, executes a little of it, and pauses again. The program has successfully driven the cart through several 20 meter indoor courses (each taking about five hours) complex enough to necessitate three or four avoiding swerves. A less successful outdoor run, in which the cart skirted two obstacles but collided with a third, was also done. Harsh lighting (very bright surfaces next to very dark shadows) giving poor pictures and movement of shadows during the cart's creeping progress were major reasons for the poorer outdoor performance. The action portions of these runs were filmed by computer controlled cameras. (Author)"
            },
            "slug": "Obstacle-avoidance-and-navigation-in-the-real-world-Moravec",
            "title": {
                "fragments": [],
                "text": "Obstacle avoidance and navigation in the real world by a seeing robot rover"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 54
                            }
                        ],
                        "text": "ACRONYM has identified aircraft in aerial photographs (Brooks 1981)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 8
                            }
                        ],
                        "text": "ACRONYM (Brooks 1981) utilizes shape descriptors that are ribbons and ellipses and describes a larger class of quasi-invariant observables of shape."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 8
                            }
                        ],
                        "text": "ACRONYM (Brooks 1981) is an implemented interpretation system containing a substantial core of fundamental mechanisms that are powerful and general."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 23
                            }
                        ],
                        "text": "An exception, ACRONYM (Brooks 1981), generates viewpoint-insensitive image models from object models in three space. The systems &dquo;know&dquo; few objects. Ohta\u2019s (1980) has four objects with subobjects. Nagao (1978) mentions about nine classes of areas, but the system described apparently distinguishes only four: fields (with vegetation or bare); buildings; wooded areas;"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 22
                            }
                        ],
                        "text": "An exception, ACRONYM (Brooks 1981), generates viewpoint-insensitive image models from object models in three space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 23
                            }
                        ],
                        "text": "An exception, ACRONYM (Brooks 1981), generates viewpoint-insensitive image models from object models in three space. The systems &dquo;know&dquo; few objects. Ohta\u2019s (1980) has four objects with subobjects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Symbolic reasoning among 3-dimensional models and 2-dimensional images"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 100
                            }
                        ],
                        "text": "That requires powerful capabilities for inference of shape such as those being developed in ACRONYM (Binford 1981)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 76
                            }
                        ],
                        "text": "Recent theoretical work on monocular interpretation of surfaces from images (Binford 1981; Lowe and Binford 1981) appear to promise that general mechanisms for generating spatial observations from images will be developed soon to support general vision systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 47
                            }
                        ],
                        "text": "of incorporating these capabilities in ACRONYM (Binford 1981)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 37551917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffcebfa2f4a8cc094f14d8ba68f8214246560b56",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Inferring-Surfaces-from-Images-Binford",
            "title": {
                "fragments": [],
                "text": "Inferring Surfaces from Images"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2739823"
                        ],
                        "name": "T. Garvey",
                        "slug": "T.-Garvey",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Garvey",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Garvey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 40
                            }
                        ],
                        "text": "The function of the system described by Garvey (1976) is to locate objects in an office environment in"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 140954692,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f4de24cd8f09e3ae1d0ccfa4ab3b933f9cdbcea4",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perceptual-strategies-for-purposive-vision-Garvey",
            "title": {
                "fragments": [],
                "text": "Perceptual strategies for purposive vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076857013"
                        ],
                        "name": "\u5927\u7530 \u53cb\u4e00",
                        "slug": "\u5927\u7530-\u53cb\u4e00",
                        "structuredName": {
                            "firstName": "\u5927\u7530",
                            "lastName": "\u53cb\u4e00",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5927\u7530 \u53cb\u4e00"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 198
                            }
                        ],
                        "text": "One vision system has succeeded in labeling large regions in aerial photographs (Nagao, Matsuyama, and Ikeda 1978); another has labeled large regions in a few outdoor scenes from ground-level views (Ohta 1980)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57211036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f219a35497ad2e244b8cfc725bcb20a45b1777a5",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-region-oriented-image-analysis-system-by-computer-\u5927\u7530",
            "title": {
                "fragments": [],
                "text": "A region-oriented image-analysis system by computer"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image understanding at CMU"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ARPA Image"
            },
            "year": 1981
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lightness and ret"
            },
            "venue": {
                "fragments": [],
                "text": "Science Applications,"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 44
                            }
                        ],
                        "text": "This approach is closely related to the one Evans (1968) uses in solving analogy problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A heuristic program"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "knowledge-directed image analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Horn (1973) has demonstrated partial success with color constancy; however, that capability is not integrated in any system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On lightness"
            },
            "venue": {
                "fragments": [],
                "text": "Memo 295. Cambridge, Mass.: Massachusetts Institute of Technology Artificial Intelligence Laboratory."
            },
            "year": 1973
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Survey-of-Model-Based-Image-Analysis-Systems-Binford/92b5734b814d72bf69920864816612f255e2e5bf?sort=total-citations"
}