{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115625054"
                        ],
                        "name": "Yalin Wang",
                        "slug": "Yalin-Wang",
                        "structuredName": {
                            "firstName": "Yalin",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yalin Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47756656"
                        ],
                        "name": "Jianying Hu",
                        "slug": "Jianying-Hu",
                        "structuredName": {
                            "firstName": "Jianying",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianying Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 1
                            }
                        ],
                        "text": "(Wang\n& Hu 2002) classified web tables into genuine tables and non-genuine tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2061833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89945f77470b6a1dabd1f224f10b7d096fd9435",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Table is a commonly used presentation scheme, especially for describing relational information. However, table understanding remains an open problem. In this paper, we consider the problem of table detection in web documents. Its potential applications include web mining, knowledge management, and web content summarization and delivery to narrow-bandwidth devices. We describe a machine learning based approach to classify each given table entity as either genuine or non-genuine. Various features reflecting the layout as well as content characteristics of tables are studied.In order to facilitate the training and evaluation of our table classifier, we designed a novel web document table ground truthing protocol and used it to build a large table ground truth database. The database consists of 1,393 HTML files collected from hundreds of different web sites and contains 11,477 leaf TABLE elements, out of which 1,740 are genuine tables. Experiments were conducted using the cross validation method and an F-measure of 95.89% was achieved."
            },
            "slug": "A-machine-learning-based-approach-for-table-on-the-Wang-Hu",
            "title": {
                "fragments": [],
                "text": "A machine learning based approach for table detection on the web"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A machine learning based approach to classify each given table entity as either genuine or non-genuine, and designed a novel web document table ground truthing protocol and used it to build a large table ground truth database."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '02"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 11
                            }
                        ],
                        "text": "TableSeer (Liu et al. 2007) is used to extract tables from these files."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 114
                            }
                        ],
                        "text": "This research is based on an existing table extraction tool, which is part of the search engine system TableSeer (Liu et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 289
                            }
                        ],
                        "text": "Through manual judgment, we find that some document components such as algorithms, code and, figures are mistakenly detected as tables; some tables with image cells are detected as empty, and some do not contain any text content due to the errors made by the PDFBOX 1 parse engine used in TableSeer."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2940120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "627ae41c9e345f002a766cdb777fdac91d5f5427",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are ubiquitous in digital libraries. In scientific documents, tables are widely used to present experimental results or statistical data in a condensed fashion. However, current search engines do not support table search. The difficulty of automatic extracting tables from un-tagged documents, the lack of a universal table metadata specification, and the limitation of the existing ranking schemes make table search problem challenging. In this paper, we describe TableSeer, a search engine for tables. TableSeer crawls digital libraries, detects tables from documents, extracts tables metadata, indexes and ranks tables, and provides a user-friendly search interface. We propose an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information. In addition, we devise a novel page box-cutting method to improve the performance of the table detection. Given a query, TableSeer ranks the matched tables using an innovative ranking algorithm - TableRank. TableRank rates each \u20edquery, table\u2102 pair with a tailored vector space model and a specific term weighting scheme. Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables. We demonstrate the value of TableSeer with empirical studies on scientific documents."
            },
            "slug": "TableSeer:-automatic-table-metadata-extraction-and-Liu-Bai",
            "title": {
                "fragments": [],
                "text": "TableSeer: automatic table metadata extraction and searching in digital libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Overall, TableSeer eliminates the burden of manually extract table data from digital libraries and enables users to automatically examine tables, and proposes an extensive set of medium-independent metadata for tables that scientists and other users can adopt for representing table information."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1957282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b05417cde0ae70e1c74a364a89e2661db5f1231",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Most prior work on information extraction has focused on extracting information from text in digital documents. However, often, the most important information being reported in an article is presented in tabular form in a digital document. If the data reported in tables can be extracted and stored in a database, the data can be queried and joined with other data using database management systems. In order to prepare the data source for table search, accurately detecting the table boundary plays a crucial role for the later table structure decomposition. Table boundary detection and content extraction is a challenging problem because tabular formats are not standardized across all documents. In this paper, we propose a simple but effective preprocessing method to improve the table boundary detection performance by considering the sparse-line property of table rows. Our method easily simplifies the table boundary detection problem into the sparse line analysis problem with much less noise. We design eight line label types and apply two machine learning techniques, Conditional Random Field (CRF) and Support Vector Machines (SVM), on the table boundary detection field. The experimental results not only compare the performances between the machine learning methods and the heuristics-based method, but also demonstrate the effectiveness of the sparse line analysis in the table boundary detection."
            },
            "slug": "Identifying-table-boundaries-in-digital-documents-Liu-Mitra",
            "title": {
                "fragments": [],
                "text": "Identifying table boundaries in digital documents via sparse line detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a simple but effective preprocessing method to improve the table boundary detection performance by considering the sparse-line property of table rows, and designs eight line label types and applies two machine learning techniques, Conditional Random Field and Support Vector Machines, on the table Boundary detection field."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109793763"
                        ],
                        "name": "Seongchan Kim",
                        "slug": "Seongchan-Kim",
                        "structuredName": {
                            "firstName": "Seongchan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seongchan Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40566342"
                        ],
                        "name": "Ying Liu",
                        "slug": "Ying-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 73
                            }
                        ],
                        "text": "Kim and Liu proposed a function-based table categories detection method (Kim & Liu 2011)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5373335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc025a37842475ed10cfc6455cce6d1d3511c170",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Better understanding the document logical components is crucial to many applications, e.g., document classification or data integration. As the development of digital libraries, more people realize the importance of the scientific tables, which contain valuable information concisely. Although tons of previous table works focus on table data extraction, few concrete works on understanding and utilizing the extracted table data exist. Based on a large-scaled quantitative study on scientific papers, we believe that identifying the original purpose of the table authors can improve the table data comprehension and facilitate the table data reusability. In this paper, scientific document tables are classified into three topical categories: background, system/method, and experimental, and two functional categories: commentary and comparison. We apply machine learning based methods to implement the table classification task. Our results demonstrate that the proposed features are effective in the classification performance and our proposed method outperforms the rule-based baseline significantly."
            },
            "slug": "Functional-Based-Table-Category-Identification-in-Kim-Liu",
            "title": {
                "fragments": [],
                "text": "Functional-Based Table Category Identification in Digital Library"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is believed that identifying the original purpose of the table authors can improve the table data comprehension and facilitate the tableData reusability and the proposed method outperforms the rule-based baseline significantly."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 27
                            }
                        ],
                        "text": "A table processing survey (Lopresti & Nagy 1999) shows 15 examples for tables and demonstrates how much tables may be different from each other in actual documents."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30699745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cd207fa19e51db1d6eadb0e5e70f1c5b8d1ecd0",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are the only acceptable means of communicating certain types of structured data. A precise definition of \"tabularity\" remains elusive because some bureaucratic forms, multicolumn text layouts, and schematic drawings share many characteristics of tables. There are significant differences between typeset tables, electronic files designed for display of tables, and tables in symbolic form intended for information retrieval. Although most research to date has addressed the extraction of low-level geometric information from scanned raster images of paper tables, the recent trend toward the analysis of tables in electronic form may pave the way to a higherl evel of table understanding. \n \nRecent research on table composition and table analysis has improved ourunde rstanding of the distinction between the logical and physical structures of tables, and has led to improved formalisms for modeling tables. The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display. \n \nAlthough tables are not a conventional format for conveying the primary content of technical papers, here we attempt to subdue our natural garrulity by adopting this genre to communicate what we have to say about tables entirely in tabular form."
            },
            "slug": "A-Tabular-Survey-of-Automated-Table-Processing-Lopresti-Nagy",
            "title": {
                "fragments": [],
                "text": "A Tabular Survey of Automated Table Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present study indicates that progress on half-a-dozen specific research issues would open the door to using existing paper and electronic tables for database update, tabular browsing, structured information retrieval through graphical and audio interfaces, multimedia table editing, and platform-independent display."
            },
            "venue": {
                "fragments": [],
                "text": "GREC"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981964"
                        ],
                        "name": "Dongpu Jin",
                        "slug": "Dongpu-Jin",
                        "structuredName": {
                            "firstName": "Dongpu",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongpu Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694279"
                        ],
                        "name": "D. Embley",
                        "slug": "D.-Embley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Embley",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Embley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33051894"
                        ],
                        "name": "Spencer Machado",
                        "slug": "Spencer-Machado",
                        "structuredName": {
                            "firstName": "Spencer",
                            "lastName": "Machado",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Spencer Machado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 559386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c7156cc9917ef0f231aa41a9e2a44caad3e9705",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method based on header paths for efficient and complete extraction of labeled data from tables meant for humans. Although many table configurations yield to the proposed syntactic analysis, some require access to semantic knowledge. Clicking on one or two critical cells per table, through a simple interface, is sufficient to resolve most of these problem tables. Header paths, a purely syntactic representation of visual tables, can be transformed (\"factored\") into existing representations of structured data such as category trees, relational tables, and RDF triples. From a random sample of 200 web tables from ten large statistical web sites, we generated 376 relational tables and 34,110 subject-predicate-object RDF triples."
            },
            "slug": "Data-Extraction-from-Web-Tables:-The-Devil-is-in-Nagy-Seth",
            "title": {
                "fragments": [],
                "text": "Data Extraction from Web Tables: The Devil is in the Details"
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759801"
                        ],
                        "name": "Ermelinda Oro",
                        "slug": "Ermelinda-Oro",
                        "structuredName": {
                            "firstName": "Ermelinda",
                            "lastName": "Oro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ermelinda Oro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794345"
                        ],
                        "name": "M. Ruffolo",
                        "slug": "M.-Ruffolo",
                        "structuredName": {
                            "firstName": "Massimo",
                            "lastName": "Ruffolo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ruffolo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5900801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99ecff93087b010e466d47aca2eedece88929aab",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents PDF-TREX, an heuristic approach for table recognition and extraction from PDF documents.The heuristics starts from an initial set of basic content elements and aligns and groups them, in bottom-up way by considering only their spatial features, in order to identify tabular arrangements of information. The scope of the approach is to recognize tables contained in PDF documents as a 2-dimensional grid on a Cartesian plane and extract them as a set of cells equipped by 2-dimensional coordinates. Experiments, carried out on a dataset composed of tables contained in documents coming from different domains, shows that the approach is well performing in recognizing table cells.The approach aims at improving PDF document annotation and information extraction by providing an output that can be further processed for understanding table and document contents."
            },
            "slug": "PDF-TREX:-An-Approach-for-Recognizing-and-Tables-Oro-Ruffolo",
            "title": {
                "fragments": [],
                "text": "PDF-TREX: An Approach for Recognizing and Extracting Tables from PDF Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The approach aims at improving PDF document annotation and information extraction by providing an output that can be further processed for understanding table and document contents."
            },
            "venue": {
                "fragments": [],
                "text": "2009 10th International Conference on Document Analysis and Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46398476"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143930195"
                        ],
                        "name": "P. Mitra",
                        "slug": "P.-Mitra",
                        "structuredName": {
                            "firstName": "Prasenjit",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654778"
                        ],
                        "name": "Kun Bai",
                        "slug": "Kun-Bai",
                        "structuredName": {
                            "firstName": "Kun",
                            "lastName": "Bai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kun Bai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 159
                            }
                        ],
                        "text": "It automatically identifies tables in PDF digital documents, detects table boundaries (Liu, Mitra, & Giles 2008) and extracts the contents in the table cells (Liu et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6795495,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ba3e110dfb9a5d70da1c257f3868f5d4842f341",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are used to present, list, summarize, and structure important data in documents. In scholarly articles, they are often used to present the relationships among data and highlight a collection of results obtained from experiments and scientific analysis. In digital libraries, extracting this data automatically and understanding the structure and content of tables are very important to many applications. Automatic identification extraction, and search for the contents of tables can be made more precise with the help of metadata. In this paper, we propose a set of medium-independent table metadata to facilitate the table indexing, searching, and exchanging. To extract the contents of tables and their metadata, an automatic table metadata extraction algorithm is designed and tested on PDF documents"
            },
            "slug": "Automatic-extraction-of-table-metadata-from-digital-Liu-Mitra",
            "title": {
                "fragments": [],
                "text": "Automatic extraction of table metadata from digital documents"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A set of medium-independent table metadata is proposed to facilitate the table indexing, searching, and exchanging and an automatic table metadata extraction algorithm is designed and tested on PDF documents."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 6th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL '06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2632608"
                        ],
                        "name": "B. Yildiz",
                        "slug": "B.-Yildiz",
                        "structuredName": {
                            "firstName": "Burcu",
                            "lastName": "Yildiz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yildiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804028"
                        ],
                        "name": "K. Kaiser",
                        "slug": "K.-Kaiser",
                        "structuredName": {
                            "firstName": "Katharina",
                            "lastName": "Kaiser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kaiser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692521"
                        ],
                        "name": "S. Miksch",
                        "slug": "S.-Miksch",
                        "structuredName": {
                            "firstName": "Silvia",
                            "lastName": "Miksch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miksch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17242556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dc08add84ef4070b00c2b43dac037bcfd6df460",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Tables are a common structuring element in many documents, such as PDF files. To reuse such tables, appropriate methods need to be develop, which capture the structure and the content information. We have developed several heuristics which together recognize and decompose tables in PDF files and store the extracted data in a structured data format (XML) for easier reuse. Additionally, we implemented a prototype, which gives the user the ability of making adjustments on the extracted data. Our work shows that purely heuristic-based approaches can achieve good results, especially for lucid tables."
            },
            "slug": "pdf2table:-A-Method-to-Extract-Table-Information-Yildiz-Kaiser",
            "title": {
                "fragments": [],
                "text": "pdf2table: A Method to Extract Table Information from PDF Files"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work developed several heuristics which together recognize and decompose tables in PDF files and store the extracted data in a structured data format (XML) for easier reuse and shows that purely heuristic-based approaches can achieve good results, especially for lucid tables."
            },
            "venue": {
                "fragments": [],
                "text": "IICAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145062511"
                        ],
                        "name": "S. Seth",
                        "slug": "S.-Seth",
                        "structuredName": {
                            "firstName": "Sharad",
                            "lastName": "Seth",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32686247"
                        ],
                        "name": "R. Jandhyala",
                        "slug": "R.-Jandhyala",
                        "structuredName": {
                            "firstName": "Ramana",
                            "lastName": "Jandhyala",
                            "middleNames": [
                                "Chakradhar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jandhyala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751773"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mukkai",
                            "lastName": "Krishnamoorthy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145916951"
                        ],
                        "name": "G. Nagy",
                        "slug": "G.-Nagy",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nagy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 205
                            }
                        ],
                        "text": "The former refers to segmenting table cells, rows, and columns, while the latter aims at finding out about table headers, extraction of header hierarchy, and analysis of index relations (Hirayama 1995) - (Seth et al 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16786910,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb36f1d41b79f766a5b98704808222fde8c5d0b4",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a component of a document analysis system for constructing ontologies for domain-specific web tables imported into Excel. This component automates extraction of the Wang Notation for the column header of a table. Using column-header specific rules for XY cutting we convert the geometric structure of the column header to a linear string denoting cell attributes and directions of cuts. The string representation is parsed by a context-free grammar and the parse tree is further processed to produce an abstract data-type representation (the Wang notation tree) of each column category. Experiments were carried out to evaluate this scheme on the original and edited column headers of Excel tables drawn from a collection of 200 used in our earlier work. The transformed headers were obtained by editing the original column headers to conform to the format targeted by our grammar. Forty-four original headers and their reformatted versions were submitted as input to our software system. Our grammar was able to parse and the extract Wang notation tree for all the edited headers, but for only four of the original headers. We suggest extensions to our table grammar that would enable processing a larger fraction of headers without manual editing."
            },
            "slug": "Analysis-and-taxonomy-of-column-header-categories-Seth-Jandhyala",
            "title": {
                "fragments": [],
                "text": "Analysis and taxonomy of column header categories for web tables"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A component of a document analysis system for constructing ontologies for domain-specific web tables imported into Excel automates extraction of the Wang Notation for the column header of a table using column-header specific rules for XY cutting to convert the geometric structure of the column Header to a linear string denoting cell attributes and directions of cuts."
            },
            "venue": {
                "fragments": [],
                "text": "DAS '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73282614"
                        ],
                        "name": "Y. Hirayama",
                        "slug": "Y.-Hirayama",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Hirayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hirayama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 187
                            }
                        ],
                        "text": "The former refers to segmenting table cells, rows, and columns, while the latter aims at finding out about table headers, extraction of header hierarchy, and analysis of index relations (Hirayama 1995) - (Seth et al 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206774876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcf75b367f24919a8a4b0f627960f6d6bf5ae33f",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel method for table structure analysis. Many documents have table areas, and some have both table and figure areas. It is very important to be able to classify table and figure areas automatically. Furthermore, in tables, the column and row in which a character string is located are very important pieces of information. To detect and analyze table areas, the following method is applied: First, areas that may contain tables or figures are distinguished from text areas by the presence of horizontal and vertical lines. Next, the areas are assumed to be table areas and are analyzed as such. A judgment is made on whether each of the areas can in fact be a table area or not; in this way, the actual table areas are detected. Finally, the structures of the areas are analyzed and character strings in the areas are arranged by using the DP matching method. This method was applied to sixty-five pages of Japanese technical papers, magazines, manuals for software programs, and pages including 34 table areas, 48 line drawing areas, and 35 image areas. As a result, 96.6 percent of the areas were detected correctly and 91.7 percent of the tables were analyzed and arranged correctly."
            },
            "slug": "A-method-for-table-structure-analysis-using-DP-Hirayama",
            "title": {
                "fragments": [],
                "text": "A method for table structure analysis using DP matching"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper presents a novel method for table structure analysis that was applied to sixty-five pages of Japanese technical papers, magazines, manuals for software programs, and pages including 34 table areas, 48 line drawing areas, and 35 image areas."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18592170"
                        ],
                        "name": "Tamir Hassan",
                        "slug": "Tamir-Hassan",
                        "structuredName": {
                            "firstName": "Tamir",
                            "lastName": "Hassan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamir Hassan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144221846"
                        ],
                        "name": "Robert Baumgartner",
                        "slug": "Robert-Baumgartner",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Baumgartner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Baumgartner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 974385,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59b8cb6efb8505eb93b0f1da1e1007862b66c500",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a flexible method for detecting and understanding tables in PDF files, which is not reliant upon one particular feature being present, for example ruling lines or indentations, and is therefore applicable to a wide variety of visual presentations. We describe the steps required in transforming the low-level PDF instructions into text segments, lines and boxes on a page. We propose three different classifications for published tables, and develop methods to detect these tables and correctly identify their respective rows and columns. We also explain how to recognize spanning rows and columns, and multi-line rows. Experimental results show that our algorithm is effective in converting a wide variety of tabular presentations into HTML for information extraction purposes."
            },
            "slug": "Table-Recognition-and-Understanding-from-PDF-Files-Hassan-Baumgartner",
            "title": {
                "fragments": [],
                "text": "Table Recognition and Understanding from PDF Files"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A flexible method for detecting and understanding tables in PDF files, which is not reliant upon one particular feature being present, for example ruling lines or indentations, and is therefore applicable to a wide variety of visual presentations."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49915337"
                        ],
                        "name": "A. C. E. Silva",
                        "slug": "A.-C.-E.-Silva",
                        "structuredName": {
                            "firstName": "Ana",
                            "lastName": "Silva",
                            "middleNames": [
                                "Costa",
                                "e"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. C. E. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772839"
                        ],
                        "name": "A. Jorge",
                        "slug": "A.-Jorge",
                        "structuredName": {
                            "firstName": "Al\u00edpio",
                            "lastName": "Jorge",
                            "middleNames": [
                                "M\u00e1rio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jorge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66444903"
                        ],
                        "name": "L. Torgo",
                        "slug": "L.-Torgo",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Torgo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torgo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15425019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7f1c7ab6bb331944c0667b3ab75cba46021db1a",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper plans an end-to-end method for extracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information. We start by defining table. Then we describe the steps involved in extracting information from tables and analyse table-related research to place the contribution of different authors, find the paths research is following, and identify issues that are still unsolved. We then analyse current approaches to evaluating table processing algorithms and propose two new metrics for the task of segmenting cells/columns/rows. We proceed to design our own end-to-end method, where there is a higher interaction between different steps; we indicate how back loops in the usual order of the steps can reduce the possibility of errors and contribute to solving previously unsolved problems. Finally, we explore how the actual interpretation of the table not only allows inferring the accuracy of the overall extraction process but also contributes to actually improving its quality. In order to do so, we believe interpretation has to consider context-specific knowledge; we explore how the addition of this knowledge can be made in a plug-in/out manner, such that the overall method will maintain its operability in different contexts."
            },
            "slug": "Design-of-an-end-to-end-method-to-extract-from-Silva-Jorge",
            "title": {
                "fragments": [],
                "text": "Design of an end-to-end method to extract information from tables"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper plans an end-to-end method for extracting information from tables embedded in documents; input format is ASCII, to which any richer format can be converted, preserving all textual and much of the layout information."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3320897"
                        ],
                        "name": "T. Kieninger",
                        "slug": "T.-Kieninger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kieninger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kieninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145279674"
                        ],
                        "name": "A. Dengel",
                        "slug": "A.-Dengel",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Dengel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dengel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206776168,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d25a61cc0cd816eba75864912fe2f6f44be3cecf",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables. T-Recs works on the output of commercial OCR systems that provide the word bounding box geometry together with the text itself (e.g. Xerox ScanWorX). While T-Recs performs well on a number of document categories, business letters still remained a challenging domain because the T-Recs location heuristics are mislead by their header or footer resulting in a low recognition precision. Business letters such as invoices are a very interesting domain for industrial applications due to the large amount of documents to be analyzed and the importance of the data carried within their tables. Hence, we developed a more restrictive approach which is implemented in the T-Recs++ prototype. This paper describes the ideas of the T-Recs++ location and also proposes a quality evaluation measure that reflects the bottom-up strategy of either T-Recs or T-Recs++. Finally, some results comparing both systems on a collection of business letters are given."
            },
            "slug": "Applying-the-T-Recs-table-recognition-system-to-the-Kieninger-Dengel",
            "title": {
                "fragments": [],
                "text": "Applying the T-Recs table recognition system to the business letter domain"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This paper summarizes the core idea of the T-Recs table recognition system, an integrated system covering block-segmentation, table location and a model-free structural analysis of tables, and proposes a quality evaluation measure that reflects the bottom-up strategy of either T-recs or T- Recs++."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Sixth International Conference on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145501780"
                        ],
                        "name": "Matthew F. Hurst",
                        "slug": "Matthew-F.-Hurst",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hurst",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew F. Hurst"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901883"
                        ],
                        "name": "Shona Douglas",
                        "slug": "Shona-Douglas",
                        "structuredName": {
                            "firstName": "Shona",
                            "lastName": "Douglas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shona Douglas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14091058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "971af881cefc0bccb7f47046095d0a92f0de3152",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Describes a prototype system for assigning table cells to their proper place in the logical structure of the table, based on a simple model of table structure combined with a number of measures of cohesion between cells. A framework is presented for examining the effect of particular variables on the performance of the system, and preliminary results are presented showing the effect of cohesion measures based on the simplest domain-independent analyses, with the aim allowing future comparison with more knowledge-intensive analyses based on natural language processing. These baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as we require. Future work will pursue the aim of more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells."
            },
            "slug": "Layout-and-language:-preliminary-investigations-in-Hurst-Douglas",
            "title": {
                "fragments": [],
                "text": "Layout and language: preliminary investigations in recognizing the structure of tables"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "B baseline results suggest that very simple string-based cohesion measures are not sufficient to support the extraction of tuples as it is suggested that more adequate approximations to a notional subtype/supertype definition of the relationship between value cells and label cells are needed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793699"
                        ],
                        "name": "R. Zanibbi",
                        "slug": "R.-Zanibbi",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zanibbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zanibbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703931"
                        ],
                        "name": "D. Blostein",
                        "slug": "D.-Blostein",
                        "structuredName": {
                            "firstName": "Dorothea",
                            "lastName": "Blostein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Blostein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683822"
                        ],
                        "name": "J. Cordy",
                        "slug": "J.-Cordy",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Cordy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cordy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14319498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6e4c5aa32fd8180d336ce2b6ea8bf3194678636",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Table characteristics vary widely. Consequently, a great variety of computational approaches have been applied to table recognition. In this survey, the table recognition literature is presented as an interaction of table models, observations, transformations and inferences. A table model defines the physical and logical structure of tables; the model is used to detect tables, and to analyze and decompose the detected tables. Observations perform feature measurements and data lookup, transformations alter or restructure data, and inferences generate and test hypotheses. This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "slug": "A-Survey-of-Table-Recognition-:-Models-,-,-,-and-Zanibbi-Blostein",
            "title": {
                "fragments": [],
                "text": "A Survey of Table Recognition : Models , Observations , Transformations , and Inferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This presentation clarifies the decisions that are made by a table recognizer, and the assumptions and inferencing techniques that underlie these decisions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3100918"
                        ],
                        "name": "W. Wong",
                        "slug": "W.-Wong",
                        "structuredName": {
                            "firstName": "Wern",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143696281"
                        ],
                        "name": "David Mart\u00ednez",
                        "slug": "David-Mart\u00ednez",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mart\u00ednez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Mart\u00ednez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788025"
                        ],
                        "name": "L. Cavedon",
                        "slug": "L.-Cavedon",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Cavedon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cavedon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6773023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95d19871710a295fdd245ac3bad805f10075fe74",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the challenge of extracting information about genetic mutations from tables, an important source of information in scientific papers. We use various machine learning algorithms and feature sets, and evaluate performance in extracting fields associated with an existing handcreated database of mutations. We then show how classifying tabular information can be leveraged for the task of named entity detection for mutations."
            },
            "slug": "Extraction-of-Named-Entities-from-Tables-in-Gene-Wong-Mart\u00ednez",
            "title": {
                "fragments": [],
                "text": "Extraction of Named Entities from Tables in Gene Mutation Literature"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work investigates the challenge of extracting information about genetic mutations from tables, and shows how classifying tabular information can be leveraged for the task of named entity detection for mutations."
            },
            "venue": {
                "fragments": [],
                "text": "BioNLP@HLT-NAACL"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65207,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9419406"
                        ],
                        "name": "I. Witten",
                        "slug": "I.-Witten",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Witten",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Witten"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 202790837,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8a5a2ac9c63c7d055ef3f695229eba04ee688c7a",
            "isKey": false,
            "numCitedBy": 8993,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "tic regression, and it concerns studying the effect of covariates on the risk of disease. The chapter includes generalized estimating equations (GEE\u2019s) with computing using PROC GENMOD in SAS and multilevel analysis of clustered binary data using generalized linear mixed-effects models with PROC LOGISTIC. As a prelude to the following chapter on repeated-measures data, Chapter 5 presents time series analysis. The material on repeated-measures analysis uses linear additive models with GEE\u2019s and PROC MIXED in SAS for linear mixed-effects models. Chapter 7 is about survival data analysis. All computing throughout the book is done using SAS procedures."
            },
            "slug": "Data-Mining-Witten",
            "title": {
                "fragments": [],
                "text": "Data Mining"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71619391"
                        ],
                        "name": "\u0e2d\u0e19\u0e34\u0e23\u0e38\u0e18 \u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c",
                        "slug": "\u0e2d\u0e19\u0e34\u0e23\u0e38\u0e18-\u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c",
                        "structuredName": {
                            "firstName": "\u0e2d\u0e19\u0e34\u0e23\u0e38\u0e18",
                            "lastName": "\u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u0e2d\u0e19\u0e34\u0e23\u0e38\u0e18 \u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Then, we use the \u2018InfoGain\u2019 attribute evaluator of the Weka toolkit to choose the most important features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "3 http://www.r-project.org/\nintegrated in Weka, such as NiaveBayes, BayesNet, J48 (C4.5 decision tree algorithm), AdaBoost, etc."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 36
                            }
                        ],
                        "text": "For random forest, we use the Weka (Witten and Frank, 2005) toolkit, which contains a wide selection of in-built algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64641472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b42b1bfdc262bf99e9484e2e9df94df216b96374",
            "isKey": true,
            "numCitedBy": 10619,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Data-Mining-Practical-Machine-Learning-Tools-and-\u0e2a\u0e37\u0e1a\u0e2a\u0e34\u0e07\u0e2b\u0e4c",
            "title": {
                "fragments": [],
                "text": "Data Mining Practical Machine Learning Tools and Techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107834957"
                        ],
                        "name": "M. W. Green",
                        "slug": "M.-W.-Green",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Green",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. W. Green"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 162
                            }
                        ],
                        "text": "\u2026classifier with the popular RBF kernel, and the popular \u201cgrid-search\u201d and cross validation to find the optimal soft margin parameter C, ii) a logistic regression (Balakrishnan 1991) based classifier, and iii) a random forest based classifier (Breiman 2011) to separate the header from the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 213
                            }
                        ],
                        "text": "In our paper, we use i) an SVM (Burges 1998) based classifier with the popular RBF kernel, and the popular \u201cgrid-search\u201d and cross validation to find the optimal soft margin parameter C, ii) a logistic regression (Balakrishnan 1991) based classifier, and iii) a random forest based classifier (Breiman 2011) to separate the header from the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 124669532,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "f45ed4d0841fafc51915ef3b4bb42dd207f84349",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "2.-Handbook-of-the-Logistic-Distribution-Green",
            "title": {
                "fragments": [],
                "text": "2. Handbook of the Logistic Distribution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644344103"
                        ],
                        "name": "J. C. BurgesChristopher",
                        "slug": "J.-C.-BurgesChristopher",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "BurgesChristopher",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. BurgesChristopher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215966761,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6716697767fc601efc7690f40820d9ea7a7bf57c",
            "isKey": false,
            "numCitedBy": 13527,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, w..."
            },
            "slug": "A-Tutorial-on-Support-Vector-Machines-for-Pattern-BurgesChristopher",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Support Vector Machines for Pattern Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "This tutorial starts with an overview of the concepts of VC dimension and structural risk minimization and describes linear Support Vector Machines (SVMs) for separable and non-separable data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 159
                            }
                        ],
                        "text": "It automatically identifies tables in PDF digital documents, detects table boundaries (Liu, Mitra, & Giles 2008) and extracts the contents in the table cells (Liu et al. 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Extraction of Table Metadata from PDF Documents"
            },
            "venue": {
                "fragments": [],
                "text": "JCDL, 11"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 33
                            }
                        ],
                        "text": "For logical structure analysis, (Nagy et al 2010) presented a grammatical framework for parsing a linear string representation of column headers of tables in a range of specified formats for web pages."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table Metadata Headers, Augmentations and Aggregates. In DAS"
            },
            "venue": {
                "fragments": [],
                "text": "Table Metadata Headers, Augmentations and Aggregates. In DAS"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 33
                            }
                        ],
                        "text": "For logical structure analysis, (Nagy et al 2010) presented a grammatical framework for parsing a linear string representation of column headers of tables in a range of specified formats for web pages."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Table Metadata Headers, Augmentations and Aggregates"
            },
            "venue": {
                "fragments": [],
                "text": "DAS, 507 510."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 11
                            }
                        ],
                        "text": "TableSeer (Liu et al. 2007) is used to extract tables from these files."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 114
                            }
                        ],
                        "text": "This research is based on an existing table extraction tool, which is part of the search engine system TableSeer (Liu et al. 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 289
                            }
                        ],
                        "text": "Through manual judgment, we find that some document components such as algorithms, code and, figures are mistakenly detected as tables; some tables with image cells are detected as empty, and some do not contain any text content due to the errors made by the PDFBOX 1 parse engine used in TableSeer."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TableSeer : Automatic Table Metadata Extraction and Searching inDigital Libraries Categories and Subject Descriptors"
            },
            "venue": {
                "fragments": [],
                "text": "JCDL, 91 100."
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 6,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Table-Header-Detection-and-Classification-Fang-Mitra/9fbdeb0ed5d4adbb81ea8fe830ceabd6c398c06a?sort=total-citations"
}