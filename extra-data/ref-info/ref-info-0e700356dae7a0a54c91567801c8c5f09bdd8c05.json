{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 240
                            }
                        ],
                        "text": "Our approach is most related to recent work in modeling geometric scene structure from a single image: inferring qualitative geometry of surfaces [13], grouping lines into surfaces [16], and estimating volumetric representations of a scene [8, 12, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 117
                            }
                        ],
                        "text": "To address these shortcomings, there has been a recent push towards more geometric approaches to image understanding [8, 11, 13, 16, 20, 22, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16466083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e37993b6612f433057f737ad37785743f3c4436b",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Since most current scene understanding approaches operate either on the 2D image or using a surface-based representation, they do not allow reasoning about the physical constraints within the 3D scene. Inspired by the \"Blocks World\" work in the 1960's, we present a qualitative physical representation of an outdoor scene where objects have volume and mass, and relationships describe 3D structure and mechanical configurations. Our representation allows us to apply powerful global geometric constraints between 3D volumes as well as the laws of statics in a qualitative manner. We also present a novel iterative \"interpretation-by-synthesis\" approach where, starting from an empty ground plane, we progressively \"build up\" a physically-plausible 3D interpretation of the image. For surface layout estimation, our method demonstrates an improvement in performance over the state-of-the-art [9]. But more importantly, our approach automatically generates 3D parse graphs which describe qualitative geometric and mechanical properties of objects and relationships between objects within an image."
            },
            "slug": "Blocks-World-Revisited:-Image-Understanding-Using-Gupta-Efros",
            "title": {
                "fragments": [],
                "text": "Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a qualitative physical representation of an outdoor scene where objects have volume and mass, and relationships describe 3D structure and mechanical configurations, and automatically generates 3D parse graphs which describe qualitative geometric and mechanical properties of objects and relationships between objects within an image."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115317745"
                        ],
                        "name": "David C. Lee",
                        "slug": "David-C.-Lee",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lee",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 980317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3228234ab663758d7439d9ee8f30c8fb29db8e7f",
            "isKey": false,
            "numCitedBy": 245,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of generating plausible interpretations of a scene from a collection of line segments automatically extracted from a single indoor image. We show that we can recognize the three dimensional structure of the interior of a building, even in the presence of occluding objects. Several physically valid structure hypotheses are proposed by geometric reasoning and verified to find the best fitting model to line segments, which is then converted to a full 3D model. Our experiments demonstrate that our structure recovery from line segments is comparable with methods using full image appearance. Our approach shows how a set of rules describing geometric constraints between groups of segments can be used to prune scene interpretation hypotheses and to generate the most plausible interpretation."
            },
            "slug": "Geometric-reasoning-for-single-image-structure-Lee-Hebert",
            "title": {
                "fragments": [],
                "text": "Geometric reasoning for single image structure recovery"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown how a set of rules describing geometric constraints between groups of segments can be used to prune scene interpretation hypotheses and to generate the most plausible interpretation."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3236027"
                        ],
                        "name": "Varsha Hedau",
                        "slug": "Varsha-Hedau",
                        "structuredName": {
                            "firstName": "Varsha",
                            "lastName": "Hedau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varsha Hedau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 240
                            }
                        ],
                        "text": "Our approach is most related to recent work in modeling geometric scene structure from a single image: inferring qualitative geometry of surfaces [13], grouping lines into surfaces [16], and estimating volumetric representations of a scene [8, 12, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 73
                            }
                        ],
                        "text": "The building blocks of this work, single-view indoor geometry estimation [11, 12, 15, 16] and human pose analysis via motion capture [3], are by no means perfect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 135
                            }
                        ],
                        "text": "We adopt a geometric representation that is consistent with recent approaches for extracting indoor scene geometry from a single image [11, 12, 15, 16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2046975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f5cbb7295216d43247773d211295630012221f5",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we show that a geometric representation of an object occurring in indoor scenes, along with rich scene structure can be used to produce a detector for that object in a single image. Using perspective cues from the global scene geometry, we first develop a 3D based object detector. This detector is competitive with an image based detector built using state-of-the-art methods; however, combining the two produces a notably improved detector, because it unifies contextual and geometric information. We then use a probabilistic model that explicitly uses constraints imposed by spatial layout - the locations of walls and floor in the image - to refine the 3D object estimates. We use an existing approach to compute spatial layout [1], and use constraints such as objects are supported by floor and can not stick through the walls. The resulting detector (a) has significantly improved accuracy when compared to the state-of-the-art 2D detectors and (b) gives a 3D interpretation of the location of the object, derived from a 2D image. We evaluate the detector on beds, for which we give extensive quantitative results derived from images of real scenes."
            },
            "slug": "Thinking-Inside-the-Box:-Using-Appearance-Models-on-Hedau-Hoiem",
            "title": {
                "fragments": [],
                "text": "Thinking Inside the Box: Using Appearance Models and Context Based on Room Geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "It is shown that a geometric representation of an object occurring in indoor scenes, along with rich scene structure can be used to produce a detector for that object in a single image, and this detector has significantly improved accuracy when compared to the state-of-the-art 2D detectors."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Our approach is most related to recent work in modeling geometric scene structure from a single image: inferring qualitative geometry of surfaces [13], grouping lines into surfaces [16], and estimating volumetric representations of a scene [8, 12, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 117
                            }
                        ],
                        "text": "To address these shortcomings, there has been a recent push towards more geometric approaches to image understanding [8, 11, 13, 16, 20, 22, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37206,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5276705d71e3dac961ab5d06b86a7b806cc9af64",
            "isKey": false,
            "numCitedBy": 718,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans have an amazing ability to instantly grasp the overall 3D structure of a scene\u2014ground orientation, relative positions of major landmarks, etc.\u2014even from a single image. This ability is completely missing in most popular recognition algorithms, which pretend that the world is flat and/or view it through a patch-sized peephole. Yet it seems very likely that having a grasp of this \u201csurface layout\u201d of a scene should be of great assistance for many tasks, including recognition, navigation, and novel view synthesis.In this paper, we take the first step towards constructing the surface layout, a labeling of the image intogeometric classes. Our main insight is to learn appearance-based models of these geometric classes, which coarsely describe the 3D scene orientation of each image region. Our multiple segmentation framework provides robust spatial support, allowing a wide variety of cues (e.g., color, texture, and perspective) to contribute to the confidence in each geometric label. In experiments on a large set of outdoor images, we evaluate the impact of the individual cues and design choices in our algorithm. We further demonstrate the applicability of our method to indoor images, describe potential applications, and discuss extensions to a more complete notion of surface layout."
            },
            "slug": "Recovering-Surface-Layout-from-an-Image-Hoiem-Efros",
            "title": {
                "fragments": [],
                "text": "Recovering Surface Layout from an Image"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper takes the first step towards constructing the surface layout, a labeling of the image intogeometric classes, to learn appearance-based models of these geometric classes, which coarsely describe the 3D scene orientation of each image region."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115317745"
                        ],
                        "name": "David C. Lee",
                        "slug": "David-C.-Lee",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lee",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145670946"
                        ],
                        "name": "M. Hebert",
                        "slug": "M.-Hebert",
                        "structuredName": {
                            "firstName": "Martial",
                            "lastName": "Hebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17105597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63d4018a9882eba91da21052164775095d410f23",
            "isKey": false,
            "numCitedBy": 293,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been a recent push in extraction of 3D spatial layout of scenes. However, none of these approaches model the 3D interaction between objects and the spatial layout. In this paper, we argue for a parametric representation of objects in 3D, which allows us to incorporate volumetric constraints of the physical world. We show that augmenting current structured prediction techniques with volumetric reasoning significantly improves the performance of the state-of-the-art."
            },
            "slug": "Estimating-Spatial-Layout-of-Rooms-using-Volumetric-Lee-Gupta",
            "title": {
                "fragments": [],
                "text": "Estimating Spatial Layout of Rooms using Volumetric Reasoning about Objects and Surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper argues for a parametric representation of objects in 3D, which allows us to incorporate volumetric constraints of the physical world, and shows that augmenting current structured prediction techniques withvolumetric reasoning significantly improves the performance of the state-of-the-art."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38916673"
                        ],
                        "name": "B. Yao",
                        "slug": "B.-Yao",
                        "structuredName": {
                            "firstName": "Bangpeng",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7352553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "927432c50d920e647260c67506859d7845c7f729",
            "isKey": false,
            "numCitedBy": 576,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting objects in cluttered scenes and estimating articulated human body parts are two challenging problems in computer vision. The difficulty is particularly pronounced in activities involving human-object interactions (e.g. playing tennis), where the relevant object tends to be small or only partially visible, and the human body parts are often self-occluded. We observe, however, that objects and human poses can serve as mutual context to each other \u2013 recognizing one facilitates the recognition of the other. In this paper we propose a new random field model to encode the mutual context of objects and human poses in human-object interaction activities. We then cast the model learning task as a structure learning problem, of which the structural connectivity between the object, the overall human pose, and different body parts are estimated through a structure search approach, and the parameters of the model are estimated by a new max-margin algorithm. On a sports data set of six classes of human-object interactions [12], we show that our mutual context model significantly outperforms state-of-the-art in detecting very difficult objects and human poses."
            },
            "slug": "Modeling-mutual-context-of-object-and-human-pose-in-Yao-Fei-Fei",
            "title": {
                "fragments": [],
                "text": "Modeling mutual context of object and human pose in human-object interaction activities"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new random field model is proposed to encode the mutual context of objects and human poses in human-object interaction activities and it is shown that this mutual context model significantly outperforms state-of-the-art in detecting very difficult objects andhuman poses."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3236027"
                        ],
                        "name": "Varsha Hedau",
                        "slug": "Varsha-Hedau",
                        "structuredName": {
                            "firstName": "Varsha",
                            "lastName": "Hedau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varsha Hedau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 191
                            }
                        ],
                        "text": "We decided to limit our focus to indoor scenes, since they allow for more interesting human interactions, and since several approaches exist specifically for estimating indoor scene geometry [11, 15] (Section 3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 135
                            }
                        ],
                        "text": "We adopt a geometric representation that is consistent with recent approaches for extracting indoor scene geometry from a single image [11, 12, 15, 16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "For robustness, we use two sources of geometry based on the outputs of [11, 15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "We also compute the probability of each pixel being associated with object/clutter using the surface layout algorithm [11] (Figure 5b)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "Since we build upon the results of [11, 15], we use the same set of test images used in these papers."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 26
                            }
                        ],
                        "text": "3We used images for which [11, 15] report reasonable vanishing point estimates."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 117
                            }
                        ],
                        "text": "To address these shortcomings, there has been a recent push towards more geometric approaches to image understanding [8, 11, 13, 16, 20, 22, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 73
                            }
                        ],
                        "text": "The building blocks of this work, single-view indoor geometry estimation [11, 12, 15, 16] and human pose analysis via motion capture [3], are by no means perfect."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6619564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "451a06626afe8dd70099c7dfec86de7af909a062",
            "isKey": true,
            "numCitedBy": 484,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the problem of recovering the spatial layout of indoor scenes from monocular images. The presence of clutter is a major problem for existing single-view 3D reconstruction algorithms, most of which rely on finding the ground-wall boundary. In most rooms, this boundary is partially or entirely occluded. We gain robustness to clutter by modeling the global room space with a parameteric 3D \u201cbox\u201d and by iteratively localizing clutter and refitting the box. To fit the box, we introduce a structured learning algorithm that chooses the set of parameters to minimize error, based on global perspective cues. On a dataset of 308 images, we demonstrate the ability of our algorithm to recover spatial layout in cluttered rooms and show several examples of estimated free space."
            },
            "slug": "Recovering-the-spatial-layout-of-cluttered-rooms-Hedau-Hoiem",
            "title": {
                "fragments": [],
                "text": "Recovering the spatial layout of cluttered rooms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces a structured learning algorithm that chooses the set of parameters to minimize error, based on global perspective cues, and gains robustness to clutter by modeling the global room space with a parameteric 3D \u201cbox\u201d and by iteratively localizing clutter and refitting the box."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144971290"
                        ],
                        "name": "K. Yamane",
                        "slug": "K.-Yamane",
                        "structuredName": {
                            "firstName": "Katsu",
                            "lastName": "Yamane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yamane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722785"
                        ],
                        "name": "J. Kuffner",
                        "slug": "J.-Kuffner",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kuffner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kuffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788773"
                        ],
                        "name": "J. Hodgins",
                        "slug": "J.-Hodgins",
                        "structuredName": {
                            "firstName": "Jessica",
                            "lastName": "Hodgins",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hodgins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Researchers in computer graphics have looked into generating sets of constraints on human motions when interacting with objects in an environment [ 24 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12904685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15d434ece6ec032db3d429aeab8041ca2d938c71",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Even such simple tasks as placing a box on a shelf are difficult to animate, because the animator must carefully position the character to satisfy geometric and balance constraints while creating motion to perform the task with a natural-looking style. In this paper, we explore an approach for animating characters manipulating objects that combines the power of path planning with the domain knowledge inherent in data-driven, constraint-based inverse kinematics. A path planner is used to find a motion for the object such that the corresponding poses of the character satisfy geometric, kinematic, and posture constraints. The inverse kinematics computation of the character's pose resolves redundancy by biasing the solution toward natural-looking poses extracted from a database of captured motions. Having this database greatly helps to increase the quality of the output motion. The computed path is converted to a motion trajectory using a model of the velocity profile. We demonstrate the effectiveness of the algorithm by generating animations across a wide range of scenarios that cover variations in the geometric, kinematic, and dynamic models of the character, the manipulated object, and obstacles in the scene."
            },
            "slug": "Synthesizing-animations-of-human-manipulation-tasks-Yamane-Kuffner",
            "title": {
                "fragments": [],
                "text": "Synthesizing animations of human manipulation tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper explores an approach for animating characters manipulating objects that combines the power of path planning with the domain knowledge inherent in data-driven, constraint-based inverse kinematics."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107881808"
                        ],
                        "name": "Stella X. Yu",
                        "slug": "Stella-X.-Yu",
                        "structuredName": {
                            "firstName": "Stella",
                            "lastName": "Yu",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stella X. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145140331"
                        ],
                        "name": "Hao Zhang",
                        "slug": "Hao-Zhang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 117
                            }
                        ],
                        "text": "To address these shortcomings, there has been a recent push towards more geometric approaches to image understanding [8, 11, 13, 16, 20, 22, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1187062,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "47075aa3dfde4ae9b0498375fb7c27cc3d785bd5",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Inferring the 3D spatial layout from a single 2D image is a fundamental visual task. We formulate it as a grouping problem where edges are grouped into lines, quadrilaterals, and finally depth-ordered planes. We demonstrate that the 3D structure of planar objects in indoor scenes can be fast and accurately inferred without any learning or indexing."
            },
            "slug": "Inferring-spatial-layout-from-a-single-image-via-Yu-Zhang",
            "title": {
                "fragments": [],
                "text": "Inferring spatial layout from a single image via depth-ordered grouping"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is demonstrated that the 3D structure of planar objects in indoor scenes can be fast and accurately inferred without any learning or indexing."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2684226"
                        ],
                        "name": "Aniruddha Kembhavi",
                        "slug": "Aniruddha-Kembhavi",
                        "structuredName": {
                            "firstName": "Aniruddha",
                            "lastName": "Kembhavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aniruddha Kembhavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 127
                            }
                        ],
                        "text": "1There have been a few recent papers which model the semantic relationships between humans and objects in 2D using appearances [9, 25]; however, our focus is on geometric and physical reasoning in 3D using form and structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5829319,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "3a8da6accff92f915c1b8ac26d8176308c425b61",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Interpretation of images and videos containing humans interacting with different objects is a daunting task. It involves understanding scene or event, analyzing human movements, recognizing manipulable objects, and observing the effect of the human movement on those objects. While each of these perceptual tasks can be conducted independently, recognition rate improves when interactions between them are considered. Motivated by psychological studies of human perception, we present a Bayesian approach which integrates various perceptual tasks involved in understanding human-object interactions. Previous approaches to object and action recognition rely on static shape or appearance feature matching and motion analysis, respectively. Our approach goes beyond these traditional approaches and applies spatial and functional constraints on each of the perceptual elements for coherent semantic interpretation. Such constraints allow us to recognize objects and actions when the appearances are not discriminative enough. We also demonstrate the use of such constraints in recognition of actions from static images without using any motion information."
            },
            "slug": "Observing-Human-Object-Interactions:-Using-Spatial-Gupta-Kembhavi",
            "title": {
                "fragments": [],
                "text": "Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a Bayesian approach which applies spatial and functional constraints on each of the perceptual elements for coherent semantic interpretation and demonstrates the use of such constraints in recognition of actions from static images without using any motion information."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747801"
                        ],
                        "name": "E. Rivlin",
                        "slug": "E.-Rivlin",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Rivlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779136"
                        ],
                        "name": "S. Dickinson",
                        "slug": "S.-Dickinson",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Dickinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dickinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 178
                            }
                        ],
                        "text": "In computer vision, over the last 30 years there have been regular attempts to use functional reasoning as a way to model objects by their \u201cpurpose\u201d rather than their appearance [4, 19, 21, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121993192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2bc67ba8025995068c9808be1d9aa50c14a420cb",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We present an approach to function-based object recognition that reasons about the functionality of an object's intuitive parts. We extend the popular \"recognition by parts\" shape recognition framework to support \"recognition by functional parts,\" by combining a set of functional primitives and their relations with a set of abstract volumetric shape primitives and their relations. Previous approaches have relied on more global object features, often ignoring the problem of object segmentation and thereby restricting themselves to range images of unoccluded scenes. We show how these shape primitives and relations can be easily recovered from superquadric ellipsoids which, in turn, can be recovered from either range or intensity images of occluded scenes, Furthermore, the proposed framework supports both unexpected (bottom-up) object recognition and expected (top-down) object recognition, We demonstrate the approach on a simple domain by recognizing a restricted class of hand-tools from 2-D images."
            },
            "slug": "Recognition-by-Functional-Parts-Rivlin-Dickinson",
            "title": {
                "fragments": [],
                "text": "Recognition by Functional Parts"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown how these shape primitives and relations can be easily recovered from superquadric ellipsoids which, in turn, can be recovered from either range or intensity images of occluded scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109230200"
                        ],
                        "name": "Huayan Wang",
                        "slug": "Huayan-Wang",
                        "structuredName": {
                            "firstName": "Huayan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huayan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 117
                            }
                        ],
                        "text": "To address these shortcomings, there has been a recent push towards more geometric approaches to image understanding [8, 11, 13, 16, 20, 22, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7189981,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1b3b880814d46b78a417db7b1150044453e1039",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of understanding an indoor scene from a single image in terms of recovering the room geometry (floor, ceiling, and walls) and furniture layout. A major challenge of this task arises from the fact that most indoor scenes are cluttered by furniture and decorations, whose appearances vary drastically across scenes, thus can hardly be modeled (or even hand-labeled) consistently. In this paper we tackle this problem by introducing latent variables to account for clutter, so that the observed image is jointly explained by the room and clutter layout. Model parameters are learned from a training set of images that are only labeled with the layout of the room geometry. Our approach enables taking into account and inferring indoor clutter without hand-labeling of the clutter in the training set, which is often inaccurate. Yet it outperforms the state-of-the-art method of Hedau et al. that requires clutter labels. As a latent variable based method, our approach has an interesting feature that latent variables are used in direct correspondence with a concrete visual concept (clutter in the room) and thus interpretable."
            },
            "slug": "Discriminative-learning-with-latent-variables-for-Wang-Gould",
            "title": {
                "fragments": [],
                "text": "Discriminative learning with latent variables for cluttered indoor scene understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This approach enables taking into account and inferring indoor clutter without hand-labeling of the clutter in the training set, which is often inaccurate, and outperforms the state-of-the-art method of Hedau et al. that requires clutter labels."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30457331"
                        ],
                        "name": "J. Gibson",
                        "slug": "J.-Gibson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Gibson",
                            "middleNames": [
                                "Jerome"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gibson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "Gibson [7] who proposed the notion of affordances."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33656271,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "4971bec3386a33fa6c3850abf3d358e7143dff8b",
            "isKey": false,
            "numCitedBy": 18753,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Contents: Preface. Introduction. Part I: The Environment To Be Perceived.The Animal And The Environment. Medium, Substances, Surfaces. The Meaningful Environment. Part II: The Information For Visual Perception.The Relationship Between Stimulation And Stimulus Information. The Ambient Optic Array. Events And The Information For Perceiving Events. The Optical Information For Self-Perception. The Theory Of Affordances. Part III: Visual Perception.Experimental Evidence For Direct Perception: Persisting Layout. Experiments On The Perception Of Motion In The World And Movement Of The Self. The Discovery Of The Occluding Edge And Its Implications For Perception. Looking With The Head And Eyes. Locomotion And Manipulation. The Theory Of Information Pickup And Its Consequences. Part IV: Depiction.Pictures And Visual Awareness. Motion Pictures And Visual Awareness. Conclusion. Appendixes: The Principal Terms Used in Ecological Optics. The Concept of Invariants in Ecological Optics."
            },
            "slug": "The-Ecological-Approach-to-Visual-Perception-Gibson",
            "title": {
                "fragments": [],
                "text": "The Ecological Approach to Visual Perception"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17173992"
                        ],
                        "name": "B. Wrobel",
                        "slug": "B.-Wrobel",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Wrobel",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wrobel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "Each voxel in 3D space is projected onto the image using the standard projective camera model, where camera calibration2 is performed using estimated vanishing points [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44793400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "339093c7ed71919ce59a7e78979a77abd25bad0c",
            "isKey": false,
            "numCitedBy": 16324,
            "numCiting": 222,
            "paperAbstract": {
                "fragments": [],
                "text": "Downloading the book in this website lists can give you more advantages. It will show you the best book collections and completed collections. So many books can be found in this website. So, this is not only this multiple view geometry in computer vision. However, this book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts. This is simple, read the soft file of the book and you get it."
            },
            "slug": "Multiple-View-Geometry-in-Computer-Vision-Wrobel",
            "title": {
                "fragments": [],
                "text": "Multiple View Geometry in Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This book is referred to read because it is an inspiring book to give you more chance to get experiences and also thoughts and it will show the best book collections and completed collections."
            },
            "venue": {
                "fragments": [],
                "text": "K\u00fcnstliche Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144258209"
                        ],
                        "name": "L. Stark",
                        "slug": "L.-Stark",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Stark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Stark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143759604"
                        ],
                        "name": "K. Bowyer",
                        "slug": "K.-Bowyer",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Bowyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Bowyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 178
                            }
                        ],
                        "text": "In computer vision, over the last 30 years there have been regular attempts to use functional reasoning as a way to model objects by their \u201cpurpose\u201d rather than their appearance [4, 19, 21, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] used manually-defined rules to reason about functional elements of 3D CAD objects (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206421973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f0d8a0097a095f863caeb344b6a7448b9b99129",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "An attempt is made to demonstrate the feasibility of defining an object category in terms of the functional properties shared by all objects in the category. This form of representation should allow much greater generality. A complete system has been implemented that takes the boundary surface description of a 3D object as its input and attempts to recognize whether the object belongs to the category 'chair' and, if so, into which subcategory if falls. This is, to the authors' knowledge, the first implemented system to explore the use of a purely function-based definition of an object category (that is, no explicit geometric or structural model) to recognize 3D objects. System competence has been evaluated on a database of over 100 objects, and the results largely agree with human interpretation of the objects. >"
            },
            "slug": "Achieving-Generalized-Object-Recognition-through-of-Stark-Bowyer",
            "title": {
                "fragments": [],
                "text": "Achieving Generalized Object Recognition through Reasoning about Association of Function to Structure"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This is, to the authors' knowledge, the first implemented system to explore the use of a purely function-based definition of an object category (that is, no explicit geometric or structural model) to recognize 3D objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "One popular answer is locating and naming the objects in the scene [6] (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060896"
                        ],
                        "name": "P. Winston",
                        "slug": "P.-Winston",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Winston",
                            "middleNames": [
                                "Henry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Winston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6104312"
                        ],
                        "name": "Boris Katz",
                        "slug": "Boris-Katz",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Katz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Katz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065580568"
                        ],
                        "name": "Michael R. Lowry",
                        "slug": "Michael-R.-Lowry",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lowry",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lowry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 178
                            }
                        ],
                        "text": "In computer vision, over the last 30 years there have been regular attempts to use functional reasoning as a way to model objects by their \u201cpurpose\u201d rather than their appearance [4, 19, 21, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7856739,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3945122239c960401555787a4128f54c127af97",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : It is too hard to tell vision systems what things look like. It is easier to talk about purpose and what things are for. Consequently, we want vision systems to use functional descriptions to identify things, when necessary, and we want them to learn physical descriptions for themselves, when possible. This paper describes a theory that explains how to make such systems work. The theory is a synthesis of two sets of ideas: ideas about learning from precedents and exercises developed at MIT and ideas about physical description developed at Stanford. The strength of the synthesis is illustrated by way of representative experiments. All of these experiments have been performed with an implemented system. (Author)"
            },
            "slug": "Learning-Physical-Descriptions-From-Functional-and-Winston-Katz",
            "title": {
                "fragments": [],
                "text": "Learning Physical Descriptions From Functional Definitions, Examples, and Precedents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The theory is a synthesis of two sets of ideas: ideas about learning from precedents and exercises developed at MIT and ideas about physical description developed at Stanford, and is illustrated by way of representative experiments."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114409274"
                        ],
                        "name": "K. Koffka",
                        "slug": "K.-Koffka",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Koffka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Koffka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "However, understanding on the level of bounding boxes (or image segments) is rather superficial \u2013 it tells us little about where the objects are located within the 3D scene and how one can interact with them."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1775179,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c6688c195b3f30267f4a832605e4d8904de9bd64",
            "isKey": false,
            "numCitedBy": 3012,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Routledge is now re-issuing this prestigious series of 204 volumes originally published between 1910 and 1965. The titles include works by key figures such asC.G. Jung, Sigmund Freud, Jean Piaget, Otto Rank, James Hillman, Erich Fromm, Karen Horney and Susan Isaacs. Each volume is available on its own, as part of a themed mini-set, or as part of a specially-priced 204-volume set. A brochure listing each title in the \"International Library of Psychology\" series is available upon request."
            },
            "slug": "Principles-Of-Gestalt-Psychology-Koffka",
            "title": {
                "fragments": [],
                "text": "Principles Of Gestalt Psychology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1935
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097800"
                        ],
                        "name": "S. Baum",
                        "slug": "S.-Baum",
                        "structuredName": {
                            "firstName": "Seth",
                            "lastName": "Baum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32258107"
                        ],
                        "name": "B. Tonn",
                        "slug": "B.-Tonn",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Tonn",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Tonn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "By analogy to the workspace of a robot, defined as the set of reachable poses given the geometry of a robot\u2019s mechanism [3], the idea is to represent a scene as a human workspace \u2013 that is, a set of reachable pose states for a typical human."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 220103459,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "bd6e918ddf6e441a2db8a6cfd1563a1218d2c32c",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The purpose of this text is to begin the process of developing a working familiarity with some of these key mathematical concepts. As your studies in the life sciences become more specialized you will naturally find that certain mathematical fields receive more emphasis than do others. We hope that we will have laid a foundation that will allow you to deepen your understanding as the need to do so arises."
            },
            "slug": "Intro-Baum-Tonn",
            "title": {
                "fragments": [],
                "text": "Intro"
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "By analogy to the workspace of a robot, defined as the set of reachable poses given the geometry of a robot\u2019s mechanism [5], the idea is to represent a scene as a human workspace \u2013 that is, a set of reachable pose states for a typical human within the scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Intro. to Robotics: Mech. & Control"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "Researchers in computer graphics have looked into generating sets of constraints on human motions when interacting with objects in an environment [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Synthesizing animations of human manipulation"
            },
            "venue": {
                "fragments": [],
                "text": "tasks. ACM. Trans. on Graphics,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 117
                            }
                        ],
                        "text": "To address these shortcomings, there has been a recent push towards more geometric approaches to image understanding [8, 11, 13, 16, 20, 22, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Make3D: Learning 3D scene structure from a single still image"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, we believe that now is the time to start designing ways to represent space and actions together, as it will guide further research in both geometry estimation as well as action recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The two beds in the image are represented by the set of occupied voxels in the 3D scene."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In a way, this work revisits the principle of Gibsonian affordances, reinterpreting it for the modern, data-driven era."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cmu motion capture database"
            },
            "venue": {
                "fragments": [],
                "text": "Cmu motion capture database"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In a way, this work revisits the principle of Gibsonian affordances, reinterpreting it for the modern, data-driven era."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Make3d: Learning 3d scene structure from a single still image. PAMI"
            },
            "venue": {
                "fragments": [],
                "text": "Make3d: Learning 3d scene structure from a single still image. PAMI"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 178
                            }
                        ],
                        "text": "In computer vision, over the last 30 years there have been regular attempts to use functional reasoning as a way to model objects by their \u201cpurpose\u201d rather than their appearance [4, 19, 21, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The mechanics mate"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in AI,"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In a way, this work revisits the principle of Gibsonian affordances, reinterpreting it for the modern, data-driven era."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Craig. Intro. to Robotics: Mech. & Control"
            },
            "venue": {
                "fragments": [],
                "text": "J. Craig. Intro. to Robotics: Mech. & Control"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "To address these shortcomings, Neisser [17] narrowed the concept and proposed physical affordances where only the physical interactions could be perceived from the physical structure of the objects."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Direct recognition and perception as distinct perceptual systems"
            },
            "venue": {
                "fragments": [],
                "text": "Ann. Meet. of Cognitive Sci. Society,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, we believe that now is the time to start designing ways to represent space and actions together, as it will guide further research in both geometry estimation as well as action recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In a way, this work revisits the principle of Gibsonian affordances, reinterpreting it for the modern, data-driven era."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Character motion systems"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH-Course 9"
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Although 3D model-based vision (fitting blocks and cylinders to images [17]) gained popularity, the efforts to create general-purpose recognition systems failed, due to the semantic gap between geometric structures and categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine perception of 3d solids"
            },
            "venue": {
                "fragments": [],
                "text": "PhD,"
            },
            "year": 1965
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 6,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 29,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/From-3D-scene-geometry-to-human-workspace-Gupta-Satkin/0e700356dae7a0a54c91567801c8c5f09bdd8c05?sort=total-citations"
}