{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069634816"
                        ],
                        "name": "J. Kumar",
                        "slug": "J.-Kumar",
                        "structuredName": {
                            "firstName": "Jayant",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36073757"
                        ],
                        "name": "R. Prasad",
                        "slug": "R.-Prasad",
                        "structuredName": {
                            "firstName": "Rohit",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39784761"
                        ],
                        "name": "Huaigu Cao",
                        "slug": "Huaigu-Cao",
                        "structuredName": {
                            "firstName": "Huaigu",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaigu Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404588675"
                        ],
                        "name": "W. Abd-Almageed",
                        "slug": "W.-Abd-Almageed",
                        "structuredName": {
                            "firstName": "Wael",
                            "lastName": "Abd-Almageed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Abd-Almageed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145603129"
                        ],
                        "name": "P. Natarajan",
                        "slug": "P.-Natarajan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Natarajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Natarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6294186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4fb819a736b808b76c2cbcd94f714792dbd3f01d",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel method for extracting handwritten and printed text zones from noisy document images with mixed content. We use Triple-Adjacent-Segment (TAS) based features which encode local shape characteristics of text in a consistent manner. We first construct two codebooks of the shape features extracted from a set of handwritten and printed text documents respectively. We then compute the normalized histogram of codewords for each segmented zone and use it to train a Support Vector Machine (SVM) classifier. The codebook based approach is robust to the background noise present in the image and TAS features are invariant to translation, scale and rotation of text. In experiments, we show that a pixel-weighted zone classification accuracy of 98% can be achieved for noisy Arabic documents. Further, we demonstrate the effectiveness of our method for document page classification and show that a high precision can be achieved for the detection of machine printed documents. The proposed method is robust to the size of zones, which may contain text content at line or paragraph level."
            },
            "slug": "Shape-codebook-based-handwritten-and-machine-text-Kumar-Prasad",
            "title": {
                "fragments": [],
                "text": "Shape codebook based handwritten and machine printed text zone extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel method for extracting handwritten and printed text zones from noisy document images with mixed content using Triple-Adjacent-Segment (TAS) based features which encode local shape characteristics of text in a consistent manner is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114036784"
                        ],
                        "name": "Guangyu Zhu",
                        "slug": "Guangyu-Zhu",
                        "structuredName": {
                            "firstName": "Guangyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangyu Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110381386"
                        ],
                        "name": "Yefeng Zheng",
                        "slug": "Yefeng-Zheng",
                        "structuredName": {
                            "firstName": "Yefeng",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yefeng Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144230620"
                        ],
                        "name": "Stefan Jaeger",
                        "slug": "Stefan-Jaeger",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Jaeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan Jaeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 169
                            }
                        ],
                        "text": "The problem of retrieving structurally similar document images from a large heterogenous collection given a few relevant images, has been of interest for many years [6, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5288845,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d9fcf95d13b19a19227e845d92faa072f62ea15",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "As one of the most pervasive methods of individual identification and document authentication, signatures present convincing evidence and provide an important form of indexing for effective document image processing and retrieval in a broad range of applications. However, detection and segmentation of free-form objects such as signatures from clustered background is currently an open document analysis problem. In this paper, we focus on two fundamental problems in signature-based document image retrieval. First, we propose a novel multiscale approach to jointly detecting and segmenting signatures from document images. Rather than focusing on local features that typically have large variations, our approach captures the structural saliency using a signature production model and computes the dynamic curvature of 2D contour fragments over multiple scales. This detection framework is general and computationally tractable. Second, we treat the problem of signature retrieval in the unconstrained setting of translation, scale, and rotation invariant nonrigid shape matching. We propose two novel measures of shape dissimilarity based on anisotropic scaling and registration residual error and present a supervised learning framework for combining complementary shape information from different dissimilarity metrics using LDA. We quantitatively study state-of-the-art shape representations, shape matching algorithms, measures of dissimilarity, and the use of multiple instances as query in document image retrieval. We further demonstrate our matching techniques in offline signature verification. Extensive experiments using large real-world collections of English and Arabic machine-printed and handwritten documents demonstrate the excellent performance of our approaches."
            },
            "slug": "Signature-Detection-and-Matching-for-Document-Image-Zhu-Zheng",
            "title": {
                "fragments": [],
                "text": "Signature Detection and Matching for Document Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a novel multiscale approach to jointly detecting and segmenting signatures from document images, and quantitatively studies state-of-the-art shape representations, shape matching algorithms, measures of dissimilarity, and the use of multiple instances as query in document image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941286"
                        ],
                        "name": "Christian K. Shin",
                        "slug": "Christian-K.-Shin",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Shin",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian K. Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48471936"
                        ],
                        "name": "D. Doermann",
                        "slug": "D.-Doermann",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doermann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doermann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 165
                            }
                        ],
                        "text": "The problem of retrieving structurally similar document images from a large heterogenous collection given a few relevant images, has been of interest for many years [6, 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8015543,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d67d64b16537107ccb81af1915b7b0b40b147300",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe issues related to the measurement of structural similarity between document images. We define structural similarity, and discuss the benefits of using it as a complement to content similarity for querying document image databases. We present an approach to computing a geometrically invariant structural similarity, and use this measure to search document image databases. Our approach supports both full image matching using query by example (QBE) and sub-image matching using query by sketch (QBS). The similarity measure considers spatial and layout structure, and is computed by aggregating content area overlap measures with respect to their underlying column structures. These techniques are tested within the Intelligent Document Image Retrieval (IDIR) System, and results demonstrating effectiveness and efficiency of structure queries with respect to human relevance judgments are presented."
            },
            "slug": "Document-Image-Retrieval-Based-on-Layout-Structural-Shin-Doermann",
            "title": {
                "fragments": [],
                "text": "Document Image Retrieval Based on Layout Structural Similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An approach to computing a geometrically invariant structural similarity, and use this measure to search document image databases, and results demonstrating effectiveness and efficiency of structure queries with respect to human relevance judgments are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IPCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": false,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706007"
                        ],
                        "name": "Jianchao Yang",
                        "slug": "Jianchao-Yang",
                        "structuredName": {
                            "firstName": "Jianchao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianchao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108863279"
                        ],
                        "name": "Thomas Huang",
                        "slug": "Thomas-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 440212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c9633aedafe4ee8cf238fa06c40b84f47e17362",
            "isKey": false,
            "numCitedBy": 1469,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently SVMs using spatial pyramid matching (SPM) kernel have been highly successful in image classification. Despite its popularity, these nonlinear SVMs have a complexity O(n2 ~ n3) in training and O(n) in testing, where n is the training size, implying that it is nontrivial to scaleup the algorithms to handle more than thousands of training images. In this paper we develop an extension of the SPM method, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and propose a linear SPM kernel based on SIFT sparse codes. This new approach remarkably reduces the complexity of SVMs to O(n) in training and a constant in testing. In a number of image categorization experiments, we find that, in terms of classification accuracy, the suggested linear SPM based on sparse coding of SIFT descriptors always significantly outperforms the linear SPM kernel on histograms, and is even better than the nonlinear SPM kernels, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors."
            },
            "slug": "Linear-spatial-pyramid-matching-using-sparse-coding-Yang-Yu",
            "title": {
                "fragments": [],
                "text": "Linear spatial pyramid matching using sparse coding for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An extension of the SPM method is developed, by generalizing vector quantization to sparse coding followed by multi-scale spatial max pooling, and a linear SPM kernel based on SIFT sparse codes is proposed, leading to state-of-the-art performance on several benchmarks by using a single type of descriptors."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143685864"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145211099"
                        ],
                        "name": "S. Newsam",
                        "slug": "S.-Newsam",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Newsam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Newsam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 231648,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "93deda60276a7e5b378c41013af6604b45351588",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image. Specifically, the co-occurrences of visual words are computed with respect to spatial predicates over a hierarchical spatial partitioning of an image. The representation captures both the absolute and relative spatial arrangement of the words and, through the choice and combination of the predicates, can characterize a variety of spatial relationships. Our representation is motivated by the analysis of overhead imagery such as from satellites or aircraft. This imagery generally does not have an absolute reference frame and thus the relative spatial arrangement of the image elements often becomes the key discriminating feature. We validate this hypothesis using a challenging ground truth image dataset of 21 land-use classes manually extracted from high-resolution aerial imagery. Our approach is shown to result in higher classification rates than a non-spatial bagof- visual-words approach as well as a popular approach for characterizing the absolute spatial arrangement of visual words, the spatial pyramid representation of Lazebnik et al. [7]. While our primary objective is analyzing overhead imagery, we demonstrate that our approach achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset."
            },
            "slug": "Spatial-pyramid-co-occurrence-for-image-Yang-Newsam",
            "title": {
                "fragments": [],
                "text": "Spatial pyramid co-occurrence for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A novel image representation termed spatial pyramid co-occurrence which characterizes both the photometric and geometric aspects of an image which achieves state-of-the-art performance on the Graz-01 object class dataset and performs competitively on the 15 Scene dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65207,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749245"
                        ],
                        "name": "Zhaohui Zheng",
                        "slug": "Zhaohui-Zheng",
                        "structuredName": {
                            "firstName": "Zhaohui",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaohui Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143690397"
                        ],
                        "name": "Xiaoyun Wu",
                        "slug": "Xiaoyun-Wu",
                        "structuredName": {
                            "firstName": "Xiaoyun",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoyun Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748081"
                        ],
                        "name": "R. Srihari",
                        "slug": "R.-Srihari",
                        "structuredName": {
                            "firstName": "Rohini",
                            "lastName": "Srihari",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "One of the popular methods proposes the creation of spatial-pyramid features by partitioning the image into increasingly finer grids and computing the weighted histogram of features in each region for scene classification [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7956405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebe5b9a24275793de12cb367802db19690751f41",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of feature selection metrics have been explored in text categorization, among which information gain (IG), chi-square (CHI), correlation coefficient (CC) and odds ratios (OR) are considered most effective. CC and OR are one-sided metrics while IG and CHI are two-sided. Feature selection using one-sided metrics selects the features most indicative of membership only, while feature selection using two-sided metrics implicitly combines the features most indicative of membership (e.g. positive features) and non-membership (e.g. negative features) by ignoring the signs of features. The former never consider the negative features, which are quite valuable, while the latter cannot ensure the optimal combination of the two kinds of features especially on imbalanced data. In this work, we investigate the usefulness of explicit control of that combination within a proposed feature selection framework. Using multinomial na\u00efve Bayes and regularized logistic regression as classifiers, our experiments show both great potential and actual merits of explicitly combining positive and negative features in a nearly optimal fashion according to the imbalanced data."
            },
            "slug": "Feature-selection-for-text-categorization-on-data-Zheng-Wu",
            "title": {
                "fragments": [],
                "text": "Feature selection for text categorization on imbalanced data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work investigates the usefulness of explicit control of that combination within a proposed feature selection framework and shows both great potential and actual merits of explicitly combining positive and negative features in a nearly optimal fashion according to the imbalanced data."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587444"
                        ],
                        "name": "Andy Liaw",
                        "slug": "Andy-Liaw",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Liaw",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andy Liaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39707890"
                        ],
                        "name": "M. Wiener",
                        "slug": "M.-Wiener",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Wiener",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wiener"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We used the standard values of b 2 \u221a Nc, where N is the number of features for mTry and nTree = 1000, suggested in previous work [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3093707,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e633b41d93051375ef9135102d54fa097dc8cf8",
            "isKey": false,
            "numCitedBy": 13682,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been a lot of interest in \u201censemble learning\u201d \u2014 methods that generate many classifiers and aggregate their results. Two well-known methods are boosting (see, e.g., Shapire et al., 1998) and bagging Breiman (1996) of classification trees. In boosting, successive trees give extra weight to points incorrectly predicted by earlier predictors. In the end, a weighted vote is taken for prediction. In bagging, successive trees do not depend on earlier trees \u2014 each is independently constructed using a bootstrap sample of the data set. In the end, a simple majority vote is taken for prediction. Breiman (2001) proposed random forests, which add an additional layer of randomness to bagging. In addition to constructing each tree using a different bootstrap sample of the data, random forests change how the classification or regression trees are constructed. In standard trees, each node is split using the best split among all variables. In a random forest, each node is split using the best among a subset of predictors randomly chosen at that node. This somewhat counterintuitive strategy turns out to perform very well compared to many other classifiers, including discriminant analysis, support vector machines and neural networks, and is robust against overfitting (Breiman, 2001). In addition, it is very user-friendly in the sense that it has only two parameters (the number of variables in the random subset at each node and the number of trees in the forest), and is usually not very sensitive to their values. The randomForest package provides an R interface to the Fortran programs by Breiman and Cutler (available at http://www.stat.berkeley.edu/ users/breiman/). This article provides a brief introduction to the usage and features of the R functions."
            },
            "slug": "Classification-and-Regression-by-randomForest-Liaw-Wiener",
            "title": {
                "fragments": [],
                "text": "Classification and Regression by randomForest"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "random forests are proposed, which add an additional layer of randomness to bagging and are robust against overfitting, and the randomForest package provides an R interface to the Fortran programs by Breiman and Cutler."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472298"
                        ],
                        "name": "Chih-Chung Chang",
                        "slug": "Chih-Chung-Chang",
                        "structuredName": {
                            "firstName": "Chih-Chung",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Chung Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 961425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "273dfbcb68080251f5e9ff38b4413d7bd84b10a1",
            "isKey": false,
            "numCitedBy": 40077,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail."
            },
            "slug": "LIBSVM:-A-library-for-support-vector-machines-Chang-Lin",
            "title": {
                "fragments": [],
                "text": "LIBSVM: A library for support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail."
            },
            "venue": {
                "fragments": [],
                "text": "TIST"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification and regression by randomforest. R News"
            },
            "venue": {
                "fragments": [],
                "text": "Classification and regression by randomforest. R News"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-document-structure-for-retrieval-and-Kumar-Ye/31da8cace27a08e6339145f95f190a77197f01b2?sort=total-citations"
}