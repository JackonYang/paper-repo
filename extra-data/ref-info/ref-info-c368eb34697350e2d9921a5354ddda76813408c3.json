{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 158
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in [38, 37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 78
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle ltering tracking framework [37, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 182
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only briefly describes the Bayesian tracking framework; details of the approach can be found in Sidenbladh and Black (2001) and Sidenbladh et al. (2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 79
                            }
                        ],
                        "text": "N , are maintained, and are propagated in time with a linear motion model (see Sidenbladh and Black (2001) for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "Here N = 5000 hypotheses (samples, or particles), t , s = 1 : : : N , are maintained, and are propagated in time with a linear motion model (see [37] for details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 188
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in Sidenbladh et al. (2000a) and Sidenbladh and Black (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 170
                            }
                        ],
                        "text": "This suggests that a tracking scheme that models the whole distribution, such as particle filtering (e.g., CONDENSATION (Isard and Blake, 1998; Sidenbladh et al., 2000a; Sidenbladh and Black, 2001)) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 81
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle filtering tracking framework (Sidenbladh and Black, 2001; Sidenbladh et al., 2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only brie y describes the Bayesian tracking framework; details of the approach can be found in [37, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "To overcome this problem, a re-sampling approach is used [37] that essentially smoothes the likelihood and damps the highest peaks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 13
                            }
                        ],
                        "text": "Condensation [17, 38, 37]) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 58
                            }
                        ],
                        "text": "To overcome this problem, a re-sampling approach is used (Sidenbladh and Black, 2001) that essentially smoothes the likelihood and damps the highest peaks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6557014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c0c1b02f23a44859caa06fc26ff9cdf03c4b232",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a framework for learning probabilistic models of objects and scenes and for exploiting these models for tracking complex, deformable, or articulated objects in image sequences. We focus on the probabilistic tracking of people and learn models of how they appear and move in images. In particular we learn the likelihood of observing various spatial and temporal filter responses corresponding to edges, ridges, and motion differences given a model of the person. Similarly, we learn probability distributions over filter responses for general scenes that define a likelihood of observing the filter responses for arbitrary backgrounds. We then derive a probabilistic model for tracking that exploits the ratio between the likelihood that image pixels corresponding to the foreground (person) were generated by an actual person or by some unknown background. The paper extends previous work on learning image statistics and combines it with Bayesian tracking using particle filtering. By combining multiple image cues, and by using learned likelihood models, we demonstrate improved robustness and accuracy when tracking complex objects such as people in monocular image sequences with cluttered scene and a moving camera."
            },
            "slug": "Learning-image-statistics-for-Bayesian-tracking-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Learning image statistics for Bayesian tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Improved robustness and accuracy is demonstrated when tracking complex objects such as people in monocular image sequences with cluttered scene and a moving camera by combining multiple image cues and using learned likelihood models."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 100
                            }
                        ],
                        "text": "the prior distribution; for examples of generic and event-speci c priors, the reader is referred to [28, 39, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 151
                            }
                        ],
                        "text": "Here we do not address the prior distribution; for examples of generic and event-specific priors, the reader is referred to Ormoneit et al. (2001) and Sidenbladh et al. (2000a, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6017383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7776d0a6bf3cdf9b3cd18b13d32c6babed84614b",
            "isKey": false,
            "numCitedBy": 376,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of probabilistically modeling 3D human motion for synthesis and tracking. Given the high dimensional nature of human motion, learning an explicit probabilistic model from available training data is currently impractical. Instead we exploit methods from texture synthesis that treat images as representing an implicit empirical distribution. These methods replace the problem of representing the probability of a texture pattern with that of searching the training data for similar instances of that pattern. We extend this idea to temporal data representing 3D human motion with a large database of example motions. To make the method useful in practice, we must address the problem of efficient search in a large training set; efficiency is particularly important for tracking. Towards that end, we learn a low dimensional linear model of human motion that is used to structure the example motion database into a binary tree. An approximate probabilistic tree search method exploits the coefficients of this low-dimensional representation and runs in sub-linear time. This probabilistic tree search returns a particular sample human motion with probability approximating the true distribution of human motions in the database. This sampling method is suitable for use with particle filtering techniques and is applied to articulated 3D tracking of humans within a Bayesian framework. Successful tracking results are presented, along with examples of synthesizing human motion using the model."
            },
            "slug": "Implicit-Probabilistic-Models-of-Human-Motion-for-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Implicit Probabilistic Models of Human Motion for Synthesis and Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A low dimensional linear model of human motion is learned that is used to structure the example motion database into a binary tree and an approximate probabilistic tree search method exploits the coefficients of this low-dimensional representation and runs in sub-linear time."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2798041"
                        ],
                        "name": "I. Haritaoglu",
                        "slug": "I.-Haritaoglu",
                        "structuredName": {
                            "firstName": "Ismail",
                            "lastName": "Haritaoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Haritaoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145298122"
                        ],
                        "name": "D. Harwood",
                        "slug": "D.-Harwood",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harwood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harwood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 180
                            }
                        ],
                        "text": "In many cases, these cues are sequence-specific and capture local color distributions (Wren et al., 1997) or segment the person from the background using a known background model (Haritaoglu and Davis, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 48
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "In many cases, these cues are sequence-speci c and capture local color distributions [47] or segment the person from the background using a known background model [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Background subtraction [8, 16, 32, 33, 47] gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6837802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "518597d91ed49c28f5cf3f0a0b05609568b7e084",
            "isKey": true,
            "numCitedBy": 2784,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "W/sup 4/ is a real time visual surveillance system for detecting and tracking multiple people and monitoring their activities in an outdoor environment. It operates on monocular gray-scale video imagery, or on video imagery from an infrared camera. W/sup 4/ employs a combination of shape analysis and tracking to locate people and their parts (head, hands, feet, torso) and to create models of people's appearance so that they can be tracked through interactions such as occlusions. It can determine whether a foreground region contains multiple people and can segment the region into its constituent people and track them. W/sup 4/ can also determine whether people are carrying objects, and can segment objects from their silhouettes, and construct appearance models for them so they can be identified in subsequent frames. W/sup 4/ can recognize events between people and objects, such as depositing an object, exchanging bags, or removing an object. It runs at 25 Hz for 320/spl times/240 resolution images on a 400 MHz dual-Pentium II PC."
            },
            "slug": "W4:-Real-Time-Surveillance-of-People-and-Their-Haritaoglu-Harwood",
            "title": {
                "fragments": [],
                "text": "W4: Real-Time Surveillance of People and Their Activities"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "W/sup 4/ employs a combination of shape analysis and tracking to locate people and their parts and to create models of people's appearance so that they can be tracked through interactions such as occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 193
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Background subtraction [8, 16, 32, 33, 47] gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 204851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43140645e6eeb1d71d86b0c1a44bc687476de665",
            "isKey": true,
            "numCitedBy": 90,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "Within the field of computer vision the automatic interpretation of human movements is one of the most challenging tasks. A central problem in analyzing such movements is due to the fact that the human body consists of body parts linked to each other at joints which allows different movements of the parts. Therefore, the human body generally has to be treated as a nonrigid or more precisely as an articulated body. In addition, for general camera positions always some of the body parts are occluded. Although occlusions can provide important cues in a recognition task, the automatic interpretation is more difficult. Another problem that has to be dealt with is the clothing which can have a large influence on the appearence of a person (wide or tight trousers, different jackets, etc.). Clothing can also cause complex illumination phenomena that, in addition, change during movement (compare with efforts in the field of computer graphics to simulate cloth objects, e.g., [83])."
            },
            "slug": "Human-Movement-Analysis-Based-on-Explicit-Motion-Rohr",
            "title": {
                "fragments": [],
                "text": "Human Movement Analysis Based on Explicit Motion Models"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "Within the field of computer vision the automatic interpretation of human movements is one of the most challenging tasks due to the fact that the human body consists of body parts linked to each other at joints which allows different movements of the parts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 179
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 214
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only briefly describes the Bayesian tracking framework; details of the approach can be found in Sidenbladh and Black (2001) and Sidenbladh et al. (2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 25
                            }
                        ],
                        "text": "This idea is extended in Sidenbladh et al. (2000b) for learning low-dimensional linear models of the appearance of cylindrical limb surfaces using principal component analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 211
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in Sidenbladh et al. (2000a) and Sidenbladh and Black (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 151
                            }
                        ],
                        "text": "Here we do not address the prior distribution; for examples of generic and event-specific priors, the reader is referred to Ormoneit et al. (2001) and Sidenbladh et al. (2000a, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 82
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "This suggests that a tracking scheme that models the whole distribution, such as particle filtering (e.g., CONDENSATION (Isard and Blake, 1998; Sidenbladh et al., 2000a; Sidenbladh and Black, 2001)) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Both of these areas have attracted a considerable amount of interest in the recent years and are reviewed briefly here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The sub-sections below provide details of the statistical models for the various cues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 109
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle filtering tracking framework (Sidenbladh and Black, 2001; Sidenbladh et al., 2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 72
                            }
                        ],
                        "text": "Using a particle filtering method (Gordon, 1993; Isard and Blake, 1998; Sidenbladh et al., 2000a), the posterior probability distribution over poses of the body model is represented using a discrete set of samples (where each sample corresponds to some pose of\nthe body)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46737148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a39ac21415d028402c9e83443188b613a16961d",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic method for tracking 3D articulated human figures in monocular image sequences is presented. Within a Bayesian framework, we define a generative model of image appearance, a robust likelihood function based on image graylevel differences, and a prior probability distribution over pose and joint angles that models how humans move. The posterior probability distribution over model parameters is represented using a discrete set of samples and is propagated over time using particle filtering. The approach extends previous work on parameterized optical flow estimation to exploit a complex 3D articulated motion model. It also extends previous work on human motion tracking by including a perspective camera model, by modeling limb self occlusion, and by recovering 3D motion from a monocular sequence. The explicit posterior probability distribution represents ambiguities due to image matching, model singularities, and perspective projection. The method relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds."
            },
            "slug": "Stochastic-Tracking-of-3D-Human-Figures-Using-2D-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Stochastic Tracking of 3D Human Figures Using 2D Image Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A probabilistic method for tracking 3D articulated human figures in monocular image sequences that relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144196926"
                        ],
                        "name": "S. Wachter",
                        "slug": "S.-Wachter",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Wachter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans [7, 38, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 149
                            }
                        ],
                        "text": "While many systems combine cues such as motion, color, or stereo for person detection and tracking (Darrell et al., 2000; Rasmussen and Hager, 2001; Wachter and Nagel, 1999), the formulation and combination of these cues is often ad hoc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 153
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance (Gavrila, 1996), or by enforcing a maximum distance between limb boundaries and image edges (Hogg, 1983; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 268
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 271
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "To avoid this drift, brightness constancy is therefore often used in combination with edges [7, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 108
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 120
                            }
                        ],
                        "text": "To avoid this drift, brightness constancy is therefore often used in combination with edges (DeCarlo and Metaxas, 1996; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance [11], or by enforcing a maximum distance between limb boundaries and image edges [15, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 99
                            }
                        ],
                        "text": "While many systems combine cues such as motion, color, or stereo for person detection and tracking [6, 29, 46], the formulation and combination of these cues is often ad hoc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5916504,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a6fad775a27cc172479fdb6f291e361b35fd2f1e",
            "isKey": true,
            "numCitedBy": 277,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantitative geometric descriptions of the movements of persons are obtained by fitting the projection of a three-dimensional person model to consecutive frames of an image sequence. The kinematic of the person model is given by a homogeneous transformation tree and its body parts are modeled by right-elliptical cones. The values of a varying number of degrees of freedom (DOFs; body joints, position, and orientation of the person relative to the camera) can be determined according to the application and the kind of image sequence. The determination of the DOFs is understood as an estimation problem which is solved by an iterated extended Kalman filter (IEKF). For this purpose, the person model is augmented by a simple motion model of constant velocity for all DOFs which is used in the prediction step of the IEKF. In the update step, both region and edge information are used. Various experiments demonstrate the efficiency of our approach."
            },
            "slug": "Tracking-Persons-in-Monocular-Image-Sequences-Wachter-Nagel",
            "title": {
                "fragments": [],
                "text": "Tracking Persons in Monocular Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The person model is augmented by a simple motion model of constant velocity for all DOFs which is used in the prediction step of the IEKF and in the update step, both region and edge information are used."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40302807"
                        ],
                        "name": "G. Gordon",
                        "slug": "G.-Gordon",
                        "structuredName": {
                            "firstName": "Gaile",
                            "lastName": "Gordon",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143833523"
                        ],
                        "name": "M. Harville",
                        "slug": "M.-Harville",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Harville",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Harville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803592"
                        ],
                        "name": "J. Woodfill",
                        "slug": "J.-Woodfill",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Woodfill",
                            "middleNames": [
                                "Iselin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Woodfill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 100
                            }
                        ],
                        "text": "While many systems combine cues such as motion, color, or stereo for person detection and tracking (Darrell et al., 2000; Rasmussen and Hager, 2001; Wachter and Nagel, 1999), the formulation and combination of these cues is often ad hoc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "\u2026specifically, the image response for an edge of orientation \u03b8 at pyramid level \u03c3 is formulated as the image gradient perpendicular to the edge orientation:\nfe(x, \u03b8, \u03c3 ) = sin \u03b8 fx (x, \u03c3 ) \u2212 cos \u03b8 fy(x, \u03c3 ) (2)\nwhere fx (x, \u03c3 ) and fy(x, \u03c3 ) are the image derivatives in the x and y image\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10236323,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43000bd6b1cc93c47fb6860cab71fe0dfafd73ad",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to real-time person tracking in crowded and/or unknown environments using integration of multiple visual modalities. We combine stereo, color, and face detection modules into a single robust system, and show an initial application in an interactive, face-responsive display. Dense, real-time stereo processing is used to isolate users from other objects and people in the background. Skin-hue classification identifies and tracks likely body parts within the silhouette of a user. Face pattern detection discriminates and localizes the face within the identified body parts. Faces and bodies of users are tracked over several temporal scales: short-term (user stays within the field of view), medium-term (user exits/reenters within minutes), and long term (user returns after hours or days). Short-term tracking is performed using simple region position and size correspondences, while medium and long-term tracking are based on statistics of user appearance. We discuss the failure modes of each individual module, describe our integration method, and report results with the complete system in trials with thousands of users."
            },
            "slug": "Integrated-Person-Tracking-Using-Stereo,-Color,-and-Darrell-Gordon",
            "title": {
                "fragments": [],
                "text": "Integrated Person Tracking Using Stereo, Color, and Pattern Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work combines stereo, color, and face detection modules into a single robust system, shows an initial application in an interactive, face-responsive display, and discusses the failure modes of each individual module."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 163
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames (Bregler and Malik, 1998;  Ju et al., 1996 ) or between an initial template and the current frame (Cham and Rehg, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "\u2026or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998;  Ju et al., 1996;  Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames (Bregler and Malik, 1998; Ju et al., 1996) or between an initial template and the current frame (Cham and Rehg, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These models vary in complexity from assemblies of 2D color blobs (Wren et al., 1997) or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999;  Ju et al., 1996 ), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5170789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e3b20fb94803d71910043059f402554aa5137b2",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the work of Black and Yacoob (1995) on the tracking and recognition of human facial expressions using parametrized models of optical flow to deal with the articulated motion of human limbs. We define a \"card-board person model\" in which a person's limbs are represented by a set of connected planar patches. The parametrized image motion of these patches in constrained to enforce articulated motion and is solved for directly using a robust estimation technique. The recovered motion parameters provide a rich and concise description of the activity that can be used for recognition. We propose a method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion. We illustrate the method with examples of tracking human legs of long image sequences."
            },
            "slug": "Cardboard-people:-a-parameterized-model-of-image-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: a parameterized model of articulated image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 203
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter (Deutscher et al., 2000; Gavrila, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 49
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance (Gavrila, 1996), or by enforcing a maximum distance between limb boundaries and image edges (Hogg, 1983; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 143
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 178
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter [8, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance [11], or by enforcing a maximum distance between limb boundaries and image edges [15, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 111
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11295711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99b22537b071aa3c46367aed0952d97c67955833",
            "isKey": true,
            "numCitedBy": 21,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to recognize humans and their activities by vision is essential for future machines to interact intelligently and effortlessly with a human-inhabited environment. Some of the more promising applications are discussed. \nA prototype vision system is presented for the tracking of whole-body movement using multiple cameras. 3-D body pose is recovered at each time instant based on occluding contours. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. Hermite deformable contours are proposed as a tool for the 2-D contour tracking problem. \nThe main contribution of this dissertation is that it demonstrates for the first time a set of techniques that allow accurate vision-based 3-D tracking of arbitrary whole-body movement without the use of markers."
            },
            "slug": "Vision-based-3-D-tracking-of-humans-in-action-Gavrila",
            "title": {
                "fragments": [],
                "text": "Vision-based 3-D tracking of humans in action"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This dissertation demonstrates for the first time a set of techniques that allow accurate vision-based 3-D tracking of arbitrary whole-body movement without the use of markers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867160"
                        ],
                        "name": "F. D. L. Torre",
                        "slug": "F.-D.-L.-Torre",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Torre",
                            "middleNames": [
                                "De",
                                "la"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. L. Torre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 179
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 214
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only briefly describes the Bayesian tracking framework; details of the approach can be found in Sidenbladh and Black (2001) and Sidenbladh et al. (2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 25
                            }
                        ],
                        "text": "This idea is extended in Sidenbladh et al. (2000b) for learning low-dimensional linear models of the appearance of cylindrical limb surfaces using principal component analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 211
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in Sidenbladh et al. (2000a) and Sidenbladh and Black (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 151
                            }
                        ],
                        "text": "Here we do not address the prior distribution; for examples of generic and event-specific priors, the reader is referred to Ormoneit et al. (2001) and Sidenbladh et al. (2000a, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 82
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "This suggests that a tracking scheme that models the whole distribution, such as particle filtering (e.g., CONDENSATION (Isard and Blake, 1998; Sidenbladh et al., 2000a; Sidenbladh and Black, 2001)) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The sub-sections below provide details of the statistical models for the various cues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 109
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle filtering tracking framework (Sidenbladh and Black, 2001; Sidenbladh et al., 2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 72
                            }
                        ],
                        "text": "Using a particle filtering method (Gordon, 1993; Isard and Blake, 1998; Sidenbladh et al., 2000a), the posterior probability distribution over poses of the body model is represented using a discrete set of samples (where each sample corresponds to some pose of\nthe body)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5476898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2dfa8d94e1d8fb771d9016a702ffdcd637e7da5",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a framework for constructing a linear subspace model of image appearance for complex articulated 3D figures such as humans and other animals. A commercial motion capture system provides 3D data that is aligned with images of subjects performing various activities. Portions of a limb's image appearance are seen from multiple views and for multiple subjects. From these partial views, weighted principal component analysis is used to construct a linear subspace representation of the \"unwrapped\" image appearance of each limb. The linear subspaces provide a generative model of the object appearance that is exploited in a Bayesian particle filtering tracking system. Results of tracking single limbs and walking humans are presented."
            },
            "slug": "A-framework-for-modeling-the-appearance-of-3D-Kjellstr\u00f6m-Torre",
            "title": {
                "fragments": [],
                "text": "A framework for modeling the appearance of 3D articulated figures"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A framework for constructing a linear subspace model of image appearance for complex articulated 3D figures such as humans and other animals and results of tracking single limbs and walking humans are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 143
                            }
                        ],
                        "text": "\u2026edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames [3, 19] or between an initial template and the current frame [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 147
                            }
                        ],
                        "text": "\u2026to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 120
                            }
                        ],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames (Bregler and Malik, 1998; Ju et al., 1996) or between an initial template and the current frame (Cham and Rehg, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 122
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2751624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9",
            "isKey": true,
            "numCitedBy": 882,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences. We introduce the use of a novel mathematical technique, the product of exponential maps and twist motions, and its integration into a differential motion estimation. This results in solving simple linear systems, and enables us to recover robustly the kinematic degrees-of-freedom in noise and complex self occluded configurations. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-animating an artificial 3D human model. We are also able to recover and re-animate the famous movements of Eadweard Muybridge's motion studies from the last century. To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "slug": "Tracking-people-with-twists-and-exponential-maps-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Tracking people with twists and exponential maps"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences, and is the first computer vision based system able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829021"
                        ],
                        "name": "D. Ruderman",
                        "slug": "D.-Ruderman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ruderman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 77
                            }
                        ],
                        "text": "We also test the global contrast normalization used by Lee et al. (2001) and Ruderman (1994)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 156
                            }
                        ],
                        "text": "The distributions over different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 112
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 22
                            }
                        ],
                        "text": "This is also found by Ruderman (1994, 1997) and Zhu and Mumford (1997)\u2014edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 82
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 142
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 31
                            }
                        ],
                        "text": "This is also found by Ruderman [34, 35] and Zhu and Mumford [49] { edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12865273,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "be8cdeafb6bcda28468fec7733cedc3259dbdf83",
            "isKey": true,
            "numCitedBy": 275,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Origins-of-scaling-in-natural-images-Ruderman",
            "title": {
                "fragments": [],
                "text": "Origins of scaling in natural images"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145286523"
                        ],
                        "name": "K. Rohr",
                        "slug": "K.-Rohr",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Rohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Rohr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 193
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 76
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 146
                            }
                        ],
                        "text": "\u2026have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Background subtraction [8, 16, 32, 33, 47] gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122238372,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92ab4fc76e2f085dde81626794b79b5e9d1d00e0",
            "isKey": true,
            "numCitedBy": 491,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The interpretation of the movements of articulated bodies in image sequences is one of the most challenging problems in computer vision. In this contribution, we introduce a model-based approach for the recognition of pedestrians. We represent the human body by a 3D-model consisting of cylinders, whereas for modelling the movement of walking we use data from medical motion studies. The estimation of model parameters in consecutive images is done by applying a Kalman filter. Experimental results are shown for synthetic as well as for real image data."
            },
            "slug": "Towards-model-based-recognition-of-human-movements-Rohr",
            "title": {
                "fragments": [],
                "text": "Towards model-based recognition of human movements in image sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model-based approach for the recognition of pedestrians is introduced and the human body is represented by a 3D-model consisting of cylinders, whereas for modelling the movement of walking the authors use data from medical motion studies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 34
                            }
                        ],
                        "text": "These filter responses, fr , are a function of [ fxx , fxy, fyy], the second derivatives of the image brightness function in the horizontal and vertical directions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 172
                            }
                        ],
                        "text": "We can assume that the function relating limb width and scale is linear, since the scale can be viewed as a length measure in the image\u2014a linear function of the radius or length of the structures visible at that scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 85
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 80
                            }
                        ],
                        "text": "Both of these areas have attracted a considerable amount of interest in the recent years and are reviewed briefly here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 115
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9526302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e309e441a38ccee6456bd02e0f1e894e44180d53",
            "isKey": true,
            "numCitedBy": 618,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural images contain characteristic statistical regularities that set them apart from purely random images. Understanding what these regularities are can enable natural images to be coded more efficiently. In this paper, we describe some of the forms of structure that are contained in natural images, and we show how these are related to the response properties of neurons at early stages of the visual system. Many of the important forms of structure require higher-order (i.e. more than linear, pairwise) statistics to characterize, which makes models based on linear Hebbian learning, or principal components analysis, inappropriate for finding efficient codes for natural images. We suggest that a good objective for an efficient coding of natural scenes is to maximize the sparseness of the representation, and we show that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive fields similar to those in the mammalian striate cortex."
            },
            "slug": "Natural-image-statistics-and-efficient-coding.-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Natural image statistics and efficient coding."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that a good objective for an efficient coding of natural Scenes is to maximize the sparseness of the representation, and it is shown that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive fields similar to those in the mammalian striate cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700569"
                        ],
                        "name": "T. Moeslund",
                        "slug": "T.-Moeslund",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Moeslund",
                            "middleNames": [
                                "Baltzer"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moeslund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700008"
                        ],
                        "name": "E. Granum",
                        "slug": "E.-Granum",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Granum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Granum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 100
                            }
                        ],
                        "text": "Previous work on human motion tracking has exploited a variety of image cues (see Gavrila (1999) or Moeslund and Granum (2001) for recent reviews)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Previous work on human motion tracking has exploited a variety of image cues (see Gavrila [12] or Moeslund and Granum [25] for recent reviews)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14970359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ee709de9c13034bcae1fff96b5abb7312bd097e",
            "isKey": false,
            "numCitedBy": 1978,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive survey of computer vision-based human motion capture literature from the past two decades is presented. The focus is on a general overview based on a taxonomy of system functionalities, broken down into four processes: initialization, tracking, pose estimation, and recognition. Each process is discussed and divided into subprocesses and/or categories of methods to provide a reference to describe and compare the more than 130 publications covered by the survey. References are included throughout the paper to exemplify important issues and their relations to the various methods. A number of general assumptions used in this research field are identified and the character of these assumptions indicates that the research field is still in an early stage of development. To evaluate the state of the art, the major application areas are identified and performances are analyzed in light of the methods presented in the survey. Finally, suggestions for future research directions are offered."
            },
            "slug": "A-Survey-of-Computer-Vision-Based-Human-Motion-Moeslund-Granum",
            "title": {
                "fragments": [],
                "text": "A Survey of Computer Vision-Based Human Motion Capture"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A comprehensive survey of computer vision-based human motion capture literature from the past two decades is presented, with a general overview based on a taxonomy of system functionalities, broken down into four processes: initialization, tracking, pose estimation, and recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1829021"
                        ],
                        "name": "D. Ruderman",
                        "slug": "D.-Ruderman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ruderman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ruderman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 77
                            }
                        ],
                        "text": "We also test the global contrast normalization used by Lee et al. (2001) and Ruderman (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 156
                            }
                        ],
                        "text": "The distributions over different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 82
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 112
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 22
                            }
                        ],
                        "text": "This is also found by Ruderman (1994, 1997) and Zhu and Mumford (1997)\u2014edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 139
                            }
                        ],
                        "text": "\u2026over different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 74
                            }
                        ],
                        "text": "This builds upon recent work on learning the statistics of natural scenes [21, 23, 27, 34, 41, 49] and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 134
                            }
                        ],
                        "text": "The distributions over di erent kinds of lter responses have two notable things in common: The distributions are invariant over scale [23, 34, 49], and they are non-Gaussian, with a high kurtosis [13, 23, 34, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 82
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 142
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 256
                            }
                        ],
                        "text": "\u2026kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 31
                            }
                        ],
                        "text": "This is also found by Ruderman [34, 35] and Zhu and Mumford [49] { edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Studies on the statistics of natural images [21, 23, 27, 34, 41, 49] have shown that this is not the case { the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2793971,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "13206b6ba3711a14a56cf1599ecb08c16f49061e",
            "isKey": true,
            "numCitedBy": 912,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently there has been a resurgence of interest in the properties of natural images. Their statistics are important not only in image compression but also for the study of sensory processing in biology, which can be viewed as satisfying certain \u2018design criteria\u2019. This review summarizes previous work on image statistics and presents our own data. Perhaps the most notable property of natural images is an invariance to scale. We present data to support this claim as well as evidence for a hierarchical invariance in natural scenes. These symmetries provide a powerful description of natural images as they greatly restrict the class of allowed distributions."
            },
            "slug": "The-statistics-of-natural-images-Ruderman",
            "title": {
                "fragments": [],
                "text": "The statistics of natural images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723930"
                        ],
                        "name": "A. Jepson",
                        "slug": "A.-Jepson",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Jepson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jepson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Black and Jepson (1998) addressed this problem by learning parameterized models of the appearance of an object from an arbitrary view given a few example views of the same object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 56
                            }
                        ],
                        "text": "Recent work on tracking and learning appearance models (Jepson et al., 2001) may provide a principled way of adapting models of limb appearance over time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Black and Jepson [2] addressed this problem by learning parameterized models of the appearance of an object from an arbitrary view given a few example views of the same object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 25
                            }
                        ],
                        "text": "We are grateful to Allan Jepson for discussions on foreground/background modeling and Bayesian tracking."
                    },
                    "intents": []
                }
            ],
            "corpusId": 572947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9158048426a7f673bcc513e074e76b0b7e435b7",
            "isKey": false,
            "numCitedBy": 1297,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an approach for tracking rigid and articulated objects using a view-based representation. The approach builds on and extends work on eigenspace representations, robust estimation techniques, and parameterized optical flow estimation. First, we note that the least-squares image reconstruction of standard eigenspace techniques has a number of problems and we reformulate the reconstruction problem as one of robust estimation. Second we define a \u201csubspace constancy assumption\u201d that allows us to exploit techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image. To account for large affine transformations between the eigenspace and the image we define a multi-scale eigenspace representation and a coarse-to-fine matching strategy. Finally, we use these techniques to track objects over long image sequences in which the objects simultaneously undergo both affine image motions and changes of view. In particular we use this \u201cEigenTracking\u201d technique to track and recognize the gestures of a moving hand."
            },
            "slug": "EigenTracking:-Robust-Matching-and-Tracking-of-a-Black-Jepson",
            "title": {
                "fragments": [],
                "text": "EigenTracking: Robust Matching and Tracking of Articulated Objects Using a View-Based Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A \u201csubspace constancy assumption\u201d is defined that allows techniques for parameterized optical flow estimation to simultaneously solve for the view of an object and the affine transformation between the eigenspace and the image."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 141
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance (Gavrila, 1996), or by enforcing a maximum distance between limb boundaries and image edges (Hogg, 1983; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 158
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Given the complexity of the appearance of a human, it is di\u00c6cult to use bottom-up approaches to detect humans in images [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance [11], or by enforcing a maximum distance between limb boundaries and image edges [15, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 126
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 123
                            }
                        ],
                        "text": "Given the complexity of the appearance of a human, it is difficult to use bottom-up approaches to detect humans in images (Hogg, 1983)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34873540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f98b189cec1220d479e3079b942e71b244aa65",
            "isKey": true,
            "numCitedBy": 597,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-based-vision:-a-program-to-see-a-walking-Hogg",
            "title": {
                "fragments": [],
                "text": "Model-based vision: a program to see a walking person"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46887763"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rasmussen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678633"
                        ],
                        "name": "Gregory Hager",
                        "slug": "Gregory-Hager",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Hager",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Hager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "The Bayesian approach presented in this paper enables combination of di erent cues in a principled way (for a related Bayesian method see [29])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 122
                            }
                        ],
                        "text": "While many systems combine cues such as motion, color, or stereo for person detection and tracking (Darrell et al., 2000; Rasmussen and Hager, 2001; Wachter and Nagel, 1999), the formulation and combination of these cues is often ad hoc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 139
                            }
                        ],
                        "text": "The Bayesian approach presented in this paper enables combination of different cues in a principled way (for a related Bayesian method see Rasmussen and Hager (2001))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 189
                            }
                        ],
                        "text": "These experiments suggest that tracking can benefit from likelihood measures using multiple cues, since the cues have different properties and are effected by different kinds of noise (cf. Rasmussen and Hager (2001))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 99
                            }
                        ],
                        "text": "While many systems combine cues such as motion, color, or stereo for person detection and tracking [6, 29, 46], the formulation and combination of these cues is often ad hoc."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 859164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86d8adbb1b6389860f0de14217c2f364da9eac8a",
            "isKey": true,
            "numCitedBy": 449,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a framework that explicitly reasons about data association to improve tracking performance in many difficult visual environments. A hierarchy of tracking strategies results from ascribing ambiguous or missing data to: 1) noise-like visual occurrences, 2) persistent, known scene elements (i.e., other tracked objects), or 3) persistent, unknown scene elements. First, we introduce a randomized tracking algorithm adapted from an existing probabilistic data association filter (PDAF) that is resistant to clutter and follows agile motion. The algorithm is applied to three different tracking modalities-homogeneous regions, textured regions, and snakes-and extensibly defined for straightforward inclusion of other methods. Second, we add the capacity to track multiple objects by adapting to vision a joint PDAF which oversees correspondence choices between same-modality trackers and image features. We then derive a related technique that allows mixed tracker modalities and handles object overlaps robustly. Finally, we represent complex objects as conjunctions of cues that are diverse both geometrically (e.g., parts) and qualitatively (e.g., attributes). Rigid and hinge constraints between part trackers and multiple descriptive attributes for individual parts render the whole object more distinctive, reducing susceptibility to mistracking. Results are given for diverse objects such as people, microscopic cells, and chess pieces."
            },
            "slug": "Probabilistic-Data-Association-Methods-for-Tracking-Rasmussen-Hager",
            "title": {
                "fragments": [],
                "text": "Probabilistic Data Association Methods for Tracking Complex Visual Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A randomized tracking algorithm adapted from an existing probabilistic data association filter (PDAF) that is resistant to clutter and follows agile motion is introduced and a related technique that allows mixed tracker modalities and handles object overlaps robustly is derived."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 85
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 74
                            }
                        ],
                        "text": "This builds upon recent work on learning the statistics of natural scenes [21, 23, 27, 34, 41, 49] and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 115
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Studies on the statistics of natural images [21, 23, 27, 34, 41, 49] have shown that this is not the case { the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15125241,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44352b35791ceaad3439b8ccf165cc9b4978d801",
            "isKey": true,
            "numCitedBy": 31,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural images contain characteristic statistical regularities that set them apart from purely random images. Understanding what these regularities are can enable natural images to be coded more eeciently. In this paper, we describe some of the forms of structure that are contained in natural images, and we show how these are related to the response properties of neurons at early stages of the visual system. Many of the important forms of structure require higher-order (i.e., more than linear, pairwise) statistics to characterize, which makes models based on linear Hebbian learning, or principal components analysis, inappropriate for nding eecient codes for natural images. We suggest that a good objective for an eecient coding of natural scenes is to maximize the sparseness of the representation, and we show that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive elds similar to those in the primate striate cortex."
            },
            "slug": "Natural-Image-Statistics-and-Eecient-Coding-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Natural Image Statistics and Eecient Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that a good objective for an eecient coding of natural Scenes is to maximize the sparseness of the representation, and it is shown that a network that learns sparse codes of natural scenes succeeds in developing localized, oriented, bandpass receptive elds similar to those in the primate striate cortex."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 111
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 203
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter (Deutscher et al., 2000; Gavrila, 1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 49
                            }
                        ],
                        "text": "This can be computed using the Chamfer distance (Gavrila, 1996), or by enforcing a maximum distance between limb boundaries and image edges (Hogg, 1983; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 357,
                                "start": 350
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs (Wren et al., 1997) or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 82
                            }
                        ],
                        "text": "Previous work on human motion tracking has exploited a variety of image cues (see Gavrila (1999) or Moeslund and Granum (2001) for recent reviews)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "Previous work on human motion tracking has exploited a variety of image cues (see Gavrila [12] or Moeslund and Granum [25] for recent reviews)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7788290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4e4b41b6010ac1e6c90791168f57bcd75b696ab",
            "isKey": true,
            "numCitedBy": 2210,
            "numCiting": 145,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to recognize humans and their activities by vision is key for a machine to interact intelligently and effortlessly with a human-inhabited environment. Because of many potentially important applications, \u201clooking at people\u201d is currently one of the most active application domains in computer vision. This survey identifies a number of promising applications and provides an overview of recent developments in this domain. The scope of this survey is limited to work on whole-body or hand motion; it does not include work on human faces. The emphasis is on discussing the various methodologies; they are grouped in 2-D approaches with or without explicit shape models and 3-D approaches. Where appropriate, systems are reviewed. We conclude with some thoughts about future directions."
            },
            "slug": "The-Visual-Analysis-of-Human-Movement:-A-Survey-Gavrila",
            "title": {
                "fragments": [],
                "text": "The Visual Analysis of Human Movement: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A number of promising applications are identified and an overview of recent developments in this domain is provided, including work on whole-body or hand motion and the various methodologies."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50626295"
                        ],
                        "name": "J. Sullivan",
                        "slug": "J.-Sullivan",
                        "structuredName": {
                            "firstName": "Josephine",
                            "lastName": "Sullivan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sullivan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[44, 45] who model the distributions of lter responses for a general background and a particular foreground (using a generalized template)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 236
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 104
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 70
                            }
                        ],
                        "text": "In general, issues of spatial correlation deserve further study (c.f. Sullivan et al. (1999, 2000))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 199
                            }
                        ],
                        "text": "\u2026(Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 57
                            }
                        ],
                        "text": "Our work is also closely related to the tracking work of Sullivan et al. (1999, 2000) who model the distributions of filter responses for a general background and a particular foreground (using a generalized template)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8391961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b9ecbf766ef7abd523497996421d583200244b4",
            "isKey": true,
            "numCitedBy": 148,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Maximisation of cross correlation is a commonly used principle for intensity based object localization that gives a single estimate of location. However, to facilitate sequential inference (e.g. over time or scale) and to allow the representation of ambiguity, it is desirable to represent an entire probability distribution for object location. Although the cross correlation itself (or some function of it) has sometimes been treated as a probability distribution, this is not generally justifiable. Bayesian correlation achieves a consistent probabilistic treatment by combining several developments. The first is the interpretation of correlation matching functions in probabilistic terms, as observation likelihoods. Second, probability distributions of filter bank responses are learned from training examples. Inescapably, response learning also demands statistical modelling of background intensities, and there are links here with image coding and Independent Component Analysis. Lastly, multi scale processing is achieved in a Bayesian context by means of a new algorithm, layered sampling, for which asymptotic properties are derived."
            },
            "slug": "Object-localization-by-Bayesian-correlation-Sullivan-Blake",
            "title": {
                "fragments": [],
                "text": "Object localization by Bayesian correlation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Bayesian correlation achieves a consistent probabilistic treatment by combining several developments, the interpretation of correlation matching functions in probabilistically terms, as observation likelihoods."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 172
                            }
                        ],
                        "text": "The distributions over different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 48
                            }
                        ],
                        "text": "This is also found by Ruderman (1994, 1997) and Zhu and Mumford (1997)\u2014edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 74
                            }
                        ],
                        "text": "This builds upon recent work on learning the statistics of natural scenes [21, 23, 27, 34, 41, 49] and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 134
                            }
                        ],
                        "text": "The distributions over di erent kinds of lter responses have two notable things in common: The distributions are invariant over scale [23, 34, 49], and they are non-Gaussian, with a high kurtosis [13, 23, 34, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 176
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 272
                            }
                        ],
                        "text": "\u2026kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "This is also found by Ruderman [34, 35] and Zhu and Mumford [49] { edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Studies on the statistics of natural images [21, 23, 27, 34, 41, 49] have shown that this is not the case { the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12762065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2e4d819a5934ef018d0894ad530d959f565d357",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel theory for learning generic prior models from a set of observed natural images based on a minimax entropy theory that the authors studied in modeling textures. We start by studying the statistics of natural images including the scale invariant properties, then generic prior models were learnt to duplicate the observed statistics. The learned Gibbs distributions confirm and improve the forms of existing prior models. More interestingly inverted potentials are found to be necessary, and such potentials form patterns and enhance preferred image features. The learned model is compared with existing prior models in experiments of image restoration."
            },
            "slug": "Learning-generic-prior-models-for-visual-Zhu-Mumford",
            "title": {
                "fragments": [],
                "text": "Learning generic prior models for visual computation"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A novel theory for learning generic prior models from a set of observed natural images based on a minimax entropy theory is presented, and inverted potentials are found to be necessary, and such potentials form patterns and enhance preferred image features."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716722"
                        ],
                        "name": "D. DeCarlo",
                        "slug": "D.-DeCarlo",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "DeCarlo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. DeCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 213
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 29
                            }
                        ],
                        "text": "Within a Bayesian framework, these object-specific models can be compared with generic models of natural scene statistics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 93
                            }
                        ],
                        "text": "To avoid this drift, brightness constancy is therefore often used in combination with edges (DeCarlo and Metaxas, 1996; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The sub-sections below provide details of the statistical models for the various cues."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5571579,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "71b32b16c2e1ac0718b3acc34842af675456d664",
            "isKey": true,
            "numCitedBy": 247,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a formal methodology for the integration of optical flow and deformable models. The optical flow constraint equation provides a non-holonomic constraint on the motion of the deformable model. In this augmented system, forces computed from edges and optical flow are used simultaneously. When this dynamic system is solved, a model-based least-squares solution for the optical flow is obtained and improved estimation results are achieved. The use of a 3-D model reduces or eliminates problems associated with optical flow computation. This approach instantiates a general methodology for treating visual cues as constraints on deformable models. We apply this framework to human face shape and motion estimation. Our 3-D deformable face model uses a small number of parameters to describe a rich variety of face shapes and facial expressions. We present experiments in extracting the shape and motion of a face from image sequences."
            },
            "slug": "The-integration-of-optical-flow-and-deformable-with-DeCarlo-Metaxas",
            "title": {
                "fragments": [],
                "text": "The integration of optical flow and deformable models with applications to human face shape and motion estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The 3-D deformable face model uses a small number of parameters to describe a rich variety of face shapes and facial expressions and presents experiments in extracting the shape and motion of a face from image sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9450153"
                        ],
                        "name": "H. Sidenbladh",
                        "slug": "H.-Sidenbladh",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Sidenbladh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sidenbladh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 106
                            }
                        ],
                        "text": "It is worth noting that the distributions over temporal differences can be approximated analytically (see Sidenbladh (2001) for more details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "It is worth noting that the distributions over temporal di erences can be approximated analytically (see [36] for more details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57177190,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "c7945f0d2848bab9dd97b04ef1d7f739259e447a",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 159,
            "paperAbstract": {
                "fragments": [],
                "text": "Thetrackingandreconstructionof articulatedhumanmotionin 3D is a problemthat hasattracteda greatdealof interestin thelastyears.A systemthatrecovers3D body posefrom videosequences hasapplicationsin vision-basedhuman-computer interaction, marker-lessmotion capture,animation,surveillanceandentertainment suchas computergames. Thefast,non-linearmotionandcomplicatedappearanceof humansandthelarge numberdegreesof freedomof thehumanbodymake thetrackingproblema difficult one. To addresstheseproblems,a systemfor trackingandreconstructionof human motion in 3D shouldpossessthe following: A strongmodel for the appearanceof humansin images;amodelof how peoplemove;andaneffectivestrategy for searching for the right posein eachtime step. In previously presentedsystems,the most commonway of addressingtheseissueshasbeento constrainthe problemdomain. The appearanceof humanscould be constrainedby assumingcertainclothing anda largecontrastbetweenthehumanandthebackground.Furthermore,by addingmore cameraviews,moreinformationaboutthe3D poseof thehumancanbeextractedand ambiguitiesreduced,thusmakingtheproblemeasier . The goal of this thesisis to investigateto which extent the general problemof tracking and reconstructinghumanmotion can be solved, using only a monocular cameraview. Thus, no assumptionsof the appearanceof either the humanor the backgroundareintroduced. Thethesismakesthreecontributions:A probabilisticframework for thearticulated trackingof humanfiguresin 3D; afilter-basedlearnedmodelof humanappearancein imagesandimagesequences; andthreedifferenttypesof modelsof humanmotion, intendedto constrainthesearchin eachtimestepof thetracking.Successful tracking resultsusingthehumanappearancemodelandall threemotionmodelsarepresented. Amongthequestionsleft openis theissueof initialization, a difficult problemin the high-dimensional searchspaceof anarticulatedmodelin 3D. Thecontributionsof this thesisprovideasmallsteponthewaytowardsrobustand accuratearticulated3D trackingof humansin monocularsequences."
            },
            "slug": "Probabilistic-Tracking-and-Reconstruction-of-3D-in-Sidenbladh",
            "title": {
                "fragments": [],
                "text": "Probabilistic Tracking and Reconstruction of 3D Human Motion in Monocular Video Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The goal of this thesis is to investigateto which extent the general problem of tracking and reconstructing human motion can be solved, using only a monocular cameraview, with no assumptions of the appearance of either the human or the background introduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Moreover, we show that the distribution is related to robust statistical methods for estimating optical ow [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 85
                            }
                        ],
                        "text": "This provides an interesting connection with work on robust optical flow estimation (Black and Anandan, 1996) where violations of the brightness constancy assumption are dealt with using a robust error term."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "This provides an interesting connection with work on robust optical ow estimation [1] where vio-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 110
                            }
                        ],
                        "text": "Moreover, we show that the distribution is related to robust statistical methods for estimating optical flow (Black and Anandan, 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 124
                            }
                        ],
                        "text": "This distribution is typically assumed to be Gaussian (Simoncelli et al., 1991) or some heavy-tailed, \u201crobust\u201d, distribution (Black and Anandan, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "This distribution is typically assumed to be Gaussian [42] or some heavy-tailed, \\robust\", distribution [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14070356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eee90c038f43370a29b07e46f38dfe6527143a2c",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences."
            },
            "slug": "The-Robust-Estimation-of-Multiple-Motions:-and-Flow-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A framework based on robust estimation is presented that addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions of optical flow, and is applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1832448"
                        ],
                        "name": "Ann B. Lee",
                        "slug": "Ann-B.-Lee",
                        "structuredName": {
                            "firstName": "Ann",
                            "lastName": "Lee",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ann B. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145738882"
                        ],
                        "name": "Jinggang Huang",
                        "slug": "Jinggang-Huang",
                        "structuredName": {
                            "firstName": "Jinggang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinggang Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 55
                            }
                        ],
                        "text": "We also test the global contrast normalization used by Lee et al. (2001) and Ruderman (1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 36
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 67
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 74
                            }
                        ],
                        "text": "This builds upon recent work on learning the statistics of natural scenes [21, 23, 27, 34, 41, 49] and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 134
                            }
                        ],
                        "text": "The distributions over di erent kinds of lter responses have two notable things in common: The distributions are invariant over scale [23, 34, 49], and they are non-Gaussian, with a high kurtosis [13, 23, 34, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 97
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 138
                            }
                        ],
                        "text": "The distributions over different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 238
                            }
                        ],
                        "text": "\u2026kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "\u2026statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Studies on the statistics of natural images [21, 23, 27, 34, 41, 49] have shown that this is not the case { the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13343075,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "556767b5a36ed8f7f8183882bde33399b5199328",
            "isKey": true,
            "numCitedBy": 155,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a scale-invariant version of Matheron's \u201cdead leaves model\u201d for the statistics of natural images. The model takes occlusions into account and resembles the image formation process by randomly adding independent elementary shapes, such as disks, in layers. We compare the empirical statistics of two large databases of natural images with the statistics of the occlusion model, and find an excellent qualitative, and good quantitative agreement. At this point, this is the only image model which comes close to duplicating the simplest, elementary statistics of natural images\u2014such as, the scale invariance property of marginal distributions of filter responses, the full co-occurrence statistics of two pixels, and the joint statistics of pairs of Haar wavelet responses."
            },
            "slug": "Occlusion-Models-for-Natural-Images:-A-Statistical-Lee-Mumford",
            "title": {
                "fragments": [],
                "text": "Occlusion Models for Natural Images: A Statistical Study of a Scale-Invariant Dead Leaves Model"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A scale-invariant version of Matheron's \u201cdead leaves model\u201d for the statistics of natural images that takes occlusions into account and resembles the image formation process by randomly adding independent elementary shapes, such as disks, in layers."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144530541"
                        ],
                        "name": "T. Cham",
                        "slug": "T.-Cham",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Cham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 170
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 180
                            }
                        ],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames [3, 19] or between an initial template and the current frame [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 152
                            }
                        ],
                        "text": "Templates have been used successfully for face tracking [45], and have also proven suitable for tracking of articulated structures in constrained cases [4, 30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 202131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4af6518594742d5e440fd3a13324f5a907805f08",
            "isKey": true,
            "numCitedBy": 401,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a probabilistic multiple-hypothesis framework for tracking highly articulated objects. In this framework, the probability density of the tracker state is represented as a set of modes with piecewise Gaussians characterizing the neighborhood around these modes. The temporal evolution of the probability density is achieved through sampling from the prior distribution, followed by local optimization of the sample positions to obtain updated modes. This method of generating hypotheses from state-space search does not require the use of discrete features unlike classical multiple-hypothesis tracking. The parametric form of the model is suited for high dimensional state-spaces which cannot be efficiently modeled using non-parametric approaches. Results are shown for tracking Fred Astaire in a movie dance sequence."
            },
            "slug": "A-multiple-hypothesis-approach-to-figure-tracking-Cham-Rehg",
            "title": {
                "fragments": [],
                "text": "A multiple hypothesis approach to figure tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A probabilistic multiple-hypothesis framework for tracking highly articulated objects where the probability density of the tracker state is represented as a set of modes with piecewise Gaussians characterizing the neighborhood around these modes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775672"
                        ],
                        "name": "Dirk Ormoneit",
                        "slug": "Dirk-Ormoneit",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Ormoneit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dirk Ormoneit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 100
                            }
                        ],
                        "text": "the prior distribution; for examples of generic and event-speci c priors, the reader is referred to [28, 39, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 124
                            }
                        ],
                        "text": "Here we do not address the prior distribution; for examples of generic and event-specific priors, the reader is referred to Ormoneit et al. (2001) and Sidenbladh et al. (2000a, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2217697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3470656ac8e8cd50661bf908e94e1125d49134cd",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present methods for learning and tracking human motion in video. We estimate a statistical model of typical activities from a large set of 3D periodic human motion data by segmenting these data automatically into \"cycles\". Then the mean and the principal components of the cycles are computed using a new algorithm that accounts for missing information and enforces smooth transitions between cycles. The learned temporal model provides a prior probability distribution over human motions that can be used in a Bayesian framework for tracking human subjects in complex monocular video sequences and recovering their 3D motion."
            },
            "slug": "Learning-and-Tracking-Cyclic-Human-Motion-Ormoneit-Kjellstr\u00f6m",
            "title": {
                "fragments": [],
                "text": "Learning and Tracking Cyclic Human Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The learned temporal model provides a prior probability distribution over human motions that can be used in a Bayesian framework for tracking human subjects in complex monocular video sequences and recovering their 3D motion."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707642"
                        ],
                        "name": "D. Geman",
                        "slug": "D.-Geman",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2521020"
                        ],
                        "name": "B. Jedynak",
                        "slug": "B.-Jedynak",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Jedynak",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Jedynak"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 196
                            }
                        ],
                        "text": "The distributions over di erent kinds of lter responses have two notable things in common: The distributions are invariant over scale [23, 34, 49], and they are non-Gaussian, with a high kurtosis [13, 23, 34, 49]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 104
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 174
                            }
                        ],
                        "text": "\u2026(Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 213
                            }
                        ],
                        "text": "\u2026kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7358010,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0ce6df6d6f009cbdd5f8c395bd422581e9aa0769",
            "isKey": true,
            "numCitedBy": 598,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach for tracking roads from satellite images, and thereby illustrate a general computational strategy (\"active testing\") for tracking 1D structures and other recognition tasks in computer vision. Our approach is related to recent work in active vision on \"where to look next\" and motivated by the \"divide-and-conquer\" strategy of parlour games. We choose \"tests\" (matched filters for short road segments) one at a time in order to remove as much uncertainty as possible about the \"true hypothesis\" (road position) given the results of the previous tests. The tests are chosen online based on a statistical model for the joint distribution of tests and hypotheses. The problem of minimizing uncertainty (measured by entropy) is formulated in simple and explicit analytical terms. At each iteration new image data are examined and a new entropy minimization problem is solved (exactly), resulting in a new image location to inspect, and so forth. We report experiments using panchromatic SPOT satellite imagery with a ground resolution of ten meters."
            },
            "slug": "An-Active-Testing-Model-for-Tracking-Roads-in-Geman-Jedynak",
            "title": {
                "fragments": [],
                "text": "An Active Testing Model for Tracking Roads in Satellite Images"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A new approach for tracking roads from satellite images, and thereby illustrate a general computational strategy for tracking 1D structures and other recognition tasks in computer vision, related to recent work in active vision and motivated by the \"divide-and-conquer\" strategy of parlour games."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "With these restrictions, a straight line is tted to the measured limb-width-scale tuples using RANSAC [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 105
                            }
                        ],
                        "text": "With these restrictions, a straight line is fitted to the measured limb-width-scale tuples using RANSAC (Fischler and Bolles, 1981)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 972888,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "278c9a78d4505cfaf6b709df364dbd1206a017c1",
            "isKey": false,
            "numCitedBy": 15962,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing"
            },
            "slug": "Random-sample-consensus:-a-paradigm-for-model-with-Fischler-Bolles",
            "title": {
                "fragments": [],
                "text": "Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form that provide the basis for an automatic system that can solve the Location Determination Problem under difficult viewing."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685020"
                        ],
                        "name": "D. Comaniciu",
                        "slug": "D.-Comaniciu",
                        "structuredName": {
                            "firstName": "Dorin",
                            "lastName": "Comaniciu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Comaniciu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320582"
                        ],
                        "name": "Visvanathan Ramesh",
                        "slug": "Visvanathan-Ramesh",
                        "structuredName": {
                            "firstName": "Visvanathan",
                            "lastName": "Ramesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Visvanathan Ramesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145776090"
                        ],
                        "name": "P. Meer",
                        "slug": "P.-Meer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Meer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Meer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 114
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 130
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs (Wren et al., 1997) or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 559739,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2cfa006b33084abe8160b001f9a24944cda25d05",
            "isKey": false,
            "numCitedBy": 3282,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for real time tracking of non-rigid objects seen from a moving camera is proposed. The central computational module is based on the mean shift iterations and finds the most probable target position in the current frame. The dissimilarity between the target model (its color distribution) and the target candidates is expressed by a metric derived from the Bhattacharyya coefficient. The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution. The capability of the tracker to handle in real time partial occlusions, significant clutter, and target scale variations, is demonstrated for several image sequences."
            },
            "slug": "Real-time-tracking-of-non-rigid-objects-using-mean-Comaniciu-Ramesh",
            "title": {
                "fragments": [],
                "text": "Real-time tracking of non-rigid objects using mean shift"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The theoretical analysis of the approach shows that it relates to the Bayesian framework while providing a practical, fast and efficient solution for real time tracking of non-rigid objects seen from a moving camera."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 205
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 237
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 240
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1842570,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "2d0b50d3df26b64ec5a2f949bc241b4fce515fa9",
            "isKey": true,
            "numCitedBy": 356,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for recovering 3D human body motion from monocular video sequences using robust image matching, joint limits and non-self-intersection constraints, and a new sample-and-refine search strategy guided by rescaled cost-function covariances. Monocular 3D body tracking is challenging: for reliable tracking at least 30 joint parameters need to be estimated, subject to highly nonlinear physical constraints; the problem is chronically ill conditioned as about 1/3 of the d.o.f. (the depth-related ones) are almost unobservable in any given monocular image; and matching an imperfect, highly flexible self-occluding model to cluttered image features is intrinsically hard. To reduce correspondence ambiguities we use a carefully designed robust matching-cost metric that combines robust optical flow, edge energy, and motion boundaries. Even so, the ambiguity, nonlinearity and non-observability make the parameter-space cost surface multi-modal, unpredictable and ill conditioned, so minimizing it is difficult. We discuss the limitations of CONDENSATION-like samplers, and introduce a novel hybrid search algorithm that combines inflated-covariance-scaled sampling and continuous optimization subject to physical constraints. Experiments on some challenging monocular sequences show that robust cost modelling, joint and self-intersection constraints, and informed sampling are all essential for reliable monocular 3D body tracking."
            },
            "slug": "Covariance-scaled-sampling-for-monocular-3D-body-Sminchisescu-Triggs",
            "title": {
                "fragments": [],
                "text": "Covariance scaled sampling for monocular 3D body tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Experiments on some challenging monocular sequences show that robust cost modelling, joint and self-intersection constraints, and informed sampling are all essential for reliable monocular 3D body tracking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 122
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 180
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 438781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14c97202720284dd46f98a78505415b21ce0bd70",
            "isKey": false,
            "numCitedBy": 463,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework for modeling and recognition of temporal activities is proposed. The modeling of sets of exemplar activities is achieved by parameterizing their representation in the form of principal components. Recognition of spatio-temporal variants of modeled activities is achieved by parameterizing the search in the space of admissible transformations that the activities can undergo. Experiments on recognition of articulated and deformable object motion from image motion parameters are presented."
            },
            "slug": "Parameterized-modeling-and-recognition-of-Yacoob-Black",
            "title": {
                "fragments": [],
                "text": "Parameterized modeling and recognition of activities"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments on recognition of articulated and deformable object motion from image motion parameters are presented, and a framework for modeling and recognition of temporal activities is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2879020"
                        ],
                        "name": "Oscar Nestares",
                        "slug": "Oscar-Nestares",
                        "structuredName": {
                            "firstName": "Oscar",
                            "lastName": "Nestares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oscar Nestares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 19
                            }
                        ],
                        "text": "See recent work by Nestares and Fleet (2001) for a related approach that uses the phase of complex-valued filter responses to achieve similar contrast insensitivity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "We thank David Fleet who developed an early edge likelihood model and provided many valuable insights."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Using a particle ltering method [14, 17, 38], the posterior probability 1 See recent work by Nestares and Fleet [26] for a related approach that uses the phase of complex-valued lter responses to achieve similar contrast insensitivity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 17
                            }
                        ],
                        "text": "In related work, Nestares and Fleet (2001) use a steerable pyramid of quadrature-pair filters (Freeman and Adelson, 1991) and define the likelihood of an edge in terms of the empirical distribution over the amplitude and phase of these filter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "In related work, Nestares and Fleet [26] use a steerable pyramid of quadrature-pair lters [10] and de ne the likelihood of an edge in terms of the empirical distribution over the amplitude and phase of these lter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3022262,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1bf30a27a6415a0c4f5b2b642d6728848c60b2d",
            "isKey": true,
            "numCitedBy": 19,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a probabilistic framework for detecting and tracking motion boundaries. It builds on previous work (M.J. Black and D.J. Fleet, 2000) that used a particle filter to compute a posterior distribution over multiple, local motion models, one of which was specific for motion boundaries. We extend that framework in two ways: 1) with an enhanced likelihood that combines motion and edge support, 2) with a spatiotemporal model that propagates beliefs between adjoining image neighborhoods to encourage boundary continuity and provide better temporal predictions for motion boundaries. Approximate inference is achieved with a combination of tools: sampled representations allow us to represent multimodal non-Gaussian distributions and to apply nonlinear dynamics, while mixture models are used to simplify the computation of joint prediction distributions."
            },
            "slug": "Probabilistic-tracking-of-motion-boundaries-with-Nestares-Fleet",
            "title": {
                "fragments": [],
                "text": "Probabilistic tracking of motion boundaries with spatiotemporal predictions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A probabilistic framework for detecting and tracking motion boundaries is described with an enhanced likelihood that combines motion and edge support, and with a spatiotemporal model that propagates beliefs between adjoining image neighborhoods to encourage boundary continuity and provide better temporal predictions for motion boundaries."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 82
                            }
                        ],
                        "text": "To be able to compare ridge response at different scales, normalized derivatives (Lindeberg, 1998) are used to compute the filter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "These lters are based on various derivatives of normalized Gaussians [24] and provide some measure of invariance to variations in clothing, lighting, and background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 45
                            }
                        ],
                        "text": "2. s corresponds to the scale parameter \u221a\nt in Lindeberg (1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 169
                            }
                        ],
                        "text": "The normalized filters are denoted f sxx = s2\u03b3 fxx , f sxy = s2\u03b3 fxy and f syy = s2\u03b3 fyy , where s is the scale,2 and \u03b3 = 3/4, which is optimal for ridge response detection (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 51
                            }
                        ],
                        "text": "We would also like to thank Jan-Olof Eklundh, Tony Lindeberg, and Josephine Sullivan for helpful discussions on filters and likelihood models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "For our purposes we construct steerable image pyramids [10] using normalized Gaussian derivative lters ( rst and second order) [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "2 s corresponds to the scale parameter p t in [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 72
                            }
                        ],
                        "text": "These filters are based on various derivatives of normalized Gaussians (Lindeberg, 1998) and provide some measure of invariance to variations in clothing, lighting, and background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 10
                            }
                        ],
                        "text": "Following Lindeberg (1998), we define ridge response as the second derivative of the image perpendicular to the ridge (| f\u03b8\u03b8 |), minus the second derivative\nparallel to the ridge (| f(\u03b8\u2212 \u03c02 )(\u03b8\u2212 \u03c02 )|)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Following Lindeberg [24], we de ne ridge response as the second derivative of the image perpendicular to the ridge (jf j), minus the second derivative parallel to the ridge (jf( 2 )( 2 )j)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "We employ a steerable ridge lter that responds strongly where there is high curvature of the image brightness orthogonal to the limb axis and low curvature parallel to it [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 170
                            }
                        ],
                        "text": "The normalized lters are denoted f s xx = s 2 fxx, f s xy = s 2 fxy and f s yy = s 2 fyy, where s is the scale2, and = 3=4, which is optimal for ridge response detection [24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 154
                            }
                        ],
                        "text": "For our purposes we construct steerable image pyramids (Freeman and Adelson, 1991) using normalized Gaussian derivative filters (first and second order) (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "To be able to compare ridge response at di erent scales, normalized derivatives [24] are used to compute the lter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 174
                            }
                        ],
                        "text": "We employ a steerable ridge filter that responds strongly where there is high curvature of the image brightness orthogonal to the limb axis and low curvature parallel to it (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35328443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca715e1a1e4a66a763671c2a084bfc9bc23fc3e0",
            "isKey": true,
            "numCitedBy": 1132,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "When computing descriptors of image data, the type of information that can be extracted may be strongly dependent on the scales at which the image operators are applied. This article presents a systematic methodology for addressing this problem. A mechanism is presented for automatic selection of scale levels when detecting one-dimensional image features, such as edges and ridges.A novel concept of a scale-space edge is introduced, defined as a connected set of points in scale-space at which: (i) the gradient magnitude assumes a local maximum in the gradient direction, and (ii) a normalized measure of the strength of the edge response is locally maximal over scales. An important consequence of this definition is that it allows the scale levels to vary along the edge. Two specific measures of edge strength are analyzed in detail, the gradient magnitude and a differential expression derived from the third-order derivative in the gradient direction. For a certain way of normalizing these differential descriptors, by expressing them in terms of so-called \u03b3-normalized derivatives, an immediate consequence of this definition is that the edge detector will adapt its scale levels to the local image structure. Specifically, sharp edges will be detected at fine scales so as to reduce the shape distortions due to scale-space smoothing, whereas sufficiently coarse scales will be selected at diffuse edges, such that an edge model is a valid abstraction of the intensity profile across the edge.Since the scale-space edge is defined from the intersection of two zero-crossing surfaces in scale-space, the edges will by definition form closed curves. This simplifies selection of salient edges, and a novel significance measure is proposed, by integrating the edge strength along the edge. Moreover, the scale information associated with each edge provides useful clues to the physical nature of the edge.With just slight modifications, similar ideas can be used for formulating ridge detectors with automatic selection, having the characteristic property that the selected scales on a scale-space ridge instead reflect the width of the ridge.It is shown how the methodology can be implemented in terms of straightforward visual front-end operations, and the validity of the approach is supported by theoretical analysis as well as experiments on real-world and synthetic data."
            },
            "slug": "Edge-Detection-and-Ridge-Detection-with-Automatic-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Edge Detection and Ridge Detection with Automatic Scale Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A mechanism is presented for automatic selection of scale levels when detecting one-dimensional image features, such as edges and ridges, with characteristic property that the selected scales on a scale-space ridge instead reflect the width of the ridge."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695351"
                        ],
                        "name": "J. Rittscher",
                        "slug": "J.-Rittscher",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rittscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rittscher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718829"
                        ],
                        "name": "Jien Kato",
                        "slug": "Jien-Kato",
                        "structuredName": {
                            "firstName": "Jien",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jien Kato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3304770"
                        ],
                        "name": "S. Joga",
                        "slug": "S.-Joga",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Joga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Joga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 197
                            }
                        ],
                        "text": "\u2026proportional to the ratio between the likelihood that the foreground image pixels are explained by the foreground object and the likelihood that they are explained by some general background (cf. Rittscher et al. (2000)):\np(all cues | fgrnd, bgrnd) = C p(fgrnd cues | fgrnd) p(fgrnd cues | bgrnd) ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1237556,
            "fieldsOfStudy": [
                "Environmental Science",
                "Computer Science"
            ],
            "id": "8441486293d2b742664026c5bd13a3f16c7872c7",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A new probabilistic background model based on a Hidden Markov Model is presented. The hidden states of the model enable discrimination between foreground, background and shadow. This model functions as a low level process for a car tracker. A particle filter is employed as a stochastic filter for the car tracker. The use of a particle filter allows the incorporation of the information from the low level process via importance sampling. A novel observation density for the particle filter which models the statistical dependence of neighboring pixels based on a Markov random field is presented. The effectiveness of both the low level process and the observation likelihood are demonstrated."
            },
            "slug": "A-Probabilistic-Background-Model-for-Tracking-Rittscher-Kato",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Background Model for Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel observation density for the particle filter which models the statistical dependence of neighboring pixels based on a Markov random field is presented, and the effectiveness of both the low level process and the observation likelihood are demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 148
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 156
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "Alternatively, Isard and Blake [17] de ne an"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 121
                            }
                        ],
                        "text": "This suggests that a tracking scheme that models the whole distribution, such as particle filtering (e.g., CONDENSATION (Isard and Blake, 1998; Sidenbladh et al., 2000a; Sidenbladh and Black, 2001)) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 32
                            }
                        ],
                        "text": "Using a particle ltering method [14, 17, 38], the posterior probability 1 See recent work by Nestares and Fleet [26] for a related approach that uses the phase of complex-valued lter responses to achieve similar contrast insensitivity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 15
                            }
                        ],
                        "text": "Alternatively, Isard and Blake (1998) define an edge distance measure that is converted into a conditional likelihood distribution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 49
                            }
                        ],
                        "text": "Using a particle filtering method (Gordon, 1993; Isard and Blake, 1998; Sidenbladh et al., 2000a), the posterior probability distribution over poses of the body model is represented using a discrete set of samples (where each sample corresponds to some pose of\nthe body)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 13
                            }
                        ],
                        "text": "Condensation [17, 38, 37]) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 138
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6821810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963dddc907f56bd1d6c98dd40f560eb8786e49ea",
            "isKey": true,
            "numCitedBy": 5523,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of tracking curves in dense visual clutter is challenging. Kalman filtering is inadequate because it is based on Gaussian densities which, being unimo dal, cannot represent simultaneous alternative hypotheses. The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set. Condensation uses learned dynamical models, together with visual observations, to propagate the random set over time. The result is highly robust tracking of agile motion. Notwithstanding the use of stochastic methods, the algorithm runs in near real-time."
            },
            "slug": "CONDENSATION\u2014Conditional-Density-Propagation-for-Isard-Blake",
            "title": {
                "fragments": [],
                "text": "CONDENSATION\u2014Conditional Density Propagation for Visual Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Condensation algorithm uses \u201cfactored sampling\u201d, previously applied to the interpretation of static images, in which the probability distribution of possible interpretations is represented by a randomly generated set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50626295"
                        ],
                        "name": "J. Sullivan",
                        "slug": "J.-Sullivan",
                        "structuredName": {
                            "firstName": "Josephine",
                            "lastName": "Sullivan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sullivan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695351"
                        ],
                        "name": "J. Rittscher",
                        "slug": "J.-Rittscher",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rittscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rittscher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[44, 45] who model the distributions of lter responses for a general background and a particular foreground (using a generalized template)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 259
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 104
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "Templates have been used successfully for face tracking (Sullivan et al., 2000), and have also proven suitable for tracking of articulated structures in constrained cases (Cham and Rehg, 1999; Rehg and Kanade, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "Templates have been used successfully for face tracking [45], and have also proven suitable for tracking of articulated structures in constrained cases [4, 30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 70
                            }
                        ],
                        "text": "In general, issues of spatial correlation deserve further study (c.f. Sullivan et al. (1999, 2000))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 199
                            }
                        ],
                        "text": "\u2026(Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "p(f j ) = p(fe j ) p(fr j ) p(fm j ) : (13) 4 The spatial and temporal statistics of neighboring pixels are unlikely to be independent [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 57
                            }
                        ],
                        "text": "Our work is also closely related to the tracking work of Sullivan et al. (1999, 2000) who model the distributions of filter responses for a general background and a particular foreground (using a generalized template)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "The spatial and temporal statistics of neighboring pixels are un-\nlikely to be independent (Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17554257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1c12337cd2ee5597288254c881b2725e8c2aa2f",
            "isKey": true,
            "numCitedBy": 27,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A Bayesian approach to object localisation is feasible given suitable likelihood models for image observations. Such a likelihood involves statistical modelling--and learning--both of the object foreground and of the scene background. Statistical background models are already quite well understood. Here we propose a \"conditioned likelihood\" model for the foreground, conditioned on variations both in object appearance and illumination. Its effectiveness in localising a variety of objects is demonstrated."
            },
            "slug": "Statistical-Foreground-Modelling-for-Object-Sullivan-Blake",
            "title": {
                "fragments": [],
                "text": "Statistical Foreground Modelling for Object Localisation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A \"conditioned likelihood\" model for the foreground is proposed, conditioned on variations both in object appearance and illumination, and its effectiveness in localising a variety of objects is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "This distribution is typically assumed to be Gaussian [42] or some heavy-tailed, \\robust\", distribution [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 55
                            }
                        ],
                        "text": "This distribution is typically assumed to be Gaussian (Simoncelli et al., 1991) or some heavy-tailed, \u201crobust\u201d, distribution (Black and Anandan, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2467139,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "eaf31005e3e66eda87fda48b369e90a0a95c5320",
            "isKey": false,
            "numCitedBy": 457,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Gradient methods are widely used in the computation of optical flow. The authors discuss extensions of these methods which compute probability distributions of optical flow. The use of distributions allows representation of the uncertainties inherent in the optical flow computation, facilitating the combination with information from other sources. Distributed optical flow for a synthetic image sequence is computed, and it is demonstrated that the probabilistic model accounts for the errors in the flow estimates. The distributed optical flow for a real image sequence is computed.<<ETX>>"
            },
            "slug": "Probability-distributions-of-optical-flow-Simoncelli-Adelson",
            "title": {
                "fragments": [],
                "text": "Probability distributions of optical flow"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Distributed optical flow for a synthetic image sequence is computed, and it is demonstrated that the probabilistic model accounts for the errors in the flow estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 142
                            }
                        ],
                        "text": "\u2026for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 170
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 193
                            }
                        ],
                        "text": "Templates have been used successfully for face tracking (Sullivan et al., 2000), and have also proven suitable for tracking of articulated structures in constrained cases (Cham and Rehg, 1999; Rehg and Kanade, 1995)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 152
                            }
                        ],
                        "text": "Templates have been used successfully for face tracking [45], and have also proven suitable for tracking of articulated structures in constrained cases [4, 30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": true,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 104
                            }
                        ],
                        "text": "The statistics of grey-level values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 48
                            }
                        ],
                        "text": "This is also found by Ruderman (1994, 1997) and Zhu and Mumford (1997)\u2014edge response is consistent over scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 176
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026different kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 272
                            }
                        ],
                        "text": "\u2026kinds of filter responses have two notable things in common: The distributions are invariant over scale (Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997), and they are non-Gaussian, with a high kurtosis (Geman and Jedynak, 1996; Lee et al., 2001; Ruderman, 1994; Zhu and Mumford, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7423086,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adc69aebcee4af29e115f54e3a5f210c5cc7dadc",
            "isKey": true,
            "numCitedBy": 408,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This article addresses two important themes in early visual computation: it presents a novel theory for learning the universal statistics of natural images, and, it proposes a general framework of designing reaction-diffusion equations for image processing. We studied the statistics of natural images including the scale invariant properties, then generic prior models were learned to duplicate the observed statistics, based on minimax entropy theory. The resulting Gibbs distributions have potentials of the form U(I; /spl Lambda/, S)=/spl Sigma//sub /spl alpha/=1//sup k//spl Sigma//sub x,y//spl lambda//sup (/spl alpha/)/((F/sup (/spl alpha/)/*I)(x,y)) with S={F/sup (1)/, F/sup (2)/,...,F/sup (K)/} being a set of filters and /spl Lambda/={/spl lambda//sup (1)/(),/spl lambda//sup (2)/(),...,/spl lambda//sup (K)/()} the potential functions. The learned Gibbs distributions confirm and improve the form of existing prior models such as line-process, but, in contrast to all previous models, inverted potentials were found to be necessary. We find that the partial differential equations given by gradient descent on U(I; /spl Lambda/, S) are essentially reaction-diffusion equations, where the usual energy terms produce anisotropic diffusion, while the inverted energy terms produce reaction associated with pattern formation, enhancing preferred image features. We illustrate how these models can be used for texture pattern rendering, denoising, image enhancement, and clutter removal by careful choice of both prior and data models of this type, incorporating the appropriate features."
            },
            "slug": "Prior-Learning-and-Gibbs-Reaction-Diffusion-Zhu-Mumford",
            "title": {
                "fragments": [],
                "text": "Prior Learning and Gibbs Reaction-Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is found that the partial differential equations given by gradient descent on U(I; /spl Lambda/, S) are essentially reaction-diffusion equations, where the usualEnergy terms produce anisotropic diffusion, while the inverted energy terms produce reaction associated with pattern formation, enhancing preferred image features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841773"
                        ],
                        "name": "S. Konishi",
                        "slug": "S.-Konishi",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Konishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Konishi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8436115"
                        ],
                        "name": "J. Coughlan",
                        "slug": "J.-Coughlan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Coughlan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Coughlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145380991"
                        ],
                        "name": "Song-Chun Zhu",
                        "slug": "Song-Chun-Zhu",
                        "structuredName": {
                            "firstName": "Song-Chun",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song-Chun Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 78
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 45
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "We exploit an approach based on the Bhattacharyya distance between foreground and background distributions [20, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Motivated by [21], probability distributions of various lter responses on human limbs are"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 230
                            }
                        ],
                        "text": "Let the probability distributions of foreground filter responses be peon( fe), p r on( fr ), p m on( fm)\nand the distributions over background filter responses be peoff( fe), p r off( fr ), p m off( fm), following the notation of Konishi et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 13
                            }
                        ],
                        "text": "Motivated by Konishi et al. (1999), probability distributions of various filter responses on human limbs are constructed as illustrated in Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 47
                            }
                        ],
                        "text": "This would be less appropriate for the task of Konishi et al. (1999) and, as a result of normalization, the distributions we learn have a somewhat different shape."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 74
                            }
                        ],
                        "text": "This builds upon recent work on learning the statistics of natural scenes [21, 23, 27, 34, 41, 49] and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "This marginal distribution, pon(fe j l), is based on more training data, and therefore more representative of the true distribution [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] and, as a result of normalization, the distributions we learn have a somewhat di erent shape."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 75
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 41
                            }
                        ],
                        "text": "This is similar in spirit to the work of Konishi et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 134
                            }
                        ],
                        "text": "This marginal distribution, pon( fe | l), is based on more training data, and therefore more representative of the\ntrue distribution (Konishi et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 123
                            }
                        ],
                        "text": "We exploit an approach based on the Bhattacharyya distance between foreground and background distributions (Kaliath, 1951; Konishi et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Konishi et al. (1999) also compute the distribution poff corresponding to the filter responses away from edges and used the log of the likelihood ratio between pon and poff for edge detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 141
                            }
                        ],
                        "text": "\u2026values (Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Studies on the statistics of natural images [21, 23, 27, 34, 41, 49] have shown that this is not the case { the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5565516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f2ca6cbca6ff1cbcec8a1a7db70663a0d72514",
            "isKey": true,
            "numCitedBy": 94,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We treat the problem of edge detection as one of statistical inference. Local edge cues, implemented by filters, provide information about the likely positions of edges which can be used as input to higher-level models. Different edge cues can be evaluated by the statistical effectiveness of their corresponding filters evaluated on a dataset of 100 presegmented images. We use information theoretic measures to determine the effectiveness of a variety of different edge detectors working at multiple scales on black and white and color images. Our results give quantitative measures for the advantages of multi-level processing, for the use of chromaticity in addition to greyscale, and for the relative effectiveness of different detectors."
            },
            "slug": "Fundamental-bounds-on-edge-detection:-an-theoretic-Konishi-Yuille",
            "title": {
                "fragments": [],
                "text": "Fundamental bounds on edge detection: an information theoretic evaluation of different edge cues"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work uses information theoretic measures to determine the effectiveness of a variety of different edge detectors working at multiple scales on black and white and color images and gives quantitative measures for the advantages of multi-level processing, for the use of chromaticity in addition to greyscale, and for the relative effectiveness of different detectors."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 62
                            }
                        ],
                        "text": "First derivatives of normalized Gaussian filters are steered (Freeman and Adelson, 1991) to the orientation of the limb and are applied at multiple scales."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 122
                            }
                        ],
                        "text": "The Bayesian methods require a temporal prior probability distribution and a conditional likelihood distribution that models the probability of\nobserving image cues given a predicted pose or motion of the body."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(6)\nFigure 12 shows an example of a steered ridge response for a lower arm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 73
                            }
                        ],
                        "text": "We use several different filter responses, and we use steerable filters (Freeman and Adelson, 1991) instead of isotropic ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 56
                            }
                        ],
                        "text": "For our purposes we construct steerable image pyramids (Freeman and Adelson, 1991) using normalized Gaussian derivative filters (first and second order) (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 95
                            }
                        ],
                        "text": "In related work, Nestares and Fleet (2001) use a steerable pyramid of quadrature-pair filters (Freeman and Adelson, 1991) and define the likelihood of an edge in terms of the empirical distribution over the amplitude and phase of these filter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29187618,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "993b1083455b5c4d631eaf44f230b061994e75c3",
            "isKey": true,
            "numCitedBy": 3379,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation. Steerable filters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. The authors show how to design and steer the filters and present examples of their use in the analysis of orientation and phase, angularly adaptive filtering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3-D steerable filters. >"
            },
            "slug": "The-Design-and-Use-of-Steerable-Filters-Freeman-Adelson",
            "title": {
                "fragments": [],
                "text": "The Design and Use of Steerable Filters"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present an efficient architecture to synthesize filters of arbitrary orientations from linear combinations of basis filters, allowing one to adaptively steer a filter to any orientation, and to determine analytically the filter output as a function of orientation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34751187"
                        ],
                        "name": "C. R. Wren",
                        "slug": "C.-R.-Wren",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Wren",
                            "middleNames": [
                                "Richard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. R. Wren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145271456"
                        ],
                        "name": "A. Azarbayejani",
                        "slug": "A.-Azarbayejani",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Azarbayejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Azarbayejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Let the probability distributions of foreground filter responses be peon( fe), p r on( fr ), p m on( fm)\nand the distributions over background filter responses be peoff( fe), p r off( fr ), p m off( fm), following the notation of Konishi et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 94
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 87
                            }
                        ],
                        "text": "In many cases, these cues are sequence-specific and capture local color distributions (Wren et al., 1997) or segment the person from the background using a known background model (Haritaoglu and Davis, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 169
                            }
                        ],
                        "text": "We seek a generic model of human appearance and motion that can account for the ways\n\u2217Present address: Department of Data and Information Fusion, Swedish Defence Research Agency (FOI), SE-172 90 Stockholm, Sweden."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 67
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs (Wren et al., 1997) or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9458767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb0efbce3bd812c6130ffbafa695e2e4d840ebbc",
            "isKey": true,
            "numCitedBy": 3549,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Pfinder is a real-time system for tracking and interpretation of people. It runs on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions. These representations are useful for applications such as wireless interfaces, video databases, and low-bandwidth coding, without cumbersome wires or attached sensors."
            },
            "slug": "Pfinder:-real-time-tracking-of-the-human-body-Wren-Azarbayejani",
            "title": {
                "fragments": [],
                "text": "Pfinder: real-time tracking of the human body"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Pfinder uses a multi-class statistical model of color and shape to obtain a 2-D representation of head and hands in a wide range of viewing conditions, useful for applications such as wireless interfaces, video databases, and low-bandwidth coding."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144998829"
                        ],
                        "name": "N. Gordon",
                        "slug": "N.-Gordon",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144775895"
                        ],
                        "name": "D. Salmond",
                        "slug": "D.-Salmond",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Salmond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salmond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109352679"
                        ],
                        "name": "Adrian F. M. Smith",
                        "slug": "Adrian-F.-M.-Smith",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Smith",
                            "middleNames": [
                                "F.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian F. M. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 32
                            }
                        ],
                        "text": "Using a particle ltering method [14, 17, 38], the posterior probability 1 See recent work by Nestares and Fleet [26] for a related approach that uses the phase of complex-valued lter responses to achieve similar contrast insensitivity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 35
                            }
                        ],
                        "text": "Using a particle filtering method (Gordon, 1993; Isard and Blake, 1998; Sidenbladh et al., 2000a), the posterior probability distribution over poses of the body model is represented using a discrete set of samples (where each sample corresponds to some pose of\nthe body)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12644877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5794f07b2ce5a04241198d42e81623380d2c7e2e",
            "isKey": false,
            "numCitedBy": 7793,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linear- ity or Gaussian noise: it may be applied to any state transition or measurement model. A simula- tion example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter."
            },
            "slug": "Novel-approach-to-nonlinear/non-Gaussian-Bayesian-Gordon-Salmond",
            "title": {
                "fragments": [],
                "text": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters, represented as a set of random samples, which are updated and propagated by the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720911"
                        ],
                        "name": "T. Kailath",
                        "slug": "T.-Kailath",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Kailath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kailath"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 28
                            }
                        ],
                        "text": "The Bhattacharyya distance (Kaliath, 1951) provides one measure of similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 108
                            }
                        ],
                        "text": "We exploit an approach based on the Bhattacharyya distance between foreground and background distributions (Kaliath, 1951; Konishi et al., 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "The Bhattacharyya distance [20] provides one measure of similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "We exploit an approach based on the Bhattacharyya distance between foreground and background distributions [20, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61287295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5b2ee1af1c0a867f564e44f3f79b8d2bdeca749",
            "isKey": true,
            "numCitedBy": 1797,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimization of the error probability to determine optimum signals is often difficult to carry out. Consequently, several suboptimum performance measures that are easier than the error probability to evaluate and manipulate have been studied. In this partly tutorial paper, we compare the properties of an often used measure, the divergence, with a new measure that we have called the Bhattacharyya distance. This new distance measure is often easier to evaluate than the divergence. In the problems we have worked, it gives results that are at least as good as, and are often better, than those given by the divergence."
            },
            "slug": "The-Divergence-and-Bhattacharyya-Distance-Measures-Kailath",
            "title": {
                "fragments": [],
                "text": "The Divergence and Bhattacharyya Distance Measures in Signal Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This partly tutorial paper compares the properties of an often used measure, the divergence, with a new measure that is often easier to evaluate, called the Bhattacharyya distance, which gives results that are at least as good and often better than those given by the divergence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2692987"
                        ],
                        "name": "Huaiyu Zhu",
                        "slug": "Huaiyu-Zhu",
                        "structuredName": {
                            "firstName": "Huaiyu",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaiyu Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116908168,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "87cbed883368d4a9efd42fdd91f47038f8d8fbe6",
            "isKey": false,
            "numCitedBy": 6005,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The information deviation between any two finite measures cannot be increased by any statistical operations (Markov morphisms). It is invarient if and only if the morphism is sufficient for these two measures"
            },
            "slug": "On-Information-and-Sufficiency-Zhu",
            "title": {
                "fragments": [],
                "text": "On Information and Sufficiency"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 5
                            }
                        ],
                        "text": "Distributions over edge and ridge response are only learned for upper and lower arms and legs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 313
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 132
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 179
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter (Deutscher et al., 2000; Gavrila, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 182
                            }
                        ],
                        "text": "Let the probability distributions of foreground filter responses be peon( fe), p r on( fr ), p m on( fm)\nand the distributions over background filter responses be peoff( fe), p r off( fr ), p m off( fm), following the notation of Konishi et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 453,
                                "start": 444
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs (Wren et al., 1997) or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 249
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 24
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "\u2026of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001;\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 150
                            }
                        ],
                        "text": "Building on recent work in modeling natural image statistics, our approach exploits generic filter responses that capture information about appearance and motion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Articulated motion capture by annealed particle filtering"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 62
                            }
                        ],
                        "text": "First derivatives of normalized Gaussian filters are steered (Freeman and Adelson, 1991) to the orientation of the limb and are applied at multiple scales."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "We use several di erent lter responses, and we use steerable lters [10] instead of isotropic ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "For our purposes we construct steerable image pyramids [10] using normalized Gaussian derivative lters ( rst and second order) [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 73
                            }
                        ],
                        "text": "We use several different filter responses, and we use steerable filters (Freeman and Adelson, 1991) instead of isotropic ones."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "First derivatives of normalized Gaussian lters are steered [10] to the orientation of the limb and are applied at multiple scales."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 56
                            }
                        ],
                        "text": "For our purposes we construct steerable image pyramids (Freeman and Adelson, 1991) using normalized Gaussian derivative filters (first and second order) (Lindeberg, 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 95
                            }
                        ],
                        "text": "In related work, Nestares and Fleet (2001) use a steerable pyramid of quadrature-pair filters (Freeman and Adelson, 1991) and define the likelihood of an edge in terms of the empirical distribution over the amplitude and phase of these filter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "In related work, Nestares and Fleet [26] use a steerable pyramid of quadrature-pair lters [10] and de ne the likelihood of an edge in terms of the empirical distribution over the amplitude and phase of these lter responses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "`The design and use of steerable lters"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "We can assume that the function relating limb width and scale is linear, since the scale can be viewed as a length measure in the image\u2014a linear function of the radius or length of the structures visible at that scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 128
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 262
                            }
                        ],
                        "text": "\u2026(Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Both of these areas have attracted a considerable amount of interest in the recent years and are reviewed briefly here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 158
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 111
                            }
                        ],
                        "text": "Following Lindeberg (1998), we define ridge response as the second derivative of the image perpendicular to the ridge (| f\u03b8\u03b8 |), minus the second derivative\nparallel to the ridge (| f(\u03b8\u2212 \u03c02 )(\u03b8\u2212 \u03c02 )|)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical models for images: Compression, restoration and optical flow"
            },
            "venue": {
                "fragments": [],
                "text": "Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 158
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in [38, 37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 78
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle ltering tracking framework [37, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans [7, 38, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 100
                            }
                        ],
                        "text": "the prior distribution; for examples of generic and event-speci c priors, the reader is referred to [28, 39, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 179
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 214
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only briefly describes the Bayesian tracking framework; details of the approach can be found in Sidenbladh and Black (2001) and Sidenbladh et al. (2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 25
                            }
                        ],
                        "text": "This idea is extended in Sidenbladh et al. (2000b) for learning low-dimensional linear models of the appearance of cylindrical limb surfaces using principal component analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 211
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in Sidenbladh et al. (2000a) and Sidenbladh and Black (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 151
                            }
                        ],
                        "text": "Here we do not address the prior distribution; for examples of generic and event-specific priors, the reader is referred to Ormoneit et al. (2001) and Sidenbladh et al. (2000a, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 82
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "This suggests that a tracking scheme that models the whole distribution, such as particle filtering (e.g., CONDENSATION (Isard and Blake, 1998; Sidenbladh et al., 2000a; Sidenbladh and Black, 2001)) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 109
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle filtering tracking framework (Sidenbladh and Black, 2001; Sidenbladh et al., 2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only brie y describes the Bayesian tracking framework; details of the approach can be found in [37, 38]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 32
                            }
                        ],
                        "text": "Using a particle ltering method [14, 17, 38], the posterior probability 1 See recent work by Nestares and Fleet [26] for a related approach that uses the phase of complex-valued lter responses to achieve similar contrast insensitivity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 72
                            }
                        ],
                        "text": "Using a particle filtering method (Gordon, 1993; Isard and Blake, 1998; Sidenbladh et al., 2000a), the posterior probability distribution over poses of the body model is represented using a discrete set of samples (where each sample corresponds to some pose of\nthe body)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 13
                            }
                        ],
                        "text": "Condensation [17, 38, 37]) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fleet: 2000a, `Stochastic tracking of 3D human gures using 2D image motion"
            },
            "venue": {
                "fragments": [],
                "text": "European Conference on Computer Vision, ECCV,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "We can assume that the function relating limb width and scale is linear, since the scale can be viewed as a length measure in the image\u2014a linear function of the radius or length of the structures visible at that scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 128
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 262
                            }
                        ],
                        "text": "\u2026(Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Both of these areas have attracted a considerable amount of interest in the recent years and are reviewed briefly here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 158
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 111
                            }
                        ],
                        "text": "Following Lindeberg (1998), we define ridge response as the second derivative of the image perpendicular to the ridge (| f\u03b8\u03b8 |), minus the second derivative\nparallel to the ridge (| f(\u03b8\u2212 \u03c02 )(\u03b8\u2212 \u03c02 )|)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical models for images: Compression, restoration and optical flow"
            },
            "venue": {
                "fragments": [],
                "text": "Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans [7, 38, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 213
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "To avoid this drift, brightness constancy is therefore often used in combination with edges [7, 46]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 55
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 93
                            }
                        ],
                        "text": "To avoid this drift, brightness constancy is therefore often used in combination with edges (DeCarlo and Metaxas, 1996; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "`The integration of optical ow and deformable models with applications to human face shape and motion estimation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "The statistics of grey-level values [23, 27, 34, 35, 49] as well as rst order [23, 21] and second order [13, 44, 45] gradients, and wavelet responses [41] have been studied."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 128
                            }
                        ],
                        "text": "Studies on the statistics of natural images (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) have shown that this is not the case\u2014 the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 74
                            }
                        ],
                        "text": "This builds upon recent work on learning the statistics of natural scenes [21, 23, 27, 34, 41, 49] and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 262
                            }
                        ],
                        "text": "\u2026(Lee et al., 2000; Olshausen and Field, 1996; Ruderman, 1994, 1997; Zhu and Mumford, 1997) as well as first order (Lee et al., 2001; Konishi et al., 1999) and second order (Geman and Jedynak, 1996; Sullivan et al., 1999, 2000) gradients, and wavelet responses (Simoncelli, 1997) have been studied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 158
                            }
                        ],
                        "text": "This builds upon\nrecent work on learning the statistics of natural scenes (Konishi et al., 1999; Lee et al., 2001; Olshausen and Field, 1996; Ruderman, 1994; Simoncelli, 1997; Zhu and Mumford, 1997) and extends it to the problem of people tracking."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 44
                            }
                        ],
                        "text": "Studies on the statistics of natural images [21, 23, 27, 34, 41, 49] have shown that this is not the case { the distributions are highly non-Gaussian."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "`Statistical models for images: Compression, restoration and optical ow"
            },
            "venue": {
                "fragments": [],
                "text": "Asilomar Conference on Signals, Systems and Computers"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "This idea is extended in [40] for learning low-dimensional linear models of the appearance of cylindrical limb surfaces using principal component analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 179
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 214
                            }
                        ],
                        "text": "This paper focuses on the the detailed analysis of the image statistics of people and only briefly describes the Bayesian tracking framework; details of the approach can be found in Sidenbladh and Black (2001) and Sidenbladh et al. (2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 25
                            }
                        ],
                        "text": "This idea is extended in Sidenbladh et al. (2000b) for learning low-dimensional linear models of the appearance of cylindrical limb surfaces using principal component analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 211
                            }
                        ],
                        "text": "\u2026(Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 158
                            }
                        ],
                        "text": "Experiments with a cluttered image sequence illustrate how the the learned likelihood is used for tracking human limbs in the Bayesian framework described in Sidenbladh et al. (2000a) and Sidenbladh and Black (2001)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 151
                            }
                        ],
                        "text": "Here we do not address the prior distribution; for examples of generic and event-specific priors, the reader is referred to Ormoneit et al. (2001) and Sidenbladh et al. (2000a, 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 82
                            }
                        ],
                        "text": "This assumption is used widely for tracking of humans (DeCarlo and Metaxas, 1996; Sidenbladh et al., 2000a; Wachter and Nagel, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "This suggests that a tracking scheme that models the whole distribution, such as particle filtering (e.g., CONDENSATION (Isard and Blake, 1998; Sidenbladh et al., 2000a; Sidenbladh and Black, 2001)) is more appropriate and may lead to more robust tracking."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 109
                            }
                        ],
                        "text": "The likelihood is now tested as part of a particle filtering tracking framework (Sidenbladh and Black, 2001; Sidenbladh et al., 2000a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 72
                            }
                        ],
                        "text": "Using a particle filtering method (Gordon, 1993; Isard and Blake, 1998; Sidenbladh et al., 2000a), the posterior probability distribution over poses of the body model is represented using a discrete set of samples (where each sample corresponds to some pose of\nthe body)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2000b, `A framework for modeling the appearance of 3D articulated gures"
            },
            "venue": {
                "fragments": [],
                "text": "In: International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 132
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 229
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 179
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter (Deutscher et al., 2000; Gavrila, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 24
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 178
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter [8, 11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "\u2026of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001;\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 86
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 23
                            }
                        ],
                        "text": "Background subtraction [8, 16, 32, 33, 47] gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 110
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people [4, 8, 17, 38, 43, 44, 45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "`Articulated motion capture by annealed particle ltering"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 5
                            }
                        ],
                        "text": "Distributions over edge and ridge response are only learned for upper and lower arms and legs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 313
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 132
                            }
                        ],
                        "text": "These probabilistic formulations have recently been incorporated into Bayesian frameworks for tracking people (Cham and Rehg, 1999; Deutscher et al., 2000; Isard and Blake, 1998; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Sullivan et al., 1999; Sullivan et al., 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 179
                            }
                        ],
                        "text": "Observing correlation between the boundaries of the human model and detected edges has proven to be successful in tracking, especially in indoor environments with little clutter (Deutscher et al., 2000; Gavrila, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 182
                            }
                        ],
                        "text": "Let the probability distributions of foreground filter responses be peon( fe), p r on( fr ), p m on( fm)\nand the distributions over background filter responses be peoff( fe), p r off( fr ), p m off( fm), following the notation of Konishi et al. (1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 453,
                                "start": 444
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs (Wren et al., 1997) or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 249
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 24
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 142
                            }
                        ],
                        "text": "\u2026of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Rehg and Kanade, 1995; Rohr, 1994, 1997; Sidenbladh et al., 2000a; Sminchisescu and Triggs, 2001;\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 150
                            }
                        ],
                        "text": "Building on recent work in modeling natural image statistics, our approach exploits generic filter responses that capture information about appearance and motion."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Articulated motion capture by annealed particle filtering"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conference on Computer Vision and Pattern Recognition, CVPR"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 170
                            }
                        ],
                        "text": "These models vary in complexity from assemblies of 2D color blobs [47] or areas with a certain color distribution [5], to layered 2D representations of articulated gures [4, 19], and, nally, to detailed 3D articulated structures [3, 8, 11, 15, 30, 32, 33, 38, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 163
                            }
                        ],
                        "text": "\u2026information (Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983; Isard and Blake, 1998; Rehg and Kanade, 1995; Rohr, 1994), optical flow (Bregler and Malik, 1998; Ju et al., 1996; Yacoob and Black, 1999) or both (DeCarlo and Metaxas, 1996; Sminchisescu and Triggs, 2001; Wachter and Nagel, 1999)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 119
                            }
                        ],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames [3, 19] or between an initial template and the current frame [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "\u2026or areas with a certain color distribution (Comaniciu et al., 2000), to layered 2D representations of articulated figures (Cham and Rehg, 1999; Ju et al., 1996), and, finally, to detailed 3D articulated structures (Bregler and Malik, 1998; Deutscher et al., 2000; Gavrila, 1996; Hogg, 1983;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 145
                            }
                        ],
                        "text": "Approaches that use image motion as a cue typically assume brightness constancy holds between pairs of adjacent frames (Bregler and Malik, 1998; Ju et al., 1996) or between an initial template and the current frame (Cham and Rehg, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 122
                            }
                        ],
                        "text": "Tracking approaches for generic scenes have typically used extracted edge information [8, 11, 15, 17, 30, 32], optical ow [3, 19, 48] or both [7, 43, 46]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 108068634,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "dc132c04da4d6817a775efdac86372ae77f12b0f",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cardboard-people:-A-parametrized-model-of-motion-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: A parametrized model of articulated motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 56
                            }
                        ],
                        "text": "Recent work on tracking and learning appearance models (Jepson et al., 2001) may provide a principled way of adapting models of limb appearance over time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 14
                            }
                        ],
                        "text": "The finest level, \u03c3 = 0 is the original image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27003726,
            "fieldsOfStudy": [],
            "id": "4411f262853bf7f1eb8e2efe03eb0402f5e9ad2c",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust online appearance models for visual tracking"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 195
                            }
                        ],
                        "text": "In many cases, these cues are sequence-specific and capture local color distributions (Wren et al., 1997) or segment the person from the background using a known background model (Haritaoglu and Davis, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Background subtraction (Deutscher et al., 2000; Haritaoglu and Davis, 2000; Rohr, 1994, 1997; Wren et al., 1997) gives an estimate of where the human is in the image, and the outline of the human, but does not provide information about the motion of the foreground."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Real - time surveillance of people and their activities '"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "Alternatively, the Kullback-Leibler divergence [22] between pon and po is given by \u00c6KL(pon; po ) = Z pon(y) log pon(y) po (y) dy : (4)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "`On information and su\u00c6ciency"
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematical Statistics"
            },
            "year": 1951
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 59,
            "methodology": 35,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 62,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-the-Statistics-of-People-in-Images-and-Kjellstr\u00f6m-Black/c368eb34697350e2d9921a5354ddda76813408c3?sort=total-citations"
}