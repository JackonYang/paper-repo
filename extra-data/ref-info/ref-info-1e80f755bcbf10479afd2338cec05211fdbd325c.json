{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 122
                            }
                        ],
                        "text": "DBNs have been successfully used to learn high-level structure in a wide variety of domains, including handwritten digits (Hinton et al., 2006) and human motion capture data (Taylor et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 46
                            }
                        ],
                        "text": "In \nparticular, the deep belief network (DBN) (Hinton et al., 2006) is a multilayer generative model where \neach layer encodes statistical dependencies among the units in the layer below it; it is trained to (approxi\u00admately) \nmaximize the likelihood of its training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 61
                            }
                        ],
                        "text": "There have been several approaches to learning deep networks (LeCun et al., 1989; Bengio et al., 2006; Ranzato et al., 2006; Hinton et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 45
                            }
                        ],
                        "text": "In particular, the deep belief network (DBN) (Hinton et al., 2006) is a multilayer generative model where each layer encodes statistical dependencies among the units in the layer below it; it is trained to (approximately) maximize the likelihood of its training data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Hinton et al. (2006) proposed an e.cient algorithm for training deep belief networks, \nby greedily training each layer (from low\u00adest to highest) as an RBM using the previous layer s activations \nas inputs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 125
                            }
                        ],
                        "text": "There have been several approaches to learning \ndeep networks (LeCun et al., 1989; Bengio et al., 2006; Ranzato et al., 2006; Hinton et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": "This contrasts with Hinton et al. (2006), which used undirected connections between the top two lay\u00aders, \nand top-down directed connections for the layers below."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Hinton et al. (2006) proposed approximat\u00ading \nthe posterior distribution using a single bottom-up pass."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 123
                            }
                        ],
                        "text": "DBNs have been successfully used to learn high-level structure \nin a wide variety of domains, including hand\u00adwritten digits (Hinton et al., 2006) and human motion capture \ndata (Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2309950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "isKey": true,
            "numCitedBy": 13407,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind."
            },
            "slug": "A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero",
            "title": {
                "fragments": [],
                "text": "A Fast Learning Algorithm for Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A fast, greedy algorithm is derived that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779306"
                        ],
                        "name": "Chaitanya Ekanadham",
                        "slug": "Chaitanya-Ekanadham",
                        "structuredName": {
                            "firstName": "Chaitanya",
                            "lastName": "Ekanadham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chaitanya Ekanadham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12589862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "202cbbf671743aefd380d2f23987bd46b9caaf97",
            "isKey": false,
            "numCitedBy": 1028,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivated in part by the hierarchical organization of the cortex, a number of algorithms have recently been proposed that try to learn hierarchical, or \"deep,\" structure from unlabeled data. While several authors have formally or informally compared their algorithms to computations performed in visual area V1 (and the cochlea), little attempt has been made thus far to evaluate these algorithms in terms of their fidelity for mimicking computations at deeper levels in the cortical hierarchy. This paper presents an unsupervised learning model that faithfully mimics certain properties of visual area V2. Specifically, we develop a sparse variant of the deep belief networks of Hinton et al. (2006). We learn two layers of nodes in the network, and demonstrate that the first layer, similar to prior work on sparse coding and ICA, results in localized, oriented, edge filters, similar to the Gabor functions known to model V1 cell receptive fields. Further, the second layer in our model encodes correlations of the first layer responses in the data. Specifically, it picks up both colinear (\"contour\") features as well as corners and junctions. More interestingly, in a quantitative comparison, the encoding of these more complex \"corner\" features matches well with the results from the Ito & Komatsu's study of biological V2 responses. This suggests that our sparse variant of deep belief networks holds promise for modeling more higher-order features."
            },
            "slug": "Sparse-deep-belief-net-model-for-visual-area-V2-Lee-Ekanadham",
            "title": {
                "fragments": [],
                "text": "Sparse deep belief net model for visual area V2"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An unsupervised learning model is presented that faithfully mimics certain properties of visual area V2 and the encoding of these more complex \"corner\" features matches well with the results from the Ito & Komatsu's study of biological V2 responses, suggesting that this sparse variant of deep belief networks holds promise for modeling more higher-order features."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070938295"
                        ],
                        "name": "Anand Madhavan",
                        "slug": "Anand-Madhavan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 20
                            }
                        ],
                        "text": "(However, see also (Raina et al., 2009).)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "(However, see also ( Raina et al., 2009 ).) In this section, we introduce our model, the convolutional DBN, whose weights are shared among all locations in an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 392458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
            "isKey": false,
            "numCitedBy": 640,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton & Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples.\n In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods."
            },
            "slug": "Large-scale-deep-unsupervised-learning-using-Raina-Madhavan",
            "title": {
                "fragments": [],
                "text": "Large-scale deep unsupervised learning using graphics processors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32384143"
                        ],
                        "name": "D. Popovici",
                        "slug": "D.-Popovici",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Popovici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Popovici"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14201947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "isKey": false,
            "numCitedBy": 3427,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."
            },
            "slug": "Greedy-Layer-Wise-Training-of-Deep-Networks-Bengio-Lamblin",
            "title": {
                "fragments": [],
                "text": "Greedy Layer-Wise Training of Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 53
                            }
                        ],
                        "text": "Details: Given an image from the Caltech-101 dataset (Fei-Fei et al., 2004), we scaled the image so that its longer side was 150 pixels, and computed the activations of the first and second (pooling) layers of our CDBN."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 145
                            }
                        ],
                        "text": "\u2026et \nal., 2006; Berg et al., 2005; Zhang et al., 2006).7 Recall that the CDBN was trained en\u00ad 6Details: Given \nan image from the Caltech-101 dataset (Fei-Fei et al., 2004), we scaled the image so that its longer \nside was 150 pixels, and computed the activations of the .rst and second\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2156851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aedb8df8f953429ec5a6df99fda5c5d71dbee4ff",
            "isKey": false,
            "numCitedBy": 2318,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-Generative-Visual-Models-from-Few-Training-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories"
            },
            "venue": {
                "fragments": [],
                "text": "2004 Conference on Computer Vision and Pattern Recognition Workshop"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 49
                            }
                        ],
                        "text": "Our result is comparable to the state-of-the-art (Ranzato et al., 2007; Weston et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026for the Caltech-101 data  Training Size 15 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0% 56.0% 64.6%\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "(However, see also (Raina et al., 2009).)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "We used a similar procedure to evaluate our two-layer CDBN, described in Section 4.1, \non the Caltech-101 object classi.cation task.6 The results are shown in Table 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Speci.cally, we trained a CDBN with two hidden \nlayers from the Ky\u00adoto natural image dataset.3 The .rst layer consisted of 24 groups (or bases )4 of \n10x10 pixel .lters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 50
                            }
                        ],
                        "text": "Our result is comparable to the state-of-the-art (Ran\u00adzato et al., \n2007; Weston et al., 2008).8 4.4."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Building on the .rst \nlayer representation learned from natural images, we trained two additional CDBN layers using unlabeled \nimages from single Caltech-101 categories.9 As shown in Figure 3, the second layer learned features corresponding \nto object parts, even though the algorithm was not given any labels speci\u00adfying the locations of either \nthe objects or their parts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Hence, the strong performance of these features implies that our CDBN learned a highly general \nrepresentation of images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Higher layers in the CDBN \nlearn features which are not only higher level, but also more speci.c to particu\u00adlar object categories."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 90
                            }
                        ],
                        "text": "Test error for MNIST dataset Labeled training samples 1,000 2,000 \n3,000 5,000 60,000 CDBN Ranzato et al. (2007) Hinton and Salakhutdinov (2006) Weston et al. (2008) 2.62\u00b10.12% \n3.21% -2.73% 2.13\u00b10.10% 2.53% -- 1.91\u00b10.09% --1.83% 1.59\u00b10.11% 1.52% -- 0.82% 0.64% 1.20% 1.50%  Figure \n3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "More speci.cally, \nwe consider three CDBNs trained on faces, motorbikes, and cars, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "For each CDBN, we test \nthe informativeness of individual features from each layer for distinguishing among these three cate\u00adgories."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Classi.cation accuracy for the Caltech-101 data  Training Size 15 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0% 56.0% 64.6% 66.2\u00b10.5% tirely from natural scenes, which are completely un\u00adrelated to the classi.cation \ntask."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 226
                            }
                        ],
                        "text": "Our result is competitive with state-of-the-art results \nusing highly-specialized single features, such as SIFT, geometric blur, and shape\u00adcontext (Lazebnik et \nal., 2006; Berg et al., 2005; Zhang et al., 2006).7 Recall that the CDBN was trained en\u00ad 6Details: Given \nan image from the Caltech-101 dataset (Fei-Fei et al., 2004), we scaled the image so that its longer \nside was 150 pixels, and computed the activations of the .rst and second (pooling) layers of our CDBN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "Convolutional deep belief network Finally, we are ready to de.ne the convolutional deep belief network \n(CDBN), our hierarchical generative model for full-sized images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "We further tested if the CDBN can learn hierarchi\u00adcal object-part representations when trained on im\u00adages \nfrom several object categories (rather than just one)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 44
                            }
                        ],
                        "text": "Self-taught learning for object \nrecognition Raina et al. (2007) showed that large unlabeled data can help in supervised learning tasks, \neven when the 3http://www.cnbc.cmu.edu/cplab/data_kyoto.html 4We will call one hidden group s weights \na basis."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11398758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccd52aff02b0f902f4ce7247c4fee7273014c41c",
            "isKey": true,
            "numCitedBy": 1089,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64% error on MNIST, and 54% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "slug": "Unsupervised-Learning-of-Invariant-Feature-with-to-Ranzato-Huang",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions that alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060013"
                        ],
                        "name": "Christopher S. Poultney",
                        "slug": "Christopher-S.-Poultney",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Poultney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher S. Poultney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 61
                            }
                        ],
                        "text": "There have been several approaches to learning deep networks (LeCun et al., 1989; Bengio et al., 2006; Ranzato et al., 2006; Hinton et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 416,
                                "start": 413
                            }
                        ],
                        "text": "Speci.cally, we trained a CDBN with two hidden \nlayers from the Ky\u00adoto natural image dataset.3 The .rst layer consisted of 24 groups (or bases )4 of \n10x10 pixel .lters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 103
                            }
                        ],
                        "text": "There have been several approaches to learning \ndeep networks (LeCun et al., 1989; Bengio et al., 2006; Ranzato et al., 2006; Hinton et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 143
                            }
                        ],
                        "text": "As shown in Figure 2 (top), the learned first layer bases are oriented, localized edge filters; this result is consistent with much prior work (Olshausen & Field, 1996; Bell & Sejnowski, 1997; Ranzato et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 281,
                                "start": 261
                            }
                        ],
                        "text": "\u2026while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "References Bell, A. J., &#38; \nSejnowski, T. J. (1997)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 819006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "932c2a02d462abd75af018125413b1ceaa1ee3f4",
            "isKey": true,
            "numCitedBy": 1182,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces \"stroke detectors\" when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps."
            },
            "slug": "Efficient-Learning-of-Sparse-Representations-with-Ranzato-Poultney",
            "title": {
                "fragments": [],
                "text": "Efficient Learning of Sparse Representations with an Energy-Based Model"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A novel unsupervised method for learning sparse, overcomplete features using a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 212
                            }
                        ],
                        "text": "\u2026while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "One common solution is to force the representation to be \\sparse,\" in that only a tiny fraction of the units should be active in relation to a given stimulus ( Olshausen & Field, 1996;  Lee et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 157
                            }
                        ],
                        "text": "One common solution is to force the representation to be sparse, in that only a tiny frac\u00adtion \nof the units should be active in relation to a given stimulus (Olshausen &#38; Field, 1996; Lee et al., \n2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Specically, we trained a CDBN with two hidden layers from the Kyoto natural image dataset.3 The rst layer consisted of 24 groups (or \\bases\")4 of 10x10 pixel lters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown in Figure 2 (top), the learned rst layer bases are oriented, localized edge lters; this result is consistent with much prior work ( Olshausen & Field, 1996;  Bell & Sejnowski, 1997; ..."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": true,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143836295"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 21
                            }
                        ],
                        "text": "In another approach, \nYu et al. (2009) used kernel regularization using a (previously pub\u00adlished) state-of-the-art kernel matrix \nto improve the per\u00adTable 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In another approach,  Yu et al. (2009)  used kernel regularization using a (previously published) state-of-the-art kernel matrix to improve the per-Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5881297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16802aa97dce7e60fd32d85b31f69e0d18e14726",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we aim to train deep neural networks for rapid visual recognition. The task is highly challenging, largely due to the lack of a meaningful regular-izer on the functions realized by the networks. We propose a novel regularization method that takes advantage of kernel methods, where an oracle kernel function represents prior knowledge about the recognition task of interest. We derive an efficient algorithm using stochastic gradient descent, and demonstrate encouraging results on a wide range of recognition tasks, in terms of both accuracy and speed."
            },
            "slug": "Deep-Learning-with-Kernel-Regularization-for-Visual-Yu-Xu",
            "title": {
                "fragments": [],
                "text": "Deep Learning with Kernel Regularization for Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel regularization method is proposed that takes advantage of kernel methods, where an oracle kernel function represents prior knowledge about the recognition task of interest."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110711666"
                        ],
                        "name": "T. Lee",
                        "slug": "T.-Lee",
                        "structuredName": {
                            "firstName": "Tai",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Lee and Mumford (2003)  proposed that the human visual cortex can conceptually be modeled as performing \\hierarchical Bayesian inference.\" For example, if you observe a face image with its left half in dark illumina-Figure 6. Hierarchical probabilistic inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 37
                            }
                        ],
                        "text": "Hierarchical probabilistic inference Lee and Mumford (2003) proposed that the human vi\u00adsual cortex \ncan conceptually be modeled as performing hierarchical Bayesian inference."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4284337,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science",
                "Psychology"
            ],
            "id": "5042cb5efad30f443adef472b8748e1b7bb0452f",
            "isKey": false,
            "numCitedBy": 1343,
            "numCiting": 100,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas."
            },
            "slug": "Hierarchical-Bayesian-inference-in-the-visual-Lee-Mumford",
            "title": {
                "fragments": [],
                "text": "Hierarchical Bayesian inference in the visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system, and suggests that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33597354"
                        ],
                        "name": "H. Kwong",
                        "slug": "H.-Kwong",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "Kwong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kwong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 47083315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82049bef3ed630c3ab972d20ffcb70d78e338266",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse coding is an unsupervised learning algorithm that learns a succinct high-level representation of the inputs given only unlabeled data; it represents each input as a sparse linear combination of a set of basis functions. Originally applied to modeling the human visual cortex, sparse coding has also been shown to be useful for self-taught learning, in which the goal is to solve a supervised classification task given access to additional unlabeled data drawn from different classes than that in the supervised learning problem. Shift-invariant sparse coding (SISC) is an extension of sparse coding which reconstructs a (usually time-series) input using all of the basis functions in all possible shifts. In this paper, we present an efficient algorithm for learning SISC bases. Our method is based on iteratively solving two large convex optimization problems: The first, which computes the linear coefficients, is an L1-regularized linear least squares problem with potentially hundreds of thousands of variables. Existing methods typically use a heuristic to select a small subset of the variables to optimize, but we present a way to efficiently compute the exact solution. The second, which solves for bases, is a constrained linear least squares problem. By optimizing over complex-valued variables in the Fourier domain, we reduce the coupling between the different variables, allowing the problem to be solved efficiently. We show that SISC's learned high-level representations of speech and music provide useful features for classification tasks within those domains. When applied to classification, under certain conditions the learned features outperform state of the art spectral and cepstral features."
            },
            "slug": "Shift-Invariance-Sparse-Coding-for-Audio-Grosse-Raina",
            "title": {
                "fragments": [],
                "text": "Shift-Invariance Sparse Coding for Audio Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents an efficient algorithm for learning SISC bases, and shows that SISC's learned high-level representations of speech and music provide useful features for classification tasks within those domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "\u2026data  Training Size 15 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0% 56.0% 64.6% 66.2\u00b10.5% tirely from\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Training Size 15 30 CDBN (rst layer) 53.21.2% 60.51.1% CDBN (rst+second layers) 57.71.5% 65.40.5% Raina et al. (2007) 46.6% -Ranzato et al. (2007) - 54.0%  Mutch and Lowe (2006)  51.0% 56.0% Lazebnik et al. (2006) 54.0% 64.6% Zhang et al. (2006) 59.00.56% 66.20.5%"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 444,
                                "start": 430
                            }
                        ],
                        "text": "Speci.cally, we trained a CDBN with two hidden \nlayers from the Ky\u00adoto natural image dataset.3 The .rst layer consisted of 24 groups (or bases )4 of \n10x10 pixel .lters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 50
                            }
                        ],
                        "text": "Our result is comparable to the state-of-the-art (Ran\u00adzato et al., \n2007; Weston et al., 2008).8 4.4."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 103
                            }
                        ],
                        "text": "There have been several approaches to learning \ndeep networks (LeCun et al., 1989; Bengio et al., 2006; Ranzato et al., 2006; Hinton et al., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 90
                            }
                        ],
                        "text": "Test error for MNIST dataset Labeled training samples 1,000 2,000 \n3,000 5,000 60,000 CDBN Ranzato et al. (2007) Hinton and Salakhutdinov (2006) Weston et al. (2008) 2.62\u00b10.12% \n3.21% -2.73% 2.13\u00b10.10% 2.53% -- 1.91\u00b10.09% --1.83% 1.59\u00b10.11% 1.52% -- 0.82% 0.64% 1.20% 1.50%  Figure \n3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 168
                            }
                        ],
                        "text": "Classi.cation accuracy for the Caltech-101 data  Training Size 15 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0% 56.0% 64.6% 66.2\u00b10.5% tirely from natural scenes, which are completely un\u00adrelated to the classi.cation \ntask."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1427294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e65fcb0e04174577f211d702d3f837e3624c5b",
            "isKey": true,
            "numCitedBy": 548,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply a biologically inspired model of visual object recognition to the multiclass object categorization problem. Our model modifies that of Serre, Wolf, and Poggio. As in that work, we first apply Gabor filters at all positions and scales; feature complexity and position/scale invariance are then built up by alternating template matching and max pooling operations. We refine the approach in several biologically plausible ways, using simple versions of sparsification and lateral inhibition. We demonstrate the value of retaining some position and scale information above the intermediate feature level. Using feature selection we arrive at a model that performs better with fewer features. Our final model is tested on the Caltech 101 object categories and the UIUC car localization task, in both cases achieving state-of-the-art performance. The results strengthen the case for using this class of model in computer vision."
            },
            "slug": "Multiclass-Object-Recognition-with-Sparse,-Features-Mutch-Lowe",
            "title": {
                "fragments": [],
                "text": "Multiclass Object Recognition with Sparse, Localized Features"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A biologically inspired model of visual object recognition to the multiclass object categorization problem, modifies that of Serre, Wolf, and Poggio, and demonstrates the value of retaining some position and scale information above the intermediate feature level."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Olshausen, B. A., &#38; Field, D. J. (1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 396,
                                "start": 393
                            }
                        ],
                        "text": "Speci.cally, we trained a CDBN with two hidden \nlayers from the Ky\u00adoto natural image dataset.3 The .rst layer consisted of 24 groups (or bases )4 of \n10x10 pixel .lters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 237
                            }
                        ],
                        "text": "\u2026while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "One common solution is to force the representation to be sparse, in that only a tiny frac\u00adtion \nof the units should be active in relation to a given stimulus (Olshausen &#38; Field, 1996; Lee et al., \n2008)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Specifically, we trained a CDBN with two hidden layers from the Kyoto natural image dataset.3 The first layer consisted of 24 groups (or \u201cbases\u201d)4 of 10x10 pixel filters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown in Figure 2 (top), the learned first layer bases are oriented, localized edge filters; this result is consistent with much prior work (Olshausen & Field, 1996;  Bell & Sejnowski, 1997;  ..."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 6219133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca1d23be869380ac9e900578c601c2d1febcc0c9",
            "isKey": true,
            "numCitedBy": 2373,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-\u201cindependent-components\u201d-of-natural-scenes-are-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "The \u201cindependent components\u201d of natural scenes are edge filters"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799147"
                        ],
                        "name": "F. Ratle",
                        "slug": "F.-Ratle",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Ratle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ratle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232655"
                        ],
                        "name": "H. Mobahi",
                        "slug": "H.-Mobahi",
                        "structuredName": {
                            "firstName": "Hossein",
                            "lastName": "Mobahi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mobahi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 144
                            }
                        ],
                        "text": "Test error for MNIST dataset Labeled training samples 1,000 2,000 \n3,000 5,000 60,000 CDBN Ranzato et al. (2007) Hinton and Salakhutdinov (2006) Weston et al. (2008) 2.62\u00b10.12% \n3.21% -2.73% 2.13\u00b10.10% 2.53% -- 1.91\u00b10.09% --1.83% 1.59\u00b10.11% 1.52% -- 0.82% 0.64% 1.20% 1.50%  Figure \n3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 72
                            }
                        ],
                        "text": "Our result is comparable to the state-of-the-art (Ran\u00adzato et al., \n2007; Weston et al., 2008).8 4.4."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 740114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee368e60d0b826e78f965aad8d6c7d406127104",
            "isKey": true,
            "numCitedBy": 607,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques."
            },
            "slug": "Deep-learning-via-semi-supervised-embedding-Weston-Ratle",
            "title": {
                "fragments": [],
                "text": "Deep learning via semi-supervised embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is shown how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2078284037"
                        ],
                        "name": "Alexis Battle",
                        "slug": "Alexis-Battle",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Battle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexis Battle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409971380"
                        ],
                        "name": "Ben Packer",
                        "slug": "Ben-Packer",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Packer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Packer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 44
                            }
                        ],
                        "text": "Self-taught learning for object \nrecognition Raina et al. (2007) showed that large unlabeled data can help in supervised learning tasks, \neven when the 3http://www.cnbc.cmu.edu/cplab/data_kyoto.html 4We will call one hidden group s weights \na basis."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "82% Ranzato et al. (2007) 3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 148
                            }
                        ],
                        "text": "Classi.cation accuracy for the Caltech-101 data  Training Size 15 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0%\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6692382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3852f0113fcf8a3913c55ae92393ae6ccde347e",
            "isKey": false,
            "numCitedBy": 1610,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new machine learning framework called \"self-taught learning\" for using unlabeled data in supervised classification tasks. We do not assume that the unlabeled data follows the same class labels or generative distribution as the labeled data. Thus, we would like to use a large number of unlabeled images (or audio samples, or text documents) randomly downloaded from the Internet to improve performance on a given image (or audio, or text) classification task. Such unlabeled data is significantly easier to obtain than in typical semi-supervised or transfer learning settings, making self-taught learning widely applicable to many practical learning problems. We describe an approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data. These features form a succinct input representation and significantly improve classification performance. When using an SVM for classification, we further show how a Fisher kernel can be learned for this representation."
            },
            "slug": "Self-taught-learning:-transfer-learning-from-data-Raina-Battle",
            "title": {
                "fragments": [],
                "text": "Self-taught learning: transfer learning from unlabeled data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An approach to self-taught learning that uses sparse coding to construct higher-level features using the unlabeled data to form a succinct input representation and significantly improve classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 14
                            }
                        ],
                        "text": "8We note that Hinton and Salakhutdinov (2006) s method is non-convolutional."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 112
                            }
                        ],
                        "text": "Test error for MNIST dataset Labeled training samples 1,000 2,000 \n3,000 5,000 60,000 CDBN Ranzato et al. (2007) Hinton and Salakhutdinov (2006) Weston et al. (2008) 2.62\u00b10.12% \n3.21% -2.73% 2.13\u00b10.10% 2.53% -- 1.91\u00b10.09% --1.83% 1.59\u00b10.11% 1.52% -- 0.82% 0.64% 1.20% 1.50%  Figure \n3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "8 We note that  Hinton and Salakhutdinov (2006) \u2019s method is non-convolutional."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": true,
            "numCitedBy": 14638,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Mutch, J., &#38; Lowe, D. G. (2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u202615 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0% 56.0% 64.6% 66.2\u00b10.5% tirely from natural scenes, which are\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 190
                            }
                        ],
                        "text": "Classi.cation accuracy for the Caltech-101 data  Training Size 15 30 CDBN \n(.rst layer) CDBN (.rst+second layers) 53.2\u00b11.2% 57.7\u00b11.5% 60.5\u00b11.1% 65.4\u00b10.5% Raina et al. (2007) Ranzato \net al. (2007) Mutch and Lowe (2006) Lazebnik et al. (2006) Zhang et al. (2006) 46.6% -51.0% 54.0% 59.0\u00b10.56% \n-54.0% 56.0% 64.6% 66.2\u00b10.5% tirely from natural scenes, which are completely un\u00adrelated to the classi.cation \ntask."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "Lower layers detect simple features and feed into \nhigher layers, which in turn detect more complex features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "Our result is competitive with state-of-the-art results \nusing highly-specialized single features, such as SIFT, geometric blur, and shape\u00adcontext (Lazebnik et \nal., 2006; Berg et al., 2005; Zhang et al., 2006).7 Recall that the CDBN was trained en\u00ad 6Details: Given \nan image from the Caltech-101\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 145
                            }
                        ],
                        "text": "Our result is competitive with state-of-the-art results using highly-specialized single features, such as SIFT, geometric blur, and shapecontext (Lazebnik et al., 2006; Berg et al., 2005; Zhang et al., 2006)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": true,
            "numCitedBy": 8328,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145140331"
                        ],
                        "name": "Hao Zhang",
                        "slug": "Hao-Zhang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 274094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ceb0e1a86dc35e21ce5f0524c8476f15e1b08988",
            "isKey": false,
            "numCitedBy": 1278,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories. This approach is quite flexible, and permits recognition based on color, texture, and particularly shape, in a homogeneous framework. While nearest neighbor classifiers are natural in this setting, they suffer from the problem of high variance (in bias-variance decomposition) in the case of limited sampling. Alternatively, one could use support vector machines but they involve time-consuming optimization and computation of pairwise distances. We propose a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice. The basic idea is to find close neighbors to a query sample and train a local support vector machine that preserves the distance function on the collection of neighbors. Our method can be applied to large, multiclass data sets for which it outperforms nearest neighbor and support vector machines, and remains efficient when the problem becomes intractable for support vector machines. A wide variety of distance functions can be used and our experiments show state-of-the-art performance on a number of benchmark data sets for shape and texture classification (MNIST, USPS, CUReT) and object recognition (Caltech- 101). On Caltech-101 we achieved a correct classification rate of 59.05%(\u00b10.56%) at 15 training images per class, and 66.23%(\u00b10.48%) at 30 training images."
            },
            "slug": "SVM-KNN:-Discriminative-Nearest-Neighbor-for-Visual-Zhang-Berg",
            "title": {
                "fragments": [],
                "text": "SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work considers visual category recognition in the framework of measuring similarities, or equivalently perceptual distances, to prototype examples of categories and proposes a hybrid of these two methods which deals naturally with the multiclass setting, has reasonable computational complexity both in training and at run time, and yields excellent results in practice."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 70
                            }
                        ],
                        "text": "Instead, one typically uses the contrastive divergence approximation (Hinton, 2002), \nwhich has been shown to work well in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 69
                            }
                        ],
                        "text": "Instead, one typically uses the contrastive divergence approximation (Hinton, 2002), which has been shown to work well in practice."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4567,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 175
                            }
                        ],
                        "text": "DBNs have been successfully used to learn high-level structure \nin a wide variety of domains, including hand\u00adwritten digits (Hinton et al., 2006) and human motion capture \ndata (Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 38
                            }
                        ],
                        "text": ", 2006) and human motion capture data (Taylor et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14962437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "497a80b2813cffb17f46af50e621a71505094528",
            "isKey": false,
            "numCitedBy": 511,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture."
            },
            "slug": "Modeling-Human-Motion-Using-Binary-Latent-Variables-Taylor-Hinton",
            "title": {
                "fragments": [],
                "text": "Modeling Human Motion Using Binary Latent Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \"visible\" variables that represent joint angles that makes on-line inference efficient and allows for a simple approximate learning procedure."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125256517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "576104ba976841628c67d2d794c9a64ba876eb87",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \u201cvisible\u201d variables that represent joint angles. The latent and visible variables at each time step receive directed connections from the visible variables at the last few time-steps. Such an architecture makes on-line inference efficient and allows us to use a simple approximate learning procedure. After training, the model finds a single set of parameters that simultaneously capture several different kinds of motion. We demonstrate the power of our approach by synthesizing various motion sequences and by performing on-line filling in of data lost during motion capture."
            },
            "slug": "Modeling-Human-Motion-Using-Binary-Latent-Variables-Sch\u00f6lkopf-Platt",
            "title": {
                "fragments": [],
                "text": "Modeling Human Motion Using Binary Latent Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A non-linear generative model for human motion data that uses an undirected model with binary latent variables and real-valued \u201cvisible\u201d variables that represent joint angles that makes on-line inference efficient and allows for a simple approximate learning procedure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789036"
                        ],
                        "name": "Debajyoti Ray",
                        "slug": "Debajyoti-Ray",
                        "structuredName": {
                            "firstName": "Debajyoti",
                            "lastName": "Ray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Debajyoti Ray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "7  Varma and Ray (2007)  reported better performance than ours (87.82% for 15 training images/class), but they combined many state-of-the-art features (or kernels) to improve the performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13942014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3edd9e15976ca3aa2d627d41384e1f0908a91632",
            "isKey": true,
            "numCitedBy": 582,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the problem of learning optimal descriptors for a given classification task. Many hand-crafted descriptors have been proposed in the literature for measuring visual similarity. Looking past initial differences, what really distinguishes one descriptor from another is the tradeoff that it achieves between discriminative power and invariance. Since this trade-off must vary from task to task, no single descriptor can be optimal in all situations. Our focus, in this paper, is on learning the optimal tradeoff for classification given a particular training set and prior constraints. The problem is posed in the kernel learning framework. We learn the optimal, domain-specific kernel as a combination of base kernels corresponding to base features which achieve different levels of trade-off (such as no invariance, rotation invariance, scale invariance, affine invariance, etc.) This leads to a convex optimisation problem with a unique global optimum which can be solved for efficiently. The method is shown to achieve state-of-the-art performance on the UIUC textures, Oxford flowers and Cal- tech 101 datasets."
            },
            "slug": "Learning-The-Discriminative-Power-Invariance-Varma-Ray",
            "title": {
                "fragments": [],
                "text": "Learning The Discriminative Power-Invariance Trade-Off"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This paper investigates the problem of learning optimal descriptors for a given classification task using the kernel learning framework and learns the optimal, domain-specific kernel as a combination of base kernels corresponding to base features which achieve different levels of trade-off."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 956,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108813944"
                        ],
                        "name": "Minami Ito",
                        "slug": "Minami-Ito",
                        "structuredName": {
                            "firstName": "Minami",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minami Ito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40579588"
                        ],
                        "name": "H. Komatsu",
                        "slug": "H.-Komatsu",
                        "structuredName": {
                            "firstName": "Hidehiko",
                            "lastName": "Komatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Komatsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This result is qualitatively consistent with previous work ( Ito & Komatsu, 2004;  Lee et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "This result is qual\u00aditatively consistent \nwith previous work (Ito &#38; Ko\u00admatsu, 2004; Lee et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12116094,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "940e19622b547b5e47bf8bd341e22fbd039b5ede",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Angles and junctions embedded within contours are important features to represent the shape of objects. To study the neuronal basis to extract these features, we conducted extracellular recordings while two macaque monkeys performed a fixation task. Angle stimuli were the combination of two straight half-lines larger than the size of the classical receptive fields (CRFs). Each line was drawn from the center to outside the CRFs in 1 of 12 directions, so that the stimuli passed through the CRFs and formed angles at the center of the CRFs. Of 114 neurons recorded from the superficial layer of area V2, 91 neurons showed selective responses to these angle stimuli. Of these, 41 neurons (36.0%) showed selective responses to wide angles between 60\u00b0 and 150\u00b0 that were distinct from responses to straight lines or sharp angles (30\u00b0). Responses were highly selective to a particular angle in approximately one-fourth of neurons. When we tested the selectivity of the same neurons to individual half-lines, the preferred direction was more or less consistent with one or two components of the optimal angle stimuli. These results suggest that the selectivity of the neurons depends on both the combination of two components and the responses to individual components. Angle-selective V2 neurons are unlikely to be specific angle detectors, because the magnitude of their responses to the optimal angle was indistinguishable from that to the optimal half-lines. We suggest that the extraction of information of angles embedded within contour stimuli may start in area V2."
            },
            "slug": "Representation-of-Angles-Embedded-within-Contour-in-Ito-Komatsu",
            "title": {
                "fragments": [],
                "text": "Representation of Angles Embedded within Contour Stimuli in Area V2 of Macaque Monkeys"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is suggested that the extraction of information of angles embedded within contour stimuli may start in area V2, and Angle-selective V2 neurons are unlikely to be specific angle detectors, because the magnitude of their responses to the optimal angle was indistinguishable from that from the optimal half-lines."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 11
                            }
                        ],
                        "text": "Ito, M., \n&#38; Komatsu, H. (2004)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 20
                            }
                        ],
                        "text": "Olshausen, B. A., &#38; Field, D. J. (1996)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 81
                            }
                        ],
                        "text": "This result is qual\u00aditatively consistent \nwith previous work (Ito &#38; Ko\u00admatsu, 2004; Lee et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 72
                            }
                        ],
                        "text": "For \ncomputing the gradient of sparsity regularization term, we followed Lee et al. (2008) s method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 399,
                                "start": 393
                            }
                        ],
                        "text": "Speci.cally, we trained a CDBN with two hidden \nlayers from the Ky\u00adoto natural image dataset.3 The .rst layer consisted of 24 groups (or bases )4 of \n10x10 pixel .lters, while the second layer consisted of 100 bases, each one 10x10 as well.5 As shown \nin Figure 2 (top), the learned .rst layer bases are oriented, localized edge .lters; this re\u00adsult is \nconsistent with much prior work (Olshausen &#38; Field, 1996; Bell &#38; Sejnowski, 1997; Ranzato et \nal., 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 182
                            }
                        ],
                        "text": "One common solution is to force the representation to be sparse, in that only a tiny frac\u00adtion \nof the units should be active in relation to a given stimulus (Olshausen &#38; Field, 1996; Lee et al., \n2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 22
                            }
                        ],
                        "text": "In our approach, like Lee et al. (2008), we regularize the objective function (data log-likelihood) \nto encour\u00adage each of the hidden units to have a mean activation close to some small constant .."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sparse deep belief network model for visual area V 2 . Advances in Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700379"
                        ],
                        "name": "Y. Shirai",
                        "slug": "Y.-Shirai",
                        "structuredName": {
                            "firstName": "Yoshiaki",
                            "lastName": "Shirai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shirai"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 61807205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc850f92a11c82b0132ca4eb8eb1d79a1b115c08",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Model-Based-Vision-Shirai",
            "title": {
                "fragments": [],
                "text": "Model-Based Vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713919"
                        ],
                        "name": "P. Langley",
                        "slug": "P.-Langley",
                        "structuredName": {
                            "firstName": "Pat",
                            "lastName": "Langley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Langley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6655909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "028165965fdf066821e1b65ac1de3ae6c503c30d",
            "isKey": false,
            "numCitedBy": 857,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editorial:-On-Machine-Learning-Langley",
            "title": {
                "fragments": [],
                "text": "Editorial: On Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35224059"
                        ],
                        "name": "S. Golowich",
                        "slug": "S.-Golowich",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Golowich",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Golowich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58731351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18c8c66e14d5276e5435376d67b9c9d16d7b58b7",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Information-Processing-Systems-Vapnik-Golowich",
            "title": {
                "fragments": [],
                "text": "Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 1997"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principal Mel-Spectrum Components (PMSC)"
            },
            "venue": {
                "fragments": [],
                "text": "Principal Mel-Spectrum Components (PMSC)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 65
                            }
                        ],
                        "text": "In work that was contemporary \nto and done indepen\u00addently of ours, Desjardins and Bengio (2008) also ap\u00adplied convolutional weight-sharing \nto RBMs and ex\u00adperimented on small image patches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical evaluation of convolutional RBMs for vision"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 65
                            }
                        ],
                        "text": "In work that was contemporary \nto and done indepen\u00addently of ours, Desjardins and Bengio (2008) also ap\u00adplied convolutional weight-sharing \nto RBMs and ex\u00adperimented on small image patches."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical evaluation of convolutional RBMs for vision (Technical Report)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 20
                            }
                        ],
                        "text": "(However, see also (Raina et al., 2009).)"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Largescale deep unsupervised learning using graphics processors . International Conf. on Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Largescale deep unsupervised learning using graphics processors . International Conf. on Machine Learning"
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 8,
            "result": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 32,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Convolutional-deep-belief-networks-for-scalable-of-Lee-Grosse/1e80f755bcbf10479afd2338cec05211fdbd325c?sort=total-citations"
}