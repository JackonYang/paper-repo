{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40325722"
                        ],
                        "name": "V. Fedorov",
                        "slug": "V.-Fedorov",
                        "structuredName": {
                            "firstName": "Valerii",
                            "lastName": "Fedorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Fedorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2636336"
                        ],
                        "name": "W. J. Studden",
                        "slug": "W.-J.-Studden",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Studden",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. J. Studden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98701042"
                        ],
                        "name": "E. Klimko",
                        "slug": "E.-Klimko",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Klimko",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Klimko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121909870,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "65c1a71c5307492782177a9799bef2cdf539ea00",
            "isKey": false,
            "numCitedBy": 2565,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Theory-Of-Optimal-Experiments-Fedorov-Studden",
            "title": {
                "fragments": [],
                "text": "Theory Of Optimal Experiments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144993197"
                        ],
                        "name": "R. Corbeil",
                        "slug": "R.-Corbeil",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Corbeil",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Corbeil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47534555"
                        ],
                        "name": "S. R. Searle",
                        "slug": "S.-R.-Searle",
                        "structuredName": {
                            "firstName": "Shayle",
                            "lastName": "Searle",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. R. Searle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 416,
                                "start": 23
                            }
                        ],
                        "text": "Multinomial sampling The EM algorithm was explicitly introduced by Hartley (1958) as a procedure for calculating maximum likelihood estimates given a random sample of size n from a discrete population where some of the observations are assigned not to individual cells but to aggregates of cells. The numerical example in Section 1 is such a case. In a variation on the missing-data problem, Carter and Myers (1973) proposed the EM algorithm for maximum likelihood estimation from linear combinations of discrete probability functions, using linear combinations of Poisson random variables as an example."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1219,
                                "start": 15
                            }
                        ],
                        "text": "Substituting the value of w* computed in Section 1 and using (3.19) we find DM(rr*) -. 0 132778. This value may be verified empirically via Table 1. In some cases, it may be desirable to try to speed the convergence of the EM algorithm. One way, requiring additional storage, is to use second derivatives in order to a Newton-step. These derivatives can be approximated numerically by using data from past iterations giving the empirical rate of convergence (Aitken's acceleration process when cJ has only one component), or by using equation (3.19), or (3.26) in the case of regular exponential families, together with an estimate of +8. Another possible way to reduce computation when the M-step is difficult is simply to increase the Q function rather than maximize it at each iteration. A final possibility arises with missing data patterns such that factors of the likelihood have their own distinct collections of parameters (Rubin, 1974). Since the proportion of missing data is less in each factor than in the full likelihood, the EM algorithm applied to each factor will converge more rapidly than when applied to the full likelihood. Lemma 1 and its consequence Theorem 1 were presented by Baum et al. (1970) in an unusual special case (see Section 4."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 11
                            }
                        ],
                        "text": ", yn provide data censored at various stimulus levels S,, S2, ..., S,,, which are supposed determined a priori and known. The details of the EM algorithm are straightforward and are not pursued here. Notation and relevant formulas may be found in Mantel and Greenhouse (1967) whose purpose was to remark on the special interpretation of the likelihood equations which is given in our general formula (2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 139
                            }
                        ],
                        "text": "It can be shown that the estimates Of u2, 3l *,s ak+1 found in this way are identical to those described by Patterson and Thompson (1971), Corbeil and Searle (1976) and Harville (1977) under the label REML, or \"restricted\" maximum likelihood."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 23
                            }
                        ],
                        "text": "Multinomial sampling The EM algorithm was explicitly introduced by Hartley (1958) as a procedure for calculating maximum likelihood estimates given a random sample of size n from a discrete population where some of the observations are assigned not to individual cells but to aggregates of cells."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 412,
                                "start": 14
                            }
                        ],
                        "text": "A common problem with multivariate \"continuous\" data is that different individuals are observed on different subsets of a complete set of variables. When the data are a sample from a multivariate normal population, there do not exist explicit closed-form expressions for the maximum-likelihood estimates of the means, variances and covariances of the normal population, except in cases discussed by Rubin (1974). Orchard and Woodbury (1972) and Beale and Little (1975) have described a cyclic algorithm for maximum-likelihood estimates, motivated by what Orchard and Woodbury call a \"missing information principle\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 591,
                                "start": 11
                            }
                        ],
                        "text": ", yn provide data censored at various stimulus levels S,, S2, ..., S,,, which are supposed determined a priori and known. The details of the EM algorithm are straightforward and are not pursued here. Notation and relevant formulas may be found in Mantel and Greenhouse (1967) whose purpose was to remark on the special interpretation of the likelihood equations which is given in our general formula (2.13). There is a very extensive literature on grouping, censoring and truncation, but only a few papers explicitly formulate the EM algorithm. An interesting early example is Grundy (1952) who deals with univariate normal sampling and who uses a Taylor series expansion to approximate the integrals required to handle grouping into narrow class intervals."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124586652,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "27f37d8a32a6e83cdc15f5492d0251f1a7afac31",
            "isKey": true,
            "numCitedBy": 366,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The maximum likelihood (ML) procedure of Hartley aud Rao [2] is modified by adapting a transformation from Pattersou and Thompson [7] which partitions the likelihood render normality into two parts, one being free of the fixed effects. Maximizing this part yields what are called restricted maximum likelihood (REML) estimators. As well as retaining the property of invariance under translation that ML estimators have, the REML estimators have the additional property of reducing to the analysis variance (ANOVA) estimators for many, if not all, cases of balanced data (equal subclass numbers). A computing algorithm is developed, adapting a transformation from Hemmerle and Hartley [6], which reduces computing requirements to dealing with matrices having order equal to the dimension of the parameter space rather than that of the sample space. These same matrices also occur in the asymptotic sampling variances of the estimators."
            },
            "slug": "Restricted-Maximum-Likelihood-(REML)-Estimation-of-Corbeil-Searle",
            "title": {
                "fragments": [],
                "text": "Restricted Maximum Likelihood (REML) Estimation of Variance Components in the Mixed Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143628300"
                        ],
                        "name": "H. Hartley",
                        "slug": "H.-Hartley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Hartley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288528"
                        ],
                        "name": "J. Rao",
                        "slug": "J.-Rao",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Rao",
                            "middleNames": [
                                "N.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 84
                            }
                        ],
                        "text": "We do not pursue the details, but we note that the iterative algorithm presented by Hartley and Rao (1967) for the mixed model is essentially the EM algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10110741,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b2bcc9fa711aa508d47bae12301dd5daca1182e8",
            "isKey": false,
            "numCitedBy": 607,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A procedure is developed for the maximum-likelihood estimation of the unknown constants and variances included in the general mixed analysis of variance model, involving fixed and random factors and interactions. The method applies to all cases where the design matrices satisfy certain conditions. The consistency and asymptotic efficiency of the estimates are discussed. Tests of hypotheses and confidence regions are derived. In this paper we develop a procedure for maximum-likelihood estimation for the general mixed analysis of variance model, defined in (1) below, involving any number of fixed and random factors and possibly interactions of any order. We do not specify 'equal numbers' or indeed any other experimental balance for our procedure, but we do require that our design matrices satisfy certain conditions of estimability for the parameters. In the case of balanced designs the estimation problem for the constants and variances involved in the linear model has been extensively treated: confining ourselves to just one reference on variance estimation, optimality properties of the classical analysis of variance procedures have already been demonstrated for various balanced designs (e.g. Graybill, 1961). However, results for unbalanced factorial and nested data are much more restricted: Henderson (1953) has suggested a method of unbiased estimation of variance components for the unbalanced two-way classification but his method is computationally cumbersome for a mixed model and when the number of classes is large. Searle & Henderson (1961) have suggested a simpler method also for the unbalanced two-way classification with one fixed factor containing a moderate number of levels and a random factor permitted to have quite a large number of levels. Bush & Anderson (1963) have investigated for the two-way classification random model the relative efficiency of Henderson's (1953) method and two other methods, A and B, based on the respective methods of fitting constants and weighted squares of means described by Yates (1934) for experiments based on a fixed effects model which also provide unbiased estimates of variance components. Possibilities of generalizations are indicated. In all the above methods the estimates of any constants in the model are computed from the 'Aitken Type' weighted least squares estimators based on the exact variance-covariance matrix of the experimental responses which involves the unknown variance ratios. The estimation of the latter is then based on various unbiased procedures so that little is known about any optimality properties of any of the resulting estimators. However, all these methods reduce to the well-known procedures based on minimal sufficient statistics in the special cases of balanced designs. The method of maximum-likelihood estimation here developed differs from the above in that maximum-likelihood equations are used and solved for both the estimates of constants"
            },
            "slug": "Maximum-likelihood-estimation-for-the-mixed-of-Hartley-Rao",
            "title": {
                "fragments": [],
                "text": "Maximum-likelihood estimation for the mixed analysis of variance model."
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A procedure is developed for the maximum-likelihood estimation of the unknown constants and variances included in the general mixed analysis of variance model, involving fixed and random factors and interactions, and applies to all cases where the design matrices satisfy certain conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrika"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2043869"
                        ],
                        "name": "K. J\u00f6reskog",
                        "slug": "K.-J\u00f6reskog",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "J\u00f6reskog",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. J\u00f6reskog"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 13
                            }
                        ],
                        "text": "J6RESKOG, K. G. (1969)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 186236320,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9f54b960ee86d8375e3d443fab5217f827538a00",
            "isKey": false,
            "numCitedBy": 2058,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a general procedure by which any number of parameters of the factor analytic model can be held fixed at any values and the remaining free parameters estimated by the maximum likelihood method. The generality of the approach makes it possible to deal with all kinds of solutions: orthogonal, oblique and various mixtures of these. By choosing the fixed parameters appropriately, factors can be defined to have desired properties and make subsequent rotation unnecessary. The goodness of fit of the maximum likelihood solution under the hypothesis represented by the fixed parameters is tested by a large samplex2 test based on the likelihood ratio technique. A by-product of the procedure is an estimate of the variance-covariance matrix of the estimated parameters. From this, approximate confidence intervals for the parameters can be obtained. Several examples illustrating the usefulness of the procedure are given."
            },
            "slug": "A-general-approach-to-confirmatory-maximum-factor-J\u00f6reskog",
            "title": {
                "fragments": [],
                "text": "A general approach to confirmatory maximum likelihood factor analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983540"
                        ],
                        "name": "V. Hasselblad",
                        "slug": "V.-Hasselblad",
                        "structuredName": {
                            "firstName": "Vic",
                            "lastName": "Hasselblad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hasselblad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Hasselblad (1966) discussed mixtures of R normals, and subsequently Hasselblad (1969) treated more general random sampling models, giving as examples mixtures of Poissons, binomials and exponentials."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Hasselblad (1966, 1969) reported that in practice the procedure always increased the likelihood, but none of the authors proved this fact."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120556182,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5567deb3f3f1fbe5671ad830970325d336870850",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "n observations are taken from a mixture of K normal subpopulations, where the value of K is known. It is assumed that these n observations are given as N frequencies from equally spaced intervals. Initial guesses of the K means, K variances, and K \u2212 1 proportions are made using the maximum likelihood estimates for a single truncated normal population as derived by Hald. Then an approximation to the likelihood function of the entire sample is used, and attempts to maximize this yield two iteration formulas. In practice, the method of steepest descent always converged, although the rate was not always fast. Special cases of equal variances and variances proportional to the square of the mean are also considered."
            },
            "slug": "Estimation-of-parameters-for-a-mixture-of-normal-Hasselblad",
            "title": {
                "fragments": [],
                "text": "Estimation of parameters for a mixture of normal distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50264152"
                        ],
                        "name": "N. E. Day",
                        "slug": "N.-E.-Day",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Day",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. E. Day"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 626,
                                "start": 1
                            }
                        ],
                        "text": "methods for finite mixtures of parametric families, variance components and hyperparameters in Bayesian prior distributions of parameters. In addition, the EM algorithm corresponds to certain robust estimation techniques based on iteratively reweighted least squares. We anticipate that recognition of the EM algorithm at its natural level of generality will lead to new and useful examples, possibly including the general approach to truncated data proposed in Section 4.2 and the factor-analysis algorithms proposed in Section 4.7. Some of the theory underlying the EM algorithm was presented by Orchard and Woodbury (1972), and by Sundberg (1976), and some has remained buried in the literature of special examples, notably in Baum et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 483,
                                "start": 2
                            }
                        ],
                        "text": "The M-step then becomes the usual estimation of c+ from the observed and assigned values of the indicators summed over the units. In practice, it is convenient to collect together those units with the same pattern of missing indicators, since the filled in fractional counts will be the same for each; hence one may think of the procedure as filling in estimated counts for each of the missing cells within each group of units having the same pattern of missing data. Hartley (1958) treated two restricted multinomial cases, namely, sampling from a Poisson population and sampling from a binomial population."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 604,
                                "start": 7
                            }
                        ],
                        "text": "Thus the derivatives of the log-likelihood have an attractive representation as the difference of an unconditional and a conditional expectation of the sufficient statistics. Formula (2.13) is the key to understanding the E- and M-steps of the EM algorithm, for if the algorithm converges to c$, so that in the limit ct(P) = (P+1)= c, then combining (2.2) and (2.3) leads to E(t1I*) = E(tIy,c *) or DL(4t) = 0 at cj = *. The striking representation (2.13) has been noticed in special cases by many authors. Examples will be mentioned in Section 4. The general form of (2.13) was given by Sundberg (1974) who ascribed it to unpublished 1966 lecture notes of Martin-L6f."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 8
                            }
                        ],
                        "text": "which they use but do not focus on directly. Convergence of the EM algorithm in special cases is discussed by Hartley and Hocking (1971) and by Sundberg (1976). We note that Hartley and Hocking must rule out ridges in L(c+) as a condition of their convergence theorem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 973,
                                "start": 4
                            }
                        ],
                        "text": "Since the complete-data log-likelihood is linear in the components of each zi, the E-step of the EM algorithm requires us to estimate the components of zi given the observed y and the current fitted parameters. These estimated components of zi are simply the current conditional probabilities that yi belongs to each of the R states. In many examples, the ct parameters of u(... I 4) and v(... I 4) are unrelated, so that the first and second terms in (4.3.3) may be maximized separately. The M-step is then equivalent to the complete-data maximization for the problem except that each observation yi contributes to the log-likelihood associated with each of the R states, with weights given by the R estimated components of zi, and the counts in the R states are the sums of the estimated components of the zi. The most widely studied examples of this formulation concern random samples from a mixture of normal distributions or other standard families. Hasselblad (1966) discussed mixtures of R normals, and subsequently Hasselblad (1969) treated more general random sampling models, giving as examples mixtures of Poissons, binomials and exponentials."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 2
                            }
                        ],
                        "text": "The EM algorithm has often been used for least-squares estimation in analysis of variance designs, or equivalently for maximum-likelihood estimation under the normal linear model with given residual variance CT2, whatever the value of U2. A basic reference is Healy and Westmacott (1956). The key idea is that exact least-squares computations are easily performed for special design matrices which incorporate the requisite balance and orthogonality properties, while least-squares computations for unbalanced designs require the inversion of a large matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 749,
                                "start": 1
                            }
                        ],
                        "text": "methods for finite mixtures of parametric families, variance components and hyperparameters in Bayesian prior distributions of parameters. In addition, the EM algorithm corresponds to certain robust estimation techniques based on iteratively reweighted least squares. We anticipate that recognition of the EM algorithm at its natural level of generality will lead to new and useful examples, possibly including the general approach to truncated data proposed in Section 4.2 and the factor-analysis algorithms proposed in Section 4.7. Some of the theory underlying the EM algorithm was presented by Orchard and Woodbury (1972), and by Sundberg (1976), and some has remained buried in the literature of special examples, notably in Baum et al. (1970). After defining the algorithm in Section 2, we demonstrate in Section 3 the key results which assert that successive iterations always increase the likelihood, and that convergence implies a stationary point of the likelihood."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 2
                            }
                        ],
                        "text": "The EM algorithm has been proposed many times in special circumstances. For example, Hartley (1958) gave three multinomial examples similar to our illustrative example."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 119479077,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fa8c415fb5c4d25a3a910d3c7764a1714093b07a",
            "isKey": true,
            "numCitedBy": 816,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The problem of estimating the components of a mixture of two normal distributions, multivariate or otherwise, with common but unknown covariance matrices is examined. The maximum likelihood equations are shown to be not unduly laborious to solve and the sampling properties of the resulting estimates are investigated, mainly by simulation. Moment estimators, minimum x2 and Bayes estimators are discussed but they appear greatly inferior to maximum likelihood except in the univariate case, the inferiority lying either in the sampling properties of the estimates or in the complexity of the computation. The wider problems obtained by allowing the components in the mixture to have different covariance matrices, or by having more than two components in the mixture, are briefly discussed, as is the relevance of this problem to cluster analysis."
            },
            "slug": "Estimating-the-components-of-a-mixture-of-normal-Day",
            "title": {
                "fragments": [],
                "text": "Estimating the components of a mixture of normal distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144320247"
                        ],
                        "name": "J. Edwards",
                        "slug": "J.-Edwards",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Edwards",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Edwards"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 220162343,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "1cd4617e2f5f7a54e7d12764f5ec043af43fa5d7",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book, after a curious introduction, in which the work of various distinguished non-authors is mentioned, starts well with a chapter by Wright, who expounds with conciseness and lucidity his views on drift, or rather on drifts with complex interactions, and on adaptive surfaces. The mathematics may, as his critics have pointed out, be circular, and adaptive surfaces may be useful aids to historical reconstruction, rather than recipes for struggling incipient species. Whether one can climb an imaginary surface, or get trapped in an imaginary potential well, seems a minor point, for mathematicians must be seen as painters rather than photographers or engineers, and certainly some readers will be helped in their attempts at understanding. The chapter is also a useful introduction to Wright's recent volumes, and has the advantages, and disadvantages, that the numerical treatment is mainly simple, and obtrudes less on the grand sweep of his prose. The second paper, by J. R. G. Turner, challenges Fisher's fundamental theorem not because it is too fundamental, or tautologous, but because its author reached his conclusions 'erroneously by a certain lack of mathematical rigour'. Turner's provision of additional qualifying words to Fisher's definition hardly helps in the search for bedrock and rigour. To criticize Fisher's claim that fitness resembles entropy, on the ground that his concept of fitness is hazy, seems strange, for entropy could well be criticized on the same grounds. The chapter is difficult, like its subject, and any judgement on it even more difficult. Diffusion is treated thoroughly in chapters on dispersal by Richardson and on stochastic process by Kimura, the former acting as a useful introduction and the latter as a definitive review of Neutrality by the leading Neutralist. These chapters are separated by a definitive review, on loads, by Crow, with a supplement on costs, which achieves the difficult task of being selfsufficient as an introduction to both and also by Cockerham's recursive formulation of the inbreeding problem. Hill and Robertson, in separate chapters, review and extend their own work on phenotypic selection, Robertson discussing in detail his empirical study by Monte Carlo methods of the influence of linkage on the speed and extent of selection with several loci and variable intensities of recombination. Sved and Mayo discuss and review Fisher's theory on the evolution of dominance, which thev sntdv hu hnth exact and approximate methods and by simulation studies. There is a chapter on the application of branching process theory to genetics, by Schaffer; and a chapter on incomplete binomials by Li, now a problem of mainly historical interest in an era of small families and advanced biochemistry. The book ends with short chapters on the evolutionary significance of linkage and epistasis by Kojima and Lewontin and on fitness and optimization by Levins. Dr Kojima, who was killed in a road accident last year, has created a most valuable selection of articles, mostly in the form of reviews with recent additions and a sufficient lucidity to act also as introductions. The book can be recommended highly for University libraries and departments of genetics. Many papers are dedicated to Dobzhansky for his seventieth birthday. As a whole the book is a fitting memorial to the enthusiasm and catholicism of its editor. J. H. EDWARDS"
            },
            "slug": "Biomathematics-Edwards",
            "title": {
                "fragments": [],
                "text": "Biomathematics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49234649"
                        ],
                        "name": "H. D. Patterson",
                        "slug": "H.-D.-Patterson",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Patterson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. D. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145606663"
                        ],
                        "name": "Robin Thompson",
                        "slug": "Robin-Thompson",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Thompson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robin Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 108
                            }
                        ],
                        "text": "It can be shown that the estimates Of u2, 3l *,s ak+1 found in this way are identical to those described by Patterson and Thompson (1971), Corbeil and Searle (1976) and Harville (1977) under the label REML, or \"restricted\" maximum likelihood."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 120553702,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "68f1683b30f3985f97043f5c22dd0c4cae6c3c0a",
            "isKey": false,
            "numCitedBy": 3745,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY A method is proposed for estimating intra-block and inter-block weights in the analysis of incomplete block designs with block sizes not necessarily equal. The method consists of maximizing the likelihood, not of all the data, but of a set of selected error contrasts. When block sizes are equal results are identical with those obtained by the method of Nelder (1968) for generally balanced designs. Although mainly concerned with incomplete block designs the paper also gives in outline an extension of the modified maximum likelihood procedure to designs with a more complicated block structure. In this paper we consider the estimation of weights to be used in the recovery of interblock information in incomplete block designs with possibly unequal block sizes. The problem can also be thought of as one of estimating constants and components of variance from data arranged in a general two-way classification when the effects of one classification are regarded as fixed and the effects of the second classification are regarded as random. Nelder (1968) described the efficient estimation of weights in generally balanced designs, in which the blocks are usually, although not always, of equal size. Lack of balance resulting from unequal block sizes is, however, common in some experimental work, for example in animal breeding experiments. The maximum likelihood procedure described by Hartley & Rao (1967) can be used but does not give the same estimates as Nelder's method in the balanced case. As will be shown, the two methods in effect use the same weighted sums of squares of residuals but assign different expectations. In the maximum likelihood approach, expectations are taken over a conditional distribution with the treatment effects fixed at their estimated values. In contrast Nelder uses unconditional expectations. The difference between the two methods is analogous to the well-known difference between two methods of estimating the variance o2 of a normal distribution, given a random sample of n values. Both methods use the same total sum of squares of deviations. But"
            },
            "slug": "Recovery-of-inter-block-information-when-block-are-Patterson-Thompson",
            "title": {
                "fragments": [],
                "text": "Recovery of inter-block information when block sizes are unequal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49353544"
                        ],
                        "name": "R. Fisher",
                        "slug": "R.-Fisher",
                        "structuredName": {
                            "firstName": "Rory",
                            "lastName": "Fisher",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62064968,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "3744110be1b657ab6335ade4f43224a33d3edd87",
            "isKey": false,
            "numCitedBy": 2173,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been pointed out to me that some of the statistical ideas employed in the following investigation have never received a strictly logical definition and analysis. The idea of a frequency curve, for example, evidently implies an infinite hypothetical population distributed in a definite manner; but equally evidently the idea of an infinite hypothetical population requires a more precise logical specification than is contained in that phrase. The same may be said of the intimately connected idea of random sampling. These ideas have grown up in the minds of practical statisticians and lie at the basis especially of recent work; there can be no question of their pragmatic value. It was no part of my original intention to deal with the logical bases of these ideas, but some comments which Dr Burnside has kindly made have convinced me that it may be desirable to set out for criticism the manner in which I believe the logical foundations of these ideas may be established."
            },
            "slug": "Theory-of-Statistical-Estimation-Fisher",
            "title": {
                "fragments": [],
                "text": "Theory of Statistical Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "It has been pointed out to me that some of the statistical ideas employed in the following investigation have never received a strictly logical definition and analysis, and it is desirable to set out for criticism the manner in which the logical foundations of these ideas may be established."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1925
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172770680"
                        ],
                        "name": "N. L. Johnson",
                        "slug": "N.-L.-Johnson",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Johnson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. L. Johnson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 38
                            }
                        ],
                        "text": "See formulae (le.5.6) and (le.6.6) of Rao (1965).\nt A referee has pointed out that our use of the term \"algorithm\" can be criticized because we do not specify the sequence of computing steps actually required to carry out a single E- or M-step."
                    },
                    "intents": []
                }
            ],
            "corpusId": 123126207,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f95f7fa27a4ff248f57e22164a567d75e03ac46b",
            "isKey": true,
            "numCitedBy": 2051,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"C. R. Rao would be found in almost any statistician's list of five outstanding workers in the world of Mathematical Statistics today. His book represents a comprehensive account of the main body of results that comprise modern statistical theory.\" -W. G. Cochran \"[C. R. Rao is] one of the pioneers who laid the foundations of statistics which grew from ad hoc origins into a firmly grounded mathematical science.\" -B. Efrom Translated into six major languages of the world, C. R. Rao's Linear Statistical Inference and Its Applications is one of the foremost works in statistical inference in the literature. Incorporating the important developments in the subject that have taken place in the last three decades, this paperback reprint of his classic work on statistical inference remains highly applicable to statistical analysis. Presenting the theory and techniques of statistical inference in a logically integrated and practical form, it covers: * The algebra of vectors and matrices * Probability theory, tools, and techniques * Continuous probability models * The theory of least squares and the analysis of variance * Criteria and methods of estimation * Large sample theory and methods * The theory of statistical inference * Multivariate normal distribution Written for the student and professional with a basic knowledge of statistics, this practical paperback edition gives this industry standard new life as a key resource for practicing statisticians and statisticians-in-training."
            },
            "slug": "Linear-Statistical-Inference-and-Its-Applications-Johnson",
            "title": {
                "fragments": [],
                "text": "Linear Statistical Inference and Its Applications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48343674"
                        ],
                        "name": "D. Harville",
                        "slug": "D.-Harville",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harville",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harville"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 169
                            }
                        ],
                        "text": "It can be shown that the estimates Of u2, 3l *,s ak+1 found in this way are identical to those described by Patterson and Thompson (1971), Corbeil and Searle (1976) and Harville (1977) under the label REML, or \"restricted\" maximum likelihood."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 119989539,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9903c333828bbe06bd54b90e0e50d62f8f95b759",
            "isKey": false,
            "numCitedBy": 2324,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Recent developments promise to increase greatly the popularity of maximum likelihood (ml) as a technique for estimating variance components. Patterson and Thompson (1971) proposed a restricted maximum likelihood (reml) approach which takes into account the loss in degrees of freedom resulting from estimating fixed effects. Miller (1973) developed a satisfactory asymptotic theory for ml estimators of variance components. There are many iterative algorithms that can be considered for computing the ml or reml estimates. The computations on each iteration of these algorithms are those associated with computing estimates of fixed and random effects for given values of the variance components."
            },
            "slug": "Maximum-Likelihood-Approaches-to-Variance-Component-Harville",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Approaches to Variance Component Estimation and to Related Problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34325389"
                        ],
                        "name": "R. Sundberg",
                        "slug": "R.-Sundberg",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Sundberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sundberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 40
                            }
                        ],
                        "text": "The general form of (2.13) was given by Sundberg (1974) who ascribed it to unpublished 1966 lecture notes of Martin-L6f."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 97
                            }
                        ],
                        "text": "As Professor Efron points out, R. A. Fisher long ago used the basic first derivative relation of Sundberg (1974) in the special context of inefficient statistics, but without he specific application to incomplete data problems as discussed by Hartley."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121213432,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "af0bf70910a8e58e97e1727d7fd9ce35a8fd333e",
            "isKey": true,
            "numCitedBy": 110,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper deals with the numerical solution of the likelihood equations for incomplete data from exponential families, that is for data being a function of exponential family data. Illustrative examples especially studied in this paper concern grouped and censored normal samples and normal mixtures. A simple iterative method of solution is proposed and studied. It is shown that the sequence of iterates converges to a relative maximum of the likelihood function, and that the convergence is geometric with a factor of convergence which for large samples equals the maxi-mal relative loss of Fisher information due to the incompleteness of data. This large sample factor of convergence is illustrated diagrammaticaily for the examples mentioned above. Experiences of practical application are mentioned."
            },
            "slug": "An-iterative-method-for-solution-of-the-likelihood-Sundberg",
            "title": {
                "fragments": [],
                "text": "An iterative method for solution of the likelihood equations for incomplete data from exponential families"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2250350"
                        ],
                        "name": "W. Hemmerle",
                        "slug": "W.-Hemmerle",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hemmerle",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hemmerle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143628300"
                        ],
                        "name": "H. Hartley",
                        "slug": "H.-Hartley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Hartley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hartley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 121
                            }
                        ],
                        "text": "The authors' application of EM to estimating variance components displays no advantages for EM over methods described by Hemmerle and Hartley (1973) and Hemmerle and Lorens (1976), which are directly suited to variance components models and take account of their special properties-whereas EM does\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122179950,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d90630643f0321de8837c6b48d9855570c6c5327",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The W transformation, a matrix transformation, is developed and applied for the mixed analysis of variance model to compute maximum likelihood estimates of the variance components and fixed parameters. This transformation not only eliminates the need for the explicit computation of the n \u00d7 n inverse matrix H\u2212l but permits handling the iterative calculations such that they do not depend upon n (the number of observations) in any way. Although not wedded to a particular numerical method, the W transformation is implemented in conjunction with a modified Newton-Raphson method in which variance components are restricted to being non-negative."
            },
            "slug": "Computing-Maximum-Likelihood-Estimates-for-the-the-Hemmerle-Hartley",
            "title": {
                "fragments": [],
                "text": "Computing Maximum Likelihood Estimates for the Mixed A.O.V. Model Using the W Transformation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144532254"
                        ],
                        "name": "Calyampudi R. Rao",
                        "slug": "Calyampudi-R.-Rao",
                        "structuredName": {
                            "firstName": "Calyampudi",
                            "lastName": "Rao",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Calyampudi R. Rao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 77
                            }
                        ],
                        "text": "The suggested method for factor analysis can be related to that published by Rao (1955)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123260098,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3be92cfd880e3169ac6cb18fe42751a6d5bb3395",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A distinction is drawn between the method of principal components developed by Hotelling and the common factor analysis discussed in psychological literature both from the point of view of stochastic models involved and problems of statistical inference. The appropriate statistical techniques are briefly reviewed in the first case and detailed in the second. A new method of analysis called the canonical factor analysis, explaining the correlations between rather than the variances of the measurements, is developed. This analysis furnishes one out of a number of possible solutions to the maximum likelihood equations of Lawley. It admits an iterative procedure for estimating the factor loadings and also for constructing the likelihood criterion useful in testing a specified hypothesis on the number of factors and in determining a lower confidence limit to the number of factors."
            },
            "slug": "Estimation-and-tests-of-significance-in-factor-Rao",
            "title": {
                "fragments": [],
                "text": "Estimation and tests of significance in factor analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1955
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103072546"
                        ],
                        "name": "J. Eagon",
                        "slug": "J.-Eagon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Eagon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eagon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 245
                            }
                        ],
                        "text": "\u2026AM All use subject to JSTOR Terms and Conditions\n1977] DEMPSTER et a!. - Maximum Likelihoodfrom Incomplete Data 17 Finally, we mention another independent special derivation of the EM method for finite mixtures developed in a series of papers (Baum and Eagon, 1967; Baum et al., 1970; Baum, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 171
                            }
                        ],
                        "text": "Thus - {det (M)}-1 possesses (a) and (b) with t = k, but 8 = 1 emerges as a natural power since this attains the optimum in one step if J = k; it achieves monotonicity by Baum and Eagon (1967)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14153120,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "69fc8c03d21e22e30d6642824c37158b314f36c3",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Summary. The object of this note is to prove the theorem below and sketch two applications, one to statistical estimation for (proba-bilistic) functions of Markov processes [l] and one to Blakley's model for ecology [4]. 2. Result. THEOREM. Let P(x)=P({xij}) be a polynomial with nonnegative coefficients homogeneous of degree d in its variables {##}. Let x= {##} be any point of the domain D: ## \u00a7:(), ]pLi ## = 1, i = l, \u2022 \u2022 \u2022 , p, j=l, \u2022 \u2022 \u2022 , q%. For x= {xij} \u00a3\u00a3> let 3(#) = 3{##} denote the point of D whose i, j coordinate is (dP\\ \\ f \u00ab dP 3(*)<i = (Xij 7\u2014) / 2* *<i \u2014 \\ dXij\\(X)// ,-i dXij (\u00bb> Then P(3(x))>P(x) unless 3(x)=x. Notation, fi will denote a doubly indexed array of nonnegative integers: fx= {M#}> i = l> \u2022 \u2022 \u2022 > <lu i=l, \u2022 \u2022 \u2022 , A #* then denotes Ilf-iH\u00ee-i^* Similarly, c M is an abbreviation for C[ MiJ }. The polynomial P({xij}) is then written P(x) = ]CM V^-In our notation : (1) 3(&)*i = (Z) \u00abWnys*) / JLH CpiiijX\u00bb."
            },
            "slug": "An-inequality-with-applications-to-statistical-for-Baum-Eagon",
            "title": {
                "fragments": [],
                "text": "An inequality with applications to statistical estimation for probabilistic functions of Markov processes and to a model for ecology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17155759"
                        ],
                        "name": "P. Minton",
                        "slug": "P.-Minton",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Minton",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242863"
                        ],
                        "name": "H. Raiffa",
                        "slug": "H.-Raiffa",
                        "structuredName": {
                            "firstName": "Howard",
                            "lastName": "Raiffa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Raiffa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70503349"
                        ],
                        "name": "Robert Schlaifer",
                        "slug": "Robert-Schlaifer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schlaifer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Schlaifer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124253831,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b3b885eba933831514ea3bc7ec289243a81176e9",
            "isKey": false,
            "numCitedBy": 1020,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In general, this book is concerned with capital budgeting and decision theory. Specifically, it centers around a singular uncertainty decision the decision by oil and gas operators to drill, or not to drill, a well. Actually, a sequence of decisions must precede this final action, but each one of these preliminary decisions is principally directed toward the final payoff question: Should we invest money in this well? If so, how much should we risk, and how much of the risk should we share with others? The objective of this book is twofold. The first objective is to describe the nature of decision problems in drilling for gas and oil, a business situation where uncertainties are exceptionally great, and to describe how businessmen actually make drilling decisions in the face of these uncertainties. This descriptive section, of great interest in its own right, then provides the foundation for the second objective, which is to explore the possibilities of applying \"decision theories\" to such decisions. This second objective is normative or prescriptive in its attempt to provide the driller with better guides to consistent action to meet his own goals. The presentation of the applications of mathematical theories is kept clear and simple, and the methods suggested for dealing with these problems can be understood by a reader with only a working knowledge of arithmetic and high school algebra. This book should be of interest to several audiences, among whom are the following: ( 1 ) people in the oil industry; (2) people in other industries who are actively interessed in finding ways of making better decisions in situations of risk and uncertainty; and (3) people whose interests are perhaps inore academic and who are concerned with both theory and practice in the area of decision making. xmlui.dri2xhtml.METS1.0.item-descriptionmiscellaneous 380 p., graph. Search all I-Revues This Collection"
            },
            "slug": "Applied-Statistical-Decision-Theory.-Minton-Raiffa",
            "title": {
                "fragments": [],
                "text": "Applied Statistical Decision Theory."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The objective of this book is to describe the nature of decision problems in drilling for gas and oil, a business situation where uncertainties are exceptionally great, and to describe how businessmen actually make drilling decisions in the face of these uncertainties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144957896"
                        ],
                        "name": "W. H. Carter",
                        "slug": "W.-H.-Carter",
                        "structuredName": {
                            "firstName": "Walter",
                            "lastName": "Carter",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. H. Carter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49936898"
                        ],
                        "name": "R. H. Myers",
                        "slug": "R.-H.-Myers",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Myers",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. H. Myers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 44
                            }
                        ],
                        "text": "In a variation on the missing-data problem, Carter and Myers (1973) proposed the EM algorithm for maximum likelihood estimation from linear combinations of discrete probability functions, using linear combinations of Poisson random variables as an example."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120932072,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1d8adf48ecff795174e0011dc24fc1b1fe2ed312",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this article the problem of obtaining the maximum likelihood estimates of the parameters from a special type of linear combination of discrete probability functions is discussed. It is shown that when the sample is completely categorized the estimation problem is no more complicated that that of estimating the parameters of each of the component probability functions separately. When the sample is less than completely classified an iterative procedure must be used to obtain solutions to the likelihood equations and it is shown how the problem reduces to that of the full data case. A discussion of the asymptotic properties of the resulting estimators follows."
            },
            "slug": "Maximum-Likelihood-Estimation-from-Linear-of-Carter-Myers",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Estimation from Linear Combinations of Discrete Probability Functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144908870"
                        ],
                        "name": "A. Edwards",
                        "slug": "A.-Edwards",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Edwards",
                            "middleNames": [
                                "W.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Edwards"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 44
                            }
                        ],
                        "text": "I refer to the modification of the model of Edwards (1970) discussed by Thompson (1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115393631,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "17da5633aad4dbf7b580d61cb8cf5d3ccebd39f5",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A solution to the problem of estimating the positions and times of the branch points of a Brownian-motion/Yule process, given the positions of all the particles at a particular time, is outlined. A likelihood approach is used, and it is shown that the solution involves maintaining a clear distinction between likelihood and conditional probability if difficulties over mathematical singularities are to be avoided. Several unsolved mathematical problems are encountered, and it is concluded that some simulation studies may be required for a complete solution. Questions of scientific inference which the problem raises are discussed briefly."
            },
            "slug": "Estimation-of-the-Branch-Points-of-a-Branching-Edwards",
            "title": {
                "fragments": [],
                "text": "Estimation of the Branch Points of a Branching Diffusion Process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095314816"
                        ],
                        "name": "Y. Bishop",
                        "slug": "Y.-Bishop",
                        "structuredName": {
                            "firstName": "Yvonne",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5578803"
                        ],
                        "name": "P. Holland",
                        "slug": "P.-Holland",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Holland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Holland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684961"
                        ],
                        "name": "S. Fienberg",
                        "slug": "S.-Fienberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Fienberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fienberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 295,
                                "start": 275
                            }
                        ],
                        "text": "\u2026when the version of the EM algorithm proposed by Brown (1974) is used for estimation in the model of quasi-independence in square Ix I contingency tables with missing diagonals, it is distinctly superior to the standard iterative proportional fitting algorithm described in Bishop et al. (1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62641831,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5e72530255e271a09a5a1e3607c790bed7a13db3",
            "isKey": false,
            "numCitedBy": 5281,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"At last, after a decade of mounting interest in log-linear and related models for the analysis of discrete multivariate data, particularly in the form of multidimensional tables, we now have a comprehensive text and general reference on the subject. Even a mediocre attempt to organize the extensive and widely scattered literature on discrete multivariate analysis would be welcome; happily, this is an excellent such effort, but a group of Harvard statisticians taht has contributed much to the field. Their book ought to serve as a basic guide to the analysis of quantitative data for years to come.\" --James R. Beninger, Contemporary Sociology\n\n\"A welcome addition to multivariate analysis. The discussion is lucid and very leisurely, excellently illustrated with applications drawn from a wide variety of fields. A good part of the book can be understood without very specialized statistical knowledge. It is a most welcome contribution to an interesting and lively subject.\" --D.R. Cox, Nature\n\n\"Discrete Multivariate Analysis is an ambitious attempt to present log-linear models to a broad audience. Exposition is quite discursive, and the mathematical level, except in Chapters 12 and 14, is very elementary. To illustrate possible applications, some 60 different sets of data have been gathered together from diverse fields. To aid the reader, an index of these examples has been provided. ...the book contains a wealth of material on important topics. Its numerous examples are especially valuable.\" --Shelby J. Haberman, The Annals of Statistics"
            },
            "slug": "Discrete-Multivariate-Analysis:-Theory-and-Practice-Bishop-Holland",
            "title": {
                "fragments": [],
                "text": "Discrete Multivariate Analysis: Theory and Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Discrete Multivariate Analysis is a comprehensive text and general reference on the analysis of discrete multivariate data, particularly in the form of multidimensional tables, and contains a wealth of material on important topics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Efron (1967) proposed the EM algorithm for singly censored ata, and Turnbull (1974, 1976) extended Efron's approach to arbitrarily grouped, censored and truncated data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20097672,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0cd55752a7e26a7aa5600c52e48f0fc6c4bec2e3",
            "isKey": false,
            "numCitedBy": 730,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "A medical investigator attempting to compare two different treatments for, say, prolongation of life among disease victims, often finds himself in the following situation: at time T, when it is necessary to end the experiment, or at least evaluate the results up to that time, a certain number of the patients in each treatment group will still be alive. His data will then be represented by two sets of numbers which might look like Xl, X2, X3+, X4, X5+, X6, ... , Xm and yl, Y2+, Y3+, Y4, * *, y.. Here xi and x2 would represent actual lifetimes, while X3+, a \"censored\" observation, represents a lifetime known only to exceed x3. If all the patients in both treatment groups were treated at time 0, then every + value would be equal to T, a situation that has been investigated by Halperin [1]. Frequently, however, patients enter the investigation at different times after it has begun, and the x+ and y+ values may range from 0 to T. Such a situation, of course, complicates the comparison of the two treatments, particularly if the mechanism censoring the x values is different from that censoring the y values. This may happen, for instance, if the x sequence was run some time ago, so that nearly all the patients have been observed to their death times, while the y sequence is begun later, and contains many censored observations. Gehan [2] and Gilbert [3] have independently proposed the same extension of the Wilcoxon statistic as a solution to the two sample problem with censored data. In this paper the problem is discussed further, and a different test statistic is proposed, which is shown to be, in some ways, superior to the GehanGilbert statistic."
            },
            "slug": "The-two-sample-problem-with-censored-data-Efron",
            "title": {
                "fragments": [],
                "text": "The two sample problem with censored data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983540"
                        ],
                        "name": "V. Hasselblad",
                        "slug": "V.-Hasselblad",
                        "structuredName": {
                            "firstName": "Vic",
                            "lastName": "Hasselblad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hasselblad"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Hasselblad (1966) discussed mixtures of R normals, and subsequently Hasselblad (1969) treated more general random sampling models, giving as examples mixtures of Poissons, binomials and exponentials."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Hasselblad (1966, 1969) reported that in practice the procedure always increased the likelihood, but none of the authors proved this fact."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118071830,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c9aac52c492626703709a3cd3595afb72ce55b23",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract General \u201csuccessive substitutions\u201d iteration equations are developed for obtaining estimates for finite mixtures of distributions from the exponential family. These, in general, correspond to relative maximums of the likelihood function. It is assumed that the number of distributions is known, and that the mixtures are from distributions of the same type, but with different parameter values. The particular equations for the Poisson, binomial, and exponential distributions are given, as well as examples of the results of the procedure for each distribution. From the examples tried, it was observed that the likelihood function increased at each iteration. Graphs of the asymptotic variances of the estimates are given, and two sampling experiments comparing estimates obtained by this scheme with moment estimates are also given."
            },
            "slug": "Finite-mixtures-of-distributions-from-the-family-Hasselblad",
            "title": {
                "fragments": [],
                "text": "Finite mixtures of distributions from the exponential family"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2550392"
                        ],
                        "name": "B. Efron",
                        "slug": "B.-Efron",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Efron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Efron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31727329"
                        ],
                        "name": "C. Morris",
                        "slug": "C.-Morris",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Morris",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Morris"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 117
                            }
                        ],
                        "text": "Other examples involving the use of point estimates of 4) are found in Mosteller and Wallace (1965), Good (1967) and Efron and Morris (1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53002187,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "47774e9ac7ef9601024d2d9717a2869024af7a6b",
            "isKey": false,
            "numCitedBy": 829,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In 1961, James and Stein exhibited an estimator of the mean of a multivariate normal distribution having uniformly lower mean squared error than the sample mean. This estimator is reviewed briefly in an empirical Bayes context. Stein's rule and its generalizations are then applied to predict baseball averages, to estimate toxomosis prevalence rates, and to estimate the exact size of Pearson's chi-square test with results from a computer simulation. In each of these examples, the mean square error of these rules is less than half that of the sample mean."
            },
            "slug": "Data-Analysis-Using-Stein's-Estimator-and-its-Efron-Morris",
            "title": {
                "fragments": [],
                "text": "Data Analysis Using Stein's Estimator and its Generalizations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1926128968"
                        ],
                        "name": "By R. Ceppellini",
                        "slug": "By-R.-Ceppellini",
                        "structuredName": {
                            "firstName": "By R.",
                            "lastName": "Ceppellini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "By R. Ceppellini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6686070"
                        ],
                        "name": "M. Siniscalco",
                        "slug": "M.-Siniscalco",
                        "structuredName": {
                            "firstName": "Marcello",
                            "lastName": "Siniscalco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Siniscalco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158367122"
                        ],
                        "name": "C. A. Smith",
                        "slug": "C.-A.-Smith",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Smith",
                            "middleNames": [
                                "A.",
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. A. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 55
                            }
                        ],
                        "text": "These authors also drew attention to an early paper by Ceppellini et al. (1955) who developed maximum likelihood and the EM algorithm for a class of finite-mixture problems arising in genetics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38625779,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "01c63a899ee75d4ec1ecbf69313d7ad37a99d4c2",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "1. The estimation of gene frequencies in a population is an important problem in human genetics and anthropology, especially where blood groups are concerned. Much work has already been done on this problem, notably by W. L. Stevens (1938), R. A. Fisher (1940, 1946), C. W. Cotterman (1947), D. J. Finney (1948a, b), W. C. Boyd (1954a, b ) , and others. Here we give a general procedure applicable (under very general conditions) both to samples of unrelated individuals and to families. This method is applied to data on blood groups collected from villages near the mouth of the River Po, in northern Italy, in the course of an investigation on microcythaemia (Bianco, Ceppellini, Silvestroni & Siniscalco, 1954). Experience shows that this new method of computation is reasonably rapid, except in the case of a rare, or fairly rare, recessive gene, or when such a gene is present in a series of alleles. It may also become laborious when there are complicated families and a system of several alleles; in this case, however, it seems possible to simplify the calculations, though with some sacrifice of information. Of course, in particular cases it may not be so rapid as methods specially designed for the case in question, as for example, Finney\u2019s (1948a, b ) methods when there are only two alleles concerned and the families contain at most two generations. The new method will be shown to be equivalent to maximum likelihood, and therefore fully efficient in the statistical sense. 2. We assume that the population under investigation is large, with random mating, and without difference of fitness between the different genotypes, or any other form of selection. Thus the Hardy-Weinberg rule will hold, and the gene frequencies will not change from one generation to the next. There is assumed to be complete manifestation, so that the observed phenotypes depend only on the genotypes, and not on environmental conditions. It is well known that these assumptions hold remarkably well for most blood groups and most populations, though slight deviations will be introduced by inbreeding and by incompatibility between foetus and mother. We must also assume that. the sample chosen is not biased with regard to the character whose frequency is to be estimated. Thus the families from the Po delta were selected by the presence of microcythaemia in one or both parents. Since so far no association has been found between microcythaemia and the blood groups, except possibly for a linkage with Lewis, and also possibly with the secretor character (Bianco et al. 1954), it seems reasonable to consider this as a random sample in so far as the blood groups are concerned. Of course a linkage will not of itself introduce any bias in a sample of completely unrelated families. In the case of the Italian data the populations concerned are small, and the families are accordingly related in a complicated manner. This will accordingly influence the estimates, though it will have the effect rather of slightly increasing their standard error than of introducing a bias in the estimated frequencies themselves; this caution must be borne in mind in interpreting the results given below."
            },
            "slug": "THE-ESTIMATION-OF-GENE-FREQUENCIES-IN-A-POPULATION-Ceppellini-Siniscalco",
            "title": {
                "fragments": [],
                "text": "THE ESTIMATION OF GENE FREQUENCIES IN A RANDOM\u2010MATING POPULATION"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This method is applied to data on blood groups collected from villages near the mouth of the River Po, in northern Italy, in the course of an investigation on microcythaemia, and it is shown to be equivalent to maximum likelihood, and therefore fully efficient in the statistical sense."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of human genetics"
            },
            "year": 1955
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70123613"
                        ],
                        "name": "B. J. Morgan",
                        "slug": "B.-J.-Morgan",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Morgan",
                            "middleNames": [
                                "J.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. J. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152591573"
                        ],
                        "name": "D. Titterington",
                        "slug": "D.-Titterington",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Titterington",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Titterington"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1772,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions. Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently. Although they did not differentiate with respect o natural exponential-family parameters, which would have produced derivatives directly in the appealing form (2.13), they all manipulated the likelihood equations into this form and recognized the simple interpretation in terms of unconditional nd conditional moments. Further, they all suggested the EM algorithm. For his special case, Day (1969) noticed that the estimated marginal mean and covariance are constant across iterations, o that the implementation of the algorithm can be streamlined. All offered practical advice on various aspects of the algorithm, such as initial estimates, rates of convergence and multiple solutions to the likelihood equations. Wolfe (1970) suggested the use of Aitken's acceleration process to improve the rate of convergence. Hasselblad (1966, 1969) reported that in practice the procedure always increased the likelihood, but none of the authors proved this fact. Two further papers in the same vein are by Hosmer (1973a, b). The first of these reported pessimistic simulation results on the small-sample mean squared error of the maximumlikelihood estimates for univariate normal mixtures, while the second studied the situation where independent samples are available from two normal populations, along with a sample from an unknown mixture of the two populations. The EM algorithm was developed for the special case of the second paper. Haberman (1976) presented an interesting example which includes both multinomial missing values (Section 3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 36
                            }
                        ],
                        "text": "3) leads to E(t1I*) = E(tIy,c *) or DL(4t) = 0 at cj = *. The striking representation (2.13) has been noticed in special cases by many authors. Examples will be mentioned in Section 4. The general form of (2.13) was given by Sundberg (1974) who ascribed it to unpublished 1966 lecture notes of Martin-L6f."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 724,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions. Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently. Although they did not differentiate with respect o natural exponential-family parameters, which would have produced derivatives directly in the appealing form (2.13), they all manipulated the likelihood equations into this form and recognized the simple interpretation in terms of unconditional nd conditional moments. Further, they all suggested the EM algorithm. For his special case, Day (1969) noticed that the estimated marginal mean and covariance are constant across iterations, o that the implementation of the algorithm can be streamlined."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions. Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2650,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions. Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently. Although they did not differentiate with respect o natural exponential-family parameters, which would have produced derivatives directly in the appealing form (2.13), they all manipulated the likelihood equations into this form and recognized the simple interpretation in terms of unconditional nd conditional moments. Further, they all suggested the EM algorithm. For his special case, Day (1969) noticed that the estimated marginal mean and covariance are constant across iterations, o that the implementation of the algorithm can be streamlined. All offered practical advice on various aspects of the algorithm, such as initial estimates, rates of convergence and multiple solutions to the likelihood equations. Wolfe (1970) suggested the use of Aitken's acceleration process to improve the rate of convergence. Hasselblad (1966, 1969) reported that in practice the procedure always increased the likelihood, but none of the authors proved this fact. Two further papers in the same vein are by Hosmer (1973a, b). The first of these reported pessimistic simulation results on the small-sample mean squared error of the maximumlikelihood estimates for univariate normal mixtures, while the second studied the situation where independent samples are available from two normal populations, along with a sample from an unknown mixture of the two populations. The EM algorithm was developed for the special case of the second paper. Haberman (1976) presented an interesting example which includes both multinomial missing values (Section 3.1.1) and finite mixtures: ampling from a multiway contingency table where the population cell frequencies are specified by a log-linear model. An especially interesting case arises when the incompleteness ofthe data is defined by the absence of all data on one factor. In effect, he observed ata are drawn from a lower-order contingency table which is an unknown mixture of the tables corresponding to levels of the unobserved factor. These models include the clustering or latent-structure models discussed by Wolfe (1970), but permit more general and quite complex finite-mixture models, depending on the complexity ofthe complete-data log-linear model. Haberman showed for his type of data that each iteration of the EM algorithm increases the likelihood. Orchard and Woodbury (1972) discussed finite-mixture p oblems in a non-exponentialfamily framework."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1054,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions. Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently. Although they did not differentiate with respect o natural exponential-family parameters, which would have produced derivatives directly in the appealing form (2.13), they all manipulated the likelihood equations into this form and recognized the simple interpretation in terms of unconditional nd conditional moments. Further, they all suggested the EM algorithm. For his special case, Day (1969) noticed that the estimated marginal mean and covariance are constant across iterations, o that the implementation of the algorithm can be streamlined. All offered practical advice on various aspects of the algorithm, such as initial estimates, rates of convergence and multiple solutions to the likelihood equations. Wolfe (1970) suggested the use of Aitken's acceleration process to improve the rate of convergence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 2387,
                                "start": 0
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions. Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently. Although they did not differentiate with respect o natural exponential-family parameters, which would have produced derivatives directly in the appealing form (2.13), they all manipulated the likelihood equations into this form and recognized the simple interpretation in terms of unconditional nd conditional moments. Further, they all suggested the EM algorithm. For his special case, Day (1969) noticed that the estimated marginal mean and covariance are constant across iterations, o that the implementation of the algorithm can be streamlined. All offered practical advice on various aspects of the algorithm, such as initial estimates, rates of convergence and multiple solutions to the likelihood equations. Wolfe (1970) suggested the use of Aitken's acceleration process to improve the rate of convergence. Hasselblad (1966, 1969) reported that in practice the procedure always increased the likelihood, but none of the authors proved this fact. Two further papers in the same vein are by Hosmer (1973a, b). The first of these reported pessimistic simulation results on the small-sample mean squared error of the maximumlikelihood estimates for univariate normal mixtures, while the second studied the situation where independent samples are available from two normal populations, along with a sample from an unknown mixture of the two populations. The EM algorithm was developed for the special case of the second paper. Haberman (1976) presented an interesting example which includes both multinomial missing values (Section 3.1.1) and finite mixtures: ampling from a multiway contingency table where the population cell frequencies are specified by a log-linear model. An especially interesting case arises when the incompleteness ofthe data is defined by the absence of all data on one factor. In effect, he observed ata are drawn from a lower-order contingency table which is an unknown mixture of the tables corresponding to levels of the unobserved factor. These models include the clustering or latent-structure models discussed by Wolfe (1970), but permit more general and quite complex finite-mixture models, depending on the complexity ofthe complete-data log-linear model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 38
                            }
                        ],
                        "text": "MORGAN, B. J. T. and TITTERINGTON, D. M. (1977)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120044177,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f64aa7d9f90dabff29b9777dcb6242225458c0fb",
            "isKey": true,
            "numCitedBy": 16,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY This paper considers maximum likelihood estimation for the parameters of quasiindependence in a contingency table with a missing or excluded diagonal. Two of the methods discussed derive from the EM algorithm of Dempster, Laird & Rubin (1977), the other two methods being Newton-Raphson and iterative scaling. Iterative scaling is found, empirically, to be the least efficient method."
            },
            "slug": "A-comparison-of-iterative-methods-for-obtaining-in-Morgan-Titterington",
            "title": {
                "fragments": [],
                "text": "A comparison of iterative methods for obtaining maximum likelihood estimates in contingency tables with a missing diagonal"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2023904"
                        ],
                        "name": "D. Preece",
                        "slug": "D.-Preece",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Preece",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Preece"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "Preece (1971) has investigated to what extent this result can be generalized."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120608630,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9386a41096d853ad5437366a3cdd4d541a87f81d",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Healy and Westmacott (1956) gave an iterative missing value procedure in which a simple correction is subtracted from each estimated missing value at each iteration. Experience has however shown that it is advantageous to replace the simple correction by a multiple m of it, m > 1. The multiplier m = n/E, where n is the number of units and E the number of error degrees of freedom in the absence of missing values, gives an exact solution in one step for most factorial analyses with one missing value; for other analyses, also, convergence is faster with m = n/E than with m = 1. The algebra of the general iterative procedure is given. Criteria for convergence are discussed."
            },
            "slug": "Iterative-Procedures-for-Missing-Values-in-Preece",
            "title": {
                "fragments": [],
                "text": "Iterative Procedures for Missing Values in Experiments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39867082"
                        ],
                        "name": "L. A. Goodman",
                        "slug": "L.-A.-Goodman",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Goodman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Goodman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123162468,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "038742d1ccd731e65f9bbd112b4da91b50146643",
            "isKey": false,
            "numCitedBy": 1560,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY This paper considers a wide class of latent structure models. These models can serve as possible explanations of the observed relationships among a set of m manifest polytomous variables. The class of models considered here includes both models in which the parameters are identifiable and also models in which the parameters are not. For each of the models considered here, a relatively simple method is presented for calculating the maximum likeli- hood estimate of the frequencies in the m-way contingency table expected under the model, and for determining whether the parameters in the estimated model are identifiable. In addition, methods are presented for testing whether the model fits the observed data, and for replacing unidentifiable models that fit by identifiable models that fit. Some illus- trative applications to data are also included. This paper deals with the relationships among m polytomous variables, i.e. with the analysis of an m-way contingency table. These m variables are manifest variables in that, for each observed individual in a sample, his class with respect to each of the m variables is observed. We also consider here polytomous variables that are latent in that an individ- ual's class with respect to these variables is not observed. The classes of a latent variable will be called latent classes. Consider first a 4-way contingency table which cross-classifies a sample of n individuals with respect to four manifest polytomous variables A, B, C and D. If there is, say, some latent dichotomous variable X, so that each of the n individuals is in one of the two latent classes with respect to this variable, and within the tth latent class the manifest variables (A, B, C, D) are mutually independent, then this two-class latent structure would serve as a simple explanation of the observed relationships among the variables in the 4-way con- tingency table for the n individuals. There is a direct generalization when the latent variable has T classes. We shall present some relatively simple methods for determining whether the observed relationships among the variables in the m-way contingency table can be explained by a T-class structure, or by various modifications and extensions of this latent structure. To illustrate the methods we analyze Table 1, a 24 contingency table presented earlier by Stouffer & Toby (1951, 1962, 1963), which cross-classifies 216 respondents with respect to whether they tend towards universalistic values ( + ) or particularistic values (-) when confronted by each of four different situations of role conflict. The letters A, B, C and D in"
            },
            "slug": "Exploratory-latent-structure-analysis-using-both-Goodman",
            "title": {
                "fragments": [],
                "text": "Exploratory latent structure analysis using both identifiable and unidentifiable models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2250350"
                        ],
                        "name": "W. Hemmerle",
                        "slug": "W.-Hemmerle",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hemmerle",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hemmerle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 256
                            }
                        ],
                        "text": "Dr Nelder, Dr Preece, Dr Pearce and Mr Healy point out that the rate of convergence of the EM can often be improved in the special case of missing values in ANOVA by \"stretching\" procedures, although apparently at the cost of sacrificing sure convergence (Hemmerle, 1974, 1976)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123271864,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f7e1d6a84b78c7c575ac199ca7f0af0487e7ba4b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A method is developed for computing an exact nonorthogonal analysis of variance using cell means. This is accomplished without forming or using computer storage for X 0, or X\u20320 X 0, or an orthogonal transformation of X 0, where X 0 is the N \u00d7 p nonorthogonal design matrix. The method is a convergent iterative method which utilizes balanced analysis-of-variance estimates and residuals iteratively in solving the relevant normal equations and conducting tests of hypotheses. A monotonicity property of the method is derived to minimize iteration for nonsignificant factors or interactions in hypothesis testing."
            },
            "slug": "Nonorthogonal-Analysis-of-Variance-Using-Iterative-Hemmerle",
            "title": {
                "fragments": [],
                "text": "Nonorthogonal Analysis of Variance Using Iterative Improvement and Balanced Residuals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216687"
                        ],
                        "name": "D. Hosmer",
                        "slug": "D.-Hosmer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hosmer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hosmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122922426,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "054bf5efe7c7800edfa1bbc91a7735929651b011",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "There are few results In the literature on the properties of the maximum likelihood estimates of the parameters of a mixture of two normal distributions when the components are not well separated and the sample size is small. In the present investigation mixtures of two univariate normal distributions with , and sample sizes less than 300 are studied by the Monte Carlo method. For the cases considered, empirical evidtnca is given that the method of maximum likelihood should be used with extreme caution or not at all."
            },
            "slug": "On-mle-of-the-parameters-of-a-mixture-of-two-normal-Hosmer",
            "title": {
                "fragments": [],
                "text": "On mle of the parameters of a mixture of two normal distributions when the sample size is small"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690163"
                        ],
                        "name": "G. McLachlan",
                        "slug": "G.-McLachlan",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "McLachlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. McLachlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "McClachlan (1975) has given a procedure for using unclassified observations in discriminant analysis to help estimate the discriminant function."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120764023,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "59da587c46f695a0b7867b68a22d832ca92999f3",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The construction of a suitable rule of allocation in the two-population discrimination problem is considered in the case where there are initially available from the populations II1, II2, n 1, n 2 observations and M unclassified observations. An iterative reclassification procedure based on the n 1 + n 3 + M observations is proposed and found asymptotically optimal when M \u2192 \u221e and n 1 and n 2 are moderately large. The case of finite M is evaluated by a Monte Carlo experiment which suggests that the proposed procedure, after only one iteration, gives a rule with smaller average risk than the usual rule based on just the n 1 + n 2 classified observations."
            },
            "slug": "Iterative-Reclassification-Procedure-for-An-Optimal-McLachlan",
            "title": {
                "fragments": [],
                "text": "Iterative Reclassification Procedure for Constructing An Asymptotically Optimal Rule of Allocation in Discriminant-Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3396021"
                        ],
                        "name": "B. Turnbull",
                        "slug": "B.-Turnbull",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Turnbull",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Turnbull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152537278"
                        ],
                        "name": "L. Weiss",
                        "slug": "L.-Weiss",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32355687,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "90573f5ba85f9dbf90205c48b2437b3ef476b01f",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A likelihood ratio statistic is proposed for testing goodness of fit with grouped data which are subject to random right censoring. It is shown that, under appropriate conditions, this statistic has an asymptotic chi-square distribution which is non-central under contiguous alternatives. A formula is given for the non-centrality parameter. Two examples are given. The first concerns data from a large scale animal survival study with serial sacrifice where it is attempted to fit the Weibull, Gompertz and exponential power distributions to life length. The second example concerns marijuana usage and this needs an extension of the test to the doubly censored case. Another use of the statistic is to provide a quantitative method of ranking the fit of various proposed models to survival or reliability data."
            },
            "slug": "A-likelihood-ratio-statistic-for-testing-goodness-Turnbull-Weiss",
            "title": {
                "fragments": [],
                "text": "A likelihood ratio statistic for testing goodness of fit with randomly censored data."
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A likelihood ratio statistic is proposed for testing goodness of fit with grouped data which are subject to random right censoring and it is shown that, under appropriate conditions, this statistic has an asymptotic chi-square distribution which is non-central under contiguous alternatives."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2250350"
                        ],
                        "name": "W. Hemmerle",
                        "slug": "W.-Hemmerle",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hemmerle",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hemmerle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103075035"
                        ],
                        "name": "J. Lorens",
                        "slug": "J.-Lorens",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Lorens",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lorens"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Hemmerle and Lorens (1976), for example, show how to discount this effect by a factor of 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 150
                            }
                        ],
                        "text": "\u2026authors' application of EM to estimating variance components displays no advantages for EM over methods described by Hemmerle and Hartley (1973) and Hemmerle and Lorens (1976), which are directly suited to variance components models and take account of their special properties-whereas EM does not."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120727757,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a1e8a66f351670f2d7717afcf5245e2f5f005a5d",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The W transformation greatly reduces the computational bruden in obtaining maximum likelihood estimates for the mixed A.O.V. model. However, effective optimization methods for maximizing the likelihood must comptlte the matrix W at each iteration. This paper develops an efficient Cholesky type algorithm for forming W."
            },
            "slug": "Improved-Algorithm-for-the-W-Transform-in-Variance-Hemmerle-Lorens",
            "title": {
                "fragments": [],
                "text": "Improved Algorithm for the W-Transform in Variance Component Estimation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145908059"
                        ],
                        "name": "E. Beale",
                        "slug": "E.-Beale",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Beale",
                            "middleNames": [
                                "M.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Beale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145382036"
                        ],
                        "name": "R. Little",
                        "slug": "R.-Little",
                        "structuredName": {
                            "firstName": "Roderick",
                            "lastName": "Little",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Little"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 32
                            }
                        ],
                        "text": "Orchard and Woodbury (1972) and Beale and Little (1975) have described a cyclic algorithm for maximum-likelihood estimates, motivated by what Orchard and Woodbury call a \"missing information principle\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 0
                            }
                        ],
                        "text": "Beale and Little (1975) also made use of Jensen's inequality, but in connection with theorems about stationary points. Aspects of the theory consequent on our Lemma 2 were derived by Woodbury (1971) and Orchard and Woodbury (1972) in a general framework, but their concern was with a \"principle\" rather than with the EM algorithm"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 0
                            }
                        ],
                        "text": "Beale and Little (1975) also made use of Jensen's inequality, but in connection with theorems about stationary points."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117414575,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3ce70384499cbc83661726e9a7b9f214a261c6ca",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY This paper presents computational results for some alternative methods of analysing multivariate data with missing values. We recommend an algorithm due to Orchard and Woodbury (1972), which gives an estimator that is maximum likelihood when the data come from a multivariate normal population. We include a derivation of the estimator that does not assume a multivariate normal population, as an iterated form of Buck's (1960) method. We derive an approximate method of assigning standard errors to regression coefficients estimated from incomplete observations, and quote supporting evidence from simulation studies. A brief account is given of the application of these methods to some school examinations data."
            },
            "slug": "Missing-Values-in-Multivariate-Analysis-Beale-Little",
            "title": {
                "fragments": [],
                "text": "Missing Values in Multivariate Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071792670"
                        ],
                        "name": "M. Healy",
                        "slug": "M.-Healy",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Healy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Healy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2294845"
                        ],
                        "name": "M. Westmacott",
                        "slug": "M.-Westmacott",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Westmacott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Westmacott"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 21
                            }
                        ],
                        "text": "A basic reference is Healy and Westmacott (1956)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 67
                            }
                        ],
                        "text": "As I understa6nd him, the algorithm gives the well-known method of Healy and Westmacott (1956), which always converges, though it can be very slow."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67441344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6fbd629bb18a5bf56cc9bd92cbacc1c7903fd57",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Mr Healy and Mr Westmacott describe a general technique for dealing with observations missing from block experiments analysed on automatic computers. When more than one observation is missing the technique is simpler than other methods hitherto described and has been proved in practice to be satisfactorily fast. It is applicable to any analysis in which least\u2010squares estimates are derived."
            },
            "slug": "Missing-Values-in-Experiments-Analysed-on-Automatic-Healy-Westmacott",
            "title": {
                "fragments": [],
                "text": "Missing Values in Experiments Analysed on Automatic Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A general technique for dealing with observations missing from block experiments analysed on automatic computers that is applicable to any analysis in which least\u2010squares estimates are derived."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143924545"
                        ],
                        "name": "W. G. Howe",
                        "slug": "W.-G.-Howe",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Howe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. G. Howe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 69
                            }
                        ],
                        "text": "My own very limited experience of Rao's method (and equally those of Howe, 1955, and Bargmann, 1957) is that convergence is impossibly slow-the iterative corrections are small, but they do not seem to get any smaller as the iteration progresses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 146094830,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0b19782c398690c9f54171ee6ecc86a50b04b1bd",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SOME-CONTRIBUTIONS-TO-FACTOR-ANALYSIS-Howe",
            "title": {
                "fragments": [],
                "text": "SOME CONTRIBUTIONS TO FACTOR ANALYSIS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1955
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143628300"
                        ],
                        "name": "H. Hartley",
                        "slug": "H.-Hartley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Hartley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144725965"
                        ],
                        "name": "R. R. Hocking",
                        "slug": "R.-R.-Hocking",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Hocking",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. R. Hocking"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 140
                            }
                        ],
                        "text": "\u2026matrix is a by-product of the computation of cj*. Professors Carter and Hartley speak to a question raised by Mr Orchard in remarking that Hartley and Hocking (1971) noted the possibility of obtaining an estimate of the asymptotic covariance matrix from successive iterates of the EM\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 20
                            }
                        ],
                        "text": "Theorems 2 and 3 of Hartley and Hocking (1971) prove convergence of the EM algorithm under conditions which are much more restrictive than our conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 136
                            }
                        ],
                        "text": "Finally, I would like to draw the authors' attention to our method of variance estimation (pp. 185-188 in Hartley, 1958; pp. 796-798 in Hartley and Hocking, 1971) which utilizes the iterates in the EM algorithm directly for the estimation of the elements of the variance matrix and this potential of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "Convergence ofthe EM algorithm inspecial cases is discussed by Hartley and Hocking (1971) and by Sundberg (1976)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Hartley and Hocking (1971) assume there is no ridge in g(y l 4O), and we point out that convergence generally obtains even when this condition fails."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122886115,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c807c29ca15416b7fe138057762360acc4260bc5",
            "isKey": true,
            "numCitedBy": 310,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we attempt to provide a simple taxonomy for incomplete-data problems and at the same time develop unified methods of analysis. The emphasis is on techniques which are natural extensions of the complete-data analysis and which will handle rather general classes of incomplete-data problems as opposed to custom-made techniques for special problems. The principle of estimation is either maximum likelihood or is at least based on maximum likelihood."
            },
            "slug": "The-analysis-of-incomplete-data.-Hartley-Hocking",
            "title": {
                "fragments": [],
                "text": "The analysis of incomplete data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3396021"
                        ],
                        "name": "B. Turnbull",
                        "slug": "B.-Turnbull",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Turnbull",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Turnbull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 13
                            }
                        ],
                        "text": "TURNBULL, B. W. (1974)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120804336,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5b683f3aa41d148c6a4ec1c180547c4ad8a66e9f",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A simple iterative procedure is proposed for obtaining estimates of a response time distribution when some of the data are censored on the left and some on the right. The procedure is based on the product-limit method of Kaplan and Meier [15], and it also uses the idea of self-consistency due to Efron [8]. Under fairly general assumptions, the method is shown to yield unique consistent maximum likelihood estimators. Asymptotic expressions for their variances and covariances are derived and an extension to the case of arbitrary censoring is suggested."
            },
            "slug": "Nonparametric-Estimation-of-a-Survivorship-Function-Turnbull",
            "title": {
                "fragments": [],
                "text": "Nonparametric Estimation of a Survivorship Function with Doubly Censored Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3396021"
                        ],
                        "name": "B. Turnbull",
                        "slug": "B.-Turnbull",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Turnbull",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Turnbull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 68
                            }
                        ],
                        "text": "Efron (1967) proposed the EM algorithm for singly censored ata, and Turnbull (1974, 1976) extended Efron's approach to arbitrarily grouped, censored and truncated data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "Both likelihoods are calculated using the EM algorithm or, equivalently, \"self-consistency\" (Turnbull, 1976)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122426592,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9d59e5c5d029345e176da0351a0831b9cf762096",
            "isKey": false,
            "numCitedBy": 1630,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY This paper is concerned with the non-parametric estimation of a distribution function F, when the data are incomplete due to grouping, censoring and/or truncation. Using the idea of self-consistency, a simple algorithm is constructed and shown to converge monotonically to yield a maximum likelihood estimate of F. An application to hypothesis testing is indicated."
            },
            "slug": "The-Empirical-Distribution-Function-with-Grouped,-Turnbull",
            "title": {
                "fragments": [],
                "text": "The Empirical Distribution Function with Arbitrarily Grouped, Censored, and Truncated Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 250
                            }
                        ],
                        "text": "When the data are a sample from a multivariate normal population, there do not exist explicit closed-form expressions for the maximum-likelihood estimates of the means, variances and covariances of the normal population, except in cases discussed by Rubin (1974)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 141
                            }
                        ],
                        "text": "A final possibility arises with missing data patterns such that factors of the likelihood have their own distinct collections of parameters (Rubin, 1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122597405,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d42420791f6ee3da841cb891ff5404525c81a293",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract A framework is given for organizing and understanding the problems of estimating the parameters of a multivariate data set which contains blocks of missing observations. The basic technique is to decompose the original estimation problem into smaller estimation problems by factoring the likelihood of the observed data into a product of likelihoods. The result is summarized in a \u201cfactorization table,\u201d which identifies the \u201ccomplete-data\u201d factors whose parameters may be estimated using standard, well-understood complete-data techniques, and the \u201cincomplete-data\u201d factors whose parameters must be estimated using special missing-data methods."
            },
            "slug": "Characterizing-the-Estimation-of-Parameters-in-Rubin",
            "title": {
                "fragments": [],
                "text": "Characterizing the Estimation of Parameters in Incomplete-Data Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A framework is given for organizing and understanding the problems of estimating the parameters of a multivariate data set which contains blocks of missing observations by factoring the likelihood of the observed data into a product of likelihoods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50584571"
                        ],
                        "name": "B. Blight",
                        "slug": "B.-Blight",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Blight",
                            "middleNames": [
                                "J.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Blight"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 615,
                                "start": 15
                            }
                        ],
                        "text": "A key paper is Blight (1970) which treats exponential families in general, and explicitly recognizes the appealing two-step interpretation of each EM iteration. Efron (1967) proposed the EM algorithm for singly censored data, and Turnbull (1974, 1976) extended Efron's approach to arbitrarily grouped, censored and truncated data. Although Grundy and Blight formally include truncation in their discussion, they appear to be suggesting the first level of complete-data modelling, as in (4.2.2), rather than the second level, as in (4.2.4). The second-level specification was used in special cases by Hartley (1958) and Irwin (1959, 1963)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 15
                            }
                        ],
                        "text": "A key paper is Blight (1970) which treats exponential families in general, and explicitly recognizes the appealing two-step interpretation of each EM iteration."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 684,
                                "start": 15
                            }
                        ],
                        "text": "A key paper is Blight (1970) which treats exponential families in general, and explicitly recognizes the appealing two-step interpretation of each EM iteration. Efron (1967) proposed the EM algorithm for singly censored data, and Turnbull (1974, 1976) extended Efron's approach to arbitrarily grouped, censored and truncated data. Although Grundy and Blight formally include truncation in their discussion, they appear to be suggesting the first level of complete-data modelling, as in (4.2.2), rather than the second level, as in (4.2.4). The second-level specification was used in special cases by Hartley (1958) and Irwin (1959, 1963). Irwin ascribes the idea to McKendrick (1926). The special cases concern truncated zero-frequency counts for Poisson and negative-binomial samples."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 15
                            }
                        ],
                        "text": "A key paper is Blight (1970) which treats exponential families in general, and explicitly recognizes the appealing two-step interpretation of each EM iteration. Efron (1967) proposed the EM algorithm for singly censored data, and Turnbull (1974, 1976) extended Efron's approach to arbitrarily grouped, censored and truncated data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 121587473,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a155842318383cbceb3623afd4571f014764b692",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "SUMMARY The likelihood equations are derived for the estimation of the parameters of an exponential family from a Type I censored sample and are shown to have an interpretation which suggests a particular iterative method of solution. Some results relevant to the convergence properties of this method are given and the asymptotic variance-covariance matrix is derived. The method is illustrated by an example in which it is compared with an alternative method in the case of estimation for a doubly censored normal distribution."
            },
            "slug": "Estimation-from-a-censored-sample-for-the-family-Blight",
            "title": {
                "fragments": [],
                "text": "Estimation from a censored sample for the exponential family"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375512"
                        ],
                        "name": "J. Wolfe",
                        "slug": "J.-Wolfe",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wolfe",
                            "middleNames": [
                                "Harmon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wolfe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 11
                            }
                        ],
                        "text": "Except hat Wolfe (1970) referred toHasselblad (1966), all these authors apparently worked independently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 76
                            }
                        ],
                        "text": "These models include the clustering or latent-structure models discussed by Wolfe (1970), but permit more general and quite complex finite-mixture models, depending on the complexity ofthe complete-data log-linear model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Wolfe (1970) suggested the use of Aitken's acceleration process to improve the rate of convergence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 117
                            }
                        ],
                        "text": "Day (1969) considered mixtures of two multivariate normal populations with a common unknown covariance matrix, while Wolfe (1970) studied mixtures of binomials and mixtures of arbitrary multivariate normal distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10677033,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "00b7d7d6ef41b2ef0f2d1fd07e190c9132b562c6",
            "isKey": true,
            "numCitedBy": 640,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Cluster analysis is reformulated as a problem of estimating the para- meters of a mixture of multivariate distributions. The maximum-likelihood theory and numerical solution techniques are developed for a fairly general class of distributions. The theory is applied to mixtures of multivariate nor- mals (NORMIX) and mixtures of multivariate Bernoulli distributions (Latent Classes). The feasibility of the procedures is demonstrated by two examples of computer solutions for normal mixture models of the Fisher Iris data and of artifjcially generated clusters with unequal covariance matrices."
            },
            "slug": "PATTERN-CLUSTERING-BY-MULTIVARIATE-MIXTURE-Wolfe",
            "title": {
                "fragments": [],
                "text": "PATTERN CLUSTERING BY MULTIVARIATE MIXTURE ANALYSIS."
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The maximum-likelihood theory and numerical solution techniques are developed for a fairly general class of distributions and the feasibility of the procedures is demonstrated by two examples of computer solutions for normal mixture models of the Fisher Iris data and of artify generated clusters with unequal covariance matrices."
            },
            "venue": {
                "fragments": [],
                "text": "Multivariate behavioral research"
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120971461,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "7ce10624b09c54d2604f60b4c2d48409201fcc5b",
            "isKey": false,
            "numCitedBy": 5012,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Two results are presented concerning inference when data may be missing. First, ignoring the process that causes missing data when making sampling distribution inferences about the parameter of the data, \u03b8, is generally appropriate if and only if the missing data are \u201cmissing at random\u201d and the observed data are \u201cobserved at random,\u201d and then such inferences are generally conditional on the observed pattern of missing data. Second, ignoring the process that causes missing data when making Bayesian inferences about \u03b8 is generally appropriate if and only if the missing data are missing at random and the parameter of the missing data is \u201cindependent\u201d of \u03b8. Examples and discussion indicating the implications of these results are included."
            },
            "slug": "INFERENCE-AND-MISSING-DATA-Rubin",
            "title": {
                "fragments": [],
                "text": "INFERENCE AND MISSING DATA"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40159987"
                        ],
                        "name": "N. Draper",
                        "slug": "N.-Draper",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Draper",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Draper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32214870"
                        ],
                        "name": "I. Guttman",
                        "slug": "I.-Guttman",
                        "structuredName": {
                            "firstName": "Irwin",
                            "lastName": "Guttman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guttman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 90
                            }
                        ],
                        "text": "The applicati-ons have been many and varied-as two examples amongst a host of others, see Draper and Guttman (1968) for its use in an allocation problem in sample survey, and Guttman (1971) for an application involving optimum regression designs, Indeed, the above is just another way of looking at\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36768768,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cfa25dd2413590a0742a23b13555f040be4ddf61",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : In this paper we obtain some results concerning the optimum allocation of sampling effort among k strata at the second phase of a two phase sampling procedure, using information obtained from the first phase. Two different approaches are employed; a Bayesian posterior analysis and a Bayesian preposterior analysis. Two different allocation methods are derived and illustrated with some numerical examples, for cases where some or all of the nuisance parameters are unknown. The problem when all nuisance parameters are known has been discussed by Ericson (1965). (Author)"
            },
            "slug": "Some-Bayesian-stratified-two-phase-sampling-Draper-Guttman",
            "title": {
                "fragments": [],
                "text": "Some Bayesian stratified two-phase sampling results."
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "Some results are obtained concerning the optimum allocation of sampling effort among k strata at the second phase of a two phase sampling procedure, using information obtained from the first phase."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrika"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102488892"
                        ],
                        "name": "Tar Chen",
                        "slug": "Tar-Chen",
                        "structuredName": {
                            "firstName": "Tar",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tar Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684961"
                        ],
                        "name": "S. Fienberg",
                        "slug": "S.-Fienberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Fienberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fienberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 56
                            }
                        ],
                        "text": "When I worked with a special case of the algorithm (see Chen and Fienberg, 1976), my co-author and I were unable to deal properly with the convergence properties."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125052870,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "89302c1b750307880315dc8e069435173dea9f11",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In many practical situations, investigators are forced to study the structure underlying the crossclassification of several categorical variables via tables of observed counts in which the observations corresponding to certain sets of cells are indistinguishable. Methods are presented for the analysis of such contingency tables with incompletely cross-classified data via loglinear models. The method of maximum likelihood is used to estimate the expected cell counts which are then used to test the goodness-of-fit of the model. Extensions to incomplete (or truncated) contingency tables are indicated and several examples are given."
            },
            "slug": "The-Analysis-of-Contingency-Tables-with-Classified-Chen-Fienberg",
            "title": {
                "fragments": [],
                "text": "The Analysis of Contingency Tables with Incompletely Classified Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152590738"
                        ],
                        "name": "James K. Martin",
                        "slug": "James-K.-Martin",
                        "structuredName": {
                            "firstName": "James K.",
                            "lastName": "Martin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James K. Martin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144686124"
                        ],
                        "name": "R. P. McDonald",
                        "slug": "R.-P.-McDonald",
                        "structuredName": {
                            "firstName": "Roderick",
                            "lastName": "McDonald",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. P. McDonald"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 118
                            }
                        ],
                        "text": "It is sometimes desirable to place a prior distribution o the uniquenesses to avoid the occurrence of zero estimates (Martin and McDonald, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121067245,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "688a08610c59ee1823ea272c5cbf0f6cae0eb235",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A Bayesian procedure is given for estimation in unrestricted common factor analysis. A choice of the form of the prior distribution is justified. It is shown empirically that the procedure achieves its objective of avoiding inadmissible estimates of unique variances, and is reasonably insensitive to certain variations in the shape of the prior distribution."
            },
            "slug": "Bayesian-estimation-in-unrestricted-factor-A-for-Martin-McDonald",
            "title": {
                "fragments": [],
                "text": "Bayesian estimation in unrestricted factor analysis: A treatment for heywood cases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119142953"
                        ],
                        "name": "S. Khamis",
                        "slug": "S.-Khamis",
                        "structuredName": {
                            "firstName": "Samar",
                            "lastName": "Khamis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khamis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47976263"
                        ],
                        "name": "F. Mosteller",
                        "slug": "F.-Mosteller",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Mosteller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mosteller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144087709"
                        ],
                        "name": "D. L. Wallace",
                        "slug": "D.-L.-Wallace",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wallace",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. L. Wallace"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124790138,
            "fieldsOfStudy": [
                "Sociology",
                "Computer Science",
                "Mathematics",
                "Political Science",
                "Philosophy"
            ],
            "id": "d6fb495cbb103c36608147a1eafa95988b75d2d2",
            "isKey": false,
            "numCitedBy": 700,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The 1964 publication of \"Inference and Disputed Authorship\" made the cover of \"Time\" magazine and drew the attention of academics and the public alike for its use of statistical methodology to solve one of American history's most notorious questions: the disputed authorship of the \"Federalist Papers\". Back in print for a new generation of readers, this classic volume applies mathematics, including the once-controversial Bayesian analysis, to the heart of a literary and historical problem by studying frequently used words in the texts. The reissue of this landmark book will be welcomed by anyone interested in the juncture of history, political science, and authorship."
            },
            "slug": "Inference-and-Disputed-Authorship:-The-Federalist-Khamis-Mosteller",
            "title": {
                "fragments": [],
                "text": "Inference and Disputed Authorship: The Federalist"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1886648"
                        ],
                        "name": "M. Woodbury",
                        "slug": "M.-Woodbury",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Woodbury",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Woodbury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 64
                            }
                        ],
                        "text": "Some of the theory underlying the EM algorithm was presented by Orchard and Woodbury (1972), and by Sundberg (1976), and some has remained buried in the literature of special examples, notably in Baum et al. (1970)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 84
                            }
                        ],
                        "text": "Aspects of the theory consequent on our Lemma 2 were derived by Woodbury (1971) and Orchard and Woodbury (1972) in a general framework, but their concern was with a \"principle\" rather than with the EM algorithm\nThis content downloaded on Fri, 1 Mar 2013 09:19:07 AM All use subject to JSTOR Terms\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Orchard and Woodbury (1972) discussed finite-mixture p oblems in a non-exponentialfamily framework."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 0
                            }
                        ],
                        "text": "Orchard and Woodbury (1972) and Beale and Little (1975) have described a cyclic algorithm for maximum-likelihood estimates, motivated by what Orchard and Woodbury call a \"missing information principle\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29658842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69f0ea1b895da0e68e05b57b97052cec2953a58e",
            "isKey": true,
            "numCitedBy": 466,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The problem that a relatively simple analysis is changed into a complex one just because some of the information is missing, is one which faces most practicing statisticians at some point in their career. Obviously the best way to treat missing information problems is not to have them. Unfortunately circumstances arise in which information is missing and nothing can be done to replace it for one reason or another."
            },
            "slug": "A-missing-information-principle:-theory-and-Woodbury",
            "title": {
                "fragments": [],
                "text": "A missing information principle: theory and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "The problem that a relatively simple analysis is changed into a complex one just because some of the information is missing, is one which faces most practicing statisticians at some point in their career."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145414560"
                        ],
                        "name": "E. Thompson",
                        "slug": "E.-Thompson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Thompson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 177
                            }
                        ],
                        "text": "This content downloaded on Fri, 1 Mar 2013 09:19:07 AM All use subject to JSTOR Terms and Conditions\n34 Discussion on the Paper by Professor Dempster et al. [No. 1,\nOn p. 68 of Thompson (1975) an iterative solution is proposed."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 72
                            }
                        ],
                        "text": "I refer to the modification of the model of Edwards (1970) discussed by Thompson (1975)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1116617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a29ef568a905f411f51e221d50727561467140fd",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Inference and the evolutionary tree problem 2. The model 3. The likelihood approach 4. A likelihood solution 5. Further aspects of the problem and its likelihood solution 6. The Icelandic admixture problem Summary References References index Subject index."
            },
            "slug": "Human-Evolutionary-Trees-Thompson",
            "title": {
                "fragments": [],
                "text": "Human Evolutionary Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The model helps clarify the origins of theIcelandic admixture problem and provide a likely solution to the Inference and the evolutionary tree problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 5
                            }
                        ],
                        "text": "The EM algorithm has often been used for least-squares estimation in analysis of variance designs, or equivalently for maximum-likelihood estimation under the normal linear model with given residual variance u2, whatever the value of u2. A basic reference is Healy and Westmacott (1956). The key idea is that exact least-squares computations are easily performed for special design matrices which incorporate the requisite balance and orthogonality properties, while least-squares computations for unbalanced designs require the inversion of a large matrix."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 437,
                                "start": 3
                            }
                        ],
                        "text": "Formula (2.13) is the key to understanding the E-and M-steps of the EM algorithm, for if the algorithm converges to +*, so that in the limit + ( p ) = +(p+l) = +*, then combining (2.2) and (2.3) leads to E(t I +*) '= E(t 1 y, +*) or DL(+) = 0 at + = +*. The striking representation (2.13) has been noticed in special cases by many authors. Examples will be mentioned in Section 4. The general form of (2.13) was given by Sundberg (1974) who ascribed it to unpublished 1966 lecture notes of Martin-Lof."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 413,
                                "start": 4
                            }
                        ],
                        "text": "A common problem with multivariate cccontinuous\" data is that different individuals are observed on different subsets of a complete set of variables. When the data are a sample from a multivariate normal population, there do not exist explicit closed-form expressions for the maximum-likelihood estimates of the means, variances and covariances of the normal population, except in cases discussed by Rubin (1974). Orchard and Woodbury (1972) and Beale and Little (1975) have described a cyclic algorithm for maximum-likelihood estimates, motivated by what Orchard and Woodbury call a \"missing information principle\"."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 975,
                                "start": 12
                            }
                        ],
                        "text": "Since the complete-data log-likelihood is linear in the components of each zi, the E-step of the EM algorithm requires us to estimate the components of zi given the observed y and the current fitted parameters. These estimated components of zi are simply the current conditional probabilities that yi belongs to each of the R states. In many examples, the d, parameters of u(. . . Id,) and v(. ..Id,) are unrelated, so that the first and second terms in (4.3.3) may be maximized separately. The M-step is then equivalent to the complete-data maximization for the problem except that each observation y, contributes to the log-likelihood associated with each of the R states, with weights given by the R estimated components of z,, and the counts in the R states are the sums of the estimated components of the zi. The most widely studied examples of this formulation concern random samples from a mixture of normal distributions or other standard families. Hasselblad (1966) discussed mixtures of R normals, and subsequently Hasselblad (1969) treated more general random sampling models, giving as examples mixtures of Poissons, binomials and exponentials."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 20
                            }
                        ],
                        "text": "Convergence of the EM algorithm in special cases is discussed by Hartley and Hocking (1971) and by Sundberg (1976)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 482,
                                "start": 4
                            }
                        ],
                        "text": "The M-step then becomes the usual estimation of 4 from the observed and assigned values of the indicators summed over the units. In practice, it is convenient to collect together those units with the same pattern of missing indicators, since the filled in fractional counts will be the same for each; hence one may think of the procedure as filling in estimated counts for each of the missing cells within each group of units having the same pattern of missing data. Hartley (1958) treated two restricted multinomial cases, namely, sampling from a Poisson population and sampling from a binomial population."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 20
                            }
                        ],
                        "text": "Convergence of the EM algorithm in special cases is discussed by Hartley and Hocking (1971) and by Sundberg (1976). We note that Hartley and Hocking must rule out ridges in L(+) as a condition of their convergence theorem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 5
                            }
                        ],
                        "text": "The EM algorithm has been proposed many times in special circumstances. For example, Hartley (1958) gave three multinomial examples similar to our illustrative example."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Identification of the sources of significance in two-way tables"
            },
            "venue": {
                "fragments": [],
                "text": "Appl. Statist., 23, 4 5 - 4 1 3 ."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101775270"
                        ],
                        "name": "T. Petrie",
                        "slug": "T.-Petrie",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Petrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Petrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102329511"
                        ],
                        "name": "George W. Soules",
                        "slug": "George-W.-Soules",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Soules",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George W. Soules"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063108982"
                        ],
                        "name": "Norman Weiss",
                        "slug": "Norman-Weiss",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norman Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "Lemma 1 and its consequence Theorem 1 were presented by Baum et al. (1970) in an unusual special case (see Section 4.3 below), but apparently without recognition ofthe broad generality oftheir argument."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 3
                            }
                        ],
                        "text": "In Baum et al. (1970) we have: let\nP(A) = Ifp(x, A) du(x) and Q(A, A') p(x, A) log p(x, A') d (x)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 267
                            }
                        ],
                        "text": "\u2026AM All use subject to JSTOR Terms and Conditions\n1977] DEMPSTER et a!. - Maximum Likelihoodfrom Incomplete Data 17 Finally, we mention another independent special derivation of the EM method for finite mixtures developed in a series of papers (Baum and Eagon, 1967; Baum et al., 1970; Baum, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "We did not intend to suggest hat the mathematical results of Baum et al. (1970) are of limited mathematical generality, but only that the wide range of application of these results to statistical problems was not recognized in their article."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 216
                            }
                        ],
                        "text": "It can be shown that if +(p) possesses (a) and (b) then 8 = 1/(t+ 1) achieves monotonicity if\nOtz(X) > ,() (2) where\np(r - 1), [A = p(r), 0,, (X) = PO fA O) = Ai(aolaAi)ll(t+l)(aolay )tl(t+l) This in turn is true by Baum et al. (1970) if +t (?"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "\u2026to JSTOR Terms and Conditions\n1977] Discussion on the Paper by Professor Dempster et al. 29 \"Lemma 1 and its consequence Theorem 1 were presented by Baum et al. (1970) in an unusual special case (see Section 4.3 below), but apparently without recognition of the broad generality of their argument.\""
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 196
                            }
                        ],
                        "text": "Some of the theory underlying the EM algorithm was presented by Orchard and Woodbury (1972), and by Sundberg (1976), and some has remained buried in the literature of special examples, notably in Baum et al. (1970)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 122568650,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3092a4929bdb3d6a8fe53f162586b7431b5ff8a4",
            "isKey": true,
            "numCitedBy": 4551,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Maximization-Technique-Occurring-in-the-Analysis-Baum-Petrie",
            "title": {
                "fragments": [],
                "text": "A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 56
                            }
                        ],
                        "text": "Lemma 1 and its consequence Theorem 1 were presented by Baum et al. (1970) in an unusual special case (see Section 4.3 below), but apparently without recognition ofthe broad generality oftheir argument."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 3
                            }
                        ],
                        "text": "In Baum et al. (1970) we have: let\nP(A) = Ifp(x, A) du(x) and Q(A, A') p(x, A) log p(x, A') d (x)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 267
                            }
                        ],
                        "text": "\u2026AM All use subject to JSTOR Terms and Conditions\n1977] DEMPSTER et a!. - Maximum Likelihoodfrom Incomplete Data 17 Finally, we mention another independent special derivation of the EM method for finite mixtures developed in a series of papers (Baum and Eagon, 1967; Baum et al., 1970; Baum, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 61
                            }
                        ],
                        "text": "We did not intend to suggest hat the mathematical results of Baum et al. (1970) are of limited mathematical generality, but only that the wide range of application of these results to statistical problems was not recognized in their article."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 216
                            }
                        ],
                        "text": "It can be shown that if +(p) possesses (a) and (b) then 8 = 1/(t+ 1) achieves monotonicity if\nOtz(X) > ,() (2) where\np(r - 1), [A = p(r), 0,, (X) = PO fA O) = Ai(aolaAi)ll(t+l)(aolay )tl(t+l) This in turn is true by Baum et al. (1970) if +t (?"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "\u2026to JSTOR Terms and Conditions\n1977] Discussion on the Paper by Professor Dempster et al. 29 \"Lemma 1 and its consequence Theorem 1 were presented by Baum et al. (1970) in an unusual special case (see Section 4.3 below), but apparently without recognition of the broad generality of their argument.\""
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 196
                            }
                        ],
                        "text": "Some of the theory underlying the EM algorithm was presented by Orchard and Woodbury (1972), and by Sundberg (1976), and some has remained buried in the literature of special examples, notably in Baum et al. (1970)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A maximization technique occurring"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5992254"
                        ],
                        "name": "A. Basilevsky",
                        "slug": "A.-Basilevsky",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Basilevsky",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Basilevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89161743"
                        ],
                        "name": "D. Lawley",
                        "slug": "D.-Lawley",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Lawley",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lawley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102867611"
                        ],
                        "name": "A. E. Maxwell",
                        "slug": "A.-E.-Maxwell",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Maxwell",
                            "middleNames": [
                                "Ernest"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. E. Maxwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 36
                            }
                        ],
                        "text": "The J6reskog algorithm described in Lawley and Maxwell (1971) is specifically designed to handle such problems, while it appears that the version of the EM algorithm outlined in Section 4.7 may be stopped long before a Heywood case can be recognized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67720139,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "d4d48fe00800e03fa44e066264a7524fa09af166",
            "isKey": true,
            "numCitedBy": 907,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Factor-Analysis-as-a-Statistical-Method.-Basilevsky-Lawley",
            "title": {
                "fragments": [],
                "text": "Factor Analysis as a Statistical Method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6964430"
                        ],
                        "name": "N. Mantel",
                        "slug": "N.-Mantel",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Mantel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mantel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4548701"
                        ],
                        "name": "S. Greenhouse",
                        "slug": "S.-Greenhouse",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Greenhouse",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Greenhouse"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 47
                            }
                        ],
                        "text": "Notation and relevant formulas may be found in Mantel and Greenhouse (1967) whose purpose was to remark on the special interpretation of the likelihood equations which is given in our general formula (2.13)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5376710,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ff3448a8f0da4d2241fd3953cb6d05319107250e",
            "isKey": true,
            "numCitedBy": 4,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Equivalence-of-maximum-likelihood-and-the-method-of-Mantel-Greenhouse",
            "title": {
                "fragments": [],
                "text": "Equivalence of maximum likelihood and the method of moments in probit analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 138
                            }
                        ],
                        "text": "The maximum-likelihood equation for the model of (1.2) is\n125 18 20 +34=o. 2 + -a 1--7r 1-7 T 7V\nAs M. C. K. Tweedie suggested (1945, see Smith, 1969, pp. 421-423) by replacing each term by its reciprocal we get the easily solvable linear equation\n2+-a 1--a 1- 7r 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Biomathematics, Vol"
            },
            "venue": {
                "fragments": [],
                "text": "2. London: Griffin."
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 140
                            }
                        ],
                        "text": "\u2026matrix is a by-product of the computation of cj*. Professors Carter and Hartley speak to a question raised by Mr Orchard in remarking that Hartley and Hocking (1971) noted the possibility of obtaining an estimate of the asymptotic covariance matrix from successive iterates of the EM\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 20
                            }
                        ],
                        "text": "Theorems 2 and 3 of Hartley and Hocking (1971) prove convergence of the EM algorithm under conditions which are much more restrictive than our conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 136
                            }
                        ],
                        "text": "Finally, I would like to draw the authors' attention to our method of variance estimation (pp. 185-188 in Hartley, 1958; pp. 796-798 in Hartley and Hocking, 1971) which utilizes the iterates in the EM algorithm directly for the estimation of the elements of the variance matrix and this potential of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "Convergence ofthe EM algorithm inspecial cases is discussed by Hartley and Hocking (1971) and by Sundberg (1976)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Hartley and Hocking (1971) assume there is no ridge in g(y l 4O), and we point out that convergence generally obtains even when this condition fails."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation for the mixed analysis"
            },
            "venue": {
                "fragments": [],
                "text": "The analysis of incomplete data. Biometrics,"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 45
                            }
                        ],
                        "text": "The algorithm was also recently suggested by Brown (1974) for computing the maximum-likelihood estimates of expected cell frequencies under an independence model in a two-way table with some missing cells, and by Fienberg and Chen (1976) for the special case of cross-classified data with some\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "For example, when the version of the EM algorithm proposed by Brown (1974) is used for estimation in the model of quasi-independence in square Ix I contingency tables with missing diagonals, it is distinctly superior to the standard iterative proportional fitting algorithm described in Bishop et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 45
                            }
                        ],
                        "text": "The algorithm was also recently suggested by Brown (1974) for computing the maximum-likelihood estimates of expected cell frequencies under an independence model in a two-way table with some missing cells, and by Fienberg and Chen (1976) for the special case of cross-classified data with some observations only partially classified."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 69
                            }
                        ],
                        "text": "In the examples we looked at, easily-the quickest method was that of Brown (1974), although it may not always be monotonic for 0, in which the missing cells are treated one by one."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Identification of the sources of significance in two-way tables"
            },
            "venue": {
                "fragments": [],
                "text": "Appl. Statist., 23,"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Haberman (1976) presented an interesting example which includes both multinomial missing values (Section 3.1.1) and finite mixtures: ampling from a multiway contingency table where the population cell frequencies are specified by a log-linear model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Iterative scaling procedures for log-linear models for frequency tables derived by"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 47
                            }
                        ],
                        "text": "Notation and relevant formulas may be found in Mantel and Greenhouse (1967) whose purpose was to remark on the special interpretation of the likelihood equations which is given in our general formula (2.13)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Note: Equivalence of maximum likelihood and the method"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 140
                            }
                        ],
                        "text": "\u2026matrix is a by-product of the computation of cj*. Professors Carter and Hartley speak to a question raised by Mr Orchard in remarking that Hartley and Hocking (1971) noted the possibility of obtaining an estimate of the asymptotic covariance matrix from successive iterates of the EM\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 20
                            }
                        ],
                        "text": "Theorems 2 and 3 of Hartley and Hocking (1971) prove convergence of the EM algorithm under conditions which are much more restrictive than our conditions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 136
                            }
                        ],
                        "text": "Finally, I would like to draw the authors' attention to our method of variance estimation (pp. 185-188 in Hartley, 1958; pp. 796-798 in Hartley and Hocking, 1971) which utilizes the iterates in the EM algorithm directly for the estimation of the elements of the variance matrix and this potential of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "Convergence ofthe EM algorithm inspecial cases is discussed by Hartley and Hocking (1971) and by Sundberg (1976)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Hartley and Hocking (1971) assume there is no ridge in g(y l 4O), and we point out that convergence generally obtains even when this condition fails."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1971) assume there is no ridge in g(y l 4O), and we point out"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33369069"
                        ],
                        "name": "J. Gower",
                        "slug": "J.-Gower",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gower",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gower"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89161743"
                        ],
                        "name": "D. Lawley",
                        "slug": "D.-Lawley",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Lawley",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lawley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102867611"
                        ],
                        "name": "A. E. Maxwell",
                        "slug": "A.-E.-Maxwell",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Maxwell",
                            "middleNames": [
                                "Ernest"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. E. Maxwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 150351456,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bcf16685fb1a401dbbbe2892af251cc887baacd4",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Factor-Analysis-as-a-Statistical-Method.-2nd-ed.-Gower-Lawley",
            "title": {
                "fragments": [],
                "text": "Factor Analysis as a Statistical Method. 2nd ed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50336442"
                        ],
                        "name": "G. W. Snedecor",
                        "slug": "G.-W.-Snedecor",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Snedecor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. W. Snedecor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221430447,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "092500ba9f19ac6f963c518371c1d0c30396deb1",
            "isKey": false,
            "numCitedBy": 6886,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "STATISTICAL-METHODS-Snedecor",
            "title": {
                "fragments": [],
                "text": "STATISTICAL METHODS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145671626"
                        ],
                        "name": "S. Pearce",
                        "slug": "S.-Pearce",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Pearce",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pearce"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144771934"
                        ],
                        "name": "J. Jeffers",
                        "slug": "J.-Jeffers",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Jeffers",
                            "middleNames": [
                                "N.",
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jeffers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 193
                            }
                        ],
                        "text": "I refer to the use of the multiplier, lle, where e is the error sum of squares from the analysis of variance of p, a pseudo-variate having one for the plot in question and zero for all others (Pearce and Jeffers, 1971; Rubin, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 126231584,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "975cb870d54cd32052a8f1edf09f2b861ad3e0fd",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Block-Designs-and-Missing-Data-Pearce-Jeffers",
            "title": {
                "fragments": [],
                "text": "Block Designs and Missing Data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125385534,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "777bdf51061a66947b51d0712c58704930fb121f",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-Estimation-of-Small-Frequencies-in-Tables-Good",
            "title": {
                "fragments": [],
                "text": "On the Estimation of Small Frequencies in Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 219
                            }
                        ],
                        "text": "I refer to the use of the multiplier, lle, where e is the error sum of squares from the analysis of variance of p, a pseudo-variate having one for the plot in question and zero for all others (Pearce and Jeffers, 1971; Rubin, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 126266567,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a310a649a6597fdf9cb38ab62ee42c8abfb59e4c",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Non\u2010Iterative-Algorithm-for-Least-Squares-of-in-Rubin",
            "title": {
                "fragments": [],
                "text": "A Non\u2010Iterative Algorithm for Least Squares Estimation of Missing Values in Any Analysis of Variance Design"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120055200"
                        ],
                        "name": "R. Little",
                        "slug": "R.-Little",
                        "structuredName": {
                            "firstName": "Roderick",
                            "lastName": "Little",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Little"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 134
                            }
                        ],
                        "text": "Perhaps a more promising application lies in estimation of autoregressive models for time series with missing values, as suggested in Little (1974)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125677708,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "e9438968b1f52ac632133b8010afa7fde7a07d94",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Missing-values-in-multivariate-statistical-analysis-Little",
            "title": {
                "fragments": [],
                "text": "Missing values in multivariate statistical analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216687"
                        ],
                        "name": "D. Hosmer",
                        "slug": "D.-Hosmer",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hosmer",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hosmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124275211,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "97096bd37f85b741268cdd526025c96dbf36bc76",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Comparison-of-Iterative-Maximum-Likelihood-of-the-Hosmer",
            "title": {
                "fragments": [],
                "text": "A Comparison of Iterative Maximum Likelihood Estimates of the Parameters of a Mixture of Two Normal Distributions Under Three Different Types of Sample"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145772404"
                        ],
                        "name": "J. O. Irwin",
                        "slug": "J.-O.-Irwin",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Irwin",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O. Irwin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 79
                            }
                        ],
                        "text": "The second-level specification was used in special cases by Hartley (1958) and Irwin (1959, 1963)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123219683,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "afab882735b4fe1a7f9ab786267301b8e1ab89ca",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "138.-Note:-On-the-Estimation-of-the-Mean-of-a-from-Irwin",
            "title": {
                "fragments": [],
                "text": "138. Note: On the Estimation of the Mean of a Poisson Distribution from a Sample with the Zero Class Missing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144182476"
                        ],
                        "name": "C. Robertson",
                        "slug": "C.-Robertson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Robertson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144381490"
                        ],
                        "name": "D. F. Andrews",
                        "slug": "D.-F.-Andrews",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Andrews",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. F. Andrews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678771"
                        ],
                        "name": "P. Bickel",
                        "slug": "P.-Bickel",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bickel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bickel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104460068"
                        ],
                        "name": "F. R. Hanpel",
                        "slug": "F.-R.-Hanpel",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Hanpel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. R. Hanpel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48897539"
                        ],
                        "name": "P. J. Huber",
                        "slug": "P.-J.-Huber",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Huber",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. J. Huber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153166837"
                        ],
                        "name": "W. Rogers",
                        "slug": "W.-Rogers",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Rogers",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016914"
                        ],
                        "name": "J. Tukey",
                        "slug": "J.-Tukey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tukey",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tukey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "Other examples of \"normal/independent\" densities, such as the \"normal/ uniform\" or the contaminated normal distribution may be found in Chapter 4 of Andrews et al. (1972). First suppose h(q,) is free of unknown parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 148
                            }
                        ],
                        "text": "Other examples of \"normal/independent\" densities, uch as the \"normal/ uniform\" or the contaminated normal distribution may be found in Chapter 4 of Andrews et al. (1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124605509,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "8f4f0dbeee722c263ba9f9f82a75fb48bd3d4aa1",
            "isKey": false,
            "numCitedBy": 384,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-Estimates-of-Location-Robertson-Andrews",
            "title": {
                "fragments": [],
                "text": "Robust Estimates of Location"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145633057"
                        ],
                        "name": "D. Gokhale",
                        "slug": "D.-Gokhale",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Gokhale",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gokhale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095314816"
                        ],
                        "name": "Y. Bishop",
                        "slug": "Y.-Bishop",
                        "structuredName": {
                            "firstName": "Yvonne",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Bishop"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684961"
                        ],
                        "name": "S. Fienberg",
                        "slug": "S.-Fienberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Fienberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Fienberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5578803"
                        ],
                        "name": "P. Holland",
                        "slug": "P.-Holland",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Holland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Holland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123441371,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b5893e8d0650a7396887b6fec2d08ddea81e48eb",
            "isKey": false,
            "numCitedBy": 2021,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Discrete-Multivariate-Analysis.-Gokhale-Bishop",
            "title": {
                "fragments": [],
                "text": "Discrete Multivariate Analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48343674"
                        ],
                        "name": "D. Harville",
                        "slug": "D.-Harville",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Harville",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harville"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 169
                            }
                        ],
                        "text": "It can be shown that the estimates Of u2, 3l *,s ak+1 found in this way are identical to those described by Patterson and Thompson (1971), Corbeil and Searle (1976) and Harville (1977) under the label REML, or \"restricted\" maximum likelihood."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 124116482,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ee17ee778c58b246e086a38fcbe024f8de357179",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Maximum-Likelihood-Approaches-to-Variance-Component-Harville",
            "title": {
                "fragments": [],
                "text": "Maximum Likelihood Approaches to Variance Component Estimation and to Related Problems: Rejoinder"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145772404"
                        ],
                        "name": "J. O. Irwin",
                        "slug": "J.-O.-Irwin",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Irwin",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O. Irwin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124230417,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "651a1a05a278c6bbe735729d3778f4463351e567",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Place-of-Mathematics-in-Medical-and-Biological-Irwin",
            "title": {
                "fragments": [],
                "text": "The Place of Mathematics in Medical and Biological Statistics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1436168196"
                        ],
                        "name": "A. M'Kendrick",
                        "slug": "A.-M'Kendrick",
                        "structuredName": {
                            "firstName": "Archibald",
                            "lastName": "M'Kendrick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. M'Kendrick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 124582227,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "330ac1fdfa32c53dc4e4fe91e19b9c79811f8810",
            "isKey": false,
            "numCitedBy": 797,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Applications-of-Mathematics-to-Medical-Problems-M'Kendrick",
            "title": {
                "fragments": [],
                "text": "Applications of Mathematics to Medical Problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1925
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101407329"
                        ],
                        "name": "E. Batschelet",
                        "slug": "E.-Batschelet",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Batschelet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Batschelet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 35
                            }
                        ],
                        "text": "Perhaps the lesser known papers of Batschelet (1960) and Geppert (1961) should be added to a list of references concerning maximum-likelihood estimation in incomplete contingency tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 122814286,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d4ec37d593596d903001b98913235f0c9b6b08eb",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u00dcber-eine-Kontingenztafel-mit-fehlenden-Daten-Batschelet",
            "title": {
                "fragments": [],
                "text": "\u00dcber eine Kontingenztafel mit fehlenden Daten"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 159
                            }
                        ],
                        "text": "Formally, we need to assume that (a) c+ is a priori independent of the parameters of the missing data process, and (b) the missing data are missing at random (Rubin, 1976)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 123227007,
            "fieldsOfStudy": [],
            "id": "78689756e341a2c391907dfbe3ec459592900866",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inference and missing data"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4710675"
                        ],
                        "name": "S. Haberman",
                        "slug": "S.-Haberman",
                        "structuredName": {
                            "firstName": "Shelby",
                            "lastName": "Haberman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haberman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 123010543,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fba75716f626aa6e2002f87bc12ea2ad287ab271",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Log-Linear-Models-for-Frequency-Tables-Derived-by-Haberman",
            "title": {
                "fragments": [],
                "text": "Log-Linear Models for Frequency Tables Derived by Indirect Observation: Maximum Likelihood Equations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32214870"
                        ],
                        "name": "I. Guttman",
                        "slug": "I.-Guttman",
                        "structuredName": {
                            "firstName": "Irwin",
                            "lastName": "Guttman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guttman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119634864,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f85f15468018a77b7a6f4621b4d19d1de2734f93",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Remark-on-the-Optimal-Regression-Designs-with-of-Guttman",
            "title": {
                "fragments": [],
                "text": "A Remark on the Optimal Regression Designs with Previous Observations of Covey-Crump and Silvey"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153389145"
                        ],
                        "name": "P. Grundy",
                        "slug": "P.-Grundy",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Grundy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grundy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 32
                            }
                        ],
                        "text": "An interesting early example is Grundy (1952) who deals with univariate normal sampling and who uses a Taylor series expansion to approximate the integrals required to handle grouping into narrow class intervals."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121023208,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "58783f3e9a4137cb9cba8f0062e89c5ee6c56bfe",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-FITTING-OF-GROUPED-TRUNCATED-AND-GROUPED-NORMAL-Grundy",
            "title": {
                "fragments": [],
                "text": "THE FITTING OF GROUPED TRUNCATED AND GROUPED CENSORED NORMAL DISTRIBUTIONS"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1952
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39867082"
                        ],
                        "name": "L. A. Goodman",
                        "slug": "L.-A.-Goodman",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Goodman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Goodman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 119750891,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2f3c17c811d8c949a29ee407639417c5c329c7e7",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Analysis-of-Cross-Classified-Data:-and-in-with-Goodman",
            "title": {
                "fragments": [],
                "text": "The Analysis of Cross-Classified Data: Independence, Quasi-Independence, and Interactions in Contingency Tables with or without Missing Entries"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40519737"
                        ],
                        "name": "Morton B. Brown",
                        "slug": "Morton-B.-Brown",
                        "structuredName": {
                            "firstName": "Morton",
                            "lastName": "Brown",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Morton B. Brown"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 45
                            }
                        ],
                        "text": "The algorithm was also recently suggested by Brown (1974) for computing the maximum-likelihood estimates of expected cell frequencies under an independence model in a two-way table with some missing cells, and by Fienberg and Chen (1976) for the special case of cross-classified data with some\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "For example, when the version of the EM algorithm proposed by Brown (1974) is used for estimation in the model of quasi-independence in square Ix I contingency tables with missing diagonals, it is distinctly superior to the standard iterative proportional fitting algorithm described in Bishop et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 69
                            }
                        ],
                        "text": "In the examples we looked at, easily-the quickest method was that of Brown (1974), although it may not always be monotonic for 0, in which the missing cells are treated one by one."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 66983610,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "aef88046f58d03d18555a4479ef84c780e358a2e",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Identification-of-the-Sources-of-Significance-in-Brown",
            "title": {
                "fragments": [],
                "text": "Identification of the Sources of Significance in Two\u2010Way Contingency Tables"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52024479"
                        ],
                        "name": "B. M. Hill",
                        "slug": "B.-M.-Hill",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Hill",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. M. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145179124"
                        ],
                        "name": "I. Good",
                        "slug": "I.-Good",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Good",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Good"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 10
                            }
                        ],
                        "text": "He later (Good, 1965) discussed estimation of hyperparameters by maximum likelihood for the multinomial-Dirichlet model, but without using EM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61353144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52c80779f47d3c4edd5e37ebe7d341b378c3a5d7",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Estimation-of-Probabilities:-An-Essay-on-Modern-Hill-Good",
            "title": {
                "fragments": [],
                "text": "The Estimation of Probabilities: An Essay on Modern Bayesian Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60804212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3",
            "isKey": false,
            "numCitedBy": 1785,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-inequality-and-associated-maximization-technique-Baum",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 85
                            }
                        ],
                        "text": "My own very limited experience of Rao's method (and equally those of Howe, 1955, and Bargmann, 1957) is that convergence is impossibly slow-the iterative corrections are small, but they do not seem to get any smaller as the iteration progresses."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study of independence and dependence in multivariate normal analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Mimeo"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study of independence and dependence in multivariate normal analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation from linear combinations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1955, and Bargmann, 1957) is that convergence is impossibly slow-the"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 57
                            }
                        ],
                        "text": "Perhaps the lesser known papers of Batschelet (1960) and Geppert (1961) should be added to a list of references concerning maximum-likelihood estimation in incomplete contingency tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Erwartungstreue plausibelste Schutzen aus dreieckig gestutzen Kontingenstafeln"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the estimation of the mean of a Poisson distribution with the zero class"
            },
            "venue": {
                "fragments": [],
                "text": "missing. Biometrics,"
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The estimation of gene frequencies in a random - R . , SINISCALCO , , mating population"
            },
            "venue": {
                "fragments": [],
                "text": "Ann . Hum . Genet ."
            },
            "year": 1955
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithmic approach to estimating variances"
            },
            "venue": {
                "fragments": [],
                "text": "Research"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric maximum - likelihood estimation of a distribution function with mixtures of distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation from incomplete"
            },
            "venue": {
                "fragments": [],
                "text": "data. Biometrics,"
            },
            "year": 1958
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 297,
                                "start": 283
                            }
                        ],
                        "text": "\u2026(and 2); if\nThis content downloaded on Fri, 1 Mar 2013 09:19:07 AM All use subject to JSTOR Terms and Conditions\n1977] DEMPSTER et al. - Maximum Likelihoodfrom Incomplete Data 21 restrictions are placed on R, special complete-data maximum-likelihood techniques may have to be used (Dempster, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 102
                            }
                        ],
                        "text": "restrictions are placed on R, special complete-data maximum-likelihood techniques may have to be used (Dempster, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Covariance selection"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics, 28, 157-175."
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithmic approach to estimating variances"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Uber eine Kontingenztagel mit fehlenden Daten Discrete Multivariate Analysis: Theory and S. E. and HOLLAND, Practice"
            },
            "venue": {
                "fragments": [],
                "text": "Biometr. Zeitschr"
            },
            "year": 1960
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 89
                            }
                        ],
                        "text": "In such cases of \"prognostic ensoring\", it seems that little can be done (Tsiatis, 1975; Peterson, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Presumably two \"extreme\" analyses, one optimistic and one pessimistic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Covariance selection"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics, 28, 157-175."
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 89
                            }
                        ],
                        "text": "In such cases of \"prognostic ensoring\", it seems that little can be done (Tsiatis, 1975; Peterson, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric estimation in the competing risks problem"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Stanford"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric estimation in the competing risks problem"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Stanford University."
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 12
                            }
                        ],
                        "text": "GEPPERT, M. P. (1961)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Erwartungstreue plausibelste Schutzen aus dreieckig gestutzen Kontingenstafeln"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric maximum-likelihood estimation of a distribution function with mixtures of distributions"
            },
            "venue": {
                "fragments": [],
                "text": "Nonparametric maximum-likelihood estimation of a distribution function with mixtures of distributions"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Iterative scaling procedures for log-linear models for frequency tables derived by indirect observation"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Amer. Statist. Assoc. (Statist. Comp. Sect"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the MLE of the parameters of a mixture of two normal distributions when"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improved algorithm for the Wtransform in variance component W . J . and LORENS , estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the estimation of the mean of a Poisson distribution with the zero class missing"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 27
                            }
                        ],
                        "text": "For example, Chapter 16 of Snedecor and Cochran (1967) gives a 3 x 3 table of means {Pin} for an unbalanced two-way analysis of variance, with cell counts {nij} = (36, 67, 49, 31, 60, 49, 58, 87, 80)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Statistical Methods, 6th edn"
            },
            "venue": {
                "fragments": [],
                "text": "Ames, Iowa: Iowa State"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 50
                            }
                        ],
                        "text": "BISHOP, Y. M. M., FIENBERG, S. E. and HOLLAND, P. W. (1975)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discrete Multivariate Analysis: Theory and"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The analysis of cross-classified data. interaction in contingency tables with or without missing entries"
            },
            "venue": {
                "fragments": [],
                "text": "J. Amer. Statist. Ass"
            },
            "year": 1968
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Note: Equivalence of maximum likelihood and the method MARITZ,J"
            },
            "venue": {
                "fragments": [],
                "text": "S. (1970). Empirical Bayes Methods. London: Methuen. MARTIN,"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the allocation of linear observations"
            },
            "venue": {
                "fragments": [],
                "text": "J"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Laird (1975) studies variance estimation for random parameters in log-linear models for contingency tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Log-linear models with random parameters"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Harvard University. -- (1976). Nonparametric maximum-likelihood estimation of a distribution function with mixtures of distributions. Technical Report S-47, NS-338, Dept of Statistics, Harvard University. LAWLEY, D. N. and MAXWELL, A. E. (1971). Factor Analysis as a Statistical Method "
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and GREENHOUSE, of moments in probit analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 134
                            }
                        ],
                        "text": "The authors' application of EM to estimating variance components displays no advantages for EM over methods described by Hemmerle and Hartley (1973) and Hemmerle and Lorens (1976), which are directly suited to variance components models and take account of their special properties-whereas EM does\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "model using the W transformation"
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Theory of Optimal Experiments (E"
            },
            "venue": {
                "fragments": [],
                "text": "M. Klimko and W. J. Studden, eds and trans-"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 245
                            }
                        ],
                        "text": "\u2026AM All use subject to JSTOR Terms and Conditions\n1977] DEMPSTER et a!. - Maximum Likelihoodfrom Incomplete Data 17 Finally, we mention another independent special derivation of the EM method for finite mixtures developed in a series of papers (Baum and Eagon, 1967; Baum et al., 1970; Baum, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 171
                            }
                        ],
                        "text": "Thus - {det (M)}-1 possesses (a) and (b) with t = k, but 8 = 1 emerges as a natural power since this attains the optimum in one step if J = k; it achieves monotonicity by Baum and Eagon (1967)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 128
                            }
                        ],
                        "text": "Finally, we mention another independent special derivation of the EM method for finite mixtures developed in a series of papers (Baum and Eagon, 1967; Baum et al., 1970; Baum, 1972)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "This power, however, is a special case of 8 = 1/(t +1) above since {tr (M-t)/k}1It -+ {det (M)}-l/k as t -> 0 and a det (M)/lpi = (vw M-1 v?) det (M)"
            },
            "venue": {
                "fragments": [],
                "text": "The resultant algorithm can in fact be shown directly to be an EM algorithm. Can this be done for i(p) in (1)?"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "Laird (1975) studies variance estimation for random parameters in log-linear models for contingency tables."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonparametric maximum-likelihood estimation of a distribution function with mixtures of distributions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tables based on imperfect observation. Invited paper at the 1971 ENAR meeting"
            },
            "venue": {
                "fragments": [],
                "text": "Tables based on imperfect observation. Invited paper at the 1971 ENAR meeting"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scicon Computer Services Ltd and Scientific Control Systems Ltd): It gives A study of independence and dependence in multivariate normal analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Scicon Computer Services Ltd and Scientific Control Systems Ltd): It gives A study of independence and dependence in multivariate normal analysis"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 132
                            }
                        ],
                        "text": "This behaviour seems similar to the superiority, in certain examples, of Fedorov's (1972) algorithm over the appropriate EM method (Silvey et al., 1976) for computing D-optimal designs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "Often 8> 1 produces faster convergence than the basic EM algorithm, given by 8 = 1; see also Mr Torsney's remarks and Silvey et al. (1976), where an iteration like (1) is used in computing D-optimal designs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 89
                            }
                        ],
                        "text": "The following algorithm, suggested by a result in Fellman (1974), has been formulated by Silvey et al. (1976):\npi(r) (X: pi(r -1) {a0lapi(r -1)}'6, 8 > O."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for D-optimal designs on a finite space"
            },
            "venue": {
                "fragments": [],
                "text": "Report available from the authors."
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tables based on imperfect observation"
            },
            "venue": {
                "fragments": [],
                "text": "Invited paper at the 1971 ENAR meeting,"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tables based on imperfect observation"
            },
            "venue": {
                "fragments": [],
                "text": "Invited paper at the 1971 ENAR meeting, Pennsylvania State University. -(1974). Loglinear models for frequency tables derived by indirect observation: maximum likelihood equations. Ann. Statist., 2, 911-924. HEMMERLE,"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. R. Statist. Soc., B"
            },
            "venue": {
                "fragments": [],
                "text": "J. R. Statist. Soc., B"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Note: Equivalence of maximum likelihood and the method MARITZ Empirical Bayes Methods"
            },
            "venue": {
                "fragments": [],
                "text": "J. S"
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Log-linear models with random parameters"
            },
            "venue": {
                "fragments": [],
                "text": "Log-linear models with random parameters"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 74
                            }
                        ],
                        "text": "In such cases of \"prognostic ensoring\", it seems that little can be done (Tsiatis, 1975; Peterson, 1975)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A nonidentifiability aspect of the problem of competing risks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Nat. Acad. Sci. USA,"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 79
                            }
                        ],
                        "text": "The second-level specification was used in special cases by Hartley (1958) and Irwin (1959, 1963)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the estimation of the mean of a Poisson distribution with the zero class missing"
            },
            "venue": {
                "fragments": [],
                "text": "J. R. Statist. Soc., A"
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recovery of interblock information when block sizes are H . D . and THOMPSON , unequal"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . 6 th Berkeley Symposium on Math . Statist . and Prob"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 13
                            }
                        ],
                        "text": "SMITH, C. A. B. (1969)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Biomathematics, Vol"
            },
            "venue": {
                "fragments": [],
                "text": "2. London: Griffin. SNEDECOR,"
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood estimation for the mixed analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 50
                            }
                        ],
                        "text": "The following algorithm, suggested by a result in Fellman (1974), has been formulated by Silvey et al. (1976):\npi(r) (X: pi(r -1) {a0lapi(r -1)}'6, 8 > O."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the allocation of linear observations"
            },
            "venue": {
                "fragments": [],
                "text": "Commentationes Phys.-Math., 44, Nos. 2-3."
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Log-linear models with random parameters"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. Thesis, Harvard University. -(1976). Nonparametric maximum-likelihood estimation of a distribution function with mixtures of distributions. Technical Report S-47, NS-338, Dept of Statistics, Harvard University. LAWLEY,"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 9
                            }
                        ],
                        "text": "FELLMAN, J. (1974)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 13
                            }
                        ],
                        "text": "HEMMERLE, W. J. (1974)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the allocation of linear observations"
            },
            "venue": {
                "fragments": [],
                "text": "FISHER,"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A nonidentifiability aspect of the problem of competing risks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Nut . Acad . Sci . USA"
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Erwartungstreue plausibelste Schutzen aus dreieckig gestutzen Kontingenstafeln"
            },
            "venue": {
                "fragments": [],
                "text": "Biometr. Zeitschr"
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for D-optimal designs on a h i t e space"
            },
            "venue": {
                "fragments": [],
                "text": "An algorithm for D-optimal designs on a h i t e space"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discussion of paper by Hartley and Hocking"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics, 27, 808-817. E. M. L. BEALE(Scicon Computer Services Ltd and Scientific Control Systems Ltd): I t gives me great pleasure to open the discussion of this lucid and scholarly paper on an important topic, and to thank all three authors for crossing the Atlantic to present it to us. The topi"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 64
                            }
                        ],
                        "text": "Aspects of the theory consequent on our Lemma 2 were derived by Woodbury (1971) and Orchard and Woodbury (1972) in a general framework, but their concern was with a \"principle\" rather than with the EM algorithm\nThis content downloaded on Fri, 1 Mar 2013 09:19:07 AM All use subject to JSTOR Terms\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Discussion of paper by Hartley and Hocking"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics, 27, 808-817."
            },
            "year": 1971
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 41,
            "methodology": 46,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 135,
        "totalPages": 14
    },
    "page_url": "https://www.semanticscholar.org/paper/Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird/d36efb9ad91e00faa334b549ce989bfae7e2907a?sort=total-citations"
}