{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152702479"
                        ],
                        "name": "P. Fischer",
                        "slug": "P.-Fischer",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 68
                            }
                        ],
                        "text": "The performance of DCGANs is still less than that of Exemplar CNNs (Dosovitskiy et al., 2015), a technique which trains normal discriminative CNNs in an unsupervised fashion to differentiate between specifically chosen, aggressively augmented, exemplar samples from the source dataset."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12881926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bb86dde5c7e11918b19e75e6211b77bf2649951",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. Training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. Acquisition of large training sets is one of the key challenges, when approaching a new task. In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. To this end, we train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled `seed' image patch. In contrast to supervised network training, the resulting feature representation is not class specific. It rather provides robustness to the transformations that have been applied during training. This generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101, Caltech-256). While features learned with our approach cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor."
            },
            "slug": "Discriminative-Unsupervised-Feature-Learning-with-Dosovitskiy-Fischer",
            "title": {
                "fragments": [],
                "text": "Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "While features learned with this approach cannot compete with class specific features from supervised training on a classification task, it is shown that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40081727"
                        ],
                        "name": "Emily L. Denton",
                        "slug": "Emily-L.-Denton",
                        "structuredName": {
                            "firstName": "Emily",
                            "lastName": "Denton",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emily L. Denton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3149531"
                        ],
                        "name": "Arthur D. Szlam",
                        "slug": "Arthur-D.-Szlam",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Szlam",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arthur D. Szlam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Deep belief networks (Lee et al., 2009) have also been shown to work well in learning hierarchical representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 25
                            }
                        ],
                        "text": "The non-parametric models often do matching from a database of existing images, often matching patches of images, and have been used in texture synthesis (Efros et al., 1999), super-resolution (Freeman et al., 2002) and in-painting (Hays & Efros, 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "This motivated the authors of LAPGAN (Denton et al., 2015) to develop an alternative approach to iteratively upscale low resolution generated images which can be modeled more reliably."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 48
                            }
                        ],
                        "text": "A laplacian pyramid extension to this approach (Denton et al., 2015) showed higher quality images, but they still suffered from the objects looking wobbly because of noise introduced in chaining multiple models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1282515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47900aca2f0b50da3010ad59b394c870f0e6c02e",
            "isKey": false,
            "numCitedBy": 1855,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce a generative parametric model capable of producing high quality samples of natural images. Our approach uses a cascade of convolutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion. At each level of the pyramid, a separate generative convnet model is trained using the Generative Adversarial Nets (GAN) approach [11]. Samples drawn from our model are of significantly higher quality than alternate approaches. In a quantitative assessment by human evaluators, our CIFAR10 samples were mistaken for real images around 40% of the time, compared to 10% for samples drawn from a GAN baseline model. We also show samples from models trained on the higher resolution images of the LSUN scene dataset."
            },
            "slug": "Deep-Generative-Image-Models-using-a-Laplacian-of-Denton-Chintala",
            "title": {
                "fragments": [],
                "text": "Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A generative parametric model capable of producing high quality samples of natural images using a cascade of convolutional networks within a Laplacian pyramid framework to generate images in a coarse-to-fine fashion."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 22
                            }
                        ],
                        "text": "Deep belief networks (Lee et al., 2009) have also been shown to work well in learning hierarchical representations."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12008458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "isKey": false,
            "numCitedBy": 2510,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
            },
            "slug": "Convolutional-deep-belief-networks-for-scalable-of-Lee-Grosse",
            "title": {
                "fragments": [],
                "text": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The convolutional deep belief network is presented, a hierarchical generative model which scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093491"
                        ],
                        "name": "M. Oquab",
                        "slug": "M.-Oquab",
                        "structuredName": {
                            "firstName": "Maxime",
                            "lastName": "Oquab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oquab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 86
                            }
                        ],
                        "text": "Additionally, supervised CNNs trained on scene classification learn object detectors (Oquab et al., 2014)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206592191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c08f5fa876181fc040d76c75fe2433eee3c9b001",
            "isKey": false,
            "numCitedBy": 2745,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNN) have recently shown outstanding image classification performance in the large- scale visual recognition challenge (ILSVRC2012). The success of CNNs is attributed to their ability to learn rich mid-level image representations as opposed to hand-designed low-level features used in other image classification methods. Learning CNNs, however, amounts to estimating millions of parameters and requires a very large number of annotated image samples. This property currently prevents application of CNNs to problems with limited training data. In this work we show how image representations learned with CNNs on large-scale annotated datasets can be efficiently transferred to other visual recognition tasks with limited amount of training data. We design a method to reuse layers trained on the ImageNet dataset to compute mid-level image representation for images in the PASCAL VOC dataset. We show that despite differences in image statistics and tasks in the two datasets, the transferred representation leads to significantly improved results for object and action classification, outperforming the current state of the art on Pascal VOC 2007 and 2012 datasets. We also show promising results for object and action localization."
            },
            "slug": "Learning-and-Transferring-Mid-level-Image-Using-Oquab-Bottou",
            "title": {
                "fragments": [],
                "text": "Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work designs a method to reuse layers trained on the ImageNet dataset to compute mid-level image representation for images in the PASCAL VOC dataset, and shows that despite differences in image statistics and tasks in the two datasets, the transferred representation leads to significantly improved results for object and action classification."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 45
                            }
                        ],
                        "text": "Using guided backpropagation as proposed by (Springenberg et al., 2014), we show in Fig.5 that the features learnt by the discriminator activate on typical parts of a bedroom, like beds and windows."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 40
                            }
                        ],
                        "text": "The first is the all convolutional net (Springenberg et al., 2014) which replaces deterministic spatial pooling functions (such as maxpooling) with strided convolutions, allowing the network to learn its own spatial downsampling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 51
                            }
                        ],
                        "text": "Another approach generates images using an iterative forward diffusion process (Sohl-Dickstein et al., 2015)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12998557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f84a81f431b18a78bd97f59ed4b9d8eda390970",
            "isKey": false,
            "numCitedBy": 3272,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the \"deconvolution approach\" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches."
            },
            "slug": "Striving-for-Simplicity:-The-All-Convolutional-Net-Springenberg-Dosovitskiy",
            "title": {
                "fragments": [],
                "text": "Striving for Simplicity: The All Convolutional Net"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467703"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2453026"
                        ],
                        "name": "Isabelle Lajoie",
                        "slug": "Isabelle-Lajoie",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Lajoie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isabelle Lajoie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798462"
                        ],
                        "name": "Pierre-Antoine Manzagol",
                        "slug": "Pierre-Antoine-Manzagol",
                        "structuredName": {
                            "firstName": "Pierre-Antoine",
                            "lastName": "Manzagol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Antoine Manzagol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17804904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2b7f37cd97a7907b1b8a41138721ed06a0b76cd",
            "isKey": false,
            "numCitedBy": 5610,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoders which are trained locally to denoise corrupted versions of their inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield significantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely unsupervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative experiments show that, contrary to ordinary autoencoders, denoising autoencoders are able to learn Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images. This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations."
            },
            "slug": "Stacked-Denoising-Autoencoders:-Learning-Useful-in-Vincent-Larochelle",
            "title": {
                "fragments": [],
                "text": "Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work clearly establishes the value of using a denoising criterion as a tractable unsupervised objective to guide the learning of useful higher level representations."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2887364"
                        ],
                        "name": "Tim Salimans",
                        "slug": "Tim-Salimans",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Salimans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Salimans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34415167"
                        ],
                        "name": "Vicki Cheung",
                        "slug": "Vicki-Cheung",
                        "structuredName": {
                            "firstName": "Vicki",
                            "lastName": "Cheung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicki Cheung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41192764"
                        ],
                        "name": "Xi Chen",
                        "slug": "Xi-Chen",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1687220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "571b0750085ae3d939525e62af510ee2cee9d5ea",
            "isKey": false,
            "numCitedBy": 5551,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes."
            },
            "slug": "Improved-Techniques-for-Training-GANs-Salimans-Goodfellow",
            "title": {
                "fragments": [],
                "text": "Improved Techniques for Training GANs"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This work focuses on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic, and presents ImageNet samples with unprecedented resolution and shows that the methods enable the model to learn recognizable features of ImageNet classes."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807197"
                        ],
                        "name": "F. Yu",
                        "slug": "F.-Yu",
                        "structuredName": {
                            "firstName": "Fisher",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1591143181"
                        ],
                        "name": "Yinda Zhang",
                        "slug": "Yinda-Zhang",
                        "structuredName": {
                            "firstName": "Yinda",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinda Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3340170"
                        ],
                        "name": "S. Song",
                        "slug": "S.-Song",
                        "structuredName": {
                            "firstName": "Shuran",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2233674"
                        ],
                        "name": "Ari Seff",
                        "slug": "Ari-Seff",
                        "structuredName": {
                            "firstName": "Ari",
                            "lastName": "Seff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ari Seff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40599257"
                        ],
                        "name": "Jianxiong Xiao",
                        "slug": "Jianxiong-Xiao",
                        "structuredName": {
                            "firstName": "Jianxiong",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxiong Xiao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 77
                            }
                        ],
                        "text": "We trained DCGANs on three datasets, Large-scale Scene Understanding (LSUN) (Yu et al., 2015), Imagenet-1k and a newly assembled Faces dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "To demonstrate how our model scales with more data and higher resolution generation, we train a model on the LSUN bedrooms dataset containing a little over 3 million training examples."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8317437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dcdae25a5e33682953f0853ee4cf7ca93be58a9",
            "isKey": false,
            "numCitedBy": 1073,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "While there has been remarkable progress in the performance of visual recognition algorithms, the state-of-the-art models tend to be exceptionally data-hungry. Large labeled training datasets, expensive and tedious to produce, are required to optimize millions of parameters in deep network models. Lagging behind the growth in model capacity, the available datasets are quickly becoming outdated in terms of size and density. To circumvent this bottleneck, we propose to amplify human effort through a partially automated labeling scheme, leveraging deep learning with humans in the loop. Starting from a large set of candidate images for each category, we iteratively sample a subset, ask people to label them, classify the others with a trained model, split the set into positives, negatives, and unlabeled based on the classification confidence, and then iterate with the unlabeled set. To assess the effectiveness of this cascading procedure and enable further progress in visual recognition research, we construct a new image dataset, LSUN. It contains around one million labeled images for each of 10 scene categories and 20 object categories. We experiment with training popular convolutional networks and find that they achieve substantial performance gains when trained on this dataset."
            },
            "slug": "LSUN:-Construction-of-a-Large-scale-Image-Dataset-Yu-Zhang",
            "title": {
                "fragments": [],
                "text": "LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes to amplify human effort through a partially automated labeling scheme, leveraging deep learning with humans in the loop, and constructs a new image dataset, LSUN, which contains around one million labeled images for each of 10 scene categories and 20 object categories."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 60
                            }
                        ],
                        "text": "We found the suggested learning rate of 0.001, to be too high, using 0.0002 instead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 86
                            }
                        ],
                        "text": "An unsupervised multi-layered extension of the base algorithm reaches 82.0% accuracy (Coates & Ng, 2011)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5984785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "182015c5edff1956cbafbcb3e7bbe294aa54f9fc",
            "isKey": true,
            "numCitedBy": 221,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent deep learning and unsupervised feature learning systems that learn from unlabeled data have achieved high performance in benchmarks by using extremely large architectures with many features (hidden units) at each layer. Unfortunately, for such large architectures the number of parameters can grow quadratically in the width of the network, thus necessitating hand-coded \"local receptive fields\" that limit the number of connections from lower level features to higher ones (e.g., based on spatial locality). In this paper we propose a fast method to choose these connections that may be incorporated into a wide variety of unsupervised training methods. Specifically, we choose local receptive fields that group together those low-level features that are most similar to each other according to a pairwise similarity metric. This approach allows us to harness the advantages of local receptive fields (such as improved scalability, and reduced data requirements) when we do not know how to specify such receptive fields by hand or where our unsupervised training algorithm has no obvious generalization to a topographic setting. We produce results showing how this method allows us to use even simple unsupervised training algorithms to train successful multi-layered networks that achieve state-of-the-art results on CIFAR and STL datasets: 82.0% and 60.1% accuracy, respectively."
            },
            "slug": "Selecting-Receptive-Fields-in-Deep-Networks-Coates-Ng",
            "title": {
                "fragments": [],
                "text": "Selecting Receptive Fields in Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a fast method to choose local receptive fields that group together those low-level features that are most similar to each other according to a pairwise similarity metric, and produces results showing how this method allows even simple unsupervised training algorithms to train successful multi-layered networks that achieve state-of-the-art results on CIFAR and STL datasets."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403025868"
                        ],
                        "name": "Jean Pouget-Abadie",
                        "slug": "Jean-Pouget-Abadie",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Pouget-Abadie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean Pouget-Abadie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113742925"
                        ],
                        "name": "Bing Xu",
                        "slug": "Bing-Xu",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1955694"
                        ],
                        "name": "Sherjil Ozair",
                        "slug": "Sherjil-Ozair",
                        "structuredName": {
                            "firstName": "Sherjil",
                            "lastName": "Ozair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sherjil Ozair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1033682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54e325aee6b2d476bbbb88615ac15e251c6e8214",
            "isKey": false,
            "numCitedBy": 29658,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to \u00bd everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples."
            },
            "slug": "Generative-Adversarial-Nets-Goodfellow-Pouget-Abadie",
            "title": {
                "fragments": [],
                "text": "Generative Adversarial Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A new framework for estimating generative models via an adversarial process, in which two models are simultaneously train: a generative model G that captures the data distribution and a discriminative model D that estimates the probability that a sample came from the training data rather than G."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Deep belief networks (Lee et al., 2009) have also been shown to work well in learning hierarchical representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 131
                            }
                        ],
                        "text": "Previous work has demonstrated that supervised training of CNNs on large image datasets results in very powerful learned features (Zeiler & Fergus, 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 1
                            }
                        ],
                        "text": "(Zeiler & Fergus, 2014) showed that by using deconvolutions and filtering the maximal activations, one can find the approximate purpose of each convolution filter in the network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3960646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a2a770d23b4a171fa81de62a78a3deb0588f238",
            "isKey": false,
            "numCitedBy": 11814,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets."
            },
            "slug": "Visualizing-and-Understanding-Convolutional-Zeiler-Fergus",
            "title": {
                "fragments": [],
                "text": "Visualizing and Understanding Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel visualization technique is introduced that gives insight into the function of intermediate feature layers and the operation of the classifier in large Convolutional Network models, used in a diagnostic role to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019807"
                        ],
                        "name": "Antti Rasmus",
                        "slug": "Antti-Rasmus",
                        "structuredName": {
                            "firstName": "Antti",
                            "lastName": "Rasmus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antti Rasmus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2438071"
                        ],
                        "name": "Mathias Berglund",
                        "slug": "Mathias-Berglund",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "Berglund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathias Berglund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263102"
                        ],
                        "name": "M. Honkala",
                        "slug": "M.-Honkala",
                        "structuredName": {
                            "firstName": "Mikko",
                            "lastName": "Honkala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Honkala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132516"
                        ],
                        "name": "H. Valpola",
                        "slug": "H.-Valpola",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Valpola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Valpola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785022"
                        ],
                        "name": "T. Raiko",
                        "slug": "T.-Raiko",
                        "structuredName": {
                            "firstName": "Tapani",
                            "lastName": "Raiko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Raiko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 164
                            }
                        ],
                        "text": "\u2026train auto-encoders (convolutionally, stacked (Vincent et al., 2010), separating the what and where components of the code (Zhao et al., 2015), ladder structures (Rasmus et al., 2015)) that encode an image into a compact code, and decode the code to reconstruct the image as accurately as possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5855183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99487be08cab00554c5c8db73161b2615c694f71",
            "isKey": false,
            "numCitedBy": 1002,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pre-training. Our work builds on top of the Ladder network proposed by Valpola [1] which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification in addition to permutation-invariant MNIST classification with all labels."
            },
            "slug": "Semi-supervised-Learning-with-Ladder-Networks-Rasmus-Berglund",
            "title": {
                "fragments": [],
                "text": "Semi-supervised Learning with Ladder Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work builds on top of the Ladder network proposed by Valpola which is extended by combining the model with supervision and shows that the resulting model reaches state-of-the-art performance in semi-supervised MNIST and CIFAR-10 classification in addition to permutation-invariant MNIST classification with all labels."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2142792"
                        ],
                        "name": "S\u00f8ren Hauberg",
                        "slug": "S\u00f8ren-Hauberg",
                        "structuredName": {
                            "firstName": "S\u00f8ren",
                            "lastName": "Hauberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00f8ren Hauberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546556"
                        ],
                        "name": "O. Freifeld",
                        "slug": "O.-Freifeld",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Freifeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Freifeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46560485"
                        ],
                        "name": "Anders Boesen Lindbo Larsen",
                        "slug": "Anders-Boesen-Lindbo-Larsen",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Larsen",
                            "middleNames": [
                                "Boesen",
                                "Lindbo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anders Boesen Lindbo Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31496901"
                        ],
                        "name": "John W. Fisher III",
                        "slug": "John-W.-Fisher-III",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Fisher III",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John W. Fisher III"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145579972"
                        ],
                        "name": "L. K. Hansen",
                        "slug": "L.-K.-Hansen",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Hansen",
                            "middleNames": [
                                "Kai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. K. Hansen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "No data augmentation was applied to the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 130
                            }
                        ],
                        "text": "The DCGAN is competitive with a probabilistic generative data augmentation technique utilizing learned per class transformations (Hauberg et al., 2015) while being more general as it directly models the data instead of transformations of the data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16183783,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "440349a3c81780ef08254f5a59229cad74f54904",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Data augmentation is a key element in training high-dimensional models. In this approach, one synthesizes new observations by applying pre-specified transformations to the original training data; e.g.~new images are formed by rotating old ones. Current augmentation schemes, however, rely on manual specification of the applied transformations, making data augmentation an implicit form of feature engineering. With an eye towards true end-to-end learning, we suggest learning the applied transformations on a per-class basis. Particularly, we align image pairs within each class under the assumption that the spatial transformation between images belongs to a large class of diffeomorphisms. We then learn a class-specific probabilistic generative models of the transformations in a Riemannian submanifold of the Lie group of diffeomorphisms. We demonstrate significant performance improvements in training deep neural nets over manually-specified augmentation schemes. Our code and augmented datasets are available online."
            },
            "slug": "Dreaming-More-Data:-Class-dependent-Distributions-Hauberg-Freifeld",
            "title": {
                "fragments": [],
                "text": "Dreaming More Data: Class-dependent Distributions over Diffeomorphisms for Learned Data Augmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work aligns image pairs within each class under the assumption that the spatial transformation between images belongs to a large class of diffeomorphisms, and learns a class-specific probabilistic generative models of the transformations in a Riemannian submanifold of the Lie group of diffEomorphisms."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019807"
                        ],
                        "name": "Antti Rasmus",
                        "slug": "Antti-Rasmus",
                        "structuredName": {
                            "firstName": "Antti",
                            "lastName": "Rasmus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antti Rasmus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132516"
                        ],
                        "name": "H. Valpola",
                        "slug": "H.-Valpola",
                        "structuredName": {
                            "firstName": "Harri",
                            "lastName": "Valpola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Valpola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263102"
                        ],
                        "name": "M. Honkala",
                        "slug": "M.-Honkala",
                        "structuredName": {
                            "firstName": "Mikko",
                            "lastName": "Honkala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Honkala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2438071"
                        ],
                        "name": "Mathias Berglund",
                        "slug": "Mathias-Berglund",
                        "structuredName": {
                            "firstName": "Mathias",
                            "lastName": "Berglund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathias Berglund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2785022"
                        ],
                        "name": "T. Raiko",
                        "slug": "T.-Raiko",
                        "structuredName": {
                            "firstName": "Tapani",
                            "lastName": "Raiko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Raiko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 164
                            }
                        ],
                        "text": "\u2026train auto-encoders (convolutionally, stacked (Vincent et al., 2010), separating the what and where components of the code (Zhao et al., 2015), ladder structures (Rasmus et al., 2015)) that encode an image into a compact code, and decode the code to reconstruct the image as accurately as possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15072389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cddf8a10c7f48df67a797808a615be0d4acf9a8e",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We combine supervised learning with unsupervised learning in deep neural networks. The proposed model is trained to simultaneously minimize the sum of supervised and unsupervised cost functions by backpropagation, avoiding the need for layer-wise pretraining. Our work builds on top of the Ladder network proposed by Valpola (2015) which we extend by combining the model with supervision. We show that the resulting model reaches state-of-the-art performance in various tasks: MNIST and CIFAR-10 classification in a semi-supervised setting and permutation invariant MNIST in both semi-supervised and full-labels setting."
            },
            "slug": "Semi-Supervised-Learning-with-Ladder-Network-Rasmus-Valpola",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning with Ladder Network"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work builds on top of the Ladder network proposed by Valpola (2015) which is extended by combining the model with supervision, and shows that the resulting model reaches state-of-the-art performance in various tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144717963"
                        ],
                        "name": "Karol Gregor",
                        "slug": "Karol-Gregor",
                        "structuredName": {
                            "firstName": "Karol",
                            "lastName": "Gregor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karol Gregor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748523"
                        ],
                        "name": "Danilo Jimenez Rezende",
                        "slug": "Danilo-Jimenez-Rezende",
                        "structuredName": {
                            "firstName": "Danilo",
                            "lastName": "Jimenez Rezende",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danilo Jimenez Rezende"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Deep belief networks (Lee et al., 2009) have also been shown to work well in learning hierarchical representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 30
                            }
                        ],
                        "text": "A recurrent network approach (Gregor et al., 2015) and a deconvolution network approach (Dosovitskiy et al., 2014) have also recently had some success with generating natural images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1930231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2785f66c20fbdf30ec26c0931584c6d6a0f4fca",
            "isKey": false,
            "numCitedBy": 1628,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye."
            },
            "slug": "DRAW:-A-Recurrent-Neural-Network-For-Image-Gregor-Danihelka",
            "title": {
                "fragments": [],
                "text": "DRAW: A Recurrent Neural Network For Image Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The Deep Recurrent Attentive Writer neural network architecture for image generation substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7818229"
                        ],
                        "name": "J. Zhao",
                        "slug": "J.-Zhao",
                        "structuredName": {
                            "firstName": "Junbo",
                            "lastName": "Zhao",
                            "middleNames": [
                                "Jake"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143949035"
                        ],
                        "name": "Micha\u00ebl Mathieu",
                        "slug": "Micha\u00ebl-Mathieu",
                        "structuredName": {
                            "firstName": "Micha\u00ebl",
                            "lastName": "Mathieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Micha\u00ebl Mathieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2558463"
                        ],
                        "name": "Ross Goroshin",
                        "slug": "Ross-Goroshin",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Goroshin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross Goroshin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 171
                            }
                        ],
                        "text": "This achieves state of the art (for classification using 1000 labels) at 22.48% test error, improving upon another modifcation of CNNs designed to leverage unlabled data (Zhao et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 146
                            }
                        ],
                        "text": "\u2026popular method is to train auto-encoders (convolutionally, stacked (Vincent et al., 2010), separating the what and where components of the code (Zhao et al., 2015), ladder structures (Rasmus et al., 2015)) that encode an image into a compact code, and decode the code to reconstruct the image\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7397342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cba5fbd40767a27d20e346a108b8867ac8591a27",
            "isKey": true,
            "numCitedBy": 231,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel architecture, the \"stacked what-where auto-encoders\" (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training. An instantiation of SWWAE uses a convolutional net (Convnet) (LeCun et al. (1998)) to encode the input, and employs a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce the reconstruction. The objective function includes reconstruction terms that induce the hidden states in the Deconvnet to be similar to those of the Convnet. Each pooling layer produces two sets of variables: the \"what\" which are fed to the next layer, and its complementary variable \"where\" that are fed to the corresponding layer in the generative decoder."
            },
            "slug": "Stacked-What-Where-Auto-encoders-Zhao-Mathieu",
            "title": {
                "fragments": [],
                "text": "Stacked What-Where Auto-encoders"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A novel architecture, the \"stacked what-where auto-encoders\" (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151414531"
                        ],
                        "name": "Anh M Nguyen",
                        "slug": "Anh-M-Nguyen",
                        "structuredName": {
                            "firstName": "Anh",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anh M Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2965424"
                        ],
                        "name": "J. Yosinski",
                        "slug": "J.-Yosinski",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Yosinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yosinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2552141"
                        ],
                        "name": "J. Clune",
                        "slug": "J.-Clune",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Clune",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Clune"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5284428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1ce8d00729f9e61eeb315f3cbd7b5354706adbd",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks (DNNs) have demonstrated state-of-the-art results on many pattern recognition tasks, especially vision classification problems. Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own right - similar to why we study the human brain - and will enable researchers to further improve DNNs. One path to understanding how a neural network functions internally is to study what each of its neurons has learned to detect. One such method is called activation maximization (AM), which synthesizes an input (e.g. an image) that highly activates a neuron. Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN). The algorithm (1) generates qualitatively state-of-the-art synthetic images that look almost real, (2) reveals the features learned by each neuron in an interpretable way, (3) generalizes well to new datasets and somewhat well to different network architectures without requiring the prior to be relearned, and (4) can be considered as a high-quality generative method (in this case, by generating novel, creative, interesting, recognizable images)."
            },
            "slug": "Synthesizing-the-preferred-inputs-for-neurons-in-Nguyen-Dosovitskiy",
            "title": {
                "fragments": [],
                "text": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work dramatically improves the qualitative state of the art of activation maximization by harnessing a powerful, learned prior: a deep generator network (DGN), which generates qualitatively state-of-the-art synthetic images that look almost real."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113742783"
                        ],
                        "name": "Bing Xu",
                        "slug": "Bing-Xu",
                        "structuredName": {
                            "firstName": "Bing",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bing Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48246959"
                        ],
                        "name": "Naiyan Wang",
                        "slug": "Naiyan-Wang",
                        "structuredName": {
                            "firstName": "Naiyan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naiyan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112144126"
                        ],
                        "name": "Mu Li",
                        "slug": "Mu-Li",
                        "structuredName": {
                            "firstName": "Mu",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mu Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 86
                            }
                        ],
                        "text": "Within the discriminator we found the leaky rectified activation (Maas et al., 2013) (Xu et al., 2015) to work well, especially for higher resolution modeling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, they have not leveraged the generators for supervised tasks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14083350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adf3b591281688b7e71b254ab931b2aa39b4b59f",
            "isKey": false,
            "numCitedBy": 1851,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate the performance of different types of rectified activation functions in convolutional neural network: standard rectified linear unit (ReLU), leaky rectified linear unit (Leaky ReLU), parametric rectified linear unit (PReLU) and a new randomized leaky rectified linear units (RReLU). We evaluate these activation function on standard image classification task. Our experiments suggest that incorporating a non-zero slope for negative part in rectified activation units could consistently improve the results. Thus our findings are negative on the common belief that sparsity is the key of good performance in ReLU. Moreover, on small scale dataset, using deterministic negative slope or learning it are both prone to overfitting. They are not as effective as using their randomized counterpart. By using RReLU, we achieved 75.68\\% accuracy on CIFAR-100 test set without multiple test or ensemble."
            },
            "slug": "Empirical-Evaluation-of-Rectified-Activations-in-Xu-Wang",
            "title": {
                "fragments": [],
                "text": "Empirical Evaluation of Rectified Activations in Convolutional Network"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The experiments suggest that incorporating a non-zero slope for negative part in rectified activation units could consistently improve the results, and are negative on the common belief that sparsity is the key of good performance in ReLU."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Deep belief networks (Lee et al., 2009) have also been shown to work well in learning hierarchical representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 89
                            }
                        ],
                        "text": "A recurrent network approach (Gregor et al., 2015) and a deconvolution network approach (Dosovitskiy et al., 2014) have also recently had some success with generating natural images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 157
                            }
                        ],
                        "text": "It has been previously demonstrated that conditional generative models can learn to convincingly model object attributes like scale, rotation, and position (Dosovitskiy et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15960930,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b437b5a0445f17b06b12791bc48aeb8110e95dc5",
            "isKey": false,
            "numCitedBy": 629,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We train a generative convolutional neural network which is able to generate images of objects given object type, viewpoint, and color. We train the network in a supervised manner on a dataset of rendered 3D chair models. Our experiments show that the network does not merely learn all images by heart, but rather finds a meaningful representation of a 3D chair model allowing it to assess the similarity of different chairs, interpolate between given viewpoints to generate the missing ones, or invent new chair styles by interpolating between chairs from the training set. We show that the network can be used to find correspondences between different chairs from the dataset, outperforming existing approaches on this task."
            },
            "slug": "Learning-to-generate-chairs-with-convolutional-Dosovitskiy-Springenberg",
            "title": {
                "fragments": [],
                "text": "Learning to generate chairs with convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work trains a generative convolutional neural network which is able to generate images of objects given object type, viewpoint, and color and shows that the network can be used to find correspondences between different chairs from the dataset, outperforming existing approaches on this task."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100612"
                        ],
                        "name": "R. Srivastava",
                        "slug": "R.-Srivastava",
                        "structuredName": {
                            "firstName": "Rupesh",
                            "lastName": "Srivastava",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, using a gradient descent on the inputs lets us inspect the ideal image that activates certain subsets of filters (Mordvintsev et al.)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 167
                            }
                        ],
                        "text": "The resulting code layer activations are then binarized via thresholding the ReLU activation which has been shown to be an effective information preserving technique (Srivastava et al., 2014) and provides a convenient form of semantic-hashing, allowing for linear time de-duplication ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 94224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abc866e30163ec67f1cf4f4380e5f8323a6c598d",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently proposed neural network activation functions such as rectified linear, maxout, and local winner-take-all have allowed for faster and more effective training of deep neural architectures on large and complex datasets. The common trait among these functions is that they implement local competition between small groups of computational units within a layer, so that only part of the network is activated for any given input pattern. In this paper, we attempt to visualize and understand this self-modularization, and suggest a unified explanation for the beneficial properties of such networks. We also show how our insights can be directly useful for efficiently performing retrieval over large datasets using neural networks."
            },
            "slug": "Understanding-Locally-Competitive-Networks-Srivastava-Masci",
            "title": {
                "fragments": [],
                "text": "Understanding Locally Competitive Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper attempts to visualize and understand this self-modularization of neural network activation functions, and suggests a unified explanation for the beneficial properties of such networks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 30
                            }
                        ],
                        "text": "Third is Batch Normalization (Ioffe & Szegedy, 2015) which stabilizes learning by normalizing the input to each unit to have zero mean and unit variance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 29236,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3332944"
                        ],
                        "name": "Maxim Tatarchenko",
                        "slug": "Maxim-Tatarchenko",
                        "structuredName": {
                            "firstName": "Maxim",
                            "lastName": "Tatarchenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maxim Tatarchenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 89
                            }
                        ],
                        "text": "A recurrent network approach (Gregor et al., 2015) and a deconvolution network approach (Dosovitskiy et al., 2014) have also recently had some success with generating natural images."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 157
                            }
                        ],
                        "text": "It has been previously demonstrated that conditional generative models can learn to convincingly model object attributes like scale, rotation, and position (Dosovitskiy et al., 2014)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8152666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c3d7d5a9a9eafa084913b8c83a013c81d50479f",
            "isKey": false,
            "numCitedBy": 226,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We train generative \u2018up-convolutional\u2019 neural networks which are able to generate images of objects given object style, viewpoint, and color. We train the networks on rendered 3D models of chairs, tables, and cars. Our experiments show that the networks do not merely learn all images by heart, but rather find a meaningful representation of 3D models allowing them to assess the similarity of different models, interpolate between given views to generate the missing ones, extrapolate views, and invent new objects not present in the training set by recombining training instances, or even two different object classes. Moreover, we show that such generative networks can be used to find correspondences between different objects from the dataset, outperforming existing approaches on this task."
            },
            "slug": "Learning-to-Generate-Chairs,-Tables-and-Cars-with-Dosovitskiy-Springenberg",
            "title": {
                "fragments": [],
                "text": "Learning to Generate Chairs, Tables and Cars with Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Generative \u2018up-convolutional\u2019 neural networks which are able to generate images of objects given object style, viewpoint, and color are trained and it is shown that such generative networks can be used to find correspondences between different objects from the dataset, outperforming existing approaches on this task."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073063"
                        ],
                        "name": "Lucas Theis",
                        "slug": "Lucas-Theis",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Theis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucas Theis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422336"
                        ],
                        "name": "A\u00e4ron van den Oord",
                        "slug": "A\u00e4ron-van-den-Oord",
                        "structuredName": {
                            "firstName": "A\u00e4ron",
                            "lastName": "Oord",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A\u00e4ron van den Oord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731199"
                        ],
                        "name": "M. Bethge",
                        "slug": "M.-Bethge",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Bethge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bethge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 17
                            }
                        ],
                        "text": "trivially fooled (Theis et al., 2015) by small image transforms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 95
                            }
                        ],
                        "text": "We also do not use log-likelihood metrics to quantitatively assess the model, as it is a poor (Theis et al., 2015) metric."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 66
                            }
                        ],
                        "text": "Nearest neighbors in pixel or feature space are\ntrivially fooled (Theis et al., 2015) by small image transforms."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2187805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39e0c341351f8f4a39ac890b96217c7f4bde5369",
            "isKey": true,
            "numCitedBy": 827,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Probabilistic generative models can be used for compression, denoising, inpainting, texture synthesis, semi-supervised learning, unsupervised feature learning, and other tasks. Given this wide range of applications, it is not surprising that a lot of heterogeneity exists in the way these models are formulated, trained, and evaluated. As a consequence, direct comparison between models is often difficult. This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models with a focus on image models. In particular, we show that three of the currently most commonly used criteria---average log-likelihood, Parzen window estimates, and visual fidelity of samples---are largely independent of each other when the data is high-dimensional. Good performance with respect to one criterion therefore need not imply good performance with respect to the other criteria. Our results show that extrapolation from one criterion to another is not warranted and generative models need to be evaluated directly with respect to the application(s) they were intended for. In addition, we provide examples demonstrating that Parzen window estimates should generally be avoided."
            },
            "slug": "A-note-on-the-evaluation-of-generative-models-Theis-Oord",
            "title": {
                "fragments": [],
                "text": "A note on the evaluation of generative models"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article reviews mostly known but often underappreciated properties relating to the evaluation and interpretation of generative models with a focus on image models and shows that three of the currently most commonly used criteria---average log-likelihood, Parzen window estimates, and visual fidelity of samples---are largely independent of each other when the data is high-dimensional."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180232"
                        ],
                        "name": "Yuval Netzer",
                        "slug": "Yuval-Netzer",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Netzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Netzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156632012"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726358"
                        ],
                        "name": "A. Bissacco",
                        "slug": "A.-Bissacco",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bissacco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bissacco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144397975"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 47
                            }
                        ],
                        "text": "On the StreetView House Numbers dataset (SVHN)(Netzer et al., 2011), we use the features of the discriminator of a DCGAN for supervised purposes when labeled data is scarce."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16852518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02227c94dd41fe0b439e050d377b0beb5d427cda",
            "isKey": false,
            "numCitedBy": 3896,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks."
            },
            "slug": "Reading-Digits-in-Natural-Images-with-Unsupervised-Netzer-Wang",
            "title": {
                "fragments": [],
                "text": "Reading Digits in Natural Images with Unsupervised Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new benchmark dataset for research use is introduced containing over 600,000 labeled digits cropped from Street View images, and variants of two recently proposed unsupervised feature learning methods are employed, finding that they are convincingly superior on benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1425082935"
                        ],
                        "name": "Xinyun Chen",
                        "slug": "Xinyun-Chen",
                        "structuredName": {
                            "firstName": "Xinyun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyun Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17735339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "An intriguing property of deep neural networks is the existence of adversarial examples, which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work, we are the first to conduct an extensive study of the transferability over large models and a large scale dataset, and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples, and show that while transferable non-targeted adversarial examples are easy to find, targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore, we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches, we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally, we show that the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai.com, which is a black-box image classification system."
            },
            "slug": "Under-Review-as-a-Conference-Paper-at-Iclr-2017-Ex-Chen",
            "title": {
                "fragments": [],
                "text": "Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work is the first to conduct an extensive study of the transferability over large models and a large scale dataset, and it is also theFirst to study the transferabilities of targeted adversarial examples with their target labels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10546515,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "007d73c91a1bf90d72eb59fbdd8791a4b009f363",
            "isKey": false,
            "numCitedBy": 587,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Many algorithms are available to learn deep hierarchies of features from unlabeled data, especially images. In many cases, these algorithms involve multi-layered networks of features (e.g., neural networks) that are sometimes tricky to train and tune and are difficult to scale up to many machines effectively. Recently, it has been found that K-means clustering can be used as a fast alternative training method. The main advantage of this approach is that it is very fast and easily implemented at large scale. On the other hand, employing this method in practice is not completely trivial: K-means has several limitations, and care must be taken to combine the right ingredients to get the system to work well. This chapter will summarize recent results and technical tricks that are needed to make effective use of K-means clustering for learning large-scale representations of images. We will also connect these results to other well-known algorithms to make clear when K-means can be most useful and convey intuitions about its behavior that are useful for debugging and engineering new systems."
            },
            "slug": "Learning-Feature-Representations-with-K-Means-Coates-Ng",
            "title": {
                "fragments": [],
                "text": "Learning Feature Representations with K-Means"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This chapter will summarize recent results and technical tricks that are needed to make effective use of K-means clustering for learning large-scale representations of images and connect these results to other well-known algorithms to make clear when K-Means can be most useful."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096458"
                        ],
                        "name": "Luke Metz",
                        "slug": "Luke-Metz",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Metz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Metz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16443937"
                        ],
                        "name": "Ben Poole",
                        "slug": "Ben-Poole",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Poole",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Poole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144846367"
                        ],
                        "name": "D. Pfau",
                        "slug": "D.-Pfau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pfau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pfau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1407546424"
                        ],
                        "name": "J. Sohl-Dickstein",
                        "slug": "J.-Sohl-Dickstein",
                        "structuredName": {
                            "firstName": "Jascha",
                            "lastName": "Sohl-Dickstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sohl-Dickstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6610705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "488bb25e0b1777847f04c943e6dbc4f84415b712",
            "isKey": false,
            "numCitedBy": 741,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method to stabilize Generative Adversarial Networks (GANs) by defining the generator objective with respect to an unrolled optimization of the discriminator. This allows training to be adjusted between using the optimal discriminator in the generator's objective, which is ideal but infeasible in practice, and using the current value of the discriminator, which is often unstable and leads to poor solutions. We show how this technique solves the common problem of mode collapse, stabilizes training of GANs with complex recurrent generators, and increases diversity and coverage of the data distribution by the generator."
            },
            "slug": "Unrolled-Generative-Adversarial-Networks-Metz-Poole",
            "title": {
                "fragments": [],
                "text": "Unrolled Generative Adversarial Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work introduces a method to stabilize Generative Adversarial Networks by defining the generator objective with respect to an unrolled optimization of the discriminator, and shows how this technique solves the common problem of mode collapse, stabilizes training of GANs with complex recurrent generators, and increases diversity and coverage of the data distribution by the generator."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1407546424"
                        ],
                        "name": "J. Sohl-Dickstein",
                        "slug": "J.-Sohl-Dickstein",
                        "structuredName": {
                            "firstName": "Jascha",
                            "lastName": "Sohl-Dickstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sohl-Dickstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144479710"
                        ],
                        "name": "Eric A. Weiss",
                        "slug": "Eric-A.-Weiss",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Weiss",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric A. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2333223"
                        ],
                        "name": "Niru Maheswaranathan",
                        "slug": "Niru-Maheswaranathan",
                        "structuredName": {
                            "firstName": "Niru",
                            "lastName": "Maheswaranathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niru Maheswaranathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25769960"
                        ],
                        "name": "S. Ganguli",
                        "slug": "S.-Ganguli",
                        "structuredName": {
                            "firstName": "Surya",
                            "lastName": "Ganguli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ganguli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 80
                            }
                        ],
                        "text": "Another approach generates images using an iterative forward diffusion process (Sohl-Dickstein et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14888175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dcef55a07f8607a819c21fe84131ea269cc2e3c",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm."
            },
            "slug": "Deep-Unsupervised-Learning-using-Nonequilibrium-Sohl-Dickstein-Weiss",
            "title": {
                "fragments": [],
                "text": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work develops an approach to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process, then learns a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 54
                            }
                        ],
                        "text": "A variational sampling approach to generating images (Kingma & Welling, 2013) has had some success, but the samples often suffer from being blurry."
                    },
                    "intents": []
                }
            ],
            "corpusId": 216078090,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f5dc5b9a2ba710937e2c413b37b053cd673df02",
            "isKey": false,
            "numCitedBy": 16777,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract: How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
            },
            "slug": "Auto-Encoding-Variational-Bayes-Kingma-Welling",
            "title": {
                "fragments": [],
                "text": "Auto-Encoding Variational Bayes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34961461"
                        ],
                        "name": "Andrew L. Maas",
                        "slug": "Andrew-L.-Maas",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Maas",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew L. Maas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 66
                            }
                        ],
                        "text": "Within the discriminator we found the leaky rectified activation (Maas et al., 2013) (Xu et al., 2015) to work well, especially for higher resolution modeling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "However, they have not leveraged the generators for supervised tasks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16489696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "367f2c63a6f6a10b3b64b8729d601e69337ee3cc",
            "isKey": false,
            "numCitedBy": 4401,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectified linear (ReL) hidden units demonstrates additional gains in final system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectifier nonlinearities produce 2% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the ReL unit with a gradient more amenable to optimization in an attempt to further improve deep rectifier networks."
            },
            "slug": "Rectifier-Nonlinearities-Improve-Neural-Network-Maas",
            "title": {
                "fragments": [],
                "text": "Rectifier Nonlinearities Improve Neural Network Acoustic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work explores the use of deep rectifier networks as acoustic models for the 300 hour Switchboard conversational speech recognition task, and analyzes hidden layer representations to quantify differences in how ReL units encode inputs as compared to sigmoidal units."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775622"
                        ],
                        "name": "Moritz Hardt",
                        "slug": "Moritz-Hardt",
                        "structuredName": {
                            "firstName": "Moritz",
                            "lastName": "Hardt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Moritz Hardt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9229182"
                        ],
                        "name": "B. Recht",
                        "slug": "B.-Recht",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Recht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Recht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 43
                            }
                        ],
                        "text": "Similarly, using a gradient descent on the inputs lets us inspect the ideal image that activates certain subsets of filters (Mordvintsev et al.)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 122
                            }
                        ],
                        "text": "Recent analysis has shown that there is a direct link between how fast models learn and their generalization performance (Hardt et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f7c85357c366b314b5b55c400869a62fd23372c",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that parametric models trained by a stochastic gradient method (SGM) with few iterations have vanishing generalization error. We prove our results by arguing that SGM is algorithmically stable in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex and continuous optimization. We derive stability bounds for both convex and non-convex optimization under standard Lipschitz and smoothness assumptions. \nApplying our results to the convex case, we provide new insights for why multiple epochs of stochastic gradient methods generalize well in practice. In the non-convex case, we give a new interpretation of common practices in neural networks, and formally show that popular techniques for training large deep models are indeed stability-promoting. Our findings conceptually underscore the importance of reducing training time beyond its obvious benefit."
            },
            "slug": "Train-faster,-generalize-better:-Stability-of-Hardt-Recht",
            "title": {
                "fragments": [],
                "text": "Train faster, generalize better: Stability of stochastic gradient descent"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "It is shown that parametric models trained by a stochastic gradient method (SGM) with few iterations have vanishing generalization error, and it is proved by arguing that SGM is algorithmically stable in the sense of Bousquet and Elisseeff."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 94
                            }
                        ],
                        "text": "While previous GAN work has used momentum to accelerate training, we used the Adam optimizer (Kingma & Ba, 2014) with tuned hyperparameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 90076,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, they have not leveraged the generators for supervised tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12808,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 940100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "714d48570351de99eb755735b543c7b84bd9fb46",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "What can you do with a million images? In this paper, we present a new image completion algorithm powered by a huge database of photographs gathered from the Web. The algorithm patches up holes in images by finding similar image regions in the database that are not only seamless, but also semantically valid. Our chief insight is that while the space of images is effectively infinite, the space of semantically differentiable scenes is actually not that large. For many image completion tasks, we are able to find similar scenes which contain image fragments that will convincingly complete the image. Our algorithm is entirely data driven, requiring no annotations or labeling by the user. Unlike existing image completion methods, our algorithm can generate a diverse set of image completions and we allow users to select among them. We demonstrate the superiority of our algorithm over existing image completion approaches."
            },
            "slug": "Scene-completion-using-millions-of-photographs-Hays-Efros",
            "title": {
                "fragments": [],
                "text": "Scene completion using millions of photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new image completion algorithm powered by a huge database of photographs gathered from the Web that can generate a diverse set of image completions and allow users to select among them."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2007"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824663"
                        ],
                        "name": "C. Archambeau",
                        "slug": "C.-Archambeau",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Archambeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Archambeau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15516652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "653a377af7e720face2c6c7f5f05ac5dbfc8e35f",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a generative model for performing sparse probabilistic projections, which includes sparse principal component analysis and sparse canonical correlation analysis as special cases. Sparsity is enforced by means of automatic relevance determination or by imposing appropriate prior distributions, such as generalised hyperbolic distributions. We derive a variational Expectation-Maximisation algorithm for the estimation of the hyperparameters and show that our novel probabilistic approach compares favourably to existing techniques. We illustrate how the proposed method can be applied in the context of cryptoanalysis as a preprocessing tool for the construction of template attacks."
            },
            "slug": "Sparse-probabilistic-projections-Archambeau-Bach",
            "title": {
                "fragments": [],
                "text": "Sparse probabilistic projections"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This work presents a generative model for performing sparse probabilistic projections, which includes sparse principal component analysis and sparse canonical correlation analysis as special cases, and derives a variational Expectation-Maximisation algorithm for the estimation of the hyperparameters."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773821"
                        ],
                        "name": "Matthew J. Beal",
                        "slug": "Matthew-J.-Beal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Beal",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew J. Beal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 58
                            }
                        ],
                        "text": "Canonical correlations analysis admixture / LDA / NMF [6] [2] [5]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1011289,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5f22d558526017f130c75ca35fe0a737c01aaee",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Variational approximations are becoming a widespread tool for Bayesian learning of graphical models. We provide some theoretical results for the variational updates in a very general family of conjugate-exponential graphical models. We show how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning. Applying these results to the Bayesian analysis of linear-Gaussian state-space models we obtain a learning procedure that exploits the Kalman smoothing propagation, while integrating over all model parameters. We demonstrate how this can be used to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set."
            },
            "slug": "Propagation-Algorithms-for-Variational-Bayesian-Ghahramani-Beal",
            "title": {
                "fragments": [],
                "text": "Propagation Algorithms for Variational Bayesian Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated how the belief propagation and the junction tree algorithms can be used in the inference step of variational Bayesian learning to infer the hidden state dimensionality of the state-space model in a variety of synthetic problems and one real high-dimensional data set."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9208779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66689a4f519cc1deb147def41f15870b97665487",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new statistical model for time series that iteratively segments data into regimes with approximately linear dynamics and learns the parameters of each of these linear regimes. This model combines and generalizes two of the most widely used stochastic time-series modelshidden Markov models and linear dynamical systemsand is closely related to models that are widely used in the control and econometrics literatures. It can also be derived by extending the mixture of experts neural network (Jacobs, Jordan, Nowlan, & Hinton, 1991) to its fully dynamical version, in which both expert and gating networks are recurrent. Inferring the posterior probabilities of the hidden states of this model is computationally intractable, and therefore the exact expectation maximization (EM) algorithm cannot be applied. However, we present a variational approximation that maximizes a lower bound on the log-likelihood and makes use of both the forward and backward recursions for hidden Markov models and the Kalman filter recursions for linear dynamical systems. We tested the algorithm on artificial data sets and a natural data set of respiration force from a patient with sleep apnea. The results suggest that variational approximations are a viable method for inference and learning in switching state-space models."
            },
            "slug": "Variational-Learning-for-Switching-State-Space-Ghahramani-Hinton",
            "title": {
                "fragments": [],
                "text": "Variational Learning for Switching State-Space Models"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new statistical model for time series that iteratively segments data into regimes with approximately linear dynamics and learns the parameters of each of these linear regimes is introduced and the results suggest that variational approximations are a viable method for inference and learning in switching state-space models."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17585310"
                        ],
                        "name": "M. I. Jordan",
                        "slug": "M.-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144215175"
                        ],
                        "name": "R. Jacobs",
                        "slug": "R.-Jacobs",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Canonical correlations analysis admixture / LDA / NMF [6] [2] [5]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 67000854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6d8a7fc2e2d53923832f9404376512068ca2a57",
            "isKey": false,
            "numCitedBy": 2136,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a tree-structured architecture for supervised learning. The statistical model underlying the architecture is a hierarchical mixture model in which both the mixture coefficients and the mixture components are generalized linear models (GLIM's). Learning is treated as a maximum likelihood problem; in particular, we present an Expectation-Maximization (EM) algorithm for adjusting the parameters of the architecture. We also develop an on-line learning algorithm in which the parameters are updated incrementally. Comparative simulation results are presented in the robot dynamics domain."
            },
            "slug": "Hierarchical-Mixtures-of-Experts-and-the-EM-Jordan-Jacobs",
            "title": {
                "fragments": [],
                "text": "Hierarchical mixtures of experts and the EM algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An Expectation-Maximization (EM) algorithm for adjusting the parameters of the tree-structured architecture for supervised learning and an on-line learning algorithm in which the parameters are updated incrementally."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 63
                            }
                        ],
                        "text": "In the context of evaluating learned representations of words (Mikolov et al., 2013) demonstrated that simple arithmetic operations revealed rich linear structure in representation space."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 26054,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 20
                            }
                        ],
                        "text": "We use Imagenet-1k (Deng et al., 2009) as a source of natural images for unsupervised training."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 95
                            }
                        ],
                        "text": "We trained DCGANs on three datasets, Large-scale Scene Understanding (LSUN) (Yu et al., 2015), Imagenet-1k and a newly assembled Faces dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 99
                            }
                        ],
                        "text": "To evaluate the quality of the representations learned by DCGANs for supervised tasks, we train on Imagenet-1k and then use the discriminator\u2019s convolutional features from all layers, maxpooling each layers representation to produce a 4 \u00d7 4 spatial grid."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b47265245e8db53a553049dcb27ed3e495fd625",
            "isKey": false,
            "numCitedBy": 27412,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2646100"
                        ],
                        "name": "T. Jones",
                        "slug": "T.-Jones",
                        "structuredName": {
                            "firstName": "Thouis",
                            "lastName": "Jones",
                            "middleNames": [
                                "Raymond"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 194
                            }
                        ],
                        "text": "The non-parametric models often do matching from a database of existing images, often matching patches of images, and have been used in texture synthesis (Efros et al., 1999), super-resolution (Freeman et al., 2002) and in-painting (Hays & Efros, 2007)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 26
                            }
                        ],
                        "text": ", 1999), super-resolution (Freeman et al., 2002) and in-painting (Hays & Efros, 2007)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6775458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e484ef6b9a1b38a86a8c79b5559a3070f327a033",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We call methods for achieving high-resolution enlargements of pixel-based images super-resolution algorithms. Many applications in graphics or image processing could benefit from such resolution independence, including image-based rendering (IBR), texture mapping, enlarging consumer photographs, and converting NTSC video content to high-definition television. We built on another training-based super-resolution algorithm and developed a faster and simpler algorithm for one-pass super-resolution. Our algorithm requires only a nearest-neighbor search in the training set for a vector derived from each patch of local image data. This one-pass super-resolution algorithm is a step toward achieving resolution independence in image-based representations. We don't expect perfect resolution independence-even the polygon representation doesn't have that-but increasing the resolution independence of pixel-based representations is an important task for IBR."
            },
            "slug": "Example-Based-Super-Resolution-Freeman-Jones",
            "title": {
                "fragments": [],
                "text": "Example-Based Super-Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work built on another training-based super- resolution algorithm and developed a faster and simpler algorithm for one-pass super-resolution that requires only a nearest-neighbor search in the training set for a vector derived from each patch of local image data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33523605"
                        ],
                        "name": "J. Portilla",
                        "slug": "J.-Portilla",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Portilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Portilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2475577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37afeac49518877dc96a3ca2ec3ebdfc5305e0a9",
            "isKey": false,
            "numCitedBy": 1811,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a universal statistical model for texture images in the context of an overcomplete complex wavelet transform. The model is parameterized by a set of statistics computed on pairs of coefficients corresponding to basis functions at adjacent spatial locations, orientations, and scales. We develop an efficient algorithm for synthesizing random images subject to these constraints, by iteratively projecting onto the set of images satisfying each constraint, and we use this to test the perceptual validity of the model. In particular, we demonstrate the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set. We also demonstrate the power of our model by successfully synthesizing examples drawn from a diverse collection of artificial and natural textures."
            },
            "slug": "A-Parametric-Texture-Model-Based-on-Joint-of-Portilla-Simoncelli",
            "title": {
                "fragments": [],
                "text": "A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A universal statistical model for texture images in the context of an overcomplete complex wavelet transform is presented, demonstrating the necessity of subgroups of the parameter set by showing examples of texture synthesis that fail when those parameters are removed from the set."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "Mixture of Experts Driven LDS IO-HMM Factorial HMM [7]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 519313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78e510627d3f28601e370212bf063bbfa539ebed",
            "isKey": false,
            "numCitedBy": 1200,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMMs) have proven to be one of the most widely used tools for learning probabilistic models of time series data. In an HMM, information about the past is conveyed through a single discrete variable\u2014the hidden state. We discuss a generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner. We describe an exact algorithm for inferring the posterior probabilities of the hidden state variables given the observations, and relate it to the forward\u2013backward algorithm for HMMs and to algorithms for more general graphical models. Due to the combinatorial nature of the hidden state representation, this exact algorithm is intractable. As in other intractable systems, approximate inference can be carried out using Gibbs sampling or variational methods. Within the variational framework, we present a structured approximation in which the the state variables are decoupled, yielding a tractable algorithm for learning the parameters of the model. Empirical comparisons suggest that these approximations are efficient and provide accurate alternatives to the exact methods. Finally, we use the structured approximation to model Bach's chorales and show that factorial HMMs can capture statistical structure in this data set which an unconstrained HMM cannot."
            },
            "slug": "Factorial-Hidden-Markov-Models-Ghahramani-Jordan",
            "title": {
                "fragments": [],
                "text": "Factorial Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A generalization of HMMs in which this state is factored into multiple state variables and is therefore represented in a distributed manner, and a structured approximation in which the the state variables are decoupled, yielding a tractable algorithm for learning the parameters of the model."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144464115"
                        ],
                        "name": "J. Palmer",
                        "slug": "J.-Palmer",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Palmer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Palmer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242717"
                        ],
                        "name": "D. Wipf",
                        "slug": "D.-Wipf",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wipf",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wipf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395421758"
                        ],
                        "name": "K. Kreutz-Delgado",
                        "slug": "K.-Kreutz-Delgado",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Kreutz-Delgado",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kreutz-Delgado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876925"
                        ],
                        "name": "B. Rao",
                        "slug": "B.-Rao",
                        "structuredName": {
                            "firstName": "Bhaskar",
                            "lastName": "Rao",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] Palmer, Wipf, Kreutz-Delgado, and Rao."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5209694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d2e6984435f5b35cb26fb9c2e081478a654d799",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider criteria for variational representations of non-Gaussian latent variables, and derive variational EM algorithms in general form. We establish a general equivalence among convex bounding methods, evidence based methods, and ensemble learning/Variational Bayes methods, which has previously been demonstrated only for particular cases."
            },
            "slug": "Variational-EM-Algorithms-for-Non-Gaussian-Latent-Palmer-Wipf",
            "title": {
                "fragments": [],
                "text": "Variational EM Algorithms for Non-Gaussian Latent Variable Models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A general equivalence is established among convex bounding methods, evidence based methods, and ensemble learning/Variational Bayes methods, which has previously been demonstrated only for particular cases."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145266088"
                        ],
                        "name": "T. Leung",
                        "slug": "T.-Leung",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Leung",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Leung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 221583955,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bba3264d6794538381687ad6e151a7f42f3872a9",
            "isKey": false,
            "numCitedBy": 1648,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random field model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and finding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "slug": "Texture-synthesis-by-non-parametric-sampling-Efros-Leung",
            "title": {
                "fragments": [],
                "text": "Texture synthesis by non-parametric sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A non-parametric method for texture synthesis that aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794818"
                        ],
                        "name": "S. Canu",
                        "slug": "S.-Canu",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Canu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Canu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070116614"
                        ],
                        "name": "leon",
                        "slug": "leon",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "leon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "leon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 73
                            }
                        ],
                        "text": "At one million samples per class, the DCGAN model outperforms InfiMNIST (Loosli et al., 2007), a hand developed data augmentation pipeline which uses translations and elastic deformations of training examples."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "No data augmentation was applied to the images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 72
                            }
                        ],
                        "text": "Model Test Error @50K samples Test Error @10M samples AlignMNIST - 1.4% InfiMNIST - 2.6% Real Data 3.1% -\nGAN 6.28% 5.65% DCGAN (ours) 2.98% 1.48%\nFigure 9: Side-by-side illustration of (from left-to-right) the MNIST dataset, generations from a baseline GAN, and generations from our DCGAN ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10555270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a91fe63627d5ebba45c488ed6754c60c928ae74",
            "isKey": true,
            "numCitedBy": 205,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "author?) [3] describe the efficient online LASVM algorithm using selective sampling. On the other hand, (author?) [24] propose a strategy for handling invariance in SVMs, also using selective sampling. This paper combines the two approaches to build a very large SVM. We present state-of-the-art results obtained on a handwritten digit recognition problem with 8 millions points on a single processor. This work also demonstrates that online SVMs can effectively handle really large databases."
            },
            "slug": "Training-Invariant-Support-Vector-Machines-using-Canu-leon",
            "title": {
                "fragments": [],
                "text": "Training Invariant Support Vector Machines using Selective Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper combines the two approaches to build a very large SVM, presenting state-of-the-art results obtained on a handwritten digit recognition problem with 8 millions points on a single processor and demonstrating that online SVMs can effectively handle really large databases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Canonical correlations analysis admixture / LDA / NMF [6] [2] [5]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29085cdffb3277c1c8fd10ac09e0d89452c8db83",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a recurrent architecture having a modular structure and we formulate a training procedure based on the EM algorithm. The resulting model has similarities to hidden Markov models, but supports recurrent networks processing style and allows to exploit the supervised learning paradigm while using maximum likelihood estimation."
            },
            "slug": "An-Input-Output-HMM-Architecture-Bengio-Frasconi",
            "title": {
                "fragments": [],
                "text": "An Input Output HMM Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A recurrent architecture having a modular structure that has similarities to hidden Markov models, but supports recurrent networks processing style and allows to exploit the supervised learning paradigm while using maximum likelihood estimation is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 269
                            }
                        ],
                        "text": "\u2026we validate that the CNN architecture used in DCGAN is not the key contributing factor of the model\u2019s performance by training a purely supervised CNN with the same architecture on the same data and optimizing this model via random search over 64 hyperparameter trials (Bergstra & Bengio, 2012)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Additionally, we found leaving the momentum term \u03b21 at the\nsuggested value of 0.9 resulted in training oscillation and instability while reducing it to 0.5 helped stabilize training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15700257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "188e247506ad992b8bc62d6c74789e89891a984f",
            "isKey": true,
            "numCitedBy": 5671,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent \"High Throughput\" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms."
            },
            "slug": "Random-Search-for-Hyper-Parameter-Optimization-Bergstra-Bengio",
            "title": {
                "fragments": [],
                "text": "Random Search for Hyper-Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid, and shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper- parameter optimization algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17380611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c8233a4560d00111b5436fd5d0c56a90e061708",
            "isKey": false,
            "numCitedBy": 473,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We give a probabilistic interpretation of canonical correlation (CCA) analysis as a latent variable model for two Gaussian random vectors. Our interpretation is similar to the probabilistic interpretation of principal component analysis (Tipping and Bishop, 1999, Roweis, 1998). In addition, we cast Fisher linear discriminant analysis (LDA) within the CCA framework."
            },
            "slug": "A-Probabilistic-Interpretation-of-Canonical-Bach-Jordan",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Interpretation of Canonical Correlation Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A probabilistic interpretation of canonical correlation (CCA) analysis as a latent variable model for two Gaussian random vectors for Fisher linear discriminant analysis within the CCA framework is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 171
                            }
                        ],
                        "text": "This achieves state of the art (for classification using 1000 labels) at 22.48% test error, improving upon another modifcation of CNNs designed to leverage unlabled data (Zhao et al., 2015)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 146
                            }
                        ],
                        "text": "\u2026popular method is to train auto-encoders (convolutionally, stacked (Vincent et al., 2010), separating the what and where components of the code (Zhao et al., 2015), ladder structures (Rasmus et al., 2015)) that encode an image into a compact code, and decode the code to reconstruct the image\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stacked what-where autoencoders"
            },
            "venue": {
                "fragments": [],
                "text": "Stacked what-where autoencoders"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11591502"
                        ],
                        "name": "A. Mordvintsev",
                        "slug": "A.-Mordvintsev",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Mordvintsev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mordvintsev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37232298"
                        ],
                        "name": "C. Olah",
                        "slug": "C.-Olah",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Olah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Olah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6818436"
                        ],
                        "name": "Mike Tyka",
                        "slug": "Mike-Tyka",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Tyka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Tyka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 69951972,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "ad2469bff83c9d5a55dd81040d369c8af29be132",
            "isKey": false,
            "numCitedBy": 539,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Inceptionism:-Going-Deeper-into-Neural-Networks-Mordvintsev-Olah",
            "title": {
                "fragments": [],
                "text": "Inceptionism: Going Deeper into Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inceptionism : Going deeper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Under review as a conference paper at ICLR 2016 Figure 11: Generations of a DCGAN that was trained on the Imagenet-1k dataset"
            },
            "venue": {
                "fragments": [],
                "text": "Under review as a conference paper at ICLR 2016 Figure 11: Generations of a DCGAN that was trained on the Imagenet-1k dataset"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Under review as a conference paper at ICLR 2016 Figure 10: More face generations from our Face DCGAN"
            },
            "venue": {
                "fragments": [],
                "text": "Under review as a conference paper at ICLR 2016 Figure 10: More face generations from our Face DCGAN"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unrolled generative adversarial networks. arXiv preprint arXiv:1611.02163"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Freeman , Thouis R . Jones and Egon C . Pasztor , \u201d Example - based super - resolution"
            },
            "venue": {
                "fragments": [],
                "text": "Computer Graphics and Applications"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 25
                            }
                        ],
                        "text": "Deep belief networks (Lee et al., 2009) have also been shown to work well in learning hierarchical representations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 33
                            }
                        ],
                        "text": "Generative Adversarial Networks (Goodfellow et al., 2014) generated images suffering from being noisy and incomprehensible."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 115
                            }
                        ],
                        "text": "We propose that one way to build good image representations is by training Generative Adversarial Networks (GANs) (Goodfellow et al., 2014), and later reusing parts of the generator and discriminator networks as feature extractors for supervised tasks."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generative adversarial nets. NIPS"
            },
            "venue": {
                "fragments": [],
                "text": "Generative adversarial nets. NIPS"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Auto-encoding variational bayes. arXiv preprint arXiv:1312"
            },
            "venue": {
                "fragments": [],
                "text": "Auto-encoding variational bayes. arXiv preprint arXiv:1312"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 194
                            }
                        ],
                        "text": "The non-parametric models often do matching from a database of existing images, often matching patches of images, and have been used in texture synthesis (Efros et al., 1999), super-resolution (Freeman et al., 2002) and in-painting (Hays & Efros, 2007)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example-based super-resolution. Computer Graphics and Applications"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE"
            },
            "year": 2002
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 59,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Unsupervised-Representation-Learning-with-Deep-Radford-Metz/8388f1be26329fa45e5807e968a641ce170ea078?sort=total-citations"
}