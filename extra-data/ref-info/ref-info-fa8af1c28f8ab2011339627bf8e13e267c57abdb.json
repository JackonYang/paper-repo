{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118965263"
                        ],
                        "name": "John R. Smith",
                        "slug": "John-R.-Smith",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 231
                            }
                        ],
                        "text": "The VisualSEEk project(2) has emphasized several unique objectives in order to improve image retrieval, such as: (1) automated extraction of localized regions and features [13], (2) querying by both feature and spatial information [14], (3) feature extraction from compressed data [15], (4) development of techniques for fast indexing and retrieval and (5) development of highly functional user tools."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "We will next extend the VisualSEEk system to extract and index regions of texture, and color and texture jointly [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7831560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa9a2a4e6b0f4b8641c5cf511028c275e98573b6",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a unified system for the extraction, representation and query of spatially localized color and texture regions. The system utilizes a back-projection of binary feature sets to identify and extract prominent regions. The binary feature sets provide an effective and easily indexable representation of color and texture. We also provide a mechanism for integrating features by combining the binary color and texture feature sets. This enables the extraction and representation of joint color and texture regions. Since all extracted regions are spatially localized, in image database queries the user can specify the locations and spatial boundaries of regions. We present the unified color and texture back-projection method and describe its implementation in the VisualSEEk content-based image retrieval system."
            },
            "slug": "Local-color-and-texture-extraction-and-spatial-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "Local color and texture extraction and spatial query"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A unified system for the extraction, representation and query of spatially localized color and texture regions by utilizing a back-projection of binary feature sets to identify and extract prominent regions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd IEEE International Conference on Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47088868"
                        ],
                        "name": "Joshua R. Smith",
                        "slug": "Joshua-R.-Smith",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua R. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 39
                            }
                        ],
                        "text": "Searching for im\u00adages and videos on the World-Wide Web."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "The VisualSEEk tools are also being ported to an application for searching in a collection of over one million images and videos from the World-Wide Web [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 164
                            }
                        ],
                        "text": "The VisualSEEk tools ch O ch O are also being ported to an application for searching in 0 ch1 \nT= ch1 Q: a collection of over one million images and videos from the World-Wide Web [16]. ch2 ch2 In \nthe next section, we present the color set representa- Figure 4: Generation of the binary color space \nfrom tion and back-projection region extraction process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Using a similar indexing strategy for retrieving images using color histograms in a database of 750; 000 images, the computation of the 60 best matches takes less than two seconds [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12306158,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "17d9915aa0b03bce4b336b68f180ae6434cca05d",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a prototype visual information system for searching for images and videos on the World-Wide Web. New visual information in the form of images, graphics, animations and videos is being published on the Web at an incredible rate. However, cataloging this visual data is beyond the capabilities of current text-based Web search engines. The key to cataloging it is the marriage of text-based processing and content-based visual analysis of the images and videos. In this paper, we describe a complete system by which visual information on the Web is (1) collected by automated agents, (2) processed in both text and visual feature domains, (3) catalogued and (4) indexed for fast search and retrieval. We introduce an image and video search engine which utilizes both text-based navigation and content-based technology for searching visually through the catalogued images and videos. Finally, we provide an initial evaluation based upon the cataloging of over one half million images and videos collected from the Web."
            },
            "slug": "Searching-for-Images-and-Videos-on-the-World-Wide-Smith",
            "title": {
                "fragments": [],
                "text": "Searching for Images and Videos on the World-Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A complete system by which visual information on the Web is collected by automated agents, processed in both text and visual feature domains, catalogued and indexed for fast search and retrieval is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37737599"
                        ],
                        "name": "A. Finkelstein",
                        "slug": "A.-Finkelstein",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Finkelstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Finkelstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 40
                            }
                        ],
                        "text": "C. E. Jacobs, A. Finkelstein, and D. H. Salesin."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "Jacobs, Finkelstein and \nSalesin [12] devised an image match criteria and sys\u00adtem which uses spatial information and visual features \nrepresented by dominant wavelet coefficients."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Jacobs, Finkelstein and Salesin [12] devised an image match criteria and system which uses spatial information and visual features represented by dominant wavelet coe cients."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7884491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e9bd47e9fa53e8719aba15e4367096317d45f74",
            "isKey": true,
            "numCitedBy": 835,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for searching in an image database using a query image that is similar to the intended target. The query image may be a hand-drawn sketch or a (potentially low-quality) scan of the image to be retrieved. Our searching algorithm makes use of multiresolution wavelet decompositions of the query and database images. The coefficients of these decompositions are distilled into small \u201csignatures\u201d for each image. We introduce an \u201cimage querying metric\u201d that operates on these signatures. This metric essentially compares how many significant wavelet coefficients the query has in common with potential targets. The metric includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries. The resulting algorithm is simple, requires very little storage overhead for the database of signatures, and is fast enough to be performed on a database of 20,000 images at interactive rates (on standard desktop machines) as a query is sketched. Our experiments with hundreds of queries in databases of 1000 and 20,000 images show dramatic improvement, in both speed and success rate, over using a conventional L1, L2, or color histogram norm. CR"
            },
            "slug": "Fast-multiresolution-image-querying-Jacobs-Finkelstein",
            "title": {
                "fragments": [],
                "text": "Fast multiresolution image querying"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An \u201cimage querying metric\u201d is introduced that operates on how many significant wavelet coefficients the query has in common with potential targets, and includes parameters that can be tuned, using a statistical analysis, to accommodate the kinds of image distortions found in different types of image queries."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50281905"
                        ],
                        "name": "R. Barber",
                        "slug": "R.-Barber",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Barber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Barber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712308"
                        ],
                        "name": "W. Equitz",
                        "slug": "W.-Equitz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Equitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Equitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123856769"
                        ],
                        "name": "E. Glasman",
                        "slug": "E.-Glasman",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Glasman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Glasman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143867341"
                        ],
                        "name": "D. Petkovic",
                        "slug": "D.-Petkovic",
                        "structuredName": {
                            "firstName": "Dragutin",
                            "lastName": "Petkovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Petkovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70341848"
                        ],
                        "name": "P. Yanker",
                        "slug": "P.-Yanker",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Yanker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Yanker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690237"
                        ],
                        "name": "G. Taubin",
                        "slug": "G.-Taubin",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Taubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Taubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "Histogram Quadratic Distance The QBIC project uses the histogram quadratic distance metric for matching images [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "The QBIC system [3] provides querying of whole images and manually extracted regions by color, texture and shape but not spatial relationships."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "Therefore, recent techniques have been proposed to speed-up image retrieval by utilizing simple image features, such as color histograms [1], devising compact representations [2][3], e cient indexing structures [4], and utilizing e ective pre- ltering techniques [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14145220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "824aac4970a4d149b35c19a9d2d2dec4c994688e",
            "isKey": false,
            "numCitedBy": 2235,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In the query by image content (QBIC) project we are studying methods to query large on-line image databases using the images' content as the basis of the queries. Examples of the content we use include color, texture, and shape of image objects and regions. Potential applications include medical (`Give me other images that contain a tumor with a texture like this one'), photo-journalism (`Give me images that have blue at the top and red at the bottom'), and many others in art, fashion, cataloging, retailing, and industry. Key issues include derivation and computation of attributes of images and objects that provide useful query functionality, retrieval methods based on similarity as opposed to exact match, query by image example or user drawn image, the user interfaces, query refinement and navigation, high dimensional database indexing, and automatic and semi-automatic database population. We currently have a prototype system written in X/Motif and C running on an RS/6000 that allows a variety of queries, and a test database of over 1000 images and 1000 objects populated from commercially available photo clip art images. In this paper we present the main algorithms for color texture, shape and sketch query that we use, show example query results, and discuss future directions."
            },
            "slug": "QBIC-project:-querying-images-by-content,-using-and-Niblack-Barber",
            "title": {
                "fragments": [],
                "text": "QBIC project: querying images by content, using color, texture, and shape"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The main algorithms for color texture, shape and sketch query that are presented, show example query results, and discuss future directions are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40434992"
                        ],
                        "name": "J. Bach",
                        "slug": "J.-Bach",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052276135"
                        ],
                        "name": "Charles Fuller",
                        "slug": "Charles-Fuller",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Fuller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Fuller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722619"
                        ],
                        "name": "Amarnath Gupta",
                        "slug": "Amarnath-Gupta",
                        "structuredName": {
                            "firstName": "Amarnath",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amarnath Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690709"
                        ],
                        "name": "A. Hampapur",
                        "slug": "A.-Hampapur",
                        "structuredName": {
                            "firstName": "Arun",
                            "lastName": "Hampapur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hampapur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144152544"
                        ],
                        "name": "B. Horowitz",
                        "slug": "B.-Horowitz",
                        "structuredName": {
                            "firstName": "Bradley",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143988415"
                        ],
                        "name": "R. Humphrey",
                        "slug": "R.-Humphrey",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Humphrey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Humphrey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144938732"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Jain",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144808138"
                        ],
                        "name": "Chiao-Fe Shu",
                        "slug": "Chiao-Fe-Shu",
                        "structuredName": {
                            "firstName": "Chiao-Fe",
                            "lastName": "Shu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chiao-Fe Shu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "The Virage system [10] allows querying of only image global features such as color, composition, texture and structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41630036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87cc226aa060db976fbf6ac3a07969b33b544b96",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, the management of large image databases has relied exclusively on manually entered alphanumeric annotations. Systems are beginning to emerge in both the research and commercial sectors based on 'content-based' image retrieval, a technique which explicitly manages image assets by directly representing their visual attributes. The Virage image search engine provides an open framework for building such systems. The Virage engine expresses visual features as image 'primitives.' Primitives can be very general (such as color, shape, or texture) or quite domain specific (face recognition, cancer cell detection, etc.). The basic philosophy underlying this architecture is a transformation from the data-rich representation of explicit image pixels to a compact, semantic-rich representation of visually salient characteristics. In practice, the design of such primitives is non-trivial, and is driven by a number of conflicting real-world constraints (e.g. computation time vs. accuracy). The virage engine provides an open framework for developers to 'plug-in' primitives to solve specific image management problems. The architecture has been designed to support both static images and video in a unified paradigm. The infrastructure provided by the Virage engine can be utilized to address high-level problems as well, such as automatic, unsupervised keyword assignment, or image classification."
            },
            "slug": "Virage-image-search-engine:-an-open-framework-for-Bach-Fuller",
            "title": {
                "fragments": [],
                "text": "Virage image search engine: an open framework for image management"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The Virage engine provides an open framework for developers to 'plug-in' primitives to solve specific image management problems and can be utilized to address high-level problems as well, such as automatic, unsupervised keyword assignment, or image classification."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052232"
                        ],
                        "name": "V. Gudivada",
                        "slug": "V.-Gudivada",
                        "structuredName": {
                            "firstName": "Venkat",
                            "lastName": "Gudivada",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Gudivada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714283"
                        ],
                        "name": "Vijay V. Raghavan",
                        "slug": "Vijay-V.-Raghavan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Raghavan",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay V. Raghavan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "For example, comparisons based upon 2-D strings [6], spatial quad-trees [7] and graphs [8] provide for exible and e cient spatial querying."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14252817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9600db408b6e3c81b87d52c3a78c13b8b845c93",
            "isKey": false,
            "numCitedBy": 337,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Similarity-based retrieval of images is an important task in many image database applications. A major class of users' requests requires retrieving those images in the database that are spatially similar to the query image. We propose an algorithm for computing the spatial similarity between two symbolic images. A symbolic image is a logical representation of the original image where the image objects are uniquely labeled with symbolic names. Spatial relationships in a symbolic image are represented as edges in a weighted graph referred to as spatial-orientation graph. Spatial similarity is then quantified in terms of the number of, as well as the extent to which, the edges of the spatial-orientation graph of the database image conform to the corresponding edges of the spatial-orientation graph of the query image.\nThe proposed algorithm is robust in the sense that it can deal with translation, scale, and rotational variances in images. The algorithm has quadratic time complexity in terms of the total number of objects in both the database and query images. We also introduce the idea of quantifying a system's retrieval quality by having an expert specify the expected rank ordering with respect to each query for a set of test queries. This enables us to assess the quality of algorithms comprehensively for retrieval in image databases. The characteristics of the proposed algorithm are compared with those of the previously available algorithms using a testbed of images. The comparison demonstrated that our algorithm is not only more efficient but also provides a rank ordering of images that consistently matches with the expert's expected rank ordering."
            },
            "slug": "Design-and-evaluation-of-algorithms-for-image-by-Gudivada-Raghavan",
            "title": {
                "fragments": [],
                "text": "Design and evaluation of algorithms for image retrieval by spatial similarity"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An algorithm for computing the spatial similarity between two symbolic images that is robust in the sense that it can deal with translation, scale, and rotational variances in images, and has quadratic time complexity in terms of the total number of objects in both the database and query images."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696998"
                        ],
                        "name": "A. Soffer",
                        "slug": "A.-Soffer",
                        "structuredName": {
                            "firstName": "Aya",
                            "lastName": "Soffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Soffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "The problem has only recently been addressed in limited applications, for maps in [9] and for medical images that contain both labeled and unlabeled regions [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2185670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4260cf55092ecaab445cbc6544c760b8eed720cc",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Two approaches for integrating images into the framework of a database management system are presented. The classification approach preprocesses all images and attaches a semantic classification and an associated certainty factor to each object found in the image. The abstraction approach describes each object in the image by using a vector consisting of the values of some of its features (e.g., shape, genus, etc.). The approaches differ in the way in which responses to queries that are based on image content are computed. In the classification approach, images are retrieved on the basis of whether or not they contain objects that have the same classification as query objects. In the abstraction approach, retrieval is on the basis of similarity of feature vector values of these objects. Both the pattern recognition and indexing aspects of the method are addressed for each approach. The emphasis is on extracting both contextual and spatial information from the raw images. Methods for storing and indexing symbolic images as tuples in a relation are presented for each approach. Indices are constructed for both the contextual and the spatial data. The user interface for a pictorial information system based on these two approaches is also presented."
            },
            "slug": "Retrieval-by-content-in-symbolic-image-databases-Soffer-Samet",
            "title": {
                "fragments": [],
                "text": "Retrieval by content in symbolic-image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Two approaches for integrating images into the framework of a database management system are presented and the user interface for a pictorial information system based on these two approaches is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118965263"
                        ],
                        "name": "John R. Smith",
                        "slug": "John-R.-Smith",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Smith",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John R. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 236
                            }
                        ],
                        "text": "c[m] = 1 if h[m] m 0 otherwise: (7) Color sets work well to represent regional color since (1) Tc and Q M c have been derived to give a complete set of distinct colors and (2) salient regions possess only a few, equally dominant colors [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "The VisualSEEk project(2) has emphasized several unique objectives in order to improve image retrieval, such as: (1) automated extraction of localized regions and features [13], (2) querying by both feature and spatial information [14], (3) feature extraction from compressed data [15], (4) development of techniques for fast indexing and retrieval and (5) development of highly functional user tools."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "We choose Qc , as illustrated in Figure 5, to quantize HSV into M = 166 colors [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "We brie y describe the technique here and note that a more detailed presentation appears in [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1648265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19ac010418e54a32c61d6f72a67153ec22e95d9f",
            "isKey": false,
            "numCitedBy": 632,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The growth of digital image and video archives is increasing the need for tools that effectively filter and efficiently search through large amounts of visual data. Towards this goal we propose a technique by which the color content of images and videos is automatically extracted to form a class of meta-data that is easily indexed. The color indexing algorithm uses the back- projection of binary color sets to extract color regions from images. This technique provides for both the automated extraction of regions and representation of their color content. It overcomes some of the problems with color histogram techniques such as high-dimensional feature vectors, spatial localization, indexing and distance computation. We present the binary color set back-projection technique and discuss its implementation in the VisualSEEk content- based image/video retrieval system for the World Wide Web. We also evaluate the retrieval effectiveness of the color set back-projection method and compare its performance to other color image retrieval methods."
            },
            "slug": "Tools-and-techniques-for-color-image-retrieval-Smith-Chang",
            "title": {
                "fragments": [],
                "text": "Tools and techniques for color image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a technique by which the color content of images and videos is automatically extracted to form a class of meta-data that is easily indexed and evaluates the retrieval effectiveness of the color set back-projection method and compares its performance to other color image retrieval methods."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081718"
                        ],
                        "name": "M. Stricker",
                        "slug": "M.-Stricker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Stricker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stricker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2908099"
                        ],
                        "name": "A. Dimai",
                        "slug": "A.-Dimai",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Dimai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dimai"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 34
                            }
                        ],
                        "text": "Related Work A recent approach by Stricker and Dimai \n[2] divides each image into five fuzzy regions which contribute to the color moment representation of \nthe image s color."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 175
                            }
                        ],
                        "text": "Therefore, recent techniques have been proposed to speed-up image retrieval by utilizing simple image features, such as color histograms [1], devising compact representations [2][3], e cient indexing structures [4], and utilizing e ective pre- ltering techniques [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "Related Work A recent approach by Stricker and Dimai [2] divides each image into ve fuzzy regions which contribute to the color moment representation of the image's color."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 89
                            }
                        ],
                        "text": "Color indexing. \nin\u00adternational Journal of Computer Vision, 7:11991, 2, M. Stricker and A. Dimai."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15041591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56b0814322903a5ff5f81404a3b213de2fe9d7e1",
            "isKey": true,
            "numCitedBy": 303,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "To improve the discrimination power of color indexing techniques we encode a minimal amount of spatial information in the index. We propose an approach that lies between uniformly tesselating the images with rectangular regions and relying on fully segmented images. For each image we define 5 partially overlapping, fuzzy regions. From each region in the image we extract the first three moments of the color distribution and store them in the index. The feature vectors in the index are relatively insensitive to small translations and small rotations of an image because they are extracted from fuzzy regions. To retrieve images we define a function which measures the similarity of two color feature vectors. Invariance of retrieval results with respect to the typical image rotations of 90 degrees around the center of the image is guaranteed because our feature similarity function exploits the spatial arrangement of the 5 image regions. We present experimental results using an image database which contains more than 11,000 color images. Our experiments demonstrate clearly that our weak encoding of spatial information significantly increases the discrimination power of the index compared to plain color indexing techniques."
            },
            "slug": "Color-indexing-with-weak-spatial-constraints-Stricker-Dimai",
            "title": {
                "fragments": [],
                "text": "Color indexing with weak spatial constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This work proposes an approach that lies between uniformly tesselating the images with rectangular regions and relying on fully segmented images, and encoding a minimal amount of spatial information in the index to improve the discrimination power of color indexing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50659286"
                        ],
                        "name": "A. Guttman",
                        "slug": "A.-Guttman",
                        "structuredName": {
                            "firstName": "Antonin",
                            "lastName": "Guttman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guttman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "The r-tree provides a dynamic structure for indexing k D rectangles [17], here k = 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 876601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5847fb3899eea98d544cced63d49886ecb17d9b",
            "isKey": false,
            "numCitedBy": 6039,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to handle spatial data efficiently, as required in computer aided design and geo-data applications, a database system needs an index mechanism that will help it retrieve data items quickly according to their spatial locations However, traditional indexing methods are not well suited to data objects of non-zero size located m multi-dimensional spaces In this paper we describe a dynamic index structure called an R-tree which meets this need, and give algorithms for searching and updating it. We present the results of a series of tests which indicate that the structure performs well, and conclude that it is useful for current database systems in spatial applications"
            },
            "slug": "R-trees:-a-dynamic-index-structure-for-spatial-Guttman",
            "title": {
                "fragments": [],
                "text": "R-trees: a dynamic index structure for spatial searching"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A dynamic index structure called an R-tree is described which meets this need, and algorithms for searching and updating it are given and it is concluded that it is useful for current database systems in spatial applications."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '84"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31841558"
                        ],
                        "name": "G. Pass",
                        "slug": "G.-Pass",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Pass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Pass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2984143"
                        ],
                        "name": "R. Zabih",
                        "slug": "R.-Zabih",
                        "structuredName": {
                            "firstName": "Ramin",
                            "lastName": "Zabih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zabih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109459020"
                        ],
                        "name": "Justin Miller",
                        "slug": "Justin-Miller",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Pass, Zabih and Miller [11] devised a technique which splits a global image histogram into coherent and scattered components."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 16
                            }
                        ],
                        "text": "Paas, Zabih and Miller [11] devised a technique which splits a \nglobal image histogram into coherent and scat\u00adtered components."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 30
                            }
                        ],
                        "text": "11, G. Pass, R. Zabih, and J. Miller."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14655649,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "bfe2ba7690e2351e5d5bfa4b99788f004ef9fc93",
            "isKey": true,
            "numCitedBy": 982,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Color histograms are used to compare images in many applications. Their advantages are efficiency, and insensitivity to small changes in camera viewpoint. However, color histograms lack spatial information, so images with very different appearances can have similar histograms. For example, a picture of fall foliage might contain a large number of scattered red pixels; this could have a similar color histogram to a picture with a single large red object. We describe a histogram-based method for comparing images that incorporates spatial information. We classify each pixel in a given color bucket as either coherent or incoherent, based on whether or not it is part of a large similarly-colored region. A color coherence vector (CCV) stores the number of coherent versus incoherent pixels with each color. By separating coherent pixels from incoherent pixels, CCV\u2019s provide finer distinctions than color histograms. CCV\u2019s can be computed at over 5 images per second on a standard workstation. A database with 15,000 images can be queried for the images with the most similar CCV\u2019s in under 2 seconds. We show that CCV\u2019s can give superior results to color his\u2217To whom correspondence should be addressed tograms for image retrieval."
            },
            "slug": "Comparing-images-using-color-coherence-vectors-Pass-Zabih",
            "title": {
                "fragments": [],
                "text": "Comparing images using color coherence vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that CCV\u2019s can give superior results to color histogram-based methods for comparing images that incorporates spatial information, and to whom correspondence should be addressed tograms for image retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '96"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9546964"
                        ],
                        "name": "Shih-Fu Chang",
                        "slug": "Shih-Fu-Chang",
                        "structuredName": {
                            "firstName": "Shih-Fu",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Fu Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 285,
                                "start": 281
                            }
                        ],
                        "text": "The VisualSEEk project(2) has emphasized several unique objectives in order to improve image retrieval, such as: (1) automated extraction of localized regions and features [13], (2) querying by both feature and spatial information [14], (3) feature extraction from compressed data [15], (4) development of techniques for fast indexing and retrieval and (5) development of highly functional user tools."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206803869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "329081a2828ca8f5efae0a4545c8c20c90dd03c8",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "As massive amount of visual materials are captured and stored in visual information systems, effective and efficient image indexing and manipulation techniques are required. Most visual materials in visual information systems are stored in some compressed forms. Therefore, it is desirable to explore image technologies for feature extraction and image manipulation in the compressed domain. In other words, image feature extraction and manipulation are performed on compressed images/video without decoding, or with minimal decoding only. Although the compressed-domain approach imposes many constraints, it provides great potential for reducing computational complexity, because of reduction of the amount of data after compression. This paper provides an overview of our research in this area. Specifically, it describes the results and the future directions of our work on compressed-domain texture feature extraction, image matching, image manipulation, and video indexing."
            },
            "slug": "Compressed-domain-techniques-for-image/video-and-Chang",
            "title": {
                "fragments": [],
                "text": "Compressed-domain techniques for image/video indexing and manipulation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results and the future directions of the work on compressed-domain texture feature extraction, image matching, image manipulation, and video indexing are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106531491"
                        ],
                        "name": "Q. Shi",
                        "slug": "Q.-Shi",
                        "structuredName": {
                            "firstName": "Qing-Yun",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107472893"
                        ],
                        "name": "C. Yan",
                        "slug": "C.-Yan",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Yan",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Yan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "To circumvent this exhaustive search, we utilize a convenient representation of image spatial relationships and their comparisons based upon 2-D strings [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "For example, comparisons based upon 2-D strings [6], spatial quad-trees [7] and graphs [8] provide for exible and e cient spatial querying."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12115567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fdfe67d4c053198be988c5fb24926bcfebebd26",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a new way of representing a symbolic picture by a two-dimensional string. A picture query can also be specified as a 2-D string. The problem of pictorial information retrieval then becomes a problem of 2-D subsequence matching. We present algorithms for encoding a symbolic picture into its 2-D string representation, reconstructing a picture from its 2-D string representation, and matching a 2-D string with another 2-D string. We also prove the necessary and sufficient conditions to characterize ambiguous pictures for reduced 2-D strings as well as normal 2-D strings. This approach thus allows an efficient and natural way to construct iconic indexes for pictures."
            },
            "slug": "Iconic-Indexing-by-2-D-Strings-Chang-Shi",
            "title": {
                "fragments": [],
                "text": "Iconic Indexing by 2-D Strings"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This approach allows an efficient and natural way to construct iconic indexes for pictures and proves the necessary and sufficient conditions to characterize ambiguous pictures for reduced 2D strings as well as normal 2-D strings."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719385"
                        ],
                        "name": "H. Samet",
                        "slug": "H.-Samet",
                        "structuredName": {
                            "firstName": "Hanan",
                            "lastName": "Samet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Samet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The quad-tree provides quick access to 2-D data points [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "For example, comparisons based upon 2-D strings [6], spatial quad-trees [7] and graphs [8] provide for exible and e cient spatial querying."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10319214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c2e776fb40667fde3ece360cb829f717ce5daf9",
            "isKey": false,
            "numCitedBy": 2313,
            "numCiting": 293,
            "paperAbstract": {
                "fragments": [],
                "text": "Apercu sur les quadarbres et les structures de donnees hierarchiques. Elles sont basees sur le principe de decomposition recursive. L'accentuation est mise sur la representation de donnees dans les applications de traitement d'images, d'infographie, les systemes d'informations geographiques et la robotique. On examine en detail un certain nombre d'operations dans lesquelles de telles structures de donnees trouvent leur utilisation"
            },
            "slug": "The-Quadtree-and-Related-Hierarchical-Data-Samet",
            "title": {
                "fragments": [],
                "text": "The Quadtree and Related Hierarchical Data Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "L'accentuation est mise sur la representation de donnees dans les applications de traitement d'images, d'infographie, les systemes d'informations geographiques and the robotique."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 211
                            }
                        ],
                        "text": "Therefore, recent techniques have been proposed to speed-up image retrieval by utilizing simple image features, such as color histograms [1], devising compact representations [2][3], e cient indexing structures [4], and utilizing e ective pre- ltering techniques [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "The problem has only recently been addressed in limited applications, for maps in [9] and for medical images that contain both labeled and unlabeled regions [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58710763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "836bfe1994a174b41c46e7244845b44f8702eeab",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Similarity-Searching-in-Large-Image-DataBases-Petrakis-Faloutsos",
            "title": {
                "fragments": [],
                "text": "Similarity Searching in Large Image DataBases"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40179523"
                        ],
                        "name": "J. L. Hafner",
                        "slug": "J.-L.-Hafner",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hafner",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L. Hafner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712308"
                        ],
                        "name": "W. Equitz",
                        "slug": "W.-Equitz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Equitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Equitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141915"
                        ],
                        "name": "W. Niblack",
                        "slug": "W.-Niblack",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Niblack",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Niblack"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Therefore, in large database applications, histogram indexing strategies, such as pre- ltering [5], are required to avoid exhaustive search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "In QBIC, the computation is reduced by the technique in [5] to O(M(2)C +M N ), where typically, M 00 = 3, and C << N ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 263
                            }
                        ],
                        "text": "Therefore, recent techniques have been proposed to speed-up image retrieval by utilizing simple image features, such as color histograms [1], devising compact representations [2][3], e cient indexing structures [4], and utilizing e ective pre- ltering techniques [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 30
                            }
                        ],
                        "text": "We note that the technique in [5] can be combined with the color set technique to further reduce complexity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33312054,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "e1dec5c4aaff8e79ebdcca5feec2640aebce323a",
            "isKey": true,
            "numCitedBy": 934,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "An improved shipping container having novel locking features in the end panel and corner flaps. The novel locking features improved bulge resistance at the end panels from sideward bulge of the product. The improved container comprises a pair of corner flaps being hinged from the side panels and folded inwardly against an end panel with the two corner flaps and end panel on each side of the container having a quadruple lock. The lock is formed by providing a locking tab on each corner flap as well as a pair of locking tabs on the end panel with the end panel and corner flaps locking tabs being designed to be swung and locked in the opening formed by the aligned mating locking tab."
            },
            "slug": "Efficient-Color-Histogram-Indexing-for-Quadratic-Hafner-Sawhney",
            "title": {
                "fragments": [],
                "text": "Efficient Color Histogram Indexing for Quadratic Form Distance Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "An improved shipping container having novel locking features in the end panel and corner flaps and improved bulge resistance at the end panels from sideward bulge of the product."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679040"
                        ],
                        "name": "Shi-Kuo Chang",
                        "slug": "Shi-Kuo-Chang",
                        "structuredName": {
                            "firstName": "Shi-Kuo",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Kuo Chang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "These examples of spatial reasoning can be inferred from the 2-D string [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "The 2-D string is a symbolic projection of the image along the x and y directions [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "Since the 2-D string captures the orthogonal relations of the regions in the image, conditions of overlap and surround can also be determined [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44318840,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "afdbc2e9997d47f3a42aa5d8210be4dfb7ff74aa",
            "isKey": true,
            "numCitedBy": 185,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "No wonder you activities are, reading will be always needed. It is not only to fulfil the duties that you need to finish in deadline time. Reading will encourage your mind and thoughts. Of course, reading will greatly develop your experiences about everything. Reading principles of pictorial information systems design is also a way as one of the collective books that gives many advantages. The advantages are not only for you, but for the other peoples with those meaningful benefits."
            },
            "slug": "Principles-of-pictorial-information-systems-design-Chang",
            "title": {
                "fragments": [],
                "text": "Principles of pictorial information systems design"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Reading principles of pictorial information systems design is also a way as one of the collective books that gives many advantages."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729390"
                        ],
                        "name": "Euripides G. M. Petrakis",
                        "slug": "Euripides-G.-M.-Petrakis",
                        "structuredName": {
                            "firstName": "Euripides",
                            "lastName": "Petrakis",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Euripides G. M. Petrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702392"
                        ],
                        "name": "C. Faloutsos",
                        "slug": "C.-Faloutsos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Faloutsos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Faloutsos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59672145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9996af7a068c50b5fc634abe17e6ede2e988b482",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Similarity-searching-in-large-image-database-Petrakis-Faloutsos",
            "title": {
                "fragments": [],
                "text": "Similarity searching in large image database"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "tronic Imaging: Science and Technology -Storage & Retrieval for Image and Video Databases IV"
            },
            "venue": {
                "fragments": [],
                "text": "tronic Imaging: Science and Technology -Storage & Retrieval for Image and Video Databases IV"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Intell"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Intell"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Manag. Data (SIGMOD)"
            },
            "venue": {
                "fragments": [],
                "text": "Manag. Data (SIGMOD)"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conf. Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Conf. Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine In-tell"
            },
            "venue": {
                "fragments": [],
                "text": "Machine In-tell"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 23,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/VisualSEEk:-a-fully-automated-content-based-image-Smith-Chang/fa8af1c28f8ab2011339627bf8e13e267c57abdb?sort=total-citations"
}