{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20678424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c86590e947c28e8791d1e8bab8fc8ab53302341f",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the work described here, the backpropagation neural network learning procedure is applied to the analysis and recognition of speech. This procedure takes a set of input/output pattern pairs and attempts to learn their functional relationship; it develops the necessary representational features during the course of learning. A series of computer simulation studies was carried out to assess the ability of these networks to accurately label sounds, to learn to recognize sounds without labels, and to learn feature representations of continuous speech. These studies demonstrated that the networks can learn to label presegmented test tokens with accuracies of up to 95%. Networks trained on segmented sounds using a strategy that requires no external labels were able to recognize and delineate sounds in continuous speech. These networks developed rich internal representations that included units which corresponded to such traditional distinctions as vowels and consonants, as well as units that were sensitive to novel and nonstandard features. Networks trained on a large corpus of unsegmented, continuous speech without labels also developed interesting feature representations, which may be useful in both segmentation and label learning. The results of these studies, while preliminary, demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "slug": "Learning-the-hidden-structure-of-speech.-Elman-Zipser",
            "title": {
                "fragments": [],
                "text": "Learning the hidden structure of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results of these studies demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2703811"
                        ],
                        "name": "R. Eckmiller",
                        "slug": "R.-Eckmiller",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Eckmiller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eckmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7648112"
                        ],
                        "name": "C. V. D. Malsburg",
                        "slug": "C.-V.-D.-Malsburg",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Malsburg",
                            "middleNames": [
                                "v.",
                                "d."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. V. D. Malsburg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13061488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee97f9b44b310f6915b841982200bf00870463b0",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The fifth-generation computers have essentially been designed around knowledge data bases. Originally they were supposed to accept natural data such as speech and images; these functions, however, have now been abandoned. Some vistas to sixthand later-generation computers have already been presented, too. The latter are supposed to be even more \"natural\". Certainly the fifth-generation computers have applied very traditional logic programming, but what could the alternative be? What new functions can evolve from the \"neural computer\" principles? This presentation expounds a few detailed questions of this kind. Also some more general problem areas and motivations for their handling are described. \"All forecasting is difficult, especially forecasting of the future.\" Old Chinese proverb 1. PARALLEL ASSOCIATIVE SEARCH AND INFERENCE IN KNOWLEDGE DATA BASES It is an old notion that the biological brain operates according to associative principles, and that the recall of items from memory is content-addressable (Aristotle, 384-322 B.C.). Naturally, associative mechanisms are characteristic of thinking processes, whereas nobody may want to claim that all the problem-solving procedures applied, say, in scientific thinking are directly derivable from them. It seems necessary to emphasize that cultural development has always been based on instrumental means: language, writing, logical and mathematical notations and systems, etc. which have developed during a very long time, and which obey their own mechanisms. People using them must only learn them as some kind of internal"
            },
            "slug": "Neural-Computers-Eckmiller-Malsburg",
            "title": {
                "fragments": [],
                "text": "Neural Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This presentation expounds a few detailed questions of this kind about what new functions can evolve from the \"neural computer\" principles and some more general problem areas and motivations for their handling."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Study Edition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516142"
                        ],
                        "name": "D. Tank",
                        "slug": "D.-Tank",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tank",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tank"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16810163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8879e718ab012e530608a72cddab3ac0edc30743",
            "isKey": false,
            "numCitedBy": 2070,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe how several optimization problems can be rapidly solved by highly interconnected networks of simple analog processors. Analog-to-digital (A/D) conversion was considered as a simple optimization problem, and an A/D converter of novel architecture was designed. A/D conversion is a simple example of a more general class of signal-decision problems which we show could also be solved by appropriately constructed networks. Circuits to solve these problems were designed using general principles which result from an understanding of the basic collective computational properties of a specific class of analog-processor networks. We also show that a network which solves linear programming problems can be understood from the same concepts."
            },
            "slug": "Simple-'neural'-optimization-networks:-An-A/D-and-a-Tank-Hopfield",
            "title": {
                "fragments": [],
                "text": "Simple 'neural' optimization networks: An A/D converter, signal decision circuit, and a linear programming circuit"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is described how several optimization problems can be rapidly solved by highly interconnected networks of simple analog processors, and it is shown that a network which solves linear programming Problems can be understood from the same concepts."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2537503,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "24b9eebe49cf7e00cf50cf7b7d9243386a23fe7c",
            "isKey": false,
            "numCitedBy": 6274,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "A model for a large network of \"neurons\" with a graded response (or sigmoid input-output relation) is studied. This deterministic system has collective properties in very close correspondence with the earlier stochastic model based on McCulloch - Pitts neurons. The content- addressable memory and other emergent collective properties of the original model also are present in the graded response model. The idea that such collective properties are used in biological systems is given added credence by the continued presence of such properties for more nearly biological \"neurons.\" Collective analog electrical circuits of the kind described will certainly function. The collective states of the two models have a simple correspondence. The original model will continue to be useful for simulations, because its connection to graded response systems is established. Equations that include the effect of action potentials in the graded response system are also developed."
            },
            "slug": "Neurons-with-graded-response-have-collective-like-Hopfield",
            "title": {
                "fragments": [],
                "text": "Neurons with graded response have collective computational properties like those of two-state neurons."
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A model for a large network of \"neurons\" with a graded response (or sigmoid input-output relation) is studied and collective properties in very close correspondence with the earlier stochastic model based on McCulloch - Pitts neurons are studied."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 784288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "isKey": false,
            "numCitedBy": 16692,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices."
            },
            "slug": "Neural-networks-and-physical-systems-with-emergent-Hopfield",
            "title": {
                "fragments": [],
                "text": "Neural networks and physical systems with emergent collective computational abilities."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model of a system having a large number of simple equivalent components, based on aspects of neurobiology but readily adapted to integrated circuits, produces a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775043"
                        ],
                        "name": "H. Graf",
                        "slug": "H.-Graf",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Graf",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Graf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31070601"
                        ],
                        "name": "B. Straughn",
                        "slug": "B.-Straughn",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Straughn",
                            "middleNames": [
                                "L."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Straughn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47750139"
                        ],
                        "name": "D. Tennant",
                        "slug": "D.-Tennant",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Tennant",
                            "middleNames": [
                                "Milan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tennant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145230652"
                        ],
                        "name": "D. B. Schwartz",
                        "slug": "D.-B.-Schwartz",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Schwartz",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B. Schwartz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62027607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9620c35b15e4a38223ed0b22438dd9a5ba71952d",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We designed an Electronic Neural Network (ENN) memory with 256 neurons on a single chip using a combination of analog and digital VLSI technology plus a custom microfabrication process. Amplifiers with inverting and noninverting outputs are used for the neurons to make inhibitory and excitatory connections. The connections between the individual neurons are provided by amorphous\u2010silicon resistors which are placed on the CMOS chip in the last fabrication step. This technique allows a very dense packing of the neurons. Electron\u2010beam direct\u2010writing is used to pattern the resistors making it easy to change the information stored in the network from one chip to the next."
            },
            "slug": "VLSI-implementation-of-a-neural-network-memory-with-Graf-Jackel",
            "title": {
                "fragments": [],
                "text": "VLSI implementation of a neural network memory with several hundreds of neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "An Electronic Neural Network memory with 256 neurons on a single chip using a combination of analog and digital VLSI technology plus a custom microfabrication process to allow a very dense packing of the neurons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51283223"
                        ],
                        "name": "P. Grant",
                        "slug": "P.-Grant",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Grant",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69402509"
                        ],
                        "name": "J. Sage",
                        "slug": "J.-Sage",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Sage",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sage"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60461330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac0890ff3b63d7e8570a382452400229b6eaa728",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares the performance of matched filters with several versions of nonlinear associative memory for a specific pattern recognition problem, where we attempt to identify the presence and orientation of an angled line. Comparative simulations are presented on the above processors for 5\u2013by\u20135 and 9\u2013by\u20139 pixel data fields when the input line patterns are corruped by Gaussian noise. We conclused that considerable sophistication was required in the nonlinear associative memory processor design to achieve equivalent performance to the matched filter. In all cases that matched filter was shown to exhibit a reduced computational load."
            },
            "slug": "A-comparison-of-neural-network-and-matched-filter-Grant-Sage",
            "title": {
                "fragments": [],
                "text": "A comparison of neural network and matched filter processing for detecting lines in images"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It was concluded that considerable sophistication was required in the nonlinear associative memory processor design to achieve equivalent performance to the matched filter, and in all cases that matched filter was shown to exhibit a reduced computational load."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083623461"
                        ],
                        "name": "David B. Parker",
                        "slug": "David-B.-Parker",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Parker",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David B. Parker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118914993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4d41caaa6e45176d450a145fa56eefbb73b9c23",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many different ways to connect neuron\u2010like cells into large scale learning networks. These different patterns of connections are called architectures. One problem in designing an architecture is deciding what types of neuron\u2010like cells to base it on. By examining the properties of learning networks that are independent of their architectures, this paper proposes that there is at least one type of cell which can be used in any reasonable architecture to give it nearly optimal performance. Cells of this type implement an algorithm called second order least mean square (2nd order LMS, for short)."
            },
            "slug": "A-comparison-of-algorithms-for-neuron-like-cells-Parker",
            "title": {
                "fragments": [],
                "text": "A comparison of algorithms for neuron-like cells"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proposed that there is at least one type of cell which can be used in any reasonable architecture to give it nearly optimal performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745131"
                        ],
                        "name": "S. Seneff",
                        "slug": "S.-Seneff",
                        "structuredName": {
                            "firstName": "Stephanie",
                            "lastName": "Seneff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Seneff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62471721,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "e309955bf0b97461e073fcfda6ca7ea910614c81",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer system for speech analysis based on human auditory processing is described. The system consists of a bank of 40 independent channels, spanning the frequency range from 130 to 6400 Hz. Each channel includes a linear critical band filter followed by a model for the transformation from basilar membrane motion to nerve fiber response, incorporating such nonlinear effects as half-wave rectification, adaptation, spontaneous response, and saturation. The output of this stage includes the detailed waveshape of each cycle of the probabilistic response, but the data are never reduced to a spike sequence. Finally, each channel is subjected independently to both envelope detection and synchrony detection, where the latter is tuned to the characteristic frequency [CF] of the associated filter. It is likely that the envelope response will be useful for marking acoustic boundaries and for making broad category decisions, whereas the synchronous response is more appropriate for making fine distinctions."
            },
            "slug": "A-computational-model-for-the-peripheral-auditory-Seneff",
            "title": {
                "fragments": [],
                "text": "A computational model for the peripheral auditory system: Application of speech recognition research"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A computer system for speech analysis based on human auditory processing is described, featuring a bank of 40 independent channels that includes a linear critical band filter followed by a model for the transformation from basilar membrane motion to nerve fiber response, incorporating such nonlinear effects as half-wave rectification, adaptation, spontaneous response, and saturation."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '86. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816022"
                        ],
                        "name": "B. Delgutte",
                        "slug": "B.-Delgutte",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Delgutte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Delgutte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36086875,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "64102ef3ba177779641d13b563ec3d670d6f2437",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Several processing schemes by which phonetically important information for vowels can be extracted from responses of auditory-nerve fibers are analyzed. The schemes are based on power spectra of period histograms obtained in response to a set of nine two-formant, steady-state, vowel-like stimuli presented at 60 and 75 dB SPL. One class of \"local filtering\" schemes, which was originally proposed by Young and Sachs [J. Acoust. Soc. Am. 66, 1381-1403 (1979)], consists of analyzing response patterns by filters centered at the characteristic frequencies (CF) of the fibers, so that a tonotopically arranged measure of synchronized response can be obtained. Various schemes in this class differ in the characteristics of the filter. For a wide range of filter bandwidths, formant frequencies correspond approximately to the CFs for which the response measure is maximal. If in addition, the bandwidths of the analyzing filters are made compatible with psychophysical measures of frequency selectivity, low-frequency harmonics of the stimulus fundamental are resolved in the output profile, so that fundamental frequency can also be estimated. In a second class of processing schemes, a dominant response component is defined for each fiber from a 1/6 octave spectral representation of the response pattern, and the formant frequencies are estimated from the most frequent values of the dominant component in the ensemble of auditory-nerve fibers. The local filtering schemes and the dominant component schemes can be related to \"place\" and \"periodicity\" models of auditory processing, respectively."
            },
            "slug": "Speech-coding-in-the-auditory-nerve:-II.-Processing-Delgutte",
            "title": {
                "fragments": [],
                "text": "Speech coding in the auditory nerve: II. Processing schemes for vowel-like sounds."
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Several processing schemes by which phonetically important information for vowels can be extracted from responses of auditory-nerve fibers are analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39981709"
                        ],
                        "name": "B. Gold",
                        "slug": "B.-Gold",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Gold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Gold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53681228,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "aad2de68832e1502002019548c8ecf5873563045",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A Hopfield model of 120 \u2018\u2018neurons\u2019\u2019 has been simulated on an LDSP (Lincoln Digital Signal Processor). The model has been applied to the study of problems in automatic discrimination of vowels and consonants. In the first problem, a spectral cross section was extracted by performing a fast Fourier transform on a 20 ms segment from the steady state portion of the vowel in a single syllable word. The spectrum was then smoothed and a one\u2010bit gradient measure applied at 120 frequency values, thus obtaining an assigned state for that vowel. This procedure was repeated until eight such assigned states were obtained. From this data, the connection matrix Tij was obtained using the associative equation, Tij=\u03a37s=0xsixsj Each xsi was the component of one of the assigned states."
            },
            "slug": "Hopfield-model-applied-to-vowel-and-consonant-Gold",
            "title": {
                "fragments": [],
                "text": "Hopfield model applied to vowel and consonant discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A Hopfield model of 120 \u2018\u2018neurons\u2019\u2019 has been simulated on an LDSP (Lincoln Digital Signal Processor) and the connection matrix Tij was obtained using the associative equation, Tij=\u03a37s=0xsixsj Each xsi was the component of one of the assigned states."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10080270"
                        ],
                        "name": "J. Makhoul",
                        "slug": "J.-Makhoul",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Makhoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Makhoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46924970"
                        ],
                        "name": "Salim Roukos",
                        "slug": "Salim-Roukos",
                        "structuredName": {
                            "firstName": "Salim",
                            "lastName": "Roukos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salim Roukos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793645"
                        ],
                        "name": "H. Gish",
                        "slug": "H.-Gish",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Gish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Gish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18820742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3f073ac7513183a9bf3a76154dcd245748d2ab6",
            "isKey": false,
            "numCitedBy": 903,
            "numCiting": 154,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantization, the process of approximating continuous-amplitude signals by digital (discrete-amplitude) signals, is an important aspect of data compression or coding, the field concerned with the reduction of the number of bits necessary to transmit or store analog data, subject to a distortion or fidelity criterion. The independent quantization of each signal value or parameter is termed scalar quantization, while the joint quantization of a block of parameters is termed block or vector quantization. This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization. Vector quantization is presented as a process of redundancy removal that makes effective use of four interrelated properties of vector parameters: linear dependency (correlation), nonlinear dependency, shape of the probability density function (pdf), and vector dimensionality itself. In contrast, scalar quantization can utilize effectively only linear dependency and pdf shape. The basic concepts are illustrated by means of simple examples and the theoretical limits of vector quantizer performance are reviewed, based on results from rate-distortion theory. Practical issues relating to quantizer design, implementation, and performance in actual applications are explored. While many of the methods presented are quite general and can be used for the coding of arbitrary signals, this paper focuses primarily on the coding of speech signals and parameters."
            },
            "slug": "Vector-quantization-in-speech-coding-Makhoul-Roukos",
            "title": {
                "fragments": [],
                "text": "Vector quantization in speech coding"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This tutorial review presents the basic concepts employed in vector quantization and gives a realistic assessment of its benefits and costs when compared to scalar quantization, and focuses primarily on the coding of speech signals and parameters."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143809344"
                        ],
                        "name": "G. Carpenter",
                        "slug": "G.-Carpenter",
                        "structuredName": {
                            "firstName": "Gail",
                            "lastName": "Carpenter",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Carpenter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682174"
                        ],
                        "name": "S. Grossberg",
                        "slug": "S.-Grossberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Grossberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Grossberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 25617413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "997e9960d2f98dc9ea0fd667c96cd1d06d958304",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neural-Dynamics-of-Category-Learning-and-Attention,-Carpenter-Grossberg",
            "title": {
                "fragments": [],
                "text": "Neural Dynamics of Category Learning and Recognition: Attention, Memory Consolidation, and Amnesia"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2165973"
                        ],
                        "name": "J. Feldman",
                        "slug": "J.-Feldman",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Feldman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Feldman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 62225923,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c8e33b624df1ef0da3eb6d9011ce710b5aa275b",
            "isKey": false,
            "numCitedBy": 736,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Much of the progress in the fields constituting cognitive science has been based upon the use of explicit information processing models, almost exclusively patterned after conventional serial computers. An extension of these ideas to massively parallel, connectionist models appears to offer a number of advantages. After a preliminary discussion, this paper introduces a general connectionist model and considers how it might be used in cognitive science. Among the issues addressed are: stability and noise-sensitivity, distributed decision-making, time and sequence problems, and the representation of complex concepts."
            },
            "slug": "Connectionist-Models-and-Their-Properties-Feldman-Ballard",
            "title": {
                "fragments": [],
                "text": "Connectionist Models and Their Properties"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222107"
                        ],
                        "name": "O. Ghitza",
                        "slug": "O.-Ghitza",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Ghitza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Ghitza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62205438,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "bdf353308c60d7e47dcfd924176d4b1f28b9ef0d",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In a previous report (Ghitza, 1987, [1]) we described a computational model based upon the temporal characteristics of the information in the auditory nerve fiber firing patterns, which produced an \"auditory\" spectral representation (the EIH) of the input signal. We also demonstrated that for speech recognition purposes, the EIH is more robust against noise compared to the traditional Fourier power spectrum. This paper reports on the first step towards understanding the role of different parameters in the EIH in achieving this performance. Both, the Fourier power spectrum measurement and the EIH measurement can be partitioned into two parts, a filter-bank followed by feature analyzer. In the Fourier power spectrum, the filter bank consists of uniformly shaped Hamming filters and the analyzer is based on power measurements. In the EIH, the filter bank consists of the cochlear filters and the analyzer is based on timing-synchrony measurements. The present study examines the relative importance of the filter-bank properties as compared to the analysis principle. For this purpose a modified EIH model has been created in which the cochlear filters have been replaced by the uniformly shaped Hamming filters. The output of the filter bank is processed by the timing-synchrony analyzer, as with the original EIH. The modified EIH and the Fourier power spectrum differs, therefor, only in the kind of analysis performed on the filter bank output. The modified EIH has been used as a front-end to a Dynamic Time Warp (DTW), using the same set-up as in Ghitza, 1987, [1]. A speaker dependent, isolated word recognition test has been conducted, on a database consisted of a 39 word alpha-digits vocabulary spoken by two male and two female speakers, in different levels of additive white noise. Compared to the Fourier-based front-end, the recognition scores have been slightly improved in clean environment but significantly improved in noisy environments. Furthermore, compared to the original EIH, the recognition scores have also been improved, both in clean and in noisy environments. These results demonstrate that the timing-synchrony measurement is significantly more robust against noise compared to the power measurement. They also show that the robustness is due to the timing-synchrony analyzer and not to the unique shape of the cochlear filters."
            },
            "slug": "Robustness-against-noise:-The-role-of-measurement-Ghitza",
            "title": {
                "fragments": [],
                "text": "Robustness against noise: The role of timing-synchrony measurement"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A modified EIH model has been created in which the cochlear filters have been replaced by the uniformly shaped Hamming filters, and the results demonstrate that the timing-synchrony measurement is significantly more robust against noise compared to the power measurement."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP '87. IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403674"
                        ],
                        "name": "Michael A. Cohen",
                        "slug": "Michael-A.-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682174"
                        ],
                        "name": "S. Grossberg",
                        "slug": "S.-Grossberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Grossberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Grossberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2215551,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "00e6b6ea28c0217d7c7e90824c17b37528f69104",
            "isKey": false,
            "numCitedBy": 2238,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems that are competitive and possess symmetric interactions admit a global Lyapunov function. However, a global Lyapunov function whose equilibrium set can be effectively analyzed has not yet been discovered. It remains an open question whether the Lyapunov function approach, which requires a study of equilibrium points, or an alternative global approach, such as the Lyapunov functional approach, which sidesteps a direct study of equilibrium points will ultimately handle all of the physically important cases."
            },
            "slug": "Absolute-stability-of-global-pattern-formation-and-Cohen-Grossberg",
            "title": {
                "fragments": [],
                "text": "Absolute stability of global pattern formation and parallel memory storage by competitive neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It remains an open question whether the Lyapunov function approach, which requires a study of equilibrium points, or an alternative global approach, such as the LyAPunov functional approach, will ultimately handle all of the physically important cases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12946615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07ce649d6f6eb636872527104b0209d3edc8188",
            "isKey": false,
            "numCitedBy": 16926,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Provides a unified, comprehensive and up-to-date treatment of both statistical and descriptive methods for pattern recognition. The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "slug": "Pattern-classification-and-scene-analysis-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Pattern classification and scene analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The topics treated include Bayesian decision theory, supervised and unsupervised learning, nonparametric techniques, discriminant analysis, clustering, preprosessing of pictorial data, spatial filtering, shape description techniques, perspective transformations, projective invariants, linguistic procedures, and artificial intelligence techniques for scene analysis."
            },
            "venue": {
                "fragments": [],
                "text": "A Wiley-Interscience publication"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398965769"
                        ],
                        "name": "Y. Abu-Mostafa",
                        "slug": "Y.-Abu-Mostafa",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Abu-Mostafa",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Abu-Mostafa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784553"
                        ],
                        "name": "D. Psaltis",
                        "slug": "D.-Psaltis",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Psaltis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Psaltis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 119353923,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "23a9c0f4bb4be98fd3a861e1013bcff927665d89",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reference EPFL-ARTICLE-158542doi:10.1038/scientificamerican0387-88View record in Web of Science Record created on 2010-11-25, modified on 2017-05-10"
            },
            "slug": "Optical-neural-computers-Abu-Mostafa-Psaltis",
            "title": {
                "fragments": [],
                "text": "Optical neural computers"
            },
            "tldr": {
                "abstractSimilarityScore": 32,
                "text": "This poster presents a probabilistic procedure to characterize the response of the immune system to repeated exposure to EPFL\u2019s Tournaisian\u2013Seiden\u2013Bouchut\u2013Boyaval virus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 102
                            }
                        ],
                        "text": "More recent work by Hopfield [18, 19,201, Rumelhart and McClelland [40], Sejnowski [43], Feldman [9], Grossberg [15], and others has led to a new resurgence of the field."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "Carpenter and Grossberg [3], in the development of their Adaptive Resonance Theory have designed a net which forms clusters and is trained without supemision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "The alg\u2019otithm presented ,in box 3 assumes that ,,fast learning,, is used as in the simulations presented in ,[3] and thus that elements of both inputs and stored exemplars take cm only the values Oand 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 113
                            }
                        ],
                        "text": "!oredetailed information concerning the six algorithms cribed above and other neural net algorithms can be nd in [3,7, 15,18,19,20,22,25,32, 39,40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 361,
                                "start": 352
                            }
                        ],
                        "text": "REFERENCES\n[1] Y. S. Abu-MOstafa and D. Pslatis, ,,Optical Neural Computers, \u201d Scientific Amer;can, 256, 88\u201395, March 1987, [2] E. B. Baum, J. Moody, and F. Wilczek, ,,Internal Repre-\nsentations for Associative Memory,,, NSF-lTP-86138 Institute for Theoretical Physics, University of California, Santa Barbara, California, 1986,\n[3] G. A. Carpenter, and S. Grossberg, ,,Neural Dynamics\nof Category Learning and Recognition: Attention, Memo~ Consolidation, and Amnesia,,, in J. Davis, R, Newburgh, and E. Wegman (Eds.)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 263
                            }
                        ],
                        "text": "A bina~ input is presented at the bottom andwhen classification is complete only one output is high, Not shown are additional components required to perform the vigilance test and to cfisabla the output node with the Iargeat output,\nThe behavior of the Carpenter/Grossberg net is illus. trated in Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 8
                            }
                        ],
                        "text": "[15] S. Grossberg, The Adaptive Bra;n /; Cognition, Learn-\ning, Reinforcement, and Rhythm, and The Adapdve Brain //: Vision, Speech, Language, and Motor Contro/, Elsevier/North-Hol land, Amsterdam (1986)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 92
                            }
                        ],
                        "text": "Bra;n Sfrucfure, Learning, and Memory, AAAS Symposium Series, 1986,\n[4] M. A. Cohen, and S. Grossberg, ,,Absolute Stability of\nGlobal Pattern Formation and Parallel Memory Storage by Competitive Neural Network s,,, IEEE Trans."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 44
                            }
                        ],
                        "text": "These results illustrate that the Carpenter/Grossberg algorithm can perform well with perfect input patterns but that even a small amount of noise can cause problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "These could include adapting weights more slowly and changing the vigilance threshold during training and testing as suggested in [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 35
                            }
                        ],
                        "text": "THE CARPENTER/GROSSBERG CLASSIFIER\nCarpenter and Grossberg [3], in the development of their Adaptive Resonance Theory have designed a net which forms clusters and is trained without supemision."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 117
                            }
                        ],
                        "text": "He also demonstrates how the orithm can be used in a speech recognize as a vector antizer [23], Unlike the Carpenter/Grossberg classifier, ; algorithm can perform relatively well in noise because ! number of classes is fixed, weights adapt slowly, and lptation stops after training."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 36
                            }
                        ],
                        "text": "The major components of a Carpenter/Grossberg classification net with three inputs and wo output nodes is presented in Fig."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamics of Category Learning and Recognition: Attention, Memo~ Consolidation, and Amnesia,"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143834737"
                        ],
                        "name": "D. A. Bell",
                        "slug": "D.-A.-Bell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. Bell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 109410157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e163fb03f549ab2bb1dbbf746005553ea15a575",
            "isKey": false,
            "numCitedBy": 2797,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Information-Theory-and-Reliable-Communication-Bell",
            "title": {
                "fragments": [],
                "text": "Information Theory and Reliable Communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69402509"
                        ],
                        "name": "J. Sage",
                        "slug": "J.-Sage",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Sage",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072707085"
                        ],
                        "name": "K. Thompson",
                        "slug": "K.-Thompson",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Thompson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thompson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38793993"
                        ],
                        "name": "R. Withers",
                        "slug": "R.-Withers",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Withers",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Withers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 108601361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a15ff49b48064c295015488eeebd805802c6cc3b",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the design principles for an implementation of an artificial neural network (ANN) in the form of a silicon integrated circuit based on charge\u2010coupled device (CCD) and metal\u2010nitride\u2010oxide\u2010semiconductor (MNOS) technologies. The significant features of this design are: (1) the synaptic coupling strengths stored in the MNOS devices can take on continuous, analog values and (2) the synaptic weights can be reprogrammed at any time under electrical control and in response to conditions in the network. These features should make possible ANNs that are capable of dynamic, in situ learning."
            },
            "slug": "An-artificial-neural-network-integrated-circuit-on-Sage-Thompson",
            "title": {
                "fragments": [],
                "text": "An artificial neural network integrated circuit based on MNOS/CCD principles"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "The design principles for an implementation of an artificial neural network in the form of a silicon integrated circuit based on charge\u2010coupled device (CCD) and metal\u2010nitride\u2010oxide\u2010semiconductor (MNOS) technologies should make possible ANNs that are capable of dynamic, in situ learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144959271"
                        ],
                        "name": "J. Hartigan",
                        "slug": "J.-Hartigan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hartigan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hartigan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64660655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb615ff62e6193ba2f0b38bb9f5f765617d81bb2",
            "isKey": false,
            "numCitedBy": 5022,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Clustering-Algorithms-Hartigan",
            "title": {
                "fragments": [],
                "text": "Clustering Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3547091"
                        ],
                        "name": "D. Hebb",
                        "slug": "D.-Hebb",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Hebb",
                            "middleNames": [
                                "Olding"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hebb"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62285311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2760c82b71bbcd586f786ca8017d5916f2a7c8ec",
            "isKey": false,
            "numCitedBy": 4624,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-organization-of-behavior-Hebb",
            "title": {
                "fragments": [],
                "text": "The organization of behavior"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145158318"
                        ],
                        "name": "P. Mueller",
                        "slug": "P.-Mueller",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Mueller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mueller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144458026"
                        ],
                        "name": "J. Lazzaro",
                        "slug": "J.-Lazzaro",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lazzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lazzaro"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60548989,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "c7f77502189dd4ae44d9425c50c537c745d685d0",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "400 analog electronic neurons have been assembled and connected for the analysis and recognition of acoustical patterns, including speech. Input to the net comes from a set of 18 band pass filters (Qmax 300 dB/octave; 180 to 6000 Hz, log scale). The net is organized into two parts, the first performs in real time the decomposition of the input patterns into their primitives of energy, space (frequency) and time relations. The other part decodes the set of primitives.216 neurons are dedicated to pattern decomposition. The output of the individual filters is rectified and fed to two sets of 18 neurons in an opponent center\u2010surround organization of synaptic connections (\u2018\u2018on center\u2019\u2019 and (\u2018\u2018off center\u2019\u2019). These units compute maxima and minima of energy at different frequencies.The next two sets of neutrons compute the temporal boundaries (\u2018\u2018on\u2019\u2019) and \u2018\u2018off\u2019\u2019) and the following two the movement of the energy maxima (formants) up or down the frequency axis. There are in addition \u2018\u2018hyperacuity\u2019\u2019 units which exp..."
            },
            "slug": "A-machine-for-neural-computation-of-acoustical-with-Mueller-Lazzaro",
            "title": {
                "fragments": [],
                "text": "A machine for neural computation of acoustical patterns with application to real time speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "400 analog electronic neurons have been assembled and connected for the analysis and recognition of acoustical patterns, including speech, and the decomposition of the input patterns into their primitives of energy, space (frequency) and time relations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913418"
                        ],
                        "name": "B. Widrow",
                        "slug": "B.-Widrow",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Widrow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Widrow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1976925"
                        ],
                        "name": "M. Hoff",
                        "slug": "M.-Hoff",
                        "structuredName": {
                            "firstName": "Marcian",
                            "lastName": "Hoff",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60830585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e14b2ff9dc2234df94fc24d89fc25e797d0e9e7",
            "isKey": false,
            "numCitedBy": 2603,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-switching-circuits-Widrow-Hoff",
            "title": {
                "fragments": [],
                "text": "Adaptive switching circuits"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57223560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fe55d6a596906f545c1195abc2bde0f48b27883",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "AIP-Conference-Proceedings-151-on-Neural-Networks-Denker",
            "title": {
                "fragments": [],
                "text": "AIP Conference Proceedings 151 on Neural Networks for Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516142"
                        ],
                        "name": "D. Tank",
                        "slug": "D.-Tank",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tank",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tank"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10096429,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "4517ca6110dfb5de3f004f67653de3c33b8d6234",
            "isKey": false,
            "numCitedBy": 1935,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "A new conceptual framework and a minimization principle together provide an understanding of computation in model neural circuits. The circuits consist of nonlinear graded-response model neurons organized into networks with effectively symmetric synaptic connections. The neurons represent an approximation to biological neurons in which a simplified set of important computational properties is retained. Complex circuits solving problems similar to those essential in biology can be analyzed and understood without the need to follow the circuit dynamics in detail. Implementation of the model with electronic devices will provide a class of electronic circuits of novel form and function."
            },
            "slug": "Computing-with-neural-circuits:-a-model.-Hopfield-Tank",
            "title": {
                "fragments": [],
                "text": "Computing with neural circuits: a model."
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A new conceptual framework and a minimization principle together provide an understanding of computation in model neural circuits that represent an approximation to biological neurons in which a simplified set of important computational properties is retained."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adaptive Signal Process- 86, 4, 37.8.1-37"
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive Signal Process- 86, 4, 37.8.1-37"
            },
            "year": 1960
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acoust. Soc. Am"
            },
            "venue": {
                "fragments": [],
                "text": "Acoust. Soc. Am"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Isolated Digit Recognition Experiments with a Cochlear Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hebb, The Organization o f Behavior"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Networks and Ptiysical Systems with Emergent Collective Computational Abilities Neurons with Grade,d Response Have Collective Computational Properties Like Those of Two-State Neurons"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Natl. Acad. Sci. USA Proc. Natl. Acad. Sci. USA"
            },
            "year": 1191
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Adaptive Brain I: Cognition, Learning , Reinforcement, and Rhythm, and The Adaptive Brain I/: Vision, Speech, Language, and Motor Control"
            },
            "venue": {
                "fragments": [],
                "text": "The Adaptive Brain I: Cognition, Learning , Reinforcement, and Rhythm, and The Adaptive Brain I/: Vision, Speech, Language, and Motor Control"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 264
                            }
                        ],
                        "text": "The Hamming net can also be modified to be a minimum error classifier when errors are generated by reversing input elements from +1 to \u20131 and frOm \u20131 to +1 asymmetrically with different probabilities [25] and when the values of specific input elements are unknown [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representations for Associative Memory,,, NSF-lTP-86- 138 Institute for Theoretical Physics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Adaptive Brain I: Cognition, Learning, Reinforcement, and Rhythm, and The Adaptive Brain I"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Internal Representations for Associative Memory NSF-ITP-86- 138 Institute for Theoretical Physics"
            },
            "venue": {
                "fragments": [],
                "text": "Internal Representations for Associative Memory NSF-ITP-86- 138 Institute for Theoretical Physics"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memory and Learning iri'?a Class of h p r a l Models"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Workshop on Lattice Cmge Theory"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Multi - Layer Perception as a Tool for Speech Pattern Processing Research"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimization Networks : An ND Converter , Signal Decision C ; rcuit , and a Linear Programming Circuit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Memory and Learning iri \u2019 ? a Class of h p r a l Models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Organization o f Behavior"
            },
            "venue": {
                "fragments": [],
                "text": "The Organization o f Behavior"
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pslatis, \u201cOptical Neural Computers,"
            },
            "venue": {
                "fragments": [],
                "text": "Scientific American,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech-Coding in the Audiiory"
            },
            "venue": {
                "fragments": [],
                "text": "Networks,\u201d I\u20ac\u20ac\u20ac Trans. Syst. Man Cybern"
            },
            "year": 1983
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 44,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/An-introduction-to-computing-with-neural-nets-Lippmann/b8778bb692cf105254fe767ef11a3a8afac4a068?sort=total-citations"
}