{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23073168,
            "fieldsOfStudy": [
                "Computer Science",
                "Art"
            ],
            "id": "3ef36b0186bb73619d08d02661616ce7df218ecd",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors examine the problem of locating and extracting text from images on the World Wide Web. They describe a text detection algorithm which is based on color clustering and connected component analysis. The algorithm first quantizes the color space of the input image into a number of color classes using a parameter-free clustering procedure. It then identifies text-like connected components in each color class based on their shapes. Finally, a post-processing procedure aligns text-like components into text lines. Experimental results suggest this approach is promising despite the challenging nature of the input data."
            },
            "slug": "Extracting-text-from-WWW-images-Zhou-Lopresti",
            "title": {
                "fragments": [],
                "text": "Extracting text from WWW images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A text detection algorithm which is based on color clustering and connected component analysis is described, which suggests this approach is promising despite the challenging nature of the input data."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113455824"
                        ],
                        "name": "Zhibin Lei",
                        "slug": "Zhibin-Lei",
                        "structuredName": {
                            "firstName": "Zhibin",
                            "lastName": "Lei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhibin Lei"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29236195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5f719c98abe9e3da61cb39ca1b836aeb09a4624",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A significant amount of text now present in World Wide Web documents is embedded in image data, and a large portion of it does not appear elsewhere at all. To make this information available, we need to develop techniques for recovering textual information from in-line Web images. In this paper, we describe two methods for Web image OCR. Recognizing text extracted from in-line Web images is difficult because characters in these images are often rendered at a low spatial resolution. Such images are typically considered to be 'low quality' by traditional OCR technologies. Our proposed methods utilize the information contained in the color bits to compensate for the loss of information due to low sampling resolution. The first method uses a polynomial surface fitting technique for object recognition. The second method is based on the traditional n-tuple technique. We collected a small set of character samples from Web documents and tested the two algorithms. Preliminary experimental results show that our n-tuple method works quite well. However, the surface fitting method performs rather poorly due to the coarseness and small number of color shades used in the text."
            },
            "slug": "OCR-for-World-Wide-Web-images-Zhou-Lopresti",
            "title": {
                "fragments": [],
                "text": "OCR for World Wide Web images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Two methods for Web image OCR based on the traditional n-tuple technique, which utilize the information contained in the color bits to compensate for the loss of information due to low sampling resolution."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47260288"
                        ],
                        "name": "L. Fletcher",
                        "slug": "L.-Fletcher",
                        "structuredName": {
                            "firstName": "Lloyd",
                            "lastName": "Fletcher",
                            "middleNames": [
                                "Alan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fletcher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3110392"
                        ],
                        "name": "R. Kasturi",
                        "slug": "R.-Kasturi",
                        "structuredName": {
                            "firstName": "Rangachar",
                            "lastName": "Kasturi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kasturi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2685456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b08e547ba4edb60902d1708a5593d71f075aa7f1",
            "isKey": false,
            "numCitedBy": 655,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described. It is intended for use in an automated system for document analysis. The principal parts of the algorithm are the generation of connected components and the application of the Hough transform in order to group components into logical character strings that can then be separated from the graphics. The algorithm outputs two images, one containing text strings and the other graphics. These images can then be processed by suitable character recognition and graphics recognition systems. The performance of the algorithm, both in terms of its effectiveness and computational efficiency, was evaluated using several test images and showed superior performance compared to other techniques. >"
            },
            "slug": "A-Robust-Algorithm-for-Text-String-Separation-from-Fletcher-Kasturi",
            "title": {
                "fragments": [],
                "text": "A Robust Algorithm for Text String Separation from Mixed Text/Graphics Images"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "The development and implementation of an algorithm for automated text string separation that is relatively independent of changes in text font style and size and of string orientation are described and showed superior performance compared to other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116415943"
                        ],
                        "name": "B. Yu",
                        "slug": "B.-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153701268"
                        ],
                        "name": "M. Mohiuddin",
                        "slug": "M.-Mohiuddin",
                        "structuredName": {
                            "firstName": "Marzia",
                            "lastName": "Mohiuddin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohiuddin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61109635,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "e9f890d2ce8b6ef47301312a768366fec32ba1a0",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Unlike simple letter envelopes which have a high degree of global spatial structure among a limited number of entities, many mail pieces such as magazines usually have an address block printed on a label which can be pasted in an arbitrary position and orientation among text, graphics and images on a magazine cover, which is often shrink wrapped. This work concentrates on address block location for complex mail pieces with an arbitrary layout of printed entities. Using a bottom-up approach, a pyramid model is created for the address block. Based on this model, some features are extracted for assigning a confidence value to the located address blocks. The typical processing time for locating a destination address block is 0.1 seconds on a SGI Indy workstation."
            },
            "slug": "Address-block-location-on-complex-mail-pieces-Yu-Jain",
            "title": {
                "fragments": [],
                "text": "Address block location on complex mail pieces"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "Using a bottom-up approach, a pyramid model is created for the address block and some features are extracted for assigning a confidence value to the located address blocks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678564"
                        ],
                        "name": "Y. Ariki",
                        "slug": "Y.-Ariki",
                        "structuredName": {
                            "firstName": "Yasuo",
                            "lastName": "Ariki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ariki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053606391"
                        ],
                        "name": "T. Teranishi",
                        "slug": "T.-Teranishi",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Teranishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Teranishi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1721719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f0195767bdacd6d56a86f587725c15ab65eb4b7",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In accumulating and retrieving multimedia information such as images, speech and text, it is necessary to compress and retrieve the information efficiently and accurately. The purpose of this paper is to construct a multimedia database of TV news images based on telop character recognition. The first step is to detect telop frames and to segment the characters by differentiating the telop frames based on the fact that character regions have high brightness and the character edges are clear. The second step is the telop character recognition. It is performed by a subspace method using direction histogram features. The third step is indexing by extracting noun words after morphological analysis of the recognized telop characters. These noun words correspond with key words and are given to TV news articles as their indices. Finally TV news articles are classified into 10 topics such as politics, economics, culture, amusements, sports and so on based on the extracted indices. We employed an index-topic table to classify the articles using indices. The telop character recognition rate was 65.7% and the article classification rate was 67.3%."
            },
            "slug": "Indexing-and-classification-of-TV-news-articles-on-Ariki-Teranishi",
            "title": {
                "fragments": [],
                "text": "Indexing and classification of TV news articles based on telop recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A multimedia database of TV news images based on telop character recognition, indexing by extracting noun words after morphological analysis of the recognized telop characters and classified the articles using indices."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Fourth International Conference on Document Analysis and Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828940"
                        ],
                        "name": "D. Lopresti",
                        "slug": "D.-Lopresti",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lopresti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lopresti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2461436"
                        ],
                        "name": "Jiangying Zhou",
                        "slug": "Jiangying-Zhou",
                        "structuredName": {
                            "firstName": "Jiangying",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangying Zhou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "(1)) ('lustering based on HGB distance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 43192785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd93ae58946ca46216a918a4e60d605f4bd3b18a",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-Analysis-and-the-World-Wide-Web-Lopresti-Zhou",
            "title": {
                "fragments": [],
                "text": "Document Analysis and the World Wide Web"
            },
            "venue": {
                "fragments": [],
                "text": "DAS"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35696139,
            "fieldsOfStudy": [],
            "id": "d68b95534860e2bddd17d17ef7f362d16c550bde",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Locating text in complex color images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 7,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Finding-text-in-color-images-Zhou-Lopresti/0bad076c5f89ac43026a2b5fca648d488f54f45e?sort=total-citations"
}