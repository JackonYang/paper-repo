{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8483722"
                        ],
                        "name": "C. Atkeson",
                        "slug": "C.-Atkeson",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Atkeson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Atkeson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745219"
                        ],
                        "name": "S. Schaal",
                        "slug": "S.-Schaal",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Schaal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schaal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 34
                            }
                        ],
                        "text": "One notable exception is given in Atkeson & Schaal (1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2399207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ce0468a0827ec3ce9b53a45150e40a46a22cc94",
            "isKey": false,
            "numCitedBy": 719,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of robot learning from demonstration is to have a robot learn from watching a demonstration of the task to be performed. In our approach to learning from demonstration the robot learns a reward function from the demonstration and a task model from repeated attempts to perform the task. A policy is computed based on the learned reward function and task model. Lessons learned from an implementation on an anthropomorphic robot arm using a pendulum swing up task include 1) simply mimicking demonstrated motions is not adequate to perform this task, 2) a task planner can use a learned model and reward function to compute an appropriate policy, 3) this modelbased planning process supports rapid learning, 4) both parametric and nonparametric models can be learned and used, and 5) incorporating a task level direct learning component, which is non-model-based, in addition to the model-based planner, is useful in compensating for structural modeling errors and slow model learning."
            },
            "slug": "Robot-Learning-From-Demonstration-Atkeson-Schaal",
            "title": {
                "fragments": [],
                "text": "Robot Learning From Demonstration"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work has shown that incorporating a task level direct learning component, which is non-model-based, in addition to the model-based planner, is useful in compensating for structural modeling errors and slow model learning."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1868677"
                        ],
                        "name": "D. Harada",
                        "slug": "D.-Harada",
                        "structuredName": {
                            "firstName": "Daishi",
                            "lastName": "Harada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Harada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 96
                            }
                        ],
                        "text": "A (finite-state) Markov decision process (MDP) is a tuple (S,A, T, \u03b3,D,R), where S is a finite set of states; A is a set of actions; T = {Psa} is a set of state transition probabilities (here, Psa is the state transition distribution upon taking action a in state s); \u03b3 \u2208 [0, 1) is a discount\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 98
                            }
                        ],
                        "text": "1\nIn practice, this means that the reward function is often manually tweaked (cf. reward shaping, Ng et al., 1999) until the desired behavior is obtained."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5730166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94066dc12fe31e96af7557838159bde598cb4f10",
            "isKey": false,
            "numCitedBy": 1603,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates conditions under which modi cations to the reward function of a Markov decision process preserve the op timal policy It is shown that besides the positive linear transformation familiar from utility theory one can add a reward for tran sitions between states that is expressible as the di erence in value of an arbitrary poten tial function applied to those states Further more this is shown to be a necessary con dition for invariance in the sense that any other transformation may yield suboptimal policies unless further assumptions are made about the underlying MDP These results shed light on the practice of reward shap ing a method used in reinforcement learn ing whereby additional training rewards are used to guide the learning agent In par ticular some well known bugs in reward shaping procedures are shown to arise from non potential based rewards and methods are given for constructing shaping potentials corresponding to distance based and subgoal based heuristics We show that such po tentials can lead to substantial reductions in learning time"
            },
            "slug": "Policy-Invariance-Under-Reward-Transformations:-and-Ng-Harada",
            "title": {
                "fragments": [],
                "text": "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Conditions under which modi cations to the reward function of a Markov decision process preserve the op timal policy are investigated to shed light on the practice of reward shap ing a method used in reinforcement learn ing whereby additional training rewards are used to guide the learning agent."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1842943"
                        ],
                        "name": "Y. Uno",
                        "slug": "Y.-Uno",
                        "structuredName": {
                            "firstName": "Yoji",
                            "lastName": "Uno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Uno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144391220"
                        ],
                        "name": "M. Kawato",
                        "slug": "M.-Kawato",
                        "structuredName": {
                            "firstName": "Mitsuo",
                            "lastName": "Kawato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kawato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50465418"
                        ],
                        "name": "R. Suzuki",
                        "slug": "R.-Suzuki",
                        "structuredName": {
                            "firstName": "Ryoji",
                            "lastName": "Suzuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Suzuki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 1
                            }
                        ],
                        "text": "(Uno et al., 1989) Related examples are also found in economics and some other literatures."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 8099349,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "01ef02d990569ffb88de29d007fdc27c15f19c66",
            "isKey": false,
            "numCitedBy": 1249,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "AbstractIn this paper, we study trajectory planning and control in voluntary, human arm movements. When a hand is moved to a target, the central nervous system must select one specific trajectory among an infinite number of possible trajectories that lead to the target position. First, we discuss what criterion is adopted for trajectory determination. Several researchers measured the hand trajectories of skilled movements and found common invariant features. For example, when moving the hand between a pair of targets, subjects tended to generate roughly straight hand paths with bell-shaped speed profiles. On the basis of these observations and dynamic optimization theory, we propose a mathematical model which accounts for formation of hand trajectories. This model is formulated by defining an objective function, a measure of performance for any possible movement: square of the rate of change of torque integrated over the entire movement. That is, the objective function CT is defined as follows: \n$$C_T = \\frac{1}{2}{}^t\\int\\limits_0^f {\\sum\\limits_{i = 1}^n {\\left( {\\frac{{{\\text{d}}z_i }}{{{\\text{d}}t}}} \\right)^2 {\\text{d}}t,} } $$\n where ziis the torque generated by the i-th actuator (muslce) out of n actuators, and tfis the movement time. Since this objective function critically depends on the complex nonlinear dynamics of the musculoskeletal system, it is very difficult to determine the unique trajectory which yields the best performance. We overcome this difficult by developing an iterative scheme, with which the optimal trajectory and the associated motor command are simultaneously computed. To evaluate our model, human hand trajectories were experimentally measured under various behavioral situations. These results supported the idea that the human hand trajectory is planned and controlled in accordance with the minimum torquechange criterion."
            },
            "slug": "Formation-and-control-of-optimal-trajectory-in-arm-Uno-Kawato",
            "title": {
                "fragments": [],
                "text": "Formation and control of optimal trajectory in human multijoint arm movement"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The idea that the human hand trajectory is planned and controlled in accordance with the minimum torquechange criterion is supported by developing an iterative scheme, with which the optimal trajectory and the associated motor command are simultaneously computed."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004141631"
                        ],
                        "name": "R. Amit",
                        "slug": "R.-Amit",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Amit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Amit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51962510"
                        ],
                        "name": "M. Matari",
                        "slug": "M.-Matari",
                        "structuredName": {
                            "firstName": "Maja",
                            "lastName": "Matari",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Matari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 17
                            }
                        ],
                        "text": "(See the discussion in Ng & Russell, 2000.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 141
                            }
                        ],
                        "text": "This literature is too wide to survey here, but some examples include Sammut et al. (1992); Kuniyoshi et al. (1994); Demiris & Hayes (1994); Amit & Mataric (2002); Pomerleau (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2354605,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology",
                "Psychology"
            ],
            "id": "66766026eecd7a38cf14e01422db343ee63d8134",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a control and learning architecture for humanoid robots designed for acquiring movement skills in the context of imitation learning. Multiple levels of movement abstraction occur across the hierarchical structure of the architecture, finally leading to the representation of movement sequences within a probabilistic framework. As its substrate, the framework uses the notion of visuo-motor primitives, modules capable of recognizing as well as executing similar movements. This notion is heavily motivated by the neuroscience evidence for motor primitives and mirror neurons. Experimental results from an implementation of the architecture are presented involving learning and representation of demonstrated movement sequences from synthetic as well as real human movement data."
            },
            "slug": "Learning-movement-sequences-from-demonstration-Amit-Matari",
            "title": {
                "fragments": [],
                "text": "Learning movement sequences from demonstration"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "Presents a control and learning architecture for humanoid robots designed for acquiring movement skills in the context of imitation learning, and uses the notion of visuo-motor primitives, modules capable of recognizing as well as executing similar movements."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2nd International Conference on Development and Learning. ICDL 2002"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52422973"
                        ],
                        "name": "A. S. Manne",
                        "slug": "A.-S.-Manne",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Manne",
                            "middleNames": [
                                "s."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Manne"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 1
                            }
                        ],
                        "text": "(Manne, 1960) Specifically, in this LP the variables are the state/action visitation rates, and it is possible to place constraints on the learned policy\u2019s stationary distribution directly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119960595,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "80ce0c40ddc207c47aed2f6a979c288c304df94e",
            "isKey": false,
            "numCitedBy": 433,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Using an illustration drawn from the area of inventory control, this paper demonstrates how a typical sequential probabilistic model may be formulated in terms of a an initial decision rule and b a Markov process, and then optimized by means of linear programming. This linear programming technique may turn out to be an efficient alternative to the functional equation approach in the numerical analysis of such problems. Regardless of computational significance, however, it is of interest that there should be such a close relationship between the two traditionally distinct areas of dynamic programming and linear programming."
            },
            "slug": "Linear-Programming-and-Sequential-Decisions-Manne",
            "title": {
                "fragments": [],
                "text": "Linear Programming and Sequential Decisions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145301291"
                        ],
                        "name": "N. Hogan",
                        "slug": "N.-Hogan",
                        "structuredName": {
                            "firstName": "Neville",
                            "lastName": "Hogan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hogan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 82
                            }
                        ],
                        "text": "Examples include the minimum jerk principle to explain limb movement in primates (Hogan, 1984), and the minimum torque-change model to explain trajectories in human multijoint arm movement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14331761,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "584358bd2a56be949940cb0461275f6b8c62792f",
            "isKey": false,
            "numCitedBy": 1215,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a mathematical model which predicts both the major qualitative features and, within experimental error, the quantitative details of a class of perturbed and unperturbed large-amplitude, voluntary movements performed at intermediate speed by primates. A feature of the mathematical model is that a concise description of the behavioral organization of the movement has been formulated which is separate and distinct from the description of the dynamics of movement execution. Based on observations of voluntary movements in primates, the organization has been described as though the goal were to make the smoothest movement possible under the circumstances, i.e., to minimize the accelerative transients. This has been formalized by using dynamic optimization theory to determine the movement which minimizes the rate of change of acceleration (jerk) of the limb. Based on observations of muscle mechanics, the concept of a \u201cvirtual position\u201d determined by the active states of the muscles is rigorously defined as one of the mechanical consequences of the neural commands to the muscles. This provides insight into the mechanics of perturbed and unperturbed movements and is a useful aid in the separation of the descriptions of movement organization and movement execution."
            },
            "slug": "An-organizing-principle-for-a-class-of-voluntary-Hogan",
            "title": {
                "fragments": [],
                "text": "An organizing principle for a class of voluntary movements"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A mathematical model is presented which predicts both the major qualitative features and, within experimental error, the quantitative details of a class of perturbed and unperturbed large-amplitude, voluntary movements performed at intermediate speed by primates."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744602"
                        ],
                        "name": "Y. Kuniyoshi",
                        "slug": "Y.-Kuniyoshi",
                        "structuredName": {
                            "firstName": "Yasuo",
                            "lastName": "Kuniyoshi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Kuniyoshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749935"
                        ],
                        "name": "M. Inaba",
                        "slug": "M.-Inaba",
                        "structuredName": {
                            "firstName": "Masayuki",
                            "lastName": "Inaba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Inaba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738023"
                        ],
                        "name": "H. Inoue",
                        "slug": "H.-Inoue",
                        "structuredName": {
                            "firstName": "Hirochika",
                            "lastName": "Inoue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Inoue"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15009135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83165c83d1ad77920e3e6f1ec5fa00373fdd9fd8",
            "isKey": false,
            "numCitedBy": 776,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel task instruction method for future intelligent robots is presented, In our method, a robot learns reusable task plans by watching a human perform assembly tasks. Functional units and working algorithms for visual recognition and analysis of human action sequences are presented. The overall system is model based and integrated at the symbolic level. Temporal segmentation of a continuous task performance into meaningful units and identification of each operation is processed in real time by concurrent recognition processes under active attention control. Dependency among assembly operations in the recognized action sequence is analyzed, which results in a hierarchical task plan describing the higher level structure of the task. In another workspace with a different initial state, the system re-instantiates and executes the task plan to accomplish an equivalent goal. The effectiveness of our method is supported by experimental results with block assembly tasks. >"
            },
            "slug": "Learning-by-watching:-extracting-reusable-task-from-Kuniyoshi-Inaba",
            "title": {
                "fragments": [],
                "text": "Learning by watching: extracting reusable task knowledge from visual observation of human performance"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel task instruction method for future intelligent robots that learns reusable task plans by watching a human perform assembly tasks is presented, which results in a hierarchical task plan describing the higher level structure of the task."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Robotics Autom."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 1
                            }
                        ],
                        "text": "(Vapnik, 1998) The equivalence is obtained by associating a label 1 with the expert\u2019s feature expectations \u00b5E , and a label \u22121 with the feature expectations {\u00b5(\u03c0(j)) : j = 0..(i\u22121)}."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "(Vapnik, 1998) The equivalence is obtained by associating a label 1 with the expert\u2019s feature expectations \u03bcE , and a label \u22121 with the feature expectations {\u03bc(\u03c0) : j = 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": false,
            "numCitedBy": 26322,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48855558"
                        ],
                        "name": "D. Pomerleau",
                        "slug": "D.-Pomerleau",
                        "structuredName": {
                            "firstName": "Dean",
                            "lastName": "Pomerleau",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pomerleau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "(See the discussion in Ng & Russell, 2000.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 164
                            }
                        ],
                        "text": "This literature is too wide to survey here, but some examples include Sammut et al. (1992); Kuniyoshi et al. (1994); Demiris & Hayes (1994); Amit & Mataric (2002); Pomerleau (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18420840,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7786bc6c25ba38ff0135f1bdad192f6b3c4ad0b3",
            "isKey": false,
            "numCitedBy": 1459,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer back-propagation network designed for the task of road following. Currently ALVINN takes images from a camera and a laser range finder as input and produces as output the direction the vehicle should travel in order to follow the road. Training has been conducted using simulated road images. Successful tests on the Carnegie Mellon autonomous navigation test vehicle indicate that the network can effectively follow real roads under certain field conditions. The representation developed to perform the task differs dramatically when the network is trained under various conditions, suggesting the possibility of a novel adaptive autonomous navigation system capable of tailoring its processing to the conditions at hand."
            },
            "slug": "ALVINN:-An-Autonomous-Land-Vehicle-in-a-Neural-Pomerleau",
            "title": {
                "fragments": [],
                "text": "ALVINN: An Autonomous Land Vehicle in a Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer back-propagation network designed for the task of road following that can effectively follow real roads under certain field conditions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72599094"
                        ],
                        "name": "A. Edrei",
                        "slug": "A.-Edrei",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Edrei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Edrei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729514"
                        ],
                        "name": "E. Saff",
                        "slug": "E.-Saff",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Saff",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Saff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145119134"
                        ],
                        "name": "R. Varga",
                        "slug": "R.-Varga",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Varga",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Varga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124797694,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "81a727e6ab41974b0e1f0e756a578326c8c7be26",
            "isKey": false,
            "numCitedBy": 667,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Notation: For signed permutations A and B, we denote the inversion distance by d(A, B). Given permutations A, B, C and X, where X may or may not be a median of the first three, we call the sum d(X, A) + d(X, B) + d(X,C) the tree length with respect to X; if X is a median, we also call the sum the median score of A, B, and C. We write M A,B,C to denote the set of inversion medians of three given permutations A, B, and C and P A,B,C to denote the set of signed permutations that lie in one or more of the optimal (inversion) sorting paths between A and B, A and C, or B and C. We denote by P(A, B) the set of all permutations that lie on sorting paths from A to B. Given permutation x 12 , that lies on a sorting path from A to B, such that x 12 is closest to C we call d(C, x 12) the closest-path distance of C. Proof. Let \u03c6 1 = (4 3 1 2), \u03c6 2 = (4 2 1 3) and \u03c6 3 = \u03b9, the identity. The following facts can be easily checked from the sorting paths of these permutations: 1. d(\u03c6 1 , \u03c6 3) = 3, d(\u03c6 1 , \u03c6 2) = 2, d(\u03c6 2 , \u03c6 3) = 2. 2. The permutation in P(\u03c6 1 , \u03c6 2) that is closest to \u03c6 3 is \u03c6 2 so \u03c6 3 has closest-path distance 2. 3. The permutation in P(\u03c6 2 , \u03c6 3) that is closest to \u03c6 1 is \u03c6 2 so \u03c6 1 has closest-path distance 2. 4. The permutations in P(\u03c6 3 , \u03c6 1) that are closest to \u03c6 2 are \u03c6 1 and \u03c6 3 , so \u03c6 2 has closest-path distance 2. 5. The tree length of \u03c6 2 with respect to \u03c6 1 , \u03c6 2 and \u03c6 3 is 4. 6. The tree length of \u03c6 3 and \u03c6 1 are both 5; hence neither is a median. Let C1, C2 and C3 be the breakpoint graphs of \u03c6 1 , \u03c6 2 and \u03c6 3 respectively. We construct A in such a way that its breakpoint graph is a concatenation of C3, C1 and C2 (in that order). Similarly, B is a concatenation of C1, C2 \u2026"
            },
            "slug": "Proof-of-Theorem-2-Edrei-Saff",
            "title": {
                "fragments": [],
                "text": "Proof of Theorem 2"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The inversion distance is denoted by d(A, B) for signed permutations A and B and the set of all permutations that lie on sorting paths from A to B is written as M A, B,C to denote theSet of inversion medians of three given permutations B, C, and C are written."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38757,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 23
                            }
                        ],
                        "text": "(See the discussion in Ng & Russell, 2000.)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "This step is similar to one used in (Ng & Russell, 2000), but unlike the algorithms given there, because of the 2-norm constraint on w it cannot be posed as a linear program (LP), but only as a quadratic program.5\nReaders familiar with support vector machines (SVMs) will also recognize this\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 115
                            }
                        ],
                        "text": "The problem is the following: Given an MDP\\R, a feature mapping \u03c6 and the expert\u2019s feature expectations \u00b5E , find a policy whose performance is close to that of the expert\u2019s, on the unknown reward function R\u2217 = w\u2217T \u03c6."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 274
                            }
                        ],
                        "text": "\u2026robust, and transferable definition of the task, it seems natural to consider an approach to apprenticeship learning whereby the reward function is learned.2\nThe problem of deriving a reward function from observed behavior is referred to as inverse reinforcement learning (Ng & Russell, 2000)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 34196655,
            "fieldsOfStudy": [
                "Medicine",
                "Biology"
            ],
            "id": "b05b67aca720d0bc39bc9afad02a19f522c7a1bc",
            "isKey": false,
            "numCitedBy": 2416,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Objective\u2014To evaluate the pharmacokinetics of a novel commercial formulation of ivermectin after administration to goats.\r\n\r\nAnimals\u20146 healthy adult goats.\r\n\r\nProcedure\u2014Ivermectin (200 \u03bcg/kg) was initially administered IV to each goat, and plasma samples were obtained for 36 days. After a washout period of 3 weeks, each goat received a novel commercial formulation of ivermectin (200 \u03bcg/kg) by SC injection. Plasma samples were then obtained for 42 days. Drug concentrations were quantified by use of high-performance liquid chromatography with fluorescence detection.\r\n\r\nResults\u2014Pharmacokinetics of ivermectin after IV administration were best described by a 2-compartment open model; values for main compartmental variables included volume of distribution at a steady state (9.94 L/kg), clearance (1.54 L/kg/d), and area under the plasma concentration-time curve (AUC; 143 [ng\u2022d]/mL). Values for the noncompartmental variables included mean residence time (7.37 days), AUC (153 [ng\u2022d]/mL), and clearance (1.43 L/kg/d). After SC administration, noncompartmental pharmacokinetic analysis was conducted. Values of the variables calculated by use of this method included maximum plasma concentration (Cmax; 21.8 ng/mL), time to reach Cmax (3 days), and bioavailability (F; 91.8%).\r\n\r\nConclusions and Clinical Relevance\u2014The commercial formulation used in this study is a good option to consider when administering ivermectin to goats because of the high absorption, which is characterized by high values of F. In addition, the values of Cmax and time to reach Cmax are higher than those reported by other investigators who used other routes of administration."
            },
            "slug": "Pharmacokinetics-of-a-novel-formulation-of-after-to-Ng-Russell",
            "title": {
                "fragments": [],
                "text": "Pharmacokinetics of a novel formulation of ivermectin after administration to goats"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Pharmacokinetics of ivermectin after IV administration were best described by a 2-compartment open model; values for main compartmental variables included volume of distribution at a steady state, area under the plasma concentration-time curve, and area underThe AUC curve."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "In (Abbeel & Ng, 2004) we give longer, easier to read proofs of the theorems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 1
                            }
                        ],
                        "text": "(Abbeel & Ng, 2004)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "That proof is very similar, but has more technicalities and is significantly longer (Abbeel & Ng, 2004).\nw ~\n_\n^ E\n(i+1)\n(i)\n(i+1)\n\u00b5\n\u00b5\n\u00b5\u00b5\nk\u221a k2+(1\u2212\u03b3)2 2 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "An example showing three iterations of the projection method is shown in Figure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 70
                            }
                        ],
                        "text": "The full justification for this method is deferred to the full paper (Abbeel and Ng, 2004), but in Sections 4 and 5 we will also give convergence results for it, and empirically compare it to the max-margin\n6In k-dimensional space, any point that is a convex combination of a set of N points, with N\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Apprenticeship learning via inverse reinforcement learning. (Full paper"
            },
            "venue": {
                "fragments": [],
                "text": "Apprenticeship learning via inverse reinforcement learning. (Full paper"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 1
                            }
                        ],
                        "text": "(Abbeel & Ng, 2004)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "In (Abbeel & Ng, 2004) we give longer, easier to read proofs of the theorems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "That proof is very similar, but has more technicalities and is significantly longer (Abbeel & Ng, 2004).\nw ~\n_\n^ E\n(i+1)\n(i)\n(i+1)\n\u00b5\n\u00b5\n\u00b5\u00b5\nk\u221a k2+(1\u2212\u03b3)2 2 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 70
                            }
                        ],
                        "text": "The full justification for this method is deferred to the full paper (Abbeel and Ng, 2004), but in Sections 4 and 5 we will also give convergence results for it, and empirically compare it to the max-margin\n6In k-dimensional space, any point that is a convex combination of a set of N points, with N\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Apprenticeship learning via inverse reinforcement learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "In (Abbeel & Ng, 2004) we give longer, easier to read proofs of the theorems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 1
                            }
                        ],
                        "text": "(Abbeel & Ng, 2004)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 85
                            }
                        ],
                        "text": "That proof is very similar, but has more technicalities and is significantly longer (Abbeel & Ng, 2004).\nw ~\n_\n^ E\n(i+1)\n(i)\n(i+1)\n\u00b5\n\u00b5\n\u00b5\u00b5\nk\u221a k2+(1\u2212\u03b3)2 2 ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 70
                            }
                        ],
                        "text": "The full justification for this method is deferred to the full paper (Abbeel and Ng, 2004), but in Sections 4 and 5 we will also give convergence results for it, and empirically compare it to the max-margin\n6In k-dimensional space, any point that is a convex combination of a set of N points, with N\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 69
                            }
                        ],
                        "text": "The full justification for this method is deferred to the full paper (Abbeel and Ng, 2004), but in Sections 4 and 5 we will also give convergence results for it, and empirically compare it to the max-margin"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Apprenticeship learning via inverse reinforcement learning. (Full paper.) http://www.cs.stanford.edu/~pabbeel/irl"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103990701"
                        ],
                        "name": "\u5b87\u91ce \u6d0b\u4e8c",
                        "slug": "\u5b87\u91ce-\u6d0b\u4e8c",
                        "structuredName": {
                            "firstName": "\u5b87\u91ce",
                            "lastName": "\u6d0b\u4e8c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u5b87\u91ce \u6d0b\u4e8c"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 1
                            }
                        ],
                        "text": "(Uno et al., 1989) Related examples are also found in economics and some other literatures."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 189
                            }
                        ],
                        "text": "Examples include the minimum jerk principle to explain limb movement in primates (Hogan, 1984), and the minimum torque-change model to explain trajectories in human multijoint arm movement.(Uno et al., 1989) Related examples are also found in economics and some other literatures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124664914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de46b8b2d1d5a031ec3aaa5ab17de1b1faf20ac0",
            "isKey": false,
            "numCitedBy": 632,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Formation-and-control-of-optimal-trajectory-in-arm-\u5b87\u91ce",
            "title": {
                "fragments": [],
                "text": "Formation and control of optimal trajectory in human multijoint arm movement : minimum torque-change model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134746652"
                        ],
                        "name": "S. Pattinson",
                        "slug": "S.-Pattinson",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Pattinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pattinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "(Uno et al., 1989) Related examples are also found in economics and some other literatures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "This literature is too wide to survey here, but some examples include Sammut et al. (1992); Kuniyoshi et al. (1994); Demiris & Hayes (1994); Amit & Mataric (2002); Pomerleau (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5419699,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "5dd2ff36858e377c64d1d935b4b287f98a10d0d8",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-to-fly.-Pattinson",
            "title": {
                "fragments": [],
                "text": "Learning to fly."
            },
            "venue": {
                "fragments": [],
                "text": "Nursing"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30668475"
                        ],
                        "name": "G. Hayes",
                        "slug": "G.-Hayes",
                        "structuredName": {
                            "firstName": "Gillian",
                            "lastName": "Hayes",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3132238"
                        ],
                        "name": "J. Demiris",
                        "slug": "J.-Demiris",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Demiris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demiris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 85
                            }
                        ],
                        "text": "(Uno et al., 1989) Related examples are also found in economics and some other literatures."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "This literature is too wide to survey here, but some examples include Sammut et al. (1992); Kuniyoshi et al. (1994); Demiris & Hayes (1994); Amit & Mataric (2002); Pomerleau (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59842754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cda8da6bc7b7b82ca8f2716f23ccc6ef339de35c",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Robot-Controller-Using-Learning-by-Imitation-Hayes-Demiris",
            "title": {
                "fragments": [],
                "text": "A Robot Controller Using Learning by Imitation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66418228"
                        ],
                        "name": "\u4e38\u5c71 \u5fb9",
                        "slug": "\u4e38\u5c71-\u5fb9",
                        "structuredName": {
                            "firstName": "\u4e38\u5c71",
                            "lastName": "\u5fb9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u4e38\u5c71 \u5fb9"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117573922,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b272701e77ddb860741a193ac1701ca382853680",
            "isKey": false,
            "numCitedBy": 7930,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convex-Analysis\u306e\u4e8c,\u4e09\u306e\u9032\u5c55\u306b\u3064\u3044\u3066-\u4e38\u5c71",
            "title": {
                "fragments": [],
                "text": "Convex Analysis\u306e\u4e8c,\u4e09\u306e\u9032\u5c55\u306b\u3064\u3044\u3066"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 4,
            "result": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Apprenticeship-learning-via-inverse-reinforcement-Abbeel-Ng/f65020fc3b1692d7989e099d6b6e698be5a50a93?sort=total-citations"
}