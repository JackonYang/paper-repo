{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "To handle these difficulties, time integration or additional domain constraints such as joint limits and body non-self-intersection must be incorporated."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1719474,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2523864e14ea5e2434cfef8bf0fd0213204068cc",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of articulated 3D human motion tracking in monocular video sequences. Addressing problems related to unconstrained scene structure, uncertainty, and the high-dimensional parameter spaces required for human modeling, we present a novel, layered-robust, multiple hypothesis algorithm for estimating the distribution of the model parameters and propagating it over time. We use cost function based on robust contour and image intensity descriptors in a multiple assignment data association scheme. Our mixed discrete/global and continuous/local search technique uses both informed sampling and continuous optimization. Its novel hypothesis generation and pruning strategy focuses attention on poorly constrained directions in which large parameter space deviations are most likely, thus adaptively tracking the complex cost surface produced by non-linear kinematics, perspecti- ve projection and data-association problems. We also address the issue of semi-automatic acquisition of initial model pose and proportions, and show experimental tracking results involving complex motions with significant background clutter and self-occlusion."
            },
            "slug": "A-Robust-Multiple-Hypothesis-Approach-to-Monocular-Sminchisescu-Triggs",
            "title": {
                "fragments": [],
                "text": "A Robust Multiple Hypothesis Approach to Monocular Human Motion Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel, layered-robust, multiple hypothesis algorithm for estimating the distribution of the model parameters and propagating it over time and uses cost function based on robust contour and image intensity descriptors in a multiple assignment data association scheme."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706204"
                        ],
                        "name": "I. Kakadiaris",
                        "slug": "I.-Kakadiaris",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Kakadiaris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Kakadiaris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711560"
                        ],
                        "name": "Dimitris N. Metaxas",
                        "slug": "Dimitris-N.-Metaxas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Metaxas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitris N. Metaxas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "using local Taylor models to predict good search directions [6, 23,  18 , 28, 22]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e.g."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7, 17] or multi-camera 3D [ 18 , 11, 6, 22] tracking and surprisingly few works have addressed it [9, 25, 28, 15, 5]. The main additional difficulty is the omnipresence of depth ambiguities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18748251,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4d24117d83ad925d837ed0b7d6aa065140fb0248",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for the 3D model-based tracking of human body parts. To mitigate the difficulties arising due to occlusion among body parts, we employ multiple calibrated cameras in a mutually orthogonal configuration. In addition, we develop criteria for a time varying active selection of a set of cameras to track the motion of a particular human part. In particular, at every frame, each camera tracks a number of parts depending on the visibility of these parts and the observability of their predicted motion from the specific camera. To relate points on the occluding contours of the parts to points on their models we apply concepts from projective geometry. Then, within the physics-based framework we compute the generalized forces applied from the parts' occluding contours to model points of the body parts. These forces update the translational and rotational degrees of freedom of the model, such as to minimize the discrepancy between the sensory data and the estimated model state. We present initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion."
            },
            "slug": "Model-based-estimation-of-3D-human-motion-with-on-Kakadiaris-Metaxas",
            "title": {
                "fragments": [],
                "text": "Model-based estimation of 3D human motion with occlusion based on active multi-viewpoint selection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Initial tracking results from a series of experiments involving the recovery of complex 3D motions in the presence of significant occlusion are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704879"
                        ],
                        "name": "H. Kjellstr\u00f6m",
                        "slug": "H.-Kjellstr\u00f6m",
                        "structuredName": {
                            "firstName": "Hedvig",
                            "lastName": "Kjellstr\u00f6m",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kjellstr\u00f6m"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793739"
                        ],
                        "name": "David J. Fleet",
                        "slug": "David-J.-Fleet",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fleet",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Fleet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "(iii) Matching a complex, imperfectly known, self-occluding model to a cluttered scene is inherently hard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "\u2026improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e.g. a local rectangular grid [11]; and stochastic sampling\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 46737148,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49ec1434331e16ad91550c8fb8906bf2c1031b98",
            "isKey": false,
            "numCitedBy": 837,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic method for tracking 3D articulated human figures in monocular image sequences is presented. Within a Bayesian framework, we define a generative model of image appearance, a robust likelihood function based on image graylevel differences, and a prior probability distribution over pose and joint angles that models how humans move. The posterior probability distribution over model parameters is represented using a discrete set of samples and is propagated over time using particle filtering. The approach extends previous work on parameterized optical flow estimation to exploit a complex 3D articulated motion model. It also extends previous work on human motion tracking by including a perspective camera model, by modeling limb self occlusion, and by recovering 3D motion from a monocular sequence. The explicit posterior probability distribution represents ambiguities due to image matching, model singularities, and perspective projection. The method relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds."
            },
            "slug": "Stochastic-Tracking-of-3D-Human-Figures-Using-2D-Kjellstr\u00f6m-Black",
            "title": {
                "fragments": [],
                "text": "Stochastic Tracking of 3D Human Figures Using 2D Image Motion"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A probabilistic method for tracking 3D articulated human figures in monocular image sequences that relies only on a frame-to-frame assumption of brightness constancy and hence is able to track people under changing viewpoints, in grayscale image sequences, and with complex unknown backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693428"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Davis",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7, 17] or multi-camera 3D [18,  11 , 6, 22] tracking and surprisingly few works have addressed it [9, 25, 28, 15, 5]. The main additional difficulty is the omnipresence of depth ambiguities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "a local rectangular grid [ 11 ]; and stochastic sampling generates random sampling points according to some hypothesis distribution encoding \u201cgood places to look\u201d [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5697345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc9b263c1af95ea803c4f5c8888ef8e37f0cef80",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a vision system for the 3-D model-based tracking of unconstrained human movement. Using image sequences acquired simultaneously from multiple views, we recover the 3-D body pose at each time instant without the use of markers. The pose-recovery problem is formulated as a search problem and entails finding the pose parameters of a graphical human model whose synthesized appearance is most similar to the actual appearance of the real human in the multi-view images. The models used for this purpose are acquired from the images. We use a decomposition approach and a best-first technique to search through the high dimensional pose parameter space. A robust variant of chamfer matching is used as a fast similarity measure between synthesized and real edge images. We present initial tracking results from a large new Humans-in-Action (HIA) database containing more than 2500 frames in each of four orthogonal views. They contain subjects involved in a variety of activities, of various degrees of complexity, ranging from the more simple one-person hand waving to the challenging two-person close interaction in the Argentine Tango."
            },
            "slug": "3-D-model-based-tracking-of-humans-in-action:-a-Gavrila-Davis",
            "title": {
                "fragments": [],
                "text": "3-D model-based tracking of humans in action: a multi-view approach"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A vision system for the 3-D model-based tracking of unconstrained human movement and initial tracking results from a large new Humans-in-Action database containing more than 2500 frames in each of four orthogonal views are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144196926"
                        ],
                        "name": "S. Wachter",
                        "slug": "S.-Wachter",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Wachter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Wachter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144721252"
                        ],
                        "name": "H. Nagel",
                        "slug": "H.-Nagel",
                        "structuredName": {
                            "firstName": "Hans-Hellmut",
                            "lastName": "Nagel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nagel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 280
                            }
                        ],
                        "text": "Extracting 3D human motion from natural monocular video sequences poses difficult modelling and computation problems: (i) Even a minimal human model is very complex, with at least 30 joint parameters and many more body shape ones, subject to joint limits and non-self-intersection constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "\u2026improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e.g. a local rectangular grid [11]; and stochastic sampling\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5916504,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a6fad775a27cc172479fdb6f291e361b35fd2f1e",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Quantitative geometric descriptions of the movements of persons are obtained by fitting the projection of a three-dimensional person model to consecutive frames of an image sequence. The kinematic of the person model is given by a homogeneous transformation tree and its body parts are modeled by right-elliptical cones. The values of a varying number of degrees of freedom (DOFs; body joints, position, and orientation of the person relative to the camera) can be determined according to the application and the kind of image sequence. The determination of the DOFs is understood as an estimation problem which is solved by an iterated extended Kalman filter (IEKF). For this purpose, the person model is augmented by a simple motion model of constant velocity for all DOFs which is used in the prediction step of the IEKF. In the update step, both region and edge information are used. Various experiments demonstrate the efficiency of our approach."
            },
            "slug": "Tracking-Persons-in-Monocular-Image-Sequences-Wachter-Nagel",
            "title": {
                "fragments": [],
                "text": "Tracking Persons in Monocular Image Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The person model is augmented by a simple motion model of constant velocity for all DOFs which is used in the prediction step of the IEKF and in the update step, both region and edge information are used."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144956884"
                        ],
                        "name": "R\u00f3mer Rosales",
                        "slug": "R\u00f3mer-Rosales",
                        "structuredName": {
                            "firstName": "R\u00f3mer",
                            "lastName": "Rosales",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00f3mer Rosales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12126519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fc6c277261a004b378f2feec3310fa86bc0b91b",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel approach for estimating articulated body posture and motion from monocular video sequences is proposed. Human pose is defined as the instantaneous two dimensional configuration (i.e. the projection onto the image plane) of a single articulated body in terms of the position of a predetermined sets of joints. First, statistical segmentation of the human bodies from the background is performed and low-level visual features are found given the segmented body shape. The goal is to be able to map these generally low level visual features to body configurations. The system estimates different mappings, each one with a specific cluster in the visual feature space. Given a set of body motion sequences for training, unsupervised clustering is obtained via the Expectation Maximization algorithm. For each of the clusters, a function is estimated to build the mapping between low-level features to 2D pose. Given new visual features, a mapping from each cluster is performed to yield a set of possible poses. From this set, the system selects the most likely pose given the learned probability distribution and the visual feature of the proposed approach is characterized using real and artificially generated body postures, showing promising results."
            },
            "slug": "Inferring-body-pose-without-tracking-body-parts-Rosales-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Inferring body pose without tracking body parts"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A novel approach for estimating articulated body posture and motion from monocular video sequences is proposed, characterized using real and artificially generated body postures, showing promising results."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698689"
                        ],
                        "name": "N. Jojic",
                        "slug": "N.-Jojic",
                        "structuredName": {
                            "firstName": "Nebojsa",
                            "lastName": "Jojic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Jojic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17441304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b4360fe5f2d70aa5f804b135e45dc8cea5f134c",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an algorithm for real-time tracking of articulated structures in dense disparity maps derived from stereo image sequences. A statistical image formation model that accounts for occlusions plays the central role in our tracking approach. This graphical model (a Bayesian network) assumes that the range image of each part of the structure is formed by drawing the depth candidates from a 3-D Gaussian distribution. The advantage over the classical mixture of Gaussians is that our model takes into account occlusions by picking the minimum depth (which could be regarded as a probabilistic version of z-buffering). The model also enforces articulation constraints among the parts of the structure. The tracking problem is formulated as an inference problem in the image formation model. This model can be extended and used for other tasks in addition to the one described in the paper and can also be used for estimating probability distribution functions instead of the ML estimates of the tracked parameters. For the purposes of real-time tracking, we used certain approximations in the inference process, which resulted in a real-time two-stage inference algorithm. We were able to successfully track upper human body motion in real time and in the presence of self-occlusions."
            },
            "slug": "Tracking-self-occluding-articulated-objects-in-maps-Jojic-Turk",
            "title": {
                "fragments": [],
                "text": "Tracking self-occluding articulated objects in dense disparity maps"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An algorithm for real-time tracking of articulated structures in dense disparity maps derived from stereo image sequences is presented, able to successfully track upper human body motion in real time and in the presence of self-occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144549270"
                        ],
                        "name": "M. Brand",
                        "slug": "M.-Brand",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Brand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "\u2026an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e.g. a local rectangular grid [11]; and stochastic sampling generates\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45365612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13a1d20381ef248068a881ebab27d1fe60cf3228",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The mapping between 3D body poses and 2D shadows is fundamentally many-to-many and defeats regression methods, even with windowed context. We show how to learn a function between paths in the two systems, resolving ambiguities by integrating information over the entire length of a sequence. The basis of this function is a configural and dynamical manifold that summarizes the target system's behaviour. This manifold can be modeled from data with a hidden Markov model having special topological properties that we obtain via entropy minimization. Inference is then a matter of solving for the geodesic on the manifold that best explains the evidence in the cue sequence. We give a closed-form maximum a posteriori solution for geodesics through the learned density space, thereby obtaining optimal paths over the dynamical manifold. These methods give a completely general way to perform inference over time-series; in vision they support analysis, recognition, classification and synthesis of behaviours in linear time. We demonstrate with a prototype that infers 3D from monocular monochromatic sequences (e.g., back-subtractions), without using any articulatory body model. The framework readily accommodates multiple cameras and other sources of evidence such as optical flow or feature tracking."
            },
            "slug": "Shadow-puppetry-Brand",
            "title": {
                "fragments": [],
                "text": "Shadow puppetry"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "A closed-form maximum a posteriori solution for geodesics through the learned density space, thereby obtaining optimal paths over the dynamical manifold gives a completely general way to perform inference over time-series."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152672574"
                        ],
                        "name": "J. Deutscher",
                        "slug": "J.-Deutscher",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Deutscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deutscher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145950884"
                        ],
                        "name": "I. Reid",
                        "slug": "I.-Reid",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Reid",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Reid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We finish with experimental results on some challenging monocular sequences, that illustrate the need for each of robust cost modelling, joint and self-intersection constraints, and wellcontrolled sampling plus local optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "(iii) Matching a complex, imperfectly known, self-occluding model to a cluttered scene is inherently hard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "\u2026incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e.g. a local rectangular grid [11]; and stochastic\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 686395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f6613ef17d3d7627adf3108ac4b3be9e0abfb6e",
            "isKey": false,
            "numCitedBy": 1082,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The main challenge in articulated body motion tracking is the large number of degrees of freedom (around 30) to be recovered. Search algorithms, either deterministic or stochastic, that search such a space without constraint, fall foul of exponential computational complexity. One approach is to introduce constraints: either labelling using markers or colour coding, prior assumptions about motion trajectories or view restrictions. Another is to relax constraints arising from articulation, and track limbs as if their motions were independent. In contrast, we aim for general tracking without special preparation of objects or restrictive assumptions. The principal contribution of the paper is the development of a modified particle filter for search in high dimensional configuration spaces. It uses a continuation principle based on annealing to introduce the influence of narrow peaks in the fitness function, gradually. The new algorithm, termed annealed particle filtering, is shown to be capable of recovering full articulated body motion efficiently."
            },
            "slug": "Articulated-body-motion-capture-by-annealed-Deutscher-Blake",
            "title": {
                "fragments": [],
                "text": "Articulated body motion capture by annealed particle filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The principal contribution of the paper is the development of a modified particle filter for search in high dimensional configuration spaces that uses a continuation principle based on annealing to introduce the influence of narrow peaks in the fitness function, gradually."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 147
                            }
                        ],
                        "text": "Three main classes of search strategies exist: local descent incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 266
                            }
                        ],
                        "text": "Extracting 3D human motion from natural monocular video sequences poses difficult modelling and computation problems: (i) Even a minimal human model is very complex, with at least 30 joint parameters and many more body shape ones, subject to joint limits and non-self-intersection constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2751624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f6a3dea66b539d75c30fb24ecefe627bbb0c3a9",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences. We introduce the use of a novel mathematical technique, the product of exponential maps and twist motions, and its integration into a differential motion estimation. This results in solving simple linear systems, and enables us to recover robustly the kinematic degrees-of-freedom in noise and complex self occluded configurations. We demonstrate this on several image sequences of people doing articulated full body movements, and visualize the results in re-animating an artificial 3D human model. We are also able to recover and re-animate the famous movements of Eadweard Muybridge's motion studies from the last century. To the best of our knowledge, this is the first computer vision based system that is able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "slug": "Tracking-people-with-twists-and-exponential-maps-Bregler-Malik",
            "title": {
                "fragments": [],
                "text": "Tracking people with twists and exponential maps"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This paper demonstrates a new visual motion estimation technique that is able to recover high degree-of-freedom articulated human body configurations in complex video sequences, and is the first computer vision based system able to process such challenging footage and recover complex motions with such high accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38388395"
                        ],
                        "name": "N. Howe",
                        "slug": "N.-Howe",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Howe",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Howe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1956966"
                        ],
                        "name": "M. Leventon",
                        "slug": "M.-Leventon",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Leventon",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leventon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "\u2026improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e.g. a local rectangular grid [11]; and stochastic sampling generates\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1010343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71afe994133786f9f8865a68e6d4c065bc8101ed",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The three-dimensional motion of humans is underdetermined when the observation is limited to a single camera, due to the inherent 3D ambiguity of 2D video. We present a system that reconstructs the 3D motion of human subjects from single-camera video, relying on prior knowledge about human motion, learned from training data, to resolve those ambiguities. After initialization in 2D, the tracking and 3D reconstruction is automatic; we show results for several video sequences. The results show the power of treating 3D body tracking as an inference problem."
            },
            "slug": "Bayesian-Reconstruction-of-3D-Human-Motion-from-Howe-Leventon",
            "title": {
                "fragments": [],
                "text": "Bayesian Reconstruction of 3D Human Motion from Single-Camera Video"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A system that reconstructs the 3D motion of human subjects from single-camera video, relying on prior knowledge about human motion, learned from training data, to resolve those ambiguities."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981906"
                        ],
                        "name": "P. Anandan",
                        "slug": "P.-Anandan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Anandan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Anandan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "Cham & Rehg [7] use a similar model but need a special piecewise representation as their modes seem to occur in clusters after optimization."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14070356,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "eee90c038f43370a29b07e46f38dfe6527143a2c",
            "isKey": false,
            "numCitedBy": 1786,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Most approaches for estimating optical flow assume that, within a finite image region, only a single motion is present. Thissingle motion assumptionis violated in common situations involving transparency, depth discontinuities, independently moving objects, shadows, and specular reflections. To robustly estimate optical flow, the single motion assumption must be relaxed. This paper presents a framework based onrobust estimationthat addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions. We show how therobust estimation frameworkcan be applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions. The approach has been applied to three standard techniques for recovering optical flow: area-based regression, correlation, and regularization with motion discontinuities. This paper focuses on the recovery of multiple parametric motion models within a region, as well as the recovery of piecewise-smooth flow fields, and provides examples with natural and synthetic image sequences."
            },
            "slug": "The-Robust-Estimation-of-Multiple-Motions:-and-Flow-Black-Anandan",
            "title": {
                "fragments": [],
                "text": "The Robust Estimation of Multiple Motions: Parametric and Piecewise-Smooth Flow Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A framework based on robust estimation is presented that addresses violations of the brightness constancy and spatial smoothness assumptions caused by multiple motions of optical flow, and is applied to standard formulations of the optical flow problem thus reducing their sensitivity to violations of their underlying assumptions."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772763"
                        ],
                        "name": "E. Bernardo",
                        "slug": "E.-Bernardo",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Bernardo",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bernardo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149680415"
                        ],
                        "name": "L. Goncalves",
                        "slug": "L.-Goncalves",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Goncalves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goncalves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46614172"
                        ],
                        "name": "Enrico Ursella",
                        "slug": "Enrico-Ursella",
                        "structuredName": {
                            "firstName": "Enrico",
                            "lastName": "Ursella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enrico Ursella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19164875,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "7d91d26d47289d5633693cb6e91cb23b26195486",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of estimating the position and motion of a human arm in 3D without any constraints on its behavior and without the use of special markers. We model the arm as two truncated right-circular cones connected with spherical joints. We propose to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image. The system is demonstrated and tested on a real image sequence.<<ETX>>"
            },
            "slug": "Monocular-tracking-of-the-human-arm-in-3D-Bernardo-Goncalves",
            "title": {
                "fragments": [],
                "text": "Monocular tracking of the human arm in 3D"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes to use a recursive estimator for arm position, and to provide the estimator with error signals obtained by comparing the projected estimated arm position with that of the actual arm in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7,  17 ] or multi-camera 3D [18, 11, 6, 22] tracking and surprisingly few works have addressed it [9, 25, 28, 15, 5]. The main additional difficulty is the omnipresence of depth ambiguities."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5170789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e3b20fb94803d71910043059f402554aa5137b2",
            "isKey": false,
            "numCitedBy": 522,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the work of Black and Yacoob (1995) on the tracking and recognition of human facial expressions using parametrized models of optical flow to deal with the articulated motion of human limbs. We define a \"card-board person model\" in which a person's limbs are represented by a set of connected planar patches. The parametrized image motion of these patches in constrained to enforce articulated motion and is solved for directly using a robust estimation technique. The recovered motion parameters provide a rich and concise description of the activity that can be used for recognition. We propose a method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion. We illustrate the method with examples of tracking human legs of long image sequences."
            },
            "slug": "Cardboard-people:-a-parameterized-model-of-image-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: a parameterized model of articulated image motion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A method for performing view-based recognition of human activities from the optical flow parameters that extends previous methods to cope with the cyclical nature of human motion is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Second International Conference on Automatic Face and Gesture Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 270
                            }
                        ],
                        "text": "Extracting 3D human motion from natural monocular video sequences poses difficult modelling and computation problems: (i) Even a minimal human model is very complex, with at least 30 joint parameters and many more body shape ones, subject to joint limits and non-self-intersection constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17009967,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3740a2ab2936c2d87f6a3d8b742841a383ba502",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer sensing of hand and limb motion is an important problem for applications in human computer interaction and computer graphics. We describe a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another. Our approach uses a kinematic model to predict occlusions and windowed templates to track partially occluded objects. We present offline 3D tracking results for hand motion with significant self occlusion.<<ETX>>"
            },
            "slug": "Model-based-tracking-of-self-occluding-articulated-Rehg-Kanade",
            "title": {
                "fragments": [],
                "text": "Model-based tracking of self-occluding articulated objects"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work describes a framework for local trading of self occluding motion, in which one part of an object obstructs the visibility of another, using a kinematic model to predict occlusions and windowed templates to track partially occluded objects."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152672574"
                        ],
                        "name": "J. Deutscher",
                        "slug": "J.-Deutscher",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Deutscher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Deutscher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080413596"
                        ],
                        "name": "B. North",
                        "slug": "B.-North",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "North",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. North"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592057"
                        ],
                        "name": "B. Bascle",
                        "slug": "B.-Bascle",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Bascle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bascle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17824174,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "447d141211df152339dc49b6d4669ead738a001a",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Some issues in markerless tracking of human body motion are addressed. Extended Kalman filters have commonly been applied to kinematic variables, to combine predictions consistent with plausible motion, with the incoming stream of visual measurements. Kalman filtering is applicable only when the underlying distribution is approximately Gaussian. Often this assumption proves remarkably robust. There are two pervasive circumstances under which the Gaussianity assumption can break down. The first is kinematic singularity and the second is at joint endstops. Failure of Kalman filtering under these circumstances is illustrated. The non-Gaussian nature of the distributions is demonstrated experimentally by means of Monte Carlo simulation. Random simulation (particle filtering or Condensation) proves to provide a robust alternative algorithm for tracking that can also deal with these difficult conditions."
            },
            "slug": "Tracking-through-singularities-and-discontinuities-Deutscher-North",
            "title": {
                "fragments": [],
                "text": "Tracking through singularities and discontinuities by random sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Random simulation (particle filtering or Condensation) proves to provide a robust alternative algorithm for tracking that can also deal with these difficult conditions of markerless tracking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144449553"
                        ],
                        "name": "Daniel D. Morris",
                        "slug": "Daniel-D.-Morris",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Morris",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel D. Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2095781,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "098d076e4f6a662bcd78d1f0154b4e60f70764ce",
            "isKey": false,
            "numCitedBy": 173,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the use of kinematic constraints for articulated object tracking. Conditions for the occurrence of singularities in 3-D models are presented and their effects on tracking are characterized We describe a novel 2-D Scaled Prismatic Model (SPM) for figure registration. In contrast to 3-D kinematic models, the SPM has fewer singularity problems and does not require detailed knowledge of the 3-D kinematics. We fully characterize the singularities in the SPM and illustrate tracking through singularities using synthetic and real examples with 3-D and 2-D models. Our results demonstrate the significant benefits of the SPM in tracking with a single source of video."
            },
            "slug": "Singularity-analysis-for-articulated-object-Morris-Rehg",
            "title": {
                "fragments": [],
                "text": "Singularity analysis for articulated object tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes a novel 2-D Scaled Prismatic Model (SPM) for figure registration that has fewer singularity problems and does not require detailed knowledge of the 3-D kinematics."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5637383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7bfe222d83e9dd9117bc4f8508962a01fb0b1626",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "A new exemplar-based, probabilistic paradigm for visual tracking is presented. Probabilistic mechanisms are attractive because they handle fusion of information, especially temporal fusion, in a principled manner. Exemplars are selected representatives of raw training data, used here to represent probabilistic mixture distributions of object configurations. Their use avoids tedious hand-construction of object models and problems with changes of topology. Using exemplars in place of a parameterized model poses several challenges, addressed here with what we call the \"Metric Mixture\" (M/sup 2/) approach. The M/sup 2/ model has several valuable properties. Principally, it provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space. Secondly, it uses a noise model that is learned from training data. Lastly, it eliminates any need for an assumption of probabilistic pixelwise independence. Experiments demonstrate the effectiveness of the M/sup 2/ model in two domains tracking walking people using chamfer distances on binary edge images and tracking mouth movements by means of a shuffle distance."
            },
            "slug": "Probabilistic-tracking-in-a-metric-space-Toyama-Blake",
            "title": {
                "fragments": [],
                "text": "Probabilistic tracking in a metric space"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A new exemplar-based, probabilistic paradigm for visual tracking is presented, which provides alternatives to standard learning algorithms by allowing the use of metrics that are not embedded in a vector space and eliminates any need for an assumption of probabilistically pixelwise independence."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760976"
                        ],
                        "name": "P. McLauchlan",
                        "slug": "P.-McLauchlan",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "McLauchlan",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. McLauchlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "91799708"
                        ],
                        "name": "R. Hartley",
                        "slug": "R.-Hartley",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hartley",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hartley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47139824"
                        ],
                        "name": "A. Fitzgibbon",
                        "slug": "A.-Fitzgibbon",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Fitzgibbon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fitzgibbon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1354186,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1cf6c415f598273ff4b3c03a1597e30402800a99",
            "isKey": false,
            "numCitedBy": 3988,
            "numCiting": 212,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a survey of the theory and methods of photogrammetric bundle adjustment, aimed at potential implementors in the computer vision community. Bundle adjustment is the problem of refining a visual reconstruction to produce jointly optimal structure and viewing parameter estimates. Topics covered include: the choice of cost function and robustness; numerical optimization including sparse Newton methods, linearly convergent approximations, updating and recursive methods; gauge (datum) invariance; and quality control. The theory is developed for general robust cost functions rather than restricting attention to traditional nonlinear least squares."
            },
            "slug": "Bundle-Adjustment-A-Modern-Synthesis-Triggs-McLauchlan",
            "title": {
                "fragments": [],
                "text": "Bundle Adjustment - A Modern Synthesis"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on Vision Algorithms"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738147"
                        ],
                        "name": "R. Pl\u00e4nkers",
                        "slug": "R.-Pl\u00e4nkers",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Pl\u00e4nkers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Pl\u00e4nkers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717736"
                        ],
                        "name": "P. Fua",
                        "slug": "P.-Fua",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Fua",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "\u2026main classes of search strategies exist: local descent incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 285
                            }
                        ],
                        "text": "Extracting 3D human motion from natural monocular video sequences poses difficult modelling and computation problems: (i) Even a minimal human model is very complex, with at least 30 joint parameters and many more body shape ones, subject to joint limits and non-self-intersection constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15433078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee94336c4ce5820b649dcf33758e61a71f8fe7bd",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a framework for 3-D shape and motion recovery of articulated deformable objects. We propose a formalism that incorporates the use of implicit surfaces into earlier robotics approaches that were designed to handle articulated structures. We demonstrate its effectiveness for human body modeling from video sequences. Our method is both robust and generic. It could easily be applied to other shape and motion recovery problems."
            },
            "slug": "Articulated-soft-objects-for-video-based-body-Pl\u00e4nkers-Fua",
            "title": {
                "fragments": [],
                "text": "Articulated soft objects for video-based body modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This work develops a framework for 3-D shape and motion recovery of articulated deformable objects that incorporates the use of implicit surfaces into earlier robotics approaches that were designed to handle articulated structures."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144530541"
                        ],
                        "name": "T. Cham",
                        "slug": "T.-Cham",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Cham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We finish with experimental results on some challenging monocular sequences, that illustrate the need for each of robust cost modelling, joint and self-intersection constraints, and wellcontrolled sampling plus local optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Three main classes of search strategies exist: local descent incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Our system is the first to enforce both hard joint angle limits and body non-self-intersection constraints, and also includes full 3D occlusion prediction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "6) were shot at 25 frames (50 fields) per second against a cluttered, unevenly illuminated background."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 202131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4af6518594742d5e440fd3a13324f5a907805f08",
            "isKey": true,
            "numCitedBy": 401,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a probabilistic multiple-hypothesis framework for tracking highly articulated objects. In this framework, the probability density of the tracker state is represented as a set of modes with piecewise Gaussians characterizing the neighborhood around these modes. The temporal evolution of the probability density is achieved through sampling from the prior distribution, followed by local optimization of the sample positions to obtain updated modes. This method of generating hypotheses from state-space search does not require the use of discrete features unlike classical multiple-hypothesis tracking. The parametric form of the model is suited for high dimensional state-spaces which cannot be efficiently modeled using non-parametric approaches. Results are shown for tracking Fred Astaire in a movie dance sequence."
            },
            "slug": "A-multiple-hypothesis-approach-to-figure-tracking-Cham-Rehg",
            "title": {
                "fragments": [],
                "text": "A multiple hypothesis approach to figure tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A probabilistic multiple-hypothesis framework for tracking highly articulated objects where the probability density of the tracker state is represented as a set of modes with piecewise Gaussians characterizing the neighborhood around these modes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31589308"
                        ],
                        "name": "C. J. Taylor",
                        "slug": "C.-J.-Taylor",
                        "structuredName": {
                            "firstName": "Camillo",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11364178,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "59719c9a2be9a5b4e2c5d4183926a3ad66b96486",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the problem of recovering information about the configuration of an articulated object, such as a human figure, from point correspondences in a single-image. Unlike previous approaches, the proposed reconstruction method does not assume that the imagery was acquired with a calibrated camera. An analysis is presented which demonstrates that there are a family of solutions to this reconstruction problem parameterized by a single variable. A simple and effective algorithm is proposed for recovering the entire set of solutions by considering the foreshortening of the segments of the model in the image. Results obtained by applying this algorithm to real images are presented."
            },
            "slug": "Reconstruction-of-articulated-objects-from-point-in-Taylor",
            "title": {
                "fragments": [],
                "text": "Reconstruction of Articulated Objects from Point Correspondences in a Single Uncalibrated Image"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This paper investigates the problem of recovering information about the configuration of an articulated object, such as a human figure, from point correspondences in a single image by considering the foreshortening of the segments of the model in the image."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40178596"
                        ],
                        "name": "T. Heap",
                        "slug": "T.-Heap",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Heap",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Heap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1967104"
                        ],
                        "name": "David C. Hogg",
                        "slug": "David-C.-Hogg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hogg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David C. Hogg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We finish with experimental results on some challenging monocular sequences, that illustrate the need for each of robust cost modelling, joint and self-intersection constraints, and wellcontrolled sampling plus local optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Our system is the first to enforce both hard joint angle limits and body non-self-intersection constraints, and also includes full 3D occlusion prediction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "For linearized monomodal dynamics and observation models under Gaussian noise, this leads to (Extended) Kalman Filtering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2418402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c3948ca1d291955c78cbc29e998d83e4ede0ab4",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing object tracking algorithms generally use some form of local optimisation, assuming that an object's position and shape change smoothly over time. In some situations this assumption is not valid: the track able shape of an object may change discontinuously, for example if it is the 2D silhouette of a 3D object. In this paper we propose a novel method for modelling temporal shape discontinuities explicitly. Allowable shapes are represented as a union of (learned) bounded regions within a shape space. Discontinuous shape changes are described in terms of transitions between these regions. Transition probabilities are learned from training sequences and stored in a Markov model. In this way we can create 'wormholes' in shape space. Tracking with such models is via an adaptation, of the CONDENSATION algorithm."
            },
            "slug": "Wormholes-in-shape-space:-tracking-through-changes-Heap-Hogg",
            "title": {
                "fragments": [],
                "text": "Wormholes in shape space: tracking through discontinuous changes in shape"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a novel method for modelling temporal shape discontinuities explicitly, represented as a union of (learned) bounded regions within a shape space, which can create 'wormholes' in shape space."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698422"
                        ],
                        "name": "J. MacCormick",
                        "slug": "J.-MacCormick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "MacCormick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. MacCormick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "!) extent that the dynamics and the image matching cost are realistic statistical models, Bayes-law propagation of a probability density for the true state is possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14382281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86efc15754e34254e5991c3a0fdcffbffbc47a3e",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Partitioned sampling is a technique which was introduced in [I7] for avoiding the high cost of particle filters when tracking more than one object. In fact this technique can reduce the curse of dimensionality in other situations too. This paper describes how to use partitioned sampling on articulated objects, obtaining results that would be impossible with standard sampling methods. Because partitioned sampling is the statistical analogue of a hierarchical search, it makes sense to use it on articulated objects, since links at the base of the object can be localised before moving on to search for subsequent links."
            },
            "slug": "Partitioned-Sampling,-Articulated-Objects,-and-Hand-MacCormick-Isard",
            "title": {
                "fragments": [],
                "text": "Partitioned Sampling, Articulated Objects, and Interface-Quality Hand Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes how to use partitioned sampling on articulated objects, obtaining results that would be impossible with standard sampling methods."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34469963"
                        ],
                        "name": "J. J. Kuch",
                        "slug": "J.-J.-Kuch",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Kuch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. J. Kuch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29672561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084bc4a55619f3215b1df1dc1af488842d7df15d",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression. The model can be fitted to any person's hand and can be done using a single camera. Once the model is fitted to a real human hand, it is then used in several tracking scenarios in order to verify its effectiveness. With successful tracking achieved, the model is ready to be incorporated into a virtual environment or model based compression scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks at very low bit rates and at very high image quality.<<ETX>>"
            },
            "slug": "Vision-based-hand-modeling-and-tracking-for-virtual-Kuch-Huang",
            "title": {
                "fragments": [],
                "text": "Vision based hand modeling and tracking for virtual teleconferencing and telecollaboration"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The authors present a hand model that simultaneously satisfies both the synthesis and analysis requirements of model based compression and is ready to be incorporated into a virtual environment or model based compressed scheme such as sign language communication over telephone lines or virtual teleconferences over computer networks."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Computer Vision"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144854796"
                        ],
                        "name": "D. Gavrila",
                        "slug": "D.-Gavrila",
                        "structuredName": {
                            "firstName": "Dariu",
                            "lastName": "Gavrila",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Gavrila"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7788290,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4e4b41b6010ac1e6c90791168f57bcd75b696ab",
            "isKey": false,
            "numCitedBy": 2210,
            "numCiting": 145,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to recognize humans and their activities by vision is key for a machine to interact intelligently and effortlessly with a human-inhabited environment. Because of many potentially important applications, \u201clooking at people\u201d is currently one of the most active application domains in computer vision. This survey identifies a number of promising applications and provides an overview of recent developments in this domain. The scope of this survey is limited to work on whole-body or hand motion; it does not include work on human faces. The emphasis is on discussing the various methodologies; they are grouped in 2-D approaches with or without explicit shape models and 3-D approaches. Where appropriate, systems are reviewed. We conclude with some thoughts about future directions."
            },
            "slug": "The-Visual-Analysis-of-Human-Movement:-A-Survey-Gavrila",
            "title": {
                "fragments": [],
                "text": "The Visual Analysis of Human Movement: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A number of promising applications are identified and an overview of recent developments in this domain is provided, including work on whole-body or hand motion and the various methodologies."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3021334"
                        ],
                        "name": "A. Barr",
                        "slug": "A.-Barr",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Barr",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7, 18] or multi-camera 3D [19, 11, 6, 23] tracking and surprisingly few works have addressed it [9, 26, 31, 16, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16162806,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "3739bc6d4be47169fc9a24a4b9a54b4ab67e21e1",
            "isKey": false,
            "numCitedBy": 946,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "New hierarchical solid modeling operations are developed, which simulate twisting, bending, tapering, or similar transformations of geometric objects. The chief result is that the normal vector of an arbitrarily deformed smooth surface can be calculated directly from the surface normal vector of the undeformed surface and a transformation matrix. Deformations are easily combined in a hierarchical structure, creating complex objects from simpler ones. The position vectors and normal vectors in the simpler objects are used to calculate the position and normal vectors in the more complex forms; each level in the deformation hierarchy requires an additional matrix multiply for the normal vector calculation. Deformations are important and highly intuitive operations which ease the control and rendering of large families of three-dimensional geometric shapes."
            },
            "slug": "Global-and-local-deformations-of-solid-primitives-Barr",
            "title": {
                "fragments": [],
                "text": "Global and local deformations of solid primitives"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "New hierarchical solid modeling operations are developed, which simulate twisting, bending, tapering, or similar transformations of geometric objects, and the chief result is that the normal vector of an arbitrarily deformed smooth surface can be calculated directly from the surfacenormal vector of the undeformed surface and a transformation matrix."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145162067"
                        ],
                        "name": "A. Blake",
                        "slug": "A.-Blake",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Blake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Blake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080413596"
                        ],
                        "name": "B. North",
                        "slug": "B.-North",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "North",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. North"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "!) extent that the dynamics and the image matching cost are realistic statistical models, Bayes-law propagation of a probability density for the true state is possible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28400528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36c521146c624d9fd26ed33da098a06e0f1ebf97",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard techniques (eg. Yule-Walker) are available for learning Auto-Regressive process models of simple, directly observable, dynamical processes. When sensor noise means that dynamics are observed only approximately, learning can still been achieved via Expectation-Maximisation (EM) together with Kalman Filtering. However, this does not handle more complex dynamics, involving multiple classes of motion. For that problem, we show here how EM can be combined with the CONDENSATION algorithm, which is based on propagation of random sample-sets. Experiments have been performed with visually observed juggling, and plausible dynamical models are found to emerge from the learning process."
            },
            "slug": "Learning-Multi-Class-Dynamics-Blake-North",
            "title": {
                "fragments": [],
                "text": "Learning Multi-Class Dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown here how EM can be combined with the CONDENSATION algorithm, which is based on propagation of random sample-sets, and plausible dynamical models are found to emerge from the learning process."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144733293"
                        ],
                        "name": "R. Fletcher",
                        "slug": "R.-Fletcher",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Fletcher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fletcher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123487779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b84b383ad59f79e607ad0f08a8a10876631a0cd",
            "isKey": false,
            "numCitedBy": 9912,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface Table of Notation Part 1: Unconstrained Optimization Introduction Structure of Methods Newton-like Methods Conjugate Direction Methods Restricted Step Methods Sums of Squares and Nonlinear Equations Part 2: Constrained Optimization Introduction Linear Programming The Theory of Constrained Optimization Quadratic Programming General Linearly Constrained Optimization Nonlinear Programming Other Optimization Problems Non-Smooth Optimization References Subject Index."
            },
            "slug": "Practical-Methods-of-Optimization-Fletcher",
            "title": {
                "fragments": [],
                "text": "Practical Methods of Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The aim of this book is to provide a Discussion of Constrained Optimization and its Applications to Linear Programming and Other Optimization Problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917469"
                        ],
                        "name": "Shanon X. Ju",
                        "slug": "Shanon-X.-Ju",
                        "structuredName": {
                            "firstName": "Shanon",
                            "lastName": "Ju",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shanon X. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1964574"
                        ],
                        "name": "Y. Yacoob",
                        "slug": "Y.-Yacoob",
                        "structuredName": {
                            "firstName": "Yaser",
                            "lastName": "Yacoob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yacoob"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Three main classes of search strategies exist: local descent incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 108068634,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "dc132c04da4d6817a775efdac86372ae77f12b0f",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cardboard-people:-A-parametrized-model-of-motion-Ju-Black",
            "title": {
                "fragments": [],
                "text": "Cardboard people: A parametrized model of articulated motion"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143660080"
                        ],
                        "name": "G. Walsh",
                        "slug": "G.-Walsh",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Walsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Walsh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118507308,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db97110cd43f1398bacb7838316d72024f982c66",
            "isKey": false,
            "numCitedBy": 639,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Methods-Of-Optimization-Walsh",
            "title": {
                "fragments": [],
                "text": "Methods Of Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1970
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model - Based Estimation of 3 D Human Motion with Occlusion Prediction Based on Active MultiViewpoint Selection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DYNAMAN; A Recursive Model of Human Motion"
            },
            "venue": {
                "fragments": [],
                "text": "MIT Media Lab Tech. Report"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Deutscher [9] uses a sophisticated \u2018annealed sampling\u2019 strategy to speed up CONDENSATION, but for his main sequence uses 3 cameras and a black background."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Adding temporal models with observations Rt = {r1, . . . , rt}, the posterior distribution becomes:\np(xt|Rt) \u221d p(r\u0304t|xt) p(xt) p(xt|xt\u22121) p(xt\u22121|Rt\u22121) Here p(xt|xt\u22121) is the dynamical model and p(xt\u22121|Rt\u22121) is the prior distribution from t \u2212 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Animation Working Group Specifications for a standard humanoid"
            },
            "venue": {
                "fragments": [],
                "text": "Animation Working Group Specifications for a standard humanoid"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Three main classes of search strategies exist: local descent incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 275
                            }
                        ],
                        "text": "Extracting 3D human motion from natural monocular video sequences poses difficult modelling and computation problems: (i) Even a minimal human model is very complex, with at least 30 joint parameters and many more body shape ones, subject to joint limits and non-self-intersection constraints."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-Based Estimation of 3D Human Motion with Occlusion Prediction Based on Active Multi-Viewpoint Selection"
            },
            "venue": {
                "fragments": [],
                "text": "Model-Based Estimation of 3D Human Motion with Occlusion Prediction Based on Active Multi-Viewpoint Selection"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bundle Adjustment -A Modern Synthesis Vision Algorithms: Theory and Practice"
            },
            "venue": {
                "fragments": [],
                "text": "LNCS"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 74
                            }
                        ],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7, 17] or multi-camera 3D [18, 11, 6, 22] tracking and surprisingly few works have addressed it [9, 25, 28, 15, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cardboard people: A parameterized model of articulated motion\u201d,2nd Int.Conf.on"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic Face and Gesture Recognition,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "(ii) Unlike the 2D and multi-camera 3D cases, in any given monocular image about 1/3 of the degrees of freedom are nearly unobservable (mainly motions in (relative) depth, but also rotations of near-cylindrical limbs about their axes)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "Three main classes of search strategies exist: local descent incrementally improves an existing estimate, e.g. using local Taylor models to predict good search directions [6, 24, 19, 31, 23]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3-D Model Based Tracking of Humans in Action:a Multiview Approach"
            },
            "venue": {
                "fragments": [],
                "text": "3-D Model Based Tracking of Humans in Action:a Multiview Approach"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 60
                            }
                        ],
                        "text": "using local Taylor models to predict good search directions [6, 23, 18, 28, 22]; regular sampling evaluates the cost function at a predefined pattern of points in (a slice of) parameter space, e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 101
                            }
                        ],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7, 17] or multi-camera 3D [18, 11, 6, 22] tracking and surprisingly few works have addressed it [9, 25, 28, 15, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-Based Estimation of 3D Human Motion with Occlusion Prediction Based on Active Multi-Viewpoint Selection"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR, pp. 81-87, 1996."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Cardboard people : A parameterized model of articulated motion \u201d , 2 nd In ?"
            },
            "venue": {
                "fragments": [],
                "text": "Monocular Tracking of the human arm in 3 D , ICCV"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "a local rectangular grid [11]; and stochastic sampling generates random sampling points according to some hypothesis distribution encoding \u201cgood places to look\u201d [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 101
                            }
                        ],
                        "text": "3D body tracking from monocular sequences is significantly harder than 2D [7, 17] or multi-camera 3D [18, 11, 6, 22] tracking and surprisingly few works have addressed it [9, 25, 28, 15, 5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "3-D Model Based Tracking of Humans in Action:a Multiview Approach"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR, pp. 73-80, 1996."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model - Based Estimation of 3 D Human Motion with Occlusion Prediction Based on Active MultiViewpoint Selection"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 42,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Covariance-scaled-sampling-for-monocular-3D-body-Sminchisescu-Triggs/2d0b50d3df26b64ec5a2f949bc241b4fce515fa9?sort=total-citations"
}