{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "Similarly, one can reduce the number of feature calculations by actively selecting low-level features that help discrimination for many classes simultaneously [33]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2741819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd626564bd47e9fc67a5b276301282ba2fe3d833",
            "isKey": false,
            "numCitedBy": 793,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of detecting a large number of different classes of objects in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, at multiple locations and scales. This can be slow and can require a lot of training data since each classifier requires the computation of many different image features. In particular, for independently trained detectors, the (runtime) computational complexity and the (training-time) sample complexity scale linearly with the number of classes to be detected. We present a multitask learning procedure, based on boosted decision stumps, that reduces the computational and sample complexity by finding common features that can be shared across the classes (and/or views). The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required and, therefore, the runtime cost of the classifier, is observed to scale approximately logarithmically with the number of classes. The features selected by joint training are generic edge-like features, whereas the features chosen by training each class separately tend to be more object-specific. The generic features generalize better and considerably reduce the computational cost of multiclass object detection"
            },
            "slug": "Sharing-Visual-Features-for-Multiclass-and-Object-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Sharing Visual Features for Multiclass and Multiview Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A multitask learning procedure, based on boosted decision stumps, that reduces the computational and sample complexity by finding common features that can be shared across the classes (and/or views) and considerably reduce the computational cost of multiclass object detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105534484"
                        ],
                        "name": "Michael Fink",
                        "slug": "Michael-Fink",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Fink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Fink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We thank Charles Kemp for providing the Osherson/Wilkie class\u2013attribute matrix and Jens Weidmann for several weeks of labeling work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40683457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2aa330150205f30ce23a6fce88c1de6776744574",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nCurrent object recognition systems aim at recognizing numerous object classes under limited supervision conditions. This paper provides a benchmark for evaluating progress on this fundamental task. Several methods have recently proposed to utilize the commonalities between object classes in order to improve generalization accuracy. Such methods can be termed interclass transfer techniques. However, it is currently difficult to asses which of the proposed methods maximally utilizes the shared structure of related classes. In order to facilitate the development, as well as the assessment of methods for dealing with multiple related classes, a new dataset including images of several hundred mammal classes, is provided, together with preliminary results of its use. The images in this dataset are organized into five levels of variability, and their labels include information on the objects\u2019 identity, location and pose. From this dataset, a classification benchmark has been derived, requiring fine distinctions between 72 mammal classes. It is then demonstrated that a recognition method which is highly successful on the Caltech101, attains limited accuracy on the current benchmark (36.5%). Since this method does not utilize the shared structure between classes, the question remains as to whether interclass transfer methods can increase the accuracy to the level of human performance (90%). We suggest that a labeled benchmark of the type provided, containing a large number of related classes is crucial for the development and evaluation of classification methods which make efficient use of interclass transfer.\n"
            },
            "slug": "From-Aardvark-to-Zorro:-A-Benchmark-for-Mammal-Fink-Ullman",
            "title": {
                "fragments": [],
                "text": "From Aardvark to Zorro: A Benchmark for Mammal Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is suggested that a labeled benchmark of the type provided, containing a large number of related classes is crucial for the development and evaluation of classification methods which make efficient use of interclass transfer."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47655614"
                        ],
                        "name": "G. Griffin",
                        "slug": "G.-Griffin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Griffin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160673"
                        ],
                        "name": "Alex Holub",
                        "slug": "Alex-Holub",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Holub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Holub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Caltech [15] and PASCAL VOC4, is has become difficult to judge the true performance of newly proposed classification methods, because results based on very different feature sets need to be compared."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118828957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a5effa909cdeafaddbbb7855037e02f8e25d632",
            "isKey": false,
            "numCitedBy": 2545,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions."
            },
            "slug": "Caltech-256-Object-Category-Dataset-Griffin-Holub",
            "title": {
                "fragments": [],
                "text": "Caltech-256 Object Category Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A challenging set of 256 object categories containing a total of 30607 images is introduced and the clutter category is used to train an interest detector which rejects uninformative background regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "On a higher level, pictorial structures [13], the constellation model [10] and recent discriminatively trained deformable part models [9] are examples of the many methods that recognize objects in images by detecting discriminative parts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5745749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62837ab473124ea43cb8d7c6a4b4ee0f6f14e8c5",
            "isKey": false,
            "numCitedBy": 2487,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method to learn and recognize object class models from unlabeled and unsegmented cluttered scenes in a scale invariant manner. Objects are modeled as flexible constellations of parts. A probabilistic representation is used for all aspects of the object: shape, appearance, occlusion and relative scale. An entropy-based feature detector is used to select regions and their scale within the image. In learning the parameters of the scale-invariant object model are estimated. This is done using expectation-maximization in a maximum-likelihood setting. In recognition, this model is used in a Bayesian manner to classify images. The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "slug": "Object-class-recognition-by-unsupervised-learning-Fergus-Perona",
            "title": {
                "fragments": [],
                "text": "Object class recognition by unsupervised scale-invariant learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The flexible nature of the model is demonstrated by excellent results over a range of datasets including geometrically constrained classes (e.g. faces, cars) and flexible objects (such as animals)."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "From known object classes, one infers prior distributions over the expected intra-class variance in terms of distortions [22] or shapes and appearances [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6953475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812355cec91fa30bb50e9e992a3549af39e4f6eb",
            "isKey": false,
            "numCitedBy": 2364,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood (ML) and maximum a posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "slug": "One-shot-learning-of-object-categories-Fei-Fei-Fergus",
            "title": {
                "fragments": [],
                "text": "One-shot learning of object categories"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is found that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37742199"
                        ],
                        "name": "Philipp Zehnder",
                        "slug": "Philipp-Zehnder",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Zehnder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Zehnder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401786555"
                        ],
                        "name": "E. Koller-Meier",
                        "slug": "E.-Koller-Meier",
                        "structuredName": {
                            "firstName": "Esther",
                            "lastName": "Koller-Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Koller-Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Combinations of both approaches are also possible [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1274283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcd27094c0a91a33455a318a242aa6d6eea6248b",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel multi-class object detector, that optimizes the detection costs while retaining a desired detection rate. The detector uses a cascade that unites the handling of similar object classes while separating off classes at appropriate levels of the cascade. No prior knowledge about the relationship between classes is needed as the classifier structure is automatically determined during the training phase. The detection nodes in the cascade use Haar wavelet features and Gentle AdaBoost, however the approach is not dependent on the specific features used and can easily be extended to other cases. Experiments are presented for several numbers of object classes and the approach is compared to other classifying schemes. The results demonstrate a large efficiency gain that is particularly prominent for a greater number of classes. Also the complexity of the training scales well with the number of classes."
            },
            "slug": "An-Efficient-Shared-Multi-Class-Detection-Cascade-Zehnder-Koller-Meier",
            "title": {
                "fragments": [],
                "text": "An Efficient Shared Multi-Class Detection Cascade"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel multi-class object detector that optimizes the detection costs while retaining a desired detection rate is proposed, that uses a cascade that unites the handling of similar object classes while separating off classes at appropriate levels of the cascade."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 118
                            }
                        ],
                        "text": "Prior work in the area of computer vision has mainly studied elementary properties like colors and geometric patterns [11, 36, 38], achieving high accuracy by developing task-specific features and representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10004927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "461d2c494d0353834c54f13e74cc80cd56dbe365",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic generative model of visual attributes, together with an efficient learning algorithm. Attributes are visual qualities of objects, such as 'red', 'striped', or 'spotted'. The model sees attributes as patterns of image segments, repeatedly sharing some characteristic properties. These can be any combination of appearance, shape, or the layout of segments within the pattern. Moreover, attributes with general appearance are taken into account, such as the pattern of alternation of any two colors which is characteristic for stripes. To enable learning from unsegmented training images, the model is learnt discriminatively, by optimizing a likelihood ratio. \n \nAs demonstrated in the experimental evaluation, our model can learn in a weakly supervised setting and encompasses a broad range of attributes. We show that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images."
            },
            "slug": "Learning-Visual-Attributes-Ferrari-Zisserman",
            "title": {
                "fragments": [],
                "text": "Learning Visual Attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that attributes can be learnt starting from a text query to Google image search, and can then be used to recognize the attribute and determine its spatial extent in novel real-world images."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1938475"
                        ],
                        "name": "E. Bart",
                        "slug": "E.-Bart",
                        "structuredName": {
                            "firstName": "Evgeniy",
                            "lastName": "Bart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "Alternatively, features that are known to be discriminative for some classes can be reused and adapted to support the detection of new classes [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18632647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f2b11d835b72b1f6385ede0631d49b10c6f2914",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an object classification method that can learn a novel class from a single training example. In this method, experience with already learned classes is used to facilitate the learning of novel classes. Our classification scheme employs features that discriminate between class and non-class images. For a novel class, new features are derived by selecting features that proved useful for already learned classification tasks, and adapting these features to the new classification task. This adaptation is performed by replacing the features from already learned classes with similar features taken from the novel class. A single example of a novel class is sufficient to perform feature adaptation and achieve useful classification performance. Experiments demonstrate that the proposed algorithm can learn a novel class from a single training example, using 10 additional familiar classes. The performance is significantly improved compared to using no feature adaptation. The robustness of the proposed feature adaptation concept is demonstrated by similar performance gains across 107 widely varying object categories."
            },
            "slug": "Cross-generalization:-learning-novel-classes-from-a-Bart-Ullman",
            "title": {
                "fragments": [],
                "text": "Cross-generalization: learning novel classes from a single example by feature replacement"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An object classification method that can learn a novel class from a single training example, using 10 additional familiar classes, and the performance is significantly improved compared to using no feature adaptation."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33652486"
                        ],
                        "name": "J. Winn",
                        "slug": "J.-Winn",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Winn",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Winn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698689"
                        ],
                        "name": "N. Jojic",
                        "slug": "N.-Jojic",
                        "structuredName": {
                            "firstName": "Nebojsa",
                            "lastName": "Jojic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Jojic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "Similarly, image segmentation has been proposed as an unsupervised method to extract contours that are discriminative for object classes [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5489503,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79bd5e61e20594c13a90e66293e1abb4179935a2",
            "isKey": false,
            "numCitedBy": 412,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of learning object class models and object segmentations from unannotated images. We introduce LOCUS (learning object classes with unsupervised segmentation) which uses a generative probabilistic model to combine bottom-up cues of color and edge with top-down cues of shape and pose. A key aspect of this model is that the object appearance is allowed to vary from image to image, allowing for significant within-class variation. By iteratively updating the belief in the object's position, size, segmentation and pose, LOCUS avoids making hard decisions about any of these quantities and so allows for each to be refined at any stage. We show that LOCUS successfully learns an object class model from unlabeled images, whilst also giving segmentation accuracies that rival existing supervised methods. Finally, we demonstrate simultaneous recognition and segmentation in novel images using the learned models for a number of object classes, as well as unsupervised object discovery and tracking in video."
            },
            "slug": "LOCUS:-learning-object-classes-with-unsupervised-Winn-Jojic",
            "title": {
                "fragments": [],
                "text": "LOCUS: learning object classes with unsupervised segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "LOCUS (learning object classes with unsupervised segmentation) is introduced which uses a generative probabilistic model to combine bottom-up cues of color and edge with top-down cues of shape and pose, allowing for significant within-class variation."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "A noticable exception is [8] that uses high-level attributes to learn descriptions of object."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14940757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6a8aef1bf134294482d8088f982d5643347d2ff",
            "isKey": false,
            "numCitedBy": 1662,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to shift the goal of recognition from naming to describing. Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (\u201cspotty dog\u201d, not just \u201cdog\u201d); to say something about unfamiliar objects (\u201chairy and four-legged\u201d, not just \u201cunknown\u201d); and to learn how to recognize new objects with few or no visual examples. Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition. These attributes can be semantic (\u201cspotty\u201d) or discriminative (\u201cdogs have it but sheep do not\u201d). Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category. In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories. We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework."
            },
            "slug": "Describing-objects-by-their-attributes-Farhadi-Endres",
            "title": {
                "fragments": [],
                "text": "Describing objects by their attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper proposes to shift the goal of recognition from naming to describing, and introduces a novel feature selection method for learning attributes that generalize well across categories."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144423856"
                        ],
                        "name": "Anna Bosch",
                        "slug": "Anna-Bosch",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Bosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna Bosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062941326"
                        ],
                        "name": "X. Mu\u00f1oz",
                        "slug": "X.-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Mu\u00f1oz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The color histograms and PHOG feature vectors are extracted separately for all 21 cells of a 3-level spatial pyramids (1\u00d71, 2\u00d72, 4\u00d7 4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "For PHOG, the same construction is used, but with 12-dimensional base histograms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "We have selected six different feature types: RGB color histograms, SIFT [21], rgSIFT [35], PHOG [4], SURF [2] and local self-similarity histograms [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7211257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b98c68f01d84ac07dc7fc51af782018070da748f",
            "isKey": false,
            "numCitedBy": 1496,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The objective of this paper is classifying images by the object categories they contain, for example motorbikes or dolphins. There are three areas of novelty. First, we introduce a descriptor that represents local image shape and its spatial layout, together with a spatial pyramid kernel. These are designed so that the shape correspondence between two images can be measured by the distance between their descriptors using the kernel. Second, we generalize the spatial pyramid kernel, and learn its level weighting parameters (on a validation set). This significantly improves classification performance. Third, we show that shape and appearance kernels may be combined (again by learning parameters on a validation set).\n Results are reported for classification on Caltech-101 and retrieval on the TRECVID 2006 data sets. For Caltech-101 it is shown that the class specific optimization that we introduce exceeds the state of the art performance by more than 10%."
            },
            "slug": "Representing-shape-with-a-spatial-pyramid-kernel-Bosch-Zisserman",
            "title": {
                "fragments": [],
                "text": "Representing shape with a spatial pyramid kernel"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces a descriptor that represents local image shape and its spatial layout, together with a spatial pyramid kernel that is designed so that the shape correspondence between two images can be measured by the distance between their descriptors using the kernel."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "On a higher level, pictorial structures [13], the constellation model [10] and recent discriminatively trained deformable part models [9] are examples of the many methods that recognize objects in images by detecting discriminative parts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2616,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 356,
                                "start": 352
                            }
                        ],
                        "text": "Especially in the area of computer vision, multi-layered classification systems have been constructed, in which intermediate layers have interpretable properties: artificial neural networks or deep belief networks have been shown to learn interpretable filters, but these are typically restricted to low-level properties like edge and corner detectors [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11398758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccd52aff02b0f902f4ce7247c4fee7273014c41c",
            "isKey": false,
            "numCitedBy": 1089,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64% error on MNIST, and 54% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "slug": "Unsupervised-Learning-of-Invariant-Feature-with-to-Ranzato-Huang",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions that alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242194"
                        ],
                        "name": "Ghulum Bakiri",
                        "slug": "Ghulum-Bakiri",
                        "structuredName": {
                            "firstName": "Ghulum",
                            "lastName": "Bakiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ghulum Bakiri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "For simplicity, we assume that all attributes have binary values such that the attribute representation ay = (ay1, . . . , a y m) for any training class y are fixed-length binary vectors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47109072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d221bbcbd20c7157e4500f942de8ceec490f8936",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k > 2 values (i.e., k \"classes\"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "slug": "Solving-Multiclass-Learning-Problems-via-Output-Dietterich-Bakiri",
            "title": {
                "fragments": [],
                "text": "Solving Multiclass Learning Problems via Error-Correcting Output Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is demonstrated that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820687"
                        ],
                        "name": "Joost van de Weijer",
                        "slug": "Joost-van-de-Weijer",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Weijer",
                            "middleNames": [
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joost van de Weijer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721683"
                        ],
                        "name": "J. Verbeek",
                        "slug": "J.-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verbeek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Prior work in the area of computer vision has mainly studied elementary properties like colors and geometric patterns [11, 36, 38], achieving high accuracy by developing task-specific features and representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2852002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a38768dabcd02539265c065a4d7ac445309ae96",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Within a computer vision context color naming is the action of assigning linguistic color labels to image pixels. In general, research on color naming applies the following paradigm: a collection of color chips is labelled with color names within a well-defined experimental setup by multiple test subjects. The collected data set is subsequently used to label RGB values in real-world images with a color name. Apart from the fact that this collection process is time consuming, it is unclear to what extent color naming within a controlled setup is representative for color naming in real-world images. Therefore we propose to learn color names from real-world images. Furthermore, we avoid test subjects by using Google Image to collect a data set. Due to limitations of Google Image this data set contains a substantial quantity of wrongly labelled data. The color names are learned using a PLSA model adapted to this task. Experimental results show that color names learned from real-world images significantly outperform color names learned from labelled color chips on retrieval and classification."
            },
            "slug": "Learning-Color-Names-from-Real-World-Images-Weijer-Schmid",
            "title": {
                "fragments": [],
                "text": "Learning Color Names from Real-World Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show that color names learned from real-world images significantly outperform color names learning from labelled color chips on retrieval and classification."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "By making similar classes share large parts of their decision paths, fewer classification functions need to be learned, thereby increasing the system\u2019s performance [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1204938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32484f6d111bf21f1395a34a087991a9041dd0ae",
            "isKey": false,
            "numCitedBy": 1876,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new learning architecture: the Decision Directed Acyclic Graph (DDAG), which is used to combine many two-class classifiers into a multiclass classifier. For an N-class problem, the DDAG contains N(N - 1)/2 classifiers, one for each pair of classes. We present a VC analysis of the case when the node classifiers are hyperplanes; the resulting bound on the test error depends on N and on the margin achieved at the nodes, but not on the dimension of the space. This motivates an algorithm, DAGSVM, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG. The DAGSVM is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms."
            },
            "slug": "Large-Margin-DAGs-for-Multiclass-Classification-Platt-Cristianini",
            "title": {
                "fragments": [],
                "text": "Large Margin DAGs for Multiclass Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm, DAGSVM, is presented, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG, which is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782440"
                        ],
                        "name": "A. Ulges",
                        "slug": "A.-Ulges",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Ulges",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ulges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151477236"
                        ],
                        "name": "Christian Schulze",
                        "slug": "Christian-Schulze",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schulze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Schulze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51027911"
                        ],
                        "name": "Daniel Keysers",
                        "slug": "Daniel-Keysers",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Keysers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Keysers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733858"
                        ],
                        "name": "T. Breuel",
                        "slug": "T.-Breuel",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Breuel",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Breuel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 172
                            }
                        ],
                        "text": "Typical systems in this area combine many feature representations and, because they were designed for retrieval scenarios, they aim at high precision for low recall levels [34, 40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16060312,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b78f258cbe1f34a938547eb1585e43f8fdbd200",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A key problem with the automatic detection of semantic concepts (like 'interview' or 'soccer') in video streams is the manual acquisition of adequate training sets. Recently, we have proposed to use online videos downloaded from portals like youtube.com for this purpose, whereas tags provided by users during video upload serve as ground truth annotations.\n The problem with such training data is that it is weakly labeled: Annotations are only provided on video level, and many shots of a video may be \"non-relevant\", i.e. not visually related to a tag. In this paper, we present a probabilistic framework for learning from such weakly annotated training videos in the presence of irrelevant content. Thereby, the relevance of keyframes is modeled as a latent random variable that is estimated during training.\n In quantitative experiments on real-world online videos and TV news data, we demonstrate that the proposed model leads to a significantly increased robustness with respect to irrelevant content, and to a better generalization of the resulting concept detectors."
            },
            "slug": "Identifying-relevant-frames-in-weakly-labeled-for-Ulges-Schulze",
            "title": {
                "fragments": [],
                "text": "Identifying relevant frames in weakly labeled videos for training concept detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A probabilistic framework for learning from weakly annotated training videos in the presence of irrelevant content is presented, and the relevance of keyframes is modeled as a latent random variable that is estimated during training."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41224113"
                        ],
                        "name": "E. Miller",
                        "slug": "E.-Miller",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Miller",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1837031"
                        ],
                        "name": "Nicholas E. Matsakis",
                        "slug": "Nicholas-E.-Matsakis",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Matsakis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas E. Matsakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731948"
                        ],
                        "name": "Paul A. Viola",
                        "slug": "Paul-A.-Viola",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Viola",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul A. Viola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "From known object classes, one infers prior distributions over the expected intra-class variance in terms of distortions [22] or shapes and appearances [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2699786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7aac1045e6943b4a7978e260a3035662d5b3bf8d",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a process called congealing in which elements of a dataset (images) are brought into correspondence with each other jointly, producing a data-defined model. It is based upon minimizing the summed component-wise (pixel-wise) entropies over a continuous set of transforms on the data. One of the biproducts of this minimization is a set of transform, one associated with each original training sample. We then demonstrate a procedure for effectively bringing test data into correspondence with the data-defined model produced in the congealing process. Subsequently; we develop a probability density over the set of transforms that arose from the congealing process. We suggest that this density over transforms may be shared by many classes, and demonstrate how using this density as \"prior knowledge\" can be used to develop a classifier based on only a single training example for each class."
            },
            "slug": "Learning-from-one-example-through-shared-densities-Miller-Matsakis",
            "title": {
                "fragments": [],
                "text": "Learning from one example through shared densities on transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A probability density over the set of transforms that arose from the congealing process is developed, and it is suggested that this density over transforms may be shared by many classes, and used to develop a classifier based on only a single training example for each class."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Popular local feature descriptors, such as SIFT [21] or HoG [6], can be seen as hand-crafted stages in a feedforward architecture that transform an image from the pixel domain into a representation invariant to non-informative image variations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 181
                            }
                        ],
                        "text": "For specific object classes, in particular faces and vehicles, reliable and efficient detectors are available, based on the combination of powerful low-level features, e.g. SIFT or HoG, with modern machine learning techniques, e.g. boosting or support vector machines."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29259,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2299972"
                        ],
                        "name": "I. Biederman",
                        "slug": "I.-Biederman",
                        "structuredName": {
                            "firstName": "Irving",
                            "lastName": "Biederman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Biederman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 94
                            }
                        ],
                        "text": "It has been estimated that humans distinguish between at least 30,000 relevant object classes [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8054340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b37258659bcdbc380b1e6c4e22cce9ea06397a1",
            "isKey": false,
            "numCitedBy": 5632,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components, such as blocks, cylinders, wedges, and cones. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons (N \u00a3 36), can be derived from contrasts of five readily detectable properties of edges in a two-dimensiona l image: curvature, collinearity, symmetry, parallelism, and cotermination. The detection of these properties is generally invariant over viewing position an$ image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition: The constraints toward regularization (Pragnanz) characterize not the complete object but the object's components. Representational power derives from an allowance of free combinations of the geons. A Principle of Componential Recovery can account for the major phenomena of object recognition: If an arrangement of two or three geons can be recovered from the input, objects can be quickly recognized even when they are occluded, novel, rotated in depth, or extensively degraded. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory. Any single object can project an infinity of image configurations to the retina. The orientation of the object to the viewer can vary continuously, each giving rise to a different two-dimensional projection. The object can be occluded by other objects or texture fields, as when viewed behind foliage. The object need not be presented as a full-colored textured image but instead can be a simplified line drawing. Moreover, the object can even be missing some of its parts or be a novel exemplar of its particular category. But it is only with rare exceptions that an image fails to be rapidly and readily classified, either as an instance of a familiar object category or as an instance that cannot be so classified (itself a form of classification)."
            },
            "slug": "Recognition-by-components:-a-theory-of-human-image-Biederman",
            "title": {
                "fragments": [],
                "text": "Recognition-by-components: a theory of human image understanding."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recognition-by-components (RBC) provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11691394"
                        ],
                        "name": "R. Rifkin",
                        "slug": "R.-Rifkin",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Rifkin",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rifkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753266"
                        ],
                        "name": "A. Klautau",
                        "slug": "A.-Klautau",
                        "structuredName": {
                            "firstName": "Aldebaro",
                            "lastName": "Klautau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Klautau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "For simplicity, we assume that all attributes have binary values such that the attribute representation ay = (ay1, . . . , a y m) for any training class y are fixed-length binary vectors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13391792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c44749c8496a82512047aad0fd5e31e1b979d6a",
            "isKey": false,
            "numCitedBy": 1845,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of multiclass classification. Our main thesis is that a simple \"one-vs-all\" scheme is as accurate as any other approach, assuming that the underlying binary classifiers are well-tuned regularized classifiers such as support vector machines. This thesis is interesting in that it disagrees with a large body of recent published work on multiclass classification. We support our position by means of a critical review of the existing literature, a substantial collection of carefully controlled experimental work, and theoretical arguments."
            },
            "slug": "In-Defense-of-One-Vs-All-Classification-Rifkin-Klautau",
            "title": {
                "fragments": [],
                "text": "In Defense of One-Vs-All Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "It is argued that a simple \"one-vs-all\" scheme is as accurate as any other approach, assuming that the underlying binary classifiers are well-tuned regularized classifiers such as support vector machines."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681659"
                        ],
                        "name": "Keiji Yanai",
                        "slug": "Keiji-Yanai",
                        "structuredName": {
                            "firstName": "Keiji",
                            "lastName": "Yanai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keiji Yanai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145602732"
                        ],
                        "name": "Kobus Barnard",
                        "slug": "Kobus-Barnard",
                        "structuredName": {
                            "firstName": "Kobus",
                            "lastName": "Barnard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kobus Barnard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 118
                            }
                        ],
                        "text": "Prior work in the area of computer vision has mainly studied elementary properties like colors and geometric patterns [11, 36, 38], achieving high accuracy by developing task-specific features and representations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9479292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27e63b3ab2ed11a6848bbc8809bcd5276057f80b",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method to measure \"visualness\" of concepts, that is, what extent concepts have visual characteristics. To know which concept has visually discriminative power is important for image annotation, especially automatic image annotation by image recognition system, since not all concepts are related to visual contents. Our method performs probabilistic region selection for images which are labeled as concept \"X\" or \"non-X\", and computes an entropy measure which represents \"visualness\" of concepts. In the experiments, we collected about forty thousand images from the World-Wide Web using the Google Image Search for 150 concepts. We examined which concepts are suitable for annotation of image contents."
            },
            "slug": "Image-region-entropy:-a-measure-of-\"visualness\"-of-Yanai-Barnard",
            "title": {
                "fragments": [],
                "text": "Image region entropy: a measure of \"visualness\" of web images associated with one concept"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A new method to measure \"visualness\" of concepts, that is, what extent concepts have visual characteristics, which performs probabilistic region selection for images which are labeled as concept \"X\" or \"non-X\", and computes an entropy measure which represents \"visuals\" of concept."
            },
            "venue": {
                "fragments": [],
                "text": "MULTIMEDIA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2177801"
                        ],
                        "name": "E. Shechtman",
                        "slug": "E.-Shechtman",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Shechtman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Shechtman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144611617"
                        ],
                        "name": "M. Irani",
                        "slug": "M.-Irani",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Irani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Irani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "We have selected six different feature types: RGB color histograms, SIFT [21], rgSIFT [35], PHOG [4], SURF [2] and local self-similarity histograms [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2341530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5feb23e3c01c12c797b271fa5cd2a1f2f096130f",
            "isKey": false,
            "numCitedBy": 1062,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach for measuring similarity between visual entities (images or videos) based on matching internal self-similarities. What is correlated across images (or across video sequences) is the internal layout of local self-similarities (up to some distortions), even though the patterns generating those local self-similarities are quite different in each of the images/videos. These internal self-similarities are efficiently captured by a compact local \"self-similarity descriptor\"', measured densely throughout the image/video, at multiple scales, while accounting for local and global geometric distortions. This gives rise to matching capabilities of complex visual data, including detection of objects in real cluttered images using only rough hand-sketches, handling textured objects with no clear boundaries, and detecting complex actions in cluttered video data with no prior learning. We compare our measure to commonly used image-based and video-based similarity measures, and demonstrate its applicability to object detection, retrieval, and action detection."
            },
            "slug": "Matching-Local-Self-Similarities-across-Images-and-Shechtman-Irani",
            "title": {
                "fragments": [],
                "text": "Matching Local Self-Similarities across Images and Videos"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An approach for measuring similarity between visual entities (images or videos) based on matching internal self-similarities, measured densely throughout the image/video, at multiple scales, while accounting for local and global geometric distortions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2515436"
                        ],
                        "name": "Yantao Zheng",
                        "slug": "Yantao-Zheng",
                        "structuredName": {
                            "firstName": "Yantao",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yantao Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708955"
                        ],
                        "name": "Shi-Yong Neo",
                        "slug": "Shi-Yong-Neo",
                        "structuredName": {
                            "firstName": "Shi-Yong",
                            "lastName": "Neo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Yong Neo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056267488"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 172
                            }
                        ],
                        "text": "Typical systems in this area combine many feature representations and, because they were designed for retrieval scenarios, they aim at high precision for low recall levels [34, 40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1993013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59cb83746d4bcfd85af50032e9b34ffe352b6a4a",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a probabilistic ranking-driven classifier for the detection of video semantic concept, such as airplane, building, etc. Most existing concept detection systems utilize Support Vector Machines (SVM) to perform the detection and ranking of retrieved video shots. However, the margin maximization principle of SVM does not perform ranking optimization but merely classification error minimization. To tackle this problem, we exploit the sparse Bayesian kernel model, namely the relevance vector machine (RVM), as the classifier for semantic concept detection. Based on automatic relevance determination principle, RVM outputs the posterior probabilistic prediction of the semantic concepts. This inference output is optimal for ranking the target video shots, according to the Probabilistic Ranking Principle. The probability output of RVM on individual uni-modal features also facilitates probabilistic fusion of multi-modal evidences to minimize Bayes risk. We demonstrate both theoretically and empirically that RVM outperforms SVM for video semantic concept detection. The testings on TRECVID 07 dataset show that RVM produces statically significant improvements in MAP scores over the SVM-based methods."
            },
            "slug": "Probabilistic-optimized-ranking-for-multimedia-via-Zheng-Neo",
            "title": {
                "fragments": [],
                "text": "Probabilistic optimized ranking for multimedia semantic concept detection via RVM"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is demonstrated both theoretically and empirically that RVM outperforms SVM for video semantic concept detection and produces statically significant improvements in MAP scores over the SVM-based methods."
            },
            "venue": {
                "fragments": [],
                "text": "CIVR '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "Multi-layer or cascaded classifiers have a long tradition in pattern recognition and computer vision: multi-layer perceptrons [29], decision trees [5], mixtures of experts [17] and boosting [14] are prominent examples of classification systems built as feed-forward architectures with several stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6644398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf5208521cb8c35f50ee8873df89294b8ed7292",
            "isKey": false,
            "numCitedBy": 13118,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of the paper we consider the problem of dynamically apportioning resources among a set of options in a worst-case on-line framework. The model we study can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting. We show that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems. We show how the resulting learning algorithm can be applied to a variety of problems, including gambling, multiple-outcome prediction, repeated games, and prediction of points in Rn. In the second part of the paper we apply the multiplicative weight-update technique to derive a new boosting algorithm. This boosting algorithm does not require any prior knowledge about the performance of the weak learning algorithm. We also study generalizations of the new boosting algorithm to the problem of learning functions whose range, rather than being binary, is an arbitrary finite set or a bounded segment of the real line."
            },
            "slug": "A-decision-theoretic-generalization-of-on-line-and-Freund-Schapire",
            "title": {
                "fragments": [],
                "text": "A decision-theoretic generalization of on-line learning and an application to boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The model studied can be interpreted as a broad, abstract extension of the well-studied on-line prediction model to a general decision-theoretic setting, and it is shown that the multiplicative weight-update Littlestone?Warmuth rule can be adapted to this model, yielding bounds that are slightly weaker in some cases, but applicable to a considerably more general class of learning problems."
            },
            "venue": {
                "fragments": [],
                "text": "EuroCOLT"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195306"
                        ],
                        "name": "H. Bay",
                        "slug": "H.-Bay",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Bay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433494"
                        ],
                        "name": "Andreas Ess",
                        "slug": "Andreas-Ess",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Ess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704728"
                        ],
                        "name": "T. Tuytelaars",
                        "slug": "T.-Tuytelaars",
                        "structuredName": {
                            "firstName": "Tinne",
                            "lastName": "Tuytelaars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tuytelaars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681236"
                        ],
                        "name": "L. Gool",
                        "slug": "L.-Gool",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Gool",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gool"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "We have selected six different feature types: RGB color histograms, SIFT [21], rgSIFT [35], PHOG [4], SURF [2] and local self-similarity histograms [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14777911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdbb606ae47c64049262dfbd3bb147d3f4ba8420",
            "isKey": false,
            "numCitedBy": 11651,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speeded-Up-Robust-Features-(SURF)-Bay-Ess",
            "title": {
                "fragments": [],
                "text": "Speeded-Up Robust Features (SURF)"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756979"
                        ],
                        "name": "K. V. D. Sande",
                        "slug": "K.-V.-D.-Sande",
                        "structuredName": {
                            "firstName": "Koen",
                            "lastName": "Sande",
                            "middleNames": [
                                "E.",
                                "A.",
                                "van",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. V. D. Sande"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695527"
                        ],
                        "name": "T. Gevers",
                        "slug": "T.-Gevers",
                        "structuredName": {
                            "firstName": "Theo",
                            "lastName": "Gevers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Gevers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145404204"
                        ],
                        "name": "Cees G. M. Snoek",
                        "slug": "Cees-G.-M.-Snoek",
                        "structuredName": {
                            "firstName": "Cees",
                            "lastName": "Snoek",
                            "middleNames": [
                                "G.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cees G. M. Snoek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "All attribute SVMs are based the same kernel, the sum of individual \u03c72-kernels for each feature, where the bandwidth parameters are fixed to the five times inverse of the median of the \u03c72-distances over the training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 216079084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a93e57ac2beee562c8962468f5cfd3858e2c5c2a",
            "isKey": false,
            "numCitedBy": 220,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Image category recognition is important to access visual information on the level of objects and scene types. So far, intensity-based descriptors have been widely used. To increase illumination invariance and discriminative power, color descriptors have been proposed only recently. As many descriptors exist, a structured overview of color invariant descriptors in the context of image category recognition is required."
            },
            "slug": "Evaluation-of-color-descriptors-for-object-and-Sande-Gevers",
            "title": {
                "fragments": [],
                "text": "Evaluation of color descriptors for object and scene recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A structured overview of color invariant descriptors in the context of image category recognition is required to increase illumination invariance and discriminative power."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680223"
                        ],
                        "name": "A. Smeaton",
                        "slug": "A.-Smeaton",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smeaton",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smeaton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143645506"
                        ],
                        "name": "P. Over",
                        "slug": "P.-Over",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Over",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Over"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740640"
                        ],
                        "name": "Wessel Kraaij",
                        "slug": "Wessel-Kraaij",
                        "structuredName": {
                            "firstName": "Wessel",
                            "lastName": "Kraaij",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wessel Kraaij"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "In the field of multimedia retrieval, the annual TRECVID contest [32] contains a subtask of high-level feature extraction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7677566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cb1f624b56eca597d65d27b8da7c4f2cd4b8531",
            "isKey": false,
            "numCitedBy": 1398,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "The TREC Video Retrieval Evaluation (TRECVid)is an international benchmarking activity to encourage research in video information retrieval by providing a large test collection, uniform scoring procedures, and a forum for organizations 1 interested in comparing their results. TRECVid completed its fifth annual cycle at the end of 2005 and in 2006 TRECVid will involve almost 70 research organizations, universities and other consortia. Throughout its existence, TRECVid has benchmarked both interactive and automatic/manual searching for shots from within a video corpus,automatic detection of a variety of semantic and low-level video features, shot boundary detection and the detection of story boundaries in broadcast TV news. This paper will give an introduction to information retrieval (IR) evaluation from both a user and a system perspective, high-lighting that system evaluation is by far the most prevalent type of evaluation carried out. We also include a summary of TRECVid as an example of a system evaluation bench-marking campaign and this allows us to discuss whether such campaigns are a good thing or a bad thing. There are arguments for and against these campaigns and we present some of them in the paper concluding that on balance they have had a very positive impact on research progress."
            },
            "slug": "Evaluation-campaigns-and-TRECVid-Smeaton-Over",
            "title": {
                "fragments": [],
                "text": "Evaluation campaigns and TRECVid"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An introduction to information retrieval (IR) evaluation from both a user and a system perspective is given, high-lighting that system evaluation is by far the most prevalent type of evaluation carried out."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887059"
                        ],
                        "name": "W. Loh",
                        "slug": "W.-Loh",
                        "structuredName": {
                            "firstName": "Wei-Yin",
                            "lastName": "Loh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Loh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17654166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e708b0cd19818e0c7408765dd922835661f8a24",
            "isKey": false,
            "numCitedBy": 18455,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification and regression trees are machine\u2010learning methods for constructing prediction models from data. The models are obtained by recursively partitioning the data space and fitting a simple prediction model within each partition. As a result, the partitioning can be represented graphically as a decision tree. Classification trees are designed for dependent variables that take a finite number of unordered values, with prediction error measured in terms of misclassification cost. Regression trees are for dependent variables that take continuous or ordered discrete values, with prediction error typically measured by the squared difference between the observed and predicted values. This article gives an introduction to the subject by reviewing some widely available algorithms and comparing their capabilities, strengths, and weakness in two examples. \u00a9 2011 John Wiley & Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 14\u201023 DOI: 10.1002/widm.8"
            },
            "slug": "Classification-and-regression-trees-Loh",
            "title": {
                "fragments": [],
                "text": "Classification and regression trees"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This article gives an introduction to the subject of classification and regression trees by reviewing some widely available algorithms and comparing their capabilities, strengths, and weakness in two examples."
            },
            "venue": {
                "fragments": [],
                "text": "WIREs Data Mining Knowl. Discov."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145300792"
                        ],
                        "name": "Charles Kemp",
                        "slug": "Charles-Kemp",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Kemp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Kemp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119177686"
                        ],
                        "name": "Takeshi Yamada",
                        "slug": "Takeshi-Yamada",
                        "structuredName": {
                            "firstName": "Takeshi",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takeshi Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735221"
                        ],
                        "name": "N. Ueda",
                        "slug": "N.-Ueda",
                        "structuredName": {
                            "firstName": "Naonori",
                            "lastName": "Ueda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ueda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] made use of the same data in a machine learning context and added 2 more animals classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1021333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87ca5a0f345533c30217f6359bc4325a2442a0b9",
            "isKey": false,
            "numCitedBy": 714,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Relationships between concepts account for a large proportion of semantic knowledge. We present a nonparametric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kinship systems, and discovering structure in political data."
            },
            "slug": "Learning-Systems-of-Concepts-with-an-Infinite-Model-Kemp-Tenenbaum",
            "title": {
                "fragments": [],
                "text": "Learning Systems of Concepts with an Infinite Relational Model"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A nonparametric Bayesian model is presented that discovers systems of related concepts and applies the approach to four problems: clustering objects and features, learning ontologies, discovering kinship systems, and discovering structure in political data."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3394928"
                        ],
                        "name": "R. Elschlager",
                        "slug": "R.-Elschlager",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Elschlager",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Elschlager"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "On a higher level, pictorial structures [13], the constellation model [10] and recent discriminatively trained deformable part models [9] are examples of the many methods that recognize objects in images by detecting discriminative parts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14554383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "719da2a0ddd38e78151e1cb2db31703ea8b2e490",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "slug": "The-Representation-and-Matching-of-Pictorial-Fischler-Elschlager",
            "title": {
                "fragments": [],
                "text": "The Representation and Matching of Pictorial Structures"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The primary problem dealt with in this paper is the specification of a descriptive scheme, and a metric on which to base the decision of \"goodness\" of matching or detection."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17585310"
                        ],
                        "name": "M. I. Jordan",
                        "slug": "M.-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144215175"
                        ],
                        "name": "R. Jacobs",
                        "slug": "R.-Jacobs",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jacobs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "Multi-layer or cascaded classifiers have a long tradition in pattern recognition and computer vision: multi-layer perceptrons [29], decision trees [5], mixtures of experts [17] and boosting [14] are prominent examples of classification systems built as feed-forward architectures with several stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 67000854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6d8a7fc2e2d53923832f9404376512068ca2a57",
            "isKey": false,
            "numCitedBy": 2136,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a tree-structured architecture for supervised learning. The statistical model underlying the architecture is a hierarchical mixture model in which both the mixture coefficients and the mixture components are generalized linear models (GLIM's). Learning is treated as a maximum likelihood problem; in particular, we present an Expectation-Maximization (EM) algorithm for adjusting the parameters of the architecture. We also develop an on-line learning algorithm in which the parameters are updated incrementally. Comparative simulation results are presented in the robot dynamics domain."
            },
            "slug": "Hierarchical-Mixtures-of-Experts-and-the-EM-Jordan-Jacobs",
            "title": {
                "fragments": [],
                "text": "Hierarchical mixtures of experts and the EM algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An Expectation-Maximization (EM) algorithm for adjusting the parameters of the tree-structured architecture for supervised learning and an on-line learning algorithm in which the parameters are updated incrementally."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "Popular local feature descriptors, such as SIFT [21] or HoG [6], can be seen as hand-crafted stages in a feedforward architecture that transform an image from the pixel domain into a representation invariant to non-informative image variations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "For specific object classes, in particular faces and vehicles, reliable and efficient detectors are available, based on the combination of powerful low-level features, e.g. SIFT or HoG, with modern machine learning techniques, e.g. boosting or support vector machines."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "We have selected six different feature types: RGB color histograms, SIFT [21], rgSIFT [35], PHOG [4], SURF [2] and local self-similarity histograms [30]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25497,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717349"
                        ],
                        "name": "D. Knuth",
                        "slug": "D.-Knuth",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Knuth",
                            "middleNames": [
                                "Ervin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Knuth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "p(a|z) = Ja = azK, making use of Iverson\u2019s bracket notation: JP K = 1 if the condition P is true and it is 0 otherwise [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 119584305,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "c986ba6287f67f197071bb991911657d7bfe8bbb",
            "isKey": false,
            "numCitedBy": 420,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Mathematical notation evolves like all languages do. As new experiments are made, we sometimes witness the survival of the fittest, sometimes the survival of the most familiar. A healthy conservatism keeps things from changing too rapidly; a healthy radicalism keeps things in tune with new theoretical emphases. Our mathematical language continues to improve, just as \"the d-ism of Leibniz overtook the dotage of Newton\" in past centuries [4, Chapter 4]. In 1970 I began teaching a class at Stanford University entitled Concrete Mathematics. The students and I studied how to manipulate formulas in continuous and discrete mathematics, and the problems we investigated were often inspired by new developments in computer science. As the years went by we began to see that a few changes in notational traditions would greatly facilitate our work. The notes from that class have recently been published in a book [15], and as I wrote the final drafts of that book I learned to my surprise that two of the notations we had been using were considerably more useful than I had previously realized. The ideas \"clicked\" so well, in fact, that I've decided to write this article, blatantly attempting to promote these notations among the mathematicians who have no use for [15]. I hope that within five years everybody will be able to use these notations in published papers without needing to explain what they mean. The notations I'm talking about are (1) Iverson's convention for characteristic functions; and (2) the \"right\" notation for Stirling numbers, at last."
            },
            "slug": "Two-notes-on-notation-Knuth",
            "title": {
                "fragments": [],
                "text": "Two notes on notation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Two notations are being promoted that everybody will be able to use in published papers without needing to explain what they mean: (1) Iverson's convention for characteristic functions; and the \"right\" notation for Stirling numbers, at last."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404363"
                        ],
                        "name": "S. Sloman",
                        "slug": "S.-Sloman",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Sloman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sloman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "Typical questions in the field are how human judgements are influenced by characteristic object attributes [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54325335,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "6494fa0fc496ad329773b58594740ec2d80e06b0",
            "isKey": false,
            "numCitedBy": 448,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A connectionist model of argument strength that applies to categorical arguments involving natural categories and predicates about which subjects have few prior beliefs is proposed. An example is robins have sesamoid bones, therefore falcons have sesamoid bones. The model is based on the hypothesis that argument strength is related to the proportion of the conclusion category\u2032s features that are shared by the premise categories. The model assumes a two-stage process. First, premises are encoded by connecting the features of premise categories to the predicate. Second, conclusions are tested by examining the degree of activation of the predicate upon presentation of the features of the conclusion category. The model accounts for 13 qualitative phenomena and shows close quantitative fits to several sets of argument strength ratings."
            },
            "slug": "Feature-Based-Induction-Sloman",
            "title": {
                "fragments": [],
                "text": "Feature-Based Induction"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26201908"
                        ],
                        "name": "T. Hansen",
                        "slug": "T.-Hansen",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582173"
                        ],
                        "name": "Maria Olkkonen",
                        "slug": "Maria-Olkkonen",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Olkkonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maria Olkkonen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068679303"
                        ],
                        "name": "S. Walter",
                        "slug": "S.-Walter",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Walter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Walter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3322056"
                        ],
                        "name": "K. Gegenfurtner",
                        "slug": "K.-Gegenfurtner",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Gegenfurtner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gegenfurtner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "detection tasks depends on the presence or absence of object properties and contextual cues [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15513884,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "da5d1758100958700877f0c4c1b2c2ca463baead",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We asked human observers to adjust the color of natural fruit objects until they appeared achromatic. The objects were generally perceived to be gray when their color was shifted away from the observers' gray point in a direction opposite to the typical color of the fruit. These results show that color sensations are not determined by the incoming sensory data alone, but are significantly modulated by high-level visual memory."
            },
            "slug": "Memory-modulates-color-appearance-Hansen-Olkkonen",
            "title": {
                "fragments": [],
                "text": "Memory modulates color appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show that color sensations are not determined by the incoming sensory data alone, but are significantly modulated by high-level visual memory."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "Multi-layer or cascaded classifiers have a long tradition in pattern recognition and computer vision: multi-layer perceptrons [29], decision trees [5], mixtures of experts [17] and boosting [14] are prominent examples of classification systems built as feed-forward architectures with several stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62245742,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "111fd833a4ae576cfdbb27d87d2f8fc0640af355",
            "isKey": false,
            "numCitedBy": 19356,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-internal-representations-by-error-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning internal representations by error propagation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097702214"
                        ],
                        "name": "T. Judgmen",
                        "slug": "T.-Judgmen",
                        "structuredName": {
                            "firstName": "T",
                            "lastName": "Judgmen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Judgmen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "Typical questions in the field are how human judgements are influenced by characteristic object attributes [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15328921,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "850124a5c4409c56c35b93486ae0fde3052e0e57",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We advance a model of human probability judgment and apply it to the design of an extrapolation algorithm. Such an algorithm examines a person's judgment about the likelihood of various statements and is then able to predict the same person's judgments about new statements. The algorithm is tested against judgments produced by thirty undergraduates asked to assign probabilities to statements about mammals."
            },
            "slug": "Extrapolating-human-probability-judgment-Judgmen",
            "title": {
                "fragments": [],
                "text": "Extrapolating human probability judgment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64295966,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b7caf811d6980627caad1a8b3053f40348693508",
            "isKey": false,
            "numCitedBy": 436,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction, Fitting a Sigmoid After the SVM, Empirical Tests, Conclusions, Appendix: Pseudo-code for the Sigmoid Training"
            },
            "slug": "Probabilities-for-SV-Machines-Smola-Bartlett",
            "title": {
                "fragments": [],
                "text": "Probabilities for SV Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction, Fitting a Sigmoid After the SVM, Empirical Tests, Conclusions, Appendix: Pseudo-code for the Sigmoids Training."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072120273"
                        ],
                        "name": "Daniel",
                        "slug": "Daniel",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Daniel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062802865"
                        ],
                        "name": "N.",
                        "slug": "N.",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "N.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N."
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103156698"
                        ],
                        "name": "Osherson",
                        "slug": "Osherson",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Osherson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Osherson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096882923"
                        ],
                        "name": "P. I.D.I.A.",
                        "slug": "P.-I.D.I.A.",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "I.D.I.A.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. I.D.I.A."
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077410225"
                        ],
                        "name": "Joshua",
                        "slug": "Joshua",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Joshua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joshua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071984468"
                        ],
                        "name": "Stern",
                        "slug": "Stern",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Stern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104398064"
                        ],
                        "name": "Ormond",
                        "slug": "Ormond",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Ormond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ormond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2102063967"
                        ],
                        "name": "Wilkie",
                        "slug": "Wilkie",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Wilkie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wilkie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 49
                            }
                        ],
                        "text": "We thank Charles Kemp for providing the Osherson/Wilkie class\u2013attribute matrix and Jens Weidmann for several weeks of labeling work."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 92
                            }
                        ],
                        "text": "The Animals with Attributes Dataset\nFor their studies on attribute-based object similarity, Osherson and Wilkie [24] collected judgements from human subjects on the \u201crelative strength of association\u201d between 85 attributes and 48 animal classes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "For their studies on attribute-based object similarity, Osherson and Wilkie [24] collected judgements from human subjects on the \u201crelative strength of association\u201d between 85 attributes and 48 animal classes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17525052,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "ea9d98a6ec470047500f3df3415eb569a75f9304",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A probability may be colled \u201cdefault\u201d if it is neither derived from preestablished probabilities nor bosed on considerations of frequency or symmetry. Default probabilities presumably arise through reasoning based on causality ond similarity. This article advances o model of default probobility based on o feoturol approach to similarity. The accuracy of the model is assessed by comparing its predictions to the probabilities provided by undergraduates asked to reason about mommols."
            },
            "slug": "Default-Probability-Daniel-N.",
            "title": {
                "fragments": [],
                "text": "Default Probability"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 211123177,
            "fieldsOfStudy": [],
            "id": "2d7bff421afdf1989558ddb9a32fd501c8bd072a",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to detect unseen object classes by between-class attribute transfer"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2312012"
                        ],
                        "name": "D. Osherson",
                        "slug": "D.-Osherson",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Osherson",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Osherson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 46194195,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science"
            ],
            "id": "c808ff5badfb8cd2a562b3bae936bf3673b58391",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Joshua-Stern,-Ormond-Wilkie,-Michael-Stob,-Edward-Osherson",
            "title": {
                "fragments": [],
                "text": "Joshua Stern, Ormond Wilkie, Michael Stob, Edward E. Smith: Default Probability"
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143673845"
                        ],
                        "name": "P. Slusallek",
                        "slug": "P.-Slusallek",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Slusallek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Slusallek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144033462"
                        ],
                        "name": "P. Shirley",
                        "slug": "P.-Shirley",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Shirley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shirley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913999"
                        ],
                        "name": "W. Mark",
                        "slug": "W.-Mark",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Mark",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Mark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34574034"
                        ],
                        "name": "G. Stoll",
                        "slug": "G.-Stoll",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Stoll",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stoll"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145357585"
                        ],
                        "name": "I. Wald",
                        "slug": "I.-Wald",
                        "structuredName": {
                            "firstName": "Ingo",
                            "lastName": "Wald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Wald"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36180426,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "cf7d7684600d3ebe916ca093eda123a9dad41459",
            "isKey": false,
            "numCitedBy": 3110,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Parallel-&-distributed-processing-Slusallek-Shirley",
            "title": {
                "fragments": [],
                "text": "Parallel & distributed processing"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH Courses"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "All attribute SVMs are based the same kernel, the sum of individual \u03c72-kernels for each feature, where the bandwidth parameters are fixed to the five times inverse of the median of the \u03c72-distances over the training samples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speeded-up robust features (SURF). CVIU"
            },
            "venue": {
                "fragments": [],
                "text": "Speeded-up robust features (SURF). CVIU"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "@BULLET animals with attributes: A dataset for Attribute Based Classification"
            },
            "venue": {
                "fragments": [],
                "text": "@BULLET animals with attributes: A dataset for Attribute Based Classification"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 31,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 45,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-detect-unseen-object-classes-by-Lampert-Nickisch/0566bf06a0368b518b8b474166f7b1dfef3f9283?sort=total-citations"
}