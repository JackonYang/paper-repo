{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1983127"
                        ],
                        "name": "C. Nastar",
                        "slug": "C.-Nastar",
                        "structuredName": {
                            "firstName": "Chahab",
                            "lastName": "Nastar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nastar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 247
                            }
                        ],
                        "text": "We have recently used a Bayesian/MAP technique for facial recognition, whereby an a posteriori similarity measure is computed using Bayes rule for the two classes corresponding to interapersonal facial variation and extrapersonal facial variation [22]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "More recently, in the September 1996 FERET face recognition competition, an improved Bayesian matching version of our system [22] achieved a 95 percent recognition rate with a database of approximately 1,200 individuals, the highest recognition rate obtained in the competition [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 914689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355fa6af4450c73041310d7545fadb486dcb6211",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a probabilistic similarity measure for direct image matching based on a Bayesian analysis of image deformations. We model two classes of variation in object appearance: intra-object and extra-object. The probability density functions for each class are then estimated from training data and used to compute a similarity measure based on the a posteriori probabilities. Furthermore, we use a novel representation for characterizing image differences using a deformable technique for obtaining pixel-wise correspondences. This representation, which is based on a deformable 3D mesh in XYI-space, is then experimentally compared with two simpler representations: intensity differences and optical flow. The performance advantage of our deformable matching technique is demonstrated using a typically hard test set drawn from the US Army's FERET face database."
            },
            "slug": "A-Bayesian-similarity-measure-for-direct-image-Moghaddam-Nastar",
            "title": {
                "fragments": [],
                "text": "A Bayesian similarity measure for direct image matching"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A probabilistic similarity measure for direct image matching based on a Bayesian analysis of image deformations is proposed and a novel representation for characterizing image differences using a deformable technique for obtaining pixel-wise correspondences is used."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "Another approach is to capture the complexity of these manifolds in a universal or parametric eigenspace using splines [20], or local basis functions [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 188
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [24][6], nonlinear image interpolation [3], visual learning for object recognition [20][34], as well as visual servoing for robotics [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 14
                            }
                        ],
                        "text": "Specifically, Murase and Nayar [23] used a lowdimensional parametric eigenspace for recovering object identity and pose by matching views to a spline-based hypersurface."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Nayar et al. [24] have extended this technique to visual feedback control and servoing for a robotic arm in \u201cpeg-in-thehole\u201d insertion tasks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Such an approach, for example, has recently been used by Murase and Nayar [20] for general 3D object recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Speci cally, Murase & Nayar [20] used a low-dimensional parametric eigenspace for recovering object identity and pose by matching views to a spline-based hypersurface."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 57
                            }
                        ],
                        "text": "Such an approach, for example, has recently been used by Murase and Nayar [23] for general 3D object recognition."
                    },
                    "intents": []
                }
            ],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": true,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 676887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6af749b2b813af20c2f26962249fafdccdc6a1e",
            "isKey": false,
            "numCitedBy": 477,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image, and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with another state-of-the-art face detection system are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Human-Face-Detection-in-Visual-Scenes-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Human Face Detection in Visual Scenes"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that uses a bootstrap algorithm for training, which adds false detections into the training set as training progresses, and has better performance in terms of detection and false-positive rates than other state-of-the-art face detection systems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2428034"
                        ],
                        "name": "C. Bregler",
                        "slug": "C.-Bregler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Bregler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bregler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808760"
                        ],
                        "name": "S. Omohundro",
                        "slug": "S.-Omohundro",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Omohundro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Omohundro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "Another approach is to capture the complexity of these manifolds in a universal or parametric eigenspace using splines [23], or local basis functions [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [27], [6], nonlinear image interpolation [3], visual learning for object recognition [23], [38], as well as visual servoing for robotics [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8783809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56efe7bf4bd52a6369d9ebbe55033e81e716f7d0",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Most connectionist research has focused on learning mappings from one space to another (eg. classification and regression). This paper introduces the more general task of learning constraint surfaces. It describes a simple but powerful architecture for learning and manipulating nonlinear surfaces from data. We demonstrate the technique on low dimensional synthetic surfaces and compare it to nearest neighbor approaches. We then show its utility in learning the space of lip images in a system for improving speech recognition by lip reading. This learned surface is used to improve the visual tracking performance during recognition."
            },
            "slug": "Surface-Learning-with-Applications-to-Lipreading-Bregler-Omohundro",
            "title": {
                "fragments": [],
                "text": "Surface Learning with Applications to Lipreading"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes a simple but powerful architecture for learning and manipulating nonlinear surfaces from data and shows its utility in learning the space of lip images in a system for improving speech recognition by lip reading."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738894"
                        ],
                        "name": "T. Starner",
                        "slug": "T.-Starner",
                        "structuredName": {
                            "firstName": "Thad",
                            "lastName": "Starner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Starner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "In computer vision, eigenvector analysis of imagery has been used for characterization of human faces [17] and automatic face recognition using \u201ceigenfaces\u201d [36], [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "For \u00b145\u00b0 testing views, the average recognition rates were 50 percent (see [27] for further details)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [27], we used this formulation for a modular eigenspace representation of facial features where the corresponding residual\u2014referred to as \u201cdistance-from-feature-space\u201d or DFFS\u2014was used for localization and detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "However, these authors (with the exception of [27]) have used eigenvector analysis primarily as a dimensionality reduction technique for subsequent modeling, interpolation, or classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "One way to tackle this multimodality is to build a view-based (or object-based) formulation where separate eigenspaces are used for each view [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[27] proposed a viewbased multiple-eigenspace technique for face recognition under varying pose as well as for the detection and description of facial features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "The eigentemplate approach to the detection of facial features in \u201cmugshots\u201d was proposed in [27], where the DFFS metric was shown to be superior to standard template matching for target detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [27], [6], nonlinear image interpolation [3], visual learning for object recognition [23], [38], as well as visual servoing for robotics [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "In a statistical signal detection framework, the use of eigentemplates has been shown to yield superior performance in comparison with standard matched filtering [18], [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 136280,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bf5d558220d39698ce96d59ee5772e8e1a0663",
            "isKey": false,
            "numCitedBy": 2234,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe experiments with eigenfaces for recognition and interactive search in a large-scale face database. Accurate visual recognition is demonstrated using a database of O(10/sup 3/) faces. The problem of recognition under general viewing orientation is also examined. A view-based multiple-observer eigenspace technique is proposed for use in face recognition under variable pose. In addition, a modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields higher recognition rates as well as a more robust framework for face recognition. An automatic feature extraction technique using feature eigentemplates is also demonstrated.<<ETX>>"
            },
            "slug": "View-based-and-modular-eigenspaces-for-face-Pentland-Moghaddam",
            "title": {
                "fragments": [],
                "text": "View-based and modular eigenspaces for face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A modular eigenspace description technique is used which incorporates salient features such as the eyes, nose and mouth, in an eigenfeature layer, which yields higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50577973"
                        ],
                        "name": "J. Vincent",
                        "slug": "J.-Vincent",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Vincent",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145208455"
                        ],
                        "name": "J. Waite",
                        "slug": "J.-Waite",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Waite",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Waite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46503163"
                        ],
                        "name": "D. Myers",
                        "slug": "D.-Myers",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Myers",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Myers"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61726920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b009a4c5eaeb55f3f7b1c74c3a1a0143ab2beed0",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A two-stage neural vision system for locating facial features is described. The first stage generates search regions in an image at low spatial resolution, and the second pinpoints the features at high resolution. Both stages employ multilayered perceptrons trained to detect specific visual details, followed by sophisticated global postprocessing of their outputs. This work demonstrates the power of combining neural feature detection with knowledge-based context-sensitive methods."
            },
            "slug": "Automatic-location-of-visual-features-by-a-system-Vincent-Waite",
            "title": {
                "fragments": [],
                "text": "Automatic location of visual features by a system of multilayered perceptrons"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work demonstrates the power of combining neural feature detection with knowledge-based context-sensitive methods in a two-stage neural vision system for locating facial features."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057290826"
                        ],
                        "name": "John",
                        "slug": "John",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "John",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145926447"
                        ],
                        "name": "J. Weng",
                        "slug": "J.-Weng",
                        "structuredName": {
                            "firstName": "Juyang",
                            "lastName": "Weng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 200
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [27], [6], nonlinear image interpolation [3], visual learning for object recognition [23], [38], as well as visual servoing for robotics [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16572884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3855ef92bfabff16b42171bebc64866ec3309e65",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Comprehensive visual learning is the treatment of theories and techniques for computer vision systems to automatically learn to understand comprehensive visual information with minimal human-imposed rules about the visual world. This article discusses some major performance diiculties encountered by currently prevailing approaches to computer vision and introduces the promising direction of comprehensive learning towards overcoming these diiculties. It also indicates why the direction may have a profound impact on the performance of computer vision algorithms for real world problems. Some example techniques for comprehensive visual learning are presented."
            },
            "slug": "On-Comprehensive-Visual-Learning-John-Weng",
            "title": {
                "fragments": [],
                "text": "On Comprehensive Visual Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Some major performance diiculties encountered by currently prevailing approaches to computer vision are discussed and the promising direction of comprehensive learning towards overcoming these diiccies are introduced."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472153"
                        ],
                        "name": "S. Messelodi",
                        "slug": "S.-Messelodi",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Messelodi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Messelodi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16051290,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b3788f66dc7c67036df4edef8b5ff3cad2c28d96",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Robust-estimation-of-correlation-with-applications-Brunelli-Messelodi",
            "title": {
                "fragments": [],
                "text": "Robust estimation of correlation with applications to computer vision"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037776"
                        ],
                        "name": "D. Reisfeld",
                        "slug": "D.-Reisfeld",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Reisfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Reisfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47620675"
                        ],
                        "name": "Y. Yeshurun",
                        "slug": "Y.-Yeshurun",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Yeshurun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeshurun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 203
                            }
                        ],
                        "text": "For example, saliency maps have been constructed which employ spatio-temporal changes as cues for foveation [1] or other low-level image features, such as local symmetry for detection of interest points [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 187
                            }
                        ],
                        "text": "Over the years, various strategies for facial feature detection have been proposed, ranging from edge map projections [15], to more recent techniques using generalized symmetry operators [32] and multilayer perceptrons [37]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 33599799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aecb450ee0b3ab1883bbb85ce92df7b274f851cb",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "An operator based on the intuitive motion of symmetry, which effectively locates interest points in real time and can be incorporated also in active visual systems, is introduced. The results of its operation agree with some psychophysical evidence concerning symmetry as well as evidence concerning fixation points. The operator can be applied successfully without prior knowledge of the world. Combining the operator with some preconceptions about the image is a powerful tool for feature detection in intricate natural scenes. The localization of faces and facial features in real time is demonstrated on detailed and noisy pictures.<<ETX>>"
            },
            "slug": "Detection-of-interest-points-using-symmetry-Reisfeld-Wolfson",
            "title": {
                "fragments": [],
                "text": "Detection of interest points using symmetry"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An operator based on the intuitive motion of symmetry, which effectively locates interest points in real time and can be incorporated also in active visual systems, is introduced and the results of its operation agree with some psychophysical evidence concerning symmetry as well as evidence concerning fixation points."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1851364"
                        ],
                        "name": "S. Nene",
                        "slug": "S.-Nene",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Nene",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nene"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62528140,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d707377651ec62c75d1031bd25a1839b4fecb813",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of vision-based robot positioning and tracking is addressed. A general learning algorithm is presented for determining the mapping between robot position and object appearance. The robot is first moved through several displacements with respect to its desired position, and a large set of object images is acquired. This image set is compressed using principal component analysis to obtain a low-dimensional subspace. Variations in object images due to robot displacements are represented as a compact parametrized manifold in the subspace. While positioning or tracking, errors in end-effector coordinates are efficiently computed from a single brightness image using the parametric manifold representation. The learning component enables accurate visual control without any prior hand-eye calibration. Several experiments have been conducted to demonstrate the practical feasibility of the proposed positioning/tracking approach and its relevance to industrial applications."
            },
            "slug": "General-learning-algorithm-for-robot-vision-Nayar-Murase",
            "title": {
                "fragments": [],
                "text": "General learning algorithm for robot vision"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A general learning algorithm is presented for determining the mapping between robot position and object appearance, and the learning component enables accurate visual control without any prior hand-eye calibration."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "One can view this architecture as a set of parallel \u201cobservers,\u201d each trying to explain the image data with their set of eigenvectors (see also Darrell and Pentland [10])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "Pentland et al. [27] proposed a viewbased multiple-eigenspace technique for face recognition under varying pose as well as for the detection and description of facial features."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5344867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1807058512ae2934b2be0b43f395d8583ef67303",
            "isKey": false,
            "numCitedBy": 442,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented. Objects are represented using sets of view models, rather than single templates. Stereotypical space-time patterns, i.e., gestures, are then matched to stored gesture patterns using dynamic time warping. Real-time performance is achieved by using special purpose correlation hardware and view prediction to prune as much of the search space as possible. Both view models and view predictions are learned from examples. Results showing tracking and recognition of human hand gestures at over 10 Hz are presented.<<ETX>>"
            },
            "slug": "Space-time-gestures-Darrell-Pentland",
            "title": {
                "fragments": [],
                "text": "Space-time gestures"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A method for learning, tracking, and recognizing human gestures using a view-based approach to model articulated objects is presented and results showing tracking and recognition of human hand gestures at over 10 Hz are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "The recognition accuracy (defined as the percent correct rank-one matches) on a database of 155 individuals is 99 percent [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2841459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bcdca49ed64ec6b15d975adaea49508e9e941d2",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe experiments using eigenfaces for recognition and interactive search in the FERET face database. A recognition accuracy of 99.35% is obtained using frontal views of 155 individuals. This figure is consistent with the 95% recognition rate obtained previously on a much larger database of 7,562 `mugshots' of approximately 3,000 individuals, consisting of a mix of all age and ethnic groups. We also demonstrate that we can automatically determine head pose without significantly lowering recognition accuracy; this is accomplished by use of a view-based multiple-observer eigenspace technique. In addition, a modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer. This modular representation yields slightly higher recognition rates as well as a more robust framework for face recognition. In addition, a robust and automatic feature detection technique using eigentemplates is demonstrated."
            },
            "slug": "Face-recognition-using-view-based-and-modular-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Face recognition using view-based and modular eigenspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A modular eigenspace description is used which incorporates salient facial features such as the eyes, nose and mouth, in an eigenfeature layer, which yields slightly higher recognition rates as well as a more robust framework for face recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097660"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "The reconstruction error (or residual) of the eigenspace decomposition (referred to as the \u201cdistance-from-face-space\u201d in the context of the work with \u201ceigenfaces\u201d [36]) is an effective indicator of similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "In computer vision, eigenvector analysis of imagery has been used for characterization of human faces [17] and automatic face recognition using \u201ceigenfaces\u201d [36], [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26127529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6f1dfcc44277d4cfd8507284d994c9283dc3a2f",
            "isKey": false,
            "numCitedBy": 14954,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal components) of the set of faces; they do not necessarily correspond to features such as eyes, ears, and noses. The projection operation characterizes an individual face by a weighted sum of the eigenface features, and so to recognize a particular face it is necessary only to compare these weights to those of known individuals. Some particular advantages of our approach are that it provides for the ability to learn and later recognize new faces in an unsupervised manner, and that it is easy to implement using a neural network architecture."
            },
            "slug": "Eigenfaces-for-Recognition-Turk-Pentland",
            "title": {
                "fragments": [],
                "text": "Eigenfaces for Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals, and that is easy to implement using a neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1269370,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61a3ec03aff72b00ef17fbcf8577cbacd629a7f6",
            "isKey": false,
            "numCitedBy": 549,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Modal matching is a new method for establishing correspondences and computing canonical descriptions. The method is based on the idea of describing objects in terms of generalized symmetries, as defined by each object's eigenmodes. The resulting modal description is used for object recognition and categorization, where shape similarities are expressed as the amounts of modal deformation energy needed to align the two objects. In general, modes provide a global-to-local ordering of shape deformation and thus allow for selecting which types of deformations are used in object alignment and comparison. In contrast to previous techniques, which required correspondence to be computed with an initial or prototype shape, modal matching utilizes a new type of finite element formulation that allows for an object's eigenmodes to be computed directly from available image information. This improved formulation provides greater generality and accuracy, and is applicable to data of any dimensionality. Correspondence results with 2D contour and point feature data are shown, and recognition experiments with 2D images of hand tools and airplanes are described. >"
            },
            "slug": "Modal-Matching-for-Correspondence-and-Recognition-Sclaroff-Pentland",
            "title": {
                "fragments": [],
                "text": "Modal Matching for Correspondence and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Improved formulation of modal matching utilizes a new type of finite element formulation that allows for an object's eigenmodes to be computed directly from available image information, and is applicable to data of any dimensionality."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1893129"
                        ],
                        "name": "M. Bichsel",
                        "slug": "M.-Bichsel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Bichsel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bichsel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Multiple views of a face form nonconvex (yet connected) regions in image space [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62911157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b23f4919527264148762d476c58a7b21a21808dd",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract If we consider an n \u00d7 n image as an n2-dimensional vector, then images of faces can be considered as points in this n2-dimensional image space. Our previous studies of physical transformations of the face, including translation, small rotations, and illumination changes, showed that the set of face images consists of relatively simple connected subregions in image space. Consequently linear matching techniques can be used to obtain reliable face recognition. However, for more general transformations, such as large rotations or scale changes, the face subregions become highly non-convex. We have therefore developed a scale-space matching technique that allows us to take advantage of knowledge about important geometrical transformations and about the topology of the face subregion in image space. While recognition of faces is the focus of this paper, the algorithm is sufficiently general to be applicable to a large variety of object recognition tasks"
            },
            "slug": "Human-Face-Recognition-and-the-Face-Image-Set's-Bichsel-Pentland",
            "title": {
                "fragments": [],
                "text": "Human Face Recognition and the Face Image Set's Topology"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A scale-space matching technique that allows it to take advantage of knowledge about important geometrical transformations and about the topology of the face subregion in image space to be applicable to a large variety of object recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145955657"
                        ],
                        "name": "E. Persoon",
                        "slug": "E.-Persoon",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Persoon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Persoon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97306284"
                        ],
                        "name": "K. Fu",
                        "slug": "K.-Fu",
                        "structuredName": {
                            "firstName": "King-Sun",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": ", moments [12], Fourier descriptors [26], \\snakes\" [15], Point Distribution Models [7], and modal descriptions [30])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7148651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd3986ad19bcd24824a579486b4e550ad69faaa5",
            "isKey": false,
            "numCitedBy": 912,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Description or discrimination of boundary curves (shapes) is an important problem in picture processing and pattern recognition Fourier descriptors (FD's) have interesting properties in this respect. First, a critical review is given of two kinds of FD's. Some properties of the FD's are given and a distance measure is proposed, in terms of FD's, that measures the difference between two boundarv curves. It is shown how FD's can be used for obtaining skeletons fobjects. Finally, experimental results are given in character recognition and machine parts recognition."
            },
            "slug": "Shape-Discrimination-Using-Fourier-Descriptors-Persoon-Fu",
            "title": {
                "fragments": [],
                "text": "Shape Discrimination Using Fourier Descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A critical review is given of two kinds of Fourier descriptors and a distance measure is proposed, in terms of FD's, that measures the difference between two boundarv curves."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar effect was reported by Brunelli and Poggio [ 4 ], where the cumulative normalized correlation scores of templates for the face, eyes, nose, and mouth showed improved performance over the face-only templates."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120127765"
                        ],
                        "name": "B. V. Kumar",
                        "slug": "B.-V.-Kumar",
                        "structuredName": {
                            "firstName": "Bhagavatula",
                            "lastName": "Kumar",
                            "middleNames": [
                                "V.",
                                "K.",
                                "Vijaya"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. V. Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34925745"
                        ],
                        "name": "D. Casasent",
                        "slug": "D.-Casasent",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Casasent",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Casasent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153811123"
                        ],
                        "name": "H. Murakami",
                        "slug": "H.-Murakami",
                        "structuredName": {
                            "firstName": "Hitotoshi",
                            "lastName": "Murakami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murakami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "In a statistical signal detection framework, the use of eigentemplates has been shown to yield superior performance in comparison with standard matched ltering [17][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62246877,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "b36e4e3f910e5422171359bc492efc8ad43a74ac",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Concepts, measures, and models of image quality are shown to be quite important in pattern recognition applications. Pattern recognition of imagery subjected to geometrical differences (such as scale and rotational changes) and intensity differences (such as arise in multispectral imagery) are considered. After modeling these image differences as a stochastic process, the optimal filter is derived. This filter is shown to be the principal component of the data. This pattern recognition algorithm is verified using multi-sensor imagery, and the results are found to compare favorably to those obtained using other candidate techniques."
            },
            "slug": "Principal-Component-Imagery-For-Statistical-Pattern-Kumar-Casasent",
            "title": {
                "fragments": [],
                "text": "Principal-Component Imagery For Statistical Pattern Recognition Correlators"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This pattern recognition algorithm is verified using multi-sensor imagery, and the results are found to compare favorably to those obtained using other candidate techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804489"
                        ],
                        "name": "F. Girosi",
                        "slug": "F.-Girosi",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Girosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Girosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "We note that this learning method differs from supervised visual learning with function approximation networks [30] in which a hypersurface representation of an input/output map is automatically learned from a set of training examples."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14892653,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "089a76dbc62a06ad30ae1925530e8733e850268e",
            "isKey": false,
            "numCitedBy": 3702,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of the approximation of nonlinear mapping, (especially continuous mappings) is considered. Regularization theory and a theoretical framework for approximation (based on regularization techniques) that leads to a class of three-layer networks called regularization networks are discussed. Regularization networks are mathematically related to the radial basis functions, mainly used for strict interpolation tasks. Learning as approximation and learning as hypersurface reconstruction are discussed. Two extensions of the regularization approach are presented, along with the approach's corrections to splines, regularization, Bayes formulation, and clustering. The theory of regularization networks is generalized to a formulation that includes task-dependent clustering and dimensionality reduction. Applications of regularization networks are discussed. >"
            },
            "slug": "Networks-for-approximation-and-learning-Poggio-Girosi",
            "title": {
                "fragments": [],
                "text": "Networks for approximation and learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97129855"
                        ],
                        "name": "M. Hu",
                        "slug": "M.-Hu",
                        "structuredName": {
                            "firstName": "Ming-Kuei",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": ", moments [13], Fourier descriptors [20], \u201csnakes\u201d [16], Point Distribution Models [7], and modal descriptions [34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6431165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce1e3528047cd01937f6a8aa760640f6b3c8d531",
            "isKey": false,
            "numCitedBy": 8010,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a theory of two-dimensional moment invariants for planar geometric figures is presented. A fundamental theorem is established to relate such moment invariants to the well-known algebraic invariants. Complete systems of moment invariants under translation, similitude and orthogonal transformations are derived. Some moment invariants under general two-dimensional linear transformations are also included. Both theoretical formulation and practical models of visual pattern recognition based upon these moment invariants are discussed. A simple simulation program together with its performance are also presented. It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished. It is also indicated that generalization is possible to include invariance with parallel projection."
            },
            "slug": "Visual-pattern-recognition-by-moment-invariants-Hu",
            "title": {
                "fragments": [],
                "text": "Visual pattern recognition by moment invariants"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that recognition of geometrical patterns and alphabetical characters independently of position, size and orientation can be accomplished and it is indicated that generalization is possible to include invariance with parallel projection."
            },
            "venue": {
                "fragments": [],
                "text": "IRE Trans. Inf. Theory"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719389"
                        ],
                        "name": "Rosalind W. Picard",
                        "slug": "Rosalind-W.-Picard",
                        "structuredName": {
                            "firstName": "Rosalind",
                            "lastName": "Picard",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rosalind W. Picard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 77
                            }
                        ],
                        "text": "11 shows the results of a similarity search in an image database tool called Photobook [28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "Photobook: FERET face database.\nments tested the extrapolation performance by training on a range of views (e.g., -90\u00b0 to +45\u00b0) and testing on novel views outside the training range (e.g., +68\u00b0 and +90\u00b0)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Using ML detection for Recognition Figure 11 shows the results of a similarity search in an image database tool called Photobook [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 64046874,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c051cc68b398327aa6e54b8aadf20a01da27469",
            "isKey": false,
            "numCitedBy": 433,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually significant coefficients. We describe three Photobook tools in particular: one that allows search based on gray-level appearance, one that uses 2-D shape, and a third that allows search based on textural properties."
            },
            "slug": "Photobook:-tools-for-content-based-manipulation-of-Pentland-Picard",
            "title": {
                "fragments": [],
                "text": "Photobook: tools for content-based manipulation of image databases"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "The Photobook system is described, which is a set of interactive tools for browsing and searching images and image sequences that differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32588087"
                        ],
                        "name": "R. Redner",
                        "slug": "R.-Redner",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Redner",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Redner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145221576"
                        ],
                        "name": "H. Walker",
                        "slug": "H.-Walker",
                        "structuredName": {
                            "firstName": "Homer",
                            "lastName": "Walker",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Further details of the EM algorithm for estimation of mixture densities can be found in [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2611600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54323bf565cea5d2aaee88a03ec9d1d3444a9bfd",
            "isKey": false,
            "numCitedBy": 2829,
            "numCiting": 158,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of estimating the parameters which determine a mixture density has been the subject of a large, diverse body of literature spanning nearly ninety years. During the last two decades, the method of maximum likelihood has become the most widely followed approach to this problem, thanks primarily to the advent of high speed electronic computers. Here, we first offer a brief survey of the literature directed toward this problem and review maximum-likelihood estimation for it. We then turn to the subject of ultimate interest, which is a particular iterative procedure for numerically approximating maximum-likelihood estimates for mixture density problems. This procedure, known as the EM algorithm, is a specialization to the mixture density context of a general algorithm of the same name used to approximate maximum-likelihood estimates for incomplete data problems. We discuss the formulation and theoretical and practical properties of the EM algorithm for mixture densities, focussing in particular on ..."
            },
            "slug": "Mixture-densities,-maximum-likelihood,-and-the-EM-Redner-Walker",
            "title": {
                "fragments": [],
                "text": "Mixture densities, maximum likelihood, and the EM algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work discusses the formulation and theoretical and practical properties of the EM algorithm, a specialization to the mixture density context of a general algorithm used to approximate maximum-likelihood estimates for incomplete data problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053520352"
                        ],
                        "name": "M. Kirby",
                        "slug": "M.-Kirby",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kirby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kirby"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49555086"
                        ],
                        "name": "L. Sirovich",
                        "slug": "L.-Sirovich",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Sirovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sirovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "In computer vision, eigenvector analysis of imagery has been used for characterization of human faces [17] and automatic face recognition using \u201ceigenfaces\u201d [36], [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 570648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d75a5fe9e1b6511c5135d68e9ce8c0da5a7374",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion. This results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix, without increasing the complexity of the calculation. The resulting approximation of faces projected from outside of the data set onto this optimal basis is improved on average. >"
            },
            "slug": "Application-of-the-Karhunen-Loeve-Procedure-for-the-Kirby-Sirovich",
            "title": {
                "fragments": [],
                "text": "Application of the Karhunen-Loeve Procedure for the Characterization of Human Faces"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The use of natural symmetries (mirror images) in a well-defined family of patterns (human faces) is discussed within the framework of the Karhunen-Loeve expansion, which results in an extension of the data and imposes even and odd symmetry on the eigenfunctions of the covariance matrix."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107784547"
                        ],
                        "name": "C. H. Anderson",
                        "slug": "C.-H.-Anderson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Anderson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. H. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134039691"
                        ],
                        "name": "G. S. van der Wal",
                        "slug": "G.-S.-van-der-Wal",
                        "structuredName": {
                            "firstName": "Gooitzen",
                            "lastName": "van der Wal",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. van der Wal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "For example, saliency maps have been constructed which employ spatio-temporal changes as cues for foveation [1] or other low-level image features, such as local symmetry for detection of interest points [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62139375,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a72b3b869ac537ee893e86365dc45021eef00da0",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "An automated, or \"smart\", surveillance system must be sensitive to small object motion wherever it may occur within a large field of view. The system must also be capable of distinguishing changes of interest from other image activity or noise. Yet the data processing capabilities of practical systems is often quite limited. To achieve these performance objectives at a low data rate, a pyramid based image preprocessor has been constructed that can compute frequency tuned \"change energy\" measures in real time. A microprocessor then examines a relatively small set of these measures and follows a foveal search strategy to isolate moving objects for tracking or for more detailed analysis."
            },
            "slug": "Change-Detection-and-Tracking-Using-Pyramid-Anderson-Burt",
            "title": {
                "fragments": [],
                "text": "Change Detection and Tracking Using Pyramid Transform Techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A pyramid based image preprocessor has been constructed that can compute frequency tuned \"change energy\" measures in real time and follows a foveal search strategy to isolate moving objects for tracking or for more detailed analysis."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 235
                            }
                        ],
                        "text": "The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling [26], correspondence and matching [34], and parametric descriptions of shape [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 220
                            }
                        ],
                        "text": "We note that this spatiotopic representation of shape is biologically motivated and therefore differs from methods based purely on computational considerations (e.g., moments [13], Fourier descriptors [20], \u201csnakes\u201d [16], Point Distribution Models [7], and modal descriptions [34])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": ", moments [13], Fourier descriptors [20], \u201csnakes\u201d [16], Point Distribution Models [7], and modal descriptions [34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11058546,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4d79f7ebf833c549dd1429fd9440628d6c0824c3",
            "isKey": false,
            "numCitedBy": 346,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe 'Active Shape Models' which iteratively adapt to refine estimates of the pose, scale and shape of models of image objects. The method uses flexible models derived from sets of training examples. These models, known as Point Distribution Models, represent objects as sets of labelled points. An initial estimate of the location of the model points in an image is improved by attempting to move each point to a better position nearby. Adjustments to the pose variables and shape parameters are calculated. Limits are placed on the shape parameters ensuring that the example can only deform into shapes conforming to global constraints imposed by the training set. An iterative procedure deforms the model example to find the best fit to the image object. Results of applying the method are described. The technique is shown to be a powerful method for refining estimates of object shape and location."
            },
            "slug": "Active-Shape-Models-'smart-snakes'-Cootes-Taylor",
            "title": {
                "fragments": [],
                "text": "Active Shape Models - 'smart snakes'"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "'Active Shape Models' are described which iteratively adapt to refine estimates of the pose, scale and shape of models of image objects to be a powerful method for refining estimates of object shape and location."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48195968"
                        ],
                        "name": "A. Hill",
                        "slug": "A.-Hill",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Hill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47428527"
                        ],
                        "name": "J. Haslam",
                        "slug": "J.-Haslam",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Haslam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Haslam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4. Cootes et al. [ 8 ] have used a similar decomposition of the Mahalanobis"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 27928391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18af4688f2b9df80e648e4a96a4f75261c7cc019",
            "isKey": false,
            "numCitedBy": 824,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Use-of-active-shape-models-for-locating-structures-Cootes-Hill",
            "title": {
                "fragments": [],
                "text": "Use of active shape models for locating structures in medical images"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2359839"
                        ],
                        "name": "S. Palmer",
                        "slug": "S.-Palmer",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Palmer",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Palmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Palmer [22] has suggested that visual attention is the process of locating the object of interest and placing it in a canonical (or object-centered) reference frame suitable for recognition (or template matching)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118772290,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c95b58f49f3818139551a34f6e1e0d456fc6588e",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Psychology-of-Perceptual-Organization:-A-Palmer",
            "title": {
                "fragments": [],
                "text": "The Psychology of Perceptual Organization: A Transformational Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749590"
                        ],
                        "name": "S. Sclaroff",
                        "slug": "S.-Sclaroff",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Sclaroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sclaroff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling [ 26 ], correspondence and matching [34], and parametric descriptions of shape [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11671063,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "17005621642fe449a8999bc3f2e896bce8521607",
            "isKey": false,
            "numCitedBy": 251,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a closed-form, physically based solution for recovering a three-dimensional (3-D) solid model from collections of 3-D surface measurements. Given a sufficient number of independent measurements, the solution is overconstrained and unique except for rotational symmetries. The proposed approach is based on the finite element method (FEM) and parametric solid modeling using implicit functions. This approach provides both the convenience of parametric modeling and the expressiveness of the physically based mesh formulation and, in addition, can provide great accuracy at physical simulation. A physically based object-recognition method that allows simple, closed-form comparisons of recovered 3-D solid models is presented. The performance of these methods is evaluated using both synthetic range data with various signal-to-noise ratios and using laser rangefinder data. >"
            },
            "slug": "Closed-Form-Solutions-for-Physically-Based-Shape-Pentland-Sclaroff",
            "title": {
                "fragments": [],
                "text": "Closed-Form Solutions for Physically Based Shape Modeling and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The authors present a closed-form, physically based solution for recovering a three-dimensional (3-D) solid model from collections of 3-D surface measurements that is overconstrained and unique except for rotational symmetries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2172136929"
                        ],
                        "name": "Terry McElroy",
                        "slug": "Terry-McElroy",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "McElroy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terry McElroy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114353248"
                        ],
                        "name": "E. Wilson",
                        "slug": "E.-Wilson",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Wilson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2673070"
                        ],
                        "name": "G. Anspach",
                        "slug": "G.-Anspach",
                        "structuredName": {
                            "firstName": "Gretel",
                            "lastName": "Anspach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Anspach"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35173265,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d71729882b0a3c3014677f4ce625d0ef03f240c",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a pressing need for sign language to English translation capability to supplement the shortage of sign language interpreters and to provide an aid for training. A modular hybrid design is underway to apply various techniques, including neural networks, in the development of a translation system that can facilitate communication between deaf and hearing people as part of an overall system to automatically translate American sign language to spoken English. The key features to be analyzed are hand motion, hand location with respect to the body, and handshape. A neural network is used to recognize and classify alphanumeric handshapes using Fourier descriptor coefficients as an input vector. The algorithm is described and results shown for applying this technique to experimental images."
            },
            "slug": "Fourier-descriptors-and-neural-networks-far-shape-McElroy-Wilson",
            "title": {
                "fragments": [],
                "text": "Fourier descriptors and neural networks far shape classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A neural network is used to recognize and classify alphanumeric handshapes using Fourier descriptor coefficients as an input vector and results shown for applying this technique to experimental images are described."
            },
            "venue": {
                "fragments": [],
                "text": "1995 International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695784"
                        ],
                        "name": "U. Fayyad",
                        "slug": "U.-Fayyad",
                        "structuredName": {
                            "firstName": "Usama",
                            "lastName": "Fayyad",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Fayyad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, Burl et al. [ 6 ] used Bayesian classification for object detection using a feature vector derived from principal component images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [27], [ 6 ], nonlinear image interpolation [3], visual learning for object recognition [23], [38], as well as visual servoing for robotics [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5647595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7aeb1fd1d15173b3b0ce389993494e5d7d95960d",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Our long-term goal is to develop a trainable tool for locating patterns of interest in large image databases. Toward this goal we have developed a prototype system, based on classical filtering and statistical pattern recognition techniques, for automatically locating volcanoes in the Magellan SAR database of Venus. Training for the specific volcano-detection task is obtained by synthesizing feature templates (via normalization and principal components analysis) from a small number of examples provided by experts. Candidate regions identified by a focus of attention (FOA) algorithm are classified based on correlations with the feature templates. Preliminary tests show performance comparable to trained human observers.<<ETX>>"
            },
            "slug": "Automating-the-hunt-for-volcanoes-on-Venus-Burl-Fayyad",
            "title": {
                "fragments": [],
                "text": "Automating the hunt for volcanoes on Venus"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A prototype system, based on classical filtering and statistical pattern recognition techniques, for automatically locating volcanoes in the Magellan SAR database of Venus, and preliminary tests show performance comparable to trained human observers."
            },
            "venue": {
                "fragments": [],
                "text": "1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691986"
                        ],
                        "name": "P. Phillips",
                        "slug": "P.-Phillips",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Phillips",
                            "middleNames": [
                                "Jonathon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40638847"
                        ],
                        "name": "Hyeonjoon Moon",
                        "slug": "Hyeonjoon-Moon",
                        "structuredName": {
                            "firstName": "Hyeonjoon",
                            "lastName": "Moon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyeonjoon Moon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313513"
                        ],
                        "name": "Patrick J. Rauss",
                        "slug": "Patrick-J.-Rauss",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Rauss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick J. Rauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958806"
                        ],
                        "name": "S. A. Rizvi",
                        "slug": "S.-A.-Rizvi",
                        "structuredName": {
                            "firstName": "Syed",
                            "lastName": "Rizvi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. A. Rizvi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "This new probabilistic similarity measure was used in the September 1996 FERET competition, and was found to be the top-performing system, by a typical margin of 10 percent to the next-best competitor [29]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 278
                            }
                        ],
                        "text": "More recently, in the September 1996 FERET face recognition competition, an improved Bayesian matching version of our system [22] achieved a 95 percent recognition rate with a database of approximately 1,200 individuals, the highest recognition rate obtained in the competition [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5129656,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f04a95ec885cf98e7cee43eacff13de0c888d3b",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. In this paper, we report on the FERET database and the September 1996 FERET test. This test is the third in a series of supervised face-recognition test administered under the FERET program."
            },
            "slug": "The-FERET-September-1996-Database-and-Evaluation-Phillips-Moon",
            "title": {
                "fragments": [],
                "text": "The FERET September 1996 Database and Evaluation Procedure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The FERET database and the September 1996 FerET test are reported on, which is the third in a series of supervised face-recognition test administered under the FERGET program."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100942540"
                        ],
                        "name": "M. Lo\u00e8ve",
                        "slug": "M.-Lo\u00e8ve",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Lo\u00e8ve",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lo\u00e8ve"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123533290,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f18307ebabf398bb7fd1b3375b2f09a7f9f6c5be",
            "isKey": false,
            "numCitedBy": 6130,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "These notes cover the basic definitions of discrete probability theory, and then present some results including Bayes' rule, inclusion-exclusion formula, Chebyshev's inequality, and the weak law of large numbers. 1 Sample spaces and events To treat probability rigorously, we define a sample space S whose elements are the possible outcomes of some process or experiment. For example, the sample space might be the outcomes of the roll of a die, or flips of a coin. To each element x of the sample space, we assign a probability, which will be a non-negative number between 0 and 1, which we will denote by p(x). We require that x\u2208S p(x) = 1, so the total probability of the elements of our sample space is 1. What this means intuitively is that when we perform our process, exactly one of the things in our sample space will happen. Example. The sample space could be S = {a, b, c}, and the probabilities could be p(a) = 1/2, p(b) = 1/3, p(c) = 1/6. If all elements of our sample space have equal probabilities, we call this the uniform probability distribution on our sample space. For example, if our sample space was the outcomes of a die roll, the sample space could be denoted S = {x 1 , x 2 ,. .. , x 6 }, where the event x i correspond to rolling i. The uniform distribution, in which every outcome x i has probability 1/6 describes the situation for a fair die. Similarly, if we consider tossing a fair coin, the outcomes would be H (heads) and T (tails), each with probability 1/2. In this situation we have the uniform probability distribution on the sample space S = {H, T }. We define an event A to be a subset of the sample space. For example, in the roll of a die, if the event A was rolling an even number, then A = {x 2 , x 4 , x 6 }. The probability of an event A, denoted by P(A), is the sum of the probabilities of the corresponding elements in the sample space. For rolling an even number, we have P(A) = p(x 2) + p(x 4) + p(x 6) = 1 2 Given an event A of our sample space, there is a complementary event which consists of all points in our sample space that are not \u2026"
            },
            "slug": "Probability-Theory-I-Lo\u00e8ve",
            "title": {
                "fragments": [],
                "text": "Probability Theory I"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "These notes cover the basic definitions of discrete probability theory, and then present some results including Bayes' rule, inclusion-exclusion formula, Chebyshev's inequality, and the weak law of large numbers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "entropy [9] between the true density P(x|W) and its estimate $ P x W d i"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 190432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dbdb4209626fd92d2436a058663206216036e68",
            "isKey": false,
            "numCitedBy": 42792,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface to the Second Edition. Preface to the First Edition. Acknowledgments for the Second Edition. Acknowledgments for the First Edition. 1. Introduction and Preview. 1.1 Preview of the Book. 2. Entropy, Relative Entropy, and Mutual Information. 2.1 Entropy. 2.2 Joint Entropy and Conditional Entropy. 2.3 Relative Entropy and Mutual Information. 2.4 Relationship Between Entropy and Mutual Information. 2.5 Chain Rules for Entropy, Relative Entropy, and Mutual Information. 2.6 Jensen's Inequality and Its Consequences. 2.7 Log Sum Inequality and Its Applications. 2.8 Data-Processing Inequality. 2.9 Sufficient Statistics. 2.10 Fano's Inequality. Summary. Problems. Historical Notes. 3. Asymptotic Equipartition Property. 3.1 Asymptotic Equipartition Property Theorem. 3.2 Consequences of the AEP: Data Compression. 3.3 High-Probability Sets and the Typical Set. Summary. Problems. Historical Notes. 4. Entropy Rates of a Stochastic Process. 4.1 Markov Chains. 4.2 Entropy Rate. 4.3 Example: Entropy Rate of a Random Walk on a Weighted Graph. 4.4 Second Law of Thermodynamics. 4.5 Functions of Markov Chains. Summary. Problems. Historical Notes. 5. Data Compression. 5.1 Examples of Codes. 5.2 Kraft Inequality. 5.3 Optimal Codes. 5.4 Bounds on the Optimal Code Length. 5.5 Kraft Inequality for Uniquely Decodable Codes. 5.6 Huffman Codes. 5.7 Some Comments on Huffman Codes. 5.8 Optimality of Huffman Codes. 5.9 Shannon-Fano-Elias Coding. 5.10 Competitive Optimality of the Shannon Code. 5.11 Generation of Discrete Distributions from Fair Coins. Summary. Problems. Historical Notes. 6. Gambling and Data Compression. 6.1 The Horse Race. 6.2 Gambling and Side Information. 6.3 Dependent Horse Races and Entropy Rate. 6.4 The Entropy of English. 6.5 Data Compression and Gambling. 6.6 Gambling Estimate of the Entropy of English. Summary. Problems. Historical Notes. 7. Channel Capacity. 7.1 Examples of Channel Capacity. 7.2 Symmetric Channels. 7.3 Properties of Channel Capacity. 7.4 Preview of the Channel Coding Theorem. 7.5 Definitions. 7.6 Jointly Typical Sequences. 7.7 Channel Coding Theorem. 7.8 Zero-Error Codes. 7.9 Fano's Inequality and the Converse to the Coding Theorem. 7.10 Equality in the Converse to the Channel Coding Theorem. 7.11 Hamming Codes. 7.12 Feedback Capacity. 7.13 Source-Channel Separation Theorem. Summary. Problems. Historical Notes. 8. Differential Entropy. 8.1 Definitions. 8.2 AEP for Continuous Random Variables. 8.3 Relation of Differential Entropy to Discrete Entropy. 8.4 Joint and Conditional Differential Entropy. 8.5 Relative Entropy and Mutual Information. 8.6 Properties of Differential Entropy, Relative Entropy, and Mutual Information. Summary. Problems. Historical Notes. 9. Gaussian Channel. 9.1 Gaussian Channel: Definitions. 9.2 Converse to the Coding Theorem for Gaussian Channels. 9.3 Bandlimited Channels. 9.4 Parallel Gaussian Channels. 9.5 Channels with Colored Gaussian Noise. 9.6 Gaussian Channels with Feedback. Summary. Problems. Historical Notes. 10. Rate Distortion Theory. 10.1 Quantization. 10.2 Definitions. 10.3 Calculation of the Rate Distortion Function. 10.4 Converse to the Rate Distortion Theorem. 10.5 Achievability of the Rate Distortion Function. 10.6 Strongly Typical Sequences and Rate Distortion. 10.7 Characterization of the Rate Distortion Function. 10.8 Computation of Channel Capacity and the Rate Distortion Function. Summary. Problems. Historical Notes. 11. Information Theory and Statistics. 11.1 Method of Types. 11.2 Law of Large Numbers. 11.3 Universal Source Coding. 11.4 Large Deviation Theory. 11.5 Examples of Sanov's Theorem. 11.6 Conditional Limit Theorem. 11.7 Hypothesis Testing. 11.8 Chernoff-Stein Lemma. 11.9 Chernoff Information. 11.10 Fisher Information and the Cram-er-Rao Inequality. Summary. Problems. Historical Notes. 12. Maximum Entropy. 12.1 Maximum Entropy Distributions. 12.2 Examples. 12.3 Anomalous Maximum Entropy Problem. 12.4 Spectrum Estimation. 12.5 Entropy Rates of a Gaussian Process. 12.6 Burg's Maximum Entropy Theorem. Summary. Problems. Historical Notes. 13. Universal Source Coding. 13.1 Universal Codes and Channel Capacity. 13.2 Universal Coding for Binary Sequences. 13.3 Arithmetic Coding. 13.4 Lempel-Ziv Coding. 13.5 Optimality of Lempel-Ziv Algorithms. Compression. Summary. Problems. Historical Notes. 14. Kolmogorov Complexity. 14.1 Models of Computation. 14.2 Kolmogorov Complexity: Definitions and Examples. 14.3 Kolmogorov Complexity and Entropy. 14.4 Kolmogorov Complexity of Integers. 14.5 Algorithmically Random and Incompressible Sequences. 14.6 Universal Probability. 14.7 Kolmogorov complexity. 14.9 Universal Gambling. 14.10 Occam's Razor. 14.11 Kolmogorov Complexity and Universal Probability. 14.12 Kolmogorov Sufficient Statistic. 14.13 Minimum Description Length Principle. Summary. Problems. Historical Notes. 15. Network Information Theory. 15.1 Gaussian Multiple-User Channels. 15.2 Jointly Typical Sequences. 15.3 Multiple-Access Channel. 15.4 Encoding of Correlated Sources. 15.5 Duality Between Slepian-Wolf Encoding and Multiple-Access Channels. 15.6 Broadcast Channel. 15.7 Relay Channel. 15.8 Source Coding with Side Information. 15.9 Rate Distortion with Side Information. 15.10 General Multiterminal Networks. Summary. Problems. Historical Notes. 16. Information Theory and Portfolio Theory. 16.1 The Stock Market: Some Definitions. 16.2 Kuhn-Tucker Characterization of the Log-Optimal Portfolio. 16.3 Asymptotic Optimality of the Log-Optimal Portfolio. 16.4 Side Information and the Growth Rate. 16.5 Investment in Stationary Markets. 16.6 Competitive Optimality of the Log-Optimal Portfolio. 16.7 Universal Portfolios. 16.8 Shannon-McMillan-Breiman Theorem (General AEP). Summary. Problems. Historical Notes. 17. Inequalities in Information Theory. 17.1 Basic Inequalities of Information Theory. 17.2 Differential Entropy. 17.3 Bounds on Entropy and Relative Entropy. 17.4 Inequalities for Types. 17.5 Combinatorial Bounds on Entropy. 17.6 Entropy Rates of Subsets. 17.7 Entropy and Fisher Information. 17.8 Entropy Power Inequality and Brunn-Minkowski Inequality. 17.9 Inequalities for Determinants. 17.10 Inequalities for Ratios of Determinants. Summary. Problems. Historical Notes. Bibliography. List of Symbols. Index."
            },
            "slug": "Elements-of-Information-Theory-Cover-Thomas",
            "title": {
                "fragments": [],
                "text": "Elements of Information Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author examines the role of entropy, inequality, and randomness in the design of codes and the construction of codes in the rapidly changing environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "This estimation problem is best solved using the Expectation-Maximization (EM) algorithm [11], which consists of the following two-step iterative procedure:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48403,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "In contrast to previous work on learning and characterization\u2014which uses PCA primarily for dimensionality reduction and/or feature extraction\u2014our method uses the eigenspace decomposition as an integral part of estimating complete density functions in high-dimensional image spaces."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Intuitively, an obvious choice for a lower-dimensional representation is the principal subspace indicated by PCA, which captures the major degrees of statistical variability in the data.3\nTherefore, we divide the summation into two independent parts corresponding to the principal subspace F i i\nM="
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "PCA can be seen as a linear transformation y = 7(x) : 5N \u00c6 5M which extracts a lower-dimensional subspace of the KL basis corresponding to the maximal eigenvalues."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "The Karhunen-Loeve Transform (KLT) [18] and Principal Components Analysis (PCA) [13] are examples of eigenvector-based techniques which are commonly used for dimensionality reduction and feature extraction in pattern recognition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In PCA, a partial KLT is performed to identify the largesteigenvalue eigenvectors and obtain a principal component\nfeature vector y x= FM T ~, where ~x x x= - is the mean-\nnormalized image vector and FM is a submatrix of F containing the principal eigenvectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "Before introducing these estimators, we briefly review eigenvector decomposition as commonly used in PCA."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 230
                            }
                        ],
                        "text": "The desired target density is decomposed into two components: the density in the principal subspace (containing the traditionally-defined principal components) and its orthogonal complement (which is usually discarded in standard PCA)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "The KarhunenLoeve Transform (KLT) [19] and Principal Components Analysis (PCA) [14] are examples of eigenvector-based techniques which are commonly used for dimensionality reduction and feature extraction in pattern recognition."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "Therefore, this strategy is usually consistent with the standard PCA practice of discarding the higher-order components since these tend to correspond to the \u201cflattest\u201d portion of the eigenvalue spectrum (see Fig."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "Instead, we use a probabilistic formulation which combines the two standard paradigms of unsupervised learning\u2014PCA and density estimation\u2014to arrive at a computationally feasible estimate of the class conditional density function."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "This derivation shows that once we select the M-dimensional principal subspace F (as indicated, for example, by PCA), the optimal estimate of the sufficient statistic $( )d x will have the form of (9) with r given by (13)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "I.T., Principal Component Analysis, Springer-Verlag, New York"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872039"
                        ],
                        "name": "R. Mammone",
                        "slug": "R.-Mammone",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Mammone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mammone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145117668"
                        ],
                        "name": "J. D. Murley",
                        "slug": "J.-D.-Murley",
                        "structuredName": {
                            "firstName": "Jackie",
                            "lastName": "Murley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Murley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60883821,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1a00eba79ba879100681b381def1981bb5b6b108",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-systems-for-the-identification-and-of-:-Mammone-Murley",
            "title": {
                "fragments": [],
                "text": "Automatic systems for the identification and inspection of humans : 28-29 July 1994, San Diego, California"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acknowledgements The FERET database was provided by the US Army Research Laboratory. The multiple orientation face database was provided by Westinghouse Electric Sys- tems"
            },
            "venue": {
                "fragments": [],
                "text": "Acknowledgements The FERET database was provided by the US Army Research Laboratory. The multiple orientation face database was provided by Westinghouse Electric Sys- tems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "The identification and parametric representation of a system in terms of these principal modes is at the core of recent advances in physically-based modeling [26], correspondence and matching [34], and parametric descriptions of shape [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Closed-Form Solutions for Physically Based Shape Modeling and Recovery"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 13, no. 7, pp. 715\u2013729, July 1991."
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 111
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [27], [6], nonlinear image interpolation [3], visual learning for object recognition [23], [38], as well as visual servoing for robotics [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[6] used Bayesian classification for object detection using a feature vector derived from principal component images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automating the Hunt for Volcanos on Venus"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Conf. Computer Vision and Pattern Recognition, Seattle, June 21-23, 1994."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 311
                            }
                        ],
                        "text": "In view-based recognition (as opposed to 3D geometric or invariant-based recognition), the saliency can be formulated in terms of visual similarity using a variety of metrics ranging from simple template matching scores to more sophisticated measures using, for example, robust statistics for image correlation [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust Estimation of Correlation: An Ap-  plication to Computer Vision,"
            },
            "venue": {
                "fragments": [],
                "text": "IRST Tech. Report no"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "The recognition accuracy (de ned as the percent correct rank-one matches) on a database of 155 individuals is 99% [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face recognition using view-based and  modular eigenspaces,\" in Automatic Systems for the Identi cation and In-  spection of Humans"
            },
            "venue": {
                "fragments": [],
                "text": "SPIE vol"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We would also like to thank Wasiuddin Wahid for his hard work in helping us participate in the FERET testing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition Using View- Based and Modular Eigenspaces Automatic Systems for the Identification and Inspection of Humans"
            },
            "venue": {
                "fragments": [],
                "text": "Face Recognition Using View- Based and Modular Eigenspaces Automatic Systems for the Identification and Inspection of Humans"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Weng [34] has proposed a visual learning framework based on the KLT in conjunction with an optimal linear discriminant transform for learning and recognition of objects from 2D views."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [24][6], nonlinear image interpolation [3], visual learning for object recognition [20][34], as well as visual servoing for robotics [21]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acknowledgements  The FERET database was provided by the US Army Research Laboratory. The  multiple orientation face database was provided by Westinghouse Electric Sys-  tems"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. NSF/ARPA Work-  shop on Performance vs. Methodology in Computer Vision,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Over the years, various strategies for facial feature detection have been proposed, ranging from edge map projections [15], to more recent techniques using generalized symmetry operators [32] and multilayer perceptrons [37]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture Processing by Computer Complex and Recognition of Human Faces"
            },
            "venue": {
                "fragments": [],
                "text": "technical report, Kyoto Univ., Dept. of Information Science, 1973."
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 311
                            }
                        ],
                        "text": "In view-based recognition (as opposed to 3D geometric or invariant-based recognition), the saliency can be formulated in terms of visual similarity using a variety of metrics ranging from simple template matching scores to more sophisticated measures using, for example, robust statistics for image correlation [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust estimation of correlation: an appli-  cation to computer vision,"
            },
            "venue": {
                "fragments": [],
                "text": "IRST Tech. Report"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "From an information-theoretic point of view, this cost function should be the KullbackLeibler divergence or relative entropy [8] between the true density P (xj ) and its estimate P\u0302 (xj ) J( ) = Z P (xj ) log P (xj ) P\u0302 (xj ) dx = E \"log P (xj ) P\u0302 (xj )# (11) Using the diagonalized forms of the Mahalanobis distance d(x) and its estimate d\u0302(x) and the fact that E[y2 i ] = i , it can be easily shown that J( ) = 12 N X i=M+1 i 1 + log \u0015i (12)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Elements of Information"
            },
            "venue": {
                "fragments": [],
                "text": "PROBABILISTIC VISUAL"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "Another approach is to capture the complexity of these manifolds in a universal or parametric eigenspace using splines [22], or local basis functions [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [26][6], nonlinear image interpolation [3], visual learning for object recognition [22][36], as well as visual servoing for robotics [23]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Surface Learning with Applications to  Lip Reading,\" in Advances in Neural Information"
            },
            "venue": {
                "fragments": [],
                "text": "Processing Systems 6,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] have extended this technique to visual feedback control and servoing for a robotic arm in \\peg-in-the-hole\" insertion tasks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 238
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [24][6], nonlinear image interpolation [3], visual learning for object recognition [20][34], as well as visual servoing for robotics [21]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "General learning algorithm for robot"
            },
            "venue": {
                "fragments": [],
                "text": "Neural & Stochastic Methods in Image & Signal Processing, SPIE  Proc. vol"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": ", moments [12], Fourier descriptors [26], \\snakes\" [15], Point Distribution Models [7], and modal descriptions [30])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Snakes: active contour models,\"  ICCV'87"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PROBABILISTIC VISUAL LEARNING"
            },
            "venue": {
                "fragments": [],
                "text": "PROBABILISTIC VISUAL LEARNING"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 187
                            }
                        ],
                        "text": "PROBABILISTIC VISUAL LEARNING 11 mated using the ML principle = argmax 24NT Y t=1 P (ytj )35 (16) This estimation problem is best solved using the Expectation-Maximization (EM) algorithm [10] which consists of the following two-step iterative procedure: E-step: hki (t) = k i g(yt; ki ; ki ) Nc X j=1 k j g(yt; kj ; ki ) (17) M-step: k+1 i = NT Xt=1 hki (t) Nc Xi=1 NT Xt=1 hki (t) (18) k+1 i = NT Xt=1 hki (t)yt NT Xt=1 hki (t) (19) k+1 i = NT Xt=1 hki (t)(yt k+1 i )(yt k+1 i )T NT Xt=1 hki (t) (20) The E-step computes the a posteriori probabilities hi(t) which are the expectations of \\missing\" component labels zi(t) = f0; 1g which denote the membership of yt in the i-th component."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from in-  complete data via the EM algorithm,"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society  B,"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Palmer [24] has suggested that visual attention is the process of locating the object of interest and placing it in a canonical (or object-centered) reference frame suitable for recognition (or template matching)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Psychology of Perceptual Organization: A Transforma-  tional Approach,\" in Human and Machine"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [26][6], nonlinear image interpolation [3], visual learning for object recognition [22][36], as well as visual servoing for robotics [23]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": "Weng [36] has proposed a visual learning framework based on the KLT in conjunction with an optimal linear discriminant transform for learning and recognition of objects from 2D views."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acknowledgements  The FERET database was provided by the US Army Research Laboratory. The  multiple-view face database"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. NSF/ARPA  Workshop on Performance vs. Methodology in Computer"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": ", moments [13], Fourier descriptors [20], \\snakes\" [16], Point Distribution Models [7], and modal descriptions [32])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fourier Descriptors and Neu-  ral Networks for Shape"
            },
            "venue": {
                "fragments": [],
                "text": "Classi cation,\" in Proc. of Int'l Conf. on Acoustics,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "More recently, principal component analysis of imagery has also been applied for robust target detection [27], [6], nonlinear image interpolation [3], visual learning for object recognition [23], [38], as well as visual servoing for robotics [24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "In this view-based, multiple-observer approach, the first step is to determine the location and orientation of the target object by selecting the eigenspace which best describes the input image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Surface Learning with Applications to Lip Reading Advances in Neural Information Processing Systems 6"
            },
            "venue": {
                "fragments": [],
                "text": "Surface Learning with Applications to Lip Reading Advances in Neural Information Processing Systems 6"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Picture processing by computer complex and recogniton of human faces"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 88
                            }
                        ],
                        "text": "Perhaps the most closely related is the recent neural network face detector of Sung and Poggio [35] which is essentially a trainable nonlinear binary pattern classifier."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "A similar effect was reported by Brunelli and Poggio [4], where the cumulative normalized correlation scores of templates for the face, eyes, nose, and mouth showed improved performance over the face-only templates."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features vs. Templates"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine  Intelligence,, vol. 15, no. 10, Oct. 1993."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acknowledgements The FERET database was provided by the US Army Research Laboratory. The multiple-view face database was provided by Westinghouse Electric Systems"
            },
            "venue": {
                "fragments": [],
                "text": "Acknowledgements The FERET database was provided by the US Army Research Laboratory. The multiple-view face database was provided by Westinghouse Electric Systems"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 26,
            "methodology": 23,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 59,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland/74b312560b79929540734067e58de46966b96130?sort=total-citations"
}