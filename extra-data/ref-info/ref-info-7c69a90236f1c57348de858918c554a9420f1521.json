{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707726"
                        ],
                        "name": "J. Pustejovsky",
                        "slug": "J.-Pustejovsky",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pustejovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pustejovsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 75
                            }
                        ],
                        "text": "These semantic phenomena are well known, and are described particularly by Pustejovsky (1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7129257,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "cae22af9bb9b7a2cebe2b4ee0a0364004ab73491",
            "isKey": false,
            "numCitedBy": 3805,
            "numCiting": 161,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, I will discuss four major topics relating to current research in lexical semantics: methodology, descriptive coverage, adequacy of the representation, and the computational usefulness of representations. In addressing these issues, I will discuss what I think are some of the central problems facing the lexical semantics community, and suggest ways of best approaching these issues. Then, I will provide a method for the decomposition of lexical categories and outline a theory of lexical semantics embodying a notion of cocompositionality and type coercion, as well as several levels of semantic description, where the semantic load is spread more evenly throughout the lexicon. I argue that lexical decomposition is possible if it is performed generatively. Rather than assuming a fixed set of primitives. I will assume a fixed number of generative devices that can be seen as constructing semantic expressions. I develop a theory of Qualia Structure, a representation language for lexical items, which renders much lexical ambiguity in the lexicon unnecessary, while still explaining the systematic polysemy that words carry. Finally, I discuss how individual lexical structures can be integrated into the larger lexical knowledge base through a theory of lexical inheritance. This provides us with the necessary principles of global organization for the lexicon, enabling us to fully integrate our natural language lexicon into a conceptual whole."
            },
            "slug": "The-Generative-Lexicon-Pustejovsky",
            "title": {
                "fragments": [],
                "text": "The Generative Lexicon"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that lexical decomposition is possible if it is performed generatively and a theory of lexical inheritance is outlined, which provides the necessary principles of global organization for the lexicon, enabling us to fully integrate the authors' natural language lexicon into a conceptual whole."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 156
                            }
                        ],
                        "text": "\u2026of words and their relationships, initially by factoring large term-by-document matrices as used in information retrieval systems (Deerwester et al. 1990; Landauer & Dumais 1997) and later by examining cooccurrence between pairs of words in textual windows (Lund & Burgess 1996; Schu\u0308tze 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1144461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
            "isKey": false,
            "numCitedBy": 5789,
            "numCiting": 210,
            "paperAbstract": {
                "fragments": [],
                "text": "How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched."
            },
            "slug": "A-Solution-to-Plato's-Problem:-The-Latent-Semantic-Landauer-Dumais",
            "title": {
                "fragments": [],
                "text": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge."
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40591835"
                        ],
                        "name": "K. Lund",
                        "slug": "K.-Lund",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50611682"
                        ],
                        "name": "C. Burgess",
                        "slug": "C.-Burgess",
                        "structuredName": {
                            "firstName": "Curt",
                            "lastName": "Burgess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burgess"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 259
                            }
                        ],
                        "text": "\u2026of words and their relationships, initially by factoring large term-by-document matrices as used in information retrieval systems (Deerwester et al. 1990; Landauer & Dumais 1997) and later by examining cooccurrence between pairs of words in textual windows (Lund & Burgess 1996; Schu\u0308tze 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 942,
                                "start": 329
                            }
                        ],
                        "text": "The tensor product may be defined in terms of multilinear maps (Fulton & Harris 1991, Appendix A), though a simpler initial intuition can be obtained by a matrix description: if the vector x has coordinates xi and the vector y has coordinates yj then the tensor product x \u2297 y is represented by the matrix whose ij entry is xiyj (Plate 2003, \u00a72.4.3). For those more familiar with the Dirac bra-ket notation, this tensor wold be written |x\u3009\u3008y|, where \u3008y| is the adjoint vector of |y\u3009. Just as there are matrices which cannot be formed by taking the outer product of two individual vectors, there are tensors that cannot be obtained as the tensor product of two individual vectors. This gives rise to a formulation of the phenomenon known as quantum entanglement (Rieffel 2007). Tensor products are comparatively little known in computational linguistics and artificial intelligence, though their use was initially advocated by Smolensky (1990). Recent interest in tensor products includes the work of Clark and Pulman (2007), who propose the use of tensor products to combine the benefits of symbolic and distributional models of meaning, very much the research goal we are following here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61090106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7093913b4daa0f34d9d58a41ceb0475cc3cc9f4",
            "isKey": true,
            "numCitedBy": 1721,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word is presented. This procedure is applied to a large corpus of natural language text taken from Usenet, and the resulting vectors are examined to determine what information is contained within them. These vectors provide the coordinates in a high-dimensional space in which word relationships can be analyzed. Analyses of both vector similarity and multidimensional scaling demonstrate that there is significant semantic information carried in the vectors. A comparison of vector similarity with human reaction times in a single-word priming experiment is presented. These vectors provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "slug": "Producing-high-dimensional-semantic-spaces-from-Lund-Burgess",
            "title": {
                "fragments": [],
                "text": "Producing high-dimensional semantic spaces from lexical co-occurrence"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A procedure that processes a corpus of text and produces numeric vectors containing information about its meanings for each word, which provide the basis for a representational model of semantic memory, hyperspace analogue to language (HAL)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50419262"
                        ],
                        "name": "S. Pulman",
                        "slug": "S.-Pulman",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Pulman",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pulman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 313,
                                "start": 289
                            }
                        ],
                        "text": "It is also important to note that building a tensor product |v\u3009\u3008w| using a single relationship between |v\u3009 and |w\u3009 gives an unentangled representation, so unless we use more than one training example, the results can be expressed as products of individual scalar products (as described by Clark and Pulman (2007), see also the next experiment below)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "The work builds on that of other researchers, particularly Plate (2003) and Clark and Pulman (2007)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 234
                            }
                        ],
                        "text": "\u2026product |v\u3009\u3008w| using a single relationship between |v\u3009 and |w\u3009 gives an unentangled representation, so unless we use more than one training example, the results can be expressed as products of individual scalar products (as described by Clark and Pulman (2007), see also the next experiment below)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 76
                            }
                        ],
                        "text": "The work builds on that of other researchers, particularly Plate (2003) and Clark and Pulman (2007). Our main intent is to demonstrate that, in spite of obvious setbacks and pitfalls, there are many possible avenues of exploration which between them contain sufficient promise of useful results that much further research should be done in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 56
                            }
                        ],
                        "text": "Recent interest in tensor products includes the work of Clark and Pulman (2007), who propose the use of tensor products to combine the benefits of symbolic and distributional models of meaning, very much the research goal we are following here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2280191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "73e897104540642698321c106cc9c35af369fe12",
            "isKey": true,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The are two main approaches to the representation of meaning in Computational Linguistics: a symbolic approach and a distributional approach. This paper considers the fundamental question of how these approaches might be combined. The proposal is to adapt a method from the Cognitive Science literature, in which symbolic and connectionist representations are combined using tensor products. Possible applications of this method for language processing are described. Finally, a potentially fruitful link between Quantum Mechanics, Computational Linguistics, and other related areas such as Information Retrieval and Machine Learning, is proposed."
            },
            "slug": "Combining-Symbolic-and-Distributional-Models-of-Clark-Pulman",
            "title": {
                "fragments": [],
                "text": "Combining Symbolic and Distributional Models of Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method is to be adapted from the Cognitive Science literature, in which symbolic and connectionist representations are combined using tensor products, to adapt a method for language processing."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Spring Symposium: Quantum Interaction"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 152
                            }
                        ],
                        "text": "Quantum negation significantly out-\nperformed Boolean negation at removing search results that contained synonyms and neighbours of unwanted query terms (Widdows 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 117
                            }
                        ],
                        "text": "performed Boolean negation at removing search results that contained synonyms and neighbours of unwanted query terms (Widdows 2003)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11265322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4319d42cc6d0a6c620bf6ef87d8319ab2f72d71",
            "isKey": false,
            "numCitedBy": 137,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard IR systems can process queries such as \"web NOT internet\", enabling users who are interested in arachnids to avoid documents about computing. The documents retrieved for such a query should be irrelevant to the negated query term. Most systems implement this by reprocessing results after retrieval to remove documents containing the unwanted string of letters.This paper describes and evaluates a theoretically motivated method for removing unwanted meanings directly from the original query in vector models, with the same vector negation operator as used in quantum logic. Irrelevance in vector spaces is modelled using orthogonality, so query vectors are made orthogonal to the negated term or terms.As well as removing unwanted terms, this form of vector negation reduces the occurrence of synonyms and neighbours of the negated terms by as much as 76% compared with standard Boolean methods. By altering the query vector itself, vector negation removes not only unwanted strings but unwanted meanings."
            },
            "slug": "Orthogonal-Negation-in-Vector-Spaces-for-Modelling-Widdows",
            "title": {
                "fragments": [],
                "text": "Orthogonal Negation in Vector Spaces for Modelling Word-Meanings and Document Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes and evaluates a theoretically motivated method for removing unwanted meanings directly from the original query in vector models, with the same vector negation operator as used in quantum logic."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115491216"
                        ],
                        "name": "C. J. V. Rijsbergen",
                        "slug": "C.-J.-V.-Rijsbergen",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Rijsbergen",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. V. Rijsbergen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 375,
                                "start": 171
                            }
                        ],
                        "text": "The development of a full logic for information retrieval, along with the appreciation that it involves some distinctly non-classical operations, is thanks largely to van Rijsbergen (1986 and ongoing), culminating recently in the thorough demonstration that the vector space logic for information retrieval is the same as the quantum logic of Birkhoff and von Neumann (1936). (See (van Rijsbergen 2004) and also (Widdows 2004, Ch 7)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32113647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6383831a44922d4e07bc4c8229228af67b5c60c1",
            "isKey": false,
            "numCitedBy": 504,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is to be seen as describing a new theoretical framework for investigating information retrieval. For some years now, I have felt the need to describe such a framework. It is especially important if one wants to develop information retrieval beyond the mere keyword approach. In the closing pages of my earlier book on the subject I said the following: \u201cIt has never been assumed that a retrieval system should attempt to understand\u201d the content of a document. Most Information Retrieval systems at the moment merely aim at a bibliographic search. Documents are deemed to be relevant on the basis of a superficial description. I do not suggest that it is going to be a simple matter to program a computer to understand documents. What is suggested is that some attempt should be made to construct something like a naive model, using more than just keywords, of the content of each document in the system. The more sophisticated question-answering systems do something very similar. They have a model of their universe of discourse and can answer questions about it, and can incorporate new facts and rules as they become available (van Rijsbergen, 1979)."
            },
            "slug": "A-Non-Classical-Logic-for-Information-Retrieval-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "A Non-Classical Logic for Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This paper is to be seen as describing a new theoretical framework for investigating information retrieval, and it is suggested that some attempt should be made to construct something like a naive model, using more than just keywords, of the content of each document in the system."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755431"
                        ],
                        "name": "P. Bruza",
                        "slug": "P.-Bruza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bruza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bruza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144021632"
                        ],
                        "name": "Richard Cole",
                        "slug": "Richard-Cole",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Cole",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Cole"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 56
                            }
                        ],
                        "text": "Recent interest in tensor products includes the work of Clark and Pulman (2007), who propose the use of tensor products to combine the benefits of symbolic and distributional models of meaning, very much the research goal we are following here. As pointed out by Rieffel (2007), tensor products are as much a part of classical probability theory as they are of quantum theory, since they are the correct space for forming the joint probability distribution of two distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 56
                            }
                        ],
                        "text": "Recent interest in tensor products includes the work of Clark and Pulman (2007), who propose the use of tensor products to combine the benefits of symbolic and distributional models of meaning, very much the research goal we are following here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 67
                            }
                        ],
                        "text": "This may be a new lead in the challenge proposed by Bruza et al. ((Bruza & Cole 2005), (Widdows & Bruza 2007)) of predicting from the medical literature that the relationship between Reynaud\u2019s syndrome and fish oil was significant, in spite of their lack of immediate cooccurrence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1583338,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "da46b6bda3e7480b1a8ed68aa81f881e028e809f",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This article is an exploratory account of the the non-monotonic behaviour of conceptual associations in the light of context. Computational approximations of conceptual space are furnished by semantic space models which are emerging from the fields of cognition and computational linguistics. Semantic space models not only provide a cognitively motivated basis to underpin human practical reasoning, but from a mathematical perspective, they are real-valued Hilbert spaces. This introduces the highly speculative prospect of formalizing aspects of human practical reasoning via quantum mechanics. This account focuses on how to formalize context effects in relation to concepts as well as keeping an eye on operational issues."
            },
            "slug": "Quantum-Logic-of-Semantic-Space:-An-Exploratory-of-Bruza-Cole",
            "title": {
                "fragments": [],
                "text": "Quantum Logic of Semantic Space: An Exploratory Investigation of Context Effects in Practical Reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This article is an exploratory account of the the non-monotonic behaviour of conceptual associations in the light of context, focusing on how to formalize context effects in relation to concepts as well as keeping an eye on operational issues."
            },
            "venue": {
                "fragments": [],
                "text": "We Will Show Them!"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2412562"
                        ],
                        "name": "P. G\u00e4rdenfors",
                        "slug": "P.-G\u00e4rdenfors",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "G\u00e4rdenfors",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. G\u00e4rdenfors"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "Their importance is also becoming established in cognitive science, championed by Ga\u0308rdenfors (2000) as \u201cConceptual Spaces\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 46
                            }
                        ],
                        "text": "Adjectival modifiers show similar plasticity (Ga\u0308rdenfors 2000, p. 120)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 13
                            }
                        ],
                        "text": "For example, Ga\u0308rdenfors (2000) uses projection onto a convex region to account for the use of the term \u201cred\u201d in \u201cred wine\u201d, \u201cred skin\u201d, etc. to refer to colours that are not really \u201cred\u201d."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 13
                            }
                        ],
                        "text": "For example, G\u00e4rdenfors (2000) uses projection onto a convex region to account for the use of the term \u201cred\u201d in \u201cred wine\u201d, \u201cred skin\u201d, etc."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 82
                            }
                        ],
                        "text": "Their importance is also becoming established in cognitive science, championed by G\u00e4rdenfors (2000) as \u201cConceptual Spaces\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 13
                            }
                        ],
                        "text": "For example, G\u00e4rdenfors (2000) uses projection onto a convex region to account for the use of the term \u201cred\u201d in \u201cred wine\u201d, \u201cred skin\u201d, etc. to refer to colours that are not really \u201cred\u201d. Widdows (2004) also suggests that projections may be used to model the way a phrase like \u201ctiger moth\u201d selects the appropriate feature of \u201ctiger\u201d as a modifier to the \u201cmoth\u201d concept."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15776581,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d5547cd03e318e98f61b913123f07dceb58d3def",
            "isKey": true,
            "numCitedBy": 1162,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "Within cognitive science, two approaches currently dominate the problem of modeling representations. The symbolic approach views cognition as computation involving symbolic manipulation. Connectionism, a special case of associationism, models associations using artificial neuron networks. Peter Gardenfors offers his theory of conceptual representations as a bridge between the symbolic and connectionist approaches. Symbolic representation is particularly weak at modeling concept learning, which is paramount for understanding many cognitive phenomena. Concept learning is closely tied to the notion of similarity, which is also poorly served by the symbolic approach. Gardenfors's theory of conceptual spaces presents a framework for representing information on the conceptual level. A conceptual space is built up from geometrical structures based on a number of quality dimensions. The main applications of the theory are on the constructive side of cognitive science: as a constructive model the theory can be applied to the development of artificial systems capable of solving cognitive tasks. Gardenfors also shows how conceptual spaces can serve as an explanatory framework for a number of empirical theories, in particular those concerning concept formation, induction, and semantics. His aim is to present a coherent research program that can be used as a basis for more detailed investigations. (Less)"
            },
            "slug": "Conceptual-spaces-the-geometry-of-thought-G\u00e4rdenfors",
            "title": {
                "fragments": [],
                "text": "Conceptual spaces - the geometry of thought"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Peter Gardenfors's theory of conceptual spaces presents a framework for representing information on the conceptual level and shows how conceptual spaces can serve as an explanatory framework for a number of empirical theories, in particular those concerning concept formation, induction, and semantics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689109"
                        ],
                        "name": "Magnus Sahlgren",
                        "slug": "Magnus-Sahlgren",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Sahlgren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnus Sahlgren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 232
                            }
                        ],
                        "text": "It is also interesting that this method for constructing semantic vectors, known sometimes as \u201cRandom Indexing\u201d or \u201cRandom Projection\u201d is also the most computationally tractable and thus likely to lead to commercial-scale applications (Sahlgren 2005; Widdows & Ferraro 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17228581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ef1b0469b43acc8ede2e56d8f001ad090b04826",
            "isKey": false,
            "numCitedBy": 500,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Word space models enjoy considerable attention in current research on semantic indexing. Most notably, Latent Semantic Analysis/Indexing (LSA/LSI; Deerwester et al., 1990, Landauer & Dumais, 1997) has become a household name in information access research, and deservedly so; LSA has proven its mettle in numerous applications, and has more or less spawned an entire research field since its introduction around 1990. Today, there is a rich flora of word space models available, and there are numerous publications that report exceptional results in many different applications, including information retrieval (Dumais et al., 1988), word sense disambiguation (Schutze, 1993), various semantic knowledge tests (Lund et al., 1995, Karlgren & Sahlgren, 2001), and text categorization (Sahlgren & Karlgren, 2004). This paper introduces the Random Indexing word space approach, which presents an efficient, scalable and incremental alternative to standard word space methods. The paper is organized as follows: in the next section, we review the basic word space methodology. We then look at some of the problems that are inherent in the basic methodology, and also review some of the solutions that have been proposed in the literature. In the final section, we introduce the Random Indexing word space approach, and briefly review some of the experimental results that have been achieved with Random Indexing."
            },
            "slug": "An-Introduction-to-Random-Indexing-Sahlgren",
            "title": {
                "fragments": [],
                "text": "An Introduction to Random Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Random Indexing word space approach is introduced, which presents an efficient, scalable and incremental alternative to standard word space methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801071"
                        ],
                        "name": "Frank Smadja",
                        "slug": "Frank-Smadja",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Smadja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank Smadja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 129
                            }
                        ],
                        "text": "This is not to say that natural language processing does not have some tools to offer: for example, collocation extraction tools (Smadja 1993; Manning & Sch\u00fctze 1999) may be used to help with extracting nounphrases and indexing them accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "This is not to say that natural language processing does not have some tools to offer: for example, collocation extraction tools (Smadja 1993; Manning & Schu\u0308tze 1999) may be used to help with extracting nounphrases and indexing them accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16151922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3ff7801bcf72fea30117c88d397403a570c5c68",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural languages are full of collocations, recurrent combinations of words that co-occur more often than expected by chance and that correspond to arbitrary word usages. Recent work in lexicography indicates that collocations are pervasive in English; apparently, they are common in all types of writing, including both technical and nontechnical genres. Several approaches have been proposed to retrieve various types of collocations from the analysis of large samples of textual data. These techniques automatically produce large numbers of collocations along with statistical figures intended to reflect the relevance of the associations. However, none of these techniques provides functional information along with the collocation. Also, the results produced often contained improper word associations reflecting some spurious aspect of the training corpus that did not stand for true collocations.In this paper, we describe a set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora. These techniques produce a wide range of collocations and are based on some original filtering methods that allow the production of richer and higher-precision output. These techniques have been implemented and resulted in a lexicographic tool, Xtract. The techniques are described and some results are presented on a 10 million-word corpus of stock market news reports. A lexicographic evaluation of Xtract as a collocation retrieval tool has been made, and the estimated precision of Xtract is 80%."
            },
            "slug": "Retrieving-Collocations-from-Text:-Xtract-Smadja",
            "title": {
                "fragments": [],
                "text": "Retrieving Collocations from Text: Xtract"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A set of techniques based on statistical methods for retrieving and identifying collocations from large textual corpora, based on some original filtering methods that allow the production of richer and higher-precision output are described."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39340971"
                        ],
                        "name": "B. Partee",
                        "slug": "B.-Partee",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Partee",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Partee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909891"
                        ],
                        "name": "A. T. Meulen",
                        "slug": "A.-T.-Meulen",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Meulen",
                            "middleNames": [
                                "ter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. T. Meulen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40383053"
                        ],
                        "name": "R. Wall",
                        "slug": "R.-Wall",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Wall",
                            "middleNames": [
                                "E."
                            ],
                            "suffix": "Jr."
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118066274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9602400f20ed0e275e92937a4060df43e894fd2f",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. Part A. Set Theory. 1. Basic Concepts of Set Theory. 2. Relations and Functions. 3. Properties of Relations. 4. Infinities. Appendix A1. Part B. Logic and Formal Systems. 5. Basic Concepts of Logic. 6.Statement Logic. 7. Predicate Logic. 8. Formal Systems, Axiomatization, and Model Theory. Appendix B1. Appendix BII. Part C. Algebra. 9. Basic Concepts of Algebra. 10. Operational Structures. 11. Lattices. 12. Boolean and Heyting Algebras. Part D. English as a Formal Language. 13. Basic Concepts of Formal Languages. 14. Generalized Quantifiers. 15. Intensionality. Part E. Languages, Grammars, and Automata. 16. Basic Concepts of Languages, Grammars, and Automata. 17. Finite Automata, Regular Languages and Type 3 Grammars. 18. Pushdown Automata, Context-Free Grammars and Languages. 19. Turing Machines, Recursively Enumberable Languages, and Type 0 Grammars. 20. Linear Bounded Automata, Context-Sensitive Languages and Type 1 Grammars. 21. Languages Between Context-Free and Context-Sensitive. 22. Transformational Grammars. Appendix EI. Appendix EII. Review Problems. Index."
            },
            "slug": "Mathematical-Methods-in-Linguistics-Partee-Meulen",
            "title": {
                "fragments": [],
                "text": "Mathematical Methods in Linguistics"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The aim of this book is to clarify the role that language plays in the development of set theory and to provide a framework for the future development of such a system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721801"
                        ],
                        "name": "C. Fellbaum",
                        "slug": "C.-Fellbaum",
                        "structuredName": {
                            "firstName": "Christiane",
                            "lastName": "Fellbaum",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fellbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 51
                            }
                        ],
                        "text": "6), relations in a lexical network such as WordNet (Fellbaum 1998), and a traditional dictionary definition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 180
                            }
                        ],
                        "text": "In a larger\nsurvey, other models could well be included such as a (smoothed) collection of n-grams (Manning & Schu\u0308tze 1999, Ch. 6), relations in a lexical network such as WordNet (Fellbaum 1998), and a traditional dictionary definition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5958691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d87ceda3042f781c341ac17109d1e94a717f5f60",
            "isKey": false,
            "numCitedBy": 13578,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Part 1 The lexical database: nouns in WordNet, George A. Miller modifiers in WordNet, Katherine J. Miller a semantic network of English verbs, Christiane Fellbaum design and implementation of the WordNet lexical database and searching software, Randee I. Tengi. Part 2: automated discovery of WordNet relations, Marti A. Hearst representing verb alterations in WordNet, Karen T. Kohl et al the formalization of WordNet by methods of relational concept analysis, Uta E. Priss. Part 3 Applications of WordNet: building semantic concordances, Shari Landes et al performance and confidence in a semantic annotation task, Christiane Fellbaum et al WordNet and class-based probabilities, Philip Resnik combining local context and WordNet similarity for word sense identification, Claudia Leacock and Martin Chodorow using WordNet for text retrieval, Ellen M. Voorhees lexical chains as representations of context for the detection and correction of malapropisms, Graeme Hirst and David St-Onge temporal indexing through lexical chaining, Reem Al-Halimi and Rick Kazman COLOR-X - using knowledge from WordNet for conceptual modelling, J.F.M. Burg and R.P. van de Riet knowledge processing on an extended WordNet, Sanda M. Harabagiu and Dan I Moldovan appendix - obtaining and using WordNet."
            },
            "slug": "WordNet-:-an-electronic-lexical-database-Fellbaum",
            "title": {
                "fragments": [],
                "text": "WordNet : an electronic lexical database"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The lexical database: nouns in WordNet, Katherine J. Miller a semantic network of English verbs, and applications of WordNet: building semantic concordances are presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41124197"
                        ],
                        "name": "Kathleen Ferraro",
                        "slug": "Kathleen-Ferraro",
                        "structuredName": {
                            "firstName": "Kathleen",
                            "lastName": "Ferraro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kathleen Ferraro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 182
                            }
                        ],
                        "text": "To these ends, we have released tools for creating and exploring wordspace models through the Semantic Vectors project, which is hosted at http://code.google.com/ p/semanticvectors (Widdows & Ferraro 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 247
                            }
                        ],
                        "text": "It is also interesting that this method for constructing semantic vectors, known sometimes as \u201cRandom Indexing\u201d or \u201cRandom Projection\u201d is also the most computationally tractable and thus likely to lead to commercial-scale applications (Sahlgren 2005; Widdows & Ferraro 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12317655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d115d2f55442137893aacd641674c248064c938f",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the open source SemanticVectors package that efficiently creates semantic vectors for words and documents from a corpus of free text articles. We believe that this package can play an important role in furthering research in distributional semantics, and (perhaps more importantly) can help to significantly reduce the current gap that exists between good research results and valuable applications in production software. Two clear principles that have guided the creation of the package so far include ease-of-use and scalability. The basic package installs and runs easily on any Java-enabled platform, and depends only on Apache Lucene. Dimension reduction is performed using Random Projection, which enables the system to scale much more effectively than other algorithms used for the same purpose. This paper also describes a trial application in the Technology Management domain, which highlights some user-centred design challenges which we believe are also key to successful deployment of this technology."
            },
            "slug": "Semantic-Vectors:-a-Scalable-Open-Source-Package-Widdows-Ferraro",
            "title": {
                "fragments": [],
                "text": "Semantic Vectors: a Scalable Open Source Package and Online Technology Management Application"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "The SemanticVectors package that efficiently creates semantic vectors for words and documents from a corpus of free text articles is described, which can play an important role in furthering research in distributional semantics, and can help to significantly reduce the current gap between good research results and valuable applications in production software."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "(See (van Rijsbergen 2004) and also (Widdows 2004, Ch 7).)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 279
                            }
                        ],
                        "text": "\u2026small, they were performed using vectors from large empirical semantic vector spaces built using the 100 million word British National Corpus1 and the Infomap NLP software2, which uses singular value decomposition to create a reduced wordspace from a large cooccurrence matrix (Widdows 2004, Ch 6)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Semantic vector models are by now a recognized part of mainstream computational linguistics, and are sometimes described as wordspace models (Widdows 2004; Sahlgren 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Widdows (2004) also suggests that projections may be used to model the way a phrase like \u201ctiger moth\u201d selects the appropriate feature of \u201ctiger\u201d as a modifier to the \u201cmoth\u201d concept."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 79
                            }
                        ],
                        "text": "For an introduction to vector addition, cosine similarity and clustering, see (Widdows 2004, Ch. 5,6)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17581,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "36eff99a7f23cec395e4efc80ff7f937934c7be6",
            "isKey": false,
            "numCitedBy": 306,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "From Pythagoras's harmonic sequence to Einstein's theory of relativity, geometric models of position, proximity, ratio, and the underlying properties of physical space have provided us with powerful ideas and accurate scientific tools. Currently, similar geometric models are being applied to another type of space the conceptual space of information and meaning, where the contributions of Pythagoras and Einstein are a part of the landscape itself. The rich geometry of conceptual space can be glimpsed, for instance, in internet documents: while the documents themselves define a structure of visual layouts and point-to-point links, search engines create an additional structure by matching keywords to nearby documents in a spatial arrangement of content. What the \"Geometry of Meaning\" provides is a much-needed exploration of computational techniques to represent meaning and of the conceptual spaces on which these representations are founded.\""
            },
            "slug": "Geometry-and-Meaning-Widdows",
            "title": {
                "fragments": [],
                "text": "Geometry and Meaning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "What the \"Geometry of Meaning\" provides is a much-needed exploration of computational techniques to represent meaning and of the conceptual spaces on which these representations are founded."
            },
            "venue": {
                "fragments": [],
                "text": "Computational Linguistics"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998726"
                        ],
                        "name": "G. Leech",
                        "slug": "G.-Leech",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Leech",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Leech"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153733790"
                        ],
                        "name": "R. Garside",
                        "slug": "R.-Garside",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Garside",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garside"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40639594"
                        ],
                        "name": "M. Bryant",
                        "slug": "M.-Bryant",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bryant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bryant"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16137021,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3cc8d65946052ef661e1b6b4c7b5d8322ab37f35",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The main purpose of this paper is to describe the CLAWS4 general-purpose grammatical tagger, used for the tagging of the 100-million-word British National Corpus, of which c.70 million words have been tagged at the time of writing (April 1994)) We will emphasise the goals of (a) gener~d-purpose adaptability, (b) incorporation of linguistic knowledge to improve quality ,and consistency, and (c) accuracy, measured consistently and in a linguistically informed way. The British National Corpus (BNC) consists of c.100 million words of English written texts and spoken transcriptions, sampled from a comprehensive range of text types. The BNC includes 10 million words of spoken h'mguage, c.45% of which is impromptu conversation (see Crowdy, forthcoming). It also includes ,an immense variety of written texts, including unpublished materials. The gr,'unmatical tagging of the corpus has therefore required the 'super-robustness' of a tagger which can adapt well to virtually all kinds of text. The tagger also has had to be versatile in dealing with different tagsets (sets of grammatical category labels-see 3 below) and accepting text in varied input formats. For the purposes of the BNC, l, he tagger has been requircd both to accept and to output text in a corpus-oriented TEl-confonnant mark-up definition known as CDIF (Corpus Document Interchange Format), but within this format many variant fornaats (affecting, for example, segmentation into words and sentences) can be readily accepted. In addition, CLAWS al-"
            },
            "slug": "CLAWS4:-The-Tagging-of-the-British-National-Corpus-Leech-Garside",
            "title": {
                "fragments": [],
                "text": "CLAWS4: The Tagging of the British National Corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The main purpose of this paper is to describe the CLAWS4 general-purpose grammatical tagger, used for the tagging of the 100-million-word British National Corpus, and emphasise the goals of adaptability, incorporation of linguistic knowledge to improve quality, consistency, and accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802811"
                        ],
                        "name": "D. Widdows",
                        "slug": "D.-Widdows",
                        "structuredName": {
                            "firstName": "Dominic",
                            "lastName": "Widdows",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Widdows"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755431"
                        ],
                        "name": "P. Bruza",
                        "slug": "P.-Bruza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bruza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bruza"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 88
                            }
                        ],
                        "text": "This may be a new lead in the challenge proposed by Bruza et al. ((Bruza & Cole 2005), (Widdows & Bruza 2007)) of predicting from the medical literature that the relationship between Reynaud\u2019s syndrome and fish oil was significant, in spite of their lack of immediate cooccurrence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11567423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7441da381a5ddb87cf4fc48a547a9ba9d115577",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the fundamental insights of quantum mechanics is that complete knowledge of the state of a quantum system is not possible. Such incomplete knowledge of a physical system is the norm rather than the exception. This is becoming increasingly apparent as we apply scientific methods to increasingly complex situations. Empirically intensive disciplines in the biological, human, and geosciences all operate in situations where valid conclusions must be drawn, but deductive completeness is impossible. This paper argues that such situations are emerging examples of Open World Science. In this paradigm, scientific models are known to be acting with incomplete information. Open World models acknowledge their incompleteness, and respond positively when new information becomes available. Many methods for creating Open World models have been explored analytically in quantitative disciplines such as statistics, and the increasingly mature area of machine learning. This paper examines the role of quantum theory and quantum logic in the underpinnings of Open World models, examining the importance of structural features of such as noncommutativity, degrees of similarity, induction, and the impact of observation. Quantum mechanics is not a problem around the edges of classical theory, but is rather a secure bridgehead in the world of science to come."
            },
            "slug": "Quantum-Information-Dynamics-and-Open-World-Science-Widdows-Bruza",
            "title": {
                "fragments": [],
                "text": "Quantum Information Dynamics and Open World Science"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The role of quantum theory and quantum logic in the underpinnings of Open World models is examined, examining the importance of structural features of such as noncommutativity, degrees of similarity, induction, and the impact of observation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI Spring Symposium: Quantum Interaction"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710276"
                        ],
                        "name": "E. Rieffel",
                        "slug": "E.-Rieffel",
                        "structuredName": {
                            "firstName": "Eleanor",
                            "lastName": "Rieffel",
                            "middleNames": [
                                "Gilbert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rieffel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "This gives rise to a formulation of the phenomenon known as quantum entanglement (Rieffel 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 18
                            }
                        ],
                        "text": "As pointed out by Rieffel (2007), tensor products are as much a part of classical probability theory as they are of quantum theory, since they are the correct space for forming the joint probability distribution of two distributions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11661282,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "357db3f3de77cf5504aa3e31fcd62c52a37356c5",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "This survey, aimed at information processing researchers, highlights intriguing but lesser known results, corrects misconceptions, and suggests research areas. Themes include: certainty in quantum algorithms; the \u201cfewer worlds\u201d theory of quantum mechanics; quantum learning; probability theory versus quantum mechanics. This idiosyncratic survey delves into areas of quantum information processing of interest to researchers in fields like information retrieval, machine learning, and artificial intelligence. It overviews intriguing but lesser known results, corrects common misconceptions, and suggests research directions. Three types of applications of a quantum viewpoint on information processing are discussed: quantum algorithms and protocols; quantum proofs for classical results; the use of formalisms developed for quantum mechanics in other areas with linear algebraic or probabilistic components. This paper is not tutorial in nature; readers new to the field should read it in conjunction with a tutorial (Rieffel & Polak 2000) or book (Nielsen & Chuang 2001; Rieffel & Polak in preparation) on the subject. A number of themes underlie this paper: certainty in quantum algorithms and quantum mechanics, including a \u201cfewer worlds\u201d correction to popular conceptions of the \u201cmany worlds\u201d interpretation of quantum mechanics; relations and distinct differences between probability theory and quantum mechanics, including how entanglement differs from correlation; what is known and what remains uncertain as to the source of the power of quantum information processing. The most startling thing about quantum mechanics is not that it is probabilistic, but rather that it disobeys fundamental laws of probability theory. A common framework encompassing both probability theory and quantum mechanics throws light on many of these themes. The most technical parts of the paper establish this framework and discuss its implications."
            },
            "slug": "Certainty-and-Uncertainty-in-Quantum-Information-Rieffel",
            "title": {
                "fragments": [],
                "text": "Certainty and Uncertainty in Quantum Information Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 115
                            }
                        ],
                        "text": "Vector addition has been used for operations other than document retrieval, particularly word sense discrimination (Sch\u00fctze 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 108
                            }
                        ],
                        "text": "1990; Landauer & Dumais 1997) and later by examining cooccurrence between pairs of words in textual windows (Lund & Burgess 1996; Sch\u00fctze 1998)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 280
                            }
                        ],
                        "text": "\u2026of words and their relationships, initially by factoring large term-by-document matrices as used in information retrieval systems (Deerwester et al. 1990; Landauer & Dumais 1997) and later by examining cooccurrence between pairs of words in textual windows (Lund & Burgess 1996; Schu\u0308tze 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 116
                            }
                        ],
                        "text": "Vector addition has been used for operations other than document retrieval, particularly word sense discrimination (Schu\u0308tze 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8754851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c",
            "isKey": true,
            "numCitedBy": 1401,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words."
            },
            "slug": "Automatic-Word-Sense-Discrimination-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Automatic Word Sense Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering that demonstrates good performance of context- group discrimination for a sample of natural and artificial ambiguous words."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2859277"
                        ],
                        "name": "T. Plate",
                        "slug": "T.-Plate",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Plate",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Plate"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 59
                            }
                        ],
                        "text": "The work builds on that of other researchers, particularly Plate (2003) and Clark and Pulman (2007)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 272
                            }
                        ],
                        "text": "\u2026maps (Fulton & Harris 1991, Appendix A), though a simpler initial intuition can be obtained by a matrix description: if the vector x has coordinates xi and the vector y has coordinates yj then the tensor product x \u2297 y is represented by the matrix whose ijth entry is xiyj (Plate 2003, \u00a72.4.3)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 38
                            }
                        ],
                        "text": "The most thorough summary is given by Plate (2003) in his description of Holographic Reduced Representations, or HRRs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2352281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "564427596799f7967c91934966cd3c6bd31cb06d",
            "isKey": true,
            "numCitedBy": 542,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Associative memories are conventionally used to represent data with very simple structure: sets of pairs of vectors. This paper describes a method for representing more complex compositional structure in distributed representations. The method uses circular convolution to associate items, which are represented by vectors. Arbitrary variable bindings, short sequences of various lengths, simple frame-like structures, and reduced representations can be represented in a fixed width vector. These representations are items in their own right and can be used in constructing compositional structures. The noisy reconstructions extracted from convolution memories can be cleaned up by using a separate associative memory that has good reconstructive properties."
            },
            "slug": "Holographic-reduced-representations-Plate",
            "title": {
                "fragments": [],
                "text": "Holographic reduced representations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper describes a method for representing more complex compositional structure in distributed representations that uses circular convolution to associate items, which are represented by vectors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298207"
                        ],
                        "name": "P. Kanerva",
                        "slug": "P.-Kanerva",
                        "structuredName": {
                            "firstName": "Pentti",
                            "lastName": "Kanerva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kanerva"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 213
                            }
                        ],
                        "text": "There is considerable cognitive significance in the fact that semantic vector models can be learned and represented using only sparse distributed pieces of memory such as might be available in individual neurons (Kanerva 1988)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57931704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcdb9bd64e3d7885c10938291153257b94f3df91",
            "isKey": false,
            "numCitedBy": 1008,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nMotivated by the remarkable fluidity of memory the way in which items are pulled spontaneously and effortlessly from our memory by vague similarities to what is currently occupying our attention Sparse Distributed Memory presents a mathematically elegant theory of human long term memory. \nThe book, which is self contained, begins with background material from mathematics, computers, and neurophysiology; this is followed by a step by step development of the memory model. The concluding chapter describes an autonomous system that builds from experience an internal model of the world and bases its operation on that internal model. Close attention is paid to the engineering of the memory, including comparisons to ordinary computer memories. \nSparse Distributed Memory provides an overall perspective on neural systems. The model it describes can aid in understanding human memory and learning, and a system based on it sheds light on outstanding problems in philosophy and artificial intelligence. Applications of the memory are expected to be found in the creation of adaptive systems for signal processing, speech, vision, motor control, and (in general) robots. Perhaps the most exciting aspect of the memory, in its implications for research in neural networks, is that its realization with neuronlike components resembles the cortex of the cerebellum. \nPentti Kanerva is a scientist at the Research Institute for Advanced Computer Science at the NASA Ames Research Center and a visiting scholar at the Stanford Center for the Study of Language and Information. A Bradford Book."
            },
            "slug": "Sparse-Distributed-Memory-Kanerva",
            "title": {
                "fragments": [],
                "text": "Sparse Distributed Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Pentti Kanerva's Sparse Distributed Memory presents a mathematically elegant theory of human long term memory that resembles the cortex of the cerebellum, and provides an overall perspective on neural systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40654213,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bee570503aaa0ed5bc5dd4cf6aa742df0b5cef87",
            "isKey": false,
            "numCitedBy": 13814,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.\n\nThis major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates.\n\nTrevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting."
            },
            "slug": "The-Elements-of-Statistical-Learning:-Data-Mining,-Hastie-Tibshirani",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd Edition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Series in Statistics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689109"
                        ],
                        "name": "Magnus Sahlgren",
                        "slug": "Magnus-Sahlgren",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Sahlgren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnus Sahlgren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 156
                            }
                        ],
                        "text": "Semantic vector models are by now a recognized part of mainstream computational linguistics, and are sometimes described as wordspace models (Widdows 2004; Sahlgren 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11917163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1521ddb27860cc8834f8a82e62665bf983c8ad2c",
            "isKey": false,
            "numCitedBy": 600,
            "numCiting": 166,
            "paperAbstract": {
                "fragments": [],
                "text": "The word-space model is a computational model of word meaning that utilizes the distributional patterns of words collected over large text data to represent semantic similarity between words in ter ..."
            },
            "slug": "The-Word-Space-Model-:-Using-distributional-to-and-Sahlgren",
            "title": {
                "fragments": [],
                "text": "The Word-Space Model : Using distributional analysis to represent syntagmatic and paradigmatic relations between words in high-dimensional vector spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "The word-space model is a computational model of word meaning that utilizes the distributional patterns of words collected over large text data to represent semantic similarity between words in terabytes of data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50456197"
                        ],
                        "name": "G. Birkhoff",
                        "slug": "G.-Birkhoff",
                        "structuredName": {
                            "firstName": "Garrett",
                            "lastName": "Birkhoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Birkhoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41224665"
                        ],
                        "name": "J. Neumann",
                        "slug": "J.-Neumann",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Neumann",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Neumann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 119756757,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "ac503f361a3579e048c9b3516f1cdd747ac6e6da",
            "isKey": false,
            "numCitedBy": 1297,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the aspects of quantum theory which has attracted the most general attention, is the novelty of the logical notions which it presupposes. It asserts that even a complete mathematical description of a physical system S does not in general enable one to predict with certainty the result of an experiment on S, and that in particular one can never predict with certainty both the position and the momentum of S, (Heisenberg\u2019s Uncertainty Principle). It further asserts that most pairs of observations are incompatible, and cannot be made on S, simultaneously (Principle of Non-commutativity of Observations)."
            },
            "slug": "The-Logic-of-Quantum-Mechanics-Birkhoff-Neumann",
            "title": {
                "fragments": [],
                "text": "The Logic of Quantum Mechanics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1936
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709413"
                        ],
                        "name": "C. J. V. Rijsbergen",
                        "slug": "C.-J.-V.-Rijsbergen",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Rijsbergen",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. V. Rijsbergen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 10
                            }
                        ],
                        "text": "(See (van Rijsbergen 2004) and also (Widdows 2004, Ch 7).)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 150
                            }
                        ],
                        "text": "Their formal theory as part of information retrieval, and the relationship of their logic to that of quantum mechanics, is also well established (van Rijsbergen 2004)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5312750,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "99614334a3e9b809e43384777409af7eccde3db6",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 231,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface Prologue 1. Introduction 2. On sets and kinds in IR 3. Vector and Hilbert spaces 4. Linear transformations, operators and matrices 5. Conditional logic in IR 6. The geometry of IR Appendix I. Linear algebra Appendix II. Quantum mechanics Appendix III. Probability Bibliography Index."
            },
            "slug": "The-geometry-of-information-retrieval-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "The geometry of information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The geometry of IR is studied through the lens of linear algebra, quantum mechanics, and vector and Hilbert spaces, with a focus on linear transformations, operators and matrices."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": false,
            "numCitedBy": 13353,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767844"
                        ],
                        "name": "Diederik Aerts",
                        "slug": "Diederik-Aerts",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Aerts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik Aerts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278816"
                        ],
                        "name": "M. Czachor",
                        "slug": "M.-Czachor",
                        "structuredName": {
                            "firstName": "Marek",
                            "lastName": "Czachor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Czachor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 62
                            }
                        ],
                        "text": "This has been demonstrated in a small artificial wordspace by Aerts and Czachor (2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16701954,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "ec013e75fb6486994455db8c31d2feef71bb63a6",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A zipper tooth has a body portion with an opening at one end for connection to a tape to form a zipper stringer of a slide fastener. At the other end of the body portion is an engaging head. Just behind the engaging head are a pair of grooves, one on each side of the body portion. The grooves are contoured to accommodate portions of the engaging heads of other similar zipper teeth. At each end of each of the grooves are outwardly extending tapered projections. The projections are rolled over to provide endwalls for the grooves so that a cavity is formed for locking accepting portions of engaging heads of other zipper teeth."
            },
            "slug": "LETTER-TO-THE-EDITOR:-Quantum-aspects-of-semantic-Aerts-Czachor",
            "title": {
                "fragments": [],
                "text": "LETTER TO THE EDITOR: Quantum aspects of semantic analysis and symbolic artificial intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A zipper tooth has a body portion with an opening at one end for connection to a tape to form a zipper stringer of a slide fastener to accommodate portions of the engaging heads of other similar zipper teeth."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13041116"
                        ],
                        "name": "J. Hefferon",
                        "slug": "J.-Hefferon",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Hefferon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hefferon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 128
                            }
                        ],
                        "text": "Again, we are forced to be brief and refer readers to more detailed textbooks in linear and multilinear algebra for more detail (J\u00e4nich 1994; Fulton & Harris 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 129
                            }
                        ],
                        "text": "Again, we are forced to be brief and refer readers to more detailed textbooks in linear and multilinear algebra for more detail (Ja\u0308nich 1994; Fulton & Harris 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1300625,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1cd0b645f442a65d4a4d6f9e22f198951f97991b",
            "isKey": false,
            "numCitedBy": 1655,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "The subject of linear algebra includes the solution of linear equations, a topic properly belonging to college algebra. Earlier in this text, the theory of linear algebraic equations was presented, without the aid of vector-matrix notation. The project before us is to introduce specialized vector-matrix notation and to extend the methods used to solve linear algebraic equations. Enrichment includes a full study of rank, nullity and basis from the vector-matrix viewpoint. Engineers can view linear algebra as the essential language interface between an application and a computer algebra system or a computer numerical laboratory. Without the language interface, computer assist would be impossibly tedious."
            },
            "slug": "Linear-Algebra-Hefferon",
            "title": {
                "fragments": [],
                "text": "Linear Algebra"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The project before us is to introduce specialized vector-matrix notation and to extend the methods used to solve linear algebraic equations to include a full study of rank, nullity and basis from the vector-Matrix viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10796472"
                        ],
                        "name": "James H. Martin",
                        "slug": "James-H.-Martin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James H. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5073927,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "894149cb66e8af4a20c82840ea3f774888644fa6",
            "isKey": false,
            "numCitedBy": 3258,
            "numCiting": 356,
            "paperAbstract": {
                "fragments": [],
                "text": "is one of the most recognizablecharacters in 20th century cinema. HAL is an arti\ufb01cial agent capable of such advancedlanguage behavior as speaking and understanding English, and at a crucial moment inthe plot, even reading lips. It is now clear that HAL\u2019s creator, Arthur C. Clarke, wasa little optimistic in predicting when an arti\ufb01cial agent such as HAL would be avail-able. But just how far off was he? What would it take to create at least the language-relatedpartsofHAL?WecallprogramslikeHALthatconversewithhumansinnatural"
            },
            "slug": "Speech-and-Language-Processing-Jurafsky-Martin",
            "title": {
                "fragments": [],
                "text": "Speech and Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144321599"
                        ],
                        "name": "M. McGill",
                        "slug": "M.-McGill",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "McGill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. McGill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 174
                            }
                        ],
                        "text": "Vector addition is used throughout vector space approaches to information retrieval to compute vectors for documents and multiword queries from vectors for individual terms (Salton & McGill 1983; Baeza-Yates & Ribiero-Neto 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 43685115,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "49af3e80343eb80c61e727ae0c27541628c7c5e2",
            "isKey": false,
            "numCitedBy": 12605,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Some people may be laughing when looking at you reading in your spare time. Some may be admired of you. And some may want be like you who have reading hobby. What about your own feel? Have you felt right? Reading is a need and a hobby at once. This condition is the on that will make you feel that you must read. If you know are looking for the book enPDFd introduction to modern information retrieval as the choice of reading, you can find here."
            },
            "slug": "Introduction-to-Modern-Information-Retrieval-Salton-McGill",
            "title": {
                "fragments": [],
                "text": "Introduction to Modern Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Reading is a need and a hobby at once and this condition is the on that will make you feel that you must read."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 149
                            }
                        ],
                        "text": "Tensor products are comparatively little known in computational linguistics and artificial intelligence, though their use was initially advocated by Smolensky (1990)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 125580247,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9438172bfbb74a6a4ea4242b180d4335bb1f18b7",
            "isKey": false,
            "numCitedBy": 642,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: 1. Introduction, 2. Connectionist Representation and Tensor Product Binding: Definition and Examples, 3. Tensor Product Representation: Properties, 4. Conclusion"
            },
            "slug": "Tensor-Product-Variable-Binding-and-the-of-Symbolic-Hinton",
            "title": {
                "fragments": [],
                "text": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This chapter contains sections titled connectionist Representation and Tensor Product Binding: Definition and Examples, and tensor Product Representation: Properties."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145784991"
                        ],
                        "name": "V. Varadarajan",
                        "slug": "V.-Varadarajan",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Varadarajan",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Varadarajan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 272
                            }
                        ],
                        "text": "In a confusion of terminology, many computer scientists and mathematical linguists refer to this non-distributive structure as a \u201cnon-standard logic\u201d, whereas mathematical physicists explicitly refer to logics derived from lattices in Hilbert spaces as the \u201cstandard logics\u201d (Varadarajan 1985)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 111370874,
            "fieldsOfStudy": [
                "Physics",
                "Mathematics"
            ],
            "id": "3f5073e36438613cb9e16d08f967d2d7c0855ab8",
            "isKey": false,
            "numCitedBy": 842,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Boolean Algebras on a Classical Phase Space.- Projective Geometries.- The Logic of a Quantum Mechanical System.- Logics Associated with Hilbert Spaces.- Measure Theory on G-Spaces.- Systems of Imprimitivity.- Multipliers.- Kinematics and Dynamics.- Relativistic Free Particles."
            },
            "slug": "Geometry-of-quantum-theory-Varadarajan",
            "title": {
                "fragments": [],
                "text": "Geometry of quantum theory"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143955159"
                        ],
                        "name": "W. Fulton",
                        "slug": "W.-Fulton",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fulton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fulton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145357965"
                        ],
                        "name": "Joe W. Harris",
                        "slug": "Joe-W.-Harris",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Harris",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joe W. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "Again, we are forced to be brief and refer readers to more detailed textbooks in linear and multilinear algebra for more detail (Ja\u0308nich 1994; Fulton & Harris 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 64
                            }
                        ],
                        "text": "The tensor product may be defined in terms of multilinear maps (Fulton & Harris 1991, Appendix A), though a simpler initial intuition can be obtained by a matrix description: if the vector x has coordinates xi and the vector y has coordinates yj then the tensor product x \u2297 y is represented by the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118744956,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18012d93392ab0132341cc42823b677c06b51e53",
            "isKey": false,
            "numCitedBy": 2981,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This volume represents a series of lectures which aims to introduce the beginner to the finite dimensional representations of Lie groups and Lie algebras. Following an introduction to representation theory of finite groups, the text explains how to work out the representations of classical groups."
            },
            "slug": "Representation-Theory:-A-First-Course-Fulton-Harris",
            "title": {
                "fragments": [],
                "text": "Representation Theory: A First Course"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This volume represents a series of lectures which aims to introduce the beginner to the finite dimensional representations of Lie groups and Lie algebras."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993044131"
                        ],
                        "name": "\u674e\u5e7c\u5347",
                        "slug": "\u674e\u5e7c\u5347",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "\u674e\u5e7c\u5347",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u674e\u5e7c\u5347"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6622887"
                        ],
                        "name": "F. G. J. Hayhoe",
                        "slug": "F.-G.-J.-Hayhoe",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Hayhoe",
                            "middleNames": [
                                "G.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. G. J. Hayhoe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 222242179,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "0e9a7789ec7cfc34a1bb953530a0e57bd0e8d018",
            "isKey": false,
            "numCitedBy": 40986,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The following is a fundamental reading list for doctoral candidates to use as a guide in preparing for their comprehensive examination in the field of Modernism. A student is expected to have read widely in the field; to be thoroughly familiar with the major writers; and to read widely in the journal literature. The following reading list is suggestive rather than definitive, a list for the student and Committee on Studies to begin with. The list has four sections: \u2022 Poetry \u2022 Drama \u2022 Fiction \u2022 Secondary Sources"
            },
            "slug": "Ph-\u674e\u5e7c\u5347-Hayhoe",
            "title": {
                "fragments": [],
                "text": "Ph"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16185809"
                        ],
                        "name": "G. Boole",
                        "slug": "G.-Boole",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Boole",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Boole"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 476,
                                "start": 19
                            }
                        ],
                        "text": "The work of George Boole and Gottlob Frege in the 19 century pioneered a new era of research and development in mathematical linguistics: that is, the application of mathematical and logical methods to the study and representation of human language. Grandees of this field in the 20 century include Tarski, Montague, Fodor: a survey of this huge area is beyond the scope of this paper, though an interested reader should perhaps begin with Partee, ter Meulen, and Wall (1993). Significantly for the purposes of this paper, the point we would like to emphasize is that this tradition has been strongly influenced by a maxim that has become known as \u201cFrege\u2019s context principle\u201d or \u201cFrege\u2019s principle of compositionality\u201d, which may be translated as"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 12
                            }
                        ],
                        "text": "The work of George Boole and Gottlob Frege in the 19th century pioneered a new era of research and development in mathematical linguistics: that is, the application of mathematical and logical methods to the study and representation of human language."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 177
                            }
                        ],
                        "text": "Half-a-century before the work of Frege, Boole introduced the algebra of logical connectives, and specifically intended them to be used to model statements in natural language (Boole 1854)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 52
                            }
                        ],
                        "text": "The first attempts to incorporate something akin to Boolean operators into vector models for information retrieval was in the work of Salton, Fox, & Wu (1983). This work uses p-norms to normalize a sum of query terms, defined by"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60843160,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science",
                "Philosophy"
            ],
            "id": "b1f13aa59dc268e1e16adb2d967d313ca4a39d07",
            "isKey": true,
            "numCitedBy": 798,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Investigation-of-the-Laws-of-Thought-Boole",
            "title": {
                "fragments": [],
                "text": "An Investigation of the Laws of Thought"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1854
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "(See (van Rijsbergen 2004) and also (Widdows 2004, Ch 7).)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 279
                            }
                        ],
                        "text": "\u2026small, they were performed using vectors from large empirical semantic vector spaces built using the 100 million word British National Corpus1 and the Infomap NLP software2, which uses singular value decomposition to create a reduced wordspace from a large cooccurrence matrix (Widdows 2004, Ch 6)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 142
                            }
                        ],
                        "text": "Semantic vector models are by now a recognized part of mainstream computational linguistics, and are sometimes described as wordspace models (Widdows 2004; Sahlgren 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 42
                            }
                        ],
                        "text": "Word sense discrimination first uses clustering of word vectors to obtain clusters that can be interpreted as word senses, uses vector addition of terms in a given context window to form a context vector for each occurrence, and then assigns each occurrence to a word sense using cosine similarity."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 0
                            }
                        ],
                        "text": "Widdows (2004) also suggests that projections may be used to model the way a phrase like \u201ctiger moth\u201d selects the appropriate feature of \u201ctiger\u201d as a modifier to the \u201cmoth\u201d concept."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 79
                            }
                        ],
                        "text": "For an introduction to vector addition, cosine similarity and clustering, see (Widdows 2004, Ch. 5,6)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 57
                            }
                        ],
                        "text": "Tensor products and multilinear algebra are one answer to this question."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 82
                            }
                        ],
                        "text": "Again, a search engine may respond with informative documents, but only if one of the authors has written a document that conveniently says words to the effect that \u201cThis moth with black and orange stripes is called a tiger moth.\u201d"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Geometry and Meaning. Stanford, California: CSLI publications"
            },
            "venue": {
                "fragments": [],
                "text": "Geometry and Meaning. Stanford, California: CSLI publications"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102086451"
                        ],
                        "name": "W. Greub",
                        "slug": "W.-Greub",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Greub",
                            "middleNames": [
                                "Hildbert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Greub"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 126124770,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7fe7f7a21495d66a8659f9c5aba9a3b7d1fe2e92",
            "isKey": false,
            "numCitedBy": 2359,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linear-Algebra-Greub",
            "title": {
                "fragments": [],
                "text": "Linear Algebra"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46248115"
                        ],
                        "name": "G. Frege",
                        "slug": "G.-Frege",
                        "structuredName": {
                            "firstName": "Gottlob",
                            "lastName": "Frege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Frege"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 1
                            }
                        ],
                        "text": "(Frege 1884, \u00a760); see also (Szabo\u0301 2007)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 125236780,
            "fieldsOfStudy": [
                "Philosophy"
            ],
            "id": "b66046d4504653664ba1ee338b25f0bcd3d4c440",
            "isKey": false,
            "numCitedBy": 670,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Foundations-of-Arithmetic-Frege",
            "title": {
                "fragments": [],
                "text": "The Foundations of Arithmetic"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1884
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705425"
                        ],
                        "name": "P. Kantor",
                        "slug": "P.-Kantor",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Kantor",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kantor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 143
                            }
                        ],
                        "text": "This is not to say that natural language processing does not have some tools to offer: for example, collocation extraction tools (Smadja 1993; Manning & Schu\u0308tze 1999) may be used to help with extracting nounphrases and indexing them accordingly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 100
                            }
                        ],
                        "text": "In a larger\nsurvey, other models could well be included such as a (smoothed) collection of n-grams (Manning & Schu\u0308tze 1999, Ch. 6), relations in a lexical network such as WordNet (Fellbaum 1998), and a traditional dictionary definition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 115386587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6805f60d07f4618de4a1d1e2b9c266863ed8311e",
            "isKey": false,
            "numCitedBy": 2889,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Foundations-of-Statistical-Natural-Language-Kantor",
            "title": {
                "fragments": [],
                "text": "Foundations of Statistical Natural Language Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705950"
                        ],
                        "name": "E. Fox",
                        "slug": "E.-Fox",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Fox",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112226698"
                        ],
                        "name": "Harry Wu",
                        "slug": "Harry-Wu",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harry Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207180535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b7cbdd9e7fca94e686d726442d94635378ae04f",
            "isKey": false,
            "numCitedBy": 1079,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In conventional information retrieval Boolean combinations of index terms are used to formulate the users'' information requests. While any document is in principle retrievable by a Boolean query, the amount of output obtainable by Boolean processing is difficult to control, and the retrieved items are not ranked in any presumed order of importance to the user population. In the vector processing model of retrieval, the retrieved items are easily ranked in decreasing order of the query-record similarity, but the queries themselves are unstructured and expressed as simple sets of weighted index terms. A new, extended Boolean information retrieval system is introduced which is intermediate between the Boolean system of query processing and the vector processing model. The query structure inherent in the Boolean system is preserved, while at the same time weighted terms may be incorporated into both queries and stored documents; the retrieved output can also be ranked in strict similarity order with the user queries. A conventional retrieval system can be modified to make use of the extended system. Laboratory tests indicate that the extended system produces better retrieval output than either the Boolean or the vector processing systems."
            },
            "slug": "Extended-Boolean-information-retrieval-Salton-Fox",
            "title": {
                "fragments": [],
                "text": "Extended Boolean information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new, extended Boolean information retrieval system is introduced which is intermediate between the Boolean system of query processing and the vector processing model, and Laboratory tests indicate that the extended system produces better retrieval output than either the Boolean or thevector processing systems."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755431"
                        ],
                        "name": "P. Bruza",
                        "slug": "P.-Bruza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bruza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bruza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782059"
                        ],
                        "name": "W. Lawless",
                        "slug": "W.-Lawless",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Lawless",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lawless"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69044360"
                        ],
                        "name": "Keith van Rijsbergen",
                        "slug": "Keith-van-Rijsbergen",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Rijsbergen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Keith van Rijsbergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32358325"
                        ],
                        "name": "D. Sofge",
                        "slug": "D.-Sofge",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Sofge",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sofge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026are formed by taking this projection a step further: each diagonal is wrapped round, effectively summing the kth and k + nth entries of the convolution product to give a HRR product of dimension n. Plate used HRRs to model semantic composition in a number of simulated and hand-built experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 107877881,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "ece5274d7927792c9d9a82cde2b35055bd3bbd64",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Quantum-interaction-:-Papers-from-the-AAAI-Spring-:-Bruza-Lawless",
            "title": {
                "fragments": [],
                "text": "Quantum interaction : Papers from the AAAI Spring Symposium : Technical Report SS-07-08"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 19
                            }
                        ],
                        "text": "Still further, a \u201clong book\u201d takes a long time to read, and a \u201clong light\u201d is a traffic light that takes a long time to change."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 142
                            }
                        ],
                        "text": "Again, we are forced to be brief and refer readers to more detailed textbooks in linear and multilinear algebra for more detail (Ja\u0308nich 1994; Fulton & Harris 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 64
                            }
                        ],
                        "text": "The tensor product may be defined in terms of multilinear maps (Fulton & Harris 1991, Appendix A), though a simpler initial intuition can be obtained by a matrix description: if the vector x has coordinates xi and the vector y has coordinates yj then the tensor product x \u2297 y is represented by the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representation theory a first course. Number 129 in Graduate Texts in Mathematics"
            },
            "venue": {
                "fragments": [],
                "text": "Representation theory a first course. Number 129 in Graduate Texts in Mathematics"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 196
                            }
                        ],
                        "text": "Vector addition is used throughout vector space approaches to information retrieval to compute vectors for documents and multiword queries from vectors for individual terms (Salton & McGill 1983; Baeza-Yates & Ribiero-Neto 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modern Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Addison Wesley / ACM Press."
            },
            "year": 1999
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 24,
            "methodology": 16,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 42,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Semantic-Vector-Products:-Some-Initial-Widdows/7c69a90236f1c57348de858918c554a9420f1521?sort=total-citations"
}