{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "Since only the supervised fine-tuning phase requires labeled data, we can potentially leverage a large quantity of unlabeled data during pre-training, although this capability is not yet important for our LVSR experiments [69] due to the abundance of weakly supervised data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18141431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecd4bc32bb2717c96f76dd100fcd1255a07bd656",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, deep learning techniques have been successfully applied to automatic speech recognition tasks -first to phonetic recognition with context-independent deep belief network (DBN) hidden Markov models (HMMs) and later to large vocabulary continuous speech recognition using context-dependent (CD) DBN-HMMs. In this paper, we report our most recent experiments designed to understand the roles of the two main phases of the DBN learning -pre-training and fine tuning -in the recognition performance of a CD-DBN-HMM based large-vocabulary speech recognizer. As expected, we show that pre-training can initialize weights to a point in the space where fine-tuning can be effective and thus is crucial in training deep structured models. However, a moderate increase of the amount of unlabeled pre-training data has an insignificant effect on the final recognition results as long as the original training size is sufficiently large to initialize the DBN weights. On the other hand, with additional labeled training data, the fine-tuning phase of DBN training can significantly improve the recognition accuracy."
            },
            "slug": "Roles-of-Pre-Training-and-Fine-Tuning-in-DBN-HMMs-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that pre-training can initialize weights to a point in the space where fine-tuning can be effective and thus is crucial in training deep structured models and in the recognition performance of a CD-DBN-HMM based large-vocabulary speech recognizer."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242830"
                        ],
                        "name": "Victor Abrash",
                        "slug": "Victor-Abrash",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Abrash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Abrash"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 52
                            }
                        ],
                        "text": "Note that although these types of context-dependent ANN-HMMs outperformed GMM-HMMs for some tasks, the improvements were small."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "In addition to their inherently discriminative nature, ANN-HMMs have two additional advantages: the training can be performed using the embedded Viterbi algorithm and the decoding is generally quite efficient."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "ANN-HMMs were later extended to model context-dependent phones and were applied to mid-vocabulary and some large-vocabulary ASR tasks (e.g., in [45], which also employed recurrent neural architectures)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Our work differs from earlier context-dependent ANN-HMMs [42], [41] in two key respects."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 37480532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "583f48d72127c00e0499513c1b2f4e8ac71e4406",
            "isKey": true,
            "numCitedBy": 57,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper we present a training method and a network architecture for estimating context-dependent observation probabilities in the framework of a hybrid hidden Markov model (HMM)/multi layer perceptron (MLP) speaker-independent continuous speech recognition system. The context-dependent modeling approach we present here computes the HMM context-dependent observation probabilities using a Bayesian factorization in terms of context-conditioned posterior phone probabilities which are computed with a set of MLPs, one for every relevant context. The proposed network architecture shares the input-to-hidden layer among the set of context dependent MLPs in order to reduce the number of independent parameters. Multiple states for phone models with different context dependence for each state are used to model the different context effects at the beginning and end of phonetic segments. A new training procedure that \"smooths\" networks with different degrees of context dependence is proposed to obtain a robust estimate of the context-dependent probabilities. We have used this new architecture to model generalized biphone phonetic contexts. Tests with the speaker-independent DARPA Resource Management database have shown average reductions in word error rates of 28% using a word-pair grammar, compared to our earlier context-independent HMM/MLP hybrid."
            },
            "slug": "Context-dependent-connectionist-probability-in-a-Franco-Cohen",
            "title": {
                "fragments": [],
                "text": "Context-dependent connectionist probability estimation in a hybrid hidden Markov model-neural net speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A new training procedure that \"smooths\" networks with different degrees of context dependence is proposed to obtain a robust estimate of the context-dependent probabilities of the HMM/MLP speaker-independent continuous speech recognition system."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "This manuscript greatly extends the work presented at ICASSP 2011 [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6703261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2446e8f2012f23176ff602be633c0ed2b956d66c",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The context-independent deep belief network (DBN) hidden Markov model (HMM) hybrid architecture has recently achieved promising results for phone recognition. In this work, we propose a context-dependent DBN-HMM system that dramatically outperforms strong Gaussian mixture model (GMM)-HMM baselines on a challenging, large vocabulary, spontaneous speech recognition dataset from the Bing mobile voice search task. Our system achieves absolute sentence accuracy improvements of 5.8% and 9.2% over GMM-HMMs trained using the minimum phone error rate (MPE) and maximum likelihood (ML) criteria, respectively, which translate to relative error reductions of 16.0% and 23.2%."
            },
            "slug": "Large-vocabulary-continuous-speech-recognition-with-Dahl-Yu",
            "title": {
                "fragments": [],
                "text": "Large vocabulary continuous speech recognition with context-dependent DBN-HMMS"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes a context-dependent DBN-HMM system that dramatically outperforms strong Gaussian mixture model (GMM)-HMM baselines on a challenging, large vocabulary, spontaneous speech recognition dataset from the Bing mobile voice search task."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705919"
                        ],
                        "name": "Chuck Wooters",
                        "slug": "Chuck-Wooters",
                        "structuredName": {
                            "firstName": "Chuck",
                            "lastName": "Wooters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chuck Wooters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "However, in earlier work on context dependent ANN-HMM hybrid architectures [46], the posterior probability of the context-dependent phone was modeled as either"
                    },
                    "intents": []
                }
            ],
            "corpusId": 61017150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1116b32168ca91607d81e8aa6be64ee7b539449",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of theoretical and experimental results have suggested that multilayer perceptrons (MLPs) are an effective family of algorithms for the smooth estimate of highly dimensioned probability density functions that are useful in continuous speech recognition. All of these systems have exclusively used context-independent phonetic models, in the sense that the probabilities or costs are estimated for simple speech units such as phonemes or words, rather than biphones or triphones. Numerous conventional systems based on hidden Markov models (HMMs) have been reported that use triphone or triphone like context-dependent models. In one case the outputs of many context-dependent MLPs (one per context class) were used to help choose the best sentence from the N best sentences as determined by a context-dependent HMM system. It is shown how, without any simplifying assumptions, one can estimate likelihoods for context-dependent phonetic models with nets that are not substantially larger than context-independent MLPs.<<ETX>>"
            },
            "slug": "CDNN:-a-context-dependent-neural-network-for-speech-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "CDNN: a context dependent neural network for continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown how, without any simplifying assumptions, one can estimate likelihoods for context-dependent phonetic models with nets that are not substantially larger than context-independent MLPs."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "of MFCCs as the input features of the DNNs, following [30] and [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "demonstrated on the TIMIT dataset with some success [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10473793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0191c9b53a99942a9b4ec39dc30489e41c7aaa1",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, Deep Belief Networks (DBNs) have been proposed for phone recognition and were found to achieve highly competitive performance. In the original DBNs, only framelevel information was used for training DBN weights while it has been known for long that sequential or full-sequence information can be helpful in improving speech recognition accuracy. In this paper we investigate approaches to optimizing the DBN weights, state-to-state transition parameters, and language model scores using the sequential discriminative training criterion. We describe and analyze the proposed training algorithm and strategy, and discuss practical issues and how they affect the final results. We show that the DBNs learned using the sequence-based training criterion outperform those with frame-based criterion using both threelayer and six-layer models, but the optimization procedure for the deeper DBN is more difficult for the former criterion."
            },
            "slug": "Investigation-of-full-sequence-training-of-deep-for-Mohamed-Yu",
            "title": {
                "fragments": [],
                "text": "Investigation of full-sequence training of deep belief networks for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that the DBNs learned using the sequence-based training criterion outperform those with frame-based criterion using both threelayer and six-layer models, but the optimization procedure for the deeper DBN is more difficult for the former criterion."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "This second difference also distinguishes our work from earlier uses of DNN-HMM hybrids for phone recognition [30]\u2013[32],"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "For example, context-independent pre-trained, deep neural network HMM hybrid architectures have recently been proposed for phone recognition [30]\u2013[32] and have achieved very competitive performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "recognition tasks as was the case in [30]\u2013[32], [59]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "DNN-HMMs for phone recognition in [32]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2130362,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "90b63e917d5737b06357d50aa729619e933d9614",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Straightforward application of Deep Belief Nets (DBNs) to acoustic modeling produces a rich distributed representation of speech data that is useful for recognition and yields impressive results on the speaker-independent TIMIT phone recognition task. However, the first-layer Gaussian-Bernoulli Restricted Boltzmann Machine (GRBM) has an important limitation, shared with mixtures of diagonal-covariance Gaussians: GRBMs treat different components of the acoustic input vector as conditionally independent given the hidden state. The mean-covariance restricted Boltzmann machine (mcRBM), first introduced for modeling natural images, is a much more representationally efficient and powerful way of modeling the covariance structure of speech data. Every configuration of the precision units of the mcRBM specifies a different precision matrix for the conditional distribution over the acoustic space. In this work, we use the mcRBM to learn features of speech data that serve as input into a standard DBN. The mcRBM features combined with DBNs allow us to achieve a phone error rate of 20.5%, which is superior to all published results on speaker-independent TIMIT to date."
            },
            "slug": "Phone-Recognition-with-the-Mean-Covariance-Machine-Dahl-Ranzato",
            "title": {
                "fragments": [],
                "text": "Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work uses the mean-covariance restricted Boltzmann machine (mcRBM) to learn features of speech data that serve as input into a standard DBN, and achieves a phone error rate superior to all published results on speaker-independent TIMIT to date."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "obtain the result from [70], there may be other differences between our setup and the one used in [70] in addition to the larger training set."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "9% obtained in [70], even though the latter"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "In order to compare our results with [70], we would need to compute sentence accuracy anyway."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 1406894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6545ced234ab52e977d31b20643a3bcb9da6683",
            "isKey": true,
            "numCitedBy": 135,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a segmental conditional random field framework for large vocabulary continuous speech recognition. Fundamental to this approach is the use of acoustic detectors as the basic input, and the automatic construction of a versatile set of segment-level features. The detector streams operate at multiple time scales (frame, phone, multi-phone, syllable or word) and are combined at the word level in the CRF training and decoding processes. A key aspect of our approach is that features are defined at the word level, and are naturally geared to explain long span phenomena such as formant trajectories, duration, and syllable stress patterns. Generalization to unseen words is possible through the use of decomposable consistency features [1], [2], and our framework allows for the joint or separate discriminative training of the acoustic and language models. An initial evaluation of this framework with voice search data from the Bing Mobile (BM) application results in a 2% absolute improvement over an HMM baseline."
            },
            "slug": "A-segmental-CRF-approach-to-large-vocabulary-speech-Zweig-Nguyen",
            "title": {
                "fragments": [],
                "text": "A segmental CRF approach to large vocabulary continuous speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A segmental conditional random field framework for large vocabulary continuous speech recognition that allows for the joint or separate discriminative training of the acoustic and language models."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Workshop on Automatic Speech Recognition & Understanding"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316518"
                        ],
                        "name": "Yasser Hifny",
                        "slug": "Yasser-Hifny",
                        "structuredName": {
                            "firstName": "Yasser",
                            "lastName": "Hifny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yasser Hifny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Digital Object Identifier 10.1109/TASL.2011.2134090\nfields (CRFs) [18]\u2013[20], hidden CRFs [21], [22], and segmental CRFs [23])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "The idea of using senones as the modeling unit has been proposed in [22] where the posterior probabilities of senones were estimated using deep-structured conditional random fields (CRFs) and only one audio frame was used as the input of the posterior probability estimator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "2134090 fields (CRFs) [18]\u2013[20], hidden CRFs [21], [22], and segmental CRFs [23])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "The recently proposed CRF [18]\u2013[20] and HCRF [21], [22] models use log-linear models to replace GMM-HMMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 951317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df5b82595a29724467a98eed4d7e2a45e804579e",
            "isKey": true,
            "numCitedBy": 94,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": "Acoustic modeling based on hidden Markov models (HMMs) is employed by state-of-the-art stochastic speech recognition systems. Although HMMs are a natural choice to warp the time axis and model the temporal phenomena in the speech signal, their conditional independence properties limit their ability to model spectral phenomena well. In this paper, a new acoustic modeling paradigm based on augmented conditional random fields (ACRFs) is investigated and developed. This paradigm addresses some limitations of HMMs while maintaining many of the aspects which have made them successful. In particular, the acoustic modeling problem is reformulated in a data driven, sparse, augmented space to increase discrimination. Acoustic context modeling is explicitly integrated to handle the sequential phenomena of the speech signal. We present an efficient framework for estimating these models that ensures scalability and generality. In the TIMIT phone recognition task, a phone error rate of 23.0% was recorded on the full test set, a significant improvement over comparable HMM-based systems."
            },
            "slug": "Speech-Recognition-Using-Augmented-Conditional-Hifny-Renals",
            "title": {
                "fragments": [],
                "text": "Speech Recognition Using Augmented Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new acoustic modeling paradigm based on augmented conditional random fields (ACRFs) is investigated and developed, which addresses some limitations of HMMs while maintaining many of the aspects which have made them successful."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "recognition tasks as was the case in [30]\u2013[32], [59]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "of MFCCs as the input features of the DNNs, following [30] and [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "For example, context-independent pre-trained, deep neural network HMM hybrid architectures have recently been proposed for phone recognition [30]\u2013[32] and have achieved very competitive performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "Even the largest models we use in this work are comparable in size to ones used on TIMIT by [30], even though we use a much larger dataset here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "This second difference also distinguishes our work from earlier uses of DNN-HMM hybrids for phone recognition [30]\u2013[32],"
                    },
                    "intents": []
                }
            ],
            "corpusId": 131773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37cfdc4520c56c1eaf87cee5ec2a4028ceaa9c5",
            "isKey": false,
            "numCitedBy": 406,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov Models (HMMs) have been the state-of-the-art techniques for acoustic modeling despite their unrealistic independence assumptions and the very limited representational capacity of their hidden states. There are many proposals in the research community for deeper models that are capable of modeling the many types of variability present in the speech generation p r cess. Deep Belief Networks (DBNs) have recently proved to be very effective fo r a variety of machine learning problems and this paper applies DBNs to acous ti modeling. On the standard TIMIT corpus, DBNs consistently outperform ot her techniques and the best DBN achieves a phone error rate (PER) of 23.0% on the T IMIT core test set."
            },
            "slug": "Deep-Belief-Networks-for-phone-recognition-Mohamed-Dahl",
            "title": {
                "fragments": [],
                "text": "Deep Belief Networks for phone recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Deep Belief Networks (DBNs) have recently proved to be very effective in a variety of machine learning problems and this paper applies DBNs to acous ti modeling."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2452389"
                        ],
                        "name": "E. McDermott",
                        "slug": "E.-McDermott",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "McDermott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. McDermott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798550"
                        ],
                        "name": "Timothy J. Hazen",
                        "slug": "Timothy-J.-Hazen",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Hazen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timothy J. Hazen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9332945"
                        ],
                        "name": "Jonathan Le Roux",
                        "slug": "Jonathan-Le-Roux",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Le Roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Le Roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726970"
                        ],
                        "name": "A. Nakamura",
                        "slug": "A.-Nakamura",
                        "structuredName": {
                            "firstName": "Atsushi",
                            "lastName": "Nakamura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Nakamura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715709"
                        ],
                        "name": "S. Katagiri",
                        "slug": "S.-Katagiri",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Katagiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Katagiri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1044834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7bdb332ce9a601cdd1d0f12685eab6d8b8374250",
            "isKey": false,
            "numCitedBy": 623,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "The minimum classification error (MCE) framework for discriminative training is a simple and general formalism for directly optimizing recognition accuracy in pattern recognition problems. The framework applies directly to the optimization of hidden Markov models (HMMs) used for speech recognition problems. However, few if any studies have reported results for the application of MCE training to large-vocabulary, continuous-speech recognition tasks. This article reports significant gains in recognition performance and model compactness as a result of discriminative training based on MCE training applied to HMMs, in the context of three challenging large-vocabulary (up to 100 k word) speech recognition tasks: the Corpus of Spontaneous Japanese lecture speech transcription task, a telephone-based name recognition task, and the MIT Jupiter telephone-based conversational weather information task. On these tasks, starting from maximum likelihood (ML) baselines, MCE training yielded relative reductions in word error ranging from 7% to 20%. Furthermore, this paper evaluates the use of different methods for optimizing the MCE criterion function, as well as the use of precomputed recognition lattices to speed up training. An overview of the MCE framework is given, with an emphasis on practical implementation issues"
            },
            "slug": "Discriminative-Training-for-Large-Vocabulary-Speech-McDermott-Hazen",
            "title": {
                "fragments": [],
                "text": "Discriminative Training for Large-Vocabulary Speech Recognition Using Minimum Classification Error"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This article reports significant gains in recognition performance and model compactness as a result of discriminative training based on MCE training applied to HMMs, in the context of three challenging large-vocabulary speech recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "The idea of using senones as the modeling unit has been proposed in [22] where the posterior probabilities of senones were estimated using deep-structured conditional random fields (CRFs) and only one audio frame was used as the input of the posterior probability estimator."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "2134090 fields (CRFs) [18]\u2013[20], hidden CRFs [21], [22], and segmental CRFs [23])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "The recently proposed CRF [18]\u2013[20] and HCRF [21], [22] models use log-linear models to replace GMM-HMMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12952692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "622a40854f79fb385b61f1a3de1cdce4999e9f4b",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend our earlier work on deep-structured conditional random field (DCRF) and develop deep-structured hidden conditional random field (DHCRF). We investigate the use of this new sequential deep-learning model for phonetic recognition. DHCRF is a hierarchical model in which the final layer is a hidden conditional random field (HCRF) and the intermediate layers are zero-th-order conditional random fields (CRFs). Parameter estimation and sequence inference in the DHCRF are developed in this work. They are carried out layer by layer so that the time complexity is linear to the number of layers. In the DHCRF, the training label is available only at the final layer and the state boundary is unknown. This difficulty is addressed by using unsupervised learning for the intermediate layers and lattice-based supervised learning for the final layer. Experiments on the standard TIMIT phone recognition task show small performance improvement of a three-layer DHCRF over a two-layer DHCRF; both are significantly better than the single-layer DHCRF and are superior to the discriminatively trained tri-phone hidden Markov model (HMM) using identical input features."
            },
            "slug": "Deep-structured-hidden-conditional-random-fields-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "Deep-structured hidden conditional random fields for phonetic recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Both the DHCRF and the HMM are superior to the discriminatively trained tri-phone hidden Markov model using identical input features and the use of this new sequential deep-learning model for phonetic recognition is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9024683"
                        ],
                        "name": "Q. Zhu",
                        "slug": "Q.-Zhu",
                        "structuredName": {
                            "firstName": "Qifeng",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108424673"
                        ],
                        "name": "Barry Y. Chen",
                        "slug": "Barry-Y.-Chen",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Chen",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barry Y. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11915797,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "f34c19c1eb5b034fefe74c70452041741935797e",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the development of a speech recognition system for conversational telephone speech (CTS) that incorporates acoustic features estimated by multilayer perceptrons (MLP). The acoustic features are based on frame-level phone posterior probabilities, obtained by merging two different MLP estimators, one based on PLP-Tandem features, the other based on hidden activation TRAPs (HATs) features. This paper focuses on the challenges arising when incorporating these nonstandard features into a full-scale speech-to-text (STT) system, as used by SRI in the Fall 2004 DARPA STT evaluations. First, we developed a series of time-saving techniques for training feature MLPs on 1800 hours of speech. Second, we investigated which components of a multipass, multi-front-end recognition system are most profitably augmented with MLP features for best overall performance. The final system obtained achieved a 2% absolute (10% relative) WER reduction over a comparable baseline system that did not include Tandem/HATs MLP features."
            },
            "slug": "Using-MLP-features-in-SRI's-conversational-speech-Zhu-Stolcke",
            "title": {
                "fragments": [],
                "text": "Using MLP features in SRI's conversational speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The development of a speech recognition system for conversational telephone speech that incorporates acoustic features estimated by multilayer perceptrons (MLP) and which components of a multipass, multi-front-end recognition system are most profitably augmented with MLP features for best overall performance is described."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "recognition tasks as was the case in [30]\u2013[32], [59]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Note that [59], which also appears in this issue, is the context-independent version of our approach and builds the foundation for our work."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9530137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2b62f77cb2864e465aa60bca6c26bb1d2f84963",
            "isKey": false,
            "numCitedBy": 1641,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models."
            },
            "slug": "Acoustic-Modeling-Using-Deep-Belief-Networks-Mohamed-Dahl",
            "title": {
                "fragments": [],
                "text": "Acoustic Modeling Using Deep Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2280399"
                        ],
                        "name": "G. Heigold",
                        "slug": "G.-Heigold",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Heigold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Heigold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "typically use manually designed features and have been shown to be equivalent to the GMM-HMM [20] in their modeling ability if only the first and second order statistics are used as the features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "2134090 fields (CRFs) [18]\u2013[20], hidden CRFs [21], [22], and segmental CRFs [23])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "The recently proposed CRF [18]\u2013[20] and HCRF [21], [22] models use log-linear models to replace GMM-HMMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20980516,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d82354fab1c800f3a50632d1371f083348af0971",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 303,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional speech recognition systems are based on Gaussian hidden Markov models (HMMs). Discriminative techniques such as log-linear modeling have been investigated in speech recognition only recently. This thesis establishes a log-linear modeling framework in the context of discriminative training criteria, with examples from continuous speech recognition, part-of-speech tagging, and handwriting recognition. The focus will be on the theoretical and experimental comparison of different training algorithms. Equivalence relations for Gaussian and log-linear models in speech recognition are derived. It is shown how to incorporate a margin term into conventional discriminative training criteria like for example minimum phone error (MPE). This permits to evaluate directly the utility of the margin concept for string recognition. The equivalence relations and the margin-based training criteria lead to a unified view of three major training paradigms, namely Gaussian HMMs, log-linear models, and support vector machines (SVMs). Generalized iterative scaling (GIS) is traditionally used for the optimization of log-linear models with the maximum mutual information (MMI) criterion. This thesis suggests an extension of GIS to log-linear models including hidden variables, and to other training criteria (e.g. MPE). Finally, investigations on convex optimization in speech recognition are presented. Experimental results are provided for a variety of tasks, including the European Parliament plenary sessions task and Mandarin broadcasts."
            },
            "slug": "A-log-linear-discriminative-modeling-framework-for-Heigold",
            "title": {
                "fragments": [],
                "text": "A log-linear discriminative modeling framework for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A log-linear modeling framework is established in the context of discriminative training criteria, with examples from continuous speech recognition, part-of-speech tagging, and handwriting recognition, and the focus will be on the theoretical and experimental comparison of different training algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17366942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7952e8cb5e90b5e8bcd1fd955474d74d7cbeb43e",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative training has been a leading factor for improving automatic speech recognition (ASR) performance over the last decade. The traditional discriminative training, however, has been aimed to minimize empirical error rates on training sets, which may not be well generalized to test sets. Many attempts have been made recently to incorporate the principle of large margin (PLM) into the training of hidden Markov models (HMMs) in ASR to improve the generalization abilities. Significant error rate reduction on the test sets has been observed on both small vocabulary and large vocabulary continuous ASR tasks using large-margin discriminative training (LMDT) techniques. In this paper, we introduce the PLM, define the concept of margin in the HMMs, and survey a number of popular LMDT algorithms proposed and developed recently. Specifically, we review and compare the large-margin minimum classification error (LM-MCE) estimation, soft-margin estimation (SME), large margin estimation (LME), large relative margin estimation (LRME), and large margin training (LMT) with a focus on the insights, the training criteria, the optimization techniques used, and the strengths and weaknesses of these different approaches. We suggest future research directions in our conclusion of this paper."
            },
            "slug": "Large-Margin-Discriminative-Training-of-Hidden-for-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "Large-Margin Discriminative Training of Hidden Markov Models for Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The PLM is introduced, the concept of margin in the HMMs is defined, a number of popular LMDT algorithms proposed and developed recently are surveyed, and the strengths and weaknesses of these different approaches are compared."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Semantic Computing (ICSC 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108186844"
                        ],
                        "name": "Xinwei Li",
                        "slug": "Xinwei-Li",
                        "structuredName": {
                            "firstName": "Xinwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinwei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36357862"
                        ],
                        "name": "Hui Jiang",
                        "slug": "Hui-Jiang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2509110"
                        ],
                        "name": "Chaojun Liu",
                        "slug": "Chaojun-Liu",
                        "structuredName": {
                            "firstName": "Chaojun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chaojun Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35047936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebe746d2000448bc226ac93a86b20a24c191f1ce",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Motivated by large margin classifiers in machine learning, we propose a novel method to estimate a continuous density hidden Markov model (CDHMM) in speech recognition according to the principle of maximizing the minimum multi-class separation margin. The approach is named large margin HMM. First, we show that this type of large margin HMM estimation problem can be formulated as a standard constrained minimax optimization problem. Second, we propose an iterative localized optimization approach to perform the minimax optimization for one model at a time to guarantee that the optimal value of the objective function always exists in the course of model parameter optimization. Then, we show that during each step the optimization can be solved by the GPD (generalized probabilistic descent) algorithm if we approximate the objective function by a differentiable function, such as summation of exponential functions. The large margin HMM-based classifiers are evaluated in a speaker-independent E-set speech recognition task using the OGI ISOLET database. Experimental results show that the large margin HMMs can achieve significant word error rate (WER) reduction over conventional HMM training methods, such as maximum likelihood estimation (MLE) and minimum classification error (MCE) training."
            },
            "slug": "Large-margin-HMMs-for-speech-recognition-Li-Jiang",
            "title": {
                "fragments": [],
                "text": "Large margin HMMs for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experimental results show that the large margin HMM-based classifiers can achieve significant word error rate (WER) reduction over conventional HMM training methods, such as maximum likelihood estimation (MLE) and minimum classification error (MCE) training."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "Although dividing by the prior probability p(qt) (called scaled likelihood estimation by [38], [40], [41]) may not give im-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61058350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d82e058a5c40954b8f5db170a298a889a254c37",
            "isKey": false,
            "numCitedBy": 1409,
            "numCiting": 190,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nConnectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state-of-the-art continuous speech recognition systems based on Hidden Markov Models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e., HMM emission probability estimation and feature extraction. The book describes a successful five year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical system. Using standard databases and comparing with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods. Connectionist Speech Recognition: A Hybrid Approach is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. This book is also suitable as a text for advanced courses on neural networks or speech processing."
            },
            "slug": "Connectionist-Speech-Recognition:-A-Hybrid-Approach-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist Speech Recognition: A Hybrid Approach"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2727489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c13f4eedbe98bca38c22e0d67f514a987b2b83f4",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new toolkit SCARF for doing speech recognition with segmental conditional random fields. It is designed to allow for the integration of numerous, possibly redundant segment level acoustic features, along with a complete language model, in a coherent speech recognition framework. SCARF performs a segmental analysis, where each segment corresponds to a word, thus allowing for the incorporation of acoustic features defined at the phoneme, multi-phone, syllable and word level. SCARF is designed to make it especially convenient to use acoustic detection events as input, such as the detection of energy bursts, phonemes, or other events. Language modeling is done by associating each state in the SCRF with a state in an underlying n-gram language model, and SCARF supports the joint and discriminative training of language model and acoustic model parameters. SCARF is available for download from http://research.microsoft.com/en-us/projects/scarf/"
            },
            "slug": "SCARF:-a-segmental-conditional-random-field-toolkit-Zweig-Nguyen",
            "title": {
                "fragments": [],
                "text": "SCARF: a segmental conditional random field toolkit for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new toolkit SCARF for doing speech recognition with segmental conditional random fields, designed to allow for the integration of numerous, possibly redundant segment level acoustic features, along with a complete language model, in a coherent speech recognition framework."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109947002"
                        ],
                        "name": "Sangita Sharma",
                        "slug": "Sangita-Sharma",
                        "structuredName": {
                            "firstName": "Sangita",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangita Sharma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "Although this work uses the hybrid approach, as alluded to above, much recent work using neural networks in acoustic modeling uses the so-called TANDEM approach, first proposed in [49]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5807992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e9082caea65c76bfd23b8763872804473ee7872",
            "isKey": false,
            "numCitedBy": 805,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov model speech recognition systems typically use Gaussian mixture models to estimate the distributions of decorrelated acoustic feature vectors that correspond to individual subword units. By contrast, hybrid connectionist-HMM systems use discriminatively-trained neural networks to estimate the probability distribution among subword units given the acoustic observations. In this work we show a large improvement in word recognition performance by combining neural-net discriminative feature processing with Gaussian-mixture distribution modeling. By training the network to generate the subword probability posteriors, then using transformations of these estimates as the base features for a conventionally-trained Gaussian-mixture based system, we achieve relative error rate reductions of 35% or more on the multicondition Aurora noisy continuous digits task."
            },
            "slug": "Tandem-connectionist-feature-extraction-for-HMM-Hermansky-Ellis",
            "title": {
                "fragments": [],
                "text": "Tandem connectionist feature extraction for conventional HMM systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A large improvement in word recognition performance is shown by combining neural-net discriminative feature processing with Gaussian-mixture distribution modeling."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777280"
                        ],
                        "name": "Y. Gong",
                        "slug": "Y.-Gong",
                        "structuredName": {
                            "firstName": "Yifan",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026by the prior probability (called scaled likelihood estimation by [38], [40], [41]) may not give improved recognition accuracy under some conditions, we have found it to be very important in alleviating the label bias problem, especially when the training utterances contain long silence segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7883803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c05a3a8d13668adbd2cec2c4ff08989ad87cfe7",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new framework and the associated maximum-likelihood and discriminative training algorithms for the variable-parameter hidden Markov model (VPHMM) whose mean and variance parameters vary as functions of additional environment-dependent conditioning parameters. Our framework differs from the VPHMM proposed by Cui and Gong (2007) in that piecewise spline interpolation instead of global polynomial regression is used to represent the dependency of the HMM parameters on the conditioning parameters, and a more effective functional form is used to model the variances. Our framework unifies and extends the conventional discrete VPHMM. It no longer requires quantization in estimating the model parameters and can support both parameter sharing and instantaneous conditioning parameters naturally. We investigate the strengths and weaknesses of the model on the Aurora-3 corpus. We show that under the well-matched condition the proposed discriminatively trained VPHMM outperforms the conventional HMM trained in the same way with relative word error rate (WER) reduction of 19% and 15%, respectively, when only mean is updated and when both mean and variances are updated."
            },
            "slug": "A-Novel-Framework-and-Training-Algorithm-for-Hidden-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "A Novel Framework and Training Algorithm for Variable-Parameter Hidden Markov Models"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that under the well-matched condition the proposed discriminatively trained VPHMM outperforms the conventional HMM trained in the same way with relative word error rate (WER) reduction of 19% and 15%, respectively, when only mean is updated and when both mean and variances are updated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2316043"
                        ],
                        "name": "Qiang Huo",
                        "slug": "Qiang-Huo",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Huo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Huo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2810210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15c27aa8b55f91dea542413a9645ee9873f33463",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 209,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in automatic speech recognition are accomplished by designing a plug-in maximum a posteriori decision rule such that the forms of the acoustic and language model distributions are specified and the parameters of the assumed distributions are estimated from a collection of speech and language training corpora. Maximum-likelihood point estimation is by far the most prevailing training method. However, due to the problems of unknown speech distributions, sparse training data, high spectral and temporal variabilities in speech, and possible mismatch between training and testing conditions, a dynamic training strategy is needed. To cope with the changing speakers and speaking conditions in real operational conditions for high-performance speech recognition, such paradigms incorporate a small amount of speaker and environment specific adaptation data into the training process. Bayesian adaptive learning is an optimal way to combine prior knowledge in an existing collection of general models with a new set of condition-specific adaptation data. In this paper, the mathematical framework for Bayesian adaptation of acoustic and language model parameters is first described. Maximum a posteriori point estimation is then developed for hidden Markov models and a number of useful parameters densities commonly used in automatic speech recognition and natural language processing."
            },
            "slug": "On-adaptive-decision-rules-and-decision-parameter-Lee-Huo",
            "title": {
                "fragments": [],
                "text": "On adaptive decision rules and decision parameter adaptation for automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The mathematical framework for Bayesian adaptation of acoustic and language model parameters is first described, and maximum a posteriori point estimation is developed for hidden Markov models and a number of useful parameters densities commonly used in automatic speech recognition and natural language processing."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 571789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "677160bfb207cdd4ac0328e276d1b91b81f6b918",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, we have developed a novel discriminative training method named large-margin minimum classification error (LM-MCE) training that incorporates the idea of discriminative margin into the conventional minimum classification error (MCE) training method. In our previous work, this novel approach was formulated specifically for the MCE training using the sigmoid loss function and its effectiveness was demonstrated on the TIDIGITS task alone. In this paper two additional contributions are made. First, we formulate LM-MCE as a Bayes risk minimization problem whose loss function not only includes empirical error rates but also a margin-bound risk. This new formulation allows us to extend the same technique to a wide variety of MCE based training. Second, we have successfully applied LM-MCE training approach to the Microsoft internal large vocabulary telephony speech recognition task (with 2000 hours of training data and 120K of vocabulary) and achieved significant recognition accuracy improvement across-the-board. To our best knowledge, this is the first time that the large-margin approach is demonstrated to be successful in large-scale speech recognition tasks."
            },
            "slug": "Large-Margin-Minimum-Classification-Error-Training-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "Large-Margin Minimum Classification Error Training for Large-Scale Speech Recognition Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work has successfully applied LM-MCE training approach to the Microsoft internal large vocabulary telephony speech recognition task and achieved significant recognition accuracy improvement across-the-board."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709862"
                        ],
                        "name": "E. Trentin",
                        "slug": "E.-Trentin",
                        "structuredName": {
                            "firstName": "Edmondo",
                            "lastName": "Trentin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Trentin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467467"
                        ],
                        "name": "M. Gori",
                        "slug": "M.-Gori",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Gori",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gori"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "A variety of different architectures and training algorithms have been proposed in the literature (see the comprehensive survey in [37])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18454590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cbb8670258f80caf8168e47ee3b6d979446c8851",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 149,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-survey-of-hybrid-ANN/HMM-models-for-automatic-Trentin-Gori",
            "title": {
                "fragments": [],
                "text": "A survey of hybrid ANN/HMM models for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14421525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62c87f843ae5c1ce7972d7cdcd227e3ec3fe5417",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling dynamic structure of speech is a novel paradigm in speech recognition research within the generative modeling framework, and it offers a potential to overcome limitations of the current hidden Markov modeling approach. Analogous to structured language models where syntactic structure is exploited to represent long-distance relationships among words , the structured speech model described in this paper makes use of the dynamic structure in the hidden vocal tract resonance space to characterize long-span contextual influence among phonetic units. A general overview is provided first on hierarchically classified types of dynamic speech models in the literature. A detailed account is then given for a specific model type called the hidden trajectory model, and we describe detailed steps of model construction and the parameter estimation algorithms. We show how the use of resonance target parameters and their temporal filtering enables joint modeling of long-span coarticulation and phonetic reduction effects. Experiments on phonetic recognition evaluation demonstrate superior recognizer performance over a modern hidden Markov model-based system. Error analysis shows that the greatest performance gain occurs within the sonorant speech class"
            },
            "slug": "Structured-speech-modeling-Deng-Yu",
            "title": {
                "fragments": [],
                "text": "Structured speech modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows how the use of resonance target parameters and their temporal filtering enables joint modeling of long-span coarticulation and phonetic reduction effects and demonstrates superior recognizer performance over a modern hidden Markov model-based system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152319568"
                        ],
                        "name": "Jinyu Li",
                        "slug": "Jinyu-Li",
                        "structuredName": {
                            "firstName": "Jinyu",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinyu Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777280"
                        ],
                        "name": "Y. Gong",
                        "slug": "Y.-Gong",
                        "structuredName": {
                            "firstName": "Yifan",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "MAP [75], joint compensation of distortions [76], variable pa-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16707001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c280d7260fcc5b5ca966c6ccb7cff1752c5b355",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-unified-framework-of-HMM-adaptation-with-joint-of-Li-Deng",
            "title": {
                "fragments": [],
                "text": "A unified framework of HMM adaptation with joint compensation of additive and convolutive distortions"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5023,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2418927"
                        ],
                        "name": "P. Fousek",
                        "slug": "P.-Fousek",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Fousek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fousek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204681"
                        ],
                        "name": "L. Lamel",
                        "slug": "L.-Lamel",
                        "structuredName": {
                            "firstName": "Lori",
                            "lastName": "Lamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685010"
                        ],
                        "name": "J. Gauvain",
                        "slug": "J.-Gauvain",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Gauvain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauvain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41213563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f79b4a1795301bc40b3ef58a9e6e66bf4267e38",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes incorporating discriminative features from a multi layer perceptron (MLP) into a state-of-the-art Arabic broadcast data transcription system based on cepstral features. The MLP features are based on a recently proposed Bottle-Neck architecture with long-term warped LPTRAP speech representation at the input. It is shown that the previously reported improvements on a development Arabic transcription system carry through to a full system at a state-ofthe-art level. SAT, CMLLR and MLLR adaptation techniques are shown to be useful for both MLP and combined features, though to a lesser degree than for PLPs. Without adaptation, MLP features obtain superior performance to cepstral features in all test conditions, and with adaptation both feature sets give comparable results. Combining the features, either by feature concatenation or system hypotheses, gives significant gains. Gains from MMI model training seem to be additive to the gain coming from discriminative MLP features."
            },
            "slug": "Transcribing-broadcast-data-using-MLP-features-Fousek-Lamel",
            "title": {
                "fragments": [],
                "text": "Transcribing broadcast data using MLP features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the previously reported improvements on a development Arabic transcription system carry through to a full system at a state-of-the-art level, and gains from MMI model training seem to be additive to the gain coming from discriminative MLP features."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [39] and [38]) on the hybrid approach"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61826819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd0568b4faa03910ae3c07d00c627666f404305d",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "A phoneme based, speaker-dependent continuous-speech recognition system embedding a multilayer perceptron (MLP) (i.e. a feedforward artificial neural network) into a hidden Markov model (HMM) approach is described. Contextual information from a sliding window on the input frames is used to improve frame or phoneme classification performance over the corresponding performance for simple maximum-likelihood probabilities, or even maximum a posteriori (MAP) probabilities which are estimated without the benefit of context. Performance for a simple discrete density HMM system appears to be somewhat better when MLP methods are used to estimate the probabilities.<<ETX>>"
            },
            "slug": "Continuous-speech-recognition-using-multilayer-with-Morgan-Bourlard",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition using multilayer perceptrons with hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A phoneme based, speaker-dependent continuous-speech recognition system embedding a multilayer perceptron (MLP) into a hidden Markov model (HMM) approach is described, which appears to be somewhat better when MLP methods are used to estimate the probabilities."
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749064"
                        ],
                        "name": "D. Kanevsky",
                        "slug": "D.-Kanevsky",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Kanevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kanevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720857"
                        ],
                        "name": "B. Ramabhadran",
                        "slug": "B.-Ramabhadran",
                        "structuredName": {
                            "firstName": "Bhuvana",
                            "lastName": "Ramabhadran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ramabhadran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698208"
                        ],
                        "name": "G. Saon",
                        "slug": "G.-Saon",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Saon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Saon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2484153"
                        ],
                        "name": "K. Visweswariah",
                        "slug": "K.-Visweswariah",
                        "structuredName": {
                            "firstName": "Karthik",
                            "lastName": "Visweswariah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Visweswariah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 213
                            }
                        ],
                        "text": "To compare our proposed CD-DNN-HMM model with standard discriminatively trained, GMM-based systems, we have trained clustered cross-word triphone GMM-HMMs with maximum-likelihood (ML), maximum mutual information (MMI), and minimum phone error (MPE) criteria."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 320,
                                "start": 316
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "There have been some notable recent advances in discriminative training (see an overview in [4]; e.g., maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random\nManuscript received September 08, 2010; revised January 04, 2011, March 13, 2011; accepted March 14, 2011."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "As shown in Table II, the MPE-trained CD-GMM-HMM outperformed both the ML- and MMI-trained CD-GMM-HMM with a sentence accuracy of 65.5% and 63.8% on the development and test sets respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 256
                            }
                        ],
                        "text": "We selected the values of these hyperparameters by\n2The lattice probability scale factorLATPROBSCALEwas set to 1/LMWwhere LMW is the LM weight, i-smooth parameters ISMOOTHTAU, ISMOOTHTAUT, and ISMOOTHTAUW were set to 100, 10, and 10, respectively, for the MMI training, and 50, 10, and 10, respectively, for the MPE training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14254768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8770b4a5ca7734c88e5755f9558f79e93229c023",
            "isKey": true,
            "numCitedBy": 432,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a modified form of the maximum mutual information (MMI) objective function which gives improved results for discriminative training. The modification consists of boosting the likelihoods of paths in the denominator lattice that have a higher phone error relative to the correct transcript, by using the same phone accuracy function that is used in Minimum Phone Error (MPE) training. We combine this with another improvement to our implementation of the Extended Baum-Welch update equations for MMI, namely the canceling of any shared part of the numerator and denominator statistics on each frame (a procedure that is already done in MPE). This change affects the Gaussian-specific learning rate. We also investigate another modification whereby we replace I-smoothing to the ML estimate with I-smoothing to the previous iteration's value. Boosted MMI gives better results than MPE in both model and feature-space discriminative training, although not consistently."
            },
            "slug": "Boosted-MMI-for-model-and-feature-space-training-Povey-Kanevsky",
            "title": {
                "fragments": [],
                "text": "Boosted MMI for model and feature-space discriminative training"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A modified form of the maximum mutual information (MMI) objective function which gives improved results for discriminative training by boosting the likelihoods of paths in the denominator lattice that have a higher phone error relative to the correct transcript."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723288"
                        ],
                        "name": "J. Neto",
                        "slug": "J.-Neto",
                        "structuredName": {
                            "firstName": "Joao",
                            "lastName": "Neto",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Neto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48889683"
                        ],
                        "name": "L. Almeida",
                        "slug": "L.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Almeida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39213695"
                        ],
                        "name": "M. Hochberg",
                        "slug": "M.-Hochberg",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Hochberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hochberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112813430"
                        ],
                        "name": "Ciro Martins",
                        "slug": "Ciro-Martins",
                        "structuredName": {
                            "firstName": "Ciro",
                            "lastName": "Martins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ciro Martins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053277981"
                        ],
                        "name": "Lu\u00eds Nunes",
                        "slug": "Lu\u00eds-Nunes",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Nunes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu\u00eds Nunes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144711425"
                        ],
                        "name": "T. Robinson",
                        "slug": "T.-Robinson",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Robinson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Robinson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026by the prior probability (called scaled likelihood estimation by [38], [40], [41]) may not give improved recognition accuracy under some conditions, we have found it to be very important in alleviating the label bias problem, especially when the training utterances contain long silence segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10013344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83fab3b9a434cd3a93e2367bd52af5c3ea66c7b2",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well known that recognition performance degrades signi cantly when moving from a speakerdependent to a speaker-independent system. Traditional hidden Markov model (HMM) systems have successfully applied speaker-adaptation approaches to reduce this degradation. In this paper we present and evaluate some techniques for speaker-adaptation of a hybrid HMM-arti cial neural network (ANN) continuous speech recognition system. These techniques are applied to a well trained, speaker-independent, hybrid HMM-ANN system and the recognizer parameters are adapted to a new speaker through o -line procedures. The techniques are evaluated on the DARPA RM corpus using varying amounts of adaptation material and different ANN architectures. The results show that speaker-adaptation within the hybrid framework can substantially improve system performance."
            },
            "slug": "Speaker-adaptation-for-hybrid-HMM-ANN-continuous-Neto-Almeida",
            "title": {
                "fragments": [],
                "text": "Speaker-adaptation for hybrid HMM-ANN continuous speech recognition system"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "These techniques are applied to a well trained, speaker-independent, hybrid HMM-ANN system and the recognizer parameters are adapted to a new speaker through o -line procedures and show that speaker-adaptation within the hybrid framework can substantially improve system performance."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723288"
                        ],
                        "name": "J. Neto",
                        "slug": "J.-Neto",
                        "structuredName": {
                            "firstName": "Joao",
                            "lastName": "Neto",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Neto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112813430"
                        ],
                        "name": "Ciro Martins",
                        "slug": "Ciro-Martins",
                        "structuredName": {
                            "firstName": "Ciro",
                            "lastName": "Martins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ciro Martins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48889683"
                        ],
                        "name": "L. Almeida",
                        "slug": "L.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Almeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "and [73]) or the many successful adaptation techniques devel-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11560680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e9c9f21931be7ba3b50c07a901dafc288bd56a",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Presently the most important systems for large vocabulary, continuous speech recognition are speaker-independent. These systems deal with the inter-speaker variability through a large pool of speakers. However, this approach has several drawbacks due to its inability to cope with the individual speaker characteristics. The problem is more extreme for the cases of fast or non-native speakers. In this paper we present a technique for speaker-adaptation in the context of a hybrid HMM-MLP system for large vocabulary, speaker-independent, continuous speech recognition. This technique is implemented both in supervised and unsupervised modes. In the unsupervised case both static and incremental approaches are explored. The results show that speaker-adaptation within the hybrid HMM-MLP framework can substantially improve system performance. In the incremental unsupervised mode, the improvement is obtained without any extra demands on the speaker, i.e. without an enrolment phase."
            },
            "slug": "Speaker-adaptation-in-a-hybrid-HMM-MLP-recognizer-Neto-Martins",
            "title": {
                "fragments": [],
                "text": "Speaker-adaptation in a hybrid HMM-MLP recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results show that speaker-adaptation within the hybrid HMM-MLP framework can substantially improve system performance and without any extra demands on the speaker, i.e. without an enrolment phase."
            },
            "venue": {
                "fragments": [],
                "text": "1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792214"
                        ],
                        "name": "Daniel Povey",
                        "slug": "Daniel-Povey",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Povey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Povey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 244
                            }
                        ],
                        "text": "To compare our proposed CD-DNN-HMM model with standard discriminatively trained, GMM-based systems, we have trained clustered cross-word triphone GMM-HMMs with maximum-likelihood (ML), maximum mutual information (MMI), and minimum phone error (MPE) criteria."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Note that this accuracy is already 2.6% higher than the 65.5% achieved using the MPE-trained CD-GMM-HMMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "%) relative error rate reduction over the MPE (or ML)-trained CD-GMM-HMMs and is statistically significant at significant level of 1% according to McNemar\u2019s test."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "To achieve the best result reported in this paper, we have to run two passes of fine-tuning, one with the MPE CD-GMM-HMM alignment, and one with the CD-DNN-HMM alignment."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "%) higher than those obtained using the MPE (or ML)-trained CD-GMM-HMMs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Using alignments generated with MPE-trained CD-GMM-HMMs, we can obtain 70.7% and 68.8% accuracies on the development and test sets, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 144
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 231
                            }
                        ],
                        "text": "There have been some notable recent advances in discriminative training (see an overview in [4]; e.g., maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random\nManuscript received September 08, 2010; revised January 04, 2011, March 13, 2011; accepted March 14, 2011."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "As shown in Table II, the MPE-trained CD-GMM-HMM outperformed both the ML- and MMI-trained CD-GMM-HMM with a sentence accuracy of 65.5% and 63.8% on the development and test sets respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 315,
                                "start": 312
                            }
                        ],
                        "text": "We selected the values of these hyperparameters by\n2The lattice probability scale factorLATPROBSCALEwas set to 1/LMWwhere LMW is the LM weight, i-smooth parameters ISMOOTHTAU, ISMOOTHTAUT, and ISMOOTHTAUW were set to 100, 10, and 10, respectively, for the MMI training, and 50, 10, and 10, respectively, for the MPE training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16095655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0509bf552a0d1fe895c019e4e8f1b1599c7112e4",
            "isKey": true,
            "numCitedBy": 798,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce the Minimum Phone Error (MPE) and Minimum Word Error (MWE) criteria for the discriminative training of HMM systems. The MPE/MWE criteria are smoothed approximations to the phone or word error rate respectively. We also discuss I-smoothing which is a novel technique for smoothing discriminative training criteria using statistics for maximum likelihood estimation (MLE). Experiments have been performed on the Switchboard/Call Home corpora of telephone conversations with up to 265 hours of training data. It is shown that for the maximum mutual information estimation (MMIE) criterion, I-smoothing reduces the word error rate (WER) by 0.4% absolute over the MMIE baseline. The combination of MPE and I-smoothing gives an improvement of 1 % over MMIE and a total reduction in WER of 4.8% absolute over the original MLE system."
            },
            "slug": "Minimum-Phone-Error-and-I-smoothing-for-improved-Povey-Woodland",
            "title": {
                "fragments": [],
                "text": "Minimum Phone Error and I-smoothing for improved discriminative training"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The Minimum Phone Error (MPE) and Minimum Word Error (MWE) criteria are smoothed approximations to the phone or word error rate respectively and I-smoothing which is a novel technique for smoothing discriminative training criteria using statistics for maximum likelihood estimation (MLE)."
            },
            "venue": {
                "fragments": [],
                "text": "2002 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740397"
                        ],
                        "name": "M. Gales",
                        "slug": "M.-Gales",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gales",
                            "middleNames": [
                                "John",
                                "Francis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gales"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "Inspiration for such algorithms may come from the ANN-HMM literature (e.g., [72] and [73]) or the many successful adaptation techniques developed in the past decades for GMM-HMMs (e.g., MLLR [74], MAP [75], joint compensation of distortions [76], variable parameter HMMs [77])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": ", MLLR [74], MAP [75], joint compensation of distortions"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10613847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c5eec22c4dabb124b2bbf85966d88dd38e62193",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract One of the key issues for adaptation algorithms is to modify a large number of parameters with only a small amount of adaptation data. Speaker adaptation techniques try to obtain near speaker-dependent (SD) performance with only small amounts of speaker-specific data, and are often based on initial speaker-independent (SI) recognition systems. Some of these speaker adaptation techniques may also be applied to the task of adaptation to a new acoustic environment. In this case an SI recognition system trained in, typically, a clean acoustic environment is adapted to operate in a new, noise-corrupted, acoustic environment. This paper examines the maximum likelihood linear regression (MLLR) adaptation technique. MLLR estimates linear transformations for groups of model parameters to maximize the likelihood of the adaptation data. Previously, MLLR has been applied to the mean parameters in mixture-Gaussian HMM systems. In this paper MLLR is extended to also update the Gaussian variances and re-estimation formulae are derived for these variance transforms. MLLR with variance compensation is evaluated on several large vocabulary recognition tasks. The use of mean and variance MLLR adaptation was found to give an additional 2% to 7% decrease in word error rate over mean-only MLLR adaptation."
            },
            "slug": "Mean-and-variance-adaptation-within-the-MLLR-Gales-Woodland",
            "title": {
                "fragments": [],
                "text": "Mean and variance adaptation within the MLLR framework"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper examines the maximum likelihood linear regression (MLLR) adaptation technique, which has been applied to the mean parameters in mixture-Gaussian HMM systems and is extended to also update the Gaussian variances and re-estimation formulae are derived for these variance transforms."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801698"
                        ],
                        "name": "A. Gunawardana",
                        "slug": "A.-Gunawardana",
                        "structuredName": {
                            "firstName": "Asela",
                            "lastName": "Gunawardana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gunawardana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143817088"
                        ],
                        "name": "M. Mahajan",
                        "slug": "M.-Mahajan",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Mahajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Digital Object Identifier 10.1109/TASL.2011.2134090\nfields (CRFs) [18]\u2013[20], hidden CRFs [21], [22], and segmental CRFs [23])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "The idea of using senones as the modeling unit has been proposed in [22] where the posterior probabilities of senones were estimated using deep-structured conditional random fields (CRFs) and only one audio frame was used as the input of the posterior probability estimator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "2134090 fields (CRFs) [18]\u2013[20], hidden CRFs [21], [22], and segmental CRFs [23])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "The recently proposed CRF [18]\u2013[20] and HCRF [21], [22] models use log-linear models to replace GMM-HMMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1744924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad4cfdb0c0bb62bf1fa99cb3d0519cadd9cbc160",
            "isKey": false,
            "numCitedBy": 359,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we show the novel application of hidden conditional random fields (HCRFs) \u2013 conditional random fields with hidden state sequences \u2013 for modeling speech. Hidden state sequences are critical for modeling the non-stationarity of speech signals. We show that HCRFs can easily be trained using the simple direct optimization technique of stochastic gradient descent. We present the results on the TIMIT phone classification task and show that HCRFs outperforms comparable ML and CML/MMI trained HMMs. In fact, HCRF results on this task are the best single classifier results known to us. We note that the HCRF framework is easily extensible to recognition since it is a state and label sequence modeling technique. We also note that HCRFs have the ability to handle complex features without any change in training procedure."
            },
            "slug": "Hidden-conditional-random-fields-for-phone-Gunawardana-Mahajan",
            "title": {
                "fragments": [],
                "text": "Hidden conditional random fields for phone classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents the results on the TIMIT phone classification task and shows that HCRFs outperforms comparable ML and CML/MMI trained HMMs and has the ability to handle complex features without any change in training procedure."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7492431,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "2ffd476d481fa644b8721b43427138f858e2d9ae",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "A structured generative model of speech coarticulation and reduction is described with a novel two-stage implementation. At the first stage, the dynamics of formants or vocal tract resonances (VTRs) in fluent speech is generated using prior information of resonance targets in the phone sequence, in absence of acoustic data. Bidirectional temporal filtering with finite-impulse response (FIR) is applied to the segmental target sequence as the FIR filter's input, where forward filtering produces anticipatory coarticulation and backward filtering produces regressive coarticulation. The filtering process is shown also to result in realistic resonance-frequency undershooting or reduction for fast-rate and low-effort speech in a contextually assimilated manner. At the second stage, the dynamics of speech cepstra are predicted analytically based on the FIR-filtered and speaker-adapted VTR targets, and the prediction residuals are modeled by Gaussian random variables with trainable parameters. The combined system of these two stages, thus, generates correlated and causally related VTR and cepstral dynamics, where phonetic reduction is represented explicitly in the hidden resonance space and implicitly in the observed cepstral space. We present details of model simulation demonstrating quantitative effects of speaking rate and segment duration on the magnitude of reduction, agreeing closely with experimental measurement results in the acoustic-phonetic literature. This two-stage model is implemented and applied to the TIMIT phonetic recognition task. Using the N-best (N=2000) rescoring paradigm, the new model, which contains only context-independent parameters, is shown to significantly reduce the phone error rate of a standard hidden Markov model (HMM) system under the same experimental conditions."
            },
            "slug": "A-bidirectional-target-filtering-model-of-speech-Deng-Yu",
            "title": {
                "fragments": [],
                "text": "A bidirectional target-filtering model of speech coarticulation and reduction: two-stage implementation for phonetic recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The new model, which contains only context-independent parameters, is shown to significantly reduce the phone error rate of a standard hidden Markov model (HMM) system under the same experimental conditions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15796526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d2336389dff3031910bd21dd1c44d1b4cd51725",
            "isKey": false,
            "numCitedBy": 1724,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training."
            },
            "slug": "Why-Does-Unsupervised-Pre-training-Help-Deep-Erhan-Courville",
            "title": {
                "fragments": [],
                "text": "Why Does Unsupervised Pre-training Help Deep Learning?"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre- training."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694730"
                        ],
                        "name": "F. Valente",
                        "slug": "F.-Valente",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Valente",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Valente"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398480065"
                        ],
                        "name": "M. Magimai.-Doss",
                        "slug": "M.-Magimai.-Doss",
                        "structuredName": {
                            "firstName": "Mathew",
                            "lastName": "Magimai.-Doss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Magimai.-Doss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758476"
                        ],
                        "name": "Christian Plahl",
                        "slug": "Christian-Plahl",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Plahl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Plahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2938043"
                        ],
                        "name": "Suman V. Ravuri",
                        "slug": "Suman-V.-Ravuri",
                        "structuredName": {
                            "firstName": "Suman",
                            "lastName": "Ravuri",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suman V. Ravuri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108907688"
                        ],
                        "name": "Wen Wang",
                        "slug": "Wen-Wang",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [51]\u2013[54]) train neural networks on LVSR datasets (often in excess of 1000 hours of data) and use variants of these approaches, either augmenting the input to a GMM-HMM system with features"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1915194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbd6eab9f08e3573e523375eee4b7180ab384875",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "MLP based front-ends have shown significant complementary properties to conventional spectral features. As part of the DARPA GALE program, different MLP features were developed for Mandarin ASR. In this paper, all the proposed frontends are compared in systematic manner and we extensively investigate the scalability of these features in terms of the amount of training data (from 100 hours to 1600 hours) and system complexity (maximum likelihood training, SAT, lattice level combination, and discriminative training). Results on 5 hours of evaluation data from the GALE project reveal that the MLP features consistently produce relative improvements in the range of 15% \u2212 23% at the different steps of a multipass system when compared to the conventional short-term spectral based features like MFCC and PLP. The largest improvement is obtained using a hierarchical MLP approach. Index Terms: TANDEM features, Multi-Layer Perceptron, Acoustic features, GALE project, LVCSR."
            },
            "slug": "A-comparative-large-scale-study-of-MLP-features-for-Valente-Magimai.-Doss",
            "title": {
                "fragments": [],
                "text": "A comparative large scale study of MLP features for Mandarin ASR"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "All the proposed MLP features developed for Mandarin ASR are compared in systematic manner and the scalability of these features in terms of the amount of training data and system complexity is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143604406"
                        ],
                        "name": "B. Juang",
                        "slug": "B.-Juang",
                        "structuredName": {
                            "firstName": "Biing-Hwang",
                            "lastName": "Juang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Juang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061634414"
                        ],
                        "name": "Wu Hou",
                        "slug": "Wu-Hou",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Hou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wu Hou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "There have been some notable recent advances in discriminative training (see an overview in [4]; e.g., maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random\nManuscript received September 08, 2010; revised January 04, 2011, March 13, 2011; accepted March 14, 2011."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11313392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdc3542552842d826a661f21e87917b976b4f7ee",
            "isKey": false,
            "numCitedBy": 729,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A critical component in the pattern matching approach to speech recognition is the training algorithm, which aims at producing typical (reference) patterns or models for accurate pattern comparison. In this paper, we discuss the issue of speech recognizer training from a broad perspective with root in the classical Bayes decision theory. We differentiate the method of classifier design by way of distribution estimation and the discriminative method of minimizing classification error rate based on the fact that in many realistic applications, such as speech recognition, the real signal distribution form is rarely known precisely. We argue that traditional methods relying on distribution estimation are suboptimal when the assumed distribution form is not the true one, and that \"optimality\" in distribution estimation does not automatically translate into \"optimality\" in classifier design. We compare the two different methods in the context of hidden Markov modeling for speech recognition. We show the superiority of the minimum classification error (MCE) method over the distribution estimation method by providing the results of several key speech recognition experiments. In general, the MCE method provides a significant reduction of recognition error rate."
            },
            "slug": "Minimum-classification-error-rate-methods-for-Juang-Hou",
            "title": {
                "fragments": [],
                "text": "Minimum classification error rate methods for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The issue of speech recognizer training from a broad perspective with root in the classical Bayes decision theory is discussed, and the superiority of the minimum classification error (MCE) method over the distribution estimation method is shown by providing the results of several key speech recognition experiments."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7347692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac720f8756d88307b4c587eb229835d808a64b96",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-dynamic,-feature-based-approach-to-the-interface-Deng",
            "title": {
                "fragments": [],
                "text": "A dynamic, feature-based approach to the interface between phonology and phonetics for speech modeling and recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144091892"
                        ],
                        "name": "M. Hwang",
                        "slug": "M.-Hwang",
                        "structuredName": {
                            "firstName": "Mei-Yuh",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144531812"
                        ],
                        "name": "Xuedong Huang",
                        "slug": "Xuedong-Huang",
                        "structuredName": {
                            "firstName": "Xuedong",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuedong Huang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "neural nets and by using the senones [48] (tied triphone states) of a GMM-HMM tri-phone model as the output units of the neural network, in line with state-of-the-art HMM systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Second, we used posterior probabilities of senones (tied triphone HMM states) [48] as the output of the neural"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15917542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33ea989f1655636162b7e9b8e0cfe3fcce92c37d",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A shared-distribution hidden Markov model (HMM) is presented for speaker-independent continuous speech recognition. The output distributions across different phonetic HMMs are shared with each other when they exhibit acoustic similarity. This sharing provides the freedom to use a larger number of Markov states for each phonetic model. Although an increase in the number of states will increase the total number of free parameters, with distribution sharing one can collapse redundant states while maintaining necessary ones. The shared-distribution model reduced the word error rate on the DARPA Resource Management task by 20% in comparison with the generalized-triphone model. >"
            },
            "slug": "Shared-distribution-hidden-Markov-models-for-speech-Hwang-Huang",
            "title": {
                "fragments": [],
                "text": "Shared-distribution hidden Markov models for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A shared-distribution hidden Markov model (HMM) is presented for speaker-independent continuous speech recognition that reduced the word error rate on the DARPA Resource Management task by 20% in comparison with the generalized-triphone model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "The pre-training algorithm we use is the deep belief network (DBN) pre-training algorithm of [24], but we will denote our model with the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] used the up-down algorithm to optimize all of the DBN weights jointly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "first described in [24], for learning the connection weights in a DBN that is equivalent to training each adjacent pair of layers as an restricted Boltzmann machine (RBM)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "The deep belief net training algorithm suggested in [24] first initializes the weights of each layer individually in a purely unsupervised1 way and then fine-tunes the entire network using labeled data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2309950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "isKey": true,
            "numCitedBy": 13407,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind."
            },
            "slug": "A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero",
            "title": {
                "fragments": [],
                "text": "A Fast Learning Algorithm for Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A fast, greedy algorithm is derived that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762736"
                        ],
                        "name": "F. Gr\u00e9zl",
                        "slug": "F.-Gr\u00e9zl",
                        "structuredName": {
                            "firstName": "Frantisek",
                            "lastName": "Gr\u00e9zl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gr\u00e9zl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2418927"
                        ],
                        "name": "P. Fousek",
                        "slug": "P.-Fousek",
                        "structuredName": {
                            "firstName": "Petr",
                            "lastName": "Fousek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fousek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Although a neural network nominally containing three hidden layers (the largest number of layers investigated in [55]) might be used to create bottle-neck features, if the feature layer is the middle hidden layer then the resulting features are only produced by an encoder with a single hidden layer."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7483924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "137b572ca406ba8fc86e985c185233b8cd6517d2",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This work continues in development of the recently proposed bottle-neck features for ASR. A five-layers MLP used in bottleneck feature extraction allows to obtain arbitrary feature size without dimensionality reduction by transforms, independently on the MLP training targets. The MLP topology - number and sizes of layers, suitable training targets, the impact of output feature transforms, the need of delta features, and the dimensionality of the final feature vector are studied with respect to the best ASR result. Optimized features are employed in three LVCSR tasks: Arabic broadcast news, English conversational telephone speech and English meetings. Improvements over standard cepstral features and probabilistic MLP features are shown for different tasks and different neural net input representations. A significant improvement is observed when phoneme MLP training targets are replaced by phoneme states and when delta features are added."
            },
            "slug": "Optimizing-bottle-neck-features-for-lvcsr-Gr\u00e9zl-Fousek",
            "title": {
                "fragments": [],
                "text": "Optimizing bottle-neck features for lvcsr"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Improvements over standard cepstral features and probabilistic MLP features are shown for different tasks and different neural net input representations, and a significant improvement is observed when phoneme MLP training targets are replaced by phoneme states and when delta features are added."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36357862"
                        ],
                        "name": "Hui Jiang",
                        "slug": "Hui-Jiang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108186844"
                        ],
                        "name": "Xinwei Li",
                        "slug": "Xinwei-Li",
                        "structuredName": {
                            "firstName": "Xinwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinwei Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 221
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15599493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "369f3ab6e557bd9fabda9558994e1e72f8290762",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study how to incorporate training errors in large margin estimation (LME) under semi-definite programming (SDP) framework. Like soft-margin SVM, we propose to optimize a new objective function which linearly combines the minimum margin among positive tokens and an average error function of all negative tokens. The new method is named as soft-LME. It is shown the new soft-LME problem can still be converted into an SDP problem if we properly define the average error function of all negative tokens based on their discriminative functions. Some preliminary results on TIDIGITS show that the soft-LML/SDP method yields modest performance gain when training error rates are significant. Moreover, it is also shown that the soft-LML/SDP can achieve much faster convergence for all cases which we have investigated."
            },
            "slug": "Incorporating-Training-Errors-for-Large-Margin-HMMS-Jiang-Li",
            "title": {
                "fragments": [],
                "text": "Incorporating Training Errors for Large Margin HMMS Under Semi-Definite Programming Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown the new soft-LME problem can still be converted into an SDP problem if the authors properly define the average error function of all negative tokens based on their discriminative functions."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "that use the ANNs to estimate the HMM state-posterior probabilities [38]\u2013[45], which have been referred to as ANN-HMM hybrid models in the literature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [39] and [38]) on the hybrid approach"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Although dividing by the prior probability (called scaled likelihood estimation by [38], [40], [41]) may not give improved recognition accuracy under some conditions, we have found it to be"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8911025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4914df5c8b886e85502bba35a35741d05639bd8",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the period of 1987-1991, a series of theoretical and experimental results have suggested that multilayer perceptrons (MLP) are an effective family of algorithms for the smooth estimation of high-dimension probability density functions that are useful in continuous speech recognition. The early form of this work has focused on hidden Markov models (HMM) that are independent of phonetic context. More recently, the theory has been extended to context-dependent models. The authors review the basic principles of their hybrid HMM/MLP approach and describe a series of improvements that are analogous to the system modifications instituted for the leading conventional HMM systems over the last few years. Some of these methods directly trade off computational complexity for reduced requirements of memory and memory bandwidth. Results are presented on the widely used Resource Management speech database that has been distributed by the US National Institute of Standards and Technology."
            },
            "slug": "Continuous-speech-recognition-by-connectionist-Bourlard-Morgan",
            "title": {
                "fragments": [],
                "text": "Continuous speech recognition by connectionist statistical methods"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors review the basic principles of their hybrid HMM/MLP approach and describe a series of improvements that are analogous to the system modifications instituted for the leading conventional HMM systems over the last few years."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796044"
                        ],
                        "name": "L. Saul",
                        "slug": "L.-Saul",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Saul",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Saul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 266
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1217614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e084bbb9cbbce7c0d282df263cf70cba4042f067",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a framework for large margin classification by Gaussian mixture models (GMMs). Large margin GMMs have many parallels to support vector machines (SVMs) but use ellipsoids to model classes instead of half-spaces. Model parameters are trained discriminatively to maximize the margin of correct classification, as measured in terms of Mahalanobis distances. The required optimization is convex over the model's parameter space of positive semidefinite matrices and can be performed efficiently. Large margin GMMs are naturally suited to large problems in multiway classification; we apply them to phonetic classification and recognition on the TIMIT database. On both tasks, we obtain significant improvement over baseline systems trained by maximum likelihood estimation. For the problem of phonetic classification, our results are competitive with other state-of-the-art classifiers, such as hidden conditional random fields"
            },
            "slug": "Large-Margin-Gaussian-Mixture-Modeling-for-Phonetic-Sha-Saul",
            "title": {
                "fragments": [],
                "text": "Large Margin Gaussian Mixture Modeling for Phonetic Classification and Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A framework for large margin classification by Gaussian mixture models (GMMs), which have many parallels to support vector machines (SVMs) but use ellipsoids to model classes instead of half-spaces is developed."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145659093"
                        ],
                        "name": "S. Kapadia",
                        "slug": "S.-Kapadia",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kapadia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kapadia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782065"
                        ],
                        "name": "V. Valtchev",
                        "slug": "V.-Valtchev",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 213
                            }
                        ],
                        "text": "To compare our proposed CD-DNN-HMM model with standard discriminatively trained, GMM-based systems, we have trained clustered cross-word triphone GMM-HMMs with maximum-likelihood (ML), maximum mutual information (MMI), and minimum phone error (MPE) criteria."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 46
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "There have been some notable recent advances in discriminative training (see an overview in [4]; e.g., maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random\nManuscript received September 08, 2010; revised January 04, 2011, March 13, 2011; accepted March 14, 2011."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "As shown in Table II, the MPE-trained CD-GMM-HMM outperformed both the ML- and MMI-trained CD-GMM-HMM with a sentence accuracy of 65.5% and 63.8% on the development and test sets respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 256
                            }
                        ],
                        "text": "We selected the values of these hyperparameters by\n2The lattice probability scale factorLATPROBSCALEwas set to 1/LMWwhere LMW is the LM weight, i-smooth parameters ISMOOTHTAU, ISMOOTHTAUT, and ISMOOTHTAUW were set to 100, 10, and 10, respectively, for the MMI training, and 50, 10, and 10, respectively, for the MPE training."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57374885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd6387ca1949d61356adee35708dcdbee1e4fd05",
            "isKey": true,
            "numCitedBy": 117,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiences with a phoneme recognition system for the TIMIT database which uses multiple mixture continuous-density monophone HMMs (hidden Markov models) trained using MMI (maximum mutual information) is reported. A comprehensive set of results are presented comparing the ML (maximum likelihood) and MMI training criteria for both diagonal and full covariance models. These results using simple monophone HMMs show that clear performance gains are achieved by MMI training. These results are comparable with the best reported by others, including those which use context-dependent models. In addition, a number of performance and implementation issues which are crucial to successful MMI training are discussed.<<ETX>>"
            },
            "slug": "MMI-training-for-continuous-phoneme-recognition-on-Kapadia-Valtchev",
            "title": {
                "fragments": [],
                "text": "MMI training for continuous phoneme recognition on the TIMIT database"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "These results using simple monophone HMMs show that clear performance gains are achieved by MMI training, and are comparable with the best reported by others, including those which use context-dependent models."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798462"
                        ],
                        "name": "Pierre-Antoine Manzagol",
                        "slug": "Pierre-Antoine-Manzagol",
                        "structuredName": {
                            "firstName": "Pierre-Antoine",
                            "lastName": "Manzagol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Antoine Manzagol"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145467703"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Both [56] and [57] investigate why training deep feed-forward neural networks can often be easier with some form of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5108612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccf415df5a83b343dae261286d29a40e8b80e6c6",
            "isKey": false,
            "numCitedBy": 395,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Whereas theoretical work suggests that deep architectures might be more e cient at representing highly-varying functions, training deep architectures was unsuccessful until the recent advent of algorithms based on unsupervised pretraining. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this di cult learning problem. Answering these questions is important if learning in deep architectures is to be further improved. We attempt to shed some light on these questions through extensive simulations. The experiments confirm and clarify the advantage of unsupervised pre-training. They demonstrate the robustness of the training procedure with respect to the random initialization, the positive e ect of pre-training in terms of optimization and its role as a regularizer. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples."
            },
            "slug": "The-Difficulty-of-Training-Deep-Architectures-and-Erhan-Manzagol",
            "title": {
                "fragments": [],
                "text": "The Difficulty of Training Deep Architectures and the Effect of Unsupervised Pre-Training"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The experiments confirm and clarify the advantage of unsupervised pre- training, and empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026by the prior probability (called scaled likelihood estimation by [38], [40], [41]) may not give improved recognition accuracy under some conditions, we have found it to be very important in alleviating the label bias problem, especially when the training utterances contain long silence segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16224396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15754483b95c5386fb145751ad3b054761207451",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Major speech production models from speech science literature and a number of popular statistical \u201cgenerative\u201d models of speech used in speech technology are surveyed. Strengths and weaknesses of these two styles of speech models are analyzed, pointing to the need to integrate the respective strengths while eliminating the respective weaknesses. As an example, a statistical task-dynamic model of speech production is described, motivated by the original deterministic version of the model and targeted for integrated-multilingual speech recognition applications. Methods for model parameter learning (training) and for likelihood computation (recognition) are described based on statistical optimization principles integrated in neural network and dynamic system theories."
            },
            "slug": "Computational-Models-for-Speech-Production-Deng",
            "title": {
                "fragments": [],
                "text": "Computational Models for Speech Production"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A statistical task-dynamic model of speech production is described, motivated by the original deterministic version of the model and targeted for integrated-multilingual speech recognition applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762736"
                        ],
                        "name": "F. Gr\u00e9zl",
                        "slug": "F.-Gr\u00e9zl",
                        "structuredName": {
                            "firstName": "Frantisek",
                            "lastName": "Gr\u00e9zl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gr\u00e9zl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245567"
                        ],
                        "name": "M. Karafi\u00e1t",
                        "slug": "M.-Karafi\u00e1t",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Karafi\u00e1t",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Karafi\u00e1t"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404292"
                        ],
                        "name": "S. Kontar",
                        "slug": "S.-Kontar",
                        "structuredName": {
                            "firstName": "Stanislav",
                            "lastName": "Kontar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kontar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899242"
                        ],
                        "name": "J. Cernock\u00fd",
                        "slug": "J.-Cernock\u00fd",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Cernock\u00fd",
                            "middleNames": [
                                "Honza"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cernock\u00fd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "In a similar vein, [50] uses features derived from an earlier \u201cbottle-neck\u201d hidden layer instead of using the neural network outputs directly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1473186,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fc7204b78c4d85e9d59496fcc067d62f6f4a7e1",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, probabilistic features became an integral part of state-of-the-are LVCSR systems. In this work, we are exploring the possibility of obtaining the features directly from neural net without the necessity of converting output probabilities to features suitable for subsequent GMM-HMM system. We experimented with 5-layer MLP with bottle-neck in the middle layer. After training such a neural net, we used outputs of the bottle-neck as features for GMM-HMM recognition system. The benefits are twofold: first, improvement was gained when these features are used instead of the probabilistic features, second, the size of the system was reduced, as only part of the neural net is used. The experiments were performed on meetings recognition task defined in MST RT'05 evaluation."
            },
            "slug": "Probabilistic-and-Bottle-Neck-Features-for-LVCSR-of-Gr\u00e9zl-Karafi\u00e1t",
            "title": {
                "fragments": [],
                "text": "Probabilistic and Bottle-Neck Features for LVCSR of Meetings"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work is exploring the possibility of obtaining the features directly from neural net without the necessity of converting output probabilities to features suitable for subsequent GMM-HMM system."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3119801"
                        ],
                        "name": "Xavier Glorot",
                        "slug": "Xavier-Glorot",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Glorot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Glorot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Both [56] and [57] investigate why training deep feed-forward neural networks can often be easier with some form of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5575601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b71ac1e9fb49420d13e084ac67254a0bbd40f83f",
            "isKey": false,
            "numCitedBy": 12424,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a \u201cbetter\u201d basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact)."
            },
            "slug": "Understanding-the-difficulty-of-training-deep-Glorot-Bengio",
            "title": {
                "fragments": [],
                "text": "Understanding the difficulty of training deep feedforward neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111403728"
                        ],
                        "name": "Michael Cohen",
                        "slug": "Michael-Cohen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145660147"
                        ],
                        "name": "H. Franco",
                        "slug": "H.-Franco",
                        "structuredName": {
                            "firstName": "Horacio",
                            "lastName": "Franco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Franco"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2077908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a08c99425ad94eed67d059813511fe9ca55e73eb",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 131,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors are concerned with integrating connectionist networks into a hidden Markov model (HMM) speech recognition system. This is achieved through a statistical interpretation of connectionist networks as probability estimators. They review the basis of HMM speech recognition and point out the possible benefits of incorporating connectionist networks. Issues necessary to the construction of a connectionist HMM recognition system are discussed, including choice of connectionist probability estimator. They describe the performance of such a system using a multilayer perceptron probability estimator evaluated on the speaker-independent DARPA Resource Management database. In conclusion, they show that a connectionist component improves a state-of-the-art HMM system. >"
            },
            "slug": "Connectionist-probability-estimators-in-HMM-speech-Renals-Morgan",
            "title": {
                "fragments": [],
                "text": "Connectionist probability estimators in HMM speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that a connectionist component improves a state-of-the-art HMM system through a statistical interpretation of connectionist networks as probability estimators."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Speech Audio Process."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2416787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a2668bf420d8509a4dfa28e1cdcdac14c649975",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new type of top-level model for Deep Belief Nets and evaluate it on a 3D object recognition task. The top-level model is a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients. Performance is evaluated on the NORB database (normalized-uniform version), which contains stereo-pair images of objects under different lighting conditions and viewpoints. Our model achieves 6.5% error on the test set, which is close to the best published result for NORB (5.9%) using a convolutional neural net that has built-in knowledge of translation invariance. It substantially outperforms shallow models such as SVMs (11.6%). DBNs are especially suited for semi-supervised learning, and to demonstrate this we consider a modified version of the NORB recognition task in which additional unlabeled images are created by applying small translations to the images in the database. With the extra unlabeled data (and the same amount of labeled data as before), our model achieves 5.2% error."
            },
            "slug": "3D-Object-Recognition-with-Deep-Belief-Nets-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "3D Object Recognition with Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new type of top-level model for Deep Belief Nets is introduced, a third-order Boltzmann machine, trained using a hybrid algorithm that combines both generative and discriminative gradients that substantially outperforms shallow models such as SVMs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740054"
                        ],
                        "name": "Y. Ju",
                        "slug": "Y.-Ju",
                        "structuredName": {
                            "firstName": "Yun-Cheng",
                            "lastName": "Ju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30844359"
                        ],
                        "name": "Ye-Yi Wang",
                        "slug": "Ye-Yi-Wang",
                        "structuredName": {
                            "firstName": "Ye-Yi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ye-Yi Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "application (formerly known as Live Search for mobile [36], [60]) under real usage scenarios."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 306
                            }
                        ],
                        "text": "To evaluate the proposed CD-DNN-HMMs and to understand the effect of different decisions made at each step of CD-DNN-HMM training, we have conducted a series of experiments on a business search dataset collected from the Bing mobile voice search application (formerly known as Live Search for mobile [36], [60])\u2014a real-world large-vocabulary spontaneous speech recognition task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15316340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b2e2c520ecb48be9dfe1594bcd0d93fd5a6c339",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract The automated directory assistance system (ADAS) is traditionally formulated as an automatic speech recognition (ASR) problem. Recently, it has been formulated as a voice search problem, where a spoken utterance is firstly converted into text, which in turn is used to search for the listing. In this paper, we focus on the design and development of the utterance-to-listing component of ADAS. We show that many theoretical and practical issues need to be resolved when applying the basic idea of voice search to the development of ADAS. We share our experiences in addressing these issues, especially in pre-processing the listing database, generating a high performance LM, and developing efficient, accurate, and robust search algorithms. Field tests of our prototype system indicate that an 81% task completion rate can be achieved. Index Terms : speech recognition, directory assistance, voice search, TFIDF, spoken dialog system, vector space model 1. Introduction An automated directory assistance system (ADAS) [1] [2] [3] [5] [6] is a spoken dialog system that provides the caller with the phone number and/or address of the business or residential listing he/she requests. It is a very complicated system that involves automatic speech recognition (ASR), listing lookup, disambiguation, and dialog design. The core element of the ADAS is the utterance-to-listing (U2L) component that maps an utterance \u0007K"
            },
            "slug": "Automated-directory-assistance-system-from-theory-Yu-Ju",
            "title": {
                "fragments": [],
                "text": "Automated directory assistance system - from theory to practice"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that many theoretical and practical issues need to be resolved when applying the basic idea of voice search to the development of ADAS, and the experiences in addressing these issues are shared, especially in pre-processing the listing database, generating a high performance LM, and developing efficient, accurate, and robust search algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9353491"
                        ],
                        "name": "Qifeng Zhu",
                        "slug": "Qifeng-Zhu",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Qifeng Zhu",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qifeng Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145244442"
                        ],
                        "name": "K. Sonmez",
                        "slug": "K.-Sonmez",
                        "structuredName": {
                            "firstName": "Kemal",
                            "lastName": "Sonmez",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sonmez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739225"
                        ],
                        "name": "S. Sivadas",
                        "slug": "S.-Sivadas",
                        "structuredName": {
                            "firstName": "Sunil",
                            "lastName": "Sivadas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sivadas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732454"
                        ],
                        "name": "T. Shinozaki",
                        "slug": "T.-Shinozaki",
                        "structuredName": {
                            "firstName": "Takahiro",
                            "lastName": "Shinozaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shinozaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144339506"
                        ],
                        "name": "Mari Ostendorf",
                        "slug": "Mari-Ostendorf",
                        "structuredName": {
                            "firstName": "Mari",
                            "lastName": "Ostendorf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mari Ostendorf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066975404"
                        ],
                        "name": "P. Jain",
                        "slug": "P.-Jain",
                        "structuredName": {
                            "firstName": "Pratibha",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2862682"
                        ],
                        "name": "G. Doddington",
                        "slug": "G.-Doddington",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Doddington",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doddington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157307424"
                        ],
                        "name": "B. Chen",
                        "slug": "B.-Chen",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9376398"
                        ],
                        "name": "O. Cretin",
                        "slug": "O.-Cretin",
                        "structuredName": {
                            "firstName": "O.",
                            "lastName": "Cretin",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Cretin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705797"
                        ],
                        "name": "M. Athineos",
                        "slug": "M.-Athineos",
                        "structuredName": {
                            "firstName": "Marios",
                            "lastName": "Athineos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Athineos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Around 1999, the desire to use HMM advances from the speech research community directly without developing replacement techniques and tools contributed to a shift from using neural nets to predict phonetic states to using neural nets to augment features for later use in a conventional GMM-HMM recognizer (e.g., [ 47 ]).,There is a vast space to explore in the deep learning framework using the insights gained from temporalcentric generative modeling research in neural networks and in speech (e.g., [2], [ 47 ], [82], [83])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15156045,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d9d2ba2003d7324ae3d5ff7423a13f13efc79ca5",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite successes, there are still significant limitations to speech recognition performance, particularly for conversational speech and/or for speech with significant acoustic degradations from noise or reverberation. For this reason, authors have proposed methods that incorporate different (and larger) analysis windows, which are described in this article. Note in passing that we and many others have already taken advantage of processing techniques that incorporate information over long time ranges, for instance for normalization (by cepstral mean subtraction as stated in B. Atal (1974) or relative spectral analysis (RASTA) based in H. Hermansky and N. Morgan (1994)). They also have proposed features that are based on speech sound class posterior probabilities, which have good properties for both classification and stream combination."
            },
            "slug": "Pushing-the-envelope-aside-[speech-recognition]-Morgan-Zhu",
            "title": {
                "fragments": [],
                "text": "Pushing the envelope - aside [speech recognition]"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Authors have proposed methods that incorporate different analysis windows that incorporate features that are based on speech sound class posterior probabilities, which have good properties for both classification and stream combination."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144787400"
                        ],
                        "name": "G. Cook",
                        "slug": "G.-Cook",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Cook",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cook"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116802190"
                        ],
                        "name": "D. A. G. Williams",
                        "slug": "D.-A.-G.-Williams",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Williams",
                            "middleNames": [
                                "A.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. A. G. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "that use the ANNs to estimate the HMM state-posterior probabilities [38]\u2013[45], which have been referred to as ANN-HMM hybrid models in the literature."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "Much previous hybrid ANN-HMM work focused on context-independent or rudimentary context-dependent phone models and small to mid-vocabulary tasks (with notable exceptions such as [45]), possibly"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 5
                            }
                        ],
                        "text": ", in [45], which also employed recurrent neural architectures)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1233541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eb4c82eb0dfc4f1fb5ebbf76cfad0549dde3d11",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Connectionist-speech-recognition-of-Broadcast-News-Robinson-Cook",
            "title": {
                "fragments": [],
                "text": "Connectionist speech recognition of Broadcast News"
            },
            "venue": {
                "fragments": [],
                "text": "Speech Commun."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "Starting with the definition of , we obtain (see [62] for another version of this derivation along with other useful ones)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "As argued in [62] and [63], insufficiently deep architectures can require an exponential blow-up in the number of computational elements needed to represent certain functions satisfactorily."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207178999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e60ff004dde5c13ec53087872cfcdd12e85beb57",
            "isKey": false,
            "numCitedBy": 7558,
            "numCiting": 345,
            "paperAbstract": {
                "fragments": [],
                "text": "Theoretical results strongly suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one needs deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult optimization task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This paper discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks."
            },
            "slug": "Learning-Deep-Architectures-for-AI-Bengio",
            "title": {
                "fragments": [],
                "text": "Learning Deep Architectures for AI"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer modelssuch as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798462"
                        ],
                        "name": "Pierre-Antoine Manzagol",
                        "slug": "Pierre-Antoine-Manzagol",
                        "structuredName": {
                            "firstName": "Pierre-Antoine",
                            "lastName": "Manzagol",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre-Antoine Manzagol"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 168
                            }
                        ],
                        "text": "Thus, pre-trained neural networks often also achieve lower training error than neural networks that are not pre-trained (although this effect can often be confounded by the use of early stopping)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207168299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "843959ffdccf31c6694d135fad07425924f785b1",
            "isKey": false,
            "numCitedBy": 5465,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite."
            },
            "slug": "Extracting-and-composing-robust-features-with-Vincent-Larochelle",
            "title": {
                "fragments": [],
                "text": "Extracting and composing robust features with denoising autoencoders"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109474526"
                        ],
                        "name": "Jeremy Morris",
                        "slug": "Jeremy-Morris",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Morris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11305607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0125b014ff5171c74bd6d8365f4cffe3714c0b0",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A Conditional Random Field is a mathematical model for sequences that is similar in many ways to a Hidden Markov Model, but is discriminative rather than generative in nature. In this paper, we explore the application of the CRF model to ASR processing of discriminative phonetic features by building a system that performs first-pass phonetic recognition using discriminatively trained phonetic features. With this system, we show that this CRF model achieves an accuracy level in a phone recognition task that is superior to a similarly trained HMM model. Index Terms: speech recognition, conditional random fields."
            },
            "slug": "Combining-phonetic-attributes-using-conditional-Morris-Fosler-Lussier",
            "title": {
                "fragments": [],
                "text": "Combining phonetic attributes using conditional random fields"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper builds a system that performs first-pass phonetic recognition using discriminatively trained phonetic features and shows that this CRF model achieves an accuracy level in a phone recognition task that is superior to a similarly trained HMM model."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Recently, discriminative training strategies such as MMI [5], MCE [6], [7], MPE [8], [9], and large-margin techniques [10]\u2013[17] have been proposed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 289
                            }
                        ],
                        "text": ", maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "There have been some notable recent advances in discriminative training (see an overview in [4]; e.g., maximum mutual information (MMI) estimation [5], minimum classification error (MCE) training [6], [7], and minimum phone error (MPE) training [8], [9]), in large-margin techniques (such as large-margin estimation [10], [11], large-margin hidden Markov model (HMM) [12], large-margin MCE [13]\u2013[16], and boosted MMI [17]), as well as in novel acoustic models (such as conditional random\nManuscript received September 08, 2010; revised January 04, 2011, March 13, 2011; accepted March 14, 2011."
                    },
                    "intents": []
                }
            ],
            "corpusId": 66073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f9d0790b4b74c199d8a5b5a61762ef53637ec62",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we report our recent development of a novel discriminative learning technique which embeds the concept of discriminative margin into the well established minimum classification error (MCE) method. The idea is to impose an incrementally adjusted \u201cmargin\u201d in the loss function of MCE algorithm so that not only error rates are minimized but also discrimination \u201crobustness\u201d between training and test sets is maintained. Experimental evaluation shows that the use of the margin improves a state-of-the-art MCE method by reducing 17% digit errors and 19% string errors in the TIDigits recognition task. The string error rate of 0.55% and digit error rate of 0.19% we have obtained are the best-ever results reported on this task in the literature."
            },
            "slug": "Use-of-incrementally-regulated-discriminative-in-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "Use of incrementally regulated discriminative margins in MCE training for speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Experimental evaluation shows that the use of the margin improves a state-of-the-art MCE method by reducing 17% digit errors and 19% string errors in the TIDigits recognition task."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026by the prior probability (called scaled likelihood estimation by [38], [40], [41]) may not give improved recognition accuracy under some conditions, we have found it to be very important in alleviating the label bias problem, especially when the training utterances contain long silence segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8435923,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0228810a988f6b8f06337e14f564e2fd3f6e1056",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "The Temporal Restricted Boltzmann Machine (TRBM) is a probabilistic model for sequences that is able to successfully model (i.e., generate nice-looking samples of) several very high dimensional sequences, such as motion capture data and the pixels of low resolution videos of balls bouncing in a box. The major disadvantage of the TRBM is that exact inference is extremely hard, since even computing a Gibbs update for a single variable of the posterior is exponentially expensive. This difficulty has necessitated the use of a heuristic inference procedure, that nonetheless was accurate enough for successful learning. In this paper we introduce the Recurrent TRBM, which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable. We demonstrate that the RTRBM is better than an analogous TRBM at generating motion capture and videos of bouncing balls."
            },
            "slug": "The-Recurrent-Temporal-Restricted-Boltzmann-Machine-Sutskever-Hinton",
            "title": {
                "fragments": [],
                "text": "The Recurrent Temporal Restricted Boltzmann Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The Recurrent TRBM is introduced, which is a very slight modification of the TRBM for which exact inference is very easy and exact gradient learning is almost tractable."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145244226"
                        ],
                        "name": "Yonghong Yan",
                        "slug": "Yonghong-Yan",
                        "structuredName": {
                            "firstName": "Yonghong",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonghong Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681269"
                        ],
                        "name": "M. Fanty",
                        "slug": "M.-Fanty",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Fanty",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fanty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8089863"
                        ],
                        "name": "R. Cole",
                        "slug": "R.-Cole",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cole",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cole"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15701363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72f367ac9c6062808ed1e258023d79bbfb5e0197",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural network training targets for speech recognition are estimated using a novel method. Rather than use zero and one, continuous targets are generated using forward-backward probabilities. Each training pattern has more than one class active. Experiments showed that the new method effectively decreased the error rate by 15% in a continuous digits recognition task."
            },
            "slug": "Speech-recognition-using-neural-networks-with-Yan-Fanty",
            "title": {
                "fragments": [],
                "text": "Speech recognition using neural networks with forward-backward probability generated targets"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Neural network training targets for speech recognition are estimated using a novel method that generates continuous targets using forward-backward probabilities, which effectively decreased the error rate in a continuous digits recognition task."
            },
            "venue": {
                "fragments": [],
                "text": "1997 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107569404"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1418438552"
                        ],
                        "name": "Chin-Hul Lee",
                        "slug": "Chin-Hul-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hul",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hul Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1419536825"
                        ],
                        "name": "Douglas O'Shgughnessy",
                        "slug": "Douglas-O'Shgughnessy",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "O'Shgughnessy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas O'Shgughnessy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63630945,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "37c6843c66a0e18fbbc383a7cf344b7a7482746d",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "To advance research, it is important to identify promising future research directions, especially those that have not been adequately pursued or funded in the past. The working group producing this article was charged to elicit from the human language technology (HLT) community a set of well-considered directions or rich areas for future research that could lead to major paradigm shifts in the field of automatic speech recognition (ASR) and understanding. ASR has been an area of great interest and activity to the signal processing and HLT communities over the past several decades. As a first step, this group reviewed major developments in the field and the circumstances that led to their success and then focused on areas it deemed especially fertile for future research. Part 1 of this article will focus on historically significant developments in the ASR area, including several major research efforts that were guided by different funding agencies, and suggest general areas in which to focus research. Part 2 (to appear in the next issue) will explore in more detail several new avenues holding promise for substantial improvements in ASR performance. These entail cross-disciplinary research and specific approaches to address three-to-five-year grand challenges aimed at stimulating advanced research by dealing with realistic tasks of broad interest."
            },
            "slug": "Research-Developments-and-Directions-in-Speech-and-Baker-Deng",
            "title": {
                "fragments": [],
                "text": "Research Developments and Directions in Speech Recognition and Understanding, Part 1"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The working group producing this article was charged to elicit from the human language technology community a set of well-considered directions or rich areas for future research that could lead to major paradigm shifts in the field of automatic speech recognition (ASR) and understanding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1501682,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd5af41a81e7fc9588dc74f3831fb14daf2f8e2a",
            "isKey": false,
            "numCitedBy": 1259,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Semantic-hashing-Salakhutdinov-Hinton",
            "title": {
                "fragments": [],
                "text": "Semantic hashing"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Approx. Reason."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9068522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2c04849a3802715d5a9d89179c9f161014d6c2a",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset."
            },
            "slug": "Modeling-pixel-means-and-covariances-using-machines-Ranzato-Hinton",
            "title": {
                "fragments": [],
                "text": "Modeling pixel means and covariances using factorized third-order boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107569404"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79770421"
                        ],
                        "name": "D. O'Shaughnessy",
                        "slug": "D.-O'Shaughnessy",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "O'Shaughnessy",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. O'Shaughnessy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 357467,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b829f28c6329f66bb09750194ae36315ec7838ac",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "To advance research, it is important to identify promising future research directions, especially those that have not been adequately pursued or funded in the past. The working group producing this article was charged to elicit from the human language technology (HLT) community a set of well-considered directions or rich areas for future research that could lead to major paradigm shifts in the field of automatic speech recognition (ASR) and understanding. ASR has been an area of great interest and activity to the signal processing and HLT communities over the past several decades. As a first step, this group reviewed major developments in the field and the circumstances that led to their success and then focused on areas it deemed especially fertile for future research. Part 1 of this article will focus on historically significant developments in the ASR area, including several major research efforts that were guided by different funding agencies, and suggest general areas in which to focus research."
            },
            "slug": "Developments-and-directions-in-speech-recognition-1-Baker-Deng",
            "title": {
                "fragments": [],
                "text": "Developments and directions in speech recognition and understanding, Part 1 [DSP Education]"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The working group producing this article was charged to elicit from the human language technology community a set of well-considered directions or rich areas for future research that could lead to major paradigm shifts in the field of automatic speech recognition (ASR) and understanding."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15127727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7e4c4819b2ab455481b065b2a019a7e03785eb9",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Large-margin-minimum-classification-error-training:-Yu-Deng",
            "title": {
                "fragments": [],
                "text": "Large-margin minimum classification error training: A theoretical risk minimization perspective"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Speech Lang."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "As argued in [62] and [63], insufficiently deep architectures can require an exponential blow-up in the number of computational elements needed to represent certain functions satisfactorily."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15559637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fdb77260fc83dff91c44fea0f31a2cb8ed13d04",
            "isKey": false,
            "numCitedBy": 1117,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "One long-term goal of machine learning research is to produce methods that are applicable to highly complex tasks, such as perception (vision, audition), reasoning, intelligent control, and other artificially intelligent behaviors. We argue that in order to progress toward this goal, the Machine Learning community must endeavor to discover algorithms that can learn highly complex functions, with minimal need for prior knowledge, and with minimal human intervention. We present mathematical and empirical evidence suggesting that many popular approaches to non-parametric learning, particularly kernel methods, are fundamentally limited in their ability to learn complex high-dimensional functions. Our analysis focuses on two problems. First, kernel machines are shallow architectures, in which one large layer of simple template matchers is followed by a single layer of trainable coefficients. We argue that shallow architectures can be very inefficient in terms of required number of computational elements and examples. Second, we analyze a limitation of kernel machines with a local kernel, linked to the curse of dimensionality, that applies to supervised, unsupervised (manifold learning) and semi-supervised kernel machines. Using empirical results on invariant image recognition tasks, kernel methods are compared with deep architectures, in which lower-level features or concepts are progressively combined into more abstract and higher-level representations. We argue that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence."
            },
            "slug": "Scaling-learning-algorithms-towards-AI-Bengio-LeCun",
            "title": {
                "fragments": [],
                "text": "Scaling learning algorithms towards AI"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is argued that deep architectures have the potential to generalize in non-local ways, i.e., beyond immediate neighbors, and that this is crucial in order to make progress on the kind of complex tasks required for artificial intelligence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137069"
                        ],
                        "name": "Xiaodong He",
                        "slug": "Xiaodong-He",
                        "structuredName": {
                            "firstName": "Xiaodong",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaodong He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145320076"
                        ],
                        "name": "W. Chou",
                        "slug": "W.-Chou",
                        "structuredName": {
                            "firstName": "Wu",
                            "lastName": "Chou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Chou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17976965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d63cdc1d1f023c63f8aa3b64cd5e853670680c3e",
            "isKey": false,
            "numCitedBy": 191,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we studied the objective functions of MMI, MCE, and MPE/MWE for discriminative learning in sequential pattern recognition. We presented an approach that unifies the objective functions of MMI, MCE, and MPE/MWE in a common rational-function form of (25). The exact structure of the rational-function form for each discriminative criterion was derived and studied. While the rational-function form of MMI has been known in the past, we provided the theoretical proof that the similar rational-function form exists for the objective functions of MCE and MPE/MWE. Moreover, we showed that the rational function forms for objective functions of MMI, MCE, and MPE/MWE differ in the constant weighting factors CDT (s1 . . . sR) and these weighting factors depend only on the labeled sequence s1 . . . sR, and are independent of the parameter set - to be optimized. The derived rational-function form for MMI, MCE, and MPE/MWE allows the GT/EBW-based parameter optimization framework to be applied directly in discriminative learning. In the past, lack of the appropriate rational-function form was a difficulty for MCE and MPE/MWE, because without this form, the GT/EBW-based parameter optimization framework cannot be directly applied. Based on the unified rational-function form, in a tutorial style, we derived the GT/EBW-based parameter optimization formulas for both discrete HMMs and CDHMMs in discriminative learning using MMI, MCE, and MPE/MWE criteria. The unifying review provided in this article has been based upon a large number of earlier contributions that have been cited and discussed throughout the article. Here we provide a brief summary of such background work. Extension to large-scale speech recognition tasks was accomplished in the work of [59] and [60]. The dissertation of [47] further improved the MMI criterion to that of MPE/MWE. In a parallel vein, the work of [20] provided an alternative approach to that of [41], with an attempt to more rigorously provide a CDHMM model re-estimation formula that gives positive growth of the MMI objective function. A crucial error of this attempt was corrected in [2] for establishing an existence proof of such positive growth. The main goal of this article is to provide an underlying foundation for MMI, MCE, and MPE/MWE at the objective function level to facilitate the development of new parameter optimization techniques and to incorporate other pattern recognition concepts, e.g., discriminative margins [66], into the current discriminative learning paradigm."
            },
            "slug": "Discriminative-learning-in-sequential-pattern-He-Deng",
            "title": {
                "fragments": [],
                "text": "Discriminative learning in sequential pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The main goal of this article is to provide an underlying foundation for MMI, MCE, and MPE/MWE at the objective function level to facilitate the development of new parameter optimization techniques and to incorporate other pattern recognition concepts, e.g., discriminative margins [66], into the current discrim inative learning paradigm."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077257730"
                        ],
                        "name": "Kevin Jarrett",
                        "slug": "Kevin-Jarrett",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Jarrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Jarrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206769720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f88427d7aa8225e47f946ac41a0667d7b69ac52",
            "isKey": false,
            "numCitedBy": 2084,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%)."
            },
            "slug": "What-is-the-best-multi-stage-architecture-for-Jarrett-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "What is the best multi-stage architecture for object recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks and that two stages of feature extraction yield better accuracy than one."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "After [34] showed that deep auto-encoders could be trained effectively using deep belief net pre-training, there was a resurgence of interest in using"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "For example, [34] reports in one experiment that they are unable to get results nearly so good as those possible"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": false,
            "numCitedBy": 14635,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 232
                            }
                        ],
                        "text": "In this paper, we use the DBN weights resulting from the unsupervised pre-training algorithm to initialize the weights of a deep, but otherwise standard, feed-forward neural network and then simply use the backpropagation algorithm [61] to fine-tune the network weights with respect to a supervised criterion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205001834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "isKey": false,
            "numCitedBy": 20330,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1."
            },
            "slug": "Learning-representations-by-back-propagating-errors-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning representations by back-propagating errors"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Back-propagation repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector, which helps to represent important features of the task domain."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 158
                            }
                        ],
                        "text": "Since RBMs are in the intersection between Boltzmann machines and product of experts models, they can be trained using contrastive divergence as described in [67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4567,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722800"
                        ],
                        "name": "J. Hennebert",
                        "slug": "J.-Hennebert",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Hennebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980449"
                        ],
                        "name": "C. Ris",
                        "slug": "C.-Ris",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Ris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733733"
                        ],
                        "name": "H. Bourlard",
                        "slug": "H.-Bourlard",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Bourlard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bourlard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086187"
                        ],
                        "name": "S. Renals",
                        "slug": "S.-Renals",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Renals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Renals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12465945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bc9be16cfd119e822bc1d572fb028053a3d4caa",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Keywords: Non-Linear Signal Processing ; Speech Processing Reference LANOS-CONF-1997-001 Record created on 2004-12-03, modified on 2017-05-12"
            },
            "slug": "Estimation-of-global-posteriors-and-training-of-Hennebert-Ris",
            "title": {
                "fragments": [],
                "text": "Estimation of global posteriors and forward-backward training of hybrid HMM/ANN systems"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Non-Linear Signal Processing ; Speech Processing Reference LANOS-CONF-1997-001 Record created on 2004-12-03, modified on 2017-05-12."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107569404"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9391905"
                        ],
                        "name": "Chin-Hui Lee",
                        "slug": "Chin-Hui-Lee",
                        "structuredName": {
                            "firstName": "Chin-Hui",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Hui Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "79770421"
                        ],
                        "name": "D. O'Shaughnessy",
                        "slug": "D.-O'Shaughnessy",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "O'Shaughnessy",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. O'Shaughnessy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19014381,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "f5790cd41fbd09dc01b061fb17ea1d661cab5ac4",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This article is the second part of an updated version of the \"MINDS 2006-2007 Report of the Speech Understanding Working Group,\" one of five reports emanating from two workshops entitled \"Meeting of the MINDS: Future Directions for Human Language Technology,\" sponsored by the U.S. Disruptive Technology Office (DTO). (MINDS is an acronym for \"machine translation, information retrieval, natural-language processing, data resources, and speech understanding\")."
            },
            "slug": "Updated-MINDS-report-on-speech-recognition-and-Part-Baker-Deng",
            "title": {
                "fragments": [],
                "text": "Updated MINDS report on speech recognition and understanding, Part 2 [DSP Education]"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This article is the second part of an updated version of the \"MINDS 2006-2007 Report of the Speech Understanding Working Group,\" one of five reports emanating from two workshops entitled \"Meeting of the MINDS: Future Directions for Human Language Technology,\" sponsored by the U.S. Disruptive Technology Office (DTO)."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460212"
                        ],
                        "name": "Olivier Delalleau",
                        "slug": "Olivier-Delalleau",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Delalleau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Delalleau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28495805"
                        ],
                        "name": "Clarence Simard",
                        "slug": "Clarence-Simard",
                        "structuredName": {
                            "firstName": "Clarence",
                            "lastName": "Simard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Clarence Simard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[64] proved that constant leaf decision trees require a number of training cases exponential in their input dimensionality to learn certain rapidly varying functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15775927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c34be4a906a86b2ebc09078d80247227cd54453",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The family of decision tree learning algorithms is among the most widespread and studied. Motivated by the desire to develop learning algorithms that can generalize when learning highly varying functions such as those presumably needed to achieve artificial intelligence, we study some theoretical limitations of decision trees. We demonstrate formally that they can be seriously hurt by the curse of dimensionality in a sense that is a bit different from other nonparametric statistical methods, but most importantly, that they cannot generalize to variations not seen in the training set. This is because a decision tree creates a partition of the input space and needs at least one example in each of the regions associated with a leaf to make a sensible prediction in that region. A better understanding of the fundamental reasons for this limitation suggests that one should use forests or even deeper architectures instead of trees, which provide a form of distributed representation and can generalize to variations not encountered in the training data."
            },
            "slug": "DECISION-TREES-DO-NOT-GENERALIZE-TO-NEW-VARIATIONS-Bengio-Delalleau",
            "title": {
                "fragments": [],
                "text": "DECISION TREES DO NOT GENERALIZE TO NEW VARIATIONS"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated formally that decision trees can be seriously hurt by the curse of dimensionality in a sense that is a bit different from other nonparametric statistical methods, but most importantly that they cannot generalize to variations not seen in the training set."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Intell."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2767150"
                        ],
                        "name": "D. Vergyri",
                        "slug": "D.-Vergyri",
                        "structuredName": {
                            "firstName": "Dimitra",
                            "lastName": "Vergyri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Vergyri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33638380"
                        ],
                        "name": "Arindam Mandal",
                        "slug": "Arindam-Mandal",
                        "structuredName": {
                            "firstName": "Arindam",
                            "lastName": "Mandal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arindam Mandal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47825073"
                        ],
                        "name": "Weiqi Wang",
                        "slug": "Weiqi-Wang",
                        "structuredName": {
                            "firstName": "Weiqi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiqi Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762744"
                        ],
                        "name": "A. Stolcke",
                        "slug": "A.-Stolcke",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Stolcke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stolcke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143851659"
                        ],
                        "name": "Jing Zheng",
                        "slug": "Jing-Zheng",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790301"
                        ],
                        "name": "M. Graciarena",
                        "slug": "M.-Graciarena",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Graciarena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Graciarena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743961"
                        ],
                        "name": "David Rybach",
                        "slug": "David-Rybach",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rybach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Rybach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3165395"
                        ],
                        "name": "Christian Gollan",
                        "slug": "Christian-Gollan",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Gollan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Gollan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144490010"
                        ],
                        "name": "R. Schl\u00fcter",
                        "slug": "R.-Schl\u00fcter",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Schl\u00fcter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schl\u00fcter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783839"
                        ],
                        "name": "Katrin Kirchhoff",
                        "slug": "Katrin-Kirchhoff",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Kirchhoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Kirchhoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27001288"
                        ],
                        "name": "Arlo Faria",
                        "slug": "Arlo-Faria",
                        "structuredName": {
                            "firstName": "Arlo",
                            "lastName": "Faria",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arlo Faria"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144798098"
                        ],
                        "name": "N. Morgan",
                        "slug": "N.-Morgan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Morgan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Morgan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": ", [51]\u2013[54]) train neural networks on LVSR datasets (often in excess of 1000 hours of data) and use variants of these approaches, either augmenting the input to a GMM-HMM system with features"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15129890,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89148c5e0f62aae43ef575e07bca43ddba988470",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the large vocabulary automatic speech recognition system developed for Modern Standard Arabic by the SRI/Nightingale team, and used for the 2007 GALE evaluation as part of the speech translation system. We show how system performance is affected by different development choices, ranging from text processing and lexicon to decoding system architecture design. Word error rate results are reported on broadcast news and conversational data from the GALE development and evaluation test sets."
            },
            "slug": "Development-of-the-SRI/nightingale-Arabic-ASR-Vergyri-Mandal",
            "title": {
                "fragments": [],
                "text": "Development of the SRI/nightingale Arabic ASR system"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The large vocabulary automatic speech recognition system developed for Modern Standard Arabic by the SRI/Nightingale team is described and how system performance is affected by different development choices, ranging from text processing and lexicon to decoding system architecture design."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460212"
                        ],
                        "name": "Olivier Delalleau",
                        "slug": "Olivier-Delalleau",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Delalleau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Delalleau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7245737"
                        ],
                        "name": "Nicolas Le Roux",
                        "slug": "Nicolas-Le-Roux",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Le Roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Le Roux"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "In a related vein, [65] also proves an analogous \u201ccurse of rapidly-varying functions\u201d for a large class of local kernel machines that include both supervised learning algorithms (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8924778,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7d471970467a99bec4bce34c7dba5ef6745ad06",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior - with similarity between examples expressed with a local kernel - are sensitive to the curse of dimensionality, or more precisely to the variability of the target. Our discussion covers supervised, semi-supervised and unsupervised learning algorithms. These algorithms are found to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set. This makes them sensitive to the curse of dimensionality, well studied for classical non-parametric statistical learning. We show in the case of the Gaussian kernel that when the function to be learned has many variations, these algorithms require a number of training examples proportional to the number of variations, which could be large even though there may exist short descriptions of the target function, i.e. their Kolmogorov complexity may be low. This suggests that there exist non-local learning algorithms that at least have the potential to learn about such structured but apparently complex functions (because locally they have many variations), while not using very specific prior domain knowledge."
            },
            "slug": "The-Curse-of-Highly-Variable-Functions-for-Local-Bengio-Delalleau",
            "title": {
                "fragments": [],
                "text": "The Curse of Highly Variable Functions for Local Kernel Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A series of theoretical arguments are presented supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior - with similarity between examples expressed with a local kernel - are sensitive to the curse of dimensionality, or more precisely to the variability of the target."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704247"
                        ],
                        "name": "James Martens",
                        "slug": "James-Martens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Martens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "pre-training or a sophisticated optimizer of the sort used in [58]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11154521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c46347fbc272b21468efe3d9af34b4b2bad6684",
            "isKey": false,
            "numCitedBy": 844,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a 2nd-order optimization method based on the \"Hessian-free\" approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks they considered. Our method is practical, easy to use, scales nicely to very large datasets, and isn't limited in applicability to auto-encoders, or any specific model class. We also discuss the issue of \"pathological curvature\" as a possible explanation for the difficulty of deep-learning and how 2nd-order optimization, and our method in particular, effectively deals with it."
            },
            "slug": "Deep-learning-via-Hessian-free-optimization-Martens",
            "title": {
                "fragments": [],
                "text": "Deep learning via Hessian-free optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A 2nd-order optimization method based on the \"Hessian-free\" approach is developed, and applied to training deep auto-encoders, and results superior to those reported by Hinton & Salakhutdinov (2006) are obtained."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678311"
                        ],
                        "name": "M. Welling",
                        "slug": "M.-Welling",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Welling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Welling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398315116"
                        ],
                        "name": "M. Rosen-Zvi",
                        "slug": "M.-Rosen-Zvi",
                        "structuredName": {
                            "firstName": "Michal",
                            "lastName": "Rosen-Zvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rosen-Zvi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "The Gaussian\u2013Bernoulli restricted Boltzmann machine (GRBM) only requires a slight modification of (3) (see [68] for a generalization of RBMs to any distribution in the exponential family)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2388827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2184fb6d32bc46f252b940035029273563c4fc82",
            "isKey": false,
            "numCitedBy": 502,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Directed graphical models with one layer of observed random variables and one or more layers of hidden random variables have been the dominant modelling paradigm in many research fields. Although this approach has met with considerable success, the causal semantics of these models can make it difficult to infer the posterior distribution over the hidden variables. In this paper we propose an alternative two-layer model based on exponential family distributions and the semantics of undirected models. Inference in these \"exponential family harmoniums\" is fast while learning is performed by minimizing contrastive divergence. A member of this family is then studied as an alternative probabilistic model for latent semantic indexing. In experiments it is shown that they perform well on document retrieval tasks and provide an elegant solution to searching with keywords."
            },
            "slug": "Exponential-Family-Harmoniums-with-an-Application-Welling-Rosen-Zvi",
            "title": {
                "fragments": [],
                "text": "Exponential Family Harmoniums with an Application to Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "An alternative two-layer model based on exponential family distributions and the semantics of undirected models is proposed, which performs well on document retrieval tasks and provides an elegant solution to searching with keywords."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "helpful (even in some cases for large single hidden layer neural networks trained on massive datasets, as in [28])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15095719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b16106e35ff9ff97ffb73eb9c84b73ce1264c67",
            "isKey": false,
            "numCitedBy": 469,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Reliably extracting information from aerial imagery is a difficult problem with many practical applications. One specific case of this problem is the task of automatically detecting roads. This task is a difficult vision problem because of occlusions, shadows, and a wide variety of non-road objects. Despite 30 years of work on automatic road detection, no automatic or semi-automatic road detection system is currently on the market and no published method has been shown to work reliably on large datasets of urban imagery. We propose detecting roads using a neural network with millions of trainable weights which looks at a much larger context than was used in previous attempts at learning the task. The network is trained on massive amounts of data using a consumer GPU. We demonstrate that predictive performance can be substantially improved by initializing the feature detectors using recently developed unsupervised learning methods as well as by taking advantage of the local spatial coherence of the output labels.We show that our method works reliably on two challenging urban datasets that are an order of magnitude larger than what was used to evaluate previous approaches."
            },
            "slug": "Learning-to-Detect-Roads-in-High-Resolution-Aerial-Mnih-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning to Detect Roads in High-Resolution Aerial Images"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes detecting roads using a neural network with millions of trainable weights which looks at a much larger context than was used in previous attempts at learning the task, and shows that the method works reliably on two challenging urban datasets that are an order of magnitude larger than what was used to evaluate previous approaches."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061652703"
                        ],
                        "name": "Neal Bernstein",
                        "slug": "Neal-Bernstein",
                        "structuredName": {
                            "firstName": "Neal",
                            "lastName": "Bernstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neal Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059072947"
                        ],
                        "name": "Rob Chambers",
                        "slug": "Rob-Chambers",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Chambers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rob Chambers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740054"
                        ],
                        "name": "Y. Ju",
                        "slug": "Y.-Ju",
                        "structuredName": {
                            "firstName": "Yun-Cheng",
                            "lastName": "Ju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Ju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155447885"
                        ],
                        "name": "Xinggang Li",
                        "slug": "Xinggang-Li",
                        "structuredName": {
                            "firstName": "Xinggang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinggang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054927716"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067321183"
                        ],
                        "name": "Oliver Scholz",
                        "slug": "Oliver-Scholz",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Scholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oliver Scholz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681543"
                        ],
                        "name": "G. Zweig",
                        "slug": "G.-Zweig",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Zweig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zweig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "application (formerly known as Live Search for mobile [36], [60]) under real usage scenarios."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 300
                            }
                        ],
                        "text": "To evaluate the proposed CD-DNN-HMMs and to understand the effect of different decisions made at each step of CD-DNN-HMM training, we have conducted a series of experiments on a business search dataset collected from the Bing mobile voice search application (formerly known as Live Search for mobile [36], [60])\u2014a real-world large-vocabulary spontaneous speech recognition task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "inatively-trained context-dependent Gaussian mixture model hidden Markov model (CD-GMM-HMM) baselines on the challenging business search dataset of [36], collected under actual usage conditions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11752858,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7b542a38c5e5eb731afaade0a75c41abac0c6a4",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Live search for mobile is a cellphone application that allows users to interact with Web-based information portals. Currently the implementation is focused on information related to local businesses: their phone numbers and addresses, directions, reviews, maps of the surrounding area, and traffic. This paper describes a speech-recognition interface which was recently developed for the application, which allows the users to interact by voice. The paper presents the overall architecture, the user interface, the design and implementation of the speech recognition grammars, and initial performance results indicating that for sentence level utterance recognition we achieve 60 to 65% of human capability."
            },
            "slug": "Live-search-for-mobile:Web-services-by-voice-on-the-Acero-Bernstein",
            "title": {
                "fragments": [],
                "text": "Live search for mobile:Web services by voice on the cellphone"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A speech-recognition interface which was recently developed for live search for mobile, which allows the users to interact by voice, and initial performance results indicating that for sentence level utterance recognition the authors achieve 60 to 65% of human capability."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "We used the CUDAMat library [71] to per-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58732357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ea90fac0958d84bcf4a2875c2b169478358b480",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "CUDAMat is an open source software package that provides a CUDA-based matrix class for Python. The primary goal of CUDAMat is to make it easy to implement algorithms that are easily expressed in terms of dense matrix operations on a GPU. At present, the feature set of CUDAMat is biased towards providing functionality useful for implementing standard machine learning algorithms, however, it is general enough to be useful in other elds. We have used CUDAMat to implement several common machine learning algorithms on GPUs oering speedups of up to 50x over numpy and MATLAB implementations."
            },
            "slug": "CUDAMat:-a-CUDA-based-matrix-class-for-Python-Mnih",
            "title": {
                "fragments": [],
                "text": "CUDAMat: a CUDA-based matrix class for Python"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The feature set of CUDAMat is biased towards providing functionality useful for implementing standard machine learning algorithms, however, it is general enough to be useful in other elds."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703049"
                        ],
                        "name": "D. DeCoste",
                        "slug": "D.-DeCoste",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "DeCoste",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. DeCoste"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As argued in [62] and [63], insufficiently deep architectures can require an exponential blow-up in the number of computational elements needed to represent certain functions satisfactorily."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63554834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b04183465150e98e9b277a8dd5bdafba159528e",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction, LearningModels Toward AI, Learning Architectures, Shallow and Deep, Fundamental Limitation of Local Learning, Deep Architectures, Experiments with Visual Pattern Recognition, Conclusion"
            },
            "slug": "Scaling-Learning-Algorithms-toward-AI-Bottou-Chapelle",
            "title": {
                "fragments": [],
                "text": "Scaling Learning Algorithms toward AI"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction, LearningModels Toward AI, Learning Architectures, Shallow and Deep, Fundamental Limitation of Local Learning, Deep Architecture, Experiments with Visual Pattern Recognition, Conclusion."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 533055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f7476037408ac3d993f5088544aab427bc319c1",
            "isKey": false,
            "numCitedBy": 1947,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : At this early stage in the development of cognitive science, methodological issues are both open and central. There may have been times when developments in neuroscience, artificial intelligence, or cognitive psychology seduced researchers into believing that their discipline was on the verge of discovering the secret of intelligence. But a humbling history of hopes disappointed has produced the realization that understanding the mind will challenge the power of all these methodologies combined. The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis. The success of cognitive science, like that of many other sciences, will, I believe, depend upon the construction of a solid body of theoretical results: results that express in a mathematical language the conceptual insights of the field; results that squeeze all possible implications out of those insights by exploiting powerful mathematical techniques. This body of results, which I will call the theory of information processing, exists because information is a concept that lends itself to mathematical formalization. One part of the theory of information processing is already well-developed. The classical theory of computation provides powerful and elegant results about the notion of effective procedure, including languages for precisely expressing them and theoretical machines for realizing them."
            },
            "slug": "Information-processing-in-dynamical-systems:-of-Smolensky",
            "title": {
                "fragments": [],
                "text": "Information processing in dynamical systems: foundations of harmony theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110094"
                        ],
                        "name": "J. Bridle",
                        "slug": "J.-Bridle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Bridle",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bridle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "sion of speech inputs have been analyzed in detail in [78]\u2013[81]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63287451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b539c31c30a9c67807c27c5eca3e902ca7154117",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-investigation-of-segmental-hidden-dynamic-models-Bridle",
            "title": {
                "fragments": [],
                "text": "An investigation of segmental hidden dynamic models of speech coarticulation for automatic speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2026by the prior probability (called scaled likelihood estimation by [38], [40], [41]) may not give improved recognition accuracy under some conditions, we have found it to be very important in alleviating the label bias problem, especially when the training utterances contain long silence segments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60267605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76555d53ed889e231e9f5f3791b357d3f95c3747",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Bidirectional-Target-Filtering-Model-of-Speech-Deng-Yu",
            "title": {
                "fragments": [],
                "text": "A Bidirectional Target Filtering Model of Speech Coarticulation: two-stage Implementation for Phonetic Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A segmental conditional random field toolkit for speech recognition , \u201d in"
            },
            "venue": {
                "fragments": [],
                "text": "Proc . Interspeech"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pushing the envelope \u2014 Aside Shared - distribution hidden Markov models for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . Speech Audio Process ."
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 290
                            }
                        ],
                        "text": "\u2026to use HMM advances from the speech research community directly without developing replacement techniques and tools contributed to a shift from using neural nets to predict phonetic states to using neural nets to augment features for later use in a conventional GMM-HMM recognizer (e.g., [47])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pushing the envelope\u2014Aside"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Process. Mag., vol. 22, no. 5, pp. 81\u201388, Sep. 2005."
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scaling learning algorithms towards AI , \u201d in Large - Scale Kernel Machines"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "text - dependent connectionist probability estimation in a hybrid hidden Markov model - neural net speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans . Speech Audio Process ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "text - dependent connectionist probability estimation in a hybrid hidden Markov model - neural net speech recognition system"
            },
            "venue": {
                "fragments": [],
                "text": "Comput . Speech Lang ."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimizing bottleneck features for LVCSR , \u201d in Proc . ICASSP"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 49,
            "methodology": 21,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 93,
        "totalPages": 10
    },
    "page_url": "https://www.semanticscholar.org/paper/Context-Dependent-Pre-Trained-Deep-Neural-Networks-Dahl-Yu/6658bbf68995731b2083195054ff45b4eca38b3a?sort=total-citations"
}