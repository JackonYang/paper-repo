{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110561587"
                        ],
                        "name": "Chien-Yuan Huang",
                        "slug": "Chien-Yuan-Huang",
                        "structuredName": {
                            "firstName": "Chien-Yuan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chien-Yuan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694992"
                        ],
                        "name": "O. Camps",
                        "slug": "O.-Camps",
                        "structuredName": {
                            "firstName": "Octavia",
                            "lastName": "Camps",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Camps"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143626870"
                        ],
                        "name": "T. Kanungo",
                        "slug": "T.-Kanungo",
                        "structuredName": {
                            "firstName": "Tapas",
                            "lastName": "Kanungo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanungo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16886042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "beec814a8ad1b37e27755b504ab441c6942a324d",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The recognition of general three-dimensional objects in cluttered scenes is a challenging problem. In particular, the design of a good representation suitable to model large numbers of generic objects that is also robust to occlusion has been a stumbling block in achieving success. In this paper, we propose a representation using appearance-based parts and relations to overcome these problems. Appearance-based parts and relations are defined in terms of closed regions and the union of these regions, respectively. The regions are segmented using the MDL principle, and their appearance is obtained from collection of images and compactly represented by parametric manifolds in the two eigenspaces spanned by the parts and the relations."
            },
            "slug": "Object-recognition-using-appearance-based-parts-and-Huang-Camps",
            "title": {
                "fragments": [],
                "text": "Object recognition using appearance-based parts and relations"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes a representation using appearance-based parts and relations to overcome problems of recognition of general three-dimensional objects in cluttered scenes and its design has been a stumbling block in achieving success."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 34
                            }
                        ],
                        "text": "This is in contrast to results by Murase and Nayar [18] where only one of the two out-of-plane rotational degrees of freedom is spanned."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 5
                            }
                        ],
                        "text": "Both Nayar\u2019s and Mohr\u2019s approaches carry out recognition tests only over a 1-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Nayar presents results using eigenspace techniques for 3-"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Of the appearance-based techniques not using color, the best results on large, real image databases have been reported by Murase and Nayar [18] and Schmid and Mohr [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Murase and Nayar [18] find the major principal components of an image dataset, and use the projections of unknown images onto these as indices into a recognition memory."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": ") This is in contrast to results by Murase and Nayar [18] where only one of the two out-of-plane rotational degrees of freedom is spanned."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 130
                            }
                        ],
                        "text": "D recognition and obtains good results for a few tens of objects, again training over a circle rather than the full sphere (using Nayar\u2019s database in fact)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 126
                            }
                        ],
                        "text": "(We expect there is a factor of 5\u201310 between the number of images required to cover the full sphere as opposed to a circle for Nayar\u2019s approach.)"
                    },
                    "intents": []
                }
            ],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": true,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "Notable recent examples are Lowe [1], Lamdan and Wolfson [2], Huttenlocher and Ullman [3], and Grimson [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "Another featurebased example is a recent generalization of the alignment method by Huttenlocher and Lorigo [22] which finds consistent point matches via linear combination of model feature images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 90
                            }
                        ],
                        "text": "Analyses of the performance of some of these schemes is given by Grimson and Huttenlocher [5,6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33470636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "754b3ce07da5ea86193c4f4733be80fa72de5858",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition from sensory data involves, in part, determining the pose of a model with respect to a scene. A common method for finding an object's pose is the generalized Hough transform, which accumulates evidence for possible coordinate transformations in a parameter space whose axes are the quantized transformation parameters. Large clusters of similar transformations in that space are taken as evidence of a correct match. A theoretical analysis of the behavior of such methods is presented. The authors derive bounds on the set of transformations consistent with each pairing of data and model features, in the presence of noise and occlusion in the image. Bounds are provided on the likelihood of false peaks in the parameter space, as a function of noise, occlusion, and tessellation effects. It is argued that haphazardly applying such methods to complex recognition tasks is risky, as the probability of false positives can be very high. >"
            },
            "slug": "On-The-Sensitivity-Of-The-Hough-Transform-For-Grimson-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "On the Sensitivity of the Hough Transform for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is argued that haphazardly applying generalized Hough transform methods to complex recognition tasks is risky, as the probability of false positives can be very high."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "Notable recent examples are Lowe [1], Lamdan and Wolfson [2], Huttenlocher and Ullman [3], and Grimson [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 678619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8735690a9e8f8884bf27717877ddf7f9071472e5",
            "isKey": false,
            "numCitedBy": 1457,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Three-Dimensional-Object-Recognition-from-Single-Lowe",
            "title": {
                "fragments": [],
                "text": "Three-Dimensional Object Recognition from Single Two-Dimensional Images"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144827643"
                        ],
                        "name": "N. Ayache",
                        "slug": "N.-Ayache",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Ayache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ayache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6559782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9191de6f4059469b54cb576322e331c51312dc6f",
            "isKey": false,
            "numCitedBy": 559,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method has been designed to identify and locate objects lying on a flat surface. The merit of the approach is to provide strong robustness to partial occlusions (due for instance to uneven lighting conditions, shadows, highlights, touching and overlapping objects) thanks to a local and compact description of the objects boundaries and to a new fast recognition method involving generation and recursive evaluation of hypotheses named HYPER (HY potheses Predicted and Evaluated Recursively). The method has been integrated within a vision system coupled to an indutrial robot arm, to provide automatic picking and repositioning of partially overlapping industrial parts."
            },
            "slug": "HYPER:-A-New-Approach-for-the-Recognition-and-of-Ayache-Faugeras",
            "title": {
                "fragments": [],
                "text": "HYPER: A New Approach for the Recognition and Positioning of Two-Dimensional Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The method has been integrated within a vision system coupled to an indutrial robot arm, to provide automatic picking and repositioning of partially overlapping industrial parts to provide strong robustness to partial occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "In recent work, Poggio and Edelman [14] have recognized wire objects and Brunelli and Poggio [15] have recognized faces using appearance models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4361875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50899b2355d6908a304bacb5e406f800f3dde558",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "THE visual recognition of three-dimensional (3-D) objects on the basis of their shape poses at least two difficult problems. First, there is the problem of variable illumination, which can be addressed by working with relatively stable features such as intensity edges rather than the raw intensity images1,2. Second, there is the problem of the initially unknown pose of the object relative to the viewer. In one approach to this problem, a hypothesis is first made about the viewpoint, then the appearance of a model object from such a viewpoint is computed and compared with the actual image3\u20137. Such recognition schemes generally employ 3-D models of objects, but the automatic learning of 3-D models is itself a difficult problem8,9. To address this problem in computational vision, we have developed a scheme, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view. A network equivalent to this scheme will thus 'recognize' the object on which it was trained from any viewpoint."
            },
            "slug": "A-network-that-learns-to-recognize-objects-Poggio-Edelman",
            "title": {
                "fragments": [],
                "text": "A network that learns to recognize three-dimensional objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A scheme is developed, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view, and a network equivalent to this scheme will 'recognize' the object on which it was trained from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46817286"
                        ],
                        "name": "F. Stein",
                        "slug": "F.-Stein",
                        "structuredName": {
                            "firstName": "Fridtjof",
                            "lastName": "Stein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3463966"
                        ],
                        "name": "G. Medioni",
                        "slug": "G.-Medioni",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Medioni",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Medioni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5329255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2f8292adaeed138fcb63bf9de7d7f79127e6096",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of recognition of multiple flat objects in a cluttered environment from an arbitrary viewpoint (weak perspective) is addressed. The models are acquired automatically and initially approximated by polygons with multiple line tolerances for robustness. Groups of consecutive segments (supersegments) are then gray-coded and entered into a hash table. This provides the essential mechanism for indexing and fast retrieval. Once the database of all models is built, the recognition proceeds by segmenting the scene into a polygonal approximation; the gray code for each supersegment retrieves model hypotheses from the hash table. Hypotheses are clustered if they are mutually consistent and represent the instance of a model. The estimate of the transformation is refined. This methodology makes it possible to recognize models in the presence of noise, occlusion, scale, rotation, translation, and weak perspective. Unlike most of the current systems, its complexity grows as O(kN), where N is the number of models and k<<1/.<<ETX>>"
            },
            "slug": "Efficient-two-dimensional-object-recognition-Stein-Medioni",
            "title": {
                "fragments": [],
                "text": "Efficient two dimensional object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540531"
                        ],
                        "name": "Liana M. Lorigo",
                        "slug": "Liana-M.-Lorigo",
                        "structuredName": {
                            "firstName": "Liana",
                            "lastName": "Lorigo",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liana M. Lorigo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28647867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b900851aca0872dd0d87c22ed32335eb38f5e36",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we address the problem of recognizing an object from a novel viewpoint, given a single \"model\" view of that object. As is common in model-based recognition, objects and images are represented as sets of feature points. We present an efficient algorithm for determining whether two sets of image points (in the plane) could be projections of a common object (a three-dimensional point set). The method relies on the fact that two sets of points in the plane are orthographic projections of the same three-dimensional point set exactly when they have a common projection onto a line. This is a form of the well-known epipolar constraint used in stereopsis. Our algorithm can be used to recognize an object by comparing a stored two-dimensional view of the object against an unknown view, without requiring the correspondence between points in the views to be known a priori. We provide some examples illustrating the approach."
            },
            "slug": "Recognizing-three-dimensional-objects-by-comparing-Huttenlocher-Lorigo",
            "title": {
                "fragments": [],
                "text": "Recognizing three-dimensional objects by comparing two-dimensional images"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The algorithm can be used to recognize an object by comparing a stored two-dimensional view of the object against an unknown view, without requiring the correspondence between points in the views to be known a priori."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8768879"
                        ],
                        "name": "H. Bulthoff",
                        "slug": "H.-Bulthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Bulthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bulthoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 222
                            }
                        ],
                        "text": "Their experiments showed that even in the case of human observers, generalization to novel views was severely limited, with performance dropping to chance levels at a misorientation of about 40\u00b0 relative to familiar views [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 282
                            }
                        ],
                        "text": "More recent work, however, while confirming that people are indeed able to perform mental operations that seem most consistent with the existence of 3-D, object-centered representations, has raised questions about whether these representations are what is used for fast recognition [28,29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17772311,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "033b36f280b437fdf15bcba2a43f118a4544f930",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The topics discussed here are network models of object recognition; a computational theory of recognition; psychophysical support for a view-interpolation model: and an open issue, features of recognition. The authors survey a successful replication of central characteristics of performance in 3-D object recognition by a computational model based on interpolation among a number of stored views of each object. Network models of 3-D object recognition based on interpolation among specific stored views behave in several respects similarly to human observers in a number of recognition tasks. Even closer replication of human performance in recognition should be expected, once the issue of the features used to represent object views is resolved.<<ETX>>"
            },
            "slug": "Modeling-human-visual-object-recognition-Edelman-Bulthoff",
            "title": {
                "fragments": [],
                "text": "Modeling human visual object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The authors survey a successful replication of central characteristics of performance in 3-D object recognition by a computational model based on interpolation among a number of stored views of each object."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20693764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5271110e0b1ef852fd3bd3ed57b1932e08642e",
            "isKey": false,
            "numCitedBy": 966,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A general method for model-based object recognition in occluded scenes is presented. It is based on geometric hashing. The method stands out for its efficiency. We describe the general framework of the method and illustrate its applications for various recogni- tion problems both in 3-D and 2-D. Special attention is given to the recognition of 3-D objects in occluded scenes from 2-D gray scale images. New experimental results are included for this important case."
            },
            "slug": "Geometric-Hashing:-A-General-And-Efficient-Scheme-Lamdan-Wolfson",
            "title": {
                "fragments": [],
                "text": "Geometric Hashing: A General And Efficient Model-based Recognition Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A general method for model-based object recognition in occluded scenes is presented based on geometric hashing, which stands out for its efficiency and applications both in 3-D and 2-D."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10291007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a221ae60093283ef438e8b69e26094a2480a6299",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of recognizing objects in large image databases. The method is based on local characteristics which are invariant to similarity transformations in the image. These characteristics are computed at automatically detected keypoints using the greyvalue signal. The method therefore works on images such as paintings for which geometry based recognition fails. Due to the locality of the method, images can be recognized being given part of an image and in the presence of occlusions. Applying a voting algorithm and semi-local constraints makes the method robust to noise, scene clutter and small perspective deformations. Experiments show an efficient recognition for different types of images. The approach has been validated on an image database containing 1020 images, some of them being very similar by structure, texture or shape."
            },
            "slug": "Combining-greyvalue-invariants-with-local-for-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Combining greyvalue invariants with local constraints for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The method is based on local characteristics which are invariant to similarity transformations in the image and computed at automatically detected keypoints using the greyvalue signal and works on images such as paintings for which geometry based recognition fails."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50763023"
                        ],
                        "name": "Jin-Long Chen",
                        "slug": "Jin-Long-Chen",
                        "structuredName": {
                            "firstName": "Jin-Long",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jin-Long Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2663129"
                        ],
                        "name": "G. Stockman",
                        "slug": "G.-Stockman",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Stockman",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stockman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35146060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79a215763ee8741f3fb01f810d892215d4f33044",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a shape-based method of indexing to model aspects from a single intensity image. Objects are assumed to be rigid. A model aspect is represented by a 2 1/2 D edgemap and the parts of the object silhouette. Part decomposition is derived from a codon representation of the object silhouette. Invariant features extracted from each part are then used to index into a hash table to generate model-aspect hypotheses. Knowledge about parts is incorporated in voting schemes to order hypotheses for efficient verification of candidate models. Verification of model-aspect hypotheses is carried out by an alignment algorithm that is robust to partial occlusion. Results of tests using 658 model aspects from 100 objects demonstrate that accurate recognition can be achieved with very few verification attempts."
            },
            "slug": "Indexing-to-3D-model-aspects-using-2D-contour-Chen-Stockman",
            "title": {
                "fragments": [],
                "text": "Indexing to 3D model aspects using 2D contour features"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Results of tests demonstrate that accurate recognition can be achieved with very few verification attempts and a shape-based method of indexing to model aspects from a single intensity image."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Notable recent examples are Lowe [1], Lamdan and Wolfson [2], Huttenlocher and Ullman [3], and Grimson [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 65
                            }
                        ],
                        "text": "Analyses of the performance of some of these schemes is given by Grimson and Huttenlocher [5,6]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1530384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4462c82748d81489f4f453f516754438b35a8cec",
            "isKey": false,
            "numCitedBy": 961,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "With contributions from Tomas LozanoPerez and Daniel P. Huttenlocher.An intelligent system must know \"what \"the objects are and \"where \"they are in its environment. Examples of this ubiquitous problem in computer vision arise in tasks involving hand-eye coordination (such as assembling or sorting), inspection tasks, gauging operations, and in navigation and localization of mobile robots. This book describes an extended series of experiments into the role of geometry in the critical area of object recognition. It provides precise definitions of the recognition and localization problems, describes the methods used to address them, analyzes the solutions to these problems, and addresses the implications of this analysis.The solution to problems of object recognition are of fundamental importance in many real applications and versions of the techniques described here are already being used in industrial settings. Although a number of questions remain to be solved, the authors provide a valuable framework for understanding both the strengths and limitations of using object shape to guide recognition.W. Eric L. Grimson is Matsushita Associate Professor in the Department of Electrical Engineering and Computer Science at MIT.Contents: Introduction. Recognition as a Search Problem. Searching for Correspondences. Two-Dimensional Constraints. Three-Dimensional Constraints. Verifying Hypotheses. Controlling the Search Explosion. Selecting Subspaces of the Search Space. Empirical Testing. The Combinatorics of the Matching Process. The Combinatorics of Hough Transforms. The Combinatorics of Verification. The Combinatorics of Indexing. Evaluating the Methods. Recognition from Libraries. Parameterized Objects. The Role of Grouping. Sensing Strategies. Applications. The Next Steps."
            },
            "slug": "Object-recognition-by-computer-the-role-of-Grimson",
            "title": {
                "fragments": [],
                "text": "Object recognition by computer - the role of geometric constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book describes an extended series of experiments into the role of geometry in the critical area of object recognition, providing precise definitions of the recognition and localization problems, the methods used to address them, the solutions to these problems, and the implications of this analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1453069517"
                        ],
                        "name": "R. A. Cain",
                        "slug": "R.-A.-Cain",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Cain",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. A. Cain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208952327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2fa641d79397c3b383aea77776d8ebe49de08a",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method of locating partially visible two-dimensional objects is presented. The method is used to locate complex industrial parts that may contain several occurrences of local features, such as holes and corners. The matching process utilizes clusters of mutually consistent features to hypothesize objects and also uses templates of objects to verify these hypotheses. The technique is fast because it concentrates on key features that are automatically se lected on the basis of a detailed analysis of computer- aided design (CAD) models of the objects. The automatic analysis applies general-purpose routines for building and analyzing representations of clusters of local features that could be used in procedures to select features for other lo cational strategies. These routines include algorithms for computing the rotational and mirror symmetries of objects in terms of their local features."
            },
            "slug": "Recognizing-and-Locating-Partially-Visible-Objects:-Bolles-Cain",
            "title": {
                "fragments": [],
                "text": "Recognizing and Locating Partially Visible Objects: The Local-Feature-Focus Method"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A new method of locating partially visible two-dimensional objects is presented that concentrates on key features that are automatically focused on on the basis of a detailed analysis of computer- aided design models of the objects."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153905429"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "H",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6832179,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "0d6008d5c5cd19262a0711f7436cf4bb1c9b1f00",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 105,
            "paperAbstract": {
                "fragments": [],
                "text": "In this report we discuss a variety of psychophysical experiments that explore different aspects of the problem of object recognition and representation in human vision. In all experiments, subjects were presented with realistically rendered images of computer-generated 3D objects, with tight control over stimulus shape, surface properties, illumination, and viewpoint, as well as subjects' prior exposure to the stimulus objects. Contrary to the predictions of the paradigmatic theory of recognition, which holds that object representations are viewpoint invariant, performance in all experiments was consistently viewpoint dependent, was only partially aided by binocular stereo and other depth information, was specific to viewpoints that were familiar, and was systematically disrupted by rotation in depth more than by deforming the 2D images of the stimuli. The emerging concept of multiple-views representation supported by these results is consistent with recently advanced computational theories of recognition based on view interpolation. Moreover, in several simulated experiments employing the same stimuli used in experiments with human subjects, models based on multiple-views representations replicated many of the psychophysical results concerning the observed pattern of human performance."
            },
            "slug": "How-are-three-dimensional-objects-represented-in-B\u00fclthoff-Edelman",
            "title": {
                "fragments": [],
                "text": "How are three-dimensional objects represented in the brain?"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "In a variety of psychophysical experiments that explore different aspects of the problem of object recognition and representation in human vision, models based on multiple-views representations replicated many of the psychophysical results concerning the observed pattern of human performance."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695074"
                        ],
                        "name": "D. Perrett",
                        "slug": "D.-Perrett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Perrett",
                            "middleNames": [
                                "Ian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Perrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808846"
                        ],
                        "name": "M. Oram",
                        "slug": "M.-Oram",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Oram",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oram"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42306566,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7fca2a58484acd9f70f7b7b162e35cee68b8508c",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neurophysiology-of-shape-processing-Perrett-Oram",
            "title": {
                "fragments": [],
                "text": "Neurophysiology of shape processing"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "In recent work, Poggio and Edelman [14] have recognized wire objects and Brunelli and Poggio [15] have recognized faces using appearance models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808846"
                        ],
                        "name": "M. Oram",
                        "slug": "M.-Oram",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Oram",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Oram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695074"
                        ],
                        "name": "D. Perrett",
                        "slug": "D.-Perrett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Perrett",
                            "middleNames": [
                                "Ian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Perrett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 41905851,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "d9bd4208edcf0cfbf7a8cd2fb6e3bbf72460d670",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 182,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Modeling-visual-recognition-from-neurobiological-Oram-Perrett",
            "title": {
                "fragments": [],
                "text": "Modeling visual recognition from neurobiological constraints"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39741769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e9eab710eb82fdab42e980e74a0784eb3e581b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to representing objects viewed over long periods of time and with changing resolutions is presented. The basic strategy is to apply different representations as they become appropriate. As a result, the model of an object typically goes through a sequence of representation as new data are gathered and processed. One of these sequences might start with a crude blob description of an initially detected object, include a detailed structural model derived from a set of high-resolution images, and end with a semantic label based on the object's description and the sensor system's task. This evolution in representation is guided by a structure referred to as representation space: a lattice or representation that is traversed as new information about an object becomes available. One of the representations is associated with an object only after it has been judged to be valid. One approach for evaluating the validity of an object's description is described, based on the temporal stability of the description. These ideas are illustrated with results from a system which constructs and refines models of outdoor objects detected in sequences of range data.<<ETX>>"
            },
            "slug": "Representation-space:-an-approach-to-the-of-visual-Bobick-Bolles",
            "title": {
                "fragments": [],
                "text": "Representation space: an approach to the integration of visual information"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "One approach for evaluating the validity of an object's description is described, based on the temporal stability of the description, and results from a system which constructs and refines models of outdoor objects detected in sequences of range data are illustrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '89: IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3082093"
                        ],
                        "name": "M. Tarr",
                        "slug": "M.-Tarr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Tarr",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tarr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2693903"
                        ],
                        "name": "S. Pinker",
                        "slug": "S.-Pinker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Pinker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pinker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 233
                            }
                        ],
                        "text": "Some early work addressed the problem of mental rotation of images of 3-D objects, and determined that people were, in general able to do this, and in a way that took increasing amounts of time as the required rotation was increased [26,27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "All methods using viewpoint dependent 2-D representations may be considered as computational variants of the empirically-based multiple-views-plus-transformation (MVPT) theory of recognition [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9786799,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "5eb5243a0de130c96abeb33032e406c195dc103a",
            "isKey": false,
            "numCitedBy": 810,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mental-rotation-and-orientation-dependence-in-shape-Tarr-Pinker",
            "title": {
                "fragments": [],
                "text": "Mental rotation and orientation-dependence in shape recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "Component boundaries were extracted by modifying a stickgrowing method for finding segments developed recently by Nelson [34] so that it could follow curved boundaries."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 19385513,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "73025334a96b1171ab98ffa5e998c75586f5902e",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for extracting lineal features from an image using extended local information to provide robustness and sensitivity. The method utilizes both gradient magnitude and direction information, and incorporates explicit lineal and end-stop terms. These terms are combined nonlinearly to produce an energy landscape in which local minima correspond to lineal features called sticks that can be represented as line segments. A hill climbing (stick-growing) process is used to find these minima. The method is compared to two others, and found to have improved gap-crossing characteristics. >"
            },
            "slug": "Finding-Line-Segments-by-Stick-Growing-Nelson",
            "title": {
                "fragments": [],
                "text": "Finding Line Segments by Stick Growing"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A method is described for extracting lineal features from an image using extended local information to provide robustness and sensitivity and is compared to two others, and found to have improved gap-crossing characteristics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709131"
                        ],
                        "name": "F. Solina",
                        "slug": "F.-Solina",
                        "structuredName": {
                            "firstName": "Franc",
                            "lastName": "Solina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Solina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784213"
                        ],
                        "name": "R. Bajcsy",
                        "slug": "R.-Bajcsy",
                        "structuredName": {
                            "firstName": "Ruzena",
                            "lastName": "Bajcsy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bajcsy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27366392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "888ae7e9c6629640f39720caf11474e631e20016",
            "isKey": false,
            "numCitedBy": 682,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A method for recovery of compact volumetric models for shape representation of single-part objects in computer vision is introduced. The models are superquadrics with parametric deformations (bending, tapering, and cavity deformation). The input for the model recovery is three-dimensional range points. Model recovery is formulated as a least-squares minimization of a cost function for all range points belonging to a single part. During an iterative gradient descent minimization process, all model parameters are adjusted simultaneously, recovery position, orientation, size, and shape of the model, such that most of the given range points lie close to the model's surface. A specific solution among several acceptable solutions, where are all minima in the parameter space, can be reached by constraining the search to a part of the parameter space. The many shallow local minima in the parameter space are avoided as a solution by using a stochastic technique during minimization. Results using real range data show that the recovered models are stable and that the recovery procedure is fast. >"
            },
            "slug": "Recovery-of-Parametric-Models-from-Range-Images:-Solina-Bajcsy",
            "title": {
                "fragments": [],
                "text": "Recovery of Parametric Models from Range Images: The Case for Superquadrics with Global Deformations"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A method for recovery of compact volumetric models for shape representation of single-part objects in computer vision is introduced, which shows that the recovered models are stable and that the recovery procedure is fast."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "Notable recent examples are Lowe [1], Lamdan and Wolfson [2], Huttenlocher and Ullman [3], and Grimson [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 83
                            }
                        ],
                        "text": "Another featurebased example is a recent generalization of the alignment method by Huttenlocher and Lorigo [22] which finds consistent point matches via linear combination of model feature images."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 90
                            }
                        ],
                        "text": "Analyses of the performance of some of these schemes is given by Grimson and Huttenlocher [5,6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21629245,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5c165b95ec0dbb1bae2c401ad9e015c98b23acf4",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A formal model is presented for analyzing how the method performs in the presence of sensory uncertainty. The method performs well for simple images or for exact data. However, the performance degrades rapidly for cluttered scenes or in the presence of even moderate sensor error (3-5 pixels).<<ETX>>"
            },
            "slug": "On-the-sensitivity-of-geometric-hashing-Grimson-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "On the sensitivity of geometric hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A formal model is presented for analyzing how the method performs in the presence of sensory uncertainty and the performance degrades rapidly for cluttered scenes or in the absence of even moderate sensor error."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3438189"
                        ],
                        "name": "M. Kubovy",
                        "slug": "M.-Kubovy",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kubovy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kubovy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35287386,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c67f3c0846e80aba3be8a8fd00e9ace496bc77da",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The classic Gestalt laws of grouping by proximity and grouping by similarity have never been quantified, nor have their interactions been specified with any degree of precision. I will present a number of experimental and theoretical results from my lab, based on the responses of human observers to repeated brief (approximately 300 ms) presentations of perceptually multi-stable periodic dot patterns. I will show that the distribution of the probability of seeing any one of the possible perceptual interpretations is: (1) scale invariant, (2) changes little with reductions in duration to 100 ms, (3) can be predicted exactly on the assumption that dots are attracted to group with each other by a force that decays exponentially with the distance between them. I will also show that factors such the non-uniformity of lightness of dots in the lattice interact additively with the strength of grouping by proximity. I will also show how the fact that grouping is a hierarchical process expresses itself within the framework of the proposed model."
            },
            "slug": "Gestalt-laws-of-grouping-revisited-and-quantified-Kubovy",
            "title": {
                "fragments": [],
                "text": "Gestalt laws of grouping revisited and quantified"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that factors such the non-uniformity of lightness of dots in the lattice interact additively with the strength of grouping by proximity, and how the fact that grouping is a hierarchical process expresses itself within the framework of the proposed model."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2385092"
                        ],
                        "name": "C. Gross",
                        "slug": "C.-Gross",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gross",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gross"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 29738361,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "bd1c2795d3550dda7e2d2b65a2175f05a3346ed8",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "In primates, inferior temporal (IT) cortex is crucial for the processing and storage of visual information about form and colour. This article reviews the properties of IT neurons and considers how these properties may underlie the perceptual and mnemonic functions of IT cortex. The available evidence suggests that the processing of the facial image by IT cortex is similar to its processing of other visual patterns. Faces and other complex visual stimuli appear to be represented by the pattern of responses over a population of IT neurons rather than by the responses of specific 'feature detectors' or 'grandmother' cells. IT neurons with adult-like stimulus properties are present in monkeys as young as six weeks old."
            },
            "slug": "Representation-of-visual-stimuli-in-inferior-Gross",
            "title": {
                "fragments": [],
                "text": "Representation of visual stimuli in inferior temporal cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The properties of IT neurons are reviewed and it is considered how these properties may underlie the perceptual and mnemonic functions of IT cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical transactions of the Royal Society of London. Series B, Biological sciences"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137198"
                        ],
                        "name": "R. Shepard",
                        "slug": "R.-Shepard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Shepard",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Shepard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69508001"
                        ],
                        "name": "L. Cooper",
                        "slug": "L.-Cooper",
                        "structuredName": {
                            "firstName": "Lynn",
                            "lastName": "Cooper",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 233
                            }
                        ],
                        "text": "Some early work addressed the problem of mental rotation of images of 3-D objects, and determined that people were, in general able to do this, and in a way that took increasing amounts of time as the required rotation was increased [26,27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 144773989,
            "fieldsOfStudy": [
                "Psychology",
                "Art"
            ],
            "id": "bd9977729440f675cce025e22e89516a2408c3c3",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book collects some of the most exciting pioneering work in perceptual and cognitive psychology."
            },
            "slug": "Mental-Images-and-Their-Transformations-Shepard-Cooper",
            "title": {
                "fragments": [],
                "text": "Mental Images and Their Transformations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Primitive shape extraction from range data"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Workshop on Computer Vision"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "EEcient 2-dimensional object recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICPR"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "Mel [17] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object classification with high-dimensional vectors"
            },
            "venue": {
                "fragments": [],
                "text": "Proc Telluride Workshop on Neuromorphic Engineering. Telluride CO,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Mel (1994) [22] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object classi cation with high-dimensional vectors"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. Telluride  Workshop on Neuromorphic Engineering, Telluride CO,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "Notable recent examples are Lowe (1987), Lamdan & Wolfson (1988), Huttenlocher & Ullman (1990), and Grimson (1990) [21; 19; 17; 10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Three-dimensional object recognition from single two-dimensional im-  ages"
            },
            "venue": {
                "fragments": [],
                "text": "Arti cial Intelligence,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing and localizing partially visible objects: The local-features-focus method"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Robotics Research"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 178
                            }
                        ],
                        "text": "There has been a substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) [29; 32; 2] but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) [34; 3; 1; 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Primitive shape extraction from range  data"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. IEEE Workshop on Computer Vision,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Primitive shape extraction from range data"
            },
            "venue": {
                "fragments": [],
                "text": "Proc IEEE Workshop on Computer Vision. Miami FL, November\u2013December"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 338,
                                "start": 325
                            }
                        ],
                        "text": "There has been a substantial amount of work on the automatic acquisition of geometric models, mostly with range sensors, (Bolle 1989, Solina & Bajcsy 1990, Bobick & Bolles 1989) [29; 32; 2] but also visually, for various representations (Ullman & Basri 1991, Bolles & Cain 1982, Ayache & Faugeras 1986, Stein & Medioni 1990) [34; 3; 1; 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient 2-dimensional object recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. ICPR,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Indexing to 3 d model aspects using 2 d contour features"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Conf on Computer Vision and Pattern Recognition 96"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient 2-dimensional object recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc Int Conf on Pattern Recognition. Atlantic City,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords: Object recognition; Appearance-based representations; Visual learning"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object classiication with high-dimensional vectors"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Telluride Workshop on Neuromorphic Engineering"
            },
            "year": 1994
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 7,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Large-scale-tests-of-a-keyed,-appearance-based-3-D-Nelson-Selinger/50b77b2bc08199fe04150929d4df3d66727f96e8?sort=total-citations"
}