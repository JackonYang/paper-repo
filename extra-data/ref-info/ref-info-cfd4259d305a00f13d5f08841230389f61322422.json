{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "It is shown in [16] that such a combined ranking always exists and that it can be constructed efficiently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": "To be able to compare the quality of different retrieval functions, the method described in [16] is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "First, a user is more likely to click on a link, if it is relevant to q [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10535306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36e5365654531d4ec19e8194b9f80d7bbd5ad294",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method for evaluating the quality of retrieval functions. Unlike traditional methods that require relevance judgements by experts or explicit user feedback, it is based entirely on clickthrough data. This is a key advantage, since clickthrough data can be collected at very low cost and without overhead for the user. Taking an approach from experiment design, the paper proposes an experiment setup that generates unbiased feedback about the relative quality of two search results without explicit user feedback. A theoretical analysis shows that the method gives the same results as evaluation with traditional relevance judgements under mild statistical assumptions. An empirical analysis verifies that the assumptions are indeed justified and that the new method leads to conclusive results in a WWW retrieval study."
            },
            "slug": "Unbiased-Evaluation-of-Retrieval-Quality-using-Data-Joachims",
            "title": {
                "fragments": [],
                "text": "Unbiased Evaluation of Retrieval Quality using Clickthrough Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A theoretical analysis shows that the method gives the same results as evaluation with traditional relevance judgements under mild statistical assumptions, and an empirical analysis verifies that the assumptions are indeed justified and that the new method leads to conclusive results in a WWW retrieval study."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160326"
                        ],
                        "name": "Craig Silverstein",
                        "slug": "Craig-Silverstein",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Silverstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig Silverstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744110"
                        ],
                        "name": "M. Henzinger",
                        "slug": "M.-Henzinger",
                        "structuredName": {
                            "firstName": "Monika",
                            "lastName": "Henzinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Henzinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "l \u2248 10 [24]) links of the ranking, clicking on a link cannot be interpreted as a relevance judgment on an absolute scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 678356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78e558aa50d8f4bbc4726eff52b8e3b07afcc16a",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an analysis of a 280 GB AltaVista Search Engine query log consisting of approximately 1 billion entries for search requests over a period of six weeks. This represents approximately 285 million user sessions, each an attempt to fill a single information need. We present an analysis of individual queries, query duplication, and query sessions. Furthermore we present results of a correlation analysis of the log entries, studying the interaction of terms within queries. Our data supports the conjecture that web users differ significantly from the user assumed in the standard information retrieval literature. Specifically, we show that web users type in short queries, mostly look at the first 10 results only, and seldom modify the query. This suggests that traditional information retrieval techniques might not work well for answering web search requests. The correlation analysis showed that the most highly correlated items are constituents of phrases. This result indicates it may be useful for search engines to consider search terms as parts of phrases even if the user did not explicitly specify them as such."
            },
            "slug": "Analysis-of-a-Very-Large-Altavista-Query-Log\"-SRC-Silverstein-Henzinger",
            "title": {
                "fragments": [],
                "text": "Analysis of a Very Large Altavista Query Log\" SRC Technical note #1998-14"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that web users type in short queries, mostly look at the first 10 results only, and seldom modify the query, suggesting that traditional information retrieval techniques might not work well for answering web search requests."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035187"
                        ],
                        "name": "B. Bartell",
                        "slug": "B.-Bartell",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Bartell",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bartell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682655"
                        ],
                        "name": "R. Belew",
                        "slug": "R.-Belew",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Belew",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Belew"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[2]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18606472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "165046bd98e2e70399c3650cbe3f2602ad73fa95",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Retrieval performance can often be improved significantly by using a number of different retrieval algorithms and combining the results, in contrast to using just a single retrieval algorithm. This is because different retrieval algorithms, or retrieval experts, often emphasize different document and query features when determining relevance and therefore retrieve different sets of documents. However, it is unclear how the different experts are to be combined, in general, to yield a superior overall estimate. We propose a method by which the relevance estimates made by different experts can be automatically combined to result in superior retrieval performance. We apply the method to two expert combination tasks. The applications demonstrate that the method can identify high performance combinations of experts and also is a novel means for determining the combined effectiveness of experts."
            },
            "slug": "Automatic-combination-of-multiple-ranked-retrieval-Bartell-Cottrell",
            "title": {
                "fragments": [],
                "text": "Automatic combination of multiple ranked retrieval systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a method by which the relevance estimates made by different experts can be automatically combined to result in superior retrieval performance and applies the method to two expert combination tasks."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068005320"
                        ],
                        "name": "Raj D. Iyer",
                        "slug": "Raj-D.-Iyer",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Iyer",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raj D. Iyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] is an approach to combining many weak ranking rules into a strong ranking functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16692650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75e85c2e90b0abb17ae6445516a49ac05c1dbf0f",
            "isKey": false,
            "numCitedBy": 2182,
            "numCiting": 83,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of learning to accurately rank a set of objects by combining a given collection of ranking or preference functions. This problem of combining preferences arises in several applications, such as that of combining the results of different search engines, or the \"collaborative-filtering\" problem of ranking movies for a user based on the movie rankings provided by other users. In this work, we begin by presenting a formal framework for this general problem. We then describe and analyze an efficient algorithm called RankBoost for combining preferences based on the boosting approach to machine learning. We give theoretical results describing the algorithm's behavior both on the training data, and on new test data not seen during training. We also describe an efficient implementation of the algorithm for a particular restricted but common case. We next discuss two experiments we carried out to assess the performance of RankBoost. In the first experiment, we used the algorithm to combine different web search strategies, each of which is a query expansion for a given domain. The second experiment is a collaborative-filtering task for making movie recommendations."
            },
            "slug": "An-Efficient-Boosting-Algorithm-for-Combining-Freund-Iyer",
            "title": {
                "fragments": [],
                "text": "An Efficient Boosting Algorithm for Combining Preferences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes and analyze an efficient algorithm called RankBoost for combining preferences based on the boosting approach to machine learning, and gives theoretical results describing the algorithm's behavior both on the training data, and on new test data not seen during training."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3214276"
                        ],
                        "name": "J. Boyan",
                        "slug": "J.-Boyan",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Boyan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Boyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "The data for this table is taken from [5] ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "The data is taken from [5] and was recorded for the search engine LASER covering the WWW of the CMU School of Computer Science."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9444624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a245a5b0f11a15dc2787d9abe9ec02d643ee6de0",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Indexing systems for the World Wide Web, such as Lycos and Alta Vista, play an essential role in making the Web useful and usable. These systems are based on Information Retrieval methods for indexing plain text documents, but also include heuristics for adjusting their document rankings based on the special HTML structure of Web documents. In this paper, we describe a wide range of such heuristics|including a novel one inspired by reinforcement learning techniques for propagating rewards through a graph|which can be used to a ect a search engine's rankings. We then demonstrate a system which learns to combine these heuristics automatically, based on feedback collected unintrusively from users, resulting in much improved rankings."
            },
            "slug": "A-Machine-Learning-Architecture-for-Optimizing-Web-Boyan-Freitag",
            "title": {
                "fragments": [],
                "text": "A Machine Learning Architecture for Optimizing Web Search Engines"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A wide range of heuristics for adjusting document rankings based on the special HTML structure of Web documents are described, including a novel one inspired by reinforcement learning techniques for propagating rewards through a graph which can be used to improve a search engine's rankings."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "Table 1: Average clickrank for three retrieval functions (\u201cbxx\u201d, \u201ctfc\u201d [23] , and a \u201chand-tuned\u201d strategy that uses different weights according to HTML tags) implemented in LASER."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7725217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50a316f97c9a405aa000d883a633bd5707f1a34",
            "isKey": false,
            "numCitedBy": 9461,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Term-Weighting-Approaches-in-Automatic-Text-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Term-Weighting Approaches in Automatic Text Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698696"
                        ],
                        "name": "Yiyu Yao",
                        "slug": "Yiyu-Yao",
                        "structuredName": {
                            "firstName": "Yiyu",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiyu Yao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "[26] Y. Yao."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Furthermore, it is proportional to the measure of Yao [26] proposed for evaluating information retrieval systems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16269742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc5ba0a8c5b55dc191f69fd63317b510cebbe54d",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "The notion of user preference is adopted for the representation, interpretation, and measurement of the relevance or usefulness of documents. User judgments on documents may be formally described by a weak order (i.e., user ranking) and measured using an ordinal scale. Within this framework, a new measure of system performance is suggested based on the distance between user ranking and system ranking. It only uses the relative order of documents and therefore confirms to the valid use of an ordinal scale measuring relevance. It is also applicable to multilevel relevance judgments and ranked system output. The appropriateness of the proposed measure is demonstrated through an axiomatic approach. The inherent relationships between the new measure and many existing measures provide further supporting evidence. \u00a9 1995 John Wiley & Sons, Inc."
            },
            "slug": "Measuring-Retrieval-Effectiveness-Based-on-User-of-Yao",
            "title": {
                "fragments": [],
                "text": "Measuring Retrieval Effectiveness Based on User Preference of Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new measure of system performance is suggested based on the distance between user ranking and system ranking that only uses the relative order of documents and therefore confirms to the valid use of an ordinal scale measuring relevance."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "\u03a6(q, d) is a mapping onto features that describe the match between query q and document d like in the description-oriented retrieval approach of Fuhr et al. [10][11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16632383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "733952333854f1662c6038573aca67e575757932",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that any approach to developing optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs (<italic>f<subscrpt>l</subscrpt></italic>, <italic>d<subscrpt>m</subscrpt></italic>) are mapped onto description vectors <italic>x</italic>(<italic>f<subscrpt>l</subscrpt></italic>, <italic>d<subscrpt>m</subscrpt></italic>), and a polynomial function <italic>e</italic>(<italic>x</italic>) is developed such that it yields estimates of the probability of relevance P(<italic>R</italic> | x (<italic>f<subscrpt>l</subscrpt></italic>, <italic>d<subscrpt>m</subscrpt></italic>) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multivalued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models and it needs large samples of relevance feedback data for its application."
            },
            "slug": "Optimum-polynomial-retrieval-functions-based-on-the-Fuhr",
            "title": {
                "fragments": [],
                "text": "Optimum polynomial retrieval functions based on the probability ranking principle"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This approach is not suited to log-linear probabilistic models and it needs large samples of relevance feedback data for its application, but it can handle very complex representations of documents and requests and it can be easily applied to multivalued relevance scales."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144654543"
                        ],
                        "name": "Roberto Basili",
                        "slug": "Roberto-Basili",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Basili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roberto Basili"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "What are the computational demands of training the Ranking SVM on clickthrough data? Since SVMlight[15] solves the dual optimization problem, it depends only on inner products between feature vectors \u00a2I,(q, d)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 697700,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ba8ae55abc5b072ccef6c98d6d38ee72a901a43",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Those trying to make sense of the notion of textual content and semantics within the wild, wild world of information retrieval, categorization, and filtering have to deal often with an overwhelming sea of problems. The really strange story is that most of them (myself included) still believe that developing a linguistically principled approach to text categorization is an interesting research problem. This will also emerge in the discussion of the book that is the focus of this review. Learning to Classify Texts Using Support Vector Machines by Thorsten Joachims proposes a theory for automatic learning of text categorization models that has been repeatedly shown to be very successful. At the same time, the approach proposed is based on a rather rough linguistic generalization of (what apparently is) a language-dependent task: topic text classification (TC). The result is twofold: on the one hand, a learning theory, based on statistical learnability principles and results, that avoids the limitations of the strong empiricism typical of most text classification research; and on the other hand, the application of a naive linguistic model, the bag-of-words representation, to linguistic objects (i.e., the documents) that still achieves impressive accuracy."
            },
            "slug": "Learning-to-Classify-Text-Using-Support-Vector-and-Basili",
            "title": {
                "fragments": [],
                "text": "Learning to Classify Text Using Support Vector Machines: Methods, Theory, and Algorithms by Thorsten Joachims"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A theory for automatic learning of text categorization models that has been repeatedly shown to be very successful and is based on a rather rough linguistic generalization of a language-dependent task: topic text classification (TC)."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "Some attempts have been made to use implicit feedback by observing clicking behavior in retrieval systems [5] and browsing assistants [17] [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7662922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3022cfe4decc9ea7dd95af935764204924c2f9a1",
            "isKey": false,
            "numCitedBy": 596,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "1 We explore the notion of a tour guide software agent for assisting users browsing the World Wide Web. A Web tour guide agent provides assistance similar to that provided by a human tour guide in a museum { it guides the user along an appropriate path through the collection, based on its knowledge of the user's interests, of the location and relevance of various items in the collection, and of the way in which others have interacted with the collection in the past. This paper describes a simple but operational tour guide, called WebWatcher, which has given over 5000 tours to people browsing CMU's School of Computer Science Web pages. WebWatcher accompanies users from page to page, suggests appropriate hyperlinks, and learns from experience to improve its advice-giving skills. We describe the learning algorithms used by WebWatcher, experimental results showing their e ectiveness, and lessons learned from this case study in Web tour guide agents."
            },
            "slug": "WebWatcher-:-A-Tour-Guide-for-the-World-Wide-Web-Joachims",
            "title": {
                "fragments": [],
                "text": "WebWatcher : A Tour Guide for the World Wide Web"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The learning algorithms used by WebWatcher, experimental results showing their e ectiveness, and lessons learned from this case study in Web tour guide agents are described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[6]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2711002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0025b963134b1c0b64c1389af19610d038ab7072",
            "isKey": false,
            "numCitedBy": 974,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many applications in which it is desirable to order rather than classify instances. Here we consider the problem of learning how to order instances given feedback in the form of preference judgments, i.e., statements to the effect that one instance should be ranked ahead of another. We outline a two-stage approach in which one first learns by conventional means a binary preference function indicating whether it is advisable to rank one instance before another. Here we consider an on-line algorithm for learning preference functions that is based on Freund and Schapire's \"Hedge\" algorithm. In the second stage, new instances are ordered so as to maximize agreement with the learned preference function. We show that the problem of finding the ordering that agrees best with a learned preference function is NP-complete. Nevertheless, we describe simple greedy algorithms that are guaranteed to find a good approximation. Finally, we show how metasearch can be formulated as an ordering problem, and present experimental results on learning a combination of \"search experts,\" each of which is a domain-specific query expansion strategy for a web search engine."
            },
            "slug": "Learning-to-Order-Things-Cohen-Schapire",
            "title": {
                "fragments": [],
                "text": "Learning to Order Things"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "An on-line algorithm for learning preference functions that is based on Freund and Schapire's \"Hedge\" algorithm is considered, and it is shown that the problem of finding the ordering that agrees best with a learned preference function is NP-complete."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103447"
                        ],
                        "name": "S. Hartmann",
                        "slug": "S.-Hartmann",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084356644"
                        ],
                        "name": "G. Lustig",
                        "slug": "G.-Lustig",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lustig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1959019"
                        ],
                        "name": "M. Schwantner",
                        "slug": "M.-Schwantner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schwantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schwantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334474"
                        ],
                        "name": "Kostas Tzeras",
                        "slug": "Kostas-Tzeras",
                        "structuredName": {
                            "firstName": "Kostas",
                            "lastName": "Tzeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kostas Tzeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "\u03a6(q, d) is a mapping onto features that describe the match between query q and document d like in the description-oriented retrieval approach of Fuhr et al. [10][11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15004699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f61812ea95500993fada9f12c23577d2ba670d33",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "AIR/X is a rule-based system for indexing with terms (descriptors) from a prescribed vocabulary. For this task, an indexing dictionary with rules for mapping terms from the text onto descriptors is required, which can be derived automatically from a set of manually indexed documents. Based on the Darmstadt Indexing Approach, the indexing task is divided into a description step and a decision step. First, terms (single words or phrases) are identiied in the document text. With term-descriptor rules from the dictionary, descriptor indications are formed. The set of all indications from a document leading to the same descriptor is called a relevance description. A probabilistic classiication procedure computes indexing weights for each relevance description. Since the whole system is rule-based, it can be adapted to diierent subject elds by appropriate modiications of the rule bases. A major application of AIR/X is the AIR/PHYS system developed for a large physics database. This application is described in more detail along with experimental results."
            },
            "slug": "AIR/X-A-rule-based-multistage-indexing-system-for-Fuhr-Hartmann",
            "title": {
                "fragments": [],
                "text": "AIR/X - A rule-based multistage indexing system for Iarge subject fields"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A rule-based system for indexing with terms (descriptors) from a prescribed vocabulary, AIR/X is the AIR/PHYS system developed for a large physics database and can be adapted to diierent subject elds by appropriate modiications of the rule bases."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60532258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248a297d786228a183fcae64023092660550fcd2",
            "isKey": false,
            "numCitedBy": 1753,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on ideas from Support Vector Machines (SVMs), Learning To Classify Text Using Support Vector Machines presents a new approach to generating text classifiers from examples. The approach combines high performance and efficiency with theoretical understanding and improved robustness. In particular, it is highly effective without greedy heuristic components. The SVM approach is computationally efficient in training and classification, and it comes with a learning theory that can guide real-world applications. Learning To Classify Text Using Support Vector Machines gives a complete and detailed description of the SVM approach to learning text classifiers, including training algorithms, transductive text classification, efficient performance estimation, and a statistical learning model of text classification. In addition, it includes an overview of the field of text classification, making it self-contained even for newcomers to the field. This book gives a concise introduction to SVMs for pattern recognition, and it includes a detailed description of how to formulate text-classification tasks for machine learning."
            },
            "slug": "Learning-to-classify-text-using-support-vector-and-Joachims",
            "title": {
                "fragments": [],
                "text": "Learning to classify text using support vector machines - methods, theory and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book gives a concise introduction to SVMs for pattern recognition, and it includes a detailed description of how to formulate text-classification tasks for machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "An elegant perceptron-like algorithm for ordinal regression was recently proposed by Crammer and Singer [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 43
                            }
                        ],
                        "text": "[9] Y. Freund, R. Iyer, R. Shapire, and Y. Singer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 33
                            }
                        ],
                        "text": "[6] W. Cohen, R. Shapire, and Y. Singer."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 22
                            }
                        ],
                        "text": "[8] K. Crammer and Y. Singer."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11125057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4658b7c2c2436312b6d9cbf22c2f1625f7b76b1",
            "isKey": true,
            "numCitedBy": 658,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss the problem of ranking instances. In our framework each instance is associated with a rank or a rating, which is an integer from 1 to k. Our goal is to find a rank-predict ion rule that assigns each instance a rank which is as close as possible to the instance's true rank. We describe a simple and efficient online algorithm, analyze its performance in the mistake bound model, and prove its correctness. We describe two sets of experiments, with synthetic data and with the EachMovie dataset for collaborative filtering. In the experiments we performed, our algorithm outperforms online algorithms for regression and classification applied to ranking."
            },
            "slug": "Pranking-with-Ranking-Crammer-Singer",
            "title": {
                "fragments": [],
                "text": "Pranking with Ranking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A simple and efficient online algorithm is described, its performance in the mistake bound model is analyzed, its correctness is proved, and it outperforms online algorithms for regression and classification applied to ranking."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745366"
                        ],
                        "name": "Doug Beeferman",
                        "slug": "Doug-Beeferman",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Beeferman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doug Beeferman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710580"
                        ],
                        "name": "A. Berger",
                        "slug": "A.-Berger",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Berger",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 87
                            }
                        ],
                        "text": "While for a different problem, an interesting use of clickthrough data was proposed in [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1047454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "248280b0f0885d0da0d80934284a01d48d56a689",
            "isKey": false,
            "numCitedBy": 919,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "!# $% '&( ) ) * + ! ' , * ' * ' . ./0 ' 1 * . '&* ' % 2 ) *!3 $% ) 4 ' \" + $% ) * 65 7189 :, \" !; * $4 ) @ & A B C D E . * . ! F ' G H ' IJ K L * M & + *) N~ z'\u0086\u0088\u0087cC \u0089g) ' & \u008a p : q : \u008b r \u008cHt\u008d\u0086d|#t9~,s tvu\u008ew x yFz {\u0080|;w]tS}9~ x \u0085`|;\u007f ~ \u008f \u0087 C n+ U"
            },
            "slug": "Agglomerative-clustering-of-a-search-engine-query-Beeferman-Berger",
            "title": {
                "fragments": [],
                "text": "Agglomerative clustering of a search engine query log"
            },
            "venue": {
                "fragments": [],
                "text": "KDD '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 61116019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7550a05bf00f7b24aed9c1ac3ef000575388d21c",
            "isKey": false,
            "numCitedBy": 5454,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Training a support vector machine SVM leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples on the shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVM light is an implementation of an SVM learner which addresses the problem of large tasks. This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical. The results give guidelines for the application of SVMs to large domains."
            },
            "slug": "Making-large-scale-SVM-learning-practical-Joachims",
            "title": {
                "fragments": [],
                "text": "Making large scale SVM learning practical"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical and give guidelines for the application of SVMs to large domains."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145507148"
                        ],
                        "name": "H. Lieberman",
                        "slug": "H.-Lieberman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Lieberman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lieberman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Some attempts have been made to use implicit feedback by observing clicking behavior in retrieval systems [5] and browsing assistants [17] [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7878162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b0a95f3e0671c54d659113b94c32970d7eedc3d",
            "isKey": false,
            "numCitedBy": 1484,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Letizia is a user interface agent that assists a user browsing the World Wide Web. As the user operates a conventional Web browser such as Netscape, the agent tracks user behavior and attempts to anticipate items of interest by doing concurrent, autonomous exploration of links from the user's current position. The agent automates a browsing strategy consisting of a best-first search augmented by heuristics inferring user interest from browsing behavior."
            },
            "slug": "Letizia:-An-Agent-That-Assists-Web-Browsing-Lieberman",
            "title": {
                "fragments": [],
                "text": "Letizia: An Agent That Assists Web Browsing"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Letizia is a user interface agent that assists a user browsing the World Wide Web by automates a browsing strategy consisting of a best-first search augmented by heuristics inferring user interest from browsing behavior."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743797"
                        ],
                        "name": "I. Guyon",
                        "slug": "I.-Guyon",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Guyon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Guyon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207165665,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2599131a4bc2fa957338732a37c744cfe3e17b24",
            "isKey": false,
            "numCitedBy": 10838,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms."
            },
            "slug": "A-training-algorithm-for-optimal-margin-classifiers-Boser-Guyon",
            "title": {
                "fragments": [],
                "text": "A training algorithm for optimal margin classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented, applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227181"
                        ],
                        "name": "K. H\u00f6ffgen",
                        "slug": "K.-H\u00f6ffgen",
                        "structuredName": {
                            "firstName": "Klaus-Uwe",
                            "lastName": "H\u00f6ffgen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. H\u00f6ffgen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723095"
                        ],
                        "name": "H. Simon",
                        "slug": "H.-Simon",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Simon",
                            "middleNames": [
                                "Ulrich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1823251"
                        ],
                        "name": "K. S. V. Horn",
                        "slug": "K.-S.-V.-Horn",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Horn",
                            "middleNames": [
                                "S.",
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. S. V. Horn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6707032,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fef36189265d90252106cdfd64e0a8d9d5c4c58d",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the problem of learning concepts by presenting labeled and randomly chosen training\u2013examples to single neurons. It is well-known that linear halfspaces are learnable by the method of linear programming. The corresponding (Mc-Culloch-Pitts) neurons are therefore efficiently trainable to learn an unknown halfspace from examples. We want to analyze how fast the learning performance degrades when the representational power of the neuron is overstrained, i.e., if more complex concepts than just halfspaces are allowed. We show that a neuron cannot efficently find its probably almost optimal adjustment (unless RP = NP). If the weights and the threshold of the neuron have a fixed constant bound on their coding length, the situation is even worse: There is in general no polynomial time training method which bounds the resulting prediction error of the neuron by k.opt for a fixed constant k (unless RP = NP). Other variants of learning more complex concepts than halfspaces by single neurons are also investigated. We show that neither heuristical learning nor learning by sigmoidal neurons with a constant reject-rate is efficiently possible (unless RP = NP)."
            },
            "slug": "Robust-trainability-of-single-neurons-H\u00f6ffgen-Simon",
            "title": {
                "fragments": [],
                "text": "Robust trainability of single neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that a neuron cannot efficently find its probably almost optimal adjustment (unless RP = NP) and neither heuristical learning nor learning by sigmoidal neurons with a constant reject-rate is efficiently possible."
            },
            "venue": {
                "fragments": [],
                "text": "COLT '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "However, just like in classification SVMs [7], it is possible to approximate the solution by introducing (non-negative) slack variables \u03bei,j,k and minimizing the upper bound \u2211 \u03bei,j,k. Adding SVM regularization for margin maximization to the objective leads to the following optimization problem, which is similar to the ordinal regression approach in [12]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "However, just like in classification SVMs [7], it is possible to approximate the solution by introducing (non-negative) slack variables \u03bei,j,k and minimizing the upper bound \u2211 \u03bei,j,k."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52874011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
            "isKey": false,
            "numCitedBy": 33430,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "slug": "Support-Vector-Networks-Cortes-Vapnik",
            "title": {
                "fragments": [],
                "text": "Support-Vector Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated and the performance of the support- vector network is compared to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "This makes it possible to use Kernels [4][25] and extend the Ranking SVM algorithm to non-linear retrieval functions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "Therefore, the following algorithm directly addresses (6), taking an empirical risk minimization approach [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Note that (6) is (proportional to) a risk functional [25] with \u2212\u03c4 as the loss function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": true,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34296841"
                        ],
                        "name": "J. Snell",
                        "slug": "J.-Snell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Snell",
                            "middleNames": [
                                "Laurie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Snell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33447835"
                        ],
                        "name": "J. Kemeny",
                        "slug": "J.-Kemeny",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kemeny",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kemeny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62760299,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "fe6240dbbf4c69e83be78bb7bfb208f3ca7de093",
            "isKey": false,
            "numCitedBy": 408,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "As the need for more substantial mathematical training has increased among social science students, the lack of any adequate textbook between the very elementary and the very advanced levels has become crutial. The authors, long-time experts in this field, have answered the need with this volume, and the MIT Press has repsonded by bringing it into renewed circulation.Mathematical Models in the Social Sciences investigates and teaches the formation and analysis of mathematical models with detailed interpretations of the results. These models are self-contained, with the necessary mathematics included in each chapter. A vast range of topics in the social sciences and a wide variety of mathematical techniques are covered by the models. Ample opportunity is also provided for the students to form their own models. Republication of this book provides social science and mathematics students with a text that is the analogue of mathematical methods textbooks used in the study of the physical sciences and engineering. Prerequisites are kept to a minimum; a course in finite mathematics and a semester of calculus are all that is necessary.The chapters cover these main topics (and employ the mathematical approach parenthetically indicated): methodology; preference rankings (an axiomatic approach); ecology (two dynamic models); market stability (a dynamic model); a Markov chain model in sociology; stabilization of money flow (an application of discrete potential theory); branching processes; organization theory (applications of graph theory); and optimal scheduling (a problem in dynamic programming)."
            },
            "slug": "Mathematical-models-in-the-social-sciences-Snell-Kemeny",
            "title": {
                "fragments": [],
                "text": "Mathematical models in the social sciences"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Republication of this book provides social science and mathematics students with a text that is the analogue of mathematical methods textbooks used in the study of the physical sciences and engineering."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40692782"
                        ],
                        "name": "M. Kendall",
                        "slug": "M.-Kendall",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kendall",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kendall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122397715,
            "fieldsOfStudy": [
                "Mathematics",
                "Economics",
                "Environmental Science",
                "Psychology"
            ],
            "id": "b7000835226609a5c0ff6dacb5c2cc9d38dfe916",
            "isKey": false,
            "numCitedBy": 3265,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The measurement of rank correlation introduction to the general theory of rank correlation tied ranks tests of significance proof of the results of chapter 4 the problem of m ranking proof of the result of chapter 6 partial rank correlation ranks and variate values proof of the result of chapter 9 paired comparisons proof of the results of chapter 11 some further applications."
            },
            "slug": "Rank-Correlation-Methods-Kendall",
            "title": {
                "fragments": [],
                "text": "Rank Correlation Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1948
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66297967"
                        ],
                        "name": "R. Forthofer",
                        "slug": "R.-Forthofer",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Forthofer",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Forthofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37381182"
                        ],
                        "name": "R. Lehnen",
                        "slug": "R.-Lehnen",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Lehnen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lehnen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Since the method presented in the following does not require such a simplification, we will depart from a binary relevance scheme and adapt Kendall\u2019s \u03c4 [19][21] as a performance measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 14
                            }
                        ],
                        "text": "In this case, Kendall\u2019s \u03c4 can be defined as:\n\u03c4(ra, rb) = P \u2212Q P + Q = 1\u2212 2Q( m 2 ) (2) As an example, consider the two rankings ra and rb as follows:\nd1  ra d2  ra d3  ra d4  ra d5 (3)\nd3  rb d2  rb d1  rb d4  rb d5 (4)\nThe number of discordant pairs is 3 (ie."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 51
                            }
                        ],
                        "text": "For two finite strict orderings ra \u2282 D \u00d7 D and rb \u2282 D \u00d7 D, Kendall\u2019s \u03c4 can be defined based on the number P of concordant pairs and the number Q of discordant pairs (inversions)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 63
                            }
                        ],
                        "text": "For comparing the ordinal correlation of two random variables, Kendall\u2019s \u03c4 is the most frequently used measure in statistics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 115
                            }
                        ],
                        "text": "The offline experiment is designed to verify that the Ranking SVM can indeed learn a retrieval function maximizing Kendall\u2019s \u03c4 on partial preference feedback."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 192
                            }
                        ],
                        "text": "For a fixed but unknown distribution Pr(q, r\u2217) of queries and target rankings on a document collection D with m documents, the goal is to learn a retrieval function f(q) for which the expected Kendall\u2019s \u03c4\n\u03c4P (f) = \u222b \u03c4(rf(q), r \u2217)d Pr(q, r\u2217) (6)\nis maximal."
                    },
                    "intents": []
                }
            ],
            "corpusId": 120895672,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6094f4c6ed65e2e46dc57e2bd7a3cb10e7ed2199",
            "isKey": true,
            "numCitedBy": 3849,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Rank correlation coefficients are statistical indices that measure the degree of association between two variables having ordered categories. Some well-known rank correlation coefficients are those proposed by Goodman and Kruskal (1954, 1959), Kendall (1955), and Somers (1962). Rank correlation methods share several common features. They are based on counts and are defined such that a coefficient of zero means \u201cno association\u201d between the variables and a value of +1.0 or -1.0 means \u201cperfect agreement\u201d or \u201cperfect inverse agreement,\u201d respectively."
            },
            "slug": "Rank-Correlation-Methods-Forthofer-Lehnen",
            "title": {
                "fragments": [],
                "text": "Rank Correlation Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69857560"
                        ],
                        "name": "A. Mood",
                        "slug": "A.-Mood",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Mood",
                            "middleNames": [
                                "McFarlane"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mood"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Since the method presented in the following does not require such a simplification, we will depart from a binary relevance scheme and adapt Kendall\u2019s \u03c4 [19][21] as a performance measure."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3973811,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3da8684050df72c07731c030f7669a920ccfffde",
            "isKey": false,
            "numCitedBy": 2373,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "1 probability 2 Random variables, distribution functions, and expectation 3 Special parametric families of univariate distributions 4 Joint and conditional distributions, stochastic independence, more expectation 5 Distributions of functions of random variables 6 Sampling and sampling distributions 7 Parametric point estimation 8 Parametric interval estimation 9 Tests of hypotheses 10 Linear models 11 Nonparametric method Appendix A Mathematical Addendum Appendix B tabular summary of parametric families of distributions Appendix C References and related reading Appendix D Tables"
            },
            "slug": "An-Introduction-to-the-Theory-of-Statistics-Mood",
            "title": {
                "fragments": [],
                "text": "An Introduction to the Theory of Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1911
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7138354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8213dbed4db44e113af3ed17d6dad57471a0c048",
            "isKey": false,
            "numCitedBy": 38755,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Setting of the learning problem consistency of learning processes bounds on the rate of convergence of learning processes controlling the generalization ability of learning processes constructing learning algorithms what is important in learning theory?."
            },
            "slug": "The-Nature-of-Statistical-Learning-Theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "The Nature of Statistical Learning Theory"
            },
            "venue": {
                "fragments": [],
                "text": "Statistics for Engineering and Information Science"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "And finally, \u03c4(rf(q), r \u2217) is related to Average Precision [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 96
                            }
                        ],
                        "text": "If p1, ..., pR are the ranks of the relevant documents in rsys sorted in increasing order, then Average Precision can be computed as\nAvgPrec(rsys, rrel) = 1\nR R\u2211 i=1 i pi (24)\nWhat is the minimum value of AvgPrec(rsys, rrel), given that the number of discordant pairs is fixed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "nary relevance scale, Average Precision [1] is most frequently used in information retrieval."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 31
                            }
                        ],
                        "text": "It computes the worst possible Average Precision for a fixed value of Q.\nminimize: P (p1, ..., pR) = 1\nR R\u2211 i=1 i pi (26)\nsubject. to: p1 + ... + pR = Q +\n( R + 1\n2\n) (27)\n1 \u2264 p1 < ... < pR (28) p1, ..., pR integer (29)\nRelaxing the problem by removing the last two sets of constraints can only decrease the minimum, so that the solution without the constraints is still a lower bound."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 30
                            }
                        ],
                        "text": "For a binary relevance scale, Average Precision [1] is most frequently used in information retrieval."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 69
                            }
                        ],
                        "text": "In particular, the number of inversions Q gives a lower bound on the Average Precision as follows."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Modern Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 156049040,
            "fieldsOfStudy": [],
            "id": "187260d1e13d6fe73f5bf85b24468763286d1a85",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rank Correlation Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195997866,
            "fieldsOfStudy": [],
            "id": "ee770454b7f1dd71885304c3767073a1ed1eafb9",
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mathematical Models in the Social Sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39962304"
                        ],
                        "name": "Darren Gehring",
                        "slug": "Darren-Gehring",
                        "structuredName": {
                            "firstName": "Darren",
                            "lastName": "Gehring",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Darren Gehring"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "Adding SVM regularization for margin maximization to the objective leads to the following optimization problem, which is similar to the ordinal regression approach in [12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60533697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "958f001b6f348f7c353260b289bed185fffac847",
            "isKey": false,
            "numCitedBy": 980,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Large-Margin-Rank-Boundaries-for-Ordinal-Regression-Gehring-Graepel",
            "title": {
                "fragments": [],
                "text": "Large Margin Rank Boundaries for Ordinal Regression"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some attempts have been made to use implicit feedback by observing clicking behavior in retrieval systems [5] and browsing assistants [ 17 ][20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31643288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06de524dc581dfd6a9c8c59a87d08e76d54a0765",
            "isKey": false,
            "numCitedBy": 658,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Web-Watcher:-A-Tour-Guide-for-the-World-Wide-Web-Joachims-Freitag",
            "title": {
                "fragments": [],
                "text": "Web Watcher: A Tour Guide for the World Wide Web"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "Unfortunately, a direct generalization of the result in [13] shows that this problem is NP-hard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and K"
            },
            "venue": {
                "fragments": [],
                "text": "van Horn. Robust trainability of single neurons. Journal of Computer and System Sciences, 50:114-125"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "(Ranking SVM (partial))\nminimize: V (~w, ~\u03be) = 1\n2 ~w \u00b7 ~w + C\n\u2211 \u03bei,j,k (21)\nsubject to:\n\u2200(di, dj) \u2208 r\u20321 : ~w\u03a6(q1, di) > ~w\u03a6(q1, dj) + 1\u2212 \u03bei,j,1 ... (22) \u2200(di, dj) \u2208 r\u2032n : ~w\u03a6(qn, di) > ~w\u03a6(qn, dj) + 1\u2212 \u03bei,j,n \u2200i\u2200j\u2200k : \u03bei,j,k \u2265 0 (23)\nThe resulting retrieval function is defined analogously."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pagerank, an eigenvector based ranking approach for hypertext"
            },
            "venue": {
                "fragments": [],
                "text": "$lst Annual ACM/SIGIR International Conference on Research ~md Development in Information Retrieval"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik . A traininig algorithm for optimal margin classifiers"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( KDD )"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik . A traininig algorithm for optimal margin classifiers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik . Support \u2013 vector networks"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning Journal"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "Unfortunately, a direct generalization of the result in [13] shows that this problem is NP-hard."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and K"
            },
            "venue": {
                "fragments": [],
                "text": "van Horn. Robust trainability of single neurons. Journal of Computer and System Sciences, 50:114\u2013125"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vapnik . Support \u2013 vector networks"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning Journal"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 38,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Optimizing-search-engines-using-clickthrough-data-Joachims/cfd4259d305a00f13d5f08841230389f61322422?sort=total-citations"
}