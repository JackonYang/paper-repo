{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 217
                            }
                        ],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22, 6, 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5258236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9f836d28f52ad260213d32224a6d227f8e8849a",
            "isKey": false,
            "numCitedBy": 16256,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "slug": "Object-recognition-from-local-scale-invariant-Lowe",
            "title": {
                "fragments": [],
                "text": "Object recognition from local scale-invariant features"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Seventh IEEE International Conference on Computer Vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687022"
                        ],
                        "name": "J. Crowley",
                        "slug": "J.-Crowley",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Crowley",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Crowley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One might wonder whether this comparison is fair: it is certainly possible to use more sophisticated methods for classification than just simple NNC, such as voting schemes and decision trees [10, 22, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Schiele and Crowley [21] generalized this method by introducing multidimensional receptive field histograms to approximate the probability density function of local appearance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other global representations like color or derivative histograms [24, 21] are in its original form rather sensitive to occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22, 6, 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This model set could consist of the original images, considered as feature vectors [18, 19, 1], or of features extracted from the original views, such as color [24] or texture [21]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2551159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd232cf2ab28cc0ba06942875f14206f04ebbae0",
            "isKey": true,
            "numCitedBy": 496,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "The appearance of an object is composed of local structure. This local structure can be described and characterized by a vector of local features measured by local operators such as Gaussian derivatives or Gabor filters. This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators. As such, this represents a new class of appearance based techniques for computer vision. Based on joint statistics, the paper develops techniques for the identification of multiple objects at arbitrary positions and orientations in a cluttered scene. Experiments show that these techniques can identify over 100 objects in the presence of major occlusions. Most remarkably, the techniques have low complexity and therefore run in real-time."
            },
            "slug": "Recognition-without-Correspondence-using-Receptive-Schiele-Crowley",
            "title": {
                "fragments": [],
                "text": "Recognition without Correspondence using Multidimensional Receptive Field Histograms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents a technique where appearances of objects are represented by the joint statistics of such local neighborhood operators, which represents a new class of appearance based techniques for computer vision."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102944324"
                        ],
                        "name": "Vapnik",
                        "slug": "Vapnik",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Vapnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17719593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3473ce22ada00842b355883a5ddde5a8c7c76ba6",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that Support Vector Machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x,y) = e\u2212\u03c1 P i |x i \u2212y i | with a \u2264 1 and b \u2264 2 are evaluated on the classification of images extracted from the Corel Stock Photo Collection and shown to far outperform traditional polynomial or Gaussian RBF kernels. Moreover, we observed that a simple remapping of the input xi \u2192 x a i improves the performance of linear SVMs to such an extend that it makes them, for this problem, a valid alternative to RBF kernels. keywords: Support Vector Machines, Radial Basis Functions, Image Histogram, Image Classification, Corel."
            },
            "slug": "SVMs-for-Histogram-Based-Image-Classification-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "SVMs for Histogram Based Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper shows that Support Vector Machines (SVM) can generalize well on difficult image classification problems where the only features are high dimensional histograms and observes that a simple remapping of the input xi \u2192 x a i improves the performance of linear SVMs to such an extend that it makes them a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716824"
                        ],
                        "name": "A. Verri",
                        "slug": "A.-Verri",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Verri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Verri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 204
                            }
                        ],
                        "text": "\u2019Learning-free\u2019 algorithms such as nearest neighbor techniques can provide a good baseline for recognition experiments, but often suffer from inferior generalization capabilities in real-world conditions [8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 83
                            }
                        ],
                        "text": "This model set could consist of the original images, considered as feature vectors [18, 19, 1], or of features extracted from the original views, such as color [24] or texture [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 290
                            }
                        ],
                        "text": "Support Vector Machines (SVMs, [9, 25]), on the other hand, represent a class of learning algorithms, which are based on a thorough mathematical founding, and - while more computationally expensive than other matching techniques - have shown impressive learning and recognition performance [19, 1, 8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "The simplest representation - raw pixel data of input images - can achieve surprisingly high recognition rates [18, 19], but is highly sensitive to all signal changes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 7
                            }
                        ],
                        "text": "Pontil [18] demonstrated the robustness of SVMs to noise, bias in the registration and moderate amount of partial occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1375403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fda96d554f4e5a21e35bf33b9720141da47664b",
            "isKey": true,
            "numCitedBy": 865,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines (SVMs) have been recently proposed as a new technique for pattern recognition. Intuitively, given a set of points which belong to either of two classes, a linear SVM finds the hyperplane leaving the largest possible fraction of points of the same class on the same side, while maximizing the distance of either class from the hyperplane. The hyperplane is determined by a subset of the points of the two classes, named support vectors, and has a number of interesting theoretical properties. In this paper, we use linear SVMs for 3D object recognition. We illustrate the potential of SVMs on a database of 7200 images of 100 different objects. The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose. The excellent recognition rates achieved in all the performed experiments indicate that SVMs are well-suited for aspect-based recognition."
            },
            "slug": "Support-Vector-Machines-for-3D-Object-Recognition-Pontil-Verri",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for 3D Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The proposed system does not require feature extraction and performs recognition on images regarded as points of a space of high dimension without estimating pose, indicating that SVMs are well-suited for aspect-based recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23544307,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d09deeb2eb6b1175d13817284d967189a83dbdde",
            "isKey": false,
            "numCitedBy": 1463,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional classification approaches generalize poorly on image classification tasks, because of the high dimensionality of the feature space. This paper shows that support vector machines (SVM's) can generalize well on difficult image classification problems where the only features are high dimensional histograms. Heavy-tailed RBF kernels of the form K(x, y) = e(-rho)Sigma(i)/xia-yia/b with a < or = 1 and b < or = 2 are evaluated on the classification of images extracted from the Corel stock photo collection and shown to far outperform traditional polynomial or Gaussian radial basis function (RBF) kernels. Moreover, we observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "slug": "Support-vector-machines-for-histogram-based-image-Chapelle-Haffner",
            "title": {
                "fragments": [],
                "text": "Support vector machines for histogram-based image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is observed that a simple remapping of the input x(i)-->x(i)(a) improves the performance of linear SVM's to such an extend that it makes them, for this problem, a valid alternative to RBF kernels."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592461"
                        ],
                        "name": "A. Barla",
                        "slug": "A.-Barla",
                        "structuredName": {
                            "firstName": "Annalisa",
                            "lastName": "Barla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082819922"
                        ],
                        "name": "E. Franceschi",
                        "slug": "E.-Franceschi",
                        "structuredName": {
                            "firstName": "Emanuele",
                            "lastName": "Franceschi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Franceschi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712692"
                        ],
                        "name": "F. Odone",
                        "slug": "F.-Odone",
                        "structuredName": {
                            "firstName": "Francesca",
                            "lastName": "Odone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Odone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716824"
                        ],
                        "name": "A. Verri",
                        "slug": "A.-Verri",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Verri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Verri"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 290
                            }
                        ],
                        "text": "Support Vector Machines (SVMs, [9, 25]), on the other hand, represent a class of learning algorithms, which are based on a thorough mathematical founding, and - while more computationally expensive than other matching techniques - have shown impressive learning and recognition performance [19, 1, 8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 83
                            }
                        ],
                        "text": "This model set could consist of the original images, considered as feature vectors [18, 19, 1], or of features extracted from the original views, such as color [24] or texture [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "For these local features one can use as Kl the intersection measure introduced by Swain and Ballard [24], which was proven to be a Mercer kernel [1], or"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[1] proposed to use a new class of kernels, especially designed for vision and inspired by similarity measures successfully employed in other vision applications (including histogram intersection and Hausdorff kernels)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35169784,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34ace6c61a04d852a63d6372df12fd67bd23a7f4",
            "isKey": true,
            "numCitedBy": 41,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we discuss the mathematical properties of a few kernels specifically constructed for dealing with image data in binary classification and novelty detection problems. First, we show that histogram intersection is a Mercer's kernel. Then, we show that a similarity measure based on the notion of Hausdorff distance and directly applicable to raw images, though not a Mercer's kernel, is a kernel for novelty detection. Both kernels appear to be well suited for building effective vision-based learning systems."
            },
            "slug": "Image-Kernels-Barla-Franceschi",
            "title": {
                "fragments": [],
                "text": "Image Kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The mathematical properties of a few kernels specifically constructed for dealing with image data in binary classification and novelty detection problems and a similarity measure based on the notion of Hausdorff distance is shown to be well suited for building effective vision-based learning systems."
            },
            "venue": {
                "fragments": [],
                "text": "SVM"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793750"
                        ],
                        "name": "C. Wallraven",
                        "slug": "C.-Wallraven",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wallraven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wallraven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144813423"
                        ],
                        "name": "Arnulf B. A. Graf",
                        "slug": "Arnulf-B.-A.-Graf",
                        "structuredName": {
                            "firstName": "Arnulf",
                            "lastName": "Graf",
                            "middleNames": [
                                "B.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnulf B. A. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8238615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be0cba2989ac76a000e8ce80911a363c4391e73e",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Psychophysical studies have shown that humans actively exploit temporal information such as contiguity of images in object recognition. We have recently developed a recognition system which uses temporal contiguity to learn extensible representations of objects on-line. The system performs well both on real-world and synthetic data and shows robustness under illumination changes. In this paper, we present results which compare the proposed representation against simple image-based representations of the same complexity using Minkowski minimum distance classifiers and support vector machine classifiers. Recognition results for all classifiers show large improvements with incorporated temporal information."
            },
            "slug": "View-based-dynamic-object-recognition-based-on-B\u00fclthoff-Wallraven",
            "title": {
                "fragments": [],
                "text": "View-based dynamic object recognition based on human perception"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results are presented which compare the proposed representation against simple image-based representations of the same complexity using Minkowski minimum distance classifiers and support vector machine classifiers to show large improvements with incorporated temporal information."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801027"
                        ],
                        "name": "S. Bouattour",
                        "slug": "S.-Bouattour",
                        "structuredName": {
                            "firstName": "Sahla",
                            "lastName": "Bouattour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bouattour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144290244"
                        ],
                        "name": "H. Niemann",
                        "slug": "H.-Niemann",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Niemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Niemann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Cue integration: Kernel methods can be a powerful method for cue integration [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Both are Mercer kernels [2, 25], and both have been successfully used with histogram features [ 6 , 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22,  6 , 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The growing number of papers addressing object recognition using kernel methods (see for instance [14,  6 , 26] and many others) is an indicator for the interest of the computer vision community in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 517316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "910a506d6f45f2aee9141f9a7e74d9db433c703b",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new kernel method for appearance-based object recognition, highly robust to noise and occlusion. It consists of a fully connected Markov random field that integrates results of Spin Glass theory with Gibbs probability distributions via nonlinear kernel mapping. We call this model Spin Glass-Markov Random Field. We present theoretical analysis and several experiments that show its effectiveness and robustness to noise and occlusion. We obtain in both cases excellent results. Particularly, we achieve a recognition rate above 93% with just 40% of visible portion of the object."
            },
            "slug": "Robust-appearance-based-object-recognition-using-a-Caputo-Bouattour",
            "title": {
                "fragments": [],
                "text": "Robust appearance-based object recognition using a fully connected Markov random field"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A new kernel method for appearance-based object recognition, highly robust to noise and occlusion, consisting of a fully connected Markov random field that integrates results of Spin Glass theory with Gibbs probability distributions via nonlinear kernel mapping is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Object recognition supported by user interaction for service robots"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The COGVIS-ETH database ([13], Figure 1, middle row) is a recently released database, consisting of 80 objects from 8 different categories (apple, tomato, pear, toy-cows, toyhorses, toy-dogs, toy-cars and cups)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5764405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "397f22d68805551c500077f4a9b4dbea868d1fb3",
            "isKey": false,
            "numCitedBy": 818,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition has reached a level where we can identify a large number of previously seen and known objects. However, the more challenging and important task of categorizing previously unseen objects remains largely unsolved. Traditionally, contour and shape based methods are regarded most adequate for handling the generalization requirements needed for this task. Appearance based methods, on the other hand, have been successful in object identification and detection scenarios. Today little work is done to systematically compare existing methods and characterize their relative capabilities for categorizing objects. In order to compare different methods we present a new database specifically tailored to the task of object categorization. It contains high-resolution color images of 80 objects from 8 different categories, for a total of 3280 images. It is used to analyze the performance of several appearance and contour based methods. The best categorization result is obtained by an appropriate combination of different methods."
            },
            "slug": "Analyzing-appearance-and-contour-based-methods-for-Leibe-Schiele",
            "title": {
                "fragments": [],
                "text": "Analyzing appearance and contour based methods for object categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new database specifically tailored to the task of object categorization is presented, which contains high-resolution color images of 80 objects from 8 different categories and is used to analyze the performance of several appearance and contour based methods."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3033284"
                        ],
                        "name": "B. Caputo",
                        "slug": "B.-Caputo",
                        "structuredName": {
                            "firstName": "Barbara",
                            "lastName": "Caputo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Caputo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891864"
                        ],
                        "name": "Gyuri Dork\u00f3",
                        "slug": "Gyuri-Dork\u00f3",
                        "structuredName": {
                            "firstName": "Gyuri",
                            "lastName": "Dork\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gyuri Dork\u00f3"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "1We have chosen Gaussian kernels over polynomial kernels as there is experimental evidence that Gaussian kernels perform better for object recognition tasks [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2895738,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9b052482992bc9f9ed106cf8cd95dd4548016ac",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a kernel method that allows to combine color and shape information for appearance-based object recognition. It doesn't require to define a new common representation, but use the power of kernels to combine different representations together in an effective manner. These results are achieved using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions. Experiments show an increase in recognition rate up to 5.92% with respect to conventional strategies."
            },
            "slug": "How-to-Combine-Color-and-Shape-Information-for-3D-Caputo-Dork\u00f3",
            "title": {
                "fragments": [],
                "text": "How to Combine Color and Shape Information for 3D Object Recognition: Kernels do the Trick"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A kernel method is presented that allows to combine color and shape information for appearance-based object recognition using results of statistical mechanics of spin glasses combined with Markov random fields via kernel functions."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775242"
                        ],
                        "name": "Frederik Schaffalitzky",
                        "slug": "Frederik-Schaffalitzky",
                        "structuredName": {
                            "firstName": "Frederik",
                            "lastName": "Schaffalitzky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frederik Schaffalitzky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2964260,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aac66ac5e90cc4c187a5aa063b522e5193ef8834",
            "isKey": false,
            "numCitedBy": 236,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe and demonstrate a texture region descriptor which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region. It is applicable to texture patches which are locally planar and have stationary statistics. The novelty of the descriptor is that it is based on statistics aggregated over the region, resulting in richer and more stable descriptors than those computed at a point. Two texture matching applications of this descriptor are demonstrated: (1) it is used to automatically identify, regions of the same type of texture, but with varying surface pose, within a single image; (2) it is used to support wide baseline stereo, i.e. to enable the automatic computation of the epipolar geometry between two images acquired from quite separated viewpoints. Results are presented on several sets of real images."
            },
            "slug": "Viewpoint-invariant-texture-matching-and-wide-Schaffalitzky-Zisserman",
            "title": {
                "fragments": [],
                "text": "Viewpoint invariant texture matching and wide baseline stereo"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A texture region descriptor is described and demonstrated which is invariant to affine geometric and photometric transformations, and insensitive to the shape of the texture region, resulting in richer and more stable descriptors than those computed at a point."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Example 1 Jet features [22] are a particularly successful example of local features in the literature."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [22, 20, 12])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 an interest point detector (a popular choice is the Harris corner detector, [22, 20, 12]) detects ni points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22, 6, 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarity between jet features, which are differential intensity invariants computed around interest points, is measured via the Mahalanobis distance [22]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Local representations [22, 16, 12] address both problems as they consist of a number of localized features in the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "dM can be easily mapped into an Euclidean distance dE [22]: the covariance matrix is a real symmetric positive semidefinite matrix, which can be decomposed via SVD:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As local representation, we chose the jet features proposed in [22],"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Based on local characteristics, Schmid and Mohr [22] developed a system that can recognize objects in the case of partial visibility, image transformations and within complex scenes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 lj(Ii) is a feature vector computed locally around the j-th point (see for instance [22, 26, 20])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 325871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49fcd806450d947e56c82ef2b438ad9c484069dc",
            "isKey": true,
            "numCitedBy": 1792,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of retrieving images from large image databases. The method is based on local grayvalue invariants which are computed at automatically detected interest points. A voting algorithm and semilocal constraints make retrieval possible. Indexing allows for efficient retrieval from a database of more than 1,000 images. Experimental results show correct retrieval in the case of partial visibility, similarity transformations, extraneous features, and small perspective deformations."
            },
            "slug": "Local-Grayvalue-Invariants-for-Image-Retrieval-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Local Grayvalue Invariants for Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper addresses the problem of retrieving images from large image databases with a method based on local grayvalue invariants which are computed at automatically detected interest points and allows for efficient retrieval from a database of more than 1,000 images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2667432"
                        ],
                        "name": "D. Roobaert",
                        "slug": "D.-Roobaert",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Roobaert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roobaert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682587"
                        ],
                        "name": "M. Zillich",
                        "slug": "M.-Zillich",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Zillich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zillich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270435"
                        ],
                        "name": "J. Eklundh",
                        "slug": "J.-Eklundh",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Eklundh",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Eklundh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[19] examined the generalization capability of SVMs, when just a few number of views per objects are available."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 103
                            }
                        ],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22, 6, 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 83
                            }
                        ],
                        "text": "This model set could consist of the original images, considered as feature vectors [18, 19, 1], or of features extracted from the original views, such as color [24] or texture [21]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 290
                            }
                        ],
                        "text": "Support Vector Machines (SVMs, [9, 25]), on the other hand, represent a class of learning algorithms, which are based on a thorough mathematical founding, and - while more computationally expensive than other matching techniques - have shown impressive learning and recognition performance [19, 1, 8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "The simplest representation - raw pixel data of input images - can achieve surprisingly high recognition rates [18, 19], but is highly sensitive to all signal changes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29736465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cf70a08a6042f523b9b0716477c6c2c16b4b9f6",
            "isKey": true,
            "numCitedBy": 30,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Pursuing the goals of absolute simplicity of a detection/recognition system, a pure learning approach to background-invariance and visual 3D object detection/recognition is proposed. The approach relies on learning from examples only, and does not encode any domain knowledge (e.g. in the form of intermediate representations, or by solving segmentation or correspondence problems). To make the pure learning approach practically feasible, we propose the BW training method for teaching an object recognition system background-invariance. The method consist of pedagogically training the system, once with a black background and once with a white background. The method is formulated within the framework of support vector learning. Evaluation is performed with the Columbia Image (COIL) database, that is extended with different classes of cluttered backgrounds. Using this pure learning approach, a system is proposed that is able to perform 3D object detection/recognition successfully in real-world scenes, with varying illuminations and backgrounds. The system is able to perform this task in real-time."
            },
            "slug": "A-pure-learning-approach-to-background-invariant-Roobaert-Zillich",
            "title": {
                "fragments": [],
                "text": "A pure learning approach to background-invariant object recognition using pedagogical support vector learning"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The BW training method for teaching an object recognition system background-invariance is proposed, and a system is proposed that is able to perform 3D object detection/recognition successfully in real-world scenes, with varying illuminations and backgrounds."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2987811"
                        ],
                        "name": "M. Swain",
                        "slug": "M.-Swain",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Swain",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Swain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "For these local features one can use as Kl the intersection measure introduced by Swain and Ballard [24], which was proven to be a Mercer kernel [1], or"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 65
                            }
                        ],
                        "text": "Other global representations like color or derivative histograms [24, 21] are in its original form rather sensitive to occlusions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Swain and Ballard [24] proposed to represent an object by its color histogram, which was was shown to be robust to changes in orientation, scale, partial occlusion and changes of the viewing position."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 82
                            }
                        ],
                        "text": "For these local features one can use as Kl the intersection measure introduced by Swain and Ballard [24], which was proven to be a Mercer kernel [1], or\nK\u03c72(x,y) = exp {\u2212\u03c1\u03c72(x,y)}, (6)\nKa,b(x,y) = exp {\u2212\u03c1||xa \u2212 ya||b}, (7) with a \u2208 +, b \u2208]0, 2]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "As already observed in [24], color histograms seem to be relatively more robust to occlusion (Table 2, right column, middle)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "This model set could consist of the original images, considered as feature vectors [18, 19, 1], or of features extracted from the original views, such as color [24] or texture [21]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8167136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b1e1696564e5a3021ac3a501c9deeb6c0fbc637",
            "isKey": true,
            "numCitedBy": 5039,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer vision is embracing a new research focus in which the aim is to develop visual skills for robots that allow them to interact with a dynamic, realistic environment. To achieve this aim, new kinds of vision algorithms need to be developed which run in real time and subserve the robot's goals. Two fundamental goals are determining the location of a known object. Color can be successfully used for both tasks.This article demonstrates that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models. It shows that color histograms are stable object representations in the presence of occlusion and over change in view, and that they can differentiate among a large number of objects. For solving the identification problem, it introduces a technique calledHistogram Intersection, which matches model and image histograms and a fast incremental version of Histogram Intersection, which allows real-time indexing into a large database of stored models. For solving the location problem it introduces an algorithm calledHistogram Backprojection, which performs this task efficiently in crowded scenes."
            },
            "slug": "Color-indexing-Swain-Ballard",
            "title": {
                "fragments": [],
                "text": "Color indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is demonstrated that color histograms of multicolored objects provide a robust, efficient cue for indexing into a large database of models and that they can differentiate among a large number of objects."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144746444"
                        ],
                        "name": "H. Bischof",
                        "slug": "H.-Bischof",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bischof",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bischof"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739561"
                        ],
                        "name": "H. Wildenauer",
                        "slug": "H.-Wildenauer",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Wildenauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wildenauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732672"
                        ],
                        "name": "A. Leonardis",
                        "slug": "A.-Leonardis",
                        "structuredName": {
                            "firstName": "Ale\u0161",
                            "lastName": "Leonardis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Leonardis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 103
                            }
                        ],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22, 6, 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5207618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27dbe16d04049852bba12cb6f1c7ef28ce897029",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Variations in illumination can have a dramatic effect on the appearance of an object in an image. In this paper we propose how to deal with illumination variations in eigenspace methods. We demonstrate that the eigenimages obtained by a training set under a single illumination condition (ambient light) can be used for recognition of objects taken under different illumination conditions. The major idea is to incorporate a set of gradient based filter banks into the eigenspace recognition framework. This can be achieved since the eigenimage coefficients are invariant for linearly filtered images (input and eigenimages). To achieve further illumination insensitivity we devised a robust procedure for coefficient recovery. The proposed approach has been extensively evaluated on a set of 2160 images and the results were compared to other approaches."
            },
            "slug": "Illumination-insensitive-eigenspaces-Bischof-Wildenauer",
            "title": {
                "fragments": [],
                "text": "Illumination insensitive eigenspaces"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that the eigenimages obtained by a training set under a single illumination condition (ambient light) can be used for recognition of objects taken under different illumination conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34679741"
                        ],
                        "name": "S. Li",
                        "slug": "S.-Li",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2296344"
                        ],
                        "name": "QingDong Fu",
                        "slug": "QingDong-Fu",
                        "structuredName": {
                            "firstName": "QingDong",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "QingDong Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3062639"
                        ],
                        "name": "L. Gu",
                        "slug": "L.-Gu",
                        "structuredName": {
                            "firstName": "Lie",
                            "lastName": "Gu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49096825"
                        ],
                        "name": "Yimin Cheng",
                        "slug": "Yimin-Cheng",
                        "structuredName": {
                            "firstName": "Yimin",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yimin Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108698841"
                        ],
                        "name": "HongJiang Zhang",
                        "slug": "HongJiang-Zhang",
                        "structuredName": {
                            "firstName": "HongJiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HongJiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16401099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58e47bd5905d01022f33965f81047867ef54d69e",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Face images are subject to changes in view and illumination. Such changes cause data distribution to be highly nonlinear and complex in the image space. It is desirable to learn a nonlinear mapping from the image space to a low dimensional space such that the distribution becomes simpler tighter and therefore more predictable for better modeling effaces. In this paper we present a kernel machine based approach for learning such nonlinear mappings. The aim is to provide an effective view-based representation for multi-view face detection and pose estimation. Assuming that the view is partitioned into a number of distinct ranges, one nonlinear view-subspace is learned for each (range of) view from a set of example face images of that view (range), by using kernel principal component analysis (KPCA). Projections of the data onto the view-subspaces are then computed as view-based nonlinear features. Multi-view face detection and pose estimation are performed by classifying a face into one of the facial views or into the nonface class, by using a multi-class kernel support vector classifier (KSVC). Experimental results show that fusion of evidences from multi-views can produce better results than using the result from a single view; and that our approach yields high detection and low false alarm rates in face detection and good accuracy in pose estimation, in comparison with the linear counterpart composed of linear principal component analysis (PCA) feature extraction and Fisher linear discriminant based classification (FLDC)."
            },
            "slug": "Kernel-machine-based-learning-for-multi-view-face-Li-Fu",
            "title": {
                "fragments": [],
                "text": "Kernel machine based learning for multi-view face detection and pose estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Experimental results show that fusion of evidences from multi-views can produce better results than using the result from a single view, and that this kernel machine based approach for learning nonlinear mappings for multi-view face detection and pose estimation yields high detection and low false alarm rates."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35674406"
                        ],
                        "name": "Shigeo Abe DrEng",
                        "slug": "Shigeo-Abe-DrEng",
                        "structuredName": {
                            "firstName": "Shigeo",
                            "lastName": "DrEng",
                            "middleNames": [
                                "Abe"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shigeo Abe DrEng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 192
                            }
                        ],
                        "text": "One might wonder whether this comparison is fair: it is certainly possible to use more sophisticated methods for classification than just simple NNC, such as voting schemes and decision trees [10, 22, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9384346,
            "fieldsOfStudy": [
                "Mathematics",
                "Environmental Science"
            ],
            "id": "65a69968bb8c41aad0113cec4c2d981bddf50bc8",
            "isKey": false,
            "numCitedBy": 13095,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification \u2022 Supervised \u2013 parallelpiped \u2013 minimum distance \u2013 maximum likelihood (Bayes Rule) > non-parametric > parametric \u2013 support vector machines \u2013 neural networks \u2013 context classification \u2022 Unsupervised (clustering) \u2013 K-Means \u2013 ISODATA \u2022 Pattern recognition in remote sensing has been based on the intuitive notion that pixels belonging to the same class should have similar gray values in a given band. \u2013 Given two spectral bands, pixels from the same class plotted in a two-dimensional histogram should appear as a localized cluster. \u2013 If n images, each in a different spectral band, are available, pixels from the same class should form a localized cluster in n-space."
            },
            "slug": "Pattern-Classification-DrEng",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": "Springer London"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 82
                            }
                        ],
                        "text": "We begin by recalling that a kernel function K(x,y) must satisfy Mercer\u2019s theorem [9, 25], and that it holds that:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "Proof exp{\u2212(pjh(Lh) \u2212 pjk(Lk))(2)/2\u03c3(2)} is a Mercer kernel (Gaussian kernel, [9, 25]), thus its product with Kl is still a Mercer kernel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 291
                            }
                        ],
                        "text": "If we assume that the two classes can be separated by a hyperplane w \u00b7 x + b = 0, and that we have no prior knowledge about the data distribution, then the optimal hyperplane (that is, the one with the lowest bound on the expected generalization error) is the one which maximizes the margin [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 60
                            }
                        ],
                        "text": "where \u03b1i and b are found by using an SVC learning algorithm [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 31
                            }
                        ],
                        "text": "Support Vector Machines (SVMs, [9, 25]), on the other hand, represent a class of learning algorithms, which are based on a thorough mathematical founding, and - while more computationally expensive than other matching techniques - have shown impressive learning and recognition performance [19, 1, 8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 84
                            }
                        ],
                        "text": "For further details and the extension to multiclass settings we refer the reader to [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14727192,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53",
            "isKey": true,
            "numCitedBy": 13352,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software."
            },
            "slug": "An-Introduction-to-Support-Vector-Machines-and-Cristianini-Shawe-Taylor",
            "title": {
                "fragments": [],
                "text": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory, and will guide practitioners to updated literature, new applications, and on-line software."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712041"
                        ],
                        "name": "K. Mikolajczyk",
                        "slug": "K.-Mikolajczyk",
                        "structuredName": {
                            "firstName": "Krystian",
                            "lastName": "Mikolajczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mikolajczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8571961,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "9c7a96155f10f152cae0866102c061cdf6da02e8",
            "isKey": false,
            "numCitedBy": 1683,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas : 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images."
            },
            "slug": "An-Affine-Invariant-Interest-Point-Detector-Mikolajczyk-Schmid",
            "title": {
                "fragments": [],
                "text": "An Affine Invariant Interest Point Detector"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A novel approach for detecting affine invariant interest points that can deal with significant affine transformations including large scale changes and shows an excellent performance in the presence of large perspective transformations including significant scale changes."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2121009"
                        ],
                        "name": "J. Puzicha",
                        "slug": "J.-Puzicha",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Puzicha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Puzicha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8446909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "500db68171e4a961d7fa87b8020b3a3e62133caf",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by (1) solving for correspondences between points on the two shapes, (2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. Dis-similarity between two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework. Results are presented for silhouettes, trademarks, handwritten digits and the COIL dataset."
            },
            "slug": "Matching-shapes-Belongie-Malik",
            "title": {
                "fragments": [],
                "text": "Matching shapes"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A novel approach to measuring similarity between shapes and exploiting it for object recognition in a nearest-neighbor classification framework that applies regularized thin-plate splines to the transformation maps for this purpose."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692283"
                        ],
                        "name": "C. Bauckhage",
                        "slug": "C.-Bauckhage",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauckhage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bauckhage"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "Detection of interest points was done using a standard Harris-type corner detector, which was shown to have high repeatability and robust performance [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14571093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2713e7a59105a832e20c01c3c202b9dcd2b5f889",
            "isKey": false,
            "numCitedBy": 1730,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different low-level feature detectors exist and it is widely agreed that the evaluation of detectors is important. In this paper we introduce two evaluation criteria for interest points' repeatability rate and information content. Repeatability rate evaluates the geometric stability under different transformations. Information content measures the distinctiveness of features. Different interest point detectors are compared using these two criteria. We determine which detector gives the best results and show that it satisfies the criteria well."
            },
            "slug": "Evaluation-of-Interest-Point-Detectors-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Evaluation of Interest Point Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two evaluation criteria for interest points' repeatability rate and information content are introduced and different interest point detectors are compared using these two criteria."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143991676"
                        ],
                        "name": "I. Laptev",
                        "slug": "I.-Laptev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Laptev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Laptev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3205375"
                        ],
                        "name": "T. Lindeberg",
                        "slug": "T.-Lindeberg",
                        "structuredName": {
                            "firstName": "Tony",
                            "lastName": "Lindeberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lindeberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 235
                            }
                        ],
                        "text": "Given a set of images I = {Ii}i=1, the most general local feature vector for the image Ii can be described as Li = {lj(Ii),pj(Ii)} j=1, computed as follows: \u2022 an interest point detector (a popular choice is the Harris corner detector, [22, 20, 12]) detects ni points."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "Local representations [22, 16, 12] address both problems as they consist of a number of localized features in the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "The idea was further developed by many authors in order to include invariances (such as viewpoint invariance [20], affine invariance [16], scale-space selection [12])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 187
                            }
                        ],
                        "text": "Several successful vision systems that use such local feature representations have been developed, and seem to be able to support high recognition performance under real-world conditions [16, 20, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3781038,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "ca8cdcfe78424e27fc1cc96415a99326fd2655a0",
            "isKey": true,
            "numCitedBy": 33,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Several types of interest point detectors have been proposed for spatial images. This paper investigates how this notion can be generalised to the detection of interesting events in space-time data. Moreover, we develop a mechanism for spatio-temporal scale selection and detect events at scales corresponding to their extent in both space and time. \n \nTo detect spatio-temporal events, we build on the idea of the Harris and Forstner interest point operators and detect regions in space-time where the image structures have significant local variations in both space and time. In this way, events that correspond to curved space-time structures are emphasised, while structures with locally constant motion are disregarded. \n \nTo construct this operator, we start from a multi-scale windowed second moment matrix in space-time, and combine the determinant and the trace in a similar way as for the spatial Harris operator. All spacetime maxima of this operator are then adapted to characteristic scales by maximising a scale-normalised space-time Laplacian operator over both spatial scales and temporal scales. The motivation for performing temporal scale selection as a complement to previous approaches of spatial scale selection is to be able to robustly capture spatio-temporal events of different temporal extent. It is shown that the resulting approach is truly scale invariant with respect to both spatial scales and temporal scales. The proposed concept is tested on synthetic and real image sequences. \n \nIt is shown that the operator responds to distinct and stable points in space-time that often correspond to interesting events. The potential applications of the method are discussed."
            },
            "slug": "Interest-Point-Detection-and-Scale-Selection-in-Laptev-Lindeberg",
            "title": {
                "fragments": [],
                "text": "Interest Point Detection and Scale Selection in Space-Time"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A mechanism for spatio-temporal scale selection and detect events at scales corresponding to their extent in both space and time, and it is shown that the resulting approach is truly scale invariant with respect to both spatial scales and temporal scales."
            },
            "venue": {
                "fragments": [],
                "text": "Scale-Space"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116158963"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Nayar",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58758670,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "77afac8f4d7f47c8b34371d8f8355cefbea1d4f6",
            "isKey": false,
            "numCitedBy": 2004,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Columbia Object Image Library COIL is a database of color images of objects The objects were placed on a motorized turntable against a black background The turntable was rotated through degrees to vary object pose with respect to a xed color camera Images of the objects were taken at pose intervals of degrees This corresponds to poses per object The images were size normalized COIL is available online via ftp"
            },
            "slug": "Columbia-Object-Image-Library-(COIL100)-Nayar",
            "title": {
                "fragments": [],
                "text": "Columbia Object Image Library (COIL100)"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "Columbia Object Image Library COIL is a database of color images of objects that were placed on a motorized turntable against a black background and rotated through degrees to vary object pose with respect to a xed color camera."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "Both are Mercer kernels [2, 25], and both have been successfully used with histogram features [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 82
                            }
                        ],
                        "text": "We begin by recalling that a kernel function K(x,y) must satisfy Mercer\u2019s theorem [9, 25], and that it holds that:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "Proof exp{\u2212(pjh(Lh) \u2212 pjk(Lk))(2)/2\u03c3(2)} is a Mercer kernel (Gaussian kernel, [9, 25]), thus its product with Kl is still a Mercer kernel."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 291
                            }
                        ],
                        "text": "If we assume that the two classes can be separated by a hyperplane w \u00b7 x + b = 0, and that we have no prior knowledge about the data distribution, then the optimal hyperplane (that is, the one with the lowest bound on the expected generalization error) is the one which maximizes the margin [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 60
                            }
                        ],
                        "text": "where \u03b1i and b are found by using an SVC learning algorithm [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 31
                            }
                        ],
                        "text": "Support Vector Machines (SVMs, [9, 25]), on the other hand, represent a class of learning algorithms, which are based on a thorough mathematical founding, and - while more computationally expensive than other matching techniques - have shown impressive learning and recognition performance [19, 1, 8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 84
                            }
                        ],
                        "text": "For further details and the extension to multiclass settings we refer the reader to [9, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28637672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "385197d4c02593e2823c71e4f90a0993b703620e",
            "isKey": true,
            "numCitedBy": 26320,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "A comprehensive look at learning and generalization theory. The statistical theory of learning and generalization concerns the problem of choosing desired functions on the basis of empirical data. Highly applicable to a variety of computer science and robotics fields, this book offers lucid coverage of the theory as a whole. Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "slug": "Statistical-learning-theory-Vapnik",
            "title": {
                "fragments": [],
                "text": "Statistical learning theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "Presenting a method for determining the necessary and sufficient conditions for consistency of learning process, the author covers function estimates from small data pools, applying these estimations to real-life problems, and much more."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127116590"
                        ],
                        "name": "Thomas de Quincey",
                        "slug": "Thomas-de-Quincey",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "de Quincey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas de Quincey"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "Local representations [22, 16, 12] address both problems as they consist of a number of localized features in the image."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "The idea was further developed by many authors in order to include invariances (such as viewpoint invariance [20], affine invariance [16], scale-space selection [12])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 187
                            }
                        ],
                        "text": "Several successful vision systems that use such local feature representations have been developed, and seem to be able to support high recognition performance under real-world conditions [16, 20, 12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 224
                            }
                        ],
                        "text": "This is due to the intrinsic structure of both techniques: local representations generally consist of feature vectors of different length, and matching has traditionally required the definition of ad-hoc similarity measures [16, 20, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 239491155,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "927881a5602f430ffd145d44b8c35cf7a07b464d",
            "isKey": true,
            "numCitedBy": 69751,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In supernova (SN) spectroscopy relatively little attention has been given to the properties of optically thick spectral lines in epochs following the photosphere\u2019s recession. Most treatments and analyses of post-photospheric optical spectra of SNe assume that forbidden-line emission comprises most if not all spectral features. However, evidence exists that suggests that some spectra exhibit line profiles formed via optically thick resonance-scattering even months or years after the SN explosion. To explore this possibility, we present a geometrical approach to SN spectrum formation based on the \u201cElementary Supernova\u201d model, wherein we investigate the characteristics of resonance-scattering in optically thick lines while replacing the photosphere with a transparent central core emitting non-blackbody continuum radiation, akin to the optical continuum provided by decaying 56Co formed during the explosion. We develop the mathematical framework necessary for solving the radiative transfer equation under these conditions and calculate spectra for both isolated and blended lines. Our comparisons with analogous results from the Elementary Supernova code SYNOW reveal several marked differences in line formation. Most notably, resonance lines in these conditions form P Cygni-like profiles, but the emission peaks and absorption troughs shift redward and blueward, respectively, from the line\u2019s rest wavelength by a significant amount, despite the spherically symmetric distribution of the line optical depth in the ejecta. These properties and others that we find in this work could lead to misidentification of lines or misattribution of properties of line-forming material at post-photospheric times in SN optical spectra."
            },
            "slug": "[C]-Quincey",
            "title": {
                "fragments": [],
                "text": "[C]"
            },
            "venue": {
                "fragments": [],
                "text": "The Works of Thomas De Quincey, Vol. 1: Writings, 1799\u20131820"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 159
                            }
                        ],
                        "text": "Note that this metric does not make use of information contained in the feature positions, such as local feature constellations [22], or global feature layout [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Example 3 In [26] a first application of local SVM kernels was given, which were used on tracked local features."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "5 (see also [26]), show that it is possible to significantly improve recognition performance on degraded images by incorporating this extra information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 98
                            }
                        ],
                        "text": "The growing number of papers addressing object recognition using kernel methods (see for instance [14, 6, 26] and many others) is an indicator for the interest of the computer vision community in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 224
                            }
                        ],
                        "text": "This is due to the intrinsic structure of both techniques: local representations generally consist of feature vectors of different length, and matching has traditionally required the definition of ad-hoc similarity measures [16, 20, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "However, a common limitation of all these approaches (with the noticeable exception of [26]) is that they can handle only global features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 86
                            }
                        ],
                        "text": "\u2022 lj(Ii) is a feature vector computed locally around the j-th point (see for instance [22, 26, 20])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "View-based dynamic recognition based on human perception"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICPR\u201902"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "Cue integration: Kernel methods can be a powerful method for cue integration [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 155
                            }
                        ],
                        "text": "Recent years have seen impressive improvements in object recognition performance under such conditions [3, 19], and it seems that appearance-based methods [21, 22, 6, 3] are gaining popularity over structural methods [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 94
                            }
                        ],
                        "text": "Both are Mercer kernels [2, 25], and both have been successfully used with histogram features [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 98
                            }
                        ],
                        "text": "The growing number of papers addressing object recognition using kernel methods (see for instance [14, 6, 26] and many others) is an indicator for the interest of the computer vision community in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust appearancebased object recognition using a fully connected Markov random field"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of ICPR\u201902"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113881386"
                        ],
                        "name": "M. Turk",
                        "slug": "M.-Turk",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Turk",
                            "middleNames": [
                                "R",
                                "obert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Turk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 203705211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71d67283157475c4e6460c52408c00e9f6b8d2fe",
            "isKey": false,
            "numCitedBy": 2356,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-morphable-model-for-the-synthesis-of-3D-faces-Turk",
            "title": {
                "fragments": [],
                "text": "A morphable model for the synthesis of 3D faces"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 1999"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "The corresponding kernel (in the sense that it is the kernel which maps the data in an Euclidean space [5]) is the Gaussian kernel (7), with a = 1, b = 2 1."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117967708,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4a7a9c568e050853609ae18f9b7733dbb756177d",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Geometry-and-invariance-in-kernel-based-methods-Burges",
            "title": {
                "fragments": [],
                "text": "Geometry and invariance in kernel based methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789756"
                        ],
                        "name": "B. Leibe",
                        "slug": "B.-Leibe",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Leibe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Leibe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48920094"
                        ],
                        "name": "B. Schiele",
                        "slug": "B.-Schiele",
                        "structuredName": {
                            "firstName": "Bernt",
                            "lastName": "Schiele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Schiele"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59863240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7062b301ef75d3d407478601eccc402cb2837988",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Analyzing-contour-and-appearance-based-methods-for-Leibe-Schiele",
            "title": {
                "fragments": [],
                "text": "Analyzing contour and appearance based methods for object categorization"
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2003"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One might wonder whether this comparison is fair: it is certainly possible to use more sophisticated methods for classification than just simple NNC, such as voting schemes and decision trees [10, 22, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 196008710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78053512af13466c569e5946acfc3953bbfc9d36",
            "isKey": false,
            "numCitedBy": 18024,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-Classification-Hart-Duda",
            "title": {
                "fragments": [],
                "text": "Pattern Classification"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861222864"
                        ],
                        "name": "Miss A.O. Penney",
                        "slug": "Miss-A.O.-Penney",
                        "structuredName": {
                            "firstName": "Miss",
                            "lastName": "Penney",
                            "middleNames": [
                                "A.O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miss A.O. Penney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 98
                            }
                        ],
                        "text": "The growing number of papers addressing object recognition using kernel methods (see for instance [14, 6, 26] and many others) is an indicator for the interest of the computer vision community in this area."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 221039574,
            "fieldsOfStudy": [],
            "id": "45fd483402290ad4cae059a4e20cd586c019c3da",
            "isKey": false,
            "numCitedBy": 151818,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "(b)-Penney",
            "title": {
                "fragments": [],
                "text": "(b)"
            },
            "venue": {
                "fragments": [],
                "text": "The New Yale Book of Quotations"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proceedings of the Ninth IEEE International Conference on Computer Vision (ICCV 2003"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Ninth IEEE International Conference on Computer Vision (ICCV 2003"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 304,
                                "start": 290
                            }
                        ],
                        "text": "Support Vector Machines (SVMs, [9, 25]), on the other hand, represent a class of learning algorithms, which are based on a thorough mathematical founding, and - while more computationally expensive than other matching techniques - have shown impressive learning and recognition performance [19, 1, 8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 204
                            }
                        ],
                        "text": "\u2019Learning-free\u2019 algorithms such as nearest neighbor techniques can provide a good baseline for recognition experiments, but often suffer from inferior generalization capabilities in real-world conditions [8, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 94
                            }
                        ],
                        "text": "Both are Mercer kernels [2, 25], and both have been successfully used with histogram features [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SVMs for histogrambased image classification"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. on Neural Networks, 10(5)"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 24
                            }
                        ],
                        "text": "Both are Mercer kernels [2, 25], and both have been successfully used with histogram features [6, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Puchiza, \u201cMatching Shapes"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICCV\u201901,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support vector machines for 3 D object recognition \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TPAMI"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "View - based dynamic recognition based on human perception \u201d , Proc . ICPR \u2019 02 ,"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Recognition-with-local-features:-the-kernel-recipe-Wallraven-Caputo/c393b31ca71e8c4dd7c8c5a11653b18447c90466?sort=total-citations"
}