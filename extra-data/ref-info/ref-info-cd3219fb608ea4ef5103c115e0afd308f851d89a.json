{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367820"
                        ],
                        "name": "C. Wah",
                        "slug": "C.-Wah",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Wah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3251767"
                        ],
                        "name": "Steve Branson",
                        "slug": "Steve-Branson",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Branson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steve Branson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11263742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc15498e5b3b527e59d4ec69233f84bc851c377d",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a visual recognition system that is designed for fine-grained visual categorization. The system is composed of a machine and a human user. The user, who is unable to carry out the recognition task by himself, is interactively asked to provide two heterogeneous forms of information: clicking on object parts and answering binary questions. The machine intelligently selects the most informative question to pose to the user in order to identify the object's class as quickly as possible. By leveraging computer vision and analyzing the user responses, the overall amount of human effort required, measured in seconds, is minimized. We demonstrate promising results on a challenging dataset of uncropped images, achieving a significant average reduction in human effort over previous methods."
            },
            "slug": "Multiclass-recognition-and-part-localization-with-Wah-Branson",
            "title": {
                "fragments": [],
                "text": "Multiclass recognition and part localization with humans in the loop"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A visual recognition system that is designed for fine-grained visual categorization that leveraging computer vision and analyzing the user responses achieves a significant average reduction in human effort over previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787591"
                        ],
                        "name": "Christoph H. Lampert",
                        "slug": "Christoph-H.-Lampert",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Lampert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoph H. Lampert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748758"
                        ],
                        "name": "H. Nickisch",
                        "slug": "H.-Nickisch",
                        "structuredName": {
                            "firstName": "Hannes",
                            "lastName": "Nickisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nickisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734990"
                        ],
                        "name": "S. Harmeling",
                        "slug": "S.-Harmeling",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Harmeling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Harmeling"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10301835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0566bf06a0368b518b8b474166f7b1dfef3f9283",
            "isKey": false,
            "numCitedBy": 1951,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of object classification when training and test classes are disjoint, i.e. no training examples of the target classes are available. This setup has hardly been studied in computer vision research, but it is the rule rather than the exception, because the world contains tens of thousands of different object classes and for only a very few of them image, collections have been formed and annotated with suitable class labels. In this paper, we tackle the problem by introducing attribute-based classification. It performs object detection based on a human-specified high-level description of the target objects instead of training images. The description consists of arbitrary semantic attributes, like shape, color or even geographic information. Because such properties transcend the specific learning task at hand, they can be pre-learned, e.g. from image datasets unrelated to the current task. Afterwards, new classes can be detected based on their attribute representation, without the need for a new training phase. In order to evaluate our method and to facilitate research in this area, we have assembled a new large-scale dataset, \u201cAnimals with Attributes\u201d, of over 30,000 animal images that match the 50 classes in Osherson's classic table of how strongly humans associate 85 semantic attributes with animal classes. Our experiments show that by using an attribute layer it is indeed possible to build a learning object detection system that does not require any training images of the target classes."
            },
            "slug": "Learning-to-detect-unseen-object-classes-by-Lampert-Nickisch",
            "title": {
                "fragments": [],
                "text": "Learning to detect unseen object classes by between-class attribute transfer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The experiments show that by using an attribute layer it is indeed possible to build a learning object detection system that does not require any training images of the target classes, and assembled a new large-scale dataset, \u201cAnimals with Attributes\u201d, of over 30,000 animal images that match the 50 classes in Osherson's classic table of how strongly humans associate 85 semantic attributes with animal classes."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782755"
                        ],
                        "name": "Josef Sivic",
                        "slug": "Josef-Sivic",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Sivic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josef Sivic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1874218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "555bd3cdd261ab42c3d40194be991ddec8b6a14c",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Objects in the world can be arranged into a hierarchy based on their semantic meaning (e.g. organism - animal - feline - cat). What about defining a hierarchy based on the visual appearance of objects? This paper investigates ways to automatically discover a hierarchical structure for the visual world from a collection of unlabeled images. Previous approaches for unsupervised object and scene discovery focused on partitioning the visual data into a set of non-overlapping classes of equal granularity. In this work, we propose to group visual objects using a multi-layer hierarchy tree that is based on common visual elements. This is achieved by adapting to the visual domain the generative hierarchical latent Dirichlet allocation (hLDA) model previously used for unsupervised discovery of topic hierarchies in text. Images are modeled using quantized local image regions as analogues to words in text. Employing the multiple segmentation framework of Russell et al. [22], we show that meaningful object hierarchies, together with object segmentations, can be automatically learned from unlabeled and unsegmented image collections without supervision. We demonstrate improved object classification and localization performance using hLDA over the previous non-hierarchical method on the MSRC dataset [33]."
            },
            "slug": "Unsupervised-discovery-of-visual-object-class-Sivic-Russell",
            "title": {
                "fragments": [],
                "text": "Unsupervised discovery of visual object class hierarchies"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes to group visual objects using a multi-layer hierarchy tree that is based on common visual elements by adapting to the visual domain the generative hierarchical latent Dirichlet allocation (hLDA) model previously used for unsupervised discovery of topic hierarchies in text."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365442"
                        ],
                        "name": "B. Alexe",
                        "slug": "B.-Alexe",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Alexe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alexe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879646"
                        ],
                        "name": "Thomas Deselaers",
                        "slug": "Thomas-Deselaers",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Deselaers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Deselaers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5611404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d957ad316f7145c054d2dcbd47949869e46776b0",
            "isKey": false,
            "numCitedBy": 1007,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel method for unsupervised class segmentation on a set of images. It alternates between segmenting object instances and learning a class model. The method is based on a segmentation energy defined over all images at the same time, which can be optimized efficiently by techniques used before in interactive segmentation. Over iterations, our method progressively learns a class model by integrating observations over all images. In addition to appearance, this model captures the location and shape of the class with respect to an automatically determined coordinate frame common across images. This frame allows us to build stronger shape and location models, similar to those used in object class detection. Our method is inspired by interactive segmentation methods [1], but it is fully automatic and learns models characteristic for the object class rather than specific to one particular object/image. We experimentally demonstrate on the Caltech4, Caltech101, and Weizmann horses datasets that our method (a) transfers class knowledge across images and this improves results compared to segmenting every image independently; (b) outperforms Grabcut [1] for the task of unsupervised segmentation; (c) offers competitive performance compared to the state-of-the-art in unsupervised segmentation and in particular it outperforms the topic model [2]."
            },
            "slug": "ClassCut-for-Unsupervised-Class-Segmentation-Alexe-Deselaers",
            "title": {
                "fragments": [],
                "text": "ClassCut for Unsupervised Class Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A novel method for unsupervised class segmentation on a set of images that alternates between segmenting object instances and learning a class model based on a segmentation energy defined over all images at the same time, which can be optimized efficiently by techniques used before in interactive segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47655614"
                        ],
                        "name": "G. Griffin",
                        "slug": "G.-Griffin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Griffin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160673"
                        ],
                        "name": "Alex Holub",
                        "slug": "Alex-Holub",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Holub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Holub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118828957,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a5effa909cdeafaddbbb7855037e02f8e25d632",
            "isKey": false,
            "numCitedBy": 2545,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a challenging set of 256 object categories containing a total of 30607 images. The original Caltech-101 [1] was collected by choosing a set of object categories, downloading examples from Google Images and then manually screening out all images that did not fit the category. Caltech-256 is collected in a similar manner with several improvements: a) the number of categories is more than doubled, b) the minimum number of images in any category is increased from 31 to 80, c) artifacts due to image rotation are avoided and d) a new and larger clutter category is introduced for testing background rejection. We suggest several testing paradigms to measure classification performance, then benchmark the dataset using two simple metrics as well as a state-of-the-art spatial pyramid matching [2] algorithm. Finally we use the clutter category to train an interest detector which rejects uninformative background regions."
            },
            "slug": "Caltech-256-Object-Category-Dataset-Griffin-Holub",
            "title": {
                "fragments": [],
                "text": "Caltech-256 Object Category Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A challenging set of 256 object categories containing a total of 30607 images is introduced and the clutter category is used to train an interest detector which rejects uninformative background regions."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399545196"
                        ],
                        "name": "Gonzalo Mart\u00ednez-Mu\u00f1oz",
                        "slug": "Gonzalo-Mart\u00ednez-Mu\u00f1oz",
                        "structuredName": {
                            "firstName": "Gonzalo",
                            "lastName": "Mart\u00ednez-Mu\u00f1oz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gonzalo Mart\u00ednez-Mu\u00f1oz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022023"
                        ],
                        "name": "N. Larios",
                        "slug": "N.-Larios",
                        "structuredName": {
                            "firstName": "Natalia",
                            "lastName": "Larios",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Larios"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39226969"
                        ],
                        "name": "Eric N. Mortensen",
                        "slug": "Eric-N.-Mortensen",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Mortensen",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric N. Mortensen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38946003"
                        ],
                        "name": "Wei Zhang",
                        "slug": "Wei-Zhang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076779172"
                        ],
                        "name": "Asako Yamamuro",
                        "slug": "Asako-Yamamuro",
                        "structuredName": {
                            "firstName": "Asako",
                            "lastName": "Yamamuro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Asako Yamamuro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2260055"
                        ],
                        "name": "R. Paasch",
                        "slug": "R.-Paasch",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Paasch",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Paasch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34596561"
                        ],
                        "name": "N. Payet",
                        "slug": "N.-Payet",
                        "structuredName": {
                            "firstName": "Nadia",
                            "lastName": "Payet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Payet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4231109"
                        ],
                        "name": "D. Lytle",
                        "slug": "D.-Lytle",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lytle",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lytle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809809"
                        ],
                        "name": "L. Shapiro",
                        "slug": "L.-Shapiro",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Shapiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143856428"
                        ],
                        "name": "S. Todorovic",
                        "slug": "S.-Todorovic",
                        "structuredName": {
                            "firstName": "Sinisa",
                            "lastName": "Todorovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Todorovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144363218"
                        ],
                        "name": "A. Moldenke",
                        "slug": "A.-Moldenke",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moldenke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moldenke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3127750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1983f844a46cbe98db2a3d24945b623244e5cd6",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Current work in object categorization discriminates among objects that typically possess gross differences which are readily apparent. However, many applications require making much finer distinctions. We address an insect categorization problem that is so challenging that even trained human experts cannot readily categorize images of insects considered in this paper. The state of the art that uses visual dictionaries, when applied to this problem, yields mediocre results (16.1% error). Three possible explanations for this are (a) the dictionaries are unsupervised, (b) the dictionaries lose the detailed information contained in each keypoint, and (c) these methods rely on hand-engineered decisions about dictionary size. This paper presents a novel, dictionary-free methodology. A random forest of trees is first trained to predict the class of an image based on individual keypoint descriptors. A unique aspect of these trees is that they do not make decisions but instead merely record evidence-i.e., the number of descriptors from training examples of each category that reached each leaf of the tree. We provide a mathematical model showing that voting evidence is better than voting decisions. To categorize a new image, descriptors for all detected keypoints are \u201cdropped\u201d through the trees, and the evidence at each leaf is summed to obtain an overall evidence vector. This is then sent to a second-level classifier to make the categorization decision. We achieve excellent performance (6.4% error) on the 9-class STONEFLY9 data set. Also, our method achieves an average AUC of 0.921 on the PASCAL06 VOC, which places it fifth out of 21 methods reported in the literature and demonstrates that the method also works well for generic object categorization."
            },
            "slug": "Dictionary-free-categorization-of-very-similar-via-Mart\u00ednez-Mu\u00f1oz-Larios",
            "title": {
                "fragments": [],
                "text": "Dictionary-free categorization of very similar objects via stacked evidence trees"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper addresses an insect categorization problem that is so challenging that even trained human experts cannot readily categorize images of insects considered, and provides a mathematical model showing that voting evidence is better than voting decisions."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2831988"
                        ],
                        "name": "Ian Endres",
                        "slug": "Ian-Endres",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Endres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian Endres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2433269"
                        ],
                        "name": "Derek Hoiem",
                        "slug": "Derek-Hoiem",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Hoiem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Hoiem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144016256"
                        ],
                        "name": "D. Forsyth",
                        "slug": "D.-Forsyth",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "Alexander"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14940757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6a8aef1bf134294482d8088f982d5643347d2ff",
            "isKey": false,
            "numCitedBy": 1665,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to shift the goal of recognition from naming to describing. Doing so allows us not only to name familiar objects, but also: to report unusual aspects of a familiar object (\u201cspotty dog\u201d, not just \u201cdog\u201d); to say something about unfamiliar objects (\u201chairy and four-legged\u201d, not just \u201cunknown\u201d); and to learn how to recognize new objects with few or no visual examples. Rather than focusing on identity assignment, we make inferring attributes the core problem of recognition. These attributes can be semantic (\u201cspotty\u201d) or discriminative (\u201cdogs have it but sheep do not\u201d). Learning attributes presents a major new challenge: generalization across object categories, not just across instances within a category. In this paper, we also introduce a novel feature selection method for learning attributes that generalize well across categories. We support our claims by thorough evaluation that provides insights into the limitations of the standard recognition paradigm of naming and demonstrates the new abilities provided by our attribute-based framework."
            },
            "slug": "Describing-objects-by-their-attributes-Farhadi-Endres",
            "title": {
                "fragments": [],
                "text": "Describing objects by their attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper proposes to shift the goal of recognition from naming to describing, and introduces a novel feature selection method for learning attributes that generalize well across categories."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189118"
                        ],
                        "name": "Ashish Kapoor",
                        "slug": "Ashish-Kapoor",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Kapoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Kapoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 469536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5afcd7a69ddffc7b7ecfb82aed69f2e1ec007004",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative methods for visual object category recognition are typically non-probabilistic, predicting class labels but not directly providing an estimate of uncertainty. Gaussian Processes (GPs) are powerful regression techniques with explicit uncertainty models; we show here how Gaussian Processes with covariance functions defined based on a Pyramid Match Kernel (PMK) can be used for probabilistic object category recognition. The uncertainty model provided by GPs offers confidence estimates at test points, and naturally allows for an active learning paradigm in which points are optimally selected for interactive labeling. We derive a novel active category learning method based on our probabilistic regression model, and show that a significant boost in classification performance is possible, especially when the amount of training data for a category is ultimately very small."
            },
            "slug": "Active-Learning-with-Gaussian-Processes-for-Object-Kapoor-Grauman",
            "title": {
                "fragments": [],
                "text": "Active Learning with Gaussian Processes for Object Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work derives a novel active category learning method based on the probabilistic regression model, and shows that a significant boost in classification performance is possible, especially when the amount of training data for a category is ultimately very small."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11194336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42de22c119f25d303032396b8f7d962f62d6498b",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of detecting a large number of different object classes in cluttered scenes. Traditional approaches require applying a battery of different classifiers to the image, which can be slow and require much training data. We present a multi-class boosting procedure (joint boosting) that reduces both the computational and sample complexity, by finding common features that can be shared across the classes. The detectors for each class are trained jointly, rather than independently. For a given performance level, the total number of features required is observed to scale approximately logarithmically with the number of classes. In addition, we find that the features selected by independently trained classifiers are often specific to the class, whereas the features selected by the jointly trained classifiers are more generic features, such as lines and edges."
            },
            "slug": "Sharing-features:-efficient-boosting-procedures-for-Torralba-Murphy",
            "title": {
                "fragments": [],
                "text": "Sharing features: efficient boosting procedures for multiclass object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A multi-class boosting procedure (joint boosting) is presented that reduces both the computational and sample complexity, by finding common features that can be shared across the classes."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2918740"
                        ],
                        "name": "A. Vezhnevets",
                        "slug": "A.-Vezhnevets",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Vezhnevets",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vezhnevets"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143865718"
                        ],
                        "name": "V. Ferrari",
                        "slug": "V.-Ferrari",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Ferrari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ferrari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682548"
                        ],
                        "name": "J. Buhmann",
                        "slug": "J.-Buhmann",
                        "structuredName": {
                            "firstName": "Joachim",
                            "lastName": "Buhmann",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Buhmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1203780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2932a9c686ede327f41069e17962d330a7a3ebf",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel method for weakly supervised semantic segmentation. Training images are labeled only by the classes they contain, not by their location in the image. On test images instead, the method predicts a class label for every pixel. Our main innovation is a multi-image model (MIM) - a graphical model for recovering the pixel labels of the training images. The model connects superpixels from all training images in a data-driven fashion, based on their appearance similarity. For generalizing to new test images we integrate them into MIM using a learned multiple kernel metric, instead of learning conventional classifiers on the recovered pixel labels. We also introduce an \u201cobjectness\u201d potential, that helps separating objects (e.g. car, dog, human) from background classes (e.g. grass, sky, road). In experiments on the MSRC 21 dataset and the LabelMe subset of [18], our technique outperforms previous weakly supervised methods and achieves accuracy comparable with fully supervised methods."
            },
            "slug": "Weakly-supervised-semantic-segmentation-with-a-Vezhnevets-Ferrari",
            "title": {
                "fragments": [],
                "text": "Weakly supervised semantic segmentation with a multi-image model"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A novel method for weakly supervised semantic segmentation using a multi-image model (MIM) - a graphical model for recovering the pixel labels of the training images and introducing an \u201cobjectness\u201d potential, that helps separating objects from background classes."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Computer Vision"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144996078"
                        ],
                        "name": "Neeraj Kumar",
                        "slug": "Neeraj-Kumar",
                        "structuredName": {
                            "firstName": "Neeraj",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neeraj Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3136364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3046251ec5d6e7f90ef5ef2b0ac885c01138555",
            "isKey": false,
            "numCitedBy": 1479,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present two novel methods for face verification. Our first method - \u201cattribute\u201d classifiers - uses binary classifiers trained to recognize the presence or absence of describable aspects of visual appearance (e.g., gender, race, and age). Our second method - \u201csimile\u201d classifiers - removes the manual labeling required for attribute classification and instead learns the similarity of faces, or regions of faces, to specific reference people. Neither method requires costly, often brittle, alignment between image pairs; yet, both methods produce compact visual descriptions, and work on real-world images. Furthermore, both the attribute and simile classifiers improve on the current state-of-the-art for the LFW data set, reducing the error rates compared to the current best by 23.92% and 26.34%, respectively, and 31.68% when combined. For further testing across pose, illumination, and expression, we introduce a new data set - termed PubFig - of real-world images of public figures (celebrities and politicians) acquired from the internet. This data set is both larger (60,000 images) and deeper (300 images per individual) than existing data sets of its kind. Finally, we present an evaluation of human performance."
            },
            "slug": "Attribute-and-simile-classifiers-for-face-Kumar-Berg",
            "title": {
                "fragments": [],
                "text": "Attribute and simile classifiers for face verification"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Two novel methods for face verification using binary classifiers trained to recognize the presence or absence of describable aspects of visual appearance and a new data set of real-world images of public figures acquired from the internet."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144160673"
                        ],
                        "name": "Alex Holub",
                        "slug": "Alex-Holub",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Holub",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Holub"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2511655"
                        ],
                        "name": "M. Burl",
                        "slug": "M.-Burl",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Burl",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Burl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15855239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "777b96abef29da63d9b4b1a583fa25c24a5ee029",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Most methods for learning object categories require large amounts of labeled training data. However, obtaining such data can be a difficult and time-consuming endeavor. We have developed a novel, entropy-based ldquoactive learningrdquo approach which makes significant progress towards this problem. The main idea is to sequentially acquire labeled data by presenting an oracle (the user) with unlabeled images that will be particularly informative when labeled. Active learning adaptively prioritizes the order in which the training examples are acquired, which, as shown by our experiments, can significantly reduce the overall number of training examples required to reach near-optimal performance. At first glance this may seem counter-intuitive: how can the algorithm know whether a group of unlabeled images will be informative, when, by definition, there is no label directly associated with any of the images? Our approach is based on choosing an image to label that maximizes the expected amount of information we gain about the set of unlabeled images. The technique is demonstrated in several contexts, including improving the efficiency of Web image-search queries and open-world visual learning by an autonomous agent. Experiments on a large set of 140 visual object categories taken directly from text-based Web image searches show that our technique can provide large improvements (up to 10 x reduction in the number of training examples needed) over baseline techniques."
            },
            "slug": "Entropy-based-active-learning-for-object-Holub-Perona",
            "title": {
                "fragments": [],
                "text": "Entropy-based active learning for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel, entropy-basedactive learningrdquo approach to sequentially acquire labeled data by presenting an oracle with unlabeled images that will be particularly informative when labeled, which can significantly reduce the overall number of training examples required to reach near-optimal performance."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3083483"
                        ],
                        "name": "D. Nist\u00e9r",
                        "slug": "D.-Nist\u00e9r",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Nist\u00e9r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Nist\u00e9r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086037"
                        ],
                        "name": "Henrik Stew\u00e9nius",
                        "slug": "Henrik-Stew\u00e9nius",
                        "structuredName": {
                            "firstName": "Henrik",
                            "lastName": "Stew\u00e9nius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henrik Stew\u00e9nius"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1654266,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3e7d3e37e67af7f4546b46051063bea1b62dbae",
            "isKey": false,
            "numCitedBy": 3890,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition scheme that scales efficiently to a large number of objects is presented. The efficiency and quality is exhibited in a live demonstration that recognizes CD-covers from a database of 40000 images of popular music CD\u2019s. The scheme builds upon popular techniques of indexing descriptors extracted from local regions, and is robust to background clutter and occlusion. The local region descriptors are hierarchically quantized in a vocabulary tree. The vocabulary tree allows a larger and more discriminatory vocabulary to be used efficiently, which we show experimentally leads to a dramatic improvement in retrieval quality. The most significant property of the scheme is that the tree directly defines the quantization. The quantization and the indexing are therefore fully integrated, essentially being one and the same. The recognition quality is evaluated through retrieval on a database with ground truth, showing the power of the vocabulary tree approach, going as high as 1 million images."
            },
            "slug": "Scalable-Recognition-with-a-Vocabulary-Tree-Nist\u00e9r-Stew\u00e9nius",
            "title": {
                "fragments": [],
                "text": "Scalable Recognition with a Vocabulary Tree"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A recognition scheme that scales efficiently to a large number of objects and allows a larger and more discriminatory vocabulary to be used efficiently is presented, which it is shown experimentally leads to a dramatic improvement in retrieval quality."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885768"
                        ],
                        "name": "M. Chli",
                        "slug": "M.-Chli",
                        "structuredName": {
                            "firstName": "Margarita",
                            "lastName": "Chli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052135690"
                        ],
                        "name": "A. Davison",
                        "slug": "A.-Davison",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Davison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Davison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4518583,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04554de05a3a9ebb1890d25aaa7e34544a0d32a7",
            "isKey": false,
            "numCitedBy": 1119,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In the matching tasks which form an integral part of all types of tracking and geometrical vision, there are invariably priors available on the absolute and/or relative image locations of features of interest. Usually, these priors are used post-hoc in the process of resolving feature matches and obtaining final scene estimates, via `first get candidate matches, then resolve' consensus algorithms such as RANSAC. In this paper we show that the dramatically different approach of using priors dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operations and lower overall computational cost. Essentially, we put image processing into the loopof the search for global consensus. In particular, our approach is able to cope with significant image ambiguity thanks to a dynamic mixture of Gaussians treatment. In our fully Bayesian algorithm, the choice of the most efficient search action at each step is guided intuitively and rigorously by expected Shannon information gain. We demonstrate the algorithm in feature matching as part of a sequential SLAM system for 3D camera tracking. Robust, real-time matching can be achieved even in the previously unmanageable case of jerky, rapid motion necessitating weak motion modelling and large search regions."
            },
            "slug": "Active-Matching-Chli-Davison",
            "title": {
                "fragments": [],
                "text": "Active Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows that the dramatically different approach of using priors dynamically to guide a feature by feature matching search can achieve global matching with much fewer image processing operations and lower overall computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47655614"
                        ],
                        "name": "G. Griffin",
                        "slug": "G.-Griffin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Griffin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Griffin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12805251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49bab85f250ff4c086665691df4971c438336e0b",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The computational complexity of current visual categorization algorithms scales linearly at best with the number of categories. The goal of classifying simultaneously Ncat = 104 - 105 visual categories requires sub-linear classification costs. We explore algorithms for automatically building classification trees which have, in principle, logNcat complexity. We find that a greedy algorithm that recursively splits the set of categories into the two minimally confused subsets achieves 5-20 fold speedups at a small cost in classification performance. Our approach is independent of the specific classification algorithm used. A welcome by-product of our algorithm is a very reasonable taxonomy of the Caltech-256 dataset."
            },
            "slug": "Learning-and-using-taxonomies-for-fast-visual-Griffin-Perona",
            "title": {
                "fragments": [],
                "text": "Learning and using taxonomies for fast visual categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is found that a greedy algorithm that recursively splits the set of categories into the two minimally confused subsets achieves 5-20 fold speedups at a small cost in classification performance."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3236386"
                        ],
                        "name": "Varun Gulshan",
                        "slug": "Varun-Gulshan",
                        "structuredName": {
                            "firstName": "Varun",
                            "lastName": "Gulshan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Varun Gulshan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145859952"
                        ],
                        "name": "M. Varma",
                        "slug": "M.-Varma",
                        "structuredName": {
                            "firstName": "Manik",
                            "lastName": "Varma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Varma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206769604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9c7ab03bdb5fee15174d910d7fea14a16b086b7",
            "isKey": false,
            "numCitedBy": 883,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Our objective is to obtain a state-of-the art object category detector by employing a state-of-the-art image classifier to search for the object in all possible image sub-windows. We use multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential \u03c72 kernels, each of which captures a different feature channel. Our features include the distribution of edges, dense and sparse visual words, and feature descriptors at different levels of spatial organization."
            },
            "slug": "Multiple-kernels-for-object-detection-Vedaldi-Gulshan",
            "title": {
                "fragments": [],
                "text": "Multiple kernels for object detection"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "This work uses multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential \u03c72 kernels, each of which captures a different feature channel."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2646632"
                        ],
                        "name": "M. Nilsback",
                        "slug": "M.-Nilsback",
                        "structuredName": {
                            "firstName": "Maria-Elena",
                            "lastName": "Nilsback",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nilsback"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15193013,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02b28f3b71138a06e40dbd614abf8568420ae183",
            "isKey": false,
            "numCitedBy": 1802,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate to what extent combinations of features can improve classification performance on a large dataset of similar classes. To this end we introduce a 103 class flower dataset. We compute four different features for the flowers, each describing different aspects, namely the local shape/texture, the shape of the boundary, the overall spatial distribution of petals, and the colour. We combine the features using a multiple kernel framework with a SVM classifier. The weights for each class are learnt using the method of Varma and Ray, which has achieved state of the art performance on other large dataset, such as Caltech 101/256. Our dataset has a similar challenge in the number of classes, but with the added difficulty of large between class similarity and small within class similarity. Results show that learning the optimum kernel combination of multiple features vastly improves the performance, from 55.1% for the best single feature to 72.8% for the combination of all features."
            },
            "slug": "Automated-Flower-Classification-over-a-Large-Number-Nilsback-Zisserman",
            "title": {
                "fragments": [],
                "text": "Automated Flower Classification over a Large Number of Classes"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Results show that learning the optimum kernel combination of multiple features vastly improves the performance, from 55.1% for the best single feature to 72.8% forThe combination of all features."
            },
            "venue": {
                "fragments": [],
                "text": "2008 Sixth Indian Conference on Computer Vision, Graphics & Image Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767767"
                        ],
                        "name": "P. Belhumeur",
                        "slug": "P.-Belhumeur",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Belhumeur",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Belhumeur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40537878"
                        ],
                        "name": "Daozheng Chen",
                        "slug": "Daozheng-Chen",
                        "structuredName": {
                            "firstName": "Daozheng",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daozheng Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809403"
                        ],
                        "name": "S. Feiner",
                        "slug": "S.-Feiner",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Feiner",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Feiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734622"
                        ],
                        "name": "D. Jacobs",
                        "slug": "D.-Jacobs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145457982"
                        ],
                        "name": "W. Kress",
                        "slug": "W.-Kress",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Kress",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kress"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805398"
                        ],
                        "name": "Haibin Ling",
                        "slug": "Haibin-Ling",
                        "structuredName": {
                            "firstName": "Haibin",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haibin Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38785989"
                        ],
                        "name": "I. Lopez",
                        "slug": "I.-Lopez",
                        "structuredName": {
                            "firstName": "Ida",
                            "lastName": "Lopez",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Lopez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752236"
                        ],
                        "name": "R. Ramamoorthi",
                        "slug": "R.-Ramamoorthi",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Ramamoorthi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ramamoorthi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2853615"
                        ],
                        "name": "Sameer Sheorey",
                        "slug": "Sameer-Sheorey",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Sheorey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Sheorey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881336"
                        ],
                        "name": "Sean White",
                        "slug": "Sean-White",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712174"
                        ],
                        "name": "Ling Zhang",
                        "slug": "Ling-Zhang",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8268905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "090d99b041023c1f4af445122906baa41e41372a",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a working computer vision system that aids in the identification of plant species. A user photographs an isolated leaf on a blank background, and the system extracts the leaf shape and matches it to the shape of leaves of known species. In a few seconds, the sys- tem displays the top matching species, along with textual descriptions and additional images. This system is currently in use by botanists at the Smithsonian Institution National Museum of Natural History. The primary contributions of this paper are: a description of a working com- puter vision system and its user interface for an important new applica- tion area; the introduction of three new datasets containing thousands of single leaf images, each labeled by species and verified by botanists at the US National Herbarium; recognition results for two of the three leaf datasets; and descriptions throughout of practical lessons learned in constructing this system."
            },
            "slug": "Searching-the-World's-Herbaria:-A-System-for-Visual-Belhumeur-Chen",
            "title": {
                "fragments": [],
                "text": "Searching the World's Herbaria: A System for Visual Identification of Plant Species"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A working computer vision system that aids in the identification of plant species by extracting the leaf shape and matches it to the shape of leaves of known species is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5262555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "807c1f19047f96083e13614f7ce20f2ac98c239a",
            "isKey": false,
            "numCitedBy": 21897,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nClassifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation. \n \nC4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies. \n \nThis book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses."
            },
            "slug": "C4.5:-Programs-for-Machine-Learning-Quinlan",
            "title": {
                "fragments": [],
                "text": "C4.5: Programs for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A complete guide to the C4.5 system as implemented in C for the UNIX environment, which starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11736664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a32f6f23c05827e466580647467a322b7db9f7d",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a probabilistic part-based approach for texture and object recognition. Textures are represented using a part dictionary found by quantizing the appearance of scale- or affine- invariant keypoints. Object classes are represented using a dictionary of composite semi-local parts, or groups of neighboring keypoints with stable and distinctive appearance and geometric layout. A discriminative maximum entropy framework is used to learn the posterior distribution of the class label given the occurrences of parts from the dictionary in the training set. Experiments on two texture and two object databases demonstrate the effectiveness of this framework for visual classification."
            },
            "slug": "A-maximum-entropy-framework-for-part-based-texture-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "A maximum entropy framework for part-based texture and object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A probabilistic part-based approach for texture and object recognition using a discriminative maximum entropy framework to learn the posterior distribution of the class label given the occurrences of parts from the dictionary in the training set."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242194"
                        ],
                        "name": "Ghulum Bakiri",
                        "slug": "Ghulum-Bakiri",
                        "structuredName": {
                            "firstName": "Ghulum",
                            "lastName": "Bakiri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ghulum Bakiri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 47109072,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d221bbcbd20c7157e4500f942de8ceec490f8936",
            "isKey": false,
            "numCitedBy": 2852,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k > 2 values (i.e., k \"classes\"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and CART, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "slug": "Solving-Multiclass-Learning-Problems-via-Output-Dietterich-Bakiri",
            "title": {
                "fragments": [],
                "text": "Solving Multiclass Learning Problems via Error-Correcting Output Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is demonstrated that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058177533"
                        ],
                        "name": "Simon Tong",
                        "slug": "Simon-Tong",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Tong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7806109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8797f1d253c75669d96e6fcceda2be3f8534e1d",
            "isKey": false,
            "numCitedBy": 3138,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using pool-based active learning. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a version space. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings."
            },
            "slug": "Support-Vector-Machine-Active-Learning-with-to-Text-Tong-Koller",
            "title": {
                "fragments": [],
                "text": "Support Vector Machine Active Learning with Applications to Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Experimental results showing that employing the active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings are presented."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40403107"
                        ],
                        "name": "X. Zhou",
                        "slug": "X.-Zhou",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652752"
                        ],
                        "name": "Thomas S. Huang",
                        "slug": "Thomas-S.-Huang",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Huang",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas S. Huang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9664339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62cec1ef9f1d9135884c2a61919d20fbb8eda589",
            "isKey": false,
            "numCitedBy": 981,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We analyze the nature of the relevance feedback problem in a continuous representation space in the context of content-based image retrieval. Emphasis is put on exploring the uniqueness of the problem and comparing the assumptions, implementations, and merits of various solutions in the literature. An attempt is made to compile a list of critical issues to consider when designing a relevance feedback algorithm. With a comprehensive review as the main portion, this paper also offers some novel solutions and perspectives throughout the discussion."
            },
            "slug": "Relevance-feedback-in-image-retrieval:-A-review-Zhou-Huang",
            "title": {
                "fragments": [],
                "text": "Relevance feedback in image retrieval: A comprehensive review"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The nature of the relevance feedback problem in a continuous representation space in the context of content-based image retrieval is analyzed and a list of critical issues to consider when designing a relevance feedback algorithm is compiled."
            },
            "venue": {
                "fragments": [],
                "text": "Multimedia Systems"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2820860"
                        ],
                        "name": "R. Neapolitan",
                        "slug": "R.-Neapolitan",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Neapolitan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neapolitan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5473785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e1c26d71c62120ecfa0784bdf0b417ba6c6a982",
            "isKey": false,
            "numCitedBy": 703,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This text is a reprint of the seminal 1989 book Probabilistic Reasoning in Expert systems: Theory and Algorithms, which helped serve to create the field we now call Bayesian networks. It introduces the properties of Bayesian networks (called causal networks in the text), discusses algorithms for doing inference in Bayesian networks, covers abductive inference, and provides an introduction to decision analysis. Furthermore, it compares rule-base experts systems to ones based on Bayesian networks, and it introduces the frequentist and Bayesian approaches to probability. Finally, it provides a critique of the maximum entropy formalism. Probabilistic Reasoning in Expert Systems was written from the perspective of a mathematician with the emphasis being on the development of theorems and algorithms. Every effort was made to make the material accessible. There are ample examples throughout the text. This text is important reading for anyone interested in both the fundamentals of Bayesian networks and in the history of how they came to be. It also provides an insightful comparison of the two most prominent approaches to probability."
            },
            "slug": "Probabilistic-reasoning-in-expert-systems-theory-Neapolitan",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in expert systems - theory and algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This text is a reprint of the seminal 1989 book Probabilistic Reasoning in Expert systems: Theory and Algorithms, which helped serve to create the field the authors now call Bayesian networks and provides an insightful comparison of the two most prominent approaches to probability."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47321007"
                        ],
                        "name": "S. Tsang",
                        "slug": "S.-Tsang",
                        "structuredName": {
                            "firstName": "Smith",
                            "lastName": "Tsang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Tsang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145868757"
                        ],
                        "name": "B. Kao",
                        "slug": "B.-Kao",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Kao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4277180"
                        ],
                        "name": "Kevin Y. Yip",
                        "slug": "Kevin-Y.-Yip",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Yip",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Y. Yip"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826689"
                        ],
                        "name": "Wai-Shing Ho",
                        "slug": "Wai-Shing-Ho",
                        "structuredName": {
                            "firstName": "Wai-Shing",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai-Shing Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72490665"
                        ],
                        "name": "Sau-Dan Lee",
                        "slug": "Sau-Dan-Lee",
                        "structuredName": {
                            "firstName": "Sau-Dan",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sau-Dan Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1063727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e974ffb04ffd57d92b8cb47591dcc500838306cf",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional decision tree classifiers work with data whose values are known and precise. We extend such classifiers to handle data with uncertain information. Value uncertainty arises in many applications during the data collection process. Example sources of uncertainty include measurement/quantization errors, data staleness, and multiple repeated measurements. With uncertainty, the value of a data item is often represented not by one single value, but by multiple values forming a probability distribution. Rather than abstracting uncertain data by statistical derivatives (such as mean and median), we discover that the accuracy of a decision tree classifier can be much improved if the \"complete information\" of a data item (taking into account the probability density function (pdf)) is utilized. We extend classical decision tree building algorithms to handle data tuples with uncertain values. Extensive experiments have been conducted which show that the resulting classifiers are more accurate than those using value averages. Since processing pdfs is computationally more costly than processing single values (e.g., averages), decision tree construction on uncertain data is more CPU demanding than that for certain data. To tackle this problem, we propose a series of pruning techniques that can greatly improve construction efficiency."
            },
            "slug": "Decision-Trees-for-Uncertain-Data-Tsang-Kao",
            "title": {
                "fragments": [],
                "text": "Decision Trees for Uncertain Data"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work discovers that the accuracy of a decision tree classifier can be much improved if the \"complete information\" of a data item (taking into account the probability density function (pdf)) is utilized."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145434923"
                        ],
                        "name": "M. Beynon",
                        "slug": "M.-Beynon",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Beynon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Beynon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792288"
                        ],
                        "name": "D. Cosker",
                        "slug": "D.-Cosker",
                        "structuredName": {
                            "firstName": "Darren",
                            "lastName": "Cosker",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cosker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144353457"
                        ],
                        "name": "A. D. Marshall",
                        "slug": "A.-D.-Marshall",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Marshall",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. D. Marshall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 22406780,
            "fieldsOfStudy": [
                "Economics",
                "Business"
            ],
            "id": "d53b651e331ee2537d3f1bb26886826ad3d760cb",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-expert-system-for-multi-criteria-decision-making-Beynon-Cosker",
            "title": {
                "fragments": [],
                "text": "An expert system for multi-criteria decision making using Dempster Shafer theory"
            },
            "venue": {
                "fragments": [],
                "text": "Expert Syst. Appl."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768934"
                        ],
                        "name": "A. Dembo",
                        "slug": "A.-Dembo",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Dembo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dembo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115282352"
                        ],
                        "name": "Joy A. Thomas",
                        "slug": "Joy-A.-Thomas",
                        "structuredName": {
                            "firstName": "Joy",
                            "lastName": "Thomas",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joy A. Thomas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 845669,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7db0752f20b0ffe5f0b25455dd71efc000bb0b60",
            "isKey": false,
            "numCitedBy": 628,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The role of inequalities in information theory is reviewed, and the relationship of these inequalities to inequalities in other branches of mathematics is developed. The simple inequalities for differential entropy are applied to the standard multivariate normal to furnish new and simpler proofs of the major determinant inequalities in classical mathematics. The authors discuss differential entropy inequalities for random subsets of samples. These inequalities when specialized to multivariate normal variables provide the determinant inequalities that are presented. The authors focus on the entropy power inequality (including the related Brunn-Minkowski, Young's, and Fisher information inequalities) and address various uncertainty principles and their interrelations. >"
            },
            "slug": "Information-theoretic-inequalities-Dembo-Cover",
            "title": {
                "fragments": [],
                "text": "Information theoretic inequalities"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The authors focus on the entropy power inequality (including the related Brunn-Minkowski, Young's, and Fisher information inequalities) and address various uncertainty principles and their interrelations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64295966,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "b7caf811d6980627caad1a8b3053f40348693508",
            "isKey": false,
            "numCitedBy": 436,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter contains sections titled: Introduction, Fitting a Sigmoid After the SVM, Empirical Tests, Conclusions, Appendix: Pseudo-code for the Sigmoid Training"
            },
            "slug": "Probabilities-for-SV-Machines-Smola-Bartlett",
            "title": {
                "fragments": [],
                "text": "Probabilities for SV Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter contains sections titled: Introduction, Fitting a Sigmoid After the SVM, Empirical Tests, Conclusions, Appendix: Pseudo-code for the Sigmoids Training."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 224
                            }
                        ],
                        "text": "Performance on basic-level categories is still lower than what people would consider acceptable for practical applications (state-of-the-art accuracy on Caltech-256[1] is \u2248 45%, and \u2248 28% in the 2009 VOC detection challenge [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The PASCAL VOC Challenge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Without Computer Vision Comparing Different User Models S"
            },
            "venue": {
                "fragments": [],
                "text": "Without Computer Vision Comparing Different User Models S"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Results: With Computer Vision Computer Vision Reduces Manual Labor: 11.1 \uf0e06.5 questions S"
            },
            "venue": {
                "fragments": [],
                "text": "Results: With Computer Vision Computer Vision Reduces Manual Labor: 11.1 \uf0e06.5 questions S"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The PASCAL VOC Challenge Results"
            },
            "venue": {
                "fragments": [],
                "text": "The PASCAL VOC Challenge Results"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition with a vocabulary tree"
            },
            "venue": {
                "fragments": [],
                "text": "Recognition with a vocabulary tree"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Visual recognition with humans in the loop."
            },
            "venue": {
                "fragments": [],
                "text": "Computer Vision\u2013ECCV"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Results: With Computer Vision Users drive performance: 19% \uf0e0 68% Just Computer Vision 19% S"
            },
            "venue": {
                "fragments": [],
                "text": "Results: With Computer Vision Users drive performance: 19% \uf0e0 68% Just Computer Vision 19% S"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 35,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Visual-Recognition-with-Humans-in-the-Loop-Branson-Wah/cd3219fb608ea4ef5103c115e0afd308f851d89a?sort=total-citations"
}