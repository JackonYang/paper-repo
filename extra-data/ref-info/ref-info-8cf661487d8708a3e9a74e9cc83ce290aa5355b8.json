{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472759"
                        ],
                        "name": "F. Jelinek",
                        "slug": "F.-Jelinek",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Jelinek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Jelinek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696176"
                        ],
                        "name": "L. Bahl",
                        "slug": "L.-Bahl",
                        "structuredName": {
                            "firstName": "Lalit",
                            "lastName": "Bahl",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38697325,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "22b6737a38179c01444d69443e327850c9956c15",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current attempts at automatic speech recognition are formulated in an artificial intelligence framework. In this paper we approach the problem from an information-theoretic point of view. We describe the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech. The input to the decoder is a string of phonetic symbols estimated by an acoustic processor (AP). For each phonetic string, the decoder finds the most likely input sentence. The decoder consists of four major subparts: 1) a statistical model of the language being recognized; 2) a phonemic dictionary and statistical phonological rules characterizing the speaker; 3) a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP; 4) a word level search control. The details of each of the subparts and their interaction during the decoding process are discussed."
            },
            "slug": "Design-of-a-linguistic-statistical-decoder-for-the-Jelinek-Bahl",
            "title": {
                "fragments": [],
                "text": "Design of a linguistic statistical decoder for the recognition of continuous speech"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes the overall structure of a linguistic statistical decoder (LSD) for the recognition of continuous speech and describes a phonetic matching algorithm that computes the similarity between phonetic strings, using the performance characteristics of the AP."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721513"
                        ],
                        "name": "B. Lowerre",
                        "slug": "B.-Lowerre",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Lowerre",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lowerre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122355174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7eaeda28911ca9bfd59148ab518f3be1358ef0b",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the results of a comparison of two speech systems developed at Carnegie\u2010Mellon University: Hear\u2010Say\u20101 (1) and Dragon (2). Hear\u2010Say\u20101, Which consists of cooperating but independent knowledge sources, utilizes a best first search technique of the syntatic grammer. The search terminates when the evaluation of a completed proposed sentence achieves a heuristic threshold. In this way only the most likely paths are searched, thus achieving a fast though not always accurate recognition. Dragon utilizes a combined network of grammar and phonetic spellings for a generative Markov process. This allows Dragon to search all possible paths in parallel in an amount of time that is linear with utterance length. Dragon obtains a higher accuracy of recognition but with a higher computational overhead. Both systems have been tested on the same five sets of data consisting of 102 utterances and 564 words. Hear\u2010Say\u20101 correctly identifies about 60% of the words in about 5 to 30 times real time, depending on the number of wrong paths searched. Dragon correctly identifies about 85% of the words in an almost consistent 50 times real time. The types of errors produced by both systems are discussed. [(1) Written by D. R. Reddey, L. E. Erman, R. D. Fennell, and B. T. Lowerre, (2) Written by J. K. Baker.]"
            },
            "slug": "Comparison-of-two-speech-understanding-systems-Lowerre",
            "title": {
                "fragments": [],
                "text": "Comparison of two speech understanding systems"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A comparison of two speech systems developed at Carnegie\u2010Mellon University: Hear\u2010Say\u20101 and Dragon, which utilizes a best first search technique of the syntatic grammer, which obtains a higher accuracy of recognition but with a higher computational overhead."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685310"
                        ],
                        "name": "F. Itakura",
                        "slug": "F.-Itakura",
                        "structuredName": {
                            "firstName": "Fumitada",
                            "lastName": "Itakura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Itakura"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61601418,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf2b0948ec73e21f6d5a67b22a31a20d503cc9e",
            "isKey": false,
            "numCitedBy": 1242,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections. The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time."
            },
            "slug": "Minimum-prediction-residual-principle-applied-to-Itakura",
            "title": {
                "fragments": [],
                "text": "Minimum prediction residual principle applied to speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual through optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500689"
                        ],
                        "name": "A. Viterbi",
                        "slug": "A.-Viterbi",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Viterbi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Viterbi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15843983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145c0b53514b02bdc3dadfb2e1cea124f2abd99b",
            "isKey": false,
            "numCitedBy": 5209,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates above R_{0} , the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "slug": "Error-bounds-for-convolutional-codes-and-an-optimum-Viterbi",
            "title": {
                "fragments": [],
                "text": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates above R_{0} and whose performance bears certain similarities to that of sequential decoding algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39361090"
                        ],
                        "name": "L. Baum",
                        "slug": "L.-Baum",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "Baum",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baum"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60804212,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "539036ab9e8f038c8a948596e77cc0dfcfa91fb3",
            "isKey": false,
            "numCitedBy": 1785,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-inequality-and-associated-maximization-technique-Baum",
            "title": {
                "fragments": [],
                "text": "An inequality and associated maximization technique in statistical estimation of probabilistic functions of a Markov process"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 5,
        "totalPages": 1
    },
    "page_url": "https://www.semanticscholar.org/paper/Stochastic-modeling-for-automatic-speech-Baker/8cf661487d8708a3e9a74e9cc83ce290aa5355b8?sort=total-citations"
}