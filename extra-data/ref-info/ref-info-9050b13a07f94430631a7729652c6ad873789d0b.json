{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40089429"
                        ],
                        "name": "S. Abe",
                        "slug": "S.-Abe",
                        "structuredName": {
                            "firstName": "Shigeo",
                            "lastName": "Abe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1986947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ffe88503387750ad8e7c61f2653c79cd0b85266a",
            "isKey": false,
            "numCitedBy": 988,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A guide on the use of SVMs in pattern classification, including a rigorous performance comparison of classifiers and regressors. The book presents architectures for multiclass classification and function approximation problems, as well as evaluation criteria for classifiers and regressors. Features: Clarifies the characteristics of two-class SVMs; Discusses kernel methods for improving the generalization ability of neural networks and fuzzy systems; Contains ample illustrations and examples; Includes performance evaluation using publicly available data sets; Examines Mahalanobis kernels, empirical feature space, and the effect of model selection by cross-validation; Covers sparse SVMs, learning using privileged information, semi-supervised learning, multiple classifier systems, and multiple kernel learning; Explores incremental training based batch training and active-set training methods, and decomposition techniques for linear programming SVMs; Discusses variable selection for support vector regressors."
            },
            "slug": "Support-Vector-Machines-for-Pattern-Classification-Abe",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for Pattern Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This book presents architectures for multiclass classification and function approximation problems, as well as evaluation criteria for classifiers and regressors, and discusses kernel methods for improving the generalization ability of neural networks and fuzzy systems."
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708890"
                        ],
                        "name": "M. Baechler",
                        "slug": "M.-Baechler",
                        "structuredName": {
                            "firstName": "Micheal",
                            "lastName": "Baechler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baechler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "Due to a lack of public research data for historical document in layout analysis field, we have created our own ground truth data set using our model layout [1], [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [2], the authors presented an architecture of pyramidal approach using three analysis levels, evaluated on medieval manuscripts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11273655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15b14acb4501964721da3c028c927c2ff048a98e",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a generic layout analysis system for historical documents. It presents the architecture of a pyramidal approach using three analysis levels. Each level consists of a classifier using machine learning techniques where the output of the upper level is used as a feature in the lower level. The current implementation uses a so called Dynamic Multi-Layer perceptron (DMLP), which is a natural extension of MLP classifiers. The system is evaluated on medieval documents for which a multi-layer model is used to discriminate among 10 classes organized hierarchically."
            },
            "slug": "Multi-Resolution-Layout-Analysis-of-Medieval-Using-Baechler-Ingold",
            "title": {
                "fragments": [],
                "text": "Multi Resolution Layout Analysis of Medieval Manuscripts Using Dynamic MLP"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a generic layout analysis system for historical documents using three analysis levels using a so called Dynamic Multi-Layer perceptron (DMLP), which is a natural extension of MLP classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803149"
                        ],
                        "name": "A. Antonacopoulos",
                        "slug": "A.-Antonacopoulos",
                        "structuredName": {
                            "firstName": "Apostolos",
                            "lastName": "Antonacopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Antonacopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2764871"
                        ],
                        "name": "C. Clausner",
                        "slug": "C.-Clausner",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Clausner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clausner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070747525"
                        ],
                        "name": "C. Papadopoulos",
                        "slug": "C.-Papadopoulos",
                        "structuredName": {
                            "firstName": "Christos",
                            "lastName": "Papadopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Papadopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1980669"
                        ],
                        "name": "S. Pletschacher",
                        "slug": "S.-Pletschacher",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Pletschacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Pletschacher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206777025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4eacf020f7eae7673a746eccdd5819a6a1be9e85",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an objective comparative evaluation of layout analysis methods for scanned historical documents. It describes the competition (modus operandi, dataset and evaluation methodology) held in the context of ICDAR2011 and the International Workshop on Historical Document Imaging and Processing (HIP2011), presenting the results of the evaluation of four submitted methods. A commercial state-of-the-art system is also evaluated for comparison. Two scenarios are reported in this paper, one evaluating the ability of methods to accurately segment regions and the other evaluating the whole pipeline of segmentation and region classification (with a text extraction goal). The results indicate that there is a convergence to a certain methodology with some variations in the approach. However, there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical documents."
            },
            "slug": "Historical-Document-Layout-Analysis-Competition-Antonacopoulos-Clausner",
            "title": {
                "fragments": [],
                "text": "Historical Document Layout Analysis Competition"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An objective comparative evaluation of layout analysis methods for scanned historical documents shows that there is a convergence to a certain methodology with some variations in the approach, but there is still a considerable need to develop robust methods that deal with the idiosyncrasies of historical documents."
            },
            "venue": {
                "fragments": [],
                "text": "2011 International Conference on Document Analysis and Recognition"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748667"
                        ],
                        "name": "N. Journet",
                        "slug": "N.-Journet",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Journet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Journet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682986"
                        ],
                        "name": "R. Mullot",
                        "slug": "R.-Mullot",
                        "structuredName": {
                            "firstName": "R\u00e9my",
                            "lastName": "Mullot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mullot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721326"
                        ],
                        "name": "V. Eglin",
                        "slug": "V.-Eglin",
                        "structuredName": {
                            "firstName": "V\u00e9ronique",
                            "lastName": "Eglin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eglin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [4], the authors proposed a method of characterization of pictures of old documents based on a texture approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2949358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54886c9dbe0bc41062053a487da524be85cdba74",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we propose a method of characterization of pictures of old documents based on a texture approach. This characterization is carried out with the help of a multi- resolution study of the textures contained in the pictures of the document. So, by extracting five features linked to the frequencies and to the orientations in the different parts of a page, it is possible to extract and to compare elements of high semantic level without expressing any hypothesis about the physical or logical structure of the analysed documents. Experiments show the feasibility of the fulfillment of tools for the navigation or the indexation help. In these experimentations, we will lay the emphasis upon the pertinence of these texture features and the advances that they represent in terms of characterization of content of a deeply heterogeneous corpus."
            },
            "slug": "A-Proposition-of-Retrieval-Tools-for-Historical-Journet-Ramel",
            "title": {
                "fragments": [],
                "text": "A Proposition of Retrieval Tools for Historical Document Images Libraries"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "By extracting five features linked to the frequencies and to the orientations in the different parts of a page, it is possible to extract and to compare elements of high semantic level without expressing any hypothesis about the physical or logical structure of the analysed documents."
            },
            "venue": {
                "fragments": [],
                "text": "Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398902377"
                        ],
                        "name": "Laurence Likforman-Sulem",
                        "slug": "Laurence-Likforman-Sulem",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Likforman-Sulem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurence Likforman-Sulem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2320185"
                        ],
                        "name": "Abderrazak Zahour",
                        "slug": "Abderrazak-Zahour",
                        "structuredName": {
                            "firstName": "Abderrazak",
                            "lastName": "Zahour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abderrazak Zahour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080593310"
                        ],
                        "name": "B. Taconet",
                        "slug": "B.-Taconet",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Taconet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taconet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "Likforman-Sulem [3] presented a survey of existing methods of text line segmentation task for historical documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 619938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6df7d7e8050cb329ecc1dfb463cae8a7cb30727c",
            "isKey": false,
            "numCitedBy": 431,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a huge amount of historical documents in libraries and in various National Archives that have not been exploited electronically. Although automatic reading of complete pages remains, in most cases, a long-term objective, tasks such as word spotting, text/image alignment, authentication and extraction of specific fields are in use today. For all these tasks, a major step is document segmentation into text lines. Because of the low quality and the complexity of these documents (background noise, artifacts due to aging, interfering lines), automatic text line segmentation remains an open research field. The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest."
            },
            "slug": "Text-line-segmentation-of-historical-documents:-a-Likforman-Sulem-Zahour",
            "title": {
                "fragments": [],
                "text": "Text line segmentation of historical documents: a survey"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The objective of this paper is to present a survey of existing methods, developed during the last decade and dedicated to documents of historical interest."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2472298"
                        ],
                        "name": "Chih-Chung Chang",
                        "slug": "Chih-Chung-Chang",
                        "structuredName": {
                            "firstName": "Chih-Chung",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Chung Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "For the SVM classifier, we used LIBSVM Matlab interface with default parameters [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 961425,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "273dfbcb68080251f5e9ff38b4413d7bd84b10a1",
            "isKey": false,
            "numCitedBy": 40075,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail."
            },
            "slug": "LIBSVM:-A-library-for-support-vector-machines-Chang-Lin",
            "title": {
                "fragments": [],
                "text": "LIBSVM: A library for support vector machines"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail."
            },
            "venue": {
                "fragments": [],
                "text": "TIST"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697354"
                        ],
                        "name": "A. Garz",
                        "slug": "A.-Garz",
                        "structuredName": {
                            "firstName": "Angelika",
                            "lastName": "Garz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Garz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153745355"
                        ],
                        "name": "Andreas Fischer",
                        "slug": "Andreas-Fischer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706090"
                        ],
                        "name": "R. Sablatnig",
                        "slug": "R.-Sablatnig",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Sablatnig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sablatnig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "To benchmark our system we decide to use data sets employed by other researchers [10], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5252785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a4c6397962b7702f90ed73d271b1132779e5ce7",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Segmenting page images into text lines is a crucial pre-processing step for automated reading of historical documents. Challenging issues in this open research field are given \\eg by paper or parchment background noise, ink bleed-through, artifacts due to aging, stains, and touching text lines. In this paper, we present a novel binarization-free line segmentation method that is robust to noise and copes with overlapping and touching text lines. First, interest points representing parts of characters are extracted from gray-scale images. Next, word clusters are identified in high-density regions and touching components such as ascenders and descenders are separated using seam carving. Finally, text lines are generated by concatenating neighboring word clusters, where neighborhood is defined by the prevailing orientation of the words in the document. An experimental evaluation on the Latin manuscript images of the Saint Gall database shows promising results for real-world applications in terms of both accuracy and efficiency."
            },
            "slug": "Binarization-Free-Text-Line-Segmentation-for-Based-Garz-Fischer",
            "title": {
                "fragments": [],
                "text": "Binarization-Free Text Line Segmentation for Historical Documents Based on Interest Point Clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel binarization-free line segmentation method that is robust to noise and copes with overlapping and touching text lines is presented that shows promising results for real-world applications in terms of both accuracy and efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "2012 10th IAPR International Workshop on Document Analysis Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691805"
                        ],
                        "name": "Fouad Slimane",
                        "slug": "Fouad-Slimane",
                        "structuredName": {
                            "firstName": "Fouad",
                            "lastName": "Slimane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fouad Slimane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145492"
                        ],
                        "name": "S. Kanoun",
                        "slug": "S.-Kanoun",
                        "structuredName": {
                            "firstName": "Slim",
                            "lastName": "Kanoun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kanoun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722800"
                        ],
                        "name": "J. Hennebert",
                        "slug": "J.-Hennebert",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Hennebert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennebert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144000830"
                        ],
                        "name": "A. Alimi",
                        "slug": "A.-Alimi",
                        "structuredName": {
                            "firstName": "Adel",
                            "lastName": "Alimi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Alimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "As presented in Figure 2, the proposed physical structure extraction system includes two main parts (training and classification) similarly to the system presented in [14] for Arabic font recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "For more details about the use of GMMs, we refer to [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1936927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "098d5b733f6d97c305aac9831a6e563f2b7c9e7d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-study-on-font-family-and-font-size-recognition-to-Slimane-Kanoun",
            "title": {
                "fragments": [],
                "text": "A study on font-family and font-size recognition applied to Arabic word images at ultra-low resolution"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31612299"
                        ],
                        "name": "S. Leriche",
                        "slug": "S.-Leriche",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Leriche",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Leriche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070507435"
                        ],
                        "name": "M. Demonet",
                        "slug": "M.-Demonet",
                        "structuredName": {
                            "firstName": "Marie-Luce",
                            "lastName": "Demonet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Demonet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409108516"
                        ],
                        "name": "S. Busson",
                        "slug": "S.-Busson",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Busson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Busson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "AGORA [6], [7] is a software to extract meta-data of indexation from historical documents images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1779505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51a717b0d957ed5f8cc86022ce7f03d72e1cd368",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, based on the study of the specificity of historical printed books, we first explain the main error sources in classical methods used for page layout analysis. We show that each method (bottom-up and top-down) provides different types of useful information that should not be ignored, if we want to obtain both a generic method and good segmentation results. Next, we propose to use a hybrid segmentation algorithm that builds two maps: a shape map that focuses on connected components and a background map, which provides information about white areas corresponding to block separations in the page. Using this first segmentation, a classification of the extracted blocks can be achieved according to scenarios produced by the user. These scenarios are defined very simply during an interactive stage. The user is able to make processing sequences adapted to the different kinds of images he is likely to meet and according to the user needs. The proposed \u201cuser-driven approach\u201d is capable of doing segmentation and labelling of the required user high level concepts efficiently and has achieved above 93% accurate results over different data sets tested. User feedbacks and experimental results demonstrate the effectiveness and usability of our framework mainly because the extraction rules can be defined without difficulty and parameters are not sensitive to page layout variation."
            },
            "slug": "User-driven-page-layout-analysis-of-historical-Ramel-Leriche",
            "title": {
                "fragments": [],
                "text": "User-driven page layout analysis of historical printed books"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The main error sources in classical methods used for page layout analysis are explained and a hybrid segmentation algorithm is proposed that builds two maps: a shape map that focuses on connected components and a background map, which provides information about white areas corresponding to block separations in the page."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2260016"
                        ],
                        "name": "C. Looney",
                        "slug": "C.-Looney",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Looney",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Looney"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "Back-propagation algorithm is used to solve this optimization problem in our experiment [13]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61070677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6290f6c39b4db13ffb8c260de7c0209b6723073d",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Part I FUNDAMENTALS OF PATTERN RECOGNITION 0. Basic Concepts of Pattern Recognition 1. Decision Theoretic Algorithms 2. Structural Pattern Recognition Part II INTRODUCTORY NEURAL NETWORKS 3. Artificial Neural Network Structures 4. Supervised Training via Error Backpropogation: Derivations 5. Acceleration and Stabilization of Supervised Gradient Training of MLPs Part III ADVANCED FUNDAMENTALS OF NEURAL NETWORKS 6. Supervised Training via Strategic Search 7. Advances in Network Algorithms for Recognition 8. Using Hopfield Recurrent Neural Networks Part IV NEURAL, FEATURE, AND DATA ENGINEERING 9. Neural Engineering and Testing of FANNs 10. Feature and Data Engineering"
            },
            "slug": "Pattern-recognition-using-neural-networks:-theory-Looney",
            "title": {
                "fragments": [],
                "text": "Pattern recognition using neural networks: theory and algorithms for engineers and scientists"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "Part I FUNDAMENTALS of PATTERN RECOGNITION Basic Concepts of Pattern Recognition basic concepts of pattern recognition and decision Theoretic Algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153745355"
                        ],
                        "name": "Andreas Fischer",
                        "slug": "Andreas-Fischer",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052881224"
                        ],
                        "name": "Andreas Keller",
                        "slug": "Andreas-Keller",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Keller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Keller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688695"
                        ],
                        "name": "Volkmar Frinken",
                        "slug": "Volkmar-Frinken",
                        "structuredName": {
                            "firstName": "Volkmar",
                            "lastName": "Frinken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volkmar Frinken"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 28
                            }
                        ],
                        "text": "Secondly, Parzival data set [10] consists of 47 pages written by three writers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "To benchmark our system we decide to use data sets employed by other researchers [10], [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12811834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a35114204b9de8005c30d090781b0aeaac11251",
            "isKey": false,
            "numCitedBy": 272,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lexicon-free-handwritten-word-spotting-using-HMMs-Fischer-Keller",
            "title": {
                "fragments": [],
                "text": "Lexicon-free handwritten word spotting using character HMMs"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit. Lett."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705203"
                        ],
                        "name": "C. Grana",
                        "slug": "C.-Grana",
                        "structuredName": {
                            "firstName": "Costantino",
                            "lastName": "Grana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Grana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3301949"
                        ],
                        "name": "Daniele Borghesani",
                        "slug": "Daniele-Borghesani",
                        "structuredName": {
                            "firstName": "Daniele",
                            "lastName": "Borghesani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniele Borghesani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175529"
                        ],
                        "name": "S. Calderara",
                        "slug": "S.-Calderara",
                        "structuredName": {
                            "firstName": "Simone",
                            "lastName": "Calderara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Calderara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741922"
                        ],
                        "name": "R. Cucchiara",
                        "slug": "R.-Cucchiara",
                        "structuredName": {
                            "firstName": "Rita",
                            "lastName": "Cucchiara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cucchiara"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [8], the authors presented a system for automatic segmentation, annotation and image retrieval based on content, focused on illuminated manuscripts and in particular the Borso D\u2019Este Holy Bible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18105854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dac869c30fe8fd4fc04ee49f7cb88a187e7d00b0",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a system for automatic segmentation, annotation and image retrieval based on content, focused on illuminated manuscripts and in particular the Borso D'Este Holy Bible. To enhance the interaction possibilities with this work, full of decorations and illustrations, we exploit some well known document analysis techniques in addition to some new approaches, in order to achieve good segmentation of pages into meaningful visual objects with the relative annotation. We wanted to extend the standard keyword-based retrieval approach in a commentary with a modern visual-based retrieval by appearance similarity: an entire software user interface for exploration and visual search of illuminated manuscripts."
            },
            "slug": "\"Inside-the-bible\":-segmentation,-annotation-and-a-Grana-Borghesani",
            "title": {
                "fragments": [],
                "text": "\"Inside the bible\": segmentation, annotation and retrieval for a new browsing experience"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "A system for automatic segmentation, annotation and image retrieval based on content, focused on illuminated manuscripts and in particular the Borso D'Este Holy Bible, to achieve good segmentation of pages into meaningful visual objects with the relative annotation."
            },
            "venue": {
                "fragments": [],
                "text": "MIR '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689847"
                        ],
                        "name": "Jean-Yves Ramel",
                        "slug": "Jean-Yves-Ramel",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Ramel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Ramel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409108516"
                        ],
                        "name": "S. Busson",
                        "slug": "S.-Busson",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Busson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Busson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070507435"
                        ],
                        "name": "M. Demonet",
                        "slug": "M.-Demonet",
                        "structuredName": {
                            "firstName": "Marie-Luce",
                            "lastName": "Demonet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Demonet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16211698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "795459f7c47717d2af4a20ad5cd41065f2386a6e",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe how meta-data of indexation can be extracted from historical document images using an interactive process with a software called AGORA. The algorithms involved in AGORA use two maps to segment noisy images: a shape map that focuses on connected components and a background map that provides information on white areas corresponding to block separations in the page. Using a first segmentation result obtained by using these two maps, meta-data can be extracted according to scenarios produced by the users. These scenarios are defined very simply during an interactive stage. The user is able to make processing sequences adapted to the different kinds of images he is likely to meet and according to the desired meta-data. Finally, we describe different experimentations that have been done during the BVH project to test the usability and the performances of AGORA software"
            },
            "slug": "AGORA:-the-interactive-document-image-analysis-tool-Ramel-Busson",
            "title": {
                "fragments": [],
                "text": "AGORA: the interactive document image analysis tool of the BVH project"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "How meta-data of indexation can be extracted from historical document images using an interactive process with a software called AGORA and different experimentations that have been done during the BVH project to test the usability and the performances of AGorA software are described."
            },
            "venue": {
                "fragments": [],
                "text": "Second International Conference on Document Image Analysis for Libraries (DIAL'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708890"
                        ],
                        "name": "M. Baechler",
                        "slug": "M.-Baechler",
                        "structuredName": {
                            "firstName": "Micheal",
                            "lastName": "Baechler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baechler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1892337"
                        ],
                        "name": "Jean-Luc Bloechle",
                        "slug": "Jean-Luc-Bloechle",
                        "structuredName": {
                            "firstName": "Jean-Luc",
                            "lastName": "Bloechle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Luc Bloechle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680326"
                        ],
                        "name": "R. Ingold",
                        "slug": "R.-Ingold",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Ingold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ingold"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "Due to a lack of public research data for historical document in layout analysis field, we have created our own ground truth data set using our model layout [1], [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [1], the authors described a semiautomatic tool which annotates medieval manuscripts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30688261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a078becde6c6e96e86624a4807301ac3168cb49",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Medieval manuscript layouts are quite complex. They contain textual elements such as insertions, annotations, and corrections. They may be richly decorated with ornaments, illustrations, and decorative initials making their layout even more complex. In this paper we describe a semi-automatic tool which annotates medieval manuscripts using our generic format. This format allows to represent the physical structure of such manuscripts. Our semi-automatic tool is composed of two parts. The first part achieves a layout analysis which automatically segments manuscripts into text blocks and text lines. That is, a Multi-Layer Perceptron (MLP) identifies layout elements by using color features, it extracts the textual content image of the manuscript. Then, a segmentation based on Connected Component (CC) is performed on the textual content in order to retrieve text blocks and lines. The second part provides an interactive interface allowing the user to customize the automatic analysis, to visualize its results, and to correct them. Our tool is still a prototype, nevertheless, first experiments give encouraging results. Thus, in this paper, we show how to generate a ground truth for medieval manuscripts layouts."
            },
            "slug": "Semi-automatic-Annotation-Tool-for-Medieval-Baechler-Bloechle",
            "title": {
                "fragments": [],
                "text": "Semi-automatic Annotation Tool for Medieval Manuscripts"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A semi-automatic tool which annotates medieval manuscripts using the authors' generic format to represent the physical structure of such manuscripts and provides an interactive interface allowing the user to customize the automatic analysis, to visualize its results, and to correct them."
            },
            "venue": {
                "fragments": [],
                "text": "2010 12th International Conference on Frontiers in Handwriting Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145573734"
                        ],
                        "name": "F. Lebourgeois",
                        "slug": "F.-Lebourgeois",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Lebourgeois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Lebourgeois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739381"
                        ],
                        "name": "H. Emptoz",
                        "slug": "H.-Emptoz",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Emptoz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Emptoz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "DEBORA [5] is a multidisciplinary project aiming at digitizing and making rare 16th century books more accessible."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 64
                            }
                        ],
                        "text": "1520-5363/13 $26.00 \u00a9 2013 IEEE DOI 10.1109/ICDAR.2013.247\n125220\nDEBORA [5] is a multidisciplinary project aiming at digitizing and making rare 16th century books more accessible."
                    },
                    "intents": []
                }
            ],
            "corpusId": 39665022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0c5775a1d39eb85e7b82d5c1cd7dd24210f95bb",
            "isKey": true,
            "numCitedBy": 60,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "EBORA (Digital AccEss to BOoks of the RenAissance) is a multidisciplinary European project aiming at digitizing and thus making rare sixteenth century books more accessible. End-users, librarians, historians, researchers in book history and computer scientists participated in the development of remote and collaborative access to digitized Renaissance books, necessary because of the reduced accessibility to digital libraries in image mode through the Internet. The size of files for the storage of images, the lack of a standard file format exchange suitable for progressive transmission, and limited querying possibilities currently limit remote access to digital libraries. To improve accessibility, historical documents must be digitized and retro-converted to extract a detailed description of the image contents suited to users\u2019 needs. Specialists of the Renaissance have described the metadata generally required by end-users and the ideal functionalities of the digital library. The retro-conversion of historical documents is a complex process that includes image capture, metadata extraction, image storage and indexing, automatic conversion in a reusable electronic form, publication on the Internet, and data compression for faster remote access. The steps of this process cannot be developed independently. DEBORA proposes a global approach to retro-conversion from the digitization to the final functionalities of the digital library centered on users\u2019 needs. The retro-conversion process is mainly based on a document image analysis system that simultaneously extracts the metadata and compresses the images. We also propose a file format to describe compressed books as heterogeneous data (images/text/links/ annotation/physical layout and logical structure) suitable for progressive transmission, editing, and annotation. DEBORA is an exploratory project that aims at demonstrating the feasibility of the concepts by developing prototypes tested by end-users."
            },
            "slug": "DEBORA:-Digital-AccEss-to-BOoks-of-the-RenAissance-Lebourgeois-Emptoz",
            "title": {
                "fragments": [],
                "text": "DEBORA: Digital AccEss to BOoks of the RenAissance"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "DBORA proposes a global approach to retro-conversion from the digitization to the final functionalities of the digital library centered on users\u2019 needs, and proposes a file format to describe compressed books as heterogeneous data suitable for progressive transmission, editing, and annotation."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Document Analysis and Recognition (IJDAR)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "During training, the Expectation-Maximization (EM) algorithm is used to iteratively refine the component weights, means and variances to monotonically increase the likelihood of the training feature vectors [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48403,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 92
                            }
                        ],
                        "text": ", noise, to be between H1 and H2 and we use the penalty factor C to penalize this situation [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Support Vector Machines for Pattern"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 12
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 17,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Evaluation-of-SVM,-MLP-and-GMM-Classifiers-for-of-Wei-Baechler/9050b13a07f94430631a7729652c6ad873789d0b?sort=total-citations"
}