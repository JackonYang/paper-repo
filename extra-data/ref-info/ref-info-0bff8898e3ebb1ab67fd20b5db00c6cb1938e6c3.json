{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 199
                            }
                        ],
                        "text": "As for the expectations with respect to y, xk and h, it is intractable but Contrastive Divergence can also be used, much like for the expectations with respect to h, y and x1:K in the previous section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 703079,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "fe862c49248d8898b4712ba58e6bec13ea586732",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the central problems in computational neuroscience is to understand how the object-recognition pathway of the cortex learns a deep hierarchy of nonlinear feature detectors. Recent progress in machine learning shows that it is possible to learn deep hierarchies without requiring any labelled data. The feature detectors are learned one layer at a time and the goal of the learning procedure is to form a good generative model of images, not to predict the class of each image. The learning procedure only requires the pairwise correlations between the activations of neuron-like processing units in adjacent layers. The original version of the learning procedure is derived from a quadratic \u2018energy\u2019 function but it can be extended to allow third-order, multiplicative interactions in which neurons gate the pairwise interactions between other neurons. A technique for factoring the third-order interactions leads to a learning module that again has a simple learning rule based on pairwise correlations. This module looks remarkably like modules that have been proposed by both biologists trying to explain the responses of neurons and engineers trying to create systems that can recognize objects."
            },
            "slug": "Learning-to-represent-visual-input-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning to represent visual input"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This module looks remarkably like modules that have been proposed by both biologists trying to explain the responses of neurons and engineers trying to create systems that can recognize objects."
            },
            "venue": {
                "fragments": [],
                "text": "Philosophical Transactions of the Royal Society B: Biological Sciences"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3303774"
                        ],
                        "name": "L. Renninger",
                        "slug": "L.-Renninger",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Renninger",
                            "middleNames": [
                                "Walker"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Renninger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8436115"
                        ],
                        "name": "J. Coughlan",
                        "slug": "J.-Coughlan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Coughlan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Coughlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1929268"
                        ],
                        "name": "P. Verghese",
                        "slug": "P.-Verghese",
                        "structuredName": {
                            "firstName": "Preeti",
                            "lastName": "Verghese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Verghese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 667301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee4d5cd626cf1ba7dea02f4fad850acc113be12",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a sequential information maximization model as a general strategy for programming eye movements. The model reconstructs high-resolution visual information from a sequence of fixations, taking into account the fall-off in resolution from the fovea to the periphery. From this framework we get a simple rule for predicting fixation sequences: after each fixation, fixate next at the location that minimizes uncertainty (maximizes information) about the stimulus. By comparing our model performance to human eye movement data and to predictions from a saliency and random model, we demonstrate that our model is best at predicting fixation locations. Modeling additional biological constraints will improve the prediction of fixation sequences. Our results suggest that information maximization is a useful principle for programming eye movements."
            },
            "slug": "An-Information-Maximization-Model-of-Eye-Movements-Renninger-Coughlan",
            "title": {
                "fragments": [],
                "text": "An Information Maximization Model of Eye Movements"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "The model reconstructs high-resolution visual information from a sequence of fixations, taking into account the fall-off in resolution from the fovea to the periphery, and suggests that information maximization is a useful principle for programming eye movements."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "The only difference is that a sample xnegk for the k\nth glimpse only is needed, instead of for the whole sequence of glimpses, since we are conditioning on the previous glimpses x1:k\u22121."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1413690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0eb2e4a205a628ab059cab41d3b772f614ad29f2",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "To allow the hidden units of a restricted Boltzmann machine to model the transformation between two successive images, Memisevic and Hinton (2007) introduced three-way multiplicative interactions that use the intensity of a pixel in the first image as a multiplicative gain on a learned, symmetric weight between a pixel in the second image and a hidden unit. This creates cubically many parameters, which form a three-dimensional interaction tensor. We describe a low-rank approximation to this interaction tensor that uses a sum of factors, each of which is a three-way outer product. This approximation allows efficient learning of transformations between larger image patches. Since each factor can be viewed as an image filter, the model as a whole learns optimal filter pairs for efficiently representing transformations. We demonstrate the learning of optimal filter pairs from various synthetic and real image sequences. We also show how learning about image transformations allows the model to perform a simple visual analogy task, and we show how a completely unsupervised network trained on transformations perceives multiple motions of transparent dot patterns in the same way as humans."
            },
            "slug": "Learning-to-Represent-Spatial-Transformations-with-Memisevic-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning to Represent Spatial Transformations with Factored Higher-Order Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A low-rank approximation to this interaction tensor that uses a sum of factors, each of which is a three-way outer product, which allows efficient learning of transformations between larger image patches and demonstrates the learning of optimal filter pairs from various synthetic and real image sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3290098"
                        ],
                        "name": "Christopher Kanan",
                        "slug": "Christopher-Kanan",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Kanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Kanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48524582"
                        ],
                        "name": "G. Cottrell",
                        "slug": "G.-Cottrell",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Cottrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cottrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14474281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d8685fb5add2378cae7baa3506ea22d06f092a6",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification of images in many category datasbets has rapidly improved in recent years. However, systems that perform well on particular datasets typically have one or more limitations such as a failure to generalize across visual tasks (e.g., requiring a face detector or extensive retuning of parameters), insufficient translation invariance, inability to cope with partial views and occlusion, or significant performance degradation as the number of classes is increased. Here we attempt to overcome these challenges using a model that combines sequential visual attention using fixations with sparse coding. The model's biologically-inspired filters are acquired using unsupervised learning applied to natural image patches. Using only a single feature type, our approach achieves 78.5% accuracy on Caltech-101 and 75.2% on the 102 Flowers dataset when trained on 30 instances per class and it achieves 92.7% accuracy on the AR Face database with 1 training instance per person. The same features and parameters are used across these datasets to illustrate its robust performance."
            },
            "slug": "Robust-classification-of-objects,-faces,-and-using-Kanan-Cottrell",
            "title": {
                "fragments": [],
                "text": "Robust classification of objects, faces, and flowers using natural image statistics"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work uses a biologically-inspired filters model that combines sequential visual attention using fixations with sparse coding and unsupervised learning applied to natural image patches to overcome challenges in classification of images in many category datasbets."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Wei Zhang",
                        "slug": "Wei-Zhang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115234524"
                        ],
                        "name": "Hyejin Yang",
                        "slug": "Hyejin-Yang",
                        "structuredName": {
                            "firstName": "Hyejin",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyejin Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145654220"
                        ],
                        "name": "D. Samaras",
                        "slug": "D.-Samaras",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Samaras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Samaras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696991"
                        ],
                        "name": "G. Zelinsky",
                        "slug": "G.-Zelinsky",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Zelinsky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zelinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1785281,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "d0a98934162bb2be12846b5190e681be6994c0f4",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a computational model of human eye movements in an object class detection task. The model combines state-of-the-art computer vision object class detection methods (SIFT features trained using AdaBoost) with a biologically plausible model of human eye movement to produce a sequence of simulated fixations, culminating with the acquisition of a target. We validated the model by comparing its behavior to the behavior of human observers performing the identical object class detection task (looking for a teddy bear among visually complex non-target objects). We found considerable agreement between the model and human data in multiple eye movement measures, including number of fixations, cumulative probability of fixating the target, and scanpath distance."
            },
            "slug": "A-Computational-Model-of-Eye-Movements-during-Class-Zhang-Yang",
            "title": {
                "fragments": [],
                "text": "A Computational Model of Eye Movements during Object Class Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The model combines state-of-the-art computer vision object class detection methods (SIFT features trained using AdaBoost) with a biologically plausible model of human eye movement to produce a sequence of simulated fixations, culminating with the acquisition of a target."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 30
                            }
                        ],
                        "text": "Algorithm 2 Gibbs sampling in Contrastive Divergence, to obtain samples xneg1:k and y neg for the multi-fixation RBM, for the kth term of the hybrid-sequential cost Input: training pair (yt,xt1:k) % Notation: a \u223c p means a is sampled from p hneg \u223c p(h|yt,xt1:k) yneg \u223c p(y|hneg) xnegk \u223c p(xk|hneg)\nAll that is left to derive are the gradients of the energy function with respect to all parameters, which are simply:\n\u2202\n\u2202dl\u2217 E(y,x1:K ,h) = \u2212yl\u2217\n\u2202\n\u2202cj E(y,x1:K ,h) = \u2212hj\n\u2202\n\u2202bi E(y,x1:K ,h) = \u2212 K\u2211 k=1 xki \u2202\n\u2202Ujl\u2217 E(y,x1:K ,h) = \u2212hjyl\u2217\n\u2202\n\u2202Pji E(y,x1:K ,h) = \u2212hj K\u2211 k=1 z(ik, jk)i Fi\u00b7 xk\n\u2202\n\u2202Fji E(y,x1:K ,h) = \u2212h> K\u2211 k=1 P\u00b7jz(ik, jk)jxki\n\u2202\n\u2202z\u0304(ik, jk)a E(y,x1:K ,h) = \u2212(h>P\u00b7a) z(ik, jk)a (1\u2212 z(ik, jk)a) (Fa\u00b7 xk)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 259,
                                "start": 242
                            }
                        ],
                        "text": "(1)\nThe gradient with respect to any parameter \u03b8 has the following simple form:\n\u2202Chybrid \u2202\u03b8 = Eh|yt,xt1:K\n[ \u2202\n\u2202\u03b8 E(yt,xt1:K ,h) ] \u2212 Ey,h|xt1:K [ \u2202 \u2202\u03b8 E(y,xt1:K ,h) ] +\u03b1 ( Eh|yt,xt1:K [ \u2202 \u2202\u03b8 E(yt,xt1:K ,h) ] \u2212 Ey,x1:K ,h [ \u2202 \u2202\u03b8 E(y,x1:K ,h) ])\nAlgorithm 1 Gibbs sampling in Contrastive Divergence, to obtain samples xneg1:K and y neg for the multi-fixation RBM, for the hybrid cost Input: training pair (yt,xt1:K) % Notation: a \u223c p means a is sampled from p hneg \u223c p(h|yt,xt1:K) yneg \u223c p(y|hneg) for k from 1 to K do\nxnegk \u223c p(xk|hneg) end for\nThe expectations with respect to h only are tractable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 92
                            }
                        ],
                        "text": "As for the expectations with respect to y, xk and h, it is intractable but Contrastive Divergence can also be used, much like for the expectations with respect to h, y and x1:K in the previous section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Contrastive Divergence provides a good approximation however, by replacing the expectation over the input units x1:K with a point estimate at a sample xneg1:K ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 277
                            }
                        ],
                        "text": "We also replace the expectation over y by a point estimate at a sample yneg (while not necessary, it is more efficient to do so):\nEy,x1:K ,h\n[ \u2202\n\u2202\u03b8 E(y,x1:K ,h)\n] = Ey,x1:K [ Eh|y,x1:K [ \u2202\n\u2202\u03b8 E(h|y,x1:K) ]] = Eh|yneg,xneg1:K [ \u2202 \u2202\u03b8 E(yneg,xneg1:K ,h)\n] = \u2202\n\u2202\u03b8 E(yneg,xneg1:K ,h(y neg,xneg1:K))\nIn Contrastive Divergence, the samples xneg1:K and y neg are obtained by running a brief MCMC chain, initialized at the training data observation xt1:K and y t."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7778133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ac91e028cdc602695b46bd1f372c03b4d2776cf",
            "isKey": false,
            "numCitedBy": 213,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a probabilistic model for learning rich, distributed representations of image transformations. The basic model is defined as a gated conditional random field that is trained to predict transformations of its inputs using a factorial set of latent variables. Inference in the model consists in extracting the transformation, given a pair of images, and can be performed exactly and efficiently. We show that, when trained on natural videos, the model develops domain specific motion features, in the form of fields of locally transformed edge filters. When trained on affine, or more general, transformations of still images, the model develops codes for these transformations, and can subsequently perform recognition tasks that are invariant under these transformations. It can also fantasize new transformations on previously unseen images. We describe several variations of the basic model and provide experimental results that demonstrate its applicability to a variety of tasks."
            },
            "slug": "Unsupervised-Learning-of-Image-Transformations-Memisevic-Hinton",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Image Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A probabilistic model for learning rich, distributed representations of image transformations that develops domain specific motion features, in the form of fields of locally transformed edge filters, and can fantasize new transformations on previously unseen images."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7326223"
                        ],
                        "name": "L. Itti",
                        "slug": "L.-Itti",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Itti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Itti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2329233,
            "fieldsOfStudy": [
                "Psychology",
                "Biology",
                "Computer Science"
            ],
            "id": "320b36777d57e772d88d278ceeccd1f5e746304c",
            "isKey": false,
            "numCitedBy": 4166,
            "numCiting": 164,
            "paperAbstract": {
                "fragments": [],
                "text": "Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention."
            },
            "slug": "Computational-modelling-of-visual-attention-Itti-Koch",
            "title": {
                "fragments": [],
                "text": "Computational modelling of visual attention"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment, providing a framework for a computational and neurobiological understanding of visual attention."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Reviews Neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691898"
                        ],
                        "name": "Ethem Alpaydin",
                        "slug": "Ethem-Alpaydin",
                        "structuredName": {
                            "firstName": "Ethem",
                            "lastName": "Alpaydin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ethem Alpaydin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2347028,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "804ea41e75758e34afd4db9458e8aa118e5ec49b",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Completely parallel object recognition is NP-complete. Achieving a recognizer with feasible complexity requires a compromise between parallel and sequential processing where a system selectively focuses on parts of a given image, one after another. Successive fixations are generated to sample the image and these samples are processed and abstracted to generate a temporal context in which results are integrated over time. A computational model based on a partially recurrent feedforward network is proposed and made credible by testing on the real-world problem of recognition of handwritten digits with encouraging results."
            },
            "slug": "Selective-Attention-for-Handwritten-Digit-Alpaydin",
            "title": {
                "fragments": [],
                "text": "Selective Attention for Handwritten Digit Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A computational model based on a partially recurrent feedforward network is proposed and made credible by testing on the real-world problem of recognition of handwritten digits with encouraging results."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7326223"
                        ],
                        "name": "L. Itti",
                        "slug": "L.-Itti",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Itti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Itti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271571"
                        ],
                        "name": "E. Niebur",
                        "slug": "E.-Niebur",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Niebur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Niebur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3108956,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4816f0b6f0d05da3901441bfa5cc7be044b4da8b",
            "isKey": false,
            "numCitedBy": 9759,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented. Multiscale image features are combined into a single topographical saliency map. A dynamical neural network then selects attended locations in order of decreasing saliency. The system breaks down the complex problem of scene understanding by rapidly selecting, in a computationally efficient manner, conspicuous locations to be analyzed in detail."
            },
            "slug": "A-Model-of-Saliency-Based-Visual-Attention-for-Itti-Koch",
            "title": {
                "fragments": [],
                "text": "A Model of Saliency-Based Visual Attention for Rapid Scene Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A visual attention system, inspired by the behavior and the neuronal architecture of the early primate visual system, is presented, which breaks down the complex problem of scene understanding by rapidly selecting conspicuous locations to be analyzed in detail."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696991"
                        ],
                        "name": "G. Zelinsky",
                        "slug": "G.-Zelinsky",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Zelinsky",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Zelinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2848854"
                        ],
                        "name": "M. Hayhoe",
                        "slug": "M.-Hayhoe",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hayhoe",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hayhoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1200246,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "e1e5cf2d7c7758de35db4d4d5901563feab21805",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual cognition depends critically on the ability to make rapid eye movements known as saccades that orient the fovea over targets of interest in a visual scene. Saccades are known to be ballistic: the pattern of muscle activation for foveating a prespecified target location is computed prior to the movement and visual feedback is precluded. Despite these distinctive properties, there has been no general model of the saccadic targeting strategy employed by the human visual system during visual search in natural scenes. This paper proposes a model for saccadic targeting that uses iconic scene representations derived from oriented spatial filters at multiple scales. Visual search proceeds in a coarse-to-fine fashion with the largest scale filter responses being compared first. The model was empirically tested by comparing its performance with actual eye movement data from human subjects in a natural visual search task; preliminary results indicate substantial agreement between eye movements predicted by the model and those recorded from human subjects."
            },
            "slug": "Modeling-Saccadic-Targeting-in-Visual-Search-Rao-Zelinsky",
            "title": {
                "fragments": [],
                "text": "Modeling Saccadic Targeting in Visual Search"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A model for saccadic targeting that uses iconic scene representations derived from oriented spatial filters at multiple scales is proposed and preliminary results indicate substantial agreement between eye movements predicted by the model and those recorded from human subjects."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143868587"
                        ],
                        "name": "A. Oliva",
                        "slug": "A.-Oliva",
                        "structuredName": {
                            "firstName": "Aude",
                            "lastName": "Oliva",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oliva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060684"
                        ],
                        "name": "M. Castelhano",
                        "slug": "M.-Castelhano",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Castelhano",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Castelhano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144897958"
                        ],
                        "name": "J. Henderson",
                        "slug": "J.-Henderson",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Henderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5875815,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "b35e4d00d9a9bfae83a8b0914eb1073a77a11d78",
            "isKey": false,
            "numCitedBy": 1566,
            "numCiting": 144,
            "paperAbstract": {
                "fragments": [],
                "text": "Many experiments have shown that the human visual system makes extensive use of contextual information for facilitating object search in natural scenes. However, the question of how to formally model contextual influences is still open. On the basis of a Bayesian framework, the authors present an original approach of attentional guidance by global scene context. The model comprises 2 parallel pathways; one pathway computes local features (saliency) and the other computes global (scene-centered) features. The contextual guidance model of attention combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "slug": "Contextual-guidance-of-eye-movements-and-attention-Torralba-Oliva",
            "title": {
                "fragments": [],
                "text": "Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An original approach of attentional guidance by global scene context is presented that combines bottom-up saliency, scene context, and top-down mechanisms at an early stage of visual processing and predicts the image regions likely to be fixated by human observers performing natural search tasks in real-world scenes."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145273587"
                        ],
                        "name": "Stephen Gould",
                        "slug": "Stephen-Gould",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Gould",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Gould"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014378"
                        ],
                        "name": "Joakim Arfvidsson",
                        "slug": "Joakim-Arfvidsson",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Arfvidsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Arfvidsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34576226"
                        ],
                        "name": "A. Kaehler",
                        "slug": "A.-Kaehler",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Kaehler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kaehler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9133363"
                        ],
                        "name": "Benjamin Sapp",
                        "slug": "Benjamin-Sapp",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Sapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Sapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40457687"
                        ],
                        "name": "Marius Messner",
                        "slug": "Marius-Messner",
                        "structuredName": {
                            "firstName": "Marius",
                            "lastName": "Messner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marius Messner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720184"
                        ],
                        "name": "G. Bradski",
                        "slug": "G.-Bradski",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Bradski",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bradski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3128990"
                        ],
                        "name": "P. Baumstarck",
                        "slug": "P.-Baumstarck",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Baumstarck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baumstarck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3277589"
                        ],
                        "name": "Sukwon Chung",
                        "slug": "Sukwon-Chung",
                        "structuredName": {
                            "firstName": "Sukwon",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sukwon Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8738366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7e81c0e8bf7b0401fd206b03b47dc24b78b389e",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Human object recognition in a physical 3-d environment is still far superior to that of any robotic vision system. We believe that one reason (out of many) for this--one that has not heretofore been significantly exploited in the artificial vision literature--is that humans use a fovea to fixate on, or near an object, thus obtaining a very high resolution image of the object and rendering it easy to recognize. In this paper, we present a novel method for identifying and tracking objects in multiresolution digital video of partially cluttered environments. Our method is motivated by biological vision systems and uses a learned \"attentive\" interest map on a low resolution data stream to direct a high resolution \"fovea.\" Objects that are recognized in the fovea can then be tracked using peripheral vision. Because object recognition is run only on a small foveal image, our system achieves performance in real-time object recognition and tracking that is well beyond simpler systems."
            },
            "slug": "Peripheral-Foveal-Vision-for-Real-time-Object-and-Gould-Arfvidsson",
            "title": {
                "fragments": [],
                "text": "Peripheral-Foveal Vision for Real-time Object Recognition and Tracking in Video"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a novel method for identifying and tracking objects in multiresolution digital video of partially cluttered environments and uses a learned \"attentive\" interest map on a low resolution data stream to direct a high resolution \"fovea\"."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065653"
                        ],
                        "name": "L. Paletta",
                        "slug": "L.-Paletta",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Paletta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Paletta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145389879"
                        ],
                        "name": "G. Fritz",
                        "slug": "G.-Fritz",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Fritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145566115"
                        ],
                        "name": "C. Seifert",
                        "slug": "C.-Seifert",
                        "structuredName": {
                            "firstName": "Christin",
                            "lastName": "Seifert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Seifert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12365393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2b5dca2c46232a232356ca9034e35bc5b559dad",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This work provides a framework for learning sequential attention in real-world visual object recognition, using an architecture of three processing stages. The first stage rejects irrelevant local descriptors based on an information theoretic saliency measure, providing candidates for foci of interest (FOI). The second stage investigates the information in the FOI using a codebook matcher and providing weak object hypotheses. The third stage integrates local information via shifts of attention, resulting in chains of descriptor-action pairs that characterize object discrimination. A Q-learner adapts then from explorative search and evaluative feedback from entropy decreases on the attention sequences, eventually prioritizing shifts that lead to a geometry of descriptor-action scanpaths that is highly discriminative with respect to object recognition. The methodology is successfully evaluated on indoors (COIL-20 database) and outdoors (TSG-20 database) imagery, demonstrating significant impact by learning, outperforming standard local descriptor based methods both in recognition accuracy and processing time."
            },
            "slug": "Q-learning-of-sequential-attention-for-visual-from-Paletta-Fritz",
            "title": {
                "fragments": [],
                "text": "Q-learning of sequential attention for visual object recognition from informative local descriptors"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work provides a framework for learning sequential attention in real-world visual object recognition, using an architecture of three processing stages that integrates local information via shifts of attention, resulting in chains of descriptor-action pairs that characterize object discrimination."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4389958"
                        ],
                        "name": "A. Fazl",
                        "slug": "A.-Fazl",
                        "structuredName": {
                            "firstName": "Arash",
                            "lastName": "Fazl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fazl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682174"
                        ],
                        "name": "S. Grossberg",
                        "slug": "S.-Grossberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Grossberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Grossberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699553"
                        ],
                        "name": "E. Mingolla",
                        "slug": "E.-Mingolla",
                        "structuredName": {
                            "firstName": "Ennio",
                            "lastName": "Mingolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Mingolla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 297
                            }
                        ],
                        "text": "\u2026has the following gradient:\n\u2202Chybrid\u2212seq \u2202\u03b8\n= K\u2211\nk=1\n{ Eh|yt,xt1:k [ \u2202 \u2202\u03b8 E(yt,xt1:k,h) ] \u2212 Ey,h|xt1:k [ \u2202 \u2202\u03b8 E(y,xt1:k,h) ] (2)\n+\u03b1 (\nEh|yt,xt1:k\n[ \u2202\n\u2202\u03b8 E(yt,xt1:k,h)\n] \u2212 Ey,xk,h|x1:k\u22121 [ \u2202\n\u2202\u03b8 E(y,x1:k,h) ])} The expectations with respect to h only and with respect to h and y are still tractable."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5198589,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1c7cef3bb8c55f3fff527787b977af7797ba0d9a",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 211,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "View-invariant-object-category-learning,-and-How-Fazl-Grossberg",
            "title": {
                "fragments": [],
                "text": "View-invariant object category learning, recognition, and search: How spatial and object attention are coordinated using surface-based attentional shrouds"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 718390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "346fbcffe4237aa60e8bcb3d4294a8b99436f1d0",
            "isKey": false,
            "numCitedBy": 391,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The Conditional Restricted Boltzmann Machine (CRBM) is a recently proposed model for time series that has a rich, distributed hidden state and permits simple, exact inference. We present a new model, based on the CRBM that preserves its most important computational properties and includes multiplicative three-way interactions that allow the effective interaction weight between two units to be modulated by the dynamic state of a third unit. We factor the three-way weight tensor implied by the multiplicative model, reducing the number of parameters from O(N3) to O(N2). The result is an efficient, compact model whose effectiveness we demonstrate by modeling human motion. Like the CRBM, our model can capture diverse styles of motion with a single set of parameters, and the three-way interactions greatly improve the model's ability to blend motion styles or to transition smoothly among them."
            },
            "slug": "Factored-conditional-restricted-Boltzmann-Machines-Taylor-Hinton",
            "title": {
                "fragments": [],
                "text": "Factored conditional restricted Boltzmann Machines for modeling motion style"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new model is presented, based on the CRBM, that preserves its most important computational properties and includes multiplicative three-way interactions that allow the effective interaction weight between two units to be modulated by the dynamic state of a third unit."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373952"
                        ],
                        "name": "J. Louradour",
                        "slug": "J.-Louradour",
                        "structuredName": {
                            "firstName": "J\u00e9r\u00f4me",
                            "lastName": "Louradour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Louradour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 996073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05fd1da7b2e34f86ec7f010bef068717ae964332",
            "isKey": false,
            "numCitedBy": 1027,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization often appears to get stuck in poor solutions. Hinton et al. recently proposed a greedy layer-wise unsupervised learning procedure relying on the training algorithm of restricted Boltzmann machines (RBM) to initialize the parameters of a deep belief network (DBN), a generative model with many layers of hidden causal variables. This was followed by the proposal of another greedy layer-wise procedure, relying on the usage of autoassociator networks. In the context of the above optimization problem, we study these algorithms empirically to better understand their success. Our experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input. We also present a series of experiments aimed at evaluating the link between the performance of deep neural networks and practical aspects of their topology, for example, demonstrating cases where the addition of more depth helps. Finally, we empirically explore simple variants of these training algorithms, such as the use of different RBM input unit distributions, a simple way of combining gradient estimators to improve performance, as well as on-line versions of those algorithms."
            },
            "slug": "Exploring-Strategies-for-Training-Deep-Neural-Larochelle-Bengio",
            "title": {
                "fragments": [],
                "text": "Exploring Strategies for Training Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "These experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy helps the optimization by initializing weights in a region near a good local minimum, but also implicitly acts as a sort of regularization that brings better generalization and encourages internal distributed representations that are high-level abstractions of the input."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49627521"
                        ],
                        "name": "Urs K\u00f6ster",
                        "slug": "Urs-K\u00f6ster",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "K\u00f6ster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs K\u00f6ster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791548"
                        ],
                        "name": "A. Hyv\u00e4rinen",
                        "slug": "A.-Hyv\u00e4rinen",
                        "structuredName": {
                            "firstName": "Aapo",
                            "lastName": "Hyv\u00e4rinen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hyv\u00e4rinen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 30
                            }
                        ],
                        "text": "Algorithm 2 Gibbs sampling in Contrastive Divergence, to obtain samples xneg1:k and y neg for the multi-fixation RBM, for the kth term of the hybrid-sequential cost Input: training pair (yt,xt1:k) % Notation: a \u223c p means a is sampled from p hneg \u223c p(h|yt,xt1:k) yneg \u223c p(y|hneg) xnegk \u223c p(xk|hneg)\nAll that is left to derive are the gradients of the energy function with respect to all parameters, which are simply:\n\u2202\n\u2202dl\u2217 E(y,x1:K ,h) = \u2212yl\u2217\n\u2202\n\u2202cj E(y,x1:K ,h) = \u2212hj\n\u2202\n\u2202bi E(y,x1:K ,h) = \u2212 K\u2211 k=1 xki \u2202\n\u2202Ujl\u2217 E(y,x1:K ,h) = \u2212hjyl\u2217\n\u2202\n\u2202Pji E(y,x1:K ,h) = \u2212hj K\u2211 k=1 z(ik, jk)i Fi\u00b7 xk\n\u2202\n\u2202Fji E(y,x1:K ,h) = \u2212h> K\u2211 k=1 P\u00b7jz(ik, jk)jxki\n\u2202\n\u2202z\u0304(ik, jk)a E(y,x1:K ,h) = \u2212(h>P\u00b7a) z(ik, jk)a (1\u2212 z(ik, jk)a) (Fa\u00b7 xk)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 242
                            }
                        ],
                        "text": "(1)\nThe gradient with respect to any parameter \u03b8 has the following simple form:\n\u2202Chybrid \u2202\u03b8 = Eh|yt,xt1:K\n[ \u2202\n\u2202\u03b8 E(yt,xt1:K ,h) ] \u2212 Ey,h|xt1:K [ \u2202 \u2202\u03b8 E(y,xt1:K ,h) ] +\u03b1 ( Eh|yt,xt1:K [ \u2202 \u2202\u03b8 E(yt,xt1:K ,h) ] \u2212 Ey,x1:K ,h [ \u2202 \u2202\u03b8 E(y,x1:K ,h) ])\nAlgorithm 1 Gibbs sampling in Contrastive Divergence, to obtain samples xneg1:K and y neg for the multi-fixation RBM, for the hybrid cost Input: training pair (yt,xt1:K) % Notation: a \u223c p means a is sampled from p hneg \u223c p(h|yt,xt1:K) yneg \u223c p(y|hneg) for k from 1 to K do\nxnegk \u223c p(xk|hneg) end for\nThe expectations with respect to h only are tractable."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "As for the expectations with respect to y, xk and h, it is intractable but Contrastive Divergence can also be used, much like for the expectations with respect to h, y and x1:K in the previous section."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 0
                            }
                        ],
                        "text": "Contrastive Divergence provides a good approximation however, by replacing the expectation over the input units x1:K with a point estimate at a sample xneg1:K ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 277
                            }
                        ],
                        "text": "We also replace the expectation over y by a point estimate at a sample yneg (while not necessary, it is more efficient to do so):\nEy,x1:K ,h\n[ \u2202\n\u2202\u03b8 E(y,x1:K ,h)\n] = Ey,x1:K [ Eh|y,x1:K [ \u2202\n\u2202\u03b8 E(h|y,x1:K) ]] = Eh|yneg,xneg1:K [ \u2202 \u2202\u03b8 E(yneg,xneg1:K ,h)\n] = \u2202\n\u2202\u03b8 E(yneg,xneg1:K ,h(y neg,xneg1:K))\nIn Contrastive Divergence, the samples xneg1:K and y neg are obtained by running a brief MCMC chain, initialized at the training data observation xt1:K and y t."
                    },
                    "intents": []
                }
            ],
            "corpusId": 18039559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9cca5a7c3327f6075c58361d7f98188dc4f9d7c",
            "isKey": true,
            "numCitedBy": 43,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Capturing regularities in high-dimensional data is an important problem in machine learning and signal processing. Here we present a statistical model that learns a nonlinear representation from the data that reflects abstract, invariant properties of the signal without making requirements about the kind of signal that can be processed. The model has a hierarchy of two layers, with the first layer broadly corresponding to Independent Component Analysis (ICA) and a second layer to represent higher order structure. We estimate the model using the mathematical framework of Score Matching (SM), a novel method for the estimation of non-normalized statistical models. The model incorporates a squaring nonlinearity, which we propose to be suitable for forming a higher-order code of invariances. Additionally the squaring can be viewed as modelling subspaces to capture residual dependencies, which linear models cannot capture."
            },
            "slug": "A-Two-Layer-ICA-Like-Model-Estimated-by-Score-K\u00f6ster-Hyv\u00e4rinen",
            "title": {
                "fragments": [],
                "text": "A Two-Layer ICA-Like Model Estimated by Score Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A statistical model is presented that learns a nonlinear representation from the data that reflects abstract, invariant properties of the signal without making requirements about the kind of signal that can be processed."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15584821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a53da9916b87fa295837617c16ef2ca6462cafb8",
            "isKey": false,
            "numCitedBy": 808,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, many applications for Restricted Boltzmann Machines (RBMs) have been developed for a large variety of learning problems. However, RBMs are usually used as feature extractors for another learning algorithm or to provide a good initialization for deep feed-forward neural network classifiers, and are not considered as a standalone solution to classification problems. In this paper, we argue that RBMs provide a self-contained framework for deriving competitive non-linear classifiers. We present an evaluation of different learning algorithms for RBMs which aim at introducing a discriminative component to RBM training and improve their performance as classifiers. This approach is simple in that RBMs are used directly to build a classifier, rather than as a stepping stone. Finally, we demonstrate how discriminative RBMs can also be successfully employed in a semi-supervised setting."
            },
            "slug": "Classification-using-discriminative-restricted-Larochelle-Bengio",
            "title": {
                "fragments": [],
                "text": "Classification using discriminative restricted Boltzmann machines"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents an evaluation of different learning algorithms for RBMs which aim at introducing a discriminative component to RBM training and improve their performance as classifiers, and demonstrates how discriminating RBMs can also be successfully employed in a semi-supervised setting."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14805281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8012351bc5ebce4a4b3039bbbba3ce393bc3315",
            "isKey": false,
            "numCitedBy": 973,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks."
            },
            "slug": "An-empirical-evaluation-of-deep-architectures-on-of-Larochelle-Erhan",
            "title": {
                "fragments": [],
                "text": "An empirical evaluation of deep architectures on problems with many factors of variation"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "A series of experiments indicate that these models with deep architectures show promise in solving harder learning problems that exhibit many factors of variation."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4572,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": false,
            "numCitedBy": 14645,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 161
                            }
                        ],
                        "text": "For real-valued input vectors, an extension of Equation 1 can be derived to obtain a Gaussian distribution for the conditional distribution over x of Equation 3 [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14820265,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c50dca78e97e335d362d6b991ae0e1448914e9a3",
            "isKey": false,
            "numCitedBy": 283,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "http://www.sciencemag.org/cgi/content/full/313/5786/504 version of this article at: including high-resolution figures, can be found in the online Updated information and services, http://www.sciencemag.org/cgi/content/full/313/5786/504/DC1 can be found at: Supporting Online Material found at: can be related to this article A list of selected additional articles on the Science Web sites http://www.sciencemag.org/cgi/content/full/313/5786/504#related-content http://www.sciencemag.org/cgi/content/full/313/5786/504#otherarticles , 6 of which can be accessed for free: cites 8 articles This article 15 article(s) on the ISI Web of Science. cited by This article has been http://www.sciencemag.org/cgi/content/full/313/5786/504#otherarticles 4 articles hosted by HighWire Press; see: cited by This article has been http://www.sciencemag.org/about/permissions.dtl in whole or in part can be found at: this article permission to reproduce of this article or about obtaining reprints Information about obtaining"
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper presents a meta-analyses of the determinants of infectious disease in eight operation rooms of the immune system and shows clear patterns in response to antibiotics and their use in the setting of high-resolution images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100479873"
                        ],
                        "name": "H. Helmholtz",
                        "slug": "H.-Helmholtz",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Helmholtz",
                            "middleNames": [
                                "Ludwig",
                                "Ferdinand",
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Helmholtz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103272606"
                        ],
                        "name": "J. P. Southall",
                        "slug": "J.-P.-Southall",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Southall",
                            "middleNames": [
                                "P.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. P. Southall"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 53908365,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "a598ad426924c218fb3f1a16301e3d7ee9d48cb0",
            "isKey": false,
            "numCitedBy": 1659,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A composite thin film resistor is disclosed, including an electrically inert substrate upon which is deposited a nickel-chromium alloy thin film, and an overlying second thin film - which is initially deposited as metallic tantalum. In the final product the tantalum is passivated, as by thermal oxidation, so that the said film is substantially tantalum oxide throughout, except where such film underlies a pair of conductive terminal pads. The terminal pads are spaced on the substrate, so that the resistive path therebetween is defined through the nickel-chromium thin film - via the thin metallic tantalum film interfacing between the nickel-chromium film and conductive pads. The overlying tantalum oxide provides a very high degree of environmental protection with respect to the Ni-Cr film, whereby the product not only displays the desirably low TCR characteristics of Ni-Cr, but is also highly resistant to moisture and other environmental factors. The product also exhibits outstanding resistance to the adverse effects of electrolysis supported by the presence of moisture. The various films, including a gold film from which the terminal pads are derived, may be deposited upon the inert substrate by sequential sputtering during a single evacuation of a vacuum chamber. Desired resistive patterns may then be formed by photo-etching, subsequent to which oxidation of accessible portions of the tantalum film can be effected by heating in an appropriate atmosphere."
            },
            "slug": "Treatise-on-Physiological-Optics-Helmholtz-Southall",
            "title": {
                "fragments": [],
                "text": "Treatise on Physiological Optics"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "A composite thin film resistor is disclosed, including an electrically inert substrate upon which is deposited a nickel-chromium alloy thin film, and an overlying second thin film - which is initially deposited as metallic tantalum - which provides a very high degree of environmental protection with respect to the Ni-Cr film."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1962
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The toronto face database"
            },
            "venue": {
                "fragments": [],
                "text": "The toronto face database"
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 24,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-combine-foveal-glimpses-with-a-machine-Larochelle-Hinton/0bff8898e3ebb1ab67fd20b5db00c6cb1938e6c3?sort=total-citations"
}