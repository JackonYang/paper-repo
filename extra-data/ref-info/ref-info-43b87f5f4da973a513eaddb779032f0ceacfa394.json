{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144870565"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3999940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d39c8050a39326505e1f97dc75e08448214d3ab",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A hierarchical neural architecture for image interpretation is proposed, which is based on image pyramids and cellular neural networks inspired by the principles of information processing found in the visual cortex. The algorithms for this architecture are defined in terms of local interactions of processing elements and utilize horizontal as well as vertical feedback loops. The goal is to transform a given image into a sequence of representations with increasing level of abstraction and decreasing level of detail. A first application, the binarization of handwriting, has been implemented and shown to improve the acceptance rate of an automatic ZIP-code recognition system without decreasing its reliability."
            },
            "slug": "Neural-abstraction-pyramid:-a-hierarchical-image-Behnke-Rojas",
            "title": {
                "fragments": [],
                "text": "Neural abstraction pyramid: a hierarchical image understanding architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A hierarchical neural architecture for image interpretation is proposed, which is based on image pyramids and cellular neural networks inspired by the principles of information processing found in the visual cortex, and first application, the binarization of handwriting, has been implemented and shown to improve the acceptance rate of an automatic ZIP-code recognition system without decreasing its reliability."
            },
            "venue": {
                "fragments": [],
                "text": "1998 IEEE International Joint Conference on Neural Networks Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36227)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144870565"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54849581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d805e99d07e9b7d5c3e12886b10ca51e2fd50712",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The Neural Abstraction Pyramid is a hierarchical neural architecture for image interpretation based on image pyramids and cellular neural networks and inspired by the principles of information processing found in the visual cortex. In this paper we extend the model by describing a parallel mechanism of bottom-up attention control, the Activity Driven Update of processing elements. We apply this mechanism to the binarization of handwritten ZIP-codes in a real-world application. The experimental results indicate that updating only a fraction of the processing elements is sufficient for good binarization. Both speed and performance of the application were improved with the new method."
            },
            "slug": "Activity-Driven-Update-in-the-Neural-Abstraction-Behnke-Rojas",
            "title": {
                "fragments": [],
                "text": "Activity Driven Update in the Neural Abstraction Pyramid"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper extends the Neural Abstraction Pyramid model by describing a parallel mechanism of bottom-up attention control, the Activity Driven Update of processing elements, and applies it to the binarization of handwritten ZIP-codes in a real-world application."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 147618,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "d5ad1fdd277219257c38df86770c9fd68f4c74f0",
            "isKey": false,
            "numCitedBy": 2132,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been assumed that sensory neurons are adapted, through both evolutionary and developmental processes, to the statistical properties of the signals to which they are exposed. Attneave (1954)Barlow (1961) proposed that information theory could provide a link between environmental statistics and neural responses through the concept of coding efficiency. Recent developments in statistical modeling, along with powerful computational tools, have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis for both individual neurons and populations of neurons."
            },
            "slug": "Natural-image-statistics-and-neural-representation.-Simoncelli-Olshausen",
            "title": {
                "fragments": [],
                "text": "Natural image statistics and neural representation."
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "It has long been assumed that sensory neurons are adapted to the statistical properties of the signals to which they are exposed, but recent developments in statistical modeling have enabled researchers to study more sophisticated statistical models for visual images, to validate these models empirically against large sets of data, and to begin experimentally testing the efficient coding hypothesis."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403824444"
                        ],
                        "name": "M. Egmont-Petersen",
                        "slug": "M.-Egmont-Petersen",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Egmont-Petersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Egmont-Petersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4453577"
                        ],
                        "name": "D. Ridder",
                        "slug": "D.-Ridder",
                        "structuredName": {
                            "firstName": "Dick",
                            "lastName": "Ridder",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ridder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752786"
                        ],
                        "name": "H. Handels",
                        "slug": "H.-Handels",
                        "structuredName": {
                            "firstName": "Heinz",
                            "lastName": "Handels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Handels"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14050171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b7b950d14a536b3a6ab5e9a468e6f43f274cbc9",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 400,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-processing-with-neural-networks-a-review-Egmont-Petersen-Ridder",
            "title": {
                "fragments": [],
                "text": "Image processing with neural networks - a review"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34626013"
                        ],
                        "name": "R. Henkel",
                        "slug": "R.-Henkel",
                        "structuredName": {
                            "firstName": "Rolf",
                            "lastName": "Henkel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Henkel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2018215,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9e7b45421daca643ded242a13f237579831375d4",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network approach to stereovision is presented based on aliasing effects of simple disparity estimators and a fast coherence-detection scheme. Within a single network structure, a dense disparity map with an associated validation map and, additionally, the fused cyclopean view of the scene are available. The network operations are based on simple, biological plausible circuitry; the algorithm is fully parallel and non-iterative."
            },
            "slug": "A-Simple-and-Fast-Neural-Network-Approach-to-Henkel",
            "title": {
                "fragments": [],
                "text": "A Simple and Fast Neural Network Approach to Stereovision"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A neural network approach to stereovision is presented based on aliasing effects of simple disparity estimators and a fast coherence-detection scheme, which is fully parallel and non-iterative."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996960"
                        ],
                        "name": "M. Riesenhuber",
                        "slug": "M.-Riesenhuber",
                        "structuredName": {
                            "firstName": "Maximilian",
                            "lastName": "Riesenhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Riesenhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8920227,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "85abadb689897997f1e37baa7b5fc6f7d497518b",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual processing in cortex is classically modeled as a hierarchy of increasingly sophisticated representations, naturally extending the model of simple to complex cells of Hubel and Wiesel. Surprisingly, little quantitative modeling has been done to explore the biological feasibility of this class of models to explain aspects of higher-level visual processing such as object recognition. We describe a new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions. The model is based on a MAX-like operation applied to inputs to certain cortical neurons that may have a general role in cortical function."
            },
            "slug": "Hierarchical-models-of-object-recognition-in-cortex-Riesenhuber-Poggio",
            "title": {
                "fragments": [],
                "text": "Hierarchical models of object recognition in cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new hierarchical model consistent with physiological data from inferotemporal cortex that accounts for this complex visual task and makes testable predictions is described."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780935"
                        ],
                        "name": "B. Moghaddam",
                        "slug": "B.-Moghaddam",
                        "structuredName": {
                            "firstName": "Baback",
                            "lastName": "Moghaddam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Moghaddam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144994682"
                        ],
                        "name": "A. Pentland",
                        "slug": "A.-Pentland",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Pentland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pentland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 483975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b312560b79929540734067e58de46966b96130",
            "isKey": false,
            "numCitedBy": 1684,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised technique for visual learning, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition. Two types of density estimates are derived for modeling the training data: a multivariate Gaussian (for unimodal distributions) and a mixture-of-Gaussians model (for multimodal distributions). Those probability densities are then used to formulate a maximum-likelihood estimation framework for visual search and target detection for automatic object recognition and coding. Our learning technique is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects, such as hands."
            },
            "slug": "Probabilistic-Visual-Learning-for-Object-Moghaddam-Pentland",
            "title": {
                "fragments": [],
                "text": "Probabilistic Visual Learning for Object Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An unsupervised technique for visual learning is presented, which is based on density estimation in high-dimensional spaces using an eigenspace decomposition and is applied to the probabilistic visual modeling, detection, recognition, and coding of human faces and nonrigid objects."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144848684"
                        ],
                        "name": "L. Chua",
                        "slug": "L.-Chua",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Chua",
                            "middleNames": [
                                "Ong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772490"
                        ],
                        "name": "T. Roska",
                        "slug": "T.-Roska",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Roska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Roska"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 54140443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "65857121e6f15268d4bd6e3de35f697b19f9552f",
            "isKey": false,
            "numCitedBy": 996,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "A concise tutorial description of the cellular neural network (CNN) paradigm is given, along with a precise taxonomy. The CNN is defined, and the canonical equations are described. The importance of many independent input signal arrays, adaptive templates, and the multilayer capability is emphasized and motivated by examples. It is shown how simply a wave-type partial differential equation can be generated. >"
            },
            "slug": "The-CNN-paradigm-Chua-Roska",
            "title": {
                "fragments": [],
                "text": "The CNN paradigm"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A concise tutorial description of the cellular neural network (CNN) paradigm is given, along with a precise taxonomy, and it is shown how simply a wave-type partial differential equation can be generated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726997"
                        ],
                        "name": "E. Oja",
                        "slug": "E.-Oja",
                        "structuredName": {
                            "firstName": "Erkki",
                            "lastName": "Oja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Oja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16577977,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3e00dd12caea7c4dab1633a35d1da3cb2e76b420",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A simple linear neuron model with constrained Hebbian-type synaptic modification is analyzed and a new class of unconstrained learning rules is derived. It is shown that the model neuron tends to extract the principal component from a stationary input vector sequence."
            },
            "slug": "Simplified-neuron-model-as-a-principal-component-Oja",
            "title": {
                "fragments": [],
                "text": "Simplified neuron model as a principal component analyzer"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A simple linear neuron model with constrained Hebbian-type synaptic modification is analyzed and a new class of unconstrained learning rules is derived."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of mathematical biology"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40120983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d76ef8e61395a6e9c32627f1f108772d084e2e9",
            "isKey": false,
            "numCitedBy": 4156,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a neural network-based face detection system. A retinally connected neural network examines small windows of an image and decides whether each window contains a face. The system arbitrates between multiple networks to improve performance over a single network. We use a bootstrap algorithm for training the networks, which adds false detections into the training set as training progresses. This eliminates the difficult task of manually selecting non-face training examples, which must be chosen to span the entire space of non-face images. Comparisons with other state-of-the-art face detection systems are presented; our system has better performance in terms of detection and false-positive rates."
            },
            "slug": "Neural-network-based-face-detection-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Neural Network-Based Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A neural network-based face detection system that arbitrates between multiple networks to improve performance over a single network using a bootstrap algorithm, which eliminates the difficult task of manually selecting non-face training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615848"
                        ],
                        "name": "Rajesh P. N. Rao",
                        "slug": "Rajesh-P.-N.-Rao",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Rao",
                            "middleNames": [
                                "P.",
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rajesh P. N. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 221608503,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "a424ec3b8846f57b8ffdb566d272e28d5a525909",
            "isKey": false,
            "numCitedBy": 2690,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a model of visual processing in which feedback connections from a higher- to a lower- order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images."
            },
            "slug": "Predictive-coding-in-the-visual-cortex:-a-of-some-Rao-Ballard",
            "title": {
                "fragments": [],
                "text": "Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects."
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126340"
                        ],
                        "name": "S. Miyake",
                        "slug": "S.-Miyake",
                        "structuredName": {
                            "firstName": "Sei",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miyake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145214184"
                        ],
                        "name": "Takayuki Ito",
                        "slug": "Takayuki-Ito",
                        "structuredName": {
                            "firstName": "Takayuki",
                            "lastName": "Ito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takayuki Ito"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8235461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71ea46c9266f5104f79ea27fdfb4c5686677695a",
            "isKey": false,
            "numCitedBy": 755,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A recognition with a large-scale network is simulated on a PDP-11/34 minicomputer and is shown to have a great capability for visual pattern recognition. The model consists of nine layers of cells. The authors demonstrate that the model can be trained to recognize handwritten Arabic numerals even with considerable deformations in shape. A learning-with-a-teacher process is used for the reinforcement of the modifiable synapses in the new large-scale model, instead of the learning-without-a-teacher process applied to a previous model. The authors focus on the mechanism for pattern recognition rather than that for self-organization."
            },
            "slug": "Neocognitron:-A-neural-network-model-for-a-of-Fukushima-Miyake",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A neural network model for a mechanism of visual pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A recognition with a large-scale network is simulated on a PDP-11/34 minicomputer and is shown to have a great capability for visual pattern recognition and can be trained to recognize handwritten Arabic numerals even with considerable deformations in shape."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858054"
                        ],
                        "name": "P. F\u00f6ldi\u00e1k",
                        "slug": "P.-F\u00f6ldi\u00e1k",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "F\u00f6ldi\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F\u00f6ldi\u00e1k"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9855029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a137e6fd8af904620650edc750ec3aea53db2eaf",
            "isKey": false,
            "numCitedBy": 437,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "How does the brain form a useful representation of its environment? It is shown here that a layer of simple Hebbian units connected by modifiable anti-Hebbian feed-back connections can learn to code a set of patterns in such a way that statistical dependency between the elements of the representation is reduced, while information is preserved. The resulting code is sparse, which is favourable if it is to be used as input to a subsequent supervised associative layer. The operation of the network is demonstrated on two simple problems."
            },
            "slug": "Forming-sparse-representations-by-local-learning-F\u00f6ldi\u00e1k",
            "title": {
                "fragments": [],
                "text": "Forming sparse representations by local anti-Hebbian learning"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "It is shown here that a layer of simple Hebbian units connected by modifiable anti-Hebbian feed-back connections can learn to code a set of patterns in such a way that statistical dependency between the elements of the representation is reduced, while information is preserved."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575670"
                        ],
                        "name": "Owen Carmichael",
                        "slug": "Owen-Carmichael",
                        "structuredName": {
                            "firstName": "Owen",
                            "lastName": "Carmichael",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Owen Carmichael"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1414109,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "861897df39716877fb1e03a7d09a234faca076e9",
            "isKey": false,
            "numCitedBy": 1220,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a learning-based method for low-level vision problems\u2014estimating scenes from images. We generate a synthetic world of scenes and their corresponding rendered images, modeling their relationships with a Markov network. Bayesian belief propagation allows us to efficiently find a local maximum of the posterior probability for the scene, given an image. We call this approach VISTA\u2014Vision by Image/Scene TrAining.We apply VISTA to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results. To illustrate the potential breadth of the technique, we also apply it in two other problem domains, both simplified. We learn to distinguish shading from reflectance variations in a single image under particular lighting conditions. For the motion estimation problem in a \u201cblobs world\u201d, we show figure/ground discrimination, solution of the aperture problem, and filling-in arising from application of the same probabilistic machinery."
            },
            "slug": "Learning-Low-Level-Vision-Freeman-Pasztor",
            "title": {
                "fragments": [],
                "text": "Learning Low-Level Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A learning-based method for low-level vision problems\u2014estimating scenes from images with Bayesian belief propagation, applied to the \u201csuper-resolution\u201d problem (estimating high frequency details from a low-resolution image), showing good results."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858054"
                        ],
                        "name": "P. F\u00f6ldi\u00e1k",
                        "slug": "P.-F\u00f6ldi\u00e1k",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "F\u00f6ldi\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F\u00f6ldi\u00e1k"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50555333"
                        ],
                        "name": "M. Young",
                        "slug": "M.-Young",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Young",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18763154,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "552e26d425c6cd6d79e428716adcd2897ee62e0e",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A central goal in the study of cortical function is to understand how states of the environment are represented by firing patterns of cortical neurons. Electrophysiological recordings from single cells have revealed a remarkably close relationship among stimuli, neural activity, and perceptual states. The nature of this relationship and interpretations of experimental results are fiercely debated. Is sensory information represented by the activity of single, individually meaningful cells, or is it only the global activity pattern across a whole cell population that corresponds to interpretable states? There are now strong theoretical reasons and experimental evidence suggesting that the brain adopts a compromise between these extremes which is often referred to as sparse coding."
            },
            "slug": "Sparse-coding-in-the-primate-cortex-F\u00f6ldi\u00e1k-Young",
            "title": {
                "fragments": [],
                "text": "Sparse coding in the primate cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "There are now strong theoretical reasons and experimental evidence suggesting that the brain adopts a compromise between these extremes which is often referred to as sparse coding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11006356,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "279bf08d1795c6d10c0232a809341f0da2fc06ed",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the \\wake-sleep\" algorithm that allows a multilayer, unsupervised, neural network to build a hierarchy of representations of sensory input. The network has bottom-up \\recognition\" connections that are used to convert sensory input into underlying representations. Unlike most arti cial neural networks, it also has top-down \\generative\" connections that can be used to reconstruct the sensory input from the representations. In the \\wake\" phase of the learning algorithm, the network is driven by the bottom-up recognition connections and the top-down generative connections are trained to be better at reconstructing the sensory input from the representation chosen by the recognition process. In the \\sleep\" phase, the network is driven top-down by the generative connections to produce a fantasized representation and a fantasized sensory input. The recognition connections are then trained to be better at recovering the fantasized representation from the fantasized sensory input. In both phases, the synaptic learning rule is simple and local. The combined e ect of the two phases is to create representations of the sensory input that are e cient in the following sense: On average, it takes more bits to describe each sensory input vector directly than to rst describe the representation of the sensory input chosen by the recognition process and then describe the di erence between the sensory input and its reconstruction from the chosen representation."
            },
            "slug": "A-simple-algorithm-that-discovers-efficient-codes-Frey-Dayan",
            "title": {
                "fragments": [],
                "text": "A simple algorithm that discovers efficient perceptual codes"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The \\wake-sleep\" algorithm that allows a multilayer, unsupervised, neural network to build a hierarchy of representations of sensory input is described, which is driven top-down by the generative connections to produce a fantasized representation and a fantasizing sensory input."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1858054"
                        ],
                        "name": "P. F\u00f6ldi\u00e1k",
                        "slug": "P.-F\u00f6ldi\u00e1k",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "F\u00f6ldi\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. F\u00f6ldi\u00e1k"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2175819,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2da4e9984a75ffe28c5364662807996ac5bb2662",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The visual system can reliably identify objects even when the retinal image is transformed considerably by commonly occurring changes in the environment. A local learning rule is proposed, which allows a network to learn to generalize across such transformations. During the learning phase, the network is exposed to temporal sequences of patterns undergoing the transformation. An application of the algorithm is presented in which the network learns invariance to shift in retinal position. Such a principle may be involved in the development of the characteristic shift invariance property of complex cells in the primary visual cortex, and also in the development of more complicated invariance properties of neurons in higher visual areas."
            },
            "slug": "Learning-Invariance-from-Transformation-Sequences-F\u00f6ldi\u00e1k",
            "title": {
                "fragments": [],
                "text": "Learning Invariance from Transformation Sequences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An application of the algorithm is presented in which the network learns invariance to shift in retinal position, which may be involved in the development of the characteristic shift invariance property of complex cells in the primary visual cortex and also in theDevelopment of more complicated invariance properties of neurons in higher visual areas."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Comput."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807117"
                        ],
                        "name": "T. Sanger",
                        "slug": "T.-Sanger",
                        "structuredName": {
                            "firstName": "Terence",
                            "lastName": "Sanger",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sanger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10138295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "709b4bfc5198336ba5d70da987889a157f695c1e",
            "isKey": false,
            "numCitedBy": 1524,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimal-unsupervised-learning-in-a-single-layer-Sanger",
            "title": {
                "fragments": [],
                "text": "Optimal unsupervised learning in a single-layer linear feedforward neural network"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5062473"
                        ],
                        "name": "Zhaoping Li",
                        "slug": "Zhaoping-Li",
                        "structuredName": {
                            "firstName": "Zhaoping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaoping Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13411369,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "670e0c07765761cd3d5af9a27fb1b6a9cd4fa0c8",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-saliency-map-in-primary-visual-cortex-Li",
            "title": {
                "fragments": [],
                "text": "A saliency map in primary visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Cognitive Sciences"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3201018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a6e5ead8f5d2c0001a664066332c76724ff20d5",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The question of shift and size invariance in the primate visual system is discussed. After a short review of the relevant neurobiology and psychophysics, a more detailed analysis of computational models is given. The two main types of networks considered are the dynamic routing circuit model and invariant feature networks, such as the neocognitron. Some specific open questions in context of these models are raised and possible solutions discussed."
            },
            "slug": "How-Does-Our-Visual-System-Achieve-Shift-and-Size-Wiskott",
            "title": {
                "fragments": [],
                "text": "How Does Our Visual System Achieve Shift and Size Invariance"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The question of shift and size invariance in the primate visual system is discussed and a more detailed analysis of computational models is given, including the dynamic routing circuit model and invariant feature networks, such as the neocognitron."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145572884"
                        ],
                        "name": "R. Neal",
                        "slug": "R.-Neal",
                        "structuredName": {
                            "firstName": "R",
                            "lastName": "Neal",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 871473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dd01cd9c17d1491ead8c9f97597fbc61dead8ea",
            "isKey": false,
            "numCitedBy": 1001,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described. Bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representation in the layer above. In the \"wake\" phase, neurons are driven by recognition connections, and generative connections are adapted to increase the probability that they would reconstruct the correct activity vector in the layer below. In the \"sleep\" phase, neurons are driven by generative connections, and recognition connections are adapted to increase the probability that they would produce the correct activity vector in the layer above."
            },
            "slug": "The-\"wake-sleep\"-algorithm-for-unsupervised-neural-Hinton-Dayan",
            "title": {
                "fragments": [],
                "text": "The \"wake-sleep\" algorithm for unsupervised neural networks."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An unsupervised learning algorithm for a multilayer network of stochastic neurons is described, where bottom-up \"recognition\" connections convert the input into representations in successive hidden layers, and top-down \"generative\" connections reconstruct the representation in one layer from the representations in the layer above."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110711666"
                        ],
                        "name": "T. Lee",
                        "slug": "T.-Lee",
                        "structuredName": {
                            "firstName": "Tai",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sing"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117481816"
                        ],
                        "name": "D. Mumford",
                        "slug": "D.-Mumford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mumford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mumford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145783433"
                        ],
                        "name": "Richard D. Romero",
                        "slug": "Richard-D.-Romero",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Romero",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard D. Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145968660"
                        ],
                        "name": "V. Lamme",
                        "slug": "V.-Lamme",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lamme",
                            "middleNames": [
                                "A.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lamme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1832649,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d025ca821db7babdb9516fa4bc1c39e1c66a93f3",
            "isKey": false,
            "numCitedBy": 523,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-role-of-the-primary-visual-cortex-in-higher-Lee-Mumford",
            "title": {
                "fragments": [],
                "text": "The role of the primary visual cortex in higher level vision"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145338223"
                        ],
                        "name": "Fan Yang",
                        "slug": "Fan-Yang",
                        "structuredName": {
                            "firstName": "Fan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1902716"
                        ],
                        "name": "M. Paindavoine",
                        "slug": "M.-Paindavoine",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Paindavoine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Paindavoine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144319186"
                        ],
                        "name": "H. Abdi",
                        "slug": "H.-Abdi",
                        "structuredName": {
                            "firstName": "Herv\u00e9",
                            "lastName": "Abdi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abdi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2787483"
                        ],
                        "name": "J. Mit\u00e9ran",
                        "slug": "J.-Mit\u00e9ran",
                        "structuredName": {
                            "firstName": "Johel",
                            "lastName": "Mit\u00e9ran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mit\u00e9ran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3249547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53cb3d682e3d6c209dee7f8b79c8425af53e2e48",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to improve the performance of a linear auto- associator (which is a neural network model), we explore the use of several pre-processing techniques. The gist of our approach is to represent each pattern by one or several pre-processed (i.e., filtered) versions of the original pattern (plus the original pattern). First, we compare the performance of several pre-processing techniques (a plain vanilla version of the auto-associator as a control, a Sobel operator, a Canny- Deriche operator, and a multiscale Canny-Deriche operator) and a Wiener filter on a pattern completion task using a noise degraded version of faces stored. We found that the multiscale Canny-Deriche operator gives the best performance of all models. Second, we compare the performance of the multiscale Canny-Deriche operator with the control condition on a pattern completion task of noise degraded versions (with several levels of noise) of learned faces and new faces of the same or another race than the learned faces. In all cases, the multiscale Canny- Deriche operator performs significantly better than the control."
            },
            "slug": "New-image-filtering-technique-combining-a-wavelet-a-Yang-Paindavoine",
            "title": {
                "fragments": [],
                "text": "New image filtering technique combining a wavelet transform with a linear neural network: application to face recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This work explores the use of several pre-processing techniques to improve the performance of a linear auto- associator (which is a neural network model), and finds that the multiscale Canny-Deriche operator gives the best performance of all models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3098745"
                        ],
                        "name": "J. Reynolds",
                        "slug": "J.-Reynolds",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Reynolds",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Reynolds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375727"
                        ],
                        "name": "R. Desimone",
                        "slug": "R.-Desimone",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Desimone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Desimone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16716209,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "89df3279fc97e471d57b270552ea44bf204a031c",
            "isKey": false,
            "numCitedBy": 373,
            "numCiting": 658,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Role-of-Neural-Mechanisms-of-Attention-in-the-Reynolds-Desimone",
            "title": {
                "fragments": [],
                "text": "The Role of Neural Mechanisms of Attention in Solving the Binding Problem"
            },
            "venue": {
                "fragments": [],
                "text": "Neuron"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682833"
                        ],
                        "name": "H. Rowley",
                        "slug": "H.-Rowley",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Rowley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Rowley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767244"
                        ],
                        "name": "S. Baluja",
                        "slug": "S.-Baluja",
                        "structuredName": {
                            "firstName": "Shumeet",
                            "lastName": "Baluja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baluja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1619589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd1c99edbb3d22cec4adc9ba9319cfc2360e903",
            "isKey": false,
            "numCitedBy": 348,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a neural network-based face detection system. Unlike similar systems which are limited to detecting upright, frontal faces, this system detects faces at any degree of rotation in the image plane. The system employs multiple networks; a \"router\" network first processes each input window to determine its orientation and then uses this information to prepare the window for one or more \"detector\" networks. We present the training methods for both types of networks. We also perform sensitivity analysis on the networks, and present empirical results on a large test set. Finally, we present preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "slug": "Rotation-invariant-neural-network-based-face-Rowley-Baluja",
            "title": {
                "fragments": [],
                "text": "Rotation invariant neural network-based face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper presents a neural network-based face detection system, which is limited to detecting upright, frontal faces, and presents preliminary results for detecting faces rotated out of the image plane, such as profiles and semi-profiles."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 1998 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.98CB36231)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7205190"
                        ],
                        "name": "Tim Cootes",
                        "slug": "Tim-Cootes",
                        "structuredName": {
                            "firstName": "Tim",
                            "lastName": "Cootes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tim Cootes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50564384"
                        ],
                        "name": "G. Edwards",
                        "slug": "G.-Edwards",
                        "structuredName": {
                            "firstName": "Gareth",
                            "lastName": "Edwards",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Edwards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144482985"
                        ],
                        "name": "C. Taylor",
                        "slug": "C.-Taylor",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Taylor",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2230657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76b532e2cb573fdf29f3ae68dc1372f3319c93c2",
            "isKey": false,
            "numCitedBy": 3787,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors."
            },
            "slug": "Active-Appearance-Models-Cootes-Edwards",
            "title": {
                "fragments": [],
                "text": "Active Appearance Models"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new method of matching statistical models of appearance to images by learning the relationship between perturbations in the model parameters and the induced image errors is described."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5062473"
                        ],
                        "name": "Zhaoping Li",
                        "slug": "Zhaoping-Li",
                        "structuredName": {
                            "firstName": "Zhaoping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaoping Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13898359,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "719d21b40115fa386177292baf5deefa06d12e83",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent interactions in the primary visual cortex make its output a complex nonlinear transform of its input. This transform serves preattentive visual segmentation, that is, autonomously processing visual inputs to give outputs that selectively emphasize certain features for segmentation. An analytical understanding of the nonlinear dynamics of the recurrent neural circuit is essential to harness its computational power. We derive requirements on the neural architecture, components, and connection weights of a biologically plausible model of the cortex such that region segmentation, figure-ground segregation, and contour enhancement can be achieved simultaneously. In addition, we analyze the conditions governing neural oscillations, illusory contours, and the absence of visual hallucinations. Many of our analytical techniques can be applied to other recurrent networks with translation-invariant neural and connection structures."
            },
            "slug": "Computational-Design-and-Nonlinear-Dynamics-of-a-of-Li",
            "title": {
                "fragments": [],
                "text": "Computational Design and Nonlinear Dynamics of a Recurrent Network Model of the Primary Visual Cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work derives requirements on the neural architecture, components, and connection weights of a biologically plausible model of the cortex such that region segmentation, figure-ground segregation, and contour enhancement can be achieved simultaneously."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4358477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8012c4a1e2ca663f1a04e80cbb19631a00cbab27",
            "isKey": false,
            "numCitedBy": 5639,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs."
            },
            "slug": "Emergence-of-simple-cell-receptive-field-properties-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696508"
                        ],
                        "name": "C. Jutten",
                        "slug": "C.-Jutten",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Jutten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jutten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798563"
                        ],
                        "name": "J. H\u00e9rault",
                        "slug": "J.-H\u00e9rault",
                        "structuredName": {
                            "firstName": "Jeanny",
                            "lastName": "H\u00e9rault",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. H\u00e9rault"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33162734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e73081ed096c62c073b3faa1b3b80aab89998c5",
            "isKey": false,
            "numCitedBy": 2689,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Blind-separation-of-sources,-part-I:-An-adaptive-on-Jutten-H\u00e9rault",
            "title": {
                "fragments": [],
                "text": "Blind separation of sources, part I: An adaptive algorithm based on neuromimetic architecture"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206775608,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "69e68bfaadf2dccff800158749f5a50fe82d173b",
            "isKey": false,
            "numCitedBy": 3718,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \u201cneocognitron\u201d. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \u201cS-cells\u201d, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \u201cC-cells\u201d similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \u201cteacher\u201d during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern."
            },
            "slug": "Neocognitron:-A-self-organizing-neural-network-for-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network model for a mechanism of visual pattern recognition that is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity of their shapes without affected by their positions."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3194361"
                        ],
                        "name": "S. Geman",
                        "slug": "S.-Geman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Geman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Geman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2246319"
                        ],
                        "name": "E. Bienenstock",
                        "slug": "E.-Bienenstock",
                        "structuredName": {
                            "firstName": "Elie",
                            "lastName": "Bienenstock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bienenstock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2330895"
                        ],
                        "name": "R. Doursat",
                        "slug": "R.-Doursat",
                        "structuredName": {
                            "firstName": "Ren\u00e9",
                            "lastName": "Doursat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Doursat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14215320,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "a34e35dbbc6911fa7b94894dffdc0076a261b6f0",
            "isKey": false,
            "numCitedBy": 3532,
            "numCiting": 151,
            "paperAbstract": {
                "fragments": [],
                "text": "Feedforward neural networks trained by error backpropagation are examples of nonparametric regression estimators. We present a tutorial on nonparametric inference and its relation to neural networks, and we use the statistical viewpoint to highlight strengths and weaknesses of neural models. We illustrate the main points with some recognition experiments involving artificial data as well as handwritten numerals. In way of conclusion, we suggest that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues. Furthermore, we suggest that the fundamental challenges in neural modeling are about representation rather than learning per se. This last point is supported by additional experiments with handwritten numerals."
            },
            "slug": "Neural-Networks-and-the-Bias/Variance-Dilemma-Geman-Bienenstock",
            "title": {
                "fragments": [],
                "text": "Neural Networks and the Bias/Variance Dilemma"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is suggested that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1847175"
                        ],
                        "name": "M. Minsky",
                        "slug": "M.-Minsky",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Minsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Minsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2434678"
                        ],
                        "name": "S. Papert",
                        "slug": "S.-Papert",
                        "structuredName": {
                            "firstName": "Seymour",
                            "lastName": "Papert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Papert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5400596,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f74ded11f72099d16591a1191d72262ae6b5f14a",
            "isKey": false,
            "numCitedBy": 3040,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Cambridge, Mass.: MIT Press, 1972. 2nd. ed. The book's aim is to seek general results from the close study of abstract version of devices known as perceptrons"
            },
            "slug": "Perceptrons-an-introduction-to-computational-Minsky-Papert",
            "title": {
                "fragments": [],
                "text": "Perceptrons - an introduction to computational geometry"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The aim of this book is to seek general results from the close study of abstract version of devices known as perceptrons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718494"
                        ],
                        "name": "H. Neumann",
                        "slug": "H.-Neumann",
                        "structuredName": {
                            "firstName": "Heiko",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neumann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2828372"
                        ],
                        "name": "Wolfgang Sepp",
                        "slug": "Wolfgang-Sepp",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Sepp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Sepp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12263168,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c8ac4fc37309d88babee9997b8e02c2155f0a03c",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. A majority of cortical areas are connected via feedforward and feedback fiber projections. In feedforward pathways we mainly observe stages of feature detection and integration. The computational role of the descending pathways at different stages of processing remains mainly unknown. Based on empirical findings we suggest that the top-down feedback pathways subserve a context-dependent gain control mechanism. We propose a new computational model for recurrent contour processing in which normalized activities of orientation selective contrast cells are fed forward to the next processing stage. There, the arrangement of input activation is matched against local patterns of contour shape. The resulting activities are subsequently fed back to the previous stage to locally enhance those initial measurements that are consistent with the top-down generated responses. In all, we suggest a computational theory for recurrent processing in the visual cortex in which the significance of local measurements is evaluated on the basis of a broader visual context that is represented in terms of contour code patterns. The model serves as a framework to link physiological with perceptual data gathered in psychophysical experiments. It handles a variety of perceptual phenomena, such as the local grouping of fragmented shape outline, texture surround and density effects, and the interpolation of illusory contours."
            },
            "slug": "Recurrent-V1\u2013V2-interaction-in-early-visual-Neumann-Sepp",
            "title": {
                "fragments": [],
                "text": "Recurrent V1\u2013V2 interaction in early visual boundary processing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a new computational model for recurrent contour processing in the visual cortex in which normalized activities of orientation selective contrast cells are fed forward to the next processing stage and the significance of local measurements is evaluated on the basis of a broader visual context represented in terms of contour code patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51083130"
                        ],
                        "name": "F. Rosenblatt",
                        "slug": "F.-Rosenblatt",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Rosenblatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Rosenblatt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12781225,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "5d11aad09f65431b5d3cb1d85328743c9e53ba96",
            "isKey": false,
            "numCitedBy": 9074,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The first of these questions is in the province of sensory physiology, and is the only one for which appreciable understanding has been achieved. This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory. With regard to the second question, two alternative positions have been maintained. The first suggests that storage of sensory information is in the form of coded representations or images, with some sort of one-to-one mapping between the sensory stimulus"
            },
            "slug": "The-perceptron:-a-probabilistic-model-for-storage-Rosenblatt",
            "title": {
                "fragments": [],
                "text": "The perceptron: a probabilistic model for information storage and organization in the brain."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory."
            },
            "venue": {
                "fragments": [],
                "text": "Psychological review"
            },
            "year": 1958
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1917981"
                        ],
                        "name": "H. Sup\u00e8r",
                        "slug": "H.-Sup\u00e8r",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Sup\u00e8r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sup\u00e8r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142051"
                        ],
                        "name": "H. Spekreijse",
                        "slug": "H.-Spekreijse",
                        "structuredName": {
                            "firstName": "Henk",
                            "lastName": "Spekreijse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Spekreijse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145968660"
                        ],
                        "name": "V. Lamme",
                        "slug": "V.-Lamme",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lamme",
                            "middleNames": [
                                "A.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lamme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15130302,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "8e0df7d244b80c5e81e2b9d90b82c5596bc2386f",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Even salient sensory stimuli are sometimes not detected. What goes wrong in the brain in that case? Here we show that a late (> 100-ms) component of the neural activity in the primary visual cortex of the monkey is selectively suppressed when stimuli are not seen. As there is evidence that this activity depends on feedback from extrastriate areas, these findings suggest a specific role for recurrent processing when stimuli are reaching a perceptual level. Further results show that this perceptual level is situated between purely sensory and decision or motor stages of processing."
            },
            "slug": "Two-distinct-modes-of-sensory-processing-observed-Sup\u00e8r-Spekreijse",
            "title": {
                "fragments": [],
                "text": "Two distinct modes of sensory processing observed in monkey primary visual cortex (V1)"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "It is shown that a late (> 100-ms) component of the neural activity in the primary visual cortex of the monkey is selectively suppressed when stimuli are not seen, suggesting a specific role for recurrent processing when stimulus levels are reaching a perceptual level."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 568745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d62bcde418144411068d5b09952090962fbc05f6",
            "isKey": false,
            "numCitedBy": 1397,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised learning studies how systems can learn to represent particular input patterns in a way that reflects the statistical structure of the overall collection of input patterns. By contrast with SUPERVISED LEARNING or REINFORCEMENT LEARNING, there are no explicit target outputs or environmental evaluations associated with each input; rather the unsupervised learner brings to bear prior biases as to what aspects of the structure of the input should be captured in the output."
            },
            "slug": "Unsupervised-Learning-Hinton-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Unsupervised learning studies how systems can learn to represent particular input patterns in a way that reflects the statistical structure of the overall collection of input patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Machine Learning and Data Mining"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205001834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "isKey": false,
            "numCitedBy": 20332,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1."
            },
            "slug": "Learning-representations-by-back-propagating-errors-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning representations by back-propagating errors"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Back-propagation repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector, which helps to represent important features of the task domain."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38817267"
                        ],
                        "name": "K. Sung",
                        "slug": "K.-Sung",
                        "structuredName": {
                            "firstName": "Kah",
                            "lastName": "Sung",
                            "middleNames": [
                                "Kay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7164794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088eb2d102c6bb486f5270d0b2adff76961994cf",
            "isKey": false,
            "numCitedBy": 2061,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an example-based learning approach for locating vertical frontal views of human faces in complex scenes. The technique models the distribution of human face patterns by means of a few view-based \"face\" and \"nonface\" model clusters. At each image location, a difference feature vector is computed between the local image pattern and the distribution-based model. A trained classifier determines, based on the difference feature vector measurements, whether or not a human face exists at the current image location. We show empirically that the distance metric we adopt for computing difference feature vectors, and the \"nonface\" clusters we include in our distribution-based model, are both critical for the success of our system."
            },
            "slug": "Example-Based-Learning-for-View-Based-Human-Face-Sung-Poggio",
            "title": {
                "fragments": [],
                "text": "Example-Based Learning for View-Based Human Face Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An example-based learning approach for locating vertical frontal views of human faces in complex scenes and shows empirically that the distance metric adopted for computing difference feature vectors, and the \"nonface\" clusters included in the distribution-based model, are both critical for the success of the system."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6097411"
                        ],
                        "name": "J. Bullier",
                        "slug": "J.-Bullier",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bullier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bullier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11405177,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "ea7a25474a0548bc44d5490897f99c6ce90abff7",
            "isKey": false,
            "numCitedBy": 160,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feedback-connections-and-conscious-vision-Bullier",
            "title": {
                "fragments": [],
                "text": "Feedback connections and conscious vision"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Cognitive Sciences"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2901266"
                        ],
                        "name": "R. Eckhorn",
                        "slug": "R.-Eckhorn",
                        "structuredName": {
                            "firstName": "Reinhard",
                            "lastName": "Eckhorn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eckhorn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145911776"
                        ],
                        "name": "R. Bauer",
                        "slug": "R.-Bauer",
                        "structuredName": {
                            "firstName": "Roman",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053596632"
                        ],
                        "name": "W. Jordan",
                        "slug": "W.-Jordan",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Jordan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095985"
                        ],
                        "name": "M. Brosch",
                        "slug": "M.-Brosch",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brosch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brosch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072064608"
                        ],
                        "name": "W. Kruse",
                        "slug": "W.-Kruse",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Kruse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kruse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32569969"
                        ],
                        "name": "M. Munk",
                        "slug": "M.-Munk",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Munk",
                            "middleNames": [
                                "H.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Munk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2270000"
                        ],
                        "name": "H. Reitboeck",
                        "slug": "H.-Reitboeck",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Reitboeck",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Reitboeck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206771651,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "903b17f8d3652273d39d65f32fae3e101dcddeae",
            "isKey": false,
            "numCitedBy": 1112,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Primary visual coding can be characterized by the receptive field (RF) properties of single neurons. Subject of this paper is our search for a global,second coding step beyond the RF-concept that links related features in a visual scene. In recent models of visual coding, oscillatory activities have been proposed to constitute such linking signals. We tested the neurophysiological relevance of this hypothesis for the visual system. Single and multiple spikes as well as local field potentials were recorded simultaneously from several locations in the primary visual cortex (A17 and A18) using 7 or 19 individually advanceable fibermicroelectrodes (250 or 330 \u03bcm apart).Stimulusevoked (SE)-resonances of 35\u201385 Hz were found in these three types of signals throughout the visual cortex when the primary coding channels were activated by their specific stimuli. Stimulus position, orientation, movement direction and velocity, ocularity and stationary flicker caused specific SE-resonances.Coherent SE-resonances were found at distant cortical positions when at least one of the primary coding properties was similar. Coherence was found1) within a vertical cortex column,2) between neighbouring hypercolumns, and3) between two different cortical areas. We assume that the coherence of SE-resonances is mediated by recurrent excitatory intra- and inter-areal connections via phase locking between assemblies that represent the linking features of the actual visual scene. Visually related activities are, thus, transiently labelled by a temporal code that signalizes their momentary association."
            },
            "slug": "Coherent-oscillations:-A-mechanism-of-feature-in-Eckhorn-Bauer",
            "title": {
                "fragments": [],
                "text": "Coherent oscillations: A mechanism of feature linking in the visual cortex?"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work assumes that the coherence of SE-resonances is mediated by recurrent excitatory intra- and inter-areal connections via phase locking between assemblies that represent the linking features of the actual visual scene."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31772450"
                        ],
                        "name": "N. Logothetis",
                        "slug": "N.-Logothetis",
                        "structuredName": {
                            "firstName": "Nikos",
                            "lastName": "Logothetis",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Logothetis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144320332"
                        ],
                        "name": "J. Pauls",
                        "slug": "J.-Pauls",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Pauls",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pauls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15325604,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7d7721e2c556e02f35654428953ed83cfa8adff8",
            "isKey": false,
            "numCitedBy": 989,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Shape-representation-in-the-inferior-temporal-of-Logothetis-Pauls",
            "title": {
                "fragments": [],
                "text": "Shape representation in the inferior temporal cortex of monkeys"
            },
            "venue": {
                "fragments": [],
                "text": "Current Biology"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712899"
                        ],
                        "name": "W. Singer",
                        "slug": "W.-Singer",
                        "structuredName": {
                            "firstName": "Wolf",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941291"
                        ],
                        "name": "C. Gray",
                        "slug": "C.-Gray",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13493427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c90c3c10cba3c4700298ab2883c2bfecd7401fae",
            "isKey": false,
            "numCitedBy": 3217,
            "numCiting": 139,
            "paperAbstract": {
                "fragments": [],
                "text": "The mammalian visual system is endowed with a nearly infinite capacity for the recognition of patterns and objects. To have acquired this capability the visual system must have solved what is a fundamentally combinatorial prob\u00ad lem. Any given image consists of a collection of features, consisting of local contrast borders of luminance and wavelength, distributed across the visual field. For one to detect and recognize an object within a scene, the features comprising the object must be identified and segregated from those comprising other objects. This problem is inherently difficult to solve because of the combinatorial nature of visual images. To appreciate this point, consider a simple local feature such as a small vertically oriented line segment placed within a fixed location of the visual field. When combined with other line segments, this feature can form a nearly infinite number of geometrical objects. Any one of these objects may coexist with an equally large number of other"
            },
            "slug": "Visual-feature-integration-and-the-temporal-Singer-Gray",
            "title": {
                "fragments": [],
                "text": "Visual feature integration and the temporal correlation hypothesis."
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The mammalian visual system is endowed with a nearly infinite capacity for the recognition of patterns and objects, but to have acquired this capability the visual system must have solved what is a fundamentally combinatorial prob\u00ad lem."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of neuroscience"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686506"
                        ],
                        "name": "A. Atiya",
                        "slug": "A.-Atiya",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Atiya",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Atiya"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7406938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ff61b8e097ccdb784a35b466ba9e130c2502513",
            "isKey": false,
            "numCitedBy": 5533,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Chapters 2\u20137 make up Part II of the book: artificial neural networks. After introducing the basic concepts of neurons and artificial neuron learning rules in Chapter 2, Chapter 3 describes a particular formalism, based on signal-plus-noise, for the learning problem in general. After presenting the basic neural network types this chapter reviews the principal algorithms for error function minimization/optimization and shows how these learning issues are addressed in various supervised models. Chapter 4 deals with issues in unsupervised learning networks, such as the Hebbian learning rule, principal component learning, and learning vector quantization. Various techniques and learning paradigms are covered in Chapters 3\u20136, and especially the properties and relative merits of the multilayer perceptron networks, radial basis function networks, self-organizing feature maps and reinforcement learning are discussed in the respective four chapters. Chapter 7 presents an in-depth examination of performance issues in supervised learning, such as accuracy, complexity, convergence, weight initialization, architecture selection, and active learning. Par III (Chapters 8\u201315) offers an extensive presentation of techniques and issues in evolutionary computing. Besides the introduction to the basic concepts in evolutionary computing, it elaborates on the more important and most frequently used techniques on evolutionary computing paradigm, such as genetic algorithms, genetic programming, evolutionary programming, evolutionary strategies, differential evolution, cultural evolution, and co-evolution, including design aspects, representation, operators and performance issues of each paradigm. The differences between evolutionary computing and classical optimization are also explained. Part IV (Chapters 16 and 17) introduces swarm intelligence. It provides a representative selection of recent literature on swarm intelligence in a coherent and readable form. It illustrates the similarities and differences between swarm optimization and evolutionary computing. Both particle swarm optimization and ant colonies optimization are discussed in the two chapters, which serve as a guide to bringing together existing work to enlighten the readers, and to lay a foundation for any further studies. Part V (Chapters 18\u201321) presents fuzzy systems, with topics ranging from fuzzy sets, fuzzy inference systems, fuzzy controllers, to rough sets. The basic terminology, underlying motivation and key mathematical models used in the field are covered to illustrate how these mathematical tools can be used to handle vagueness and uncertainty. This book is clearly written and it brings together the latest concepts in computational intelligence in a friendly and complete format for undergraduate/postgraduate students as well as professionals new to the field. With about 250 pages covering such a wide variety of topics, it would be impossible to handle everything at a great length. Nonetheless, this book is an excellent choice for readers who wish to familiarize themselves with computational intelligence techniques or for an overview/introductory course in the field of computational intelligence. Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond\u2014Bernhard Sch\u00f6lkopf and Alexander Smola, (MIT Press, Cambridge, MA, 2002, ISBN 0-262-19475-9). Reviewed by Amir F. Atiya."
            },
            "slug": "Learning-with-Kernels:-Support-Vector-Machines,-and-Atiya",
            "title": {
                "fragments": [],
                "text": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This book is an excellent choice for readers who wish to familiarize themselves with computational intelligence techniques or for an overview/introductory course in the field of computational intelligence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8439071,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b20ad513361a26e98289e5a517291c6ff49960d",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "One approach to invariant object recognition employs a recurrent neural network as an associative memory. In the standard depiction of the network's state space, memories of objects are stored as attractive fixed points of the dynamics. I argue for a modification of this picture: if an object has a continuous family of instantiations, it should be represented by a continuous attractor. This idea is illustrated with a network that learns to complete patterns. To perform the task of filling in missing information, the network develops a continuous attractor that models the manifold from which the patterns are drawn. From a statistical view-point, the pattern completion task allows a formulation of unsupervised learning in terms of regression rather than density estimation."
            },
            "slug": "Learning-Continuous-Attractors-in-Recurrent-Seung",
            "title": {
                "fragments": [],
                "text": "Learning Continuous Attractors in Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "If an object has a continuous family of instantiations, it should be represented by a continuous attractor, and this idea is illustrated with a network that learns to complete patterns."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747779"
                        ],
                        "name": "Aaron Hertzmann",
                        "slug": "Aaron-Hertzmann",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Hertzmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Hertzmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10251113"
                        ],
                        "name": "C. Jacobs",
                        "slug": "C.-Jacobs",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Jacobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060131244"
                        ],
                        "name": "Nuria Oliver",
                        "slug": "Nuria-Oliver",
                        "structuredName": {
                            "firstName": "Nuria",
                            "lastName": "Oliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nuria Oliver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143800609"
                        ],
                        "name": "B. Curless",
                        "slug": "B.-Curless",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Curless",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Curless"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745260"
                        ],
                        "name": "D. Salesin",
                        "slug": "D.-Salesin",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Salesin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Salesin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2201072,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "923562d216386a88947d40da310d94bbb1376a41",
            "isKey": false,
            "numCitedBy": 1640,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies.\u201d The framework involves two stages: a design phase, in which a pair of images, with one image purported to be a \u201cfiltered\u201d version of the other, is presented as \u201ctraining data\u201d; and an application phase, in which the learned filter is applied to some new target image in order to create an \u201canalogous\u201d filtered result. Image analogies are based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis. By choosing different types of source image pairs as input, the framework supports a wide variety of \u201cimage filter\u201d effects, including traditional image filters, such as blurring or embossing; improved texture synthesis, in which some textures are synthesized with higher quality than by previous approaches; super-resolution, in which a higher-resolution image is inferred from a low-resolution source; texture transfer, in which images are \u201ctexturized\u201d with some arbitrary source texture; artistic filters, in which various drawing and painting styles are synthesized based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface."
            },
            "slug": "Image-analogies-Hertzmann-Jacobs",
            "title": {
                "fragments": [],
                "text": "Image analogies"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper describes a new framework for processing images by example, called \u201cimage analogies,\u201d based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115651440"
                        ],
                        "name": "Daniel D. Lee",
                        "slug": "Daniel-D.-Lee",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4428232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29bae9472203546847ec1352a604566d0f602728",
            "isKey": false,
            "numCitedBy": 11312,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Is perception of the whole based on perception of its parts? There is psychological and physiological evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign."
            },
            "slug": "Learning-the-parts-of-objects-by-non-negative-Lee-Seung",
            "title": {
                "fragments": [],
                "text": "Learning the parts of objects by non-negative matrix factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for non-negative matrix factorization is demonstrated that is able to learn parts of faces and semantic features of text and is in contrast to other methods that learn holistic, not parts-based, representations."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48347666"
                        ],
                        "name": "M. Stemmler",
                        "slug": "M.-Stemmler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Stemmler",
                            "middleNames": [
                                "B"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stemmler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14438840"
                        ],
                        "name": "M. Usher",
                        "slug": "M.-Usher",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Usher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Usher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271571"
                        ],
                        "name": "E. Niebur",
                        "slug": "E.-Niebur",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Niebur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Niebur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35810659,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "e5b73845d02b6abd82f3fa851f9bda38331d3313",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent physiological studies show that the spatial context of visual stimuli enhances the response of cells in primary visual cortex to weak stimuli and suppresses the response to strong stimuli. A model of orientation-tuned neurons was constructed to explore the role of lateral cortical connections in this dual effect. The differential effect of excitatory and inhibitory current and noise conveyed by the lateral connections explains the physiological results as well as the psychophysics of pop-out and contour completion. Exploiting the model's property of stochastic resonance, the visual context changes the model's intrinsic input variability to enhance the detection of weak signals."
            },
            "slug": "Lateral-interactions-in-primary-visual-cortex:-a-Stemmler-Usher",
            "title": {
                "fragments": [],
                "text": "Lateral interactions in primary visual cortex: a model bridging physiology and psychophysics."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model of orientation-tuned neurons was constructed to explore the role of lateral cortical connections in this dual effect of excitatory and inhibitory current and noise conveyed by the lateral connections, and the visual context changes the model's intrinsic input variability to enhance the detection of weak signals."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47302800"
                        ],
                        "name": "R. Raizada",
                        "slug": "R.-Raizada",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Raizada",
                            "middleNames": [
                                "D.",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raizada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682174"
                        ],
                        "name": "S. Grossberg",
                        "slug": "S.-Grossberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Grossberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Grossberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14919559,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "0e62b4f98c373a22d2c47697c3b7b9a97cbf8c2b",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 194,
            "paperAbstract": {
                "fragments": [],
                "text": "A detailed neural model is presented of how the laminar circuits of visual cortical areas V1 and V2 implement context-sensitive binding processes such as perceptual grouping and attention. The model proposes how specific laminar circuits allow the responses of visual cortical neurons to be determined not only by the stimuli within their classical receptive fields, but also to be strongly influenced by stimuli in the extra-classical surround. This context-sensitive visual processing can greatly enhance the analysis of visual scenes, especially those containing targets that are low contrast, partially occluded, or crowded by distractors. We show how interactions of feedforward, feedback, and horizontal circuitry can implement several types of contextual processing simultaneously, using shared laminar circuits. In particular, we present computer simulations that suggest how top-down attention and preattentive perceptual grouping, two processes that are fundamental for visual binding, can interact, with attentional enhancement selectively propagating along groupings of both real and illusory contours, thereby showing how attention can selectively enhance object representations. These simulations also illustrate how attention may have a stronger facilitatory effect on low contrast than on high contrast stimuli, and how pop-out from orientation contrast may occur. The specific functional roles which the model proposes for the cortical layers allow several testable neurophysiological predictions to be made. The results presented here simulate only the boundary grouping system of adult cortical architecture. However, we also discuss how this model contributes to a larger neural theory of vision that suggests how intracortical and intercortical feedback help to stabilize development and learning within these cortical circuits. Although feedback plays a key role, fast feedforward processing is possible in response to unambiguous information. Model circuits are capable of synchronizing quickly, but context-sensitive persistence of previous events can influence how synchrony develops. Although these results focus on how the interblob cortical processing stream controls boundary grouping and attention, related modelling of the blob cortical processing stream suggests how visible surfaces are formed, and modelling of the motion stream suggests how transient responses to scenic changes can control long-range apparent motion and also attract spatial attention."
            },
            "slug": "Context-sensitive-binding-by-the-laminar-circuits-A-Raizada-Grossberg",
            "title": {
                "fragments": [],
                "text": "Context-sensitive binding by the laminar circuits of V1 and V2: A unified model of perceptual grouping, attention, and orientation contrast"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Computer simulations are presented that suggest how top-down attention and preattentive perceptual grouping can interact, with attentional enhancement selectively propagating along groupings of both real and illusory contours, thereby showing how attention can selectively enhance object representations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18100780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bb4bad84a2fd896edfa4f5c22061b2913fec500d",
            "isKey": false,
            "numCitedBy": 1446,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-discovery-by-competitive-learning-Rumelhart-Zipser",
            "title": {
                "fragments": [],
                "text": "Feature discovery by competitive learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682174"
                        ],
                        "name": "S. Grossberg",
                        "slug": "S.-Grossberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Grossberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Grossberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13642660,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "023569c79293e0ba6a3c2dbdda14891152cceda2",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "The organization of neocortex into layers is one of its most salient anatomical features. These layers include circuits that form functional columns in cortical maps. A major unsolved problem concerns how bottom-up, top-down, and horizontal interactions are organized within cortical layers to generate adaptive behaviors. This article models how these interactions help visual cortex to realize: (i) the binding process whereby cortex groups distributed data into coherent object representations; (ii) the attentional process whereby cortex selectively processes important events; and (iii) the developmental and learning processes whereby cortex shapes its circuits to match environmental constraints. New computational ideas about feedback systems suggest how neocortex develops and learns in a stable way, and why top-down attention requires converging bottom-up inputs to fully activate cortical cells, whereas perceptual groupings do not."
            },
            "slug": "How-does-the-cerebral-cortex-work-Learning,-and-by-Grossberg",
            "title": {
                "fragments": [],
                "text": "How does the cerebral cortex work? Learning, attention, and grouping by the laminar circuits of visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "New computational ideas about feedback systems suggest how neocortex develops and learns in a stable way, and why top-down attention requires converging bottom-up inputs to fully activate cortical cells, whereas perceptual groupings do not."
            },
            "venue": {
                "fragments": [],
                "text": "Spatial vision"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736245"
                        ],
                        "name": "Laurenz Wiskott",
                        "slug": "Laurenz-Wiskott",
                        "structuredName": {
                            "firstName": "Laurenz",
                            "lastName": "Wiskott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurenz Wiskott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12366835,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5127759530ce213f488af2859190697770f557f3",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Invariant features of temporally varying signals are useful for analysis and classification. Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal. It is based on a nonlinear expansion of the input signal and application of principal component analysis to this expanded signal and its time derivative. It is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance. SFA can be applied hierarchically to process high-dimensional input signals and extract complex features. SFA is applied first to complex cell tuning properties based on simple cell output, including disparity and motion. Then more complicated input-output functions are learned by repeated application of SFA. Finally, a hierarchical network of SFA modules is presented as a simple model of the visual system. The same unstructured network can learn translation, size, rotation, contrast, or, to a lesser degree, illumination invariance for one-dimensional objects, depending on only the training stimulus. Surprisingly, only a few training objects suffice to achieve good generalization to new objects. The generated representation is suitable for object recognition. Performance degrades if the network is trained to learn multiple invariances simultaneously."
            },
            "slug": "Slow-Feature-Analysis:-Unsupervised-Learning-of-Wiskott-Sejnowski",
            "title": {
                "fragments": [],
                "text": "Slow Feature Analysis: Unsupervised Learning of Invariances"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Slow feature analysis (SFA) is a new method for learning invariant or slowly varying features from a vectorial input signal that is guaranteed to find the optimal solution within a family of functions directly and can learn to extract a large number of decor-related features, which are ordered by their degree of invariance."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2542741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "isKey": false,
            "numCitedBy": 2931,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "slug": "Handwritten-Digit-Recognition-with-a-Network-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition with a Back-Propagation Network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task, and has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7674447"
                        ],
                        "name": "R. V. Rullen",
                        "slug": "R.-V.-Rullen",
                        "structuredName": {
                            "firstName": "Rufin",
                            "lastName": "Rullen",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. V. Rullen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762603"
                        ],
                        "name": "A. Delorme",
                        "slug": "A.-Delorme",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Delorme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Delorme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12411745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35a54c1137433d24af7a7c19933252a1a7780f79",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feed-forward-contour-integration-in-primary-visual-Rullen-Delorme",
            "title": {
                "fragments": [],
                "text": "Feed-forward contour integration in primary visual cortex based on asynchronous spike propagation"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145347688"
                        ],
                        "name": "S. Baker",
                        "slug": "S.-Baker",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 30452203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66d890912381e2536d2dbc117a0ce59158c3be90",
            "isKey": false,
            "numCitedBy": 1232,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze the super-resolution reconstruction constraints. In particular we derive a sequence of results which all show that the constraints provide far less useful information as the magnification factor increases. It is well established that the use of a smoothness prior may help somewhat, however for large enough magnification factors any smoothness prior leads to overly smooth results. We therefore propose an algorithm that learns recognition-based priors for specific classes of scenes, the use of which gives far better super-resolution results for both faces and text."
            },
            "slug": "Limits-on-super-resolution-and-how-to-break-them-Baker-Kanade",
            "title": {
                "fragments": [],
                "text": "Limits on super-resolution and how to break them"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm is proposed that learns recognition-based priors for specific classes of scenes, the use of which gives far better super-resolution results for both faces and text."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1876397"
                        ],
                        "name": "G. Doniger",
                        "slug": "G.-Doniger",
                        "structuredName": {
                            "firstName": "Glen",
                            "lastName": "Doniger",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Doniger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3229047"
                        ],
                        "name": "J. Foxe",
                        "slug": "J.-Foxe",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Foxe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Foxe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806472"
                        ],
                        "name": "M. Murray",
                        "slug": "M.-Murray",
                        "structuredName": {
                            "firstName": "Micah",
                            "lastName": "Murray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49883761"
                        ],
                        "name": "B. Higgins",
                        "slug": "B.-Higgins",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Higgins",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Higgins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15345544"
                        ],
                        "name": "J. G. Snodgrass",
                        "slug": "J.-G.-Snodgrass",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Snodgrass",
                            "middleNames": [
                                "Gay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. G. Snodgrass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31983588"
                        ],
                        "name": "C. Schroeder",
                        "slug": "C.-Schroeder",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Schroeder",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schroeder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055508"
                        ],
                        "name": "D. Javitt",
                        "slug": "D.-Javitt",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Javitt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Javitt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37153054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ebf0a8f63697070bf67fdc768ba49192e787a36d",
            "isKey": false,
            "numCitedBy": 243,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition is achieved even in circumstances when only partial information is available to the observer. Perceptual closure processes are essential in enabling such recognitions to occur. We presented successively less fragmented images while recording high-density event-related potentials (ERPs), which permitted us to monitor brain activity during the perceptual closure processes leading up to object recognition. We reveal a bilateral ERP component (Ncl) that tracks these processes (onsets 230 msec, maximal at 290 msec). Scalp-current density mapping of the Ncl revealed bilateral occipito-temporal scalp foci, which are consistent with generators in the human ventral visual stream, and specifically the lateral-occipital or LO complex as defined by hemodynamic studies of object recognition."
            },
            "slug": "Activation-Timecourse-of-Ventral-Visual-Stream-High-Doniger-Foxe",
            "title": {
                "fragments": [],
                "text": "Activation Timecourse of Ventral Visual Stream Object-recognition Areas: High Density Electrical Mapping of Perceptual Closure Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Scalp-current density mapping of the Ncl revealed bilateral occipito-temporal scalp foci, which are consistent with generators in the human ventral visual stream, and specifically the lateral-occipital or LO complex as defined by hemodynamic studies of object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Cognitive Neuroscience"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790646"
                        ],
                        "name": "P. Dayan",
                        "slug": "P.-Dayan",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Dayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Dayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1890561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "605402e235bd62437baf3c9ebefe77fb4d92ee95",
            "isKey": false,
            "numCitedBy": 1173,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Discovering the structure inherent in a set of patterns is a fundamental aim of statistical inference or learning. One fruitful approach is to build a parameterized stochastic generative model, independent draws from which are likely to produce the patterns. For all but the simplest generative models, each pattern can be generated in exponentially many ways. It is thus intractable to adjust the parameters to maximize the probability of the observed patterns. We describe a way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations. Our method can be viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways."
            },
            "slug": "The-Helmholtz-Machine-Dayan-Hinton",
            "title": {
                "fragments": [],
                "text": "The Helmholtz Machine"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A way of finessing this combinatorial explosion by maximizing an easily computed lower bound on the probability of the observations is described, viewed as a form of hierarchical self-supervised learning that may relate to the function of bottom-up and top-down cortical processing pathways."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187218"
                        ],
                        "name": "A. J. Bell",
                        "slug": "A.-J.-Bell",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714528"
                        ],
                        "name": "T. Sejnowski",
                        "slug": "T.-Sejnowski",
                        "structuredName": {
                            "firstName": "Terrence",
                            "lastName": "Sejnowski",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sejnowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1701422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d7d0e8c4791700defd4b0df82a26b50055346e0",
            "isKey": false,
            "numCitedBy": 8757,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "We derive a new self-organizing learning algorithm that maximizes the information transferred in a network of nonlinear units. The algorithm does not assume any knowledge of the input distributions, and is defined here for the zero-noise limit. Under these conditions, information maximization has extra properties not found in the linear case (Linsker 1989). The nonlinearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the output representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalization of principal components analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to 10 speakers. We also show that a variant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, we derive dependencies of information transfer on time delays. We suggest that information maximization provides a unifying framework for problems in \"blind\" signal processing."
            },
            "slug": "An-Information-Maximization-Approach-to-Blind-and-Bell-Sejnowski",
            "title": {
                "fragments": [],
                "text": "An Information-Maximization Approach to Blind Separation and Blind Deconvolution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is suggested that information maximization provides a unifying framework for problems in \"blind\" signal processing and dependencies of information transfer on time delays are derived."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144848684"
                        ],
                        "name": "L. Chua",
                        "slug": "L.-Chua",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Chua",
                            "middleNames": [
                                "Ong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Chua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772490"
                        ],
                        "name": "T. Roska",
                        "slug": "T.-Roska",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Roska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Roska"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56490098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cae40981e8cbe372b5ea7a482a9b7d5b017c1177",
            "isKey": false,
            "numCitedBy": 240,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Once over lightly 2. Introduction - notations, definitions and mathematical foundation 3. Characteristics and analysis of simple CNN templates 4. Simulation of the CNN dynamics 5. Binary CNN characterization via Boolean functions 6. Uncoupled CNNs: unified theory and applications 7. Introduction to the CNN universal machine 8. Back to basics: nonlinear dynamics and complete stability 9. The CNN universal machine (CNN - UM) 10. Template design tools 11. CNNs for linear image processing 12. Coupled CNN with linear synaptic weights 13. Uncoupled standard CNNs with nonlinear synaptic weights 14. Standard CNNs with delayed synaptic weights and motion analysis 15. Visual microprocessors - analog and digital VLSI implementation of the CNN universal machine 16. CNN models in the visual pathway and the 'bionic eye' Appendix A. A CNN template library Appendix B. Using a simple multi-layer CNN analogic dynamic template and algorithm simulator (CANDY) Appendix C. A program for binary CNN template design and optimization (TEMPO)."
            },
            "slug": "Cellular-Neural-Networks-and-Visual-Computing-Chua-Roska",
            "title": {
                "fragments": [],
                "text": "Cellular Neural Networks and Visual Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This book presents a program for binary CNN template design and optimization (TEMPO) and back to basics: nonlinear dynamics and complete stability of the CNN universal machine."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2263062"
                        ],
                        "name": "D. B\u00e1lya",
                        "slug": "D.-B\u00e1lya",
                        "structuredName": {
                            "firstName": "D\u00e1vid",
                            "lastName": "B\u00e1lya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B\u00e1lya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089209"
                        ],
                        "name": "B. Roska",
                        "slug": "B.-Roska",
                        "structuredName": {
                            "firstName": "Botond",
                            "lastName": "Roska",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Roska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772490"
                        ],
                        "name": "T. Roska",
                        "slug": "T.-Roska",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Roska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Roska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821709"
                        ],
                        "name": "F. Werblin",
                        "slug": "F.-Werblin",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Werblin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Werblin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40960528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a49ef19dcdfb05cc1b97eead28743bccff517fb",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present here a simple multi\u2010layer cellular neural/non\u2010linear network (CNN) model of the mammalian retina, capable of implementation on CNN Universal Machine (CNN\u2010UM) chips. The basis of the model is a simple multi\u2010layer cellular neural/non\u2010linear Network (IEEE Trans. Circuits Systems 1988; 35:1257; IEEE Trans. Circuits Systems 1993; 40:147). The characterization of the elements in the CNN model is based on anatomical and physiological studies performed in the rabbit retina. The living mammalian retina represents the visual world in a set of about a dozen different \u2018feature detecting\u2019 parallel representations (Nature 2001; 410:583\u2013587). Our CNN model is capable of reproducing qualitatively the same full set of space\u2013time patterns as the living retina in response to a flashed square. The modelling framework can then be used to predict the set of retinal responses to more complex patterns and is also applicable to studies of the other biological sensory systems. The work represents a major step forward in the complexity and programmability of retinal models. Copyright \u00a9 2002 John Wiley & Sons, Ltd."
            },
            "slug": "A-CNN-framework-for-modeling-parallel-processing-in-B\u00e1lya-Roska",
            "title": {
                "fragments": [],
                "text": "A CNN framework for modeling parallel processing in a mammalian retina"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The CNN model is capable of reproducing qualitatively the same full set of space\u2013time patterns as the living retina in response to a flashed square and can be used to predict the set of retinal responses to more complex patterns."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Circuit Theory Appl."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636368"
                        ],
                        "name": "C. Brody",
                        "slug": "C.-Brody",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Brody",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Brody"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2795465,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "42fd26e1ec3c485d5fd3db8d78a8ce1228efac7d",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Recognition of complex temporal sequences is a general sensory problem that requires integration of information over time. We describe a very simple \"organism\" that performs this task, exemplified here by recognition of spoken monosyllables. The network's computation can be understood through the application of simple but generally unexploited principles describing neural activity. The organism is a network of very simple neurons and synapses; the experiments are simulations. The network's recognition capabilities are robust to variations across speakers, simple masking noises, and large variations in system parameters. The network principles underlying recognition of short temporal sequences are applied here to speech, but similar ideas can be applied to aspects of vision, touch, and olfaction. In this article, we describe only properties of the system that could be measured if it were a real biological organism. We delay publication of the principles behind the network's operation as an intellectual challenge: the essential principles of operation can be deduced based on the experimental results presented here alone. An interactive web site (http://neuron.princeton.edu/ approximately moment) is available to allow readers to design and carry out their own experiments on the organism."
            },
            "slug": "What-is-a-moment-\"Cortical\"-sensory-integration-a-Hopfield-Brody",
            "title": {
                "fragments": [],
                "text": "What is a moment? \"Cortical\" sensory integration over a brief interval."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A very simple \"organism\" that performs this task, exemplified here by recognition of spoken monosyllables, is described, which is a network of very simple neurons and synapses; the experiments are simulations."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4427718"
                        ],
                        "name": "D. Somers",
                        "slug": "D.-Somers",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Somers",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Somers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144832491"
                        ],
                        "name": "E. Todorov",
                        "slug": "E.-Todorov",
                        "structuredName": {
                            "firstName": "Emanuel",
                            "lastName": "Todorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Todorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2944650"
                        ],
                        "name": "A. Siapas",
                        "slug": "A.-Siapas",
                        "structuredName": {
                            "firstName": "Athanassios",
                            "lastName": "Siapas",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Siapas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39535208"
                        ],
                        "name": "L. Toth",
                        "slug": "L.-Toth",
                        "structuredName": {
                            "firstName": "Louis",
                            "lastName": "Toth",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Toth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146656609"
                        ],
                        "name": "D. S. Kim",
                        "slug": "D.-S.-Kim",
                        "structuredName": {
                            "firstName": "D",
                            "lastName": "Kim",
                            "middleNames": [
                                "S"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. S. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227142"
                        ],
                        "name": "M. Sur",
                        "slug": "M.-Sur",
                        "structuredName": {
                            "firstName": "Mriganka",
                            "lastName": "Sur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6577924,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "baa8761c9fef1b23d39051967e7427255a3f3920",
            "isKey": false,
            "numCitedBy": 211,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "Integration of inputs by cortical neurons provides the basis for the complex information processing performed in the cerebral cortex. Here, we have examined how primary visual cortical neurons integrate classical and nonclassical receptive field inputs. The effect of nonclassical receptive field stimuli and, correspondingly, of long-range intracortical inputs is known to be context-dependent: the same long-range stimulus can either facilitate or suppress responses, depending on the level of local activation. By constructing a large-scale model of primary visual cortex, we demonstrate that this effect can be understood in terms of the local cortical circuitry. Each receptive field position contributes both excitatory and inhibitory inputs; however, the inhibitory inputs have greater influence when overall receptive field drive is greater. This mechanism also explains contrast-dependent modulations within the classical receptive field, which similarly switch between excitatory and inhibitory. In order to simplify analysis and to explain the fundamental mechanisms of the model, self-contained modules that capture nonlinear local circuit interactions are constructed. This work supports the notion that receptive field integration is the result of local processing within small groups of neurons rather than in single neurons."
            },
            "slug": "A-local-circuit-approach-to-understanding-of-inputs-Somers-Todorov",
            "title": {
                "fragments": [],
                "text": "A local circuit approach to understanding integration of long-range inputs in primary visual cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work supports the notion that receptive field integration is the result of local processing within small groups of neurons rather than in single neurons, and construction of self-contained modules that capture nonlinear local circuit interactions are constructed."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34180590"
                        ],
                        "name": "S. Thorpe",
                        "slug": "S.-Thorpe",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Thorpe",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thorpe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50780533"
                        ],
                        "name": "D. Fize",
                        "slug": "D.-Fize",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Fize",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fize"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3677347"
                        ],
                        "name": "Catherine Marlot",
                        "slug": "Catherine-Marlot",
                        "structuredName": {
                            "firstName": "Catherine",
                            "lastName": "Marlot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Catherine Marlot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4303570,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "addbd39fc775c12aa453ebd0cb77ea1bd3389572",
            "isKey": false,
            "numCitedBy": 2548,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Speed-of-processing-in-the-human-visual-system-Thorpe-Fize",
            "title": {
                "fragments": [],
                "text": "Speed of processing in the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089209"
                        ],
                        "name": "B. Roska",
                        "slug": "B.-Roska",
                        "structuredName": {
                            "firstName": "Botond",
                            "lastName": "Roska",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Roska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1821709"
                        ],
                        "name": "F. Werblin",
                        "slug": "F.-Werblin",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Werblin",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Werblin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4417240,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "9f303d23b4d23890c16e6cdefbc27d3ab73d887f",
            "isKey": false,
            "numCitedBy": 487,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The mammalian visual system analyses the world through a set of separate spatio-temporal channels. The organization of these channels begins in the retina, where the precise laminations of\u00a0both the axon terminals of bipolar cells and the dendritic arborizations of ganglion cells suggests the presence of a vertical stack of neural strata at the inner plexiform layer (IPL). Conversely, many inhibitory amacrine cell classes are multiply or diffusely stratified, indicating that they might convey information between strata. On the basis of the diverse stratification and physiological properties of ganglion cells, it was suggested that the IPL contains a parallel set of representations of the visual world embodied in the strata and conveyed to higher centres by the classes of ganglion cells whose dendrites ramify at that stratum. Here we show that each stratum receives unique and substantively different excitatory and inhibitory neural inputs that are integrated to form at least ten different, parallel space-time spiking outputs. The response properties of these strata are ordered in the time domain. Inhibition through GABAC receptors extracts spatial edges in neural representations and seems to separate the functional properties of the strata. We describe a new form of neuronal interaction that we call \u2018vertical inhibition\u2019 that acts not laterally, but between strata."
            },
            "slug": "Vertical-interactions-across-ten-parallel,-stacked-Roska-Werblin",
            "title": {
                "fragments": [],
                "text": "Vertical interactions across ten parallel, stacked representations in the mammalian retina"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that each stratum receives unique and substantively different excitatory and inhibitory neural inputs that are integrated to form at least ten different, parallel space-time spiking outputs."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730688"
                        ],
                        "name": "G. Mayraz",
                        "slug": "G.-Mayraz",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Mayraz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Mayraz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 894623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "127bf1f99d9ec32833183c2c8160903151cfafcf",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The product of experts learning procedure [1] can discover a set of stochastic binary features that constitute a non-linear generative model of handwritten images of digits. The quality of generative models learned in this way can be assessed by learning a separate model for each class of digit and then comparing the unnormalized probabilities of test images under the 10 different class-specific models. To improve discriminative performance, it is helpful to learn a hierarchy of separate models for each digit class. Each model in the hierarchy has one layer of hidden units and the nth level model is trained on data that consists of the activities of the hidden units in the already trained (n - 1)th level model. After training, each level produces a separate, unnormalized log probabilty score. With a three-level hierarchy for each of the 10 digit classes, a test image produces 30 scores which can be used as inputs to a supervised, logistic classification network that is trained on separate data. On the MNIST database, our system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data."
            },
            "slug": "Recognizing-Hand-written-Digits-Using-Hierarchical-Mayraz-Hinton",
            "title": {
                "fragments": [],
                "text": "Recognizing Hand-written Digits Using Hierarchical Products of Experts"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "On the MNIST database, the system is comparable with current state-of-the-art discriminative methods, demonstrating that the product of experts learning procedure can produce effective generative models of high-dimensional data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143921323"
                        ],
                        "name": "G. Sommer",
                        "slug": "G.-Sommer",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Sommer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sommer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60700983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1cbc513f68f81534bb1220df1cf82bbfcfe0462",
            "isKey": false,
            "numCitedBy": 301,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Pattern Recognition by Self-Organizing Neural Networks edited by Gail A. Carpenter and Stephan Grossberg, MIT Press, 1991, ISBN 0-262-03176-0."
            },
            "slug": "Pattern-Recognition-by-Self-Organizing-Neural-Sommer",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition by Self-Organizing Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Pattern Recognition by Self-Organizing Neural Networks edited by Gail A Carpenter and Stephan Grossberg, MIT Press, 1991, ISBN 0-262-03176-0."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50371861"
                        ],
                        "name": "M. Dill",
                        "slug": "M.-Dill",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Dill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145766525"
                        ],
                        "name": "M. Fahle",
                        "slug": "M.-Fahle",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Fahle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fahle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19647367,
            "fieldsOfStudy": [
                "Psychology",
                "Biology"
            ],
            "id": "33f9a62e129a307777bc76c211104d339a92a3be",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual object recognition is considered to be largely translation invariant. An earlier study (Foster & Kahn, 1985), however, has indicated that recognition of complex novel stimuli is partially specific to location in the visual field: It is significantly easier to determine the identity of two briefly displayed random patterns if both stimuli are presented at the same, rather than at different, locations. In a series ofsame/different discrimination tasks, we characterize the processes underlying this \u201cdisplacement effect\u201d: Horizontal and vertical translations are equally effective in reducing performance. Making the task more difficult by increasing pattern similarity leads to even higher positional specificity. The displacement effect disappears after rotation or contrast reversal of the patterns, indicating that positional specificity depends on relatively low levels of processing. Control experiments rule out explanations that are independent of visual pattern memory, such as spatial attention, eye movements, or retinal afterimages. Positional specificity of recognition is found only forsame trials. Our results demonstrate that position invariance, a widely acknowledged property of the human visual system, is limited to specific experimental conditions. Normalization models involving mental shifts of an early visual representation or of a window of attention cannot easily account for these findings."
            },
            "slug": "Limited-translation-invariance-of-human-visual-Dill-Fahle",
            "title": {
                "fragments": [],
                "text": "Limited translation invariance of human visual pattern recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results demonstrate that position invariance, a widely acknowledged property of the human visual system, is limited to specific experimental conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Perception & psychophysics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073142"
                        ],
                        "name": "R. Legenstein",
                        "slug": "R.-Legenstein",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Legenstein",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Legenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247053"
                        ],
                        "name": "W. Maass",
                        "slug": "W.-Maass",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Maass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Maass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1660108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "48dfb9485895619ee73c8995255e3f508a3b3280",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce total wire length as salient complexity measure for an analysis of the circuit complexity of sensory processing in biological neural systems and neuromorphic engineering. This new complexity measure is applied to a set of basic computational problems that apparently need to be solved by circuits for translation- and scale-invariant sensory processing. We exhibit new circuit design strategies for these new benchmark functions that can be implemented within realistic complexity bounds, in particular with linear or almost linear total wire length."
            },
            "slug": "Foundations-for-a-Circuit-Complexity-Theory-of-Legenstein-Maass",
            "title": {
                "fragments": [],
                "text": "Foundations for a Circuit Complexity Theory of Sensory Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "New circuit design strategies are exhibited for these new benchmark functions that can be implemented within realistic complexity bounds, in particular with linear or almost linear total wire length."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390039794"
                        ],
                        "name": "\u00c1. Pascual-Leone",
                        "slug": "\u00c1.-Pascual-Leone",
                        "structuredName": {
                            "firstName": "\u00c1lvaro",
                            "lastName": "Pascual-Leone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c1. Pascual-Leone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058305723"
                        ],
                        "name": "V. Walsh",
                        "slug": "V.-Walsh",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Walsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Walsh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44761326,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "d797579033316aec4afac71a6f8b2b51dcf0fa87",
            "isKey": false,
            "numCitedBy": 758,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Much is known about the pathways from photoreceptors to higher visual areas in the brain. However, how we become aware of what we see or of having seen at all is a problem that has eluded neuroscience. Recordings from macaque V1 during deactivation of MT+/V5 and psychophysical studies of perceptual integration suggest that feedback from secondary visual areas to V1 is necessary for visual awareness. We used transcranial magnetic stimulation to probe the timing and function of feedback from human area MT+/V5 to V1 and found its action to be early and critical for awareness of visual motion."
            },
            "slug": "Fast-Backprojections-from-the-Motion-to-the-Primary-Pascual-Leone-Walsh",
            "title": {
                "fragments": [],
                "text": "Fast Backprojections from the Motion to the Primary Visual Area Necessary for Visual Awareness"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "Trans transcranial magnetic stimulation is used to probe the timing and function of feedback from human area MT+/V5 to V1 and found its action to be early and critical for awareness of visual motion."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2302358"
                        ],
                        "name": "P. Burt",
                        "slug": "P.-Burt",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Burt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Burt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8018433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83074157d165b6245915508d891b2d0cd066f3ad",
            "isKey": false,
            "numCitedBy": 6693,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space. Pixel-to-pixel correlations are first removed by subtracting a lowpass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure. The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to enhance salient image features. A further advantage of the present code is that it is well suited for many image analysis tasks as well as for image compression. Fast algorithms are described for coding and decoding."
            },
            "slug": "The-Laplacian-Pyramid-as-a-Compact-Image-Code-Burt-Adelson",
            "title": {
                "fragments": [],
                "text": "The Laplacian Pyramid as a Compact Image Code"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A technique for image encoding in which local operators of many scales but identical shape serve as the basis functions, which tends to enhance salient image features and is well suited for many image analysis tasks as well as for image compression."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2605935"
                        ],
                        "name": "D. Felleman",
                        "slug": "D.-Felleman",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Felleman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Felleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392063491"
                        ],
                        "name": "D. van Essen",
                        "slug": "D.-van-Essen",
                        "structuredName": {
                            "firstName": "D. C.",
                            "lastName": "van Essen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. van Essen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9334496,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "c66b40e54fcb1d748aa04d82f497f24ac22d6129",
            "isKey": false,
            "numCitedBy": 7383,
            "numCiting": 249,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, many new cortical areas have been identified in the macaque monkey. The number of identified connections between areas has increased even more dramatically. We report here on (1) a summary of the layout of cortical areas associated with vision and with other modalities, (2) a computerized database for storing and representing large amounts of information on connectivity patterns, and (3) the application of these data to the analysis of hierarchical organization of the cerebral cortex. Our analysis concentrates on the visual system, which includes 25 neocortical areas that are predominantly or exclusively visual in function, plus an additional 7 areas that we regard as visual-association areas on the basis of their extensive visual inputs. A total of 305 connections among these 32 visual and visual-association areas have been reported. This represents 31% of the possible number of pathways if each area were connected with all others. The actual degree of connectivity is likely to be closer to 40%. The great majority of pathways involve reciprocal connections between areas. There are also extensive connections with cortical areas outside the visual system proper, including the somatosensory cortex, as well as neocortical, transitional, and archicortical regions in the temporal and frontal lobes. In the somatosensory/motor system, there are 62 identified pathways linking 13 cortical areas, suggesting an overall connectivity of about 40%. Based on the laminar patterns of connections between areas, we propose a hierarchy of visual areas and of somatosensory/motor areas that is more comprehensive than those suggested in other recent studies. The current version of the visual hierarchy includes 10 levels of cortical processing. Altogether, it contains 14 levels if one includes the retina and lateral geniculate nucleus at the bottom as well as the entorhinal cortex and hippocampus at the top. Within this hierarchy, there are multiple, intertwined processing streams, which, at a low level, are related to the compartmental organization of areas V1 and V2 and, at a high level, are related to the distinction between processing centers in the temporal and parietal lobes. However, there are some pathways and relationships (about 10% of the total) whose descriptions do not fit cleanly into this hierarchical scheme for one reason or another. In most instances, though, it is unclear whether these represent genuine exceptions to a strict hierarchy rather than inaccuracies or uncertainities in the reported assignment."
            },
            "slug": "Distributed-hierarchical-processing-in-the-primate-Felleman-Essen",
            "title": {
                "fragments": [],
                "text": "Distributed hierarchical processing in the primate cerebral cortex."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A summary of the layout of cortical areas associated with vision and with other modalities, a computerized database for storing and representing large amounts of information on connectivity patterns, and the application of these data to the analysis of hierarchical organization of the cerebral cortex are reported on."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764952"
                        ],
                        "name": "K. Hornik",
                        "slug": "K.-Hornik",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Hornik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hornik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2964655"
                        ],
                        "name": "M. Stinchcombe",
                        "slug": "M.-Stinchcombe",
                        "structuredName": {
                            "firstName": "Maxwell",
                            "lastName": "Stinchcombe",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stinchcombe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149702798"
                        ],
                        "name": "H. White",
                        "slug": "H.-White",
                        "structuredName": {
                            "firstName": "Halbert",
                            "lastName": "White",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. White"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2757547,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "f22f6972e66bdd2e769fa64b0df0a13063c0c101",
            "isKey": false,
            "numCitedBy": 17353,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Multilayer-feedforward-networks-are-universal-Hornik-Stinchcombe",
            "title": {
                "fragments": [],
                "text": "Multilayer feedforward networks are universal approximators"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083485"
                        ],
                        "name": "P. Weerd",
                        "slug": "P.-Weerd",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Weerd",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Weerd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375727"
                        ],
                        "name": "R. Desimone",
                        "slug": "R.-Desimone",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Desimone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Desimone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1830863"
                        ],
                        "name": "Leslie G. Ungerleider",
                        "slug": "Leslie-G.-Ungerleider",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Ungerleider",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leslie G. Ungerleider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13969518,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "be87c09953e173556a50843174a3bc15b274e7f8",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perceptual-filling-in:-a-parametric-study-Weerd-Desimone",
            "title": {
                "fragments": [],
                "text": "Perceptual filling-in: a parametric study"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144870555"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15001270,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "c585a68ec44ae0c64417e5fb29ea597a90fbd580",
            "isKey": false,
            "numCitedBy": 2403,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We may not be able to make you love reading, but neural networks a systematic introduction will lead you to love reading starting from now. Book is the window to open the new world. The world that you want is in the better stage and level. World will always guide you to even the prestige stage of the life. You know, this is some of how reading will give you the kindness. In this case, more books you read more knowledge you know, but it can mean also the bore is full."
            },
            "slug": "Neural-Networks-A-Systematic-Introduction-Rojas",
            "title": {
                "fragments": [],
                "text": "Neural Networks - A Systematic Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors may not be able to make you love reading, but neural networks a systematic introduction will lead you to love reading starting from now."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206457500,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0be39ee052d246ae99c082a565aba25b811be2d",
            "isKey": false,
            "numCitedBy": 6144,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered."
            },
            "slug": "Learning-long-term-dependencies-with-gradient-is-Bengio-Simard",
            "title": {
                "fragments": [],
                "text": "Learning long-term dependencies with gradient descent is difficult"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work shows why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases, and exposes a trade-off between efficient learning by gradient descent and latching on information for long periods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35272407"
                        ],
                        "name": "M. Siegel",
                        "slug": "M.-Siegel",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Siegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Siegel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282030"
                        ],
                        "name": "Konrad Paul Kording",
                        "slug": "Konrad-Paul-Kording",
                        "structuredName": {
                            "firstName": "Konrad",
                            "lastName": "Kording",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Konrad Paul Kording"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40089171"
                        ],
                        "name": "P. K\u00f6nig",
                        "slug": "P.-K\u00f6nig",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "K\u00f6nig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. K\u00f6nig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 618590,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "f3d3785a5564e1324dbc1aec28474f8b296b5bf0",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "The classical view of cortical information processing is that of a bottom-up process in a feedforward hierarchy. However, psychophysical, anatomical, and physiological evidence suggests that top-down effects play a crucial role in the processing of input stimuli. Not much is known about the neural mechanisms underlying these effects. Here we investigate a physiologically inspired model of two reciprocally connected cortical areas. Each area receives bottom-up as well as top-down information. This information is integrated by a mechanism that exploits recent findings on somato-dendritic interactions. (1) This results in a burst signal that is robust in the context of noise in bottom-up signals. (2) Investigating the influence of additional top-down information, priming-like effects on the processing of bottom-up input can be demonstrated. (3) In accordance with recent physiological findings, interareal coupling in low-frequency ranges is characteristically enhanced by top-down mechanisms. The proposed scheme combines a qualitative influence of top-down directed signals on the temporal dynamics of neuronal activity with a limited effect on the mean firing rate of the targeted neurons. As it gives an account of the system properties on the cellular level, it is possible to derive several experimentally testable predictions."
            },
            "slug": "Integrating-Top-Down-and-Bottom-Up-Sensory-by-Siegel-Kording",
            "title": {
                "fragments": [],
                "text": "Integrating Top-Down and Bottom-Up Sensory Processing by Somato-Dendritic Interactions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A physiologically inspired model of two reciprocally connected cortical areas that combines a qualitative influence of top-down directed signals on the temporal dynamics of neuronal activity with a limited effect on the mean firing rate of the targeted neurons is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Computational Neuroscience"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058365460"
                        ],
                        "name": "J. Austin",
                        "slug": "J.-Austin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Austin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Austin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7355029,
            "fieldsOfStudy": [
                "Psychology",
                "Computer Science",
                "Biology"
            ],
            "id": "386db34312f780b8c1b01f43cbe6d2a19f8c97aa",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This section considers how neural networks can be used as associative memory devices. It first describes what an associative memory is, and then moves on to describe associative memories based on feedforward neural networks and associative memories based on recurrent networks. The section also describes associative memory systems based on cognitive models. It also highlights the ability of neural-network-based systems to deal with uncertain data as compared with conventional associative memory systems."
            },
            "slug": "Associative-memory-Austin",
            "title": {
                "fragments": [],
                "text": "Associative memory"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This section considers how neural networks can be used as associative memory devices and describes associative remembering systems based on feedforward neural networks and associative memories based on recurrent networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716669"
                        ],
                        "name": "Victor A. F. Lamme",
                        "slug": "Victor-A.-F.-Lamme",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lamme",
                            "middleNames": [
                                "A.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor A. F. Lamme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 23420153,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "a9f8b12630bce786f8d353a33e0356a93f93e051",
            "isKey": false,
            "numCitedBy": 908,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The activity of neurons in the primary visual cortex of the awake macaque monkey was recorded while the animals were viewing full screen arrays of either oriented line segments or moving random dots. A square patch of the screen was made to perceptually pop out as a circumscribed figure by virtue of differences between the orientation or the direction of motion of the texture elements within that patch and the surround. The animals were trained to identify the figure patches by making saccadic eye movements towards their positions. Almost every cell gave a significantly larger response to elements belonging to the figure than to similar elements belonging to the background. The figure- ground response enhancement was present along the entire extent of the patch and was absent as soon as the receptive field was outside the patch. The strength of the effect had no relation with classical receptive field properties like orientation or direction selectivity or receptive field size. The response enhancement had a latency of 30\u201340 msec relative to the onset of the neuronal response itself. The results show that context modulation within primary visual cortex has a highly sophisticated nature, putting the image features the cells are responding to into their fully evaluated perceptual context."
            },
            "slug": "The-neurophysiology-of-figure-ground-segregation-in-Lamme",
            "title": {
                "fragments": [],
                "text": "The neurophysiology of figure-ground segregation in primary visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The results show that context modulation within primary visual cortex has a highly sophisticated nature, putting the image features the cells are responding to into their fully evaluated perceptual context."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of neuroscience : the official journal of the Society for Neuroscience"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33365402"
                        ],
                        "name": "M. Giese",
                        "slug": "M.-Giese",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Giese",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Giese"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118141188,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "78cf200ef6e2683a83f8fbdc13fcbb5d363e9214",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Introduction.- I Basic Concepts.- 2 Visual perception of motion.- 2.1 Apparent Motion (AM).- 2.2 Motion Energy Models.- 2.3 Motion Correspondence Problem.- 2.4 Cooperativity in Motion Perception.- 2.5 Motion Perception as Regularization Problem.- 2.6 Motion Perception as Statistical Optimization Problem.- 2.7 Motion Perception as Dynamical Process.- 2.8 Motion Transparency.- 2.9 Adaptation.- 2.10 Summary.- 3 Basic principles of the dynamic approach.- 3.1 Central Idea.- 3.2 Behavioral Variables.- 3.3 Behavioral Dynamics.- 3.4 Stability.- 3.5 Bifurcations.- 3.6 Intrinsic Dynamics and Behavioral Information.- 3.7 Comparison between Theory and Experiment.- 3.8 Summary.- 4 Dynamic neural fields.- 4.1 Biological Motivation.- 4.2 Generalization by the Dynamic Approach.- 4.3 Amari Model: Intuitive Concepts.- 4.3.1 Field without Interaction.- 4.3.2 Field with Linear Interaction.- 4.3.3 Neural Field with Constant Input.- 4.3.4 Neural Field with Slightly Varying Input.- 4.4 Amari Model: Mathematical results.- 4.5 Summary.- II Model for Motion Perception.- 5 Dynamic neural field model for motion perception.- 5.1 Perceptive Space.- 5.2 Neural Activation Field.- 5.3 Dynamical State and Stability.- 5.4 Specification by the Stimulus.- 5.5 Cooperativity.- 5.6 Fluctuations.- 5.7 Adaptation.- 5.8 General Neural Field Model.- 5.9 Summary.- 6 Necessity of the concepts: Model for the motion quartet.- 6.1 Dynamical Model for the Motion Quartet.- 6.1.1 Perceptive Space, Activation Dynamics, and Fluctuations.- 6.1.2 Cooperativity.- 6.1.3 Adaptation.- 6.2 Experimental and Numerical Methods.- 6.3 Necessity of State and Stability.- 6.3.1 Necessity of Perceptual State.- 6.3.2 Necessity of (Multi-)Stability.- 6.4 Necessity of Fluctuations and Adaptation.- 6.4.1 Necessity of Fluctuations and Their Interaction with Stability.- 6.4.2 Necessity of Adaptation.- 6.4.3 Necessity of Activation as Dynamical State Variable.- 6.4.4 Relative Importance of Fluctuations and Adaptation.- 6.5 Discussion.- 6.6 Summary.- 7 Sufficiency of the concepts: Field model for 2D-motion perception.- 7.1 Implementation of the Neural Field Model.- 7.1.1 Neural Field Dynamics, Fluctuations, and Adaptation.- 7.1.2 Specifying Influence of the Stimulus.- 7.1.3 Interaction Function.- 7.1.4 Activity Dependent Scaling of the Interaction Function.- 7.1.5 Numerical Methods.- 7.2 Results: Integration of Multiple Functionalities.- 7.2.1 Spatio-Temporal Integration and Prediction.- 7.2.2 Solution of the Motion Correspondence Problem.- 7.2.3 Smoothing and Active Segmentation.- 7.2.4 Motion Transparency.- 7.3 Balance between Stimulus and Cooperativity.- 7.4 Discussion.- 7.5 Summary.- 8 Relationships: neural fields and computational algorithms.- 8.1 Lyapunov Functions.- 8.2 Lyapunov Functional.- 8.3 Relationship: Neural Fields and Regularization Approaches.- 8.4 Probabilistic Interpretation of Neural Fields.- 8.5 Neural Fields as Robust Estimators.- 8.6 Prediction Properties of the Neural Field.- 8.7 Summary and Discussion.- 9 Identification of field models from neurophysiological data.- 9.1 Estimation of Behavior Related Quantities from Neural Responses.- 9.2 Description of the Algorithm.- 9.2.1 Neurophysiological Data.- 9.2.2 Reconstruction of the Activation Distribution.- 9.2.3 Estimation of the Neural Field Parameters.- 9.3 Results.- 9.4 Discussion and Outlook.- 9.5 Summary.- III Other Applications of Neural Fields.- 10 Neural field model for the motor planning of eye movements.- 10.1 Basic Experimental Phenomenology.- 10.2 Neural Field Model.- 10.2.1 Neural Field for the Representation of the Motor Plan.- 10.2.2 Cooperative Interaction.- 10.2.3 Specifying Input.- 10.2.4 Output Stage.- 10.3 Examples for Reproduced Experimental Effects.- 10.3.1 Averaging and Decision Making.- 10.3.2 Bias by Statistical a Priori Information.- 10.3.3 Effect of Warning Signals.- 10.4 Discussion.- 10.5 Summary.- 11 Technical applications of neural fields.- 11.1 Path Planning for an Autonomous Robot.- 11.1.1 System Architecture.- 11.1.2 Results.- 11.2 Integration of Visual Representations.- 11.2.1 System Architecture.- 11.2.2 Results.- 11.3 Computationally Efficient Implementations.- 11.4 Discussion.- 11.5 Summary.- 12 Discussion.- 12.1 Aspects Concerning the Model for Motion Perception.- 12.2 Aspects Concerning other Applications of Neural Fields.- Appendices.- A Appendix of chapter 3.- A.1 Relationship: Eye-Position and Relative Phase Dynamics.- B Appendix of chapter 6.- B.1 Geometry Dependence of Feed-Forward Input.- B.2 Stochastic Bistable Dynamics.- B.3 Parameters of the Model for the Motion Quartet.- C Appendix of chapter 7.- C.1 Properties of the Interaction Function.- C.2 One-Dimensional Neural Field Model for Motion Direction.- C.3 Parameters of the Neural Field Model.- D Appendix of chapter 8.- D.1 Proof of Theorem 4.- D.2 Proof of Lemma 1.- D.3 Proof of Theorem 5.- E Appendix of chapter 9.- E.2 Least Squares Estimation of Kernel Functions.- E.3 Equivalent Feed-Forward System for a Linear Threshold.- F Appendix of chapter 11.- F. 1 Transformation between Robot and World Coordinates.- F.2 Transformations between the Perceptive Spaces.- F.3 Learning of the Parameters of the Approximation Dynamics.- List of Symbols."
            },
            "slug": "Dynamic-neural-field-theory-for-motion-perception-Giese",
            "title": {
                "fragments": [],
                "text": "Dynamic neural field theory for motion perception"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work focuses on the development of a dynamic neural field model for motion perception and its applications in neuroscience, and on the design and implementation of these models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1878615"
                        ],
                        "name": "U. Ramacher",
                        "slug": "U.-Ramacher",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Ramacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Ramacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46482559"
                        ],
                        "name": "W. Raab",
                        "slug": "W.-Raab",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Raab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Raab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30774013"
                        ],
                        "name": "N. Bruls",
                        "slug": "N.-Bruls",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Bruls",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bruls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9206815"
                        ],
                        "name": "U. Hachmann",
                        "slug": "U.-Hachmann",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Hachmann",
                            "middleNames": [
                                "Dr"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Hachmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73005701"
                        ],
                        "name": "C. Sauer",
                        "slug": "C.-Sauer",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Sauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2639445"
                        ],
                        "name": "A. Schackow",
                        "slug": "A.-Schackow",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Schackow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schackow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27081454"
                        ],
                        "name": "J. Gliese",
                        "slug": "J.-Gliese",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Gliese",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gliese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40511651"
                        ],
                        "name": "J. Harnisch",
                        "slug": "J.-Harnisch",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Harnisch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Harnisch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061378364"
                        ],
                        "name": "M. Richter",
                        "slug": "M.-Richter",
                        "structuredName": {
                            "firstName": "Marvin",
                            "lastName": "Richter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Richter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130124"
                        ],
                        "name": "E. Sicheneder",
                        "slug": "E.-Sicheneder",
                        "structuredName": {
                            "firstName": "Elisabeth",
                            "lastName": "Sicheneder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Sicheneder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7780484"
                        ],
                        "name": "R. Schuffny",
                        "slug": "R.-Schuffny",
                        "structuredName": {
                            "firstName": "Rene",
                            "lastName": "Schuffny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schuffny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092836183"
                        ],
                        "name": "U. Schulze",
                        "slug": "U.-Schulze",
                        "structuredName": {
                            "firstName": "U.",
                            "lastName": "Schulze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Schulze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31198545"
                        ],
                        "name": "H. Feldkamper",
                        "slug": "H.-Feldkamper",
                        "structuredName": {
                            "firstName": "H.T.",
                            "lastName": "Feldkamper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Feldkamper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8008539"
                        ],
                        "name": "C. Lutkemeyer",
                        "slug": "C.-Lutkemeyer",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Lutkemeyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lutkemeyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46721962"
                        ],
                        "name": "H. Susse",
                        "slug": "H.-Susse",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Susse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Susse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071109873"
                        ],
                        "name": "S. Altmann",
                        "slug": "S.-Altmann",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Altmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Altmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31600887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "361ac5e0f4dc4fe60891f971100fca0acc651e6c",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "whereas virtual round-table conferencing needs at the sender\u2019s side to find a person\u2019s head, cut it from the background, code it and at the receiver\u2019s side to decode and insert it at the round-table by means of geometric transformations (figure below shows virtual round table). Hence, a vision processor has to support image processing, coding/decoding and 3D graphics. Accordingly, a representative body of algorithms from these 3 vision fields was analysed with respect to computational power, elementary instructions and data types needed. It was found that scalar, vector and matrix constitute the main data types, and a set of 205 visionbased instructions for vector and matrix types was defined. Architectural studies led to a parallel array of 16 processing elements (PE) executing the vision instructions on vector and matrix data, as well as to special cache architectures adapted to the new data types. For decoding of instructions, a set of controllers had to be introduced that would deliver control bits to the amount of what full-fledged general-purpose processors use to generate, but at a decade lower power level. Finally, starting off from the OAK DSP and its Ccompiler, a programming model extending C by some vision based semantics, but keeping the C syntax was thought to be adequate for the user. It is the set of 205 application-specific instructions and its computing and memory architecture that make the vision processor a generic one (see [1] for recent alternatives). In the following, only the functional highlights are reported."
            },
            "slug": "A-53-GOPS-programmable-vision-processor-for-and-of-Ramacher-Raab",
            "title": {
                "fragments": [],
                "text": "A 53-GOPS programmable vision processor for processing, coding-decoding and synthesizing of images"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is the set of 205 application-specific instructions and its computing and memory architecture that make the vision processor a generic one."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 27th European Solid-State Circuits Conference"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143766793"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Azriel",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30489560"
                        ],
                        "name": "R. Hummel",
                        "slug": "R.-Hummel",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Hummel",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hummel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698824"
                        ],
                        "name": "S. Zucker",
                        "slug": "S.-Zucker",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Zucker",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zucker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18603445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5df9cdc54c8085781c4199a95576a14cb7198b9d",
            "isKey": false,
            "numCitedBy": 1518,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a set of objects in a scene whose identifications are ambiguous, it is often possible to use relationships among the objects to reduce or eliminate the ambiguity. A striking example of this approach was given by Waltz [13]. This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of (object, identification) data. Several different models of the process are developed, convergence properties of these models are established, and simple examples are given."
            },
            "slug": "Scene-Labeling-by-Relaxation-Operations-Rosenfeld-Hummel",
            "title": {
                "fragments": [],
                "text": "Scene Labeling by Relaxation Operations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper formulates the ambiguity-reduction process in terms of iterated parallel operations (i.e., relaxation operations) performed on an array of object, identification data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics"
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5631525"
                        ],
                        "name": "H. Jaeger",
                        "slug": "H.-Jaeger",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Jaeger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Jaeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15467150,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8430c0b9afa478ae660398704b11dca1221ccf22",
            "isKey": false,
            "numCitedBy": 1943,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The report introduces a constructive learning algorithm for recurrent neural networks, which modifies only the weights to output units in order to achieve the learning task. key words: recurrent neural networks, supervised learning Zusammenfassung. Der Report f\u00fchrt ein konstruktives Lernverfahren f\u00fcr rekurrente neuronale Netze ein, welches zum Erreichen des Lernzieles lediglich die Gewichte der zu den Ausgabeneuronen f\u00fchrenden Verbindungen modifiziert. Stichw\u00f6rter: rekurrente neuronale Netze, \u00fcberwachtes Lernen"
            },
            "slug": "The''echo-state''approach-to-analysing-and-training-Jaeger",
            "title": {
                "fragments": [],
                "text": "The''echo state''approach to analysing and training recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The report introduces a constructive learning algorithm for recurrent neural networks, which modifies only the weights to output units in order to achieve the learning task."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35268,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144665059"
                        ],
                        "name": "Y. Linde",
                        "slug": "Y.-Linde",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Linde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Linde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805395"
                        ],
                        "name": "A. Buzo",
                        "slug": "A.-Buzo",
                        "structuredName": {
                            "firstName": "Andres",
                            "lastName": "Buzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Buzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144790332"
                        ],
                        "name": "R. Gray",
                        "slug": "R.-Gray",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gray",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18530691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c46799502bebfe6a9ae0f457b7b8b92248ec260",
            "isKey": false,
            "numCitedBy": 7891,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector."
            },
            "slug": "An-Algorithm-for-Vector-Quantizer-Design-Linde-Buzo",
            "title": {
                "fragments": [],
                "text": "An Algorithm for Vector Quantizer Design"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143615842"
                        ],
                        "name": "R. Rao",
                        "slug": "R.-Rao",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Rao",
                            "middleNames": [
                                "Prakash"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8532271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26b136e37652522862ca1db1b6b425deb5be45c3",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-optimal-estimation-approach-to-visual-perception-Rao",
            "title": {
                "fragments": [],
                "text": "An optimal estimation approach to visual perception and learning"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334226"
                        ],
                        "name": "D. Hubel",
                        "slug": "D.-Hubel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hubel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hubel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2629471"
                        ],
                        "name": "T. Wiesel",
                        "slug": "T.-Wiesel",
                        "structuredName": {
                            "firstName": "Torsten",
                            "lastName": "Wiesel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Wiesel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17055992,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "6b4fe4aa4d66fecc7b2869569002714d91d0b3f7",
            "isKey": false,
            "numCitedBy": 12432,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "What chiefly distinguishes cerebral cortex from other parts of the central nervous system is the great diversity of its cell types and interconnexions. It would be astonishing if such a structure did not profoundly modify the response patterns of fibres coming into it. In the cat's visual cortex, the receptive field arrangements of single cells suggest that there is indeed a degree of complexity far exceeding anything yet seen at lower levels in the visual system. In a previous paper we described receptive fields of single cortical cells, observing responses to spots of light shone on one or both retinas (Hubel & Wiesel, 1959). In the present work this method is used to examine receptive fields of a more complex type (Part I) and to make additional observations on binocular interaction (Part II). This approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours. In the past, the technique of recording evoked slow waves has been used with great success in studies of functional anatomy. It was employed by Talbot & Marshall (1941) and by Thompson, Woolsey & Talbot (1950) for mapping out the visual cortex in the rabbit, cat, and monkey. Daniel & Whitteiidge (1959) have recently extended this work in the primate. Most of our present knowledge of retinotopic projections, binocular overlap, and the second visual area is based on these investigations. Yet the method of evoked potentials is valuable mainly for detecting behaviour common to large populations of neighbouring cells; it cannot differentiate functionally between areas of cortex smaller than about 1 mm2. To overcome this difficulty a method has in recent years been developed for studying cells separately or in small groups during long micro-electrode penetrations through nervous tissue. Responses are correlated with cell location by reconstructing the electrode tracks from histological material. These techniques have been applied to"
            },
            "slug": "Receptive-fields,-binocular-interaction-and-in-the-Hubel-Wiesel",
            "title": {
                "fragments": [],
                "text": "Receptive fields, binocular interaction and functional architecture in the cat's visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This method is used to examine receptive fields of a more complex type and to make additional observations on binocular interaction and this approach is necessary in order to understand the behaviour of individual cells, but it fails to deal with the problem of the relationship of one cell to its neighbours."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of physiology"
            },
            "year": 1962
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275441"
                        ],
                        "name": "K. Yow",
                        "slug": "K.-Yow",
                        "structuredName": {
                            "firstName": "Kin",
                            "lastName": "Yow",
                            "middleNames": [
                                "Choong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745672"
                        ],
                        "name": "R. Cipolla",
                        "slug": "R.-Cipolla",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Cipolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Cipolla"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16932868,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e2f29d26f31846d6e0294cfa3733adfc618bbb",
            "isKey": false,
            "numCitedBy": 432,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Feature-based-human-face-detection-Yow-Cipolla",
            "title": {
                "fragments": [],
                "text": "Feature-based human face detection"
            },
            "venue": {
                "fragments": [],
                "text": "Image Vis. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747625"
                        ],
                        "name": "D. Maio",
                        "slug": "D.-Maio",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Maio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687735"
                        ],
                        "name": "D. Maltoni",
                        "slug": "D.-Maltoni",
                        "structuredName": {
                            "firstName": "Davide",
                            "lastName": "Maltoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maltoni"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15505950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb8427550a099124ebdbc44f783f6b62a0583a5e",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Real-time-face-location-on-gray-scale-static-images-Maio-Maltoni",
            "title": {
                "fragments": [],
                "text": "Real-time face location on gray-scale static images"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144575699"
                        ],
                        "name": "S. Vijayakumar",
                        "slug": "S.-Vijayakumar",
                        "structuredName": {
                            "firstName": "Sethu",
                            "lastName": "Vijayakumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vijayakumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3302681"
                        ],
                        "name": "J. Conradt",
                        "slug": "J.-Conradt",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Conradt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Conradt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774593"
                        ],
                        "name": "T. Shibata",
                        "slug": "T.-Shibata",
                        "structuredName": {
                            "firstName": "Tomohiro",
                            "lastName": "Shibata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shibata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745219"
                        ],
                        "name": "S. Schaal",
                        "slug": "S.-Schaal",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Schaal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schaal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7346847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f270eb82a3e9004692aed4e45b0fe8c7b042b700",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of our research is to investigate the interplay between oculomotor control, visual processing, and limb control in humans and primates by exploring the computational issues of these processes with a biologically inspired artificial oculomotor system on an anthropomorphic robot. In this paper, we investigate the computational mechanisms for visual attention in such a system. Stimuli in the environment excite a dynamical neural network that implements a saliency map, i.e., a winner-take-all competition between stimuli while simultaneously smoothing out noise and suppressing irrelevant inputs. In real-time, this system computes new targets for the shift of gaze, executed by the head-eye system of the robot. The redundant degrees-of-freedom of the head-eye system are resolved through a learned inverse kinematics with optimization criterion. We also address important issues how to ensure that the coordinate system of the saliency map remains correct after movement of the robot. The presented attention system is built on principled modules and generally applicable for any sensory modality."
            },
            "slug": "Overt-visual-attention-for-a-humanoid-robot-Vijayakumar-Conradt",
            "title": {
                "fragments": [],
                "text": "Overt visual attention for a humanoid robot"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates the computational mechanisms for visual attention in a dynamical neural network that implements a saliency map, i.e., a winner-take-all competition between stimuli while simultaneously smoothing out noise and suppressing irrelevant inputs."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144800193"
                        ],
                        "name": "J. Haag",
                        "slug": "J.-Haag",
                        "structuredName": {
                            "firstName": "Juergen",
                            "lastName": "Haag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Haag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144036697"
                        ],
                        "name": "A. Borst",
                        "slug": "A.-Borst",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Borst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Borst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16345354,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "844c547fb0647905a0b797a64f6ba3cf55489307",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigated the information about stimulus velocity inherent in the membrane signals of two types of directionally selective, motion-sensitive interneurons in the fly visual system. One of the cells, the H1-cell, is a spiking neuron, whereas the other, the HS-cell, encodes sensory information mainly by a graded shift of its membrane potential. Using a pseudo-random velocity waveform by which a visual grating is moving along the horizontal axis of the eye, both cell types follow the stimulus velocity at higher precision than in response to a step-like velocity function. To measure how much information about the stimulus velocity is preserved in the cellular responses, we calculated the coherence between the stimulus and the neural signals as a function of stimulus frequency. At frequencies up to \u223c10 Hz motion information is well contained in the electrical signals of HS- and H1-cells: For HS-cells the coherence value amounts to \u223c70%, and for H1-cells this value is \u223c60%. Comparing these values with the coherence expected from a linear encoding reveals that the fidelity of the original stimulus is deteriorated in the neural signal partly by neural noise and partly by the nonlinearity inherent in the process of visual motion detection. The degree to which this nonlinearity contributes to the decrease in coherence depends on the maximum velocity used in the experiments; the smaller the stimulus amplitude, the higher the coherence and, thus, the smaller the nonlinearity in encoding of stimulus motion. All these results are in agreement with model simulations in which visual motion is processed by an array of local motion detectors, the spatially integrated output of which is considered the equivalent of the neural signals of HS- and H1-cells."
            },
            "slug": "Encoding-of-Visual-Motion-Information-and-in-and-Haag-Borst",
            "title": {
                "fragments": [],
                "text": "Encoding of Visual Motion Information and Reliability in Spiking and Graded Potential Neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Results are in agreement with model simulations in which visual motion is processed by an array of local motion detectors, the spatially integrated output of which is considered the equivalent of the neural signals of HS- and H1-cells."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Neuroscience"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35523185"
                        ],
                        "name": "A. Pasupathy",
                        "slug": "A.-Pasupathy",
                        "structuredName": {
                            "firstName": "Anitha",
                            "lastName": "Pasupathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pasupathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35260944"
                        ],
                        "name": "C. Connor",
                        "slug": "C.-Connor",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Connor",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Connor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5334902,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "123c269536e7cf691c5d394e2cde65b4c3e89866",
            "isKey": false,
            "numCitedBy": 469,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual shape recognition in primates depends on a multi-stage pathway running from primary visual cortex (V1) to inferotemporal cortex (IT). The mechanisms by which local shape signals from V1 are transformed into selectivity for abstract object categories in IT are unknown. One approach to this issue is to investigate shape representation at intermediate stages in the pathway, such as area V4. We studied 109 V4 cells that appeared sensitive to complex shape in preliminary tests. To achieve a more complete picture of shape representation in V4, we tested each cell with a set of 366 stimuli, constructed by systematically combining convex and concave boundary elements into closed shapes. Using this large, diverse stimulus set, we found that all the cells in our sample responded to a wide variety of shapes and did not appear to encode any single type of global shape. However, for most cells the shapes evoking strongest responses were characterized by a consistent type of boundary conformation at a specific position within the stimulus. For example, a given cell might be tuned for shapes containing concave curvature at the right, with other parts of the shape having little or no effect on responses. Many cells were tuned for more complex boundary configurations (e.g., a convex angle adjacent to a concave curve). We quantified this kind of shape tuning with Gaussian functions on a curvature x position domain. These tuning functions fit the neural responses much better than tuning functions based on edge or axis orientation. Thus individual V4 cells appear to encode moderately complex boundary information at specific locations within larger shapes. This finding suggests that, at intermediate stages in the V1-IT transformation, complex objects are represented at least partly in terms of the configurations and positions of their contour components."
            },
            "slug": "Shape-representation-in-area-V4:-position-specific-Pasupathy-Connor",
            "title": {
                "fragments": [],
                "text": "Shape representation in area V4: position-specific tuning for boundary conformation."
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Individual V4 cells appear to encode moderately complex boundary information at specific locations within larger shapes, which suggests that, at intermediate stages in the V1-IT transformation, complex objects are represented at least partly in terms of the configurations and positions of their contour components."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682174"
                        ],
                        "name": "S. Grossberg",
                        "slug": "S.-Grossberg",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Grossberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Grossberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065126010"
                        ],
                        "name": "J. Williamson",
                        "slug": "J.-Williamson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Williamson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Williamson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17454647,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3f34c9081766514c90fa092801eae31167fee7ff",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural model suggests how horizontal and interlaminar connections in visual cortical areas V1 and V2 develop within a laminar cortical architecture and give rise to adult visual percepts. The model suggests how mechanisms that control cortical development in the infant lead to properties of adult cortical anatomy, neurophysiology and visual perception. The model clarifies how excitatory and inhibitory connections can develop stably by maintaining a balance between excitation and inhibition. The growth of long-range excitatory horizontal connections between layer 2/3 pyramidal cells is balanced against that of short-range disynaptic interneuronal connections. The growth of excitatory on-center connections from layer 6-to-4 is balanced against that of inhibitory interneuronal off-surround connections. These balanced connections interact via intracortical and intercortical feedback to realize properties of perceptual grouping, attention and perceptual learning in the adult, and help to explain the observed variability in the number and temporal distribution of spikes emitted by cortical neurons. The model replicates cortical point spread functions and psychophysical data on the strength of real and illusory contours. The on-center, off-surround layer 6-to-4 circuit enables top-down attentional signals from area V2 to modulate, or attentionally prime, layer 4 cells in area V1 without fully activating them. This modulatory circuit also enables adult perceptual learning within cortical area V1 and V2 to proceed in a stable way."
            },
            "slug": "A-neural-model-of-how-horizontal-and-interlaminar-Grossberg-Williamson",
            "title": {
                "fragments": [],
                "text": "A neural model of how horizontal and interlaminar connections of visual cortex develop into adult circuits that carry out perceptual grouping and learning."
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A neural model suggests how horizontal and interlaminar connections in visual cortical areas V1 and V2 develop within a laminar cortical architecture and give rise to adult visual percepts and clarifies how excitatory and inhibitory connections can develop stably by maintaining a balance between excitation and inhibition."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14711886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce9a21b93ba29d4145a8ef6bf401e77f261848de",
            "isKey": false,
            "numCitedBy": 3833,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks. These algorithms have (1) the advantage that they do not require a precisely defined training interval, operating while the network runs; and (2) the disadvantage that they require nonlocal communication in the network being trained and are computationally expensive. These algorithms allow networks having recurrent connections to learn complex tasks that require the retention of information over time periods having either fixed or indefinite length."
            },
            "slug": "A-Learning-Algorithm-for-Continually-Running-Fully-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "A Learning Algorithm for Continually Running Fully Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The exact form of a gradient-following learning algorithm for completely recurrent networks running in continually sampled time is derived and used as the basis for practical algorithms for temporal supervised learning tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355118"
                        ],
                        "name": "G. Boynton",
                        "slug": "G.-Boynton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Boynton",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Boynton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4461673"
                        ],
                        "name": "J. B. Demb",
                        "slug": "J.-B.-Demb",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Demb",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. B. Demb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145702834"
                        ],
                        "name": "G. Glover",
                        "slug": "G.-Glover",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Glover",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Glover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6563972,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "5af7b9d9615b2ffd3d5596254b650d2b0c142ed6",
            "isKey": false,
            "numCitedBy": 378,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neuronal-basis-of-contrast-discrimination-Boynton-Demb",
            "title": {
                "fragments": [],
                "text": "Neuronal basis of contrast discrimination"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688681"
                        ],
                        "name": "T. Kohonen",
                        "slug": "T.-Kohonen",
                        "structuredName": {
                            "firstName": "Teuvo",
                            "lastName": "Kohonen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kohonen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 222292199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10055eb6f2f711a36d9aa8f759d3b3f01ebddb5d",
            "isKey": false,
            "numCitedBy": 6561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Various Aspects of Memory.- 1.1 On the Purpose and Nature of Biological Memory.- 1.1.1 Some Fundamental Concepts.- 1.1.2 The Classical Laws of Association.- 1.1.3 On Different Levels of Modelling.- 1.2 Questions Concerning the Fundamental Mechanisms of Memory.- 1.2.1 Where Do the Signals Relating to Memory Act Upon?.- 1.2.2 What Kind of Encoding is Used for Neural Signals?.- 1.2.3 What are the Variable Memory Elements?.- 1.2.4 How are Neural Signals Addressed in Memory?.- 1.3 Elementary Operations Implemented by Associative Memory.- 1.3.1 Associative Recall.- 1.3.2 Production of Sequences from the Associative Memory.- 1.3.3 On the Meaning of Background and Context.- 1.4 More Abstract Aspects of Memory.- 1.4.1 The Problem of Infinite-State Memory.- 1.4.2 Invariant Representations.- 1.4.3 Symbolic Representations.- 1.4.4 Virtual Images.- 1.4.5 The Logic of Stored Knowledge.- 2. Pattern Mathematics.- 2.1 Mathematical Notations and Methods.- 2.1.1 Vector Space Concepts.- 2.1.2 Matrix Notations.- 2.1.3 Further Properties of Matrices.- 2.1.4 Matrix Equations.- 2.1.5 Projection Operators.- 2.1.6 On Matrix Differential Calculus.- 2.2 Distance Measures for Patterns.- 2.2.1 Measures of Similarity and Distance in Vector Spaces.- 2.2.2 Measures of Similarity and Distance Between Symbol Strings.- 2.2.3 More Accurate Distance Measures for Text.- 3. Classical Learning Systems.- 3.1 The Adaptive Linear Element (Adaline).- 3.1.1 Description of Adaptation by the Stochastic Approximation.- 3.2 The Perceptron.- 3.3 The Learning Matrix.- 3.4 Physical Realization of Adaptive Weights.- 3.4.1 Perceptron and Adaline.- 3.4.2 Classical Conditioning.- 3.4.3 Conjunction Learning Switches.- 3.4.4 Digital Representation of Adaptive Circuits.- 3.4.5 Biological Components.- 4. A New Approach to Adaptive Filters.- 4.1 Survey of Some Necessary Functions.- 4.2 On the \"Transfer Function\" of the Neuron.- 4.3 Models for Basic Adaptive Units.- 4.3.1 On the Linearization of the Basic Unit.- 4.3.2 Various Cases of Adaptation Laws.- 4.3.3 Two Limit Theorems.- 4.3.4 The Novelty Detector.- 4.4 Adaptive Feedback Networks.- 4.4.1 The Autocorrelation Matrix Memory.- 4.4.2 The Novelty Filter.- 5. Self-Organizing Feature Maps.- 5.1 On the Feature Maps of the Brain.- 5.2 Formation of Localized Responses by Lateral Feedback.- 5.3 Computational Simplification of the Process.- 5.3.1 Definition of the Topology-Preserving Mapping.- 5.3.2 A Simple Two-Dimensional Self-Organizing System.- 5.4 Demonstrations of Simple Topology-Preserving Mappings.- 5.4.1 Images of Various Distributions of Input Vectors.- 5.4.2 \"The Magic TV\".- 5.4.3 Mapping by a Feeler Mechanism.- 5.5 Tonotopic Map.- 5.6 Formation of Hierarchical Representations.- 5.6.1 Taxonomy Example.- 5.6.2 Phoneme Map.- 5.7 Mathematical Treatment of Self-Organization.- 5.7.1 Ordering of Weights.- 5.7.2 Convergence Phase.- 5.8 Automatic Selection of Feature Dimensions.- 6. Optimal Associative Mappings.- 6.1 Transfer Function of an Associative Network.- 6.2 Autoassociative Recall as an Orthogonal Projection.- 6.2.1 Orthogonal Projections.- 6.2.2 Error-Correcting Properties of Projections.- 6.3 The Novelty Filter.- 6.3.1 Two Examples of Novelty Filter.- 6.3.2 Novelty Filter as an Autoassociative Memory.- 6.4 Autoassociative Encoding.- 6.4.1 An Example of Autoassociative Encoding.- 6.5 Optimal Associative Mappings.- 6.5.1 The Optimal Linear Associative Mapping.- 6.5.2 Optimal Nonlinear Associative Mappings.- 6.6 Relationship Between Associative Mapping, Linear Regression, and Linear Estimation.- 6.6.1 Relationship of the Associative Mapping to Linear Regression.- 6.6.2 Relationship of the Regression Solution to the Linear Estimator.- 6.7 Recursive Computation of the Optimal Associative Mapping.- 6.7.1 Linear Corrective Algorithms.- 6.7.2 Best Exact Solution (Gradient Projection).- 6.7.3 Best Approximate Solution (Regression).- 6.7.4 Recursive Solution in the General Case.- 6.8 Special Cases.- 6.8.1 The Correlation Matrix Memory.- 6.8.2 Relationship Between Conditional Averages and Optimal Estimator.- 7. Pattern Recognition.- 7.1 Discriminant Functions.- 7.2 Statistical Formulation of Pattern Classification.- 7.3 Comparison Methods.- 7.4 The Subspace Methods of Classification.- 7.4.1 The Basic Subspace Method.- 7.4.2 The Learning Subspace Method (LSM).- 7.5 Learning Vector Quantization.- 7.6 Feature Extraction.- 7.7 Clustering.- 7.7.1 Simple Clustering (Optimization Approach).- 7.7.2 Hierarchical Clustering (Taxonomy Approach).- 7.8 Structural Pattern Recognition Methods.- 8. More About Biological Memory.- 8.1 Physiological Foundations of Memory.- 8.1.1 On the Mechanisms of Memory in Biological Systems.- 8.1.2 Structural Features of Some Neural Networks.- 8.1.3 Functional Features of Neurons.- 8.1.4 Modelling of the Synaptic Plasticity.- 8.1.5 Can the Memory Capacity Ensue from Synaptic Changes?.- 8.2 The Unified Cortical Memory Model.- 8.2.1 The Laminar Network Organization.- 8.2.2 On the Roles of Interneurons.- 8.2.3 Representation of Knowledge Over Memory Fields.- 8.2.4 Self-Controlled Operation of Memory.- 8.3 Collateral Reading.- 8.3.1 Physiological Results Relevant to Modelling.- 8.3.2 Related Modelling.- 9. Notes on Neural Computing.- 9.1 First Theoretical Views of Neural Networks.- 9.2 Motives for the Neural Computing Research.- 9.3 What Could the Purpose of the Neural Networks be?.- 9.4 Definitions of Artificial \"Neural Computing\" and General Notes on Neural Modelling.- 9.5 Are the Biological Neural Functions Localized or Distributed?.- 9.6 Is Nonlinearity Essential to Neural Computing?.- 9.7 Characteristic Differences Between Neural and Digital Computers.- 9.7.1 The Degree of Parallelism of the Neural Networks is Still Higher than that of any \"Massively Parallel\" Digital Computer.- 9.7.2 Why the Neural Signals Cannot be Approximated by Boolean Variables.- 9.7.3 The Neural Circuits do not Implement Finite Automata.- 9.7.4 Undue Views of the Logic Equivalence of the Brain and Computers on a High Level.- 9.8 \"Connectionist Models\".- 9.9 How can the Neural Computers be Programmed?.- 10. Optical Associative Memories.- 10.1 Nonholographic Methods.- 10.2 General Aspects of Holographic Memories.- 10.3 A Simple Principle of Holographic Associative Memory.- 10.4 Addressing in Holographic Memories.- 10.5 Recent Advances of Optical Associative Memories.- Bibliography on Pattern Recognition.- References."
            },
            "slug": "Self-Organization-and-Associative-Memory-Kohonen",
            "title": {
                "fragments": [],
                "text": "Self-Organization and Associative Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The purpose and nature of Biological Memory, as well as some of the aspects of Memory Aspects, are explained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387475"
                        ],
                        "name": "B. Ramsden",
                        "slug": "B.-Ramsden",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Ramsden",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Ramsden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1971623"
                        ],
                        "name": "C. Hung",
                        "slug": "C.-Hung",
                        "structuredName": {
                            "firstName": "Chou",
                            "lastName": "Hung",
                            "middleNames": [
                                "Po"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2900863"
                        ],
                        "name": "A. Roe",
                        "slug": "A.-Roe",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Roe",
                            "middleNames": [
                                "Wang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Roe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9825772,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "7b41bfa4eb5fc85a1f47525921f707c38ab9494d",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "It is known that neurons in area V2 (the second visual area) can signal the orientation of illusory contours in the primate. Whether area V1 (primary visual cortex) can signal illusory contour orientation is more controversial. While some electrophysiology studies have ruled out illusory signaling in V1, other reports suggest that V1 shows some illusory-specific response. Here, using optical imaging and single unit electrophysiology, we report that primate V1 does show an orientation-specific response to the 'abutting line grating' illusory contour. However, this response does not signal an illusory contour in the conventional sense. Rather, we find that illusory contour stimulation leads to an activation map that, after appropriate subtraction of real line signal, is inversely related to the real orientation map. The illusory contour orientation is thus negatively signaled or de-emphasized in V1. This 'activation reversal' is robust, is not due merely to presence of line ends, is not dependent on inducer orientation, and is not due to precise position of line end stimulation of V1 cells. These data suggest a resolution for previous apparently contradictory experimental findings. We propose that the de-emphasis of illusory contour orientation in V1 may be an important signal of contour identity and may, together with illusory signal from V2, provide a unique signature for illusory contour representation."
            },
            "slug": "Real-and-illusory-contour-processing-in-area-V1-of-Ramsden-Hung",
            "title": {
                "fragments": [],
                "text": "Real and illusory contour processing in area V1 of the primate: a cortical balancing act."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is reported that primate V1 does show an orientation-specific response to the 'abutting line grating' illusory contour, and it is proposed that the de-emphasis of illusary contour orientation in V1 may be an important signal of contour identity and may, together with illusORY signal from V2, provide a unique signature for illusorous contour representation."
            },
            "venue": {
                "fragments": [],
                "text": "Cerebral cortex"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 235072,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "85a1725bfd3b4a2d3fe9a7272d66ebf03c016fed",
            "isKey": false,
            "numCitedBy": 766,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The classical solution to the noise removal problem is the Wiener filter, which utilizes the second-order statistics of the Fourier decomposition. Subband decompositions of natural images have significantly non-Gaussian higher-order point statistics; these statistics capture image properties that elude Fourier-based techniques. We develop a Bayesian estimator that is a natural extension of the Wiener solution, and that exploits these higher-order statistics. The resulting nonlinear estimator performs a \"coring\" operation. We provide a simple model for the subband statistics, and use it to develop a semi-blind noise removal algorithm based on a steerable wavelet pyramid."
            },
            "slug": "Noise-removal-via-Bayesian-wavelet-coring-Simoncelli-Adelson",
            "title": {
                "fragments": [],
                "text": "Noise removal via Bayesian wavelet coring"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A Bayesian estimator is developed that is a natural extension of the Wiener solution, and that exploits higher-order statistics of the Fourier decomposition to develop a semi-blind noise removal algorithm based on a steerable wavelet pyramid."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd IEEE International Conference on Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684626"
                        ],
                        "name": "B. Heisele",
                        "slug": "B.-Heisele",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Heisele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Heisele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704699"
                        ],
                        "name": "M. Pontil",
                        "slug": "M.-Pontil",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Pontil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pontil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14459527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7b2396cd6a70bae36f19877322b4960919add084",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : We present a trainable system for detecting frontal and near-frontal views of faces in still gray images using Support Vector Machines (SVMs). We first consider the problem of detecting the whole face pattern by a single SVM classifier. In this context we compare different types of image features, present and evaluate a new method for reducing the number features and discuss practical issues concerning the parameterization of SVMs and the selection of training data. The second part of the paper describes a component-based method for face detection consisting of a two-level hierarchy of SVM classifiers. On the first level, component classifiers independently detect components of a face, such as the eyes, the nose, and the mouth. On the second level, a single classifier checks if the geometrical configuration of the detected components in the image matches a geometrical model of a face."
            },
            "slug": "Face-Detection-in-Still-Gray-Images-Heisele-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Detection in Still Gray Images"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A trainable system for detecting frontal and near-frontal views of faces in still gray images using Support Vector Machines (SVMs), and a component-based method for face detection consisting of a two-level hierarchy of SVM classifiers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5746818"
                        ],
                        "name": "G. M. Reicher",
                        "slug": "G.-M.-Reicher",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Reicher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. M. Reicher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 34075108,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "314057b09d7a9d6a84f13c462f915d602716b4c8",
            "isKey": false,
            "numCitedBy": 1182,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The present study evaluates a class of models of human information processing made popular by Broadbent. A brief tachistoscopic display of one or two single letters, four-letter common words, or four-letter nonwords was immediately followed by a masking field along with two single-letter response alternatives chosen so as to minimize informational differences among the tasks. Giving 5s response alternatives before the stimulus display as well as after it caused an impairment of performance. Performance on single words was clearly better than performance on single letters. The data suggest that the first stages of information processing are done in parallel, but scanning of the resultant highly processed information is done serially."
            },
            "slug": "Perceptual-recognition-as-a-function-of-of-stimulus-Reicher",
            "title": {
                "fragments": [],
                "text": "Perceptual recognition as a function of meaninfulness of stimulus material."
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The data suggest that the first stages of information processing are done in parallel, but scanning of the resultant highly processed information is done serially."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of experimental psychology"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46486898"
                        ],
                        "name": "A. Krogh",
                        "slug": "A.-Krogh",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Krogh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krogh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2363971"
                        ],
                        "name": "J. Hertz",
                        "slug": "J.-Hertz",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hertz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hertz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10137788,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "48e1de7d085808004d5f0493d486669a3d2930b5",
            "isKey": false,
            "numCitedBy": 1368,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been observed in numerical simulations that a weight decay can improve generalization in a feed-forward neural network. This paper explains why. It is proven that a weight decay has two effects in a linear network. First, it suppresses any irrelevant components of the weight vector by choosing the smallest vector that solves the learning problem. Second, if the size is chosen right, a weight decay can suppress some of the effects of static noise on the targets, which improves generalization quite a lot. It is then shown how to extend these results to networks with hidden layers and non-linear units. Finally the theory is confirmed by some numerical simulations using the data from NetTalk."
            },
            "slug": "A-Simple-Weight-Decay-Can-Improve-Generalization-Krogh-Hertz",
            "title": {
                "fragments": [],
                "text": "A Simple Weight Decay Can Improve Generalization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is proven that a weight decay has two effects in a linear network, and it is shown how to extend these results to networks with hidden layers and non-linear units."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20631960"
                        ],
                        "name": "D. Senseman",
                        "slug": "D.-Senseman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Senseman",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Senseman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47758710"
                        ],
                        "name": "K. Robbins",
                        "slug": "K.-Robbins",
                        "structuredName": {
                            "firstName": "Kay",
                            "lastName": "Robbins",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Robbins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17009779,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "0e173e94f120da3bd84b1be8394d18597634a1b8",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "In the pond turtle, Pseudemys scripta elegans, visually evoked cortical waves propagate at different velocities within the primary visual area compared with waves that pass into the secondary visual area. In an effort to separate intra- and intercortical wave motions, movies of visually evoked cortical waves recorded by high-speed voltage-sensitive dye (VSD) imaging were subjected to Karhunen-Lo\u00e9ve (KL) decomposition. This procedure decomposes the VSD movies into a series of basis images that capture different spatial patterns of coherent activity. Most of the energy of the compound wave motion (>95%) was captured by the three largest basis images, M(1,1), M(1,2), and M(2,1). Based on visual comparison with maps of wave front latency, KL basis image M(1,2) appears to capture the spread of depolarization within the primary visual area, whereas KL basis image M(2,1) appears to capture the spread of depolarization from the primary into the secondary visual area. The contribution of different basis images to the intra- and intercortical wave motions was tested by reconstructing the response using different combinations of KL basis images. Only KL basis images M(1,1) and M(1,2) were needed to reconstruct intracortical wave motion, while basis images M(1,1) and M(2,1) were needed to reconstruct intercortical wave motion. It was also found that the direction and speed of wave propagation could be deduced by visual inspection of the basis image projections on to the original data set. The relative advantage of KL decomposition for the analysis of complex wave motions captured by VSD imaging is discussed."
            },
            "slug": "High-speed-VSD-imaging-of-visually-evoked-cortical-Senseman-Robbins",
            "title": {
                "fragments": [],
                "text": "High-speed VSD imaging of visually evoked cortical waves: decomposition into intra- and intercortical wave motions."
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "In an effort to separate intra- and intercortical wave motions, movies of visually evoked cortical waves recorded by high-speed voltage-sensitive dye (VSD) imaging were subjected to Karhunen-Lo\u00e9ve (KL) decomposition, which decomposes the VSD movies into a series of basis images that capture different spatial patterns of coherent activity."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400601690"
                        ],
                        "name": "A. O'Toole",
                        "slug": "A.-O'Toole",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "O'Toole",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Toole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747836"
                        ],
                        "name": "H. B\u00fclthoff",
                        "slug": "H.-B\u00fclthoff",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "B\u00fclthoff",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. B\u00fclthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2932365"
                        ],
                        "name": "N. Troje",
                        "slug": "N.-Troje",
                        "structuredName": {
                            "firstName": "Nikolaus",
                            "lastName": "Troje",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Troje"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144517651"
                        ],
                        "name": "T. Vetter",
                        "slug": "T.-Vetter",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Vetter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Vetter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7421913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f4c6791e21279f3d82e6681f935bdee5499fac4",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a computational model of face recognition that makes use of the overlapping texture and shape information visible in different views of faces. The model operates on view dependent data from three-dimensional laser scans of human heads, wich provided three-dimensional surface data as well as surface image detail in form of a texture map. View-dependent information from the surface and texture representations was registered onto separate three-dimensional head models. We used an auto-associative memory model as a pattern completion device to fill in parts of the head from a lerned view when a test view with partially overlapping information was used as a memory key- We show that the overlapping visible regions of heads for both surface and texture data can support accurate recognition, even with pose differences of as much as 90 degrees (full face to profile view) between the learning and test view."
            },
            "slug": "Face-Recognition-across-Large-Viewpoint-Changes-O'Toole-B\u00fclthoff",
            "title": {
                "fragments": [],
                "text": "Face Recognition across Large Viewpoint Changes"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that the overlapping visible regions of heads for both surface and texture data can support accurate recognition, even with pose differences of as much as 90 degrees between the learning and test view."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118180516"
                        ],
                        "name": "F. M. Silva",
                        "slug": "F.-M.-Silva",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Silva",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. M. Silva"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068289963"
                        ],
                        "name": "L. B. Almeida",
                        "slug": "L.-B.-Almeida",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Almeida",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. B. Almeida"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 30453139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a546f8798597fd2acbad81a9da358f1d11a0ad75",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Like other gradient descent techniques, backpropagation converges slowly, even for medium sized network problems. This fact results from the usually large dimension of the weight space and from the particular shape of the error surface in each iteration point. Oscillation between the sides of deep and narrow valleys, for example, is a well known case where gradient descent provides poor convergence rates."
            },
            "slug": "Acceleration-Techniques-for-the-Backpropagation-Silva-Almeida",
            "title": {
                "fragments": [],
                "text": "Acceleration Techniques for the Backpropagation Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Backpropagation converges slowly, even for medium sized network problems, because of the usually large dimension of the weight space and from the particular shape of the error surface in each iteration point."
            },
            "venue": {
                "fragments": [],
                "text": "EURASIP Workshop"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2646100"
                        ],
                        "name": "T. Jones",
                        "slug": "T.-Jones",
                        "structuredName": {
                            "firstName": "Thouis",
                            "lastName": "Jones",
                            "middleNames": [
                                "Raymond"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891751"
                        ],
                        "name": "E. Pasztor",
                        "slug": "E.-Pasztor",
                        "structuredName": {
                            "firstName": "Egon",
                            "lastName": "Pasztor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Pasztor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6775458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e484ef6b9a1b38a86a8c79b5559a3070f327a033",
            "isKey": false,
            "numCitedBy": 2357,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We call methods for achieving high-resolution enlargements of pixel-based images super-resolution algorithms. Many applications in graphics or image processing could benefit from such resolution independence, including image-based rendering (IBR), texture mapping, enlarging consumer photographs, and converting NTSC video content to high-definition television. We built on another training-based super-resolution algorithm and developed a faster and simpler algorithm for one-pass super-resolution. Our algorithm requires only a nearest-neighbor search in the training set for a vector derived from each patch of local image data. This one-pass super-resolution algorithm is a step toward achieving resolution independence in image-based representations. We don't expect perfect resolution independence-even the polygon representation doesn't have that-but increasing the resolution independence of pixel-based representations is an important task for IBR."
            },
            "slug": "Example-Based-Super-Resolution-Freeman-Jones",
            "title": {
                "fragments": [],
                "text": "Example-Based Super-Resolution"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work built on another training-based super- resolution algorithm and developed a faster and simpler algorithm for one-pass super-resolution that requires only a nearest-neighbor search in the training set for a vector derived from each patch of local image data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3148558"
                        ],
                        "name": "S. Zhong",
                        "slug": "S.-Zhong",
                        "structuredName": {
                            "firstName": "Sifen",
                            "lastName": "Zhong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zhong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5698299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42d06ff2160dae7412c299619c04f63395b784b",
            "isKey": false,
            "numCitedBy": 3302,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A multiscale Canny edge detection is equivalent to finding the local maxima of a wavelet transform. The authors study the properties of multiscale edges through the wavelet theory. For pattern recognition, one often needs to discriminate different types of edges. They show that the evolution of wavelet local maxima across scales characterize the local shape of irregular structures. Numerical descriptors of edge types are derived. The completeness of a multiscale edge representation is also studied. The authors describe an algorithm that reconstructs a close approximation of 1-D and 2-D signals from their multiscale edges. For images, the reconstruction errors are below visual sensitivity. As an application, a compact image coding algorithm that selects important edges and compresses the image data by factors over 30 has been implemented. >"
            },
            "slug": "Characterization-of-Signals-from-Multiscale-Edges-Mallat-Zhong",
            "title": {
                "fragments": [],
                "text": "Characterization of Signals from Multiscale Edges"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The authors describe an algorithm that reconstructs a close approximation of 1-D and 2-D signals from their multiscale edges and shows that the evolution of wavelet local maxima across scales characterize the local shape of irregular structures."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7726541"
                        ],
                        "name": "R. Malladi",
                        "slug": "R.-Malladi",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Malladi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Malladi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9397819"
                        ],
                        "name": "J. Sethian",
                        "slug": "J.-Sethian",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Sethian",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sethian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 40227787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0580ff927d33e57dc420bcfe359cc406e11fbd4",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a controlled image smoothing and enhancement method based on a curvature flow interpretation of the geometric heat equation. Compared to existing techniques, the model has several distinct advantages. (i) It contains just one enhancement parameter. (ii) The scheme naturally inherits a stopping criterion from the image; continued application of the scheme produces no further change. (iii) The method is one of the fastest possible schemes based on a curvature-controlled approach."
            },
            "slug": "Image-processing-via-level-set-curvature-flow.-Malladi-Sethian",
            "title": {
                "fragments": [],
                "text": "Image processing via level set curvature flow."
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A controlled image smoothing and enhancement method based on a curvature flow interpretation of the geometric heat equation that contains just one enhancement parameter and is one of the fastest possible schemes based on the curvature-controlled approach."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065808108"
                        ],
                        "name": "Pietro Perona",
                        "slug": "Pietro-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pietro Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14502908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "496c3d75b81b336411e53da1ac632a8139655604",
            "isKey": false,
            "numCitedBy": 12585,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image. >"
            },
            "slug": "Scale-Space-and-Edge-Detection-Using-Anisotropic-Perona-Malik",
            "title": {
                "fragments": [],
                "text": "Scale-Space and Edge Detection Using Anisotropic Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced, chosen to vary spatially in such a way as to encourage intra Region smoothing rather than interregion smoothing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145247053"
                        ],
                        "name": "W. Maass",
                        "slug": "W.-Maass",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Maass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Maass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792142"
                        ],
                        "name": "T. Natschl\u00e4ger",
                        "slug": "T.-Natschl\u00e4ger",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Natschl\u00e4ger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Natschl\u00e4ger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754307"
                        ],
                        "name": "H. Markram",
                        "slug": "H.-Markram",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Markram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Markram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1045112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0535dedb8607d83cd2614317c99913378e89e26",
            "isKey": false,
            "numCitedBy": 2863,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "A key challenge for neural modeling is to explain how a continuous stream of multimodal input from a rapidly changing environment can be processed by stereotypical recurrent circuits of integrate-and-fire neurons in real time. We propose a new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks. It does not require a task-dependent construction of neural circuits. Instead, it is based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry. It is shown that the inherent transient dynamics of the high-dimensional dynamical system formed by a sufficiently large and heterogeneous neural circuit may serve as universal analog fading memory. Readout neurons can learn to extract in real time from the current state of such recurrent neural circuit information about current and past inputs that may be needed for diverse tasks. Stable internal states are not required for giving a stable output, since transient internal states can be transformed by readout neurons into stable target outputs due to the high dimensionality of the dynamical system. Our approach is based on a rigorous computational model, the liquid state machine, that, unlike Turing machines, does not require sequential transitions between well-defined discrete internal states. It is supported, as the Turing machine is, by rigorous mathematical results that predict universal computational power under idealized conditions, but for the biologically more realistic scenario of real-time processing of time-varying inputs. Our approach provides new perspectives for the interpretation of neural coding, the design of experiments and data analysis in neurophysiology, and the solution of problems in robotics and neurotechnology."
            },
            "slug": "Real-Time-Computing-Without-Stable-States:-A-New-on-Maass-Natschl\u00e4ger",
            "title": {
                "fragments": [],
                "text": "Real-Time Computing Without Stable States: A New Framework for Neural Computation Based on Perturbations"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new computational model for real-time computing on time-varying input that provides an alternative to paradigms based on Turing machines or attractor neural networks, based on principles of high-dimensional dynamical systems in combination with statistical learning theory and can be implemented on generic evolved or found recurrent circuitry."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107214345"
                        ],
                        "name": "C. L. Wilson",
                        "slug": "C.-L.-Wilson",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Wilson",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Wilson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11712803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14f3ca3cb341e1b06ee634817be8b6c01ad272d4",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Eleven different Census Optical Character Recognition Systems systems are evaluated using correlations between the answers of different systems, comparing the decrease in error rate as a function of confidence of recognition, and comparing the writer dependence of recognition. This comparison shows that methods that use different algorithms for feature extraction and recognition perform with very high levels of correlation.<<ETX>>"
            },
            "slug": "Evaluation-of-character-recognition-systems-Wilson",
            "title": {
                "fragments": [],
                "text": "Evaluation of character recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Ten different Census Optical Character Recognition Systems systems are evaluated using correlations between the answers of different systems, comparing the decrease in error rate as a function of confidence of recognition, and comparing the writer dependence of recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing III - Proceedings of the 1993 IEEE-SP Workshop"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37805323"
                        ],
                        "name": "Sandiway Fong",
                        "slug": "Sandiway-Fong",
                        "structuredName": {
                            "firstName": "Sandiway",
                            "lastName": "Fong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandiway Fong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6673581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "304b814e51e3515ed7e4521cbfba5c8e36ff44d8",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 214,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the inductive inference of a complex grammar with neural networks and specifically, the task considered is that of training a network to classify natural language sentences as grammatical or ungrammatical, thereby exhibiting the same kind of discriminatory power provided by the Principles and Parameters linguistic framework, or Government-and-Binding theory. Neural networks are trained, without the division into learned vs. innate components assumed by Chomsky (1956), in an attempt to produce the same judgments as native speakers on sharply grammatical/ungrammatical data. How a recurrent neural network could possess linguistic capability and the properties of various common recurrent neural network architectures are discussed. The problem exhibits training behavior which is often not present with smaller grammars and training was initially difficult. However, after implementing several techniques aimed at improving the convergence of the gradient descent backpropagation-through-time training algorithm, significant learning was possible. It was found that certain architectures are better able to learn an appropriate grammar. The operation of the networks and their training is analyzed. Finally, the extraction of rules in the form of deterministic finite state automata is investigated."
            },
            "slug": "Natural-Language-Grammatical-Inference-with-Neural-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Natural Language Grammatical Inference with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It was found that certain architectures are better able to learn an appropriate grammar than others, and the extraction of rules in the form of deterministic finite state automata is investigated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462139"
                        ],
                        "name": "M. Tsodyks",
                        "slug": "M.-Tsodyks",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Tsodyks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tsodyks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754307"
                        ],
                        "name": "H. Markram",
                        "slug": "H.-Markram",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Markram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Markram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14075440,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "42639d562859789996f190a8722b11bbbaa0b308",
            "isKey": false,
            "numCitedBy": 1535,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Although signaling between neurons is central to the functioning of the brain, we still do not understand how the code used in signaling depends on the properties of synaptic transmission. Theoretical analysis combined with patch clamp recordings from pairs of neocortical pyramidal neurons revealed that the rate of synaptic depression, which depends on the probability of neurotransmitter release, dictates the extent to which firing rate and temporal coherence of action potentials within a presynaptic population are signaled to the postsynaptic neuron. The postsynaptic response primarily reflects rates of firing when depression is slow and temporal coherence when depression is fast. A wide range of rates of synaptic depression between different pairs of pyramidal neurons was found, suggesting that the relative contribution of rate and temporal signals varies along a continuum. We conclude that by setting the rate of synaptic depression, release probability is an important factor in determining the neural code."
            },
            "slug": "The-neural-code-between-neocortical-pyramidal-on-Tsodyks-Markram",
            "title": {
                "fragments": [],
                "text": "The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "By setting the rate of synaptic depression, release probability is an important factor in determining the neural code, suggesting that the relative contribution of rate and temporal signals varies along a continuum."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13456135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "939d584316be99e2db3fec3fbf7d71f22a477f67",
            "isKey": false,
            "numCitedBy": 340,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a distribution model for binary vectors, called the influence combination model and show how this model can be used as the basis for unsupervised learning algorithms for feature selection. The model can be represented by a particular type of Boltzmann machine with a bipartite graph structure that we call the combination machine. This machine is closely related to the Harmonium model defined by Smolensky. In the first part of the paper we analyze properties of this distribution representation scheme. We show that arbitrary distributions of binary vectors can be approximated by the combination model. We show how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits, and how the combination machine can be used as a mechanism for detecting these patterns. We compare the combination model with the mixture model and with principle component analysis. In the second part of the paper we present two algorithms for learning the combination model from examples. The first learning algorithm is the standard gradient ascent heuristic for computing maximum likelihood estimates for the parameters of the model. Here we give a closed form for this gradient that is significantly easier to compute than the corresponding gradient for the general Boltzmann machine. The second learning algorithm is a greedy method that creates the hidden units and computes their weights one at a time. This method is a variant of projection pursuit density estimation. In the third part of the paper we give experimental results for these learning methods on synthetic data and on natural data of handwritten digit images."
            },
            "slug": "Unsupervised-Learning-of-Distributions-of-Binary-Freund-Haussler",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Distributions of Binary Vectors Using 2-Layer Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that arbitrary distributions of binary vectors can be approximated by the combination model and shown how the weight vectors in the model can be interpreted as high order correlation patterns among the input bits, and how the combination machine can be used as a mechanism for detecting these patterns."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2432463"
                        ],
                        "name": "E. Hjelm\u00e5s",
                        "slug": "E.-Hjelm\u00e5s",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Hjelm\u00e5s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hjelm\u00e5s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054024193"
                        ],
                        "name": "B. K. Low",
                        "slug": "B.-K.-Low",
                        "structuredName": {
                            "firstName": "Boon",
                            "lastName": "Low",
                            "middleNames": [
                                "Kee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K. Low"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15724653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "887567782cb859ecd339693589056903b0071353",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 336,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a comprehensive and critical survey of face detection algorithms. Face detection is a necessary first-step in face recognition systems, with the purpose of localizing and extracting the face region from the background. It also has several applications in areas such as content-based image retrieval, video coding, video conferencing, crowd surveillance, and intelligent human?computer interfaces. However, it was not until recently that the face detection problem received considerable attention among researchers. The human face is a dynamic object and has a high degree of variability in its apperance, which makes face detection a difficult problem in computer vision. A wide variety of techniques have been proposed, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods. The algorithms presented in this paper are classified as either feature-based or image-based and are discussed in terms of their technical approach and performance. Due to the lack of standardized tests, we do not provide a comprehensive comparative evaluation, but in cases where results are reported on common datasets, comparisons are presented. We also give a presentation of some proposed applications and possible application areas."
            },
            "slug": "Face-Detection:-A-Survey-Hjelm\u00e5s-Low",
            "title": {
                "fragments": [],
                "text": "Face Detection: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A comprehensive and critical survey of face detection algorithms, ranging from simple edge-based algorithms to composite high-level approaches utilizing advanced pattern recognition methods, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Vis. Image Underst."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144275801"
                        ],
                        "name": "J. Illingworth",
                        "slug": "J.-Illingworth",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Illingworth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Illingworth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205012622,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "00f2938d9f10e4bd37336f01b18a41d518f749ba",
            "isKey": false,
            "numCitedBy": 2084,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimum-error-thresholding-Kittler-Illingworth",
            "title": {
                "fragments": [],
                "text": "Minimum error thresholding"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746242"
                        ],
                        "name": "S. Mallat",
                        "slug": "S.-Mallat",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Mallat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mallat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2356353,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b78626ce1a562c05b1c06f9c805e839f9760b9ab",
            "isKey": false,
            "numCitedBy": 20814,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Multiresolution representations are effective for analyzing the information content of images. The properties of the operator which approximates a signal at a given resolution were studied. It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/sup j/ (where j is an integer) can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions. In L/sup 2/(R), a wavelet orthonormal basis is a family of functions which is built by dilating and translating a unique function psi (x). This decomposition defines an orthogonal multiresolution representation called a wavelet representation. It is computed with a pyramidal algorithm based on convolutions with quadrature mirror filters. Wavelet representation lies between the spatial and Fourier domains. For images, the wavelet representation differentiates several spatial orientations. The application of this representation to data compression in image coding, texture discrimination and fractal analysis is discussed. >"
            },
            "slug": "A-Theory-for-Multiresolution-Signal-Decomposition:-Mallat",
            "title": {
                "fragments": [],
                "text": "A Theory for Multiresolution Signal Decomposition: The Wavelet Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the difference of information between the approximation of a signal at the resolutions 2/sup j+1/ and 2/Sup j/ can be extracted by decomposing this signal on a wavelet orthonormal basis of L/sup 2/(R/sup n/), the vector space of measurable, square-integrable n-dimensional functions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722325"
                        ],
                        "name": "J. Bonet",
                        "slug": "J.-Bonet",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Bonet",
                            "middleNames": [
                                "S.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bonet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1908692,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "18bc39207b4d24eabf9d98649db53563d9c2e3fd",
            "isKey": false,
            "numCitedBy": 726,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper outlines a technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled. In a two-phase process, the input texture is first analyzed by measuring the joint occurrence of texture discrimination features at multiple resolutions. In the second phase, a new texture is synthesized by sampling successive spatial frequency bands from the input texture, conditioned on the similar joint occurrence of features at lower spatial frequencies. Textures synthesized with this method more successfully capture the characteristics of input textures than do previous techniques."
            },
            "slug": "Multiresolution-sampling-procedure-for-analysis-and-Bonet",
            "title": {
                "fragments": [],
                "text": "Multiresolution sampling procedure for analysis and synthesis of texture images"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A technique for treating input texture images as probability density estimators from which new textures, with similar appearance and structural properties, can be sampled, which more successfully capture the characteristics of input textures than do previous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2972274"
                        ],
                        "name": "J. Knierim",
                        "slug": "J.-Knierim",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Knierim",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Knierim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7549580"
                        ],
                        "name": "D. V. Van Essen",
                        "slug": "D.-V.-Van-Essen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Van Essen",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. V. Van Essen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6913797,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "1beef8dc24a54f2afa1cea41363c042438ec4427",
            "isKey": false,
            "numCitedBy": 1081,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "1. We recorded responses from neurons in area V1 of the alert macaque monkey to textured patterns modeled after stimuli used in psychophysical experiments of pop-out. Neuronal responses to a single oriented line segment placed within a cell's classical receptive field (CRF) were compared with responses in which the center element was surrounded by rings of elements placed entirely outside the CRF. The orientations of the surround elements either matched the center element, were orthogonal to it, or were random. 2. The addition of the textured surround tended to suppress the response to the center element by an average of 34%. Overall, almost 80% of the 122 cells analyzed in detail were significantly suppressed by at least one of the texture surrounds. 3. Cells tended to respond more strongly to a stimulus in which there was a contrast in orientation between the center and surround than to a stimulus lacking such contrast. The average difference was 9% of the response to the optimally oriented center element alone. For the 32% of the cells showing a statistically significant orientation contrast effect, the average difference was 28%. 4. Both the general suppression and orientation contrast effects originated from surround regions at the ends of the center bar as well as regions along the sides of the center bar. 5. The amount of suppression induced by the texture surround decreased as the density of the texture elements decreased. 6. Both the general suppression and the orientation contrast effects appeared early in the population response to the stimuli. The general suppression effect took approximately 7 ms to develop, whereas the orientation contrast effect took 18-20 ms to develop. 7. These results are consistent with a possible functional role of V1 cells in the mediation of perceptual pop-out and in the segregation of texture borders. Possible anatomic substrates of the effects are discussed."
            },
            "slug": "Neuronal-responses-to-static-texture-patterns-in-V1-Knierim-Essen",
            "title": {
                "fragments": [],
                "text": "Neuronal responses to static texture patterns in area V1 of the alert macaque monkey."
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Responses from neurons in area V1 of the alert macaque monkey to textured patterns modeled after stimuli used in psychophysical experiments of pop- out are consistent with a possible functional role of V1 cells in the mediation of perceptual pop-out and in the segregation of texture borders."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of neurophysiology"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144067255"
                        ],
                        "name": "H. Sardana",
                        "slug": "H.-Sardana",
                        "structuredName": {
                            "firstName": "Harish",
                            "lastName": "Sardana",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sardana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51177873"
                        ],
                        "name": "M. F. Daemi",
                        "slug": "M.-F.-Daemi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Daemi",
                            "middleNames": [
                                "Farhang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. F. Daemi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143938284"
                        ],
                        "name": "M. K. Ibrahim",
                        "slug": "M.-K.-Ibrahim",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ibrahim",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. K. Ibrahim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10381108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bb02c583583dc2d76b4aad08f8b4558b5dd2219",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Global-description-of-edge-patterns-using-moments-Sardana-Daemi",
            "title": {
                "fragments": [],
                "text": "Global description of edge patterns using moments"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 784288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98b4d4e24aab57ab4e1124ff8106909050645cfa",
            "isKey": false,
            "numCitedBy": 16693,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices."
            },
            "slug": "Neural-networks-and-physical-systems-with-emergent-Hopfield",
            "title": {
                "fragments": [],
                "text": "Neural networks and physical systems with emergent collective computational abilities."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A model of a system having a large number of simple equivalent components, based on aspects of neurobiology but readily adapted to integrated circuits, produces a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718584"
                        ],
                        "name": "P. Angeline",
                        "slug": "P.-Angeline",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Angeline",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Angeline"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33047146"
                        ],
                        "name": "G. M. Saunders",
                        "slug": "G.-M.-Saunders",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Saunders",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. M. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fba6007d482db5fbe8cd6c3af90fe0922453e1d2",
            "isKey": false,
            "numCitedBy": 1068,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard methods for simultaneously inducing the structure and weights of recurrent neural networks limit every task to an assumed class of architectures. Such a simplification is necessary since the interactions between network structure and function are not well understood. Evolutionary computations, which include genetic algorithms and evolutionary programming, are population-based search methods that have shown promise in many similarly complex tasks. This paper argues that genetic algorithms are inappropriate for network acquisition and describes an evolutionary program, called GNARL, that simultaneously acquires both the structure and weights for recurrent networks. GNARL's empirical acquisition method allows for the emergence of complex behaviors and topologies that are potentially excluded by the artificial architectural constraints imposed in standard network induction methods."
            },
            "slug": "An-evolutionary-algorithm-that-constructs-recurrent-Angeline-Saunders",
            "title": {
                "fragments": [],
                "text": "An evolutionary algorithm that constructs recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that genetic algorithms are inappropriate for network acquisition and an evolutionary program is described, called GNARL, that simultaneously acquires both the structure and weights for recurrent networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228528"
                        ],
                        "name": "J. Terrillon",
                        "slug": "J.-Terrillon",
                        "structuredName": {
                            "firstName": "Jean-Christophe",
                            "lastName": "Terrillon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Terrillon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143906699"
                        ],
                        "name": "H. Fukamachi",
                        "slug": "H.-Fukamachi",
                        "structuredName": {
                            "firstName": "Hideo",
                            "lastName": "Fukamachi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fukamachi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49052113"
                        ],
                        "name": "S. Akamatsu",
                        "slug": "S.-Akamatsu",
                        "structuredName": {
                            "firstName": "Shigeru",
                            "lastName": "Akamatsu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Akamatsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707424"
                        ],
                        "name": "M. N. Shirazi",
                        "slug": "M.-N.-Shirazi",
                        "structuredName": {
                            "firstName": "Mahdad",
                            "lastName": "Shirazi",
                            "middleNames": [
                                "Nouri"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. N. Shirazi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39824480,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21522ac315abee52a50486ae4ff4c378f66fc337",
            "isKey": false,
            "numCitedBy": 474,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an analysis of the performance of two different skin chrominance models and of nine different chrominance spaces for the color segmentation and subsequent detection of human faces in two-dimensional static images. For each space, we use the single Gaussian model based on the Mahalanobis metric and a Gaussian mixture density model to segment faces from scene backgrounds. In the case of the mixture density model, the skin chrominance distribution is estimated by use of the expectation-maximisation (EM) algorithm. Feature extraction is performed on the segmented images by use of invariant Fourier-Mellin moments. A multilayer perceptron neural network (NN), with the invariant moments as the input vector, is then applied to distinguish faces from distractors. With the single Gaussian model, normalized color spaces are shown to produce the best segmentation results, and subsequently the highest rate of face detection. The results are comparable to those obtained with the more sophisticated mixture density model. However, the mixture density model improves the segmentation and face detection results significantly for most of the un-normalized color spaces. Ultimately, we show that, for each chrominance space, the detection efficiency depends on the capacity of each model to estimate the skin chrominance distribution and, most importantly, on the discriminability between skin and \"non-skin\" distributions."
            },
            "slug": "Comparative-performance-of-different-skin-models-of-Terrillon-Fukamachi",
            "title": {
                "fragments": [],
                "text": "Comparative performance of different skin chrominance models and chrominance spaces for the automatic detection of human faces in color images"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An analysis of the performance of two different skin chrominance models and of nine different chrominance spaces for the color segmentation and subsequent detection of human faces in two-dimensional static images shows that, for each chrominance space, the detection efficiency depends on the capacity of each model to estimate the skin Chrominance distribution and, most importantly, on the discriminability between skin and \"non-skin\" distributions."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085375589"
                        ],
                        "name": "H. Schneiderman",
                        "slug": "H.-Schneiderman",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Schneiderman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneiderman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733113"
                        ],
                        "name": "T. Kanade",
                        "slug": "T.-Kanade",
                        "structuredName": {
                            "firstName": "Takeo",
                            "lastName": "Kanade",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kanade"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12209481,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3565c5a65842f26091578b9d71d496cc1561239d",
            "isKey": false,
            "numCitedBy": 1292,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a statistical method for 3D object detection. We represent the statistics of both object appearance and \"non-object\" appearance using a product of histograms. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Our approach is to use many such histograms representing a wide variety of visual attributes. Using this method, we have developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithm that can reliably detect passenger cars over a wide range of viewpoints."
            },
            "slug": "A-statistical-method-for-3D-object-detection-to-and-Schneiderman-Kanade",
            "title": {
                "fragments": [],
                "text": "A statistical method for 3D object detection applied to faces and cars"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this method, this work has developed the first algorithm that can reliably detect human faces with out-of-plane rotation and the first algorithms thatCan reliably detect passenger cars over a wide range of viewpoints."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No.PR00662)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3219867"
                        ],
                        "name": "J. Hopfield",
                        "slug": "J.-Hopfield",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hopfield",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hopfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636368"
                        ],
                        "name": "C. Brody",
                        "slug": "C.-Brody",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Brody",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Brody"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14219816,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "406d968077fdb21f7d44e5b0c095ff1d66bcd329",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "A previous paper described a network of simple integrate-and-fire neurons that contained output neurons selective for specific spatiotemporal patterns of inputs; only experimental results were described. We now present the principles behind the operation of this network and discuss how these principles point to a general class of computational operations that can be carried out easily and naturally by networks of spiking neurons. Transient synchrony of the action potentials of a group of neurons is used to signal \"recognition\" of a space-time pattern across the inputs of those neurons. Appropriate synaptic coupling produces synchrony when the inputs to these neurons are nearly equal, leaving the neurons unsynchronized or only weakly synchronized for other input circumstances. When the input to this system comes from timed past events represented by decaying delay activity, the pattern of synaptic connections can be set such that synchronization occurs only for selected spatiotemporal patterns. We show how the recognition is invariant to uniform time warp and uniform intensity change of the input events. The fundamental recognition event is a transient collective synchronization, representing \"many neurons now agree,\" an event that is then detected easily by a cell with a small time constant. If such synchronization is used in neurobiological computation, its hallmark will be a brief burst of gamma-band electroencephalogram noise when and where such a recognition event or decision occurs."
            },
            "slug": "What-is-a-moment-Transient-synchrony-as-a-mechanism-Hopfield-Brody",
            "title": {
                "fragments": [],
                "text": "What is a moment? Transient synchrony as a collective mechanism for spatiotemporal integration."
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The principles behind the operation of a network of simple integrate-and-fire neurons that contained output neurons selective for specific spatiotemporal patterns of inputs are presented and it is shown how the recognition is invariant to uniform time warp and uniform intensity change of the input events."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748557"
                        ],
                        "name": "P. Smolensky",
                        "slug": "P.-Smolensky",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Smolensky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smolensky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 533055,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f7476037408ac3d993f5088544aab427bc319c1",
            "isKey": false,
            "numCitedBy": 1949,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : At this early stage in the development of cognitive science, methodological issues are both open and central. There may have been times when developments in neuroscience, artificial intelligence, or cognitive psychology seduced researchers into believing that their discipline was on the verge of discovering the secret of intelligence. But a humbling history of hopes disappointed has produced the realization that understanding the mind will challenge the power of all these methodologies combined. The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis. The success of cognitive science, like that of many other sciences, will, I believe, depend upon the construction of a solid body of theoretical results: results that express in a mathematical language the conceptual insights of the field; results that squeeze all possible implications out of those insights by exploiting powerful mathematical techniques. This body of results, which I will call the theory of information processing, exists because information is a concept that lends itself to mathematical formalization. One part of the theory of information processing is already well-developed. The classical theory of computation provides powerful and elegant results about the notion of effective procedure, including languages for precisely expressing them and theoretical machines for realizing them."
            },
            "slug": "Information-processing-in-dynamical-systems:-of-Smolensky",
            "title": {
                "fragments": [],
                "text": "Information processing in dynamical systems: foundations of harmony theory"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The work reported in this chapter rests on the conviction that a methodology that has a crucial role to play in the development of cognitive science is mathematical analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468098"
                        ],
                        "name": "M. M\u00f8ller",
                        "slug": "M.-M\u00f8ller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00f8ller",
                            "middleNames": [
                                "Fodslette"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00f8ller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8029054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f4a097b2131784d7ac3fc3c47d1e9283e9ac207",
            "isKey": false,
            "numCitedBy": 3758,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-scaled-conjugate-gradient-algorithm-for-fast-M\u00f8ller",
            "title": {
                "fragments": [],
                "text": "A scaled conjugate gradient algorithm for fast supervised learning"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723877"
                        ],
                        "name": "V. Govindaraju",
                        "slug": "V.-Govindaraju",
                        "structuredName": {
                            "firstName": "Venu",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Govindaraju"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29332361,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6275f9f4208e91bece3e31312717fb5ffdbdf08c",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The human face is an object that is easily located in complex scenes by infants and adults alike. Yet the development of an automated system to perform this task is extremely challenging. An attempt to solve this problem raises two important issues in object location. First, natural objects such as human faces tend to have boundaries which are not exactly described by analytical functions. Second, the object of interest (face) could occur in a scene in various sizes, thus requiring the use of scale independent techniques which can detect instances of the object at all scales.Although, the task of identifying a well-framed face (as one of a set of labeled faces) has been well researched, the task of locating a face in a natural scene is relatively unexplored. We present a computational theory for locating human faces in scenes with certain constraints. The theory will be validated by experiments confined to instances where people's faces are the primary subject of the scene, occlusion is minimal, and the faces contrast well against the background."
            },
            "slug": "Locating-human-faces-in-photographs-Govindaraju",
            "title": {
                "fragments": [],
                "text": "Locating human faces in photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A computational theory for locating human faces in scenes with certain constraints is presented and will be validated by experiments confined to instances where people's faces are the primary subject of the scene, occlusion is minimal, and the faces contrast well against the background."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143764011"
                        ],
                        "name": "R. Wong",
                        "slug": "R.-Wong",
                        "structuredName": {
                            "firstName": "Rachel",
                            "lastName": "Wong",
                            "middleNames": [
                                "O.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Wong"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39643418,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "7f14b5dba63a2fb39074aa46f87e7420c6c7e502",
            "isKey": false,
            "numCitedBy": 544,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "Many pathways in the developing visual system are restructured and become highly organized even before vision occurs. Yet the developmental processes underlying the remodeling of visual connectivity are crucially dependent on retinal activity. Surprisingly, the immature and light-insensitive retina spontaneously generates a pattern of rhythmic bursting activity during the period when the connectivity patterns of retinal ganglion cells are shaped. Spatially, the activity is seen to spread across the retina in the form of waves that bring into synchrony the bursts of neighboring cells. Waves are present in the developing retina of higher and lower vertebrates, which suggests that this form of activity may be a common and fundamental mechanism employed in the activity-dependent refinement of early patterns of visual connections. Unraveling the cues encoded by the waves promises to provide important insights into how interactions driven by specific patterns of activity could lead to the modification of connectivity during development."
            },
            "slug": "Retinal-waves-and-visual-system-development.-Wong",
            "title": {
                "fragments": [],
                "text": "Retinal waves and visual system development."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Waves are present in the developing retina of higher and lower vertebrates, which suggests that this form of activity may be a common and fundamental mechanism employed in the activity-dependent refinement of early patterns of visual connections."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of neuroscience"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31484468"
                        ],
                        "name": "M. Pfister",
                        "slug": "M.-Pfister",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Pfister",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pfister"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144870555"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13458399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "133e4c05d9cc27e367d0aef834c39580b437efd8",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents an off-line method for recognizing handwritten digits. Structural information and quantitative features are extracted from images of isolated numerals to be classified by a hybrid multi-stage recognition system. Feature extraction starts with the raw pixel-image and derives more structured representations like line-drawings and attributed structural graphs. Classification is done in two steps: 1) the structural graph is matched to prototypes; 2) for each prototype there is a neural classifier which has been trained to distinguish digits represented by the same graph-structure. The performance of the described system is evaluated on two large databases (provided by SIEMENS AG and NIST) and is compared to other systems. Finally, the combination of the described system and a time-delay neural network classifier is discussed. The experimental results indicate that there is an advantage in using structural information to enhance an unstructured neural classifier."
            },
            "slug": "Recognition-of-handwritten-digits-using-structural-Behnke-Pfister",
            "title": {
                "fragments": [],
                "text": "Recognition of handwritten digits using structural information"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The experimental results indicate that there is an advantage in using structural information to enhance an unstructured neural classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of International Conference on Neural Networks (ICNN'97)"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392813066"
                        ],
                        "name": "Tanaka Ungerleider",
                        "slug": "Tanaka-Ungerleider",
                        "structuredName": {
                            "firstName": "Tanaka",
                            "lastName": "Ungerleider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanaka Ungerleider"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121739077"
                        ],
                        "name": "G. Perrett",
                        "slug": "G.-Perrett",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "Perrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Perrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4729186"
                        ],
                        "name": "H. Sakata",
                        "slug": "H.-Sakata",
                        "structuredName": {
                            "firstName": "Honami",
                            "lastName": "Sakata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sakata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15204163,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "9cc9f9c3df44dca5e6d0e1d4d9d68f37a95ec7c1",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 202,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-and-movement-mechanisms-in-the-cerebral-Ungerleider-Perrett",
            "title": {
                "fragments": [],
                "text": "Vision and movement mechanisms in the cerebral cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Trends in Cognitive Sciences"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391278"
                        ],
                        "name": "Richard Hans Robert Hahnloser",
                        "slug": "Richard-Hans-Robert-Hahnloser",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hahnloser",
                            "middleNames": [
                                "Hans",
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Hans Robert Hahnloser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1994245"
                        ],
                        "name": "R. Sarpeshkar",
                        "slug": "R.-Sarpeshkar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sarpeshkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sarpeshkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38086808"
                        ],
                        "name": "M. Mahowald",
                        "slug": "M.-Mahowald",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Mahowald",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahowald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742758"
                        ],
                        "name": "R. Douglas",
                        "slug": "R.-Douglas",
                        "structuredName": {
                            "firstName": "Rodney",
                            "lastName": "Douglas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Douglas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4399014,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "03de8578480c53677c484e1facfced74f4f5b045",
            "isKey": false,
            "numCitedBy": 998,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital circuits such as the flip-flop use feedback to achieve multi-stability and nonlinearity to restore signals to logical levels, for example 0 and 1. Analogue feedback circuits are generally designed to operate linearly, so that signals are over a range, and the response is unique. By contrast, the response of cortical circuits to sensory stimulation can be both multistable and graded. We propose that the neocortex combines digital selection of an active set of neurons with analogue response by dynamically varying the positive feedback inherent in its recurrent connections. Strong positive feedback causes differential instabilities that drive the selection of a set of active neurons under the constraints embedded in the synaptic weights. Once selected, the active neurons generate weaker, stable feedback that provides analogue amplification of the input. Here we present our model of cortical processing as an electronic circuit that emulates this hybrid operation, and so is able to perform computations that are similar to stimulus selection, gain modulation and spatiotemporal pattern generation in the neocortex."
            },
            "slug": "Digital-selection-and-analogue-amplification-in-a-Hahnloser-Sarpeshkar",
            "title": {
                "fragments": [],
                "text": "Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The model of cortical processing is presented as an electronic circuit that emulates this hybrid operation, and so is able to perform computations that are similar to stimulus selection, gain modulation and spatiotemporal pattern generation in the neocortex."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468098"
                        ],
                        "name": "M. M\u00f8ller",
                        "slug": "M.-M\u00f8ller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "M\u00f8ller",
                            "middleNames": [
                                "Fodslette"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M\u00f8ller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9963836,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0631a99f68cb0c159b15f1cbbaa894bc9f5a738",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel algorithm combining the good properties of offline and online algorithms is introduced. The efficiency of supervised learning algorithms on small-scale problems does not necessarily scale up to large-scale problems. The redundancy of large training sets is reflected as redundancy gradient vectors in the network. Accumulating these gradient vectors implies redundant computations. In order to avoid these redundant computations a learning algorithm has to be able to update weights independently of the size of the training set. The stochastic learning algorithm proposed, the stochastic scaled conjugate gradient (SSCG) algorithm, has this property. Experimentally, it is shown that SSCG converges faster than the online backpropagation algorithm on the nettalk problem.<<ETX>>"
            },
            "slug": "Supervised-learning-on-large-redundant-training-M\u00f8ller",
            "title": {
                "fragments": [],
                "text": "Supervised learning on large redundant training sets"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A novel algorithm combining the good properties of offline and online algorithms is introduced, the stochastic scaled conjugate gradient (SSCG), and it is shown that SSCG converges faster than the online backpropagation algorithm on the nettalk problem."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks for Signal Processing II Proceedings of the 1992 IEEE Workshop"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396681"
                        ],
                        "name": "D. Eck",
                        "slug": "D.-Eck",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Eck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7541174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "850e994c086e95c8d8c2ba3c90e53104a0fa709e",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In general music composed by recurrent neural networks (RNNs) suffers from a lack of global structure. Though networks can learn note-by-note transition probabilities and even reproduce phrases, they have been unable to learn an entire musical form and use that knowledge to guide composition. In this study, we describe model details and present experimental results showing that LSTM successfully learns a form of blues music and is able to compose novel (and some listeners believe pleasing) melodies in that style. Remarkably, once the network has found the relevant structure it does not drift from it: LSTM is able to play the blues with good timing and proper structure as long as one is willing to listen."
            },
            "slug": "Learning-the-Long-Term-Structure-of-the-Blues-Eck-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Learning the Long-Term Structure of the Blues"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "LSTM is able to play the blues with good timing and proper structure as long as one is willing to listen and once the network has found the relevant structure it does not drift from it."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50263663"
                        ],
                        "name": "D. Boswell",
                        "slug": "D.-Boswell",
                        "structuredName": {
                            "firstName": "Dustin",
                            "lastName": "Boswell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Boswell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18986102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea2ea7c6e280c1cfb67ee38ea63a327b1ba3ca36",
            "isKey": false,
            "numCitedBy": 2113,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Machines (SVM\u2019s) are a relatively new learning method used for binary classification. The basic idea is to find a hyperplane which separates the d-dimensional data perfectly into its two classes. However, since example data is often not linearly separable, SVM\u2019s introduce the notion of a \u201ckernel induced feature space\u201d which casts the data into a higher dimensional space where the data is separable. Typically, casting into such a space would cause problems computationally, and with overfitting. The key insight used in SVM\u2019s is that the higher-dimensional space doesn\u2019t need to be dealt with directly (as it turns out, only the formula for the dot-product in that space is needed), which eliminates the above concerns. Furthermore, the VC-dimension (a measure of a system\u2019s likelihood to perform well on unseen data) of SVM\u2019s can be explicitly calculated, unlike other learning methods like neural networks, for which there is no measure. Overall, SVM\u2019s are intuitive, theoretically wellfounded, and have shown to be practically successful. SVM\u2019s have also been extended to solve regression tasks (where the system is trained to output a numerical value, rather than \u201cyes/no\u201d classification)."
            },
            "slug": "Introduction-to-Support-Vector-Machines-Boswell",
            "title": {
                "fragments": [],
                "text": "Introduction to Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Support Vector Machines (SVM\u2019s) are intuitive, theoretically wellfounded, and have shown to be practically successful."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37293615"
                        ],
                        "name": "T. Nazir",
                        "slug": "T.-Nazir",
                        "structuredName": {
                            "firstName": "Tatjana",
                            "lastName": "Nazir",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nazir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398984373"
                        ],
                        "name": "J. O'Regan",
                        "slug": "J.-O'Regan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "O'Regan",
                            "middleNames": [
                                "Kevin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. O'Regan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9010837,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "24caeb44501537d9afa5f4f61fe5e28f914ca234",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Four experiments were conducted to study the nature of visual translation invariance in humans. In all the experiments, subjects were trained to discriminate between a previously unknown target and two non-target distractors presented at a fixed retinal location to one side of the fixation point. In a subsequent test phase, this performance was compared with the performance when the patterns were presented either centrally at the fixation point or at a location on the other side of the fixation point, opposite to the location where the patterns were learned, but where acuity was identical to what it was at the learned location. Two different experimental paradigms were used. One used an eye movement control device (Experiment 1) to ensure the eye could not move relative to the patterns to be learned. In the other three experiments, presentation duration of the patterns was restricted to a short enough period to preclude eye movements. During the training period in Experiments 1 and 2, presentation location of the patterns was centered at 2.4 deg in the periphery, whereas in Experiments 3 and 4 presentation eccentricity was reduced to 0.86 and 0.49 deg. In all four experiments performance dropped when the pattern had to be recognized at new test positions. This result suggests that the visual system does not apply a global transposition transformation to the retinal image to compensate for translations. We propose that, instead, it decomposes the image into simple features which themselves are more-or-less translation invariant. If in a given task, patterns can be discriminated using these simple features, then translation invariance will occur. If not, then translation invariance will fail or be incomplete."
            },
            "slug": "Some-results-on-translation-invariance-in-the-human-Nazir-O'Regan",
            "title": {
                "fragments": [],
                "text": "Some results on translation invariance in the human visual system."
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The result suggests that the visual system does not apply a global transposition transformation to the retinal image to compensate for translations, and it is proposed that the image decomposes the image into simple features which themselves are more-or-less translation invariant."
            },
            "venue": {
                "fragments": [],
                "text": "Spatial vision"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3958369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8da1dda34ecc96263102181448c94ec7d645d085",
            "isKey": false,
            "numCitedBy": 6387,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is demonstrated that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2173900"
                        ],
                        "name": "K. Messer",
                        "slug": "K.-Messer",
                        "structuredName": {
                            "firstName": "Kieron",
                            "lastName": "Messer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Messer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145564537"
                        ],
                        "name": "Jiri Matas",
                        "slug": "Jiri-Matas",
                        "structuredName": {
                            "firstName": "Jiri",
                            "lastName": "Matas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiri Matas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145801638"
                        ],
                        "name": "J. Kittler",
                        "slug": "J.-Kittler",
                        "structuredName": {
                            "firstName": "Josef",
                            "lastName": "Kittler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kittler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678373"
                        ],
                        "name": "J. Luettin",
                        "slug": "J.-Luettin",
                        "structuredName": {
                            "firstName": "Juergen",
                            "lastName": "Luettin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Luettin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2488626"
                        ],
                        "name": "G. Ma\u00eetre",
                        "slug": "G.-Ma\u00eetre",
                        "structuredName": {
                            "firstName": "Gilbert",
                            "lastName": "Ma\u00eetre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ma\u00eetre"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15312675,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b62628ac06bbac998a3ab825324a41a11bc3a988",
            "isKey": false,
            "numCitedBy": 1458,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Keywords: vision Reference EPFL-CONF-82502 URL: ftp://ftp.idiap.ch/pub/papers/vision/avbpa99.pdf Record created on 2006-03-10, modified on 2017-05-10"
            },
            "slug": "XM2VTSDB:-The-Extended-M2VTS-Database-Messer-Matas",
            "title": {
                "fragments": [],
                "text": "XM2VTSDB: The Extended M2VTS Database"
            },
            "tldr": {
                "abstractSimilarityScore": 31,
                "text": "This poster presents a poster presenting a probabilistic procedure for estimating the response of the immune system to laser-spot assisted surgery to treat central giant cell granuloma."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2308463"
                        ],
                        "name": "Salah El Hihi",
                        "slug": "Salah-El-Hihi",
                        "structuredName": {
                            "firstName": "Salah",
                            "lastName": "Hihi",
                            "middleNames": [
                                "El"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Salah El Hihi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2843869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b13813b49f160e1a2010c44bd4fb3d09a28446e3",
            "isKey": false,
            "numCitedBy": 332,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have already shown that extracting long-term dependencies from sequential data is difficult, both for determimstic dynamical systems such as recurrent networks, and probabilistic models such as hidden Markov models (HMMs) or input/output hidden Markov models (IOHMMs). In practice, to avoid this problem, researchers have used domain specific a-priori knowledge to give meaning to the hidden or state variables representing past context. In this paper, we propose to use a more general type of a-priori knowledge, namely that the temporal dependencies are structured hierarchically. This implies that long-term dependencies are represented by variables with a long time scale. This principle is applied to a recurrent network which includes delays and multiple time scales. Experiments confirm the advantages of such structures. A similar approach is proposed for HMMs and IOHMMs."
            },
            "slug": "Hierarchical-Recurrent-Neural-Networks-for-Hihi-Bengio",
            "title": {
                "fragments": [],
                "text": "Hierarchical Recurrent Neural Networks for Long-Term Dependencies"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to use a more general type of a-priori knowledge, namely that the temporal dependencies are structured hierarchically, which implies that long-term dependencies are represented by variables with a long time scale."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868430"
                        ],
                        "name": "P. Kellman",
                        "slug": "P.-Kellman",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Kellman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kellman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2252285"
                        ],
                        "name": "E. Spelke",
                        "slug": "E.-Spelke",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Spelke",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Spelke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13558122,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "d68fe08468d7c402bbd1c771d73853f6b9345c43",
            "isKey": false,
            "numCitedBy": 631,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perception-of-partly-occluded-objects-in-infancy-Kellman-Spelke",
            "title": {
                "fragments": [],
                "text": "Perception of partly occluded objects in infancy"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Psychology"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43701174,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8515604037444b3f079a9d328b0c560f33da0a19",
            "isKey": false,
            "numCitedBy": 1428,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major drawbacks of orthogonal wavelet transforms is their lack of translation invariance: the content of wavelet subbands is unstable under translations of the input signal. Wavelet transforms are also unstable with respect to dilations of the input signal and, in two dimensions, rotations of the input signal. The authors formalize these problems by defining a type of translation invariance called shiftability. In the spatial domain, shiftability corresponds to a lack of aliasing; thus, the conditions under which the property holds are specified by the sampling theorem. Shiftability may also be applied in the context of other domains, particularly orientation and scale. Jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored. Two examples of jointly shiftable transforms are designed and implemented: a 1-D transform that is jointly shiftable in position and scale, and a 2-D transform that is jointly shiftable in position and orientation. The usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated. >"
            },
            "slug": "Shiftable-multiscale-transforms-Simoncelli-Freeman",
            "title": {
                "fragments": [],
                "text": "Shiftable multiscale transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Two examples of jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored and the usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48163054"
                        ],
                        "name": "M. R. Turner",
                        "slug": "M.-R.-Turner",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Turner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. R. Turner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 25312829,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "54c776555fcdd379e87efc9b28a760d94e17182d",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 86,
            "paperAbstract": {
                "fragments": [],
                "text": "A 2D Gabor filter can be realized as a sinusoidal plane wave of some frequency and orientation within a two dimensional Gaussian envelope. Its spatial extent, frequency and orientation preferences as well as bandwidths are easily controlled by the parameters used in generating the filters. However, there is an \u201cuncertainty relation\u201d associated with linear filters which limits the resolution simultaneously attainable in space and frequency. Daugman (1985) has determined that 2D Gabor filters are members of a class of functions achieving optimal joint resolution in the 2D space and 2D frequency domains. They have also been found to be a good model for two dimensional receptive fields of simple cells in the striate cortex (Jones 1985; Jones et al. 1985).The characteristic of optimal joint resolution in both space and frequency suggests that these filters are appropriate operators for tasks requiring simultaneous measurement in these domains. Texture discrimination is such a task. Computer application of a set of Gabor filters to a variety of textures found to be preattentively discriminable produces results in which differently textured regions are distinguished by firstorder differences in the values measured by the filters. This ability to reduce the statistical complexity distinguishing differently textured region as well as the sensitivity of these filters to certain types of local features suggest that Gabor functions can act as detectors of certain \u201ctexton\u201d types. The performance of the computer models suggests that cortical neurons with Gabor like receptive fields may be involved in preattentive texture discrimination."
            },
            "slug": "Texture-discrimination-by-Gabor-functions-Turner",
            "title": {
                "fragments": [],
                "text": "Texture discrimination by Gabor functions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The performance of the computer models suggests that cortical neurons with Gabor like receptive fields may be involved in preattentive texture discrimination and Gabor functions can act as detectors of certain \u201ctexton\u201d types."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115899190"
                        ],
                        "name": "C. Lee",
                        "slug": "C.-Lee",
                        "structuredName": {
                            "firstName": "Choong",
                            "lastName": "Lee",
                            "middleNames": [
                                "Hwan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109319119"
                        ],
                        "name": "Jun Sung Kim",
                        "slug": "Jun-Sung-Kim",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Kim",
                            "middleNames": [
                                "Sung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Sung Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400218066"
                        ],
                        "name": "Kyu Ho Park",
                        "slug": "Kyu-Ho-Park",
                        "structuredName": {
                            "firstName": "Kyu Ho",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyu Ho Park"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 205015249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2350cb194cd3f29ff319613859159c54dfb18577",
            "isKey": false,
            "numCitedBy": 144,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-human-face-location-in-a-complex-using-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Automatic human face location in a complex background using motion and color information"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115651440"
                        ],
                        "name": "Daniel D. Lee",
                        "slug": "Daniel-D.-Lee",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lee",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel D. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2095855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6fb07b90b7fd2785ffec0da1069e75c53f7313c2",
            "isKey": false,
            "numCitedBy": 7651,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Non-negative matrix factorization (NMF) has previously been shown to be a useful decomposition for multivariate data. Two different multiplicative algorithms for NMF are analyzed. They differ only slightly in the multiplicative factor used in the update rules. One algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized Kullback-Leibler divergence. The monotonic convergence of both algorithms can be proven using an auxiliary function analogous to that used for proving convergence of the Expectation-Maximization algorithm. The algorithms can also be interpreted as diagonally rescaled gradient descent, where the rescaling factor is optimally chosen to ensure convergence."
            },
            "slug": "Algorithms-for-Non-negative-Matrix-Factorization-Lee-Seung",
            "title": {
                "fragments": [],
                "text": "Algorithms for Non-negative Matrix Factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two different multiplicative algorithms for non-negative matrix factorization are analyzed and one algorithm can be shown to minimize the conventional least squares error while the other minimizes the generalized Kullback-Leibler divergence."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391278"
                        ],
                        "name": "Richard Hans Robert Hahnloser",
                        "slug": "Richard-Hans-Robert-Hahnloser",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Hahnloser",
                            "middleNames": [
                                "Hans",
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Hans Robert Hahnloser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 8510723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a09ef3a49654fdbc7c446884369f8c9ca542b012",
            "isKey": false,
            "numCitedBy": 123,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-piecewise-analysis-of-networks-of-linear-Hahnloser",
            "title": {
                "fragments": [],
                "text": "On the piecewise analysis of networks of linear threshold neurons"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709392"
                        ],
                        "name": "D. Donoho",
                        "slug": "D.-Donoho",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Donoho",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Donoho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364792"
                        ],
                        "name": "I. Johnstone",
                        "slug": "I.-Johnstone",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Johnstone",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Johnstone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11995267,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8cc9918add61ee5ef3b848aba9646169cc5e364e",
            "isKey": false,
            "numCitedBy": 4682,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract We attempt to recover a function of unknown smoothness from noisy sampled data. We introduce a procedure, SureShrink, that suppresses noise by thresholding the empirical wavelet coefficients. The thresholding is adaptive: A threshold level is assigned to each dyadic resolution level by the principle of minimizing the Stein unbiased estimate of risk (Sure) for threshold estimates. The computational effort of the overall procedure is order N \u00b7 log(N) as a function of the sample size N. SureShrink is smoothness adaptive: If the unknown function contains jumps, then the reconstruction (essentially) does also; if the unknown function has a smooth piece, then the reconstruction is (essentially) as smooth as the mother wavelet will allow. The procedure is in a sense optimally smoothness adaptive: It is near minimax simultaneously over a whole interval of the Besov scale; the size of this interval depends on the choice of mother wavelet. We know from a previous paper by the authors that traditional smoot..."
            },
            "slug": "Adapting-to-Unknown-Smoothness-via-Wavelet-Donoho-Johnstone",
            "title": {
                "fragments": [],
                "text": "Adapting to Unknown Smoothness via Wavelet Shrinkage"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143602141"
                        ],
                        "name": "M. Kass",
                        "slug": "M.-Kass",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809905"
                        ],
                        "name": "A. Witkin",
                        "slug": "A.-Witkin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Witkin",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Witkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750924"
                        ],
                        "name": "Demetri Terzopoulos",
                        "slug": "Demetri-Terzopoulos",
                        "structuredName": {
                            "firstName": "Demetri",
                            "lastName": "Terzopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Demetri Terzopoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12849354,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "9394a5d5adcb626128b6a42c8810b9505a3c6487",
            "isKey": false,
            "numCitedBy": 15501,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "A snake is an energy-minimizing spline guided by external constraint forces and influenced by image forces that pull it toward features such as lines and edges. Snakes are active contour models: they lock onto nearby edges, localizing them accurately. Scale-space continuation can be used to enlarge the capture region surrounding a feature. Snakes provide a unified account of a number of visual problems, including detection of edges, lines, and subjective contours; motion tracking; and stereo matching. We have used snakes successfully for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest."
            },
            "slug": "Snakes:-Active-contour-models-Kass-Witkin",
            "title": {
                "fragments": [],
                "text": "Snakes: Active contour models"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work uses snakes for interactive interpretation, in which user-imposed constraint forces guide the snake near features of interest, and uses scale-space continuation to enlarge the capture region surrounding a feature."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152353"
                        ],
                        "name": "O. Jesorsky",
                        "slug": "O.-Jesorsky",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Jesorsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Jesorsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2661823"
                        ],
                        "name": "K. Kirchberg",
                        "slug": "K.-Kirchberg",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Kirchberg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kirchberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857160"
                        ],
                        "name": "Robert Frischholz",
                        "slug": "Robert-Frischholz",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Frischholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Frischholz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2274476,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4053e3423fb70ad9140ca89351df49675197196a",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The localization of human faces in digital images is a fundamental step in the process of face recognition. This paper presents a shape comparison approach to achieve fast, accurate face detection that is robust to changes in illumination and background. The proposed method is edge-based and works on grayscale still images. The Hausdorff distance is used as a similarity measure between a general face model and possible instances of the object within the image. The paper describes an efficient implementation, making this approach suitable for real-time applications. A two-step process that allows both coarse detection and exact localization of faces is presented. Experiments were performed on a large test set base and rated with a new validation measurement."
            },
            "slug": "Robust-Face-Detection-Using-the-Hausdorff-Distance-Jesorsky-Kirchberg",
            "title": {
                "fragments": [],
                "text": "Robust Face Detection Using the Hausdorff Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A two-step process that allows both coarse detection and exact localization of faces is presented and an efficient implementation is described, making this approach suitable for real-time applications."
            },
            "venue": {
                "fragments": [],
                "text": "AVBPA"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32747148"
                        ],
                        "name": "A. Kokaram",
                        "slug": "A.-Kokaram",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Kokaram",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kokaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708961"
                        ],
                        "name": "S. Godsill",
                        "slug": "S.-Godsill",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Godsill",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Godsill"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 568502,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "4be8400c613a3a75863c9a3e986e0c701f126ca3",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Image sequence restoration has been steadily gaining in importance with the arrival of digital video broadcasting. Automated treatment of archived video material typically involves dealing with replacement noise in the form of 'blotches' with varying intensity levels and additive 'grain' noise. In the case of replacement noise the problem is essentially one of missing data which must be detected and then reconstructed based upon surrounding spatio- temporal information, while the additive noise can be treated as a noise reduction problem. This paper introduces a fully Bayesian specification of the problem, Markov chain Monte Carlo methodology is applied to the joint detection and removal of both replacement and additive noise components. The work presented builds upon the Bayesian image detection/interpolation methods developed in including now the ability to reduce noise in an image sequence as well as reconstruct the image intensity information within missing regions."
            },
            "slug": "Joint-noise-reduction,-motion-estimation,-missing-Kokaram-Godsill",
            "title": {
                "fragments": [],
                "text": "Joint noise reduction, motion estimation, missing data reconstruction, and model parameter estimation for degraded motion pictures"
            },
            "venue": {
                "fragments": [],
                "text": "Optics & Photonics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700994"
                        ],
                        "name": "R. Battiti",
                        "slug": "R.-Battiti",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Battiti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Battiti"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27960650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbf6f07e699587c8d52faf829a289f8cbc7f11a5",
            "isKey": false,
            "numCitedBy": 1216,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "On-line first-order backpropagation is sufficiently fast and effective for many large-scale classification problems but for very high precision mappings, batch processing may be the method of choice. This paper reviews first- and second-order optimization methods for learning in feedforward neural networks. The viewpoint is that of optimization: many methods can be cast in the language of optimization techniques, allowing the transfer to neural nets of detailed results about computational complexity and safety procedures to ensure convergence and to avoid numerical problems. The review is not intended to deliver detailed prescriptions for the most appropriate methods in specific applications, but to illustrate the main characteristics of the different methods and their mutual relations."
            },
            "slug": "First-and-Second-Order-Methods-for-Learning:-and-Battiti",
            "title": {
                "fragments": [],
                "text": "First- and Second-Order Methods for Learning: Between Steepest Descent and Newton's Method"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "First- and second-order optimization methods for learning in feedforward neural networks are reviewed to illustrate the main characteristics of the different methods and their mutual relations."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145326760"
                        ],
                        "name": "H. Braun",
                        "slug": "H.-Braun",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Braun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Braun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16848428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "916ceefae4b11dadc3ee754ce590381c568c90de",
            "isKey": false,
            "numCitedBy": 4443,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A learning algorithm for multilayer feedforward networks, RPROP (resilient propagation), is proposed. To overcome the inherent disadvantages of pure gradient-descent, RPROP performs a local adaptation of the weight-updates according to the behavior of the error function. Contrary to other adaptive techniques, the effect of the RPROP adaptation process is not blurred by the unforeseeable influence of the size of the derivative, but only dependent on the temporal behavior of its sign. This leads to an efficient and transparent adaptation process. The capabilities of RPROP are shown in comparison to other adaptive techniques.<<ETX>>"
            },
            "slug": "A-direct-adaptive-method-for-faster-backpropagation-Riedmiller-Braun",
            "title": {
                "fragments": [],
                "text": "A direct adaptive method for faster backpropagation learning: the RPROP algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A learning algorithm for multilayer feedforward networks, RPROP (resilient propagation), is proposed that performs a local adaptation of the weight-updates according to the behavior of the error function to overcome the inherent disadvantages of pure gradient-descent."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4571,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6134427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aab43c9c33af00b718cf2ae374b861d49862a563",
            "isKey": false,
            "numCitedBy": 15727,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine Learning is the study of methods for programming computers to learn. Computers are applied to a wide range of tasks, and for most of these it is relatively easy for programmers to design and implement the necessary software. However, there are many tasks for which this is difficult or impossible. These can be divided into four general categories. First, there are problems for which there exist no human experts. For example, in modern automated manufacturing facilities, there is a need to predict machine failures before they occur by analyzing sensor readings. Because the machines are new, there are no human experts who can be interviewed by a programmer to provide the knowledge necessary to build a computer system. A machine learning system can study recorded data and subsequent machine failures and learn prediction rules. Second, there are problems where human experts exist, but where they are unable to explain their expertise. This is the case in many perceptual tasks, such as speech recognition, hand-writing recognition, and natural language understanding. Virtually all humans exhibit expert-level abilities on these tasks, but none of them can describe the detailed steps that they follow as they perform them. Fortunately, humans can provide machines with examples of the inputs and correct outputs for these tasks, so machine learning algorithms can learn to map the inputs to the outputs. Third, there are problems where phenomena are changing rapidly. In finance, for example, people would like to predict the future behavior of the stock market, of consumer purchases, or of exchange rates. These behaviors change frequently, so that even if a programmer could construct a good predictive computer program, it would need to be rewritten frequently. A learning program can relieve the programmer of this burden by constantly modifying and tuning a set of learned prediction rules. Fourth, there are applications that need to be customized for each computer user separately. Consider, for example, a program to filter unwanted electronic mail messages. Different users will need different filters. It is unreasonable to expect each user to program his or her own rules, and it is infeasible to provide every user with a software engineer to keep the rules up-to-date. A machine learning system can learn which mail messages the user rejects and maintain the filtering rules automatically. Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis. Statistics focuses on understanding the phenomena that have generated the data, often with the goal of testing different hypotheses about those phenomena. Data mining seeks to find patterns in the data that are understandable by people. Psychological studies of human learning aspire to understand the mechanisms underlying the various learning behaviors exhibited by people (concept learning, skill acquisition, strategy change, etc.)."
            },
            "slug": "Machine-learning-Dietterich",
            "title": {
                "fragments": [],
                "text": "Machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47814225"
                        ],
                        "name": "Shi-Hong Jeng",
                        "slug": "Shi-Hong-Jeng",
                        "structuredName": {
                            "firstName": "Shi-Hong",
                            "lastName": "Jeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shi-Hong Jeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704678"
                        ],
                        "name": "H. Liao",
                        "slug": "H.-Liao",
                        "structuredName": {
                            "firstName": "Hong-Yuan",
                            "lastName": "Liao",
                            "middleNames": [
                                "Mark"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3203056"
                        ],
                        "name": "Chin-Chuan Han",
                        "slug": "Chin-Chuan-Han",
                        "structuredName": {
                            "firstName": "Chin-Chuan",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chin-Chuan Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40037860"
                        ],
                        "name": "M. Chern",
                        "slug": "M.-Chern",
                        "structuredName": {
                            "firstName": "Ming-Yang",
                            "lastName": "Chern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Chern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108924004"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Yao",
                            "lastName": "Liu",
                            "middleNames": [
                                "Tsorng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 42126886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b60030b334f9fae4f2c8744e024898ec83dc0e59",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Facial-feature-detection-using-geometrical-face-An-Jeng-Liao",
            "title": {
                "fragments": [],
                "text": "Facial feature detection using geometrical face model: An efficient approach"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2797623"
                        ],
                        "name": "H. Siegelmann",
                        "slug": "H.-Siegelmann",
                        "structuredName": {
                            "firstName": "Hava",
                            "lastName": "Siegelmann",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Siegelmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790264"
                        ],
                        "name": "Eduardo Sontag",
                        "slug": "Eduardo-Sontag",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Sontag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eduardo Sontag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44597102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a49498e51840165d55b6badd4b52e34d17860bc0",
            "isKey": false,
            "numCitedBy": 834,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper deals with finite networks which consist of interconnections of synchronously evolving processors. Each processor updates its state by applying a \u201csigmoidal\u201d scalar nonlinearity to a linear combination of the previous states of all units. We prove that one may simulate all Turing Machines by rational nets. In particular, one can do this in linear time, and there is a net made up of about 1,000 processors which computes a universal partial-recursive function. Products (high order nets) are not required, contrary to what had been stated in the literature. Furthermore, we assert a similar theorem about non-deterministic Turing Machines. Consequences for undecidability and complexity issues about nets are discussed too."
            },
            "slug": "On-the-computational-power-of-neural-nets-Siegelmann-Sontag",
            "title": {
                "fragments": [],
                "text": "On the Computational Power of Neural Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that one may simulate all Turing Machines by rational nets in linear time, and there is a net made up of about 1,000 processors which computes a universal partial-recursive function."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686506"
                        ],
                        "name": "A. Atiya",
                        "slug": "A.-Atiya",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Atiya",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Atiya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838904"
                        ],
                        "name": "A. Parlos",
                        "slug": "A.-Parlos",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Parlos",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parlos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18072366,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bdabcdcde21d4d71321935e2e0332e32eda5366",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "How to efficiently train recurrent networks remains a challenging and active research topic. Most of the proposed training approaches are based on computational ways to efficiently obtain the gradient of the error function, and can be generally grouped into five major groups. In this study we present a derivation that unifies these approaches. We demonstrate that the approaches are only five different ways of solving a particular matrix equation. The second goal of this paper is develop a new algorithm based on the insights gained from the novel formulation. The new algorithm, which is based on approximating the error gradient, has lower computational complexity in computing the weight update than the competing techniques for most typical problems. In addition, it reaches the error minimum in a much smaller number of iterations. A desirable characteristic of recurrent network training algorithms is to be able to update the weights in an on-line fashion. We have also developed an on-line version of the proposed algorithm, that is based on updating the error gradient approximation in a recursive manner."
            },
            "slug": "New-results-on-recurrent-network-training:-unifying-Atiya-Parlos",
            "title": {
                "fragments": [],
                "text": "New results on recurrent network training: unifying the algorithms and accelerating convergence"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An on-line version of the proposed algorithm, which is based on approximating the error gradient, has lower computational complexity in computing the weight update than the competing techniques for most typical problems and reaches the error minimum in a much smaller number of iterations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks Learn. Syst."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 51704,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691804"
                        ],
                        "name": "D. Ballard",
                        "slug": "D.-Ballard",
                        "structuredName": {
                            "firstName": "Dana",
                            "lastName": "Ballard",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ballard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6585372,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2c8c97918a24c26da7c949a7d6aaf3201d9d9cf9",
            "isKey": false,
            "numCitedBy": 4599,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalizing-the-Hough-transform-to-detect-shapes-Ballard",
            "title": {
                "fragments": [],
                "text": "Generalizing the Hough transform to detect arbitrary shapes"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39852175"
                        ],
                        "name": "Scott P. Johnson",
                        "slug": "Scott-P.-Johnson",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Johnson",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott P. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3065843"
                        ],
                        "name": "R. Aslin",
                        "slug": "R.-Aslin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Aslin",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Aslin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4635509,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6d4c9c014d1a21fdef18140cd23527eb9d065e9c",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perception-of-object-unity-in-young-infants:-The-of-Johnson-Aslin",
            "title": {
                "fragments": [],
                "text": "Perception of object unity in young infants: The roles of motion, depth, and orientation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9166388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "isKey": false,
            "numCitedBy": 32844,
            "numCiting": 636,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning."
            },
            "slug": "Reinforcement-Learning:-An-Introduction-Sutton-Barto",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: An Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book provides a clear and simple account of the key ideas and algorithms of reinforcement learning, which ranges from the history of the field's intellectual foundations to the most recent developments and applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061273807"
                        ],
                        "name": "K. Nakayama",
                        "slug": "K.-Nakayama",
                        "structuredName": {
                            "firstName": "Kenta",
                            "lastName": "Nakayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nakayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47706614"
                        ],
                        "name": "S. Shimojo",
                        "slug": "S.-Shimojo",
                        "structuredName": {
                            "firstName": "Shinsuke",
                            "lastName": "Shimojo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shimojo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888069"
                        ],
                        "name": "V. Ramachandran",
                        "slug": "V.-Ramachandran",
                        "structuredName": {
                            "firstName": "Vilayanur",
                            "lastName": "Ramachandran",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ramachandran"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 22269539,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "61167f74c9a997202351c242d88214d2ef834cac",
            "isKey": false,
            "numCitedBy": 229,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The perception of transparency is highly dependent on luminance and perceived depth. An image region is seen as transparent if it is of intermediate luminance relative to adjacent image regions, and if it is perceived in front of another region and has a boundary which provides information that an object is visible through this region. Yet, transparency is not just the passive end-product of these required conditions. If perceived transparency is triggered, a number of seemingly more elemental perceptual primitives such as color, contour, and depth can be radically altered. Thus, with the perception of transparency, neon color spreading becomes apparent, depth changes, stereoscopic depth capture can be eliminated, and otherwise robust subjective contours can be abolished. In addition, we show that transparency is not coupled strongly to real-world chromatic constraints since combinations of luminance and color which would be unlikely to arise in real-world scenes still give rise to the perception of transparency. Rather than seeing transparency as a perceptual end-point, determined by seemingly more primitive processes, we interpret perceived transparency as much a \u2018cause\u2019, as an \u2018effect\u2019. We speculate that the anatomical substrate for such mutual interaction may lie in cortical feed-forward connections which maintain modular segregation and cortical feedback connections which do not."
            },
            "slug": "Transparency:-Relation-to-Depth,-Subjective-and-Nakayama-Shimojo",
            "title": {
                "fragments": [],
                "text": "Transparency: Relation to Depth, Subjective Contours, Luminance, and Neon Color Spreading"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Perceived transparency is interpreted as much a \u2018cause\u2019, as an \u2018effect\u2019 and is shown that transparency is not coupled strongly to real-world chromatic constraints since combinations of luminance and color which would be unlikely to arise in real- world scenes still give rise to the perception of transparency."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243689"
                        ],
                        "name": "T. Ba\u015far",
                        "slug": "T.-Ba\u015far",
                        "structuredName": {
                            "firstName": "Tamer",
                            "lastName": "Ba\u015far",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ba\u015far"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 120239200,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d36a38125557764efb0fd2b3ef0a4cde515b3861",
            "isKey": false,
            "numCitedBy": 17403,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The clssical filleting and prediclion problem is re-examined using the Bode-Shannon representation of random processes and the ?stat-tran-sition? method of analysis of dynamic systems. New result are: (1) The formulation and Methods of solution of the problm apply, without modification to stationary and nonstationary stalistics end to growing-memory and infinile -memory filters. (2) A nonlinear difference (or differential) equalion is dericed for the covariance matrix of the optimal estimalion error. From the solution of this equation the coefficients of the difference, (or differential) equation of the optimal linear filter are obtained without further caleulations. (3) Tke fillering problem is shoum to be the dual of the nois-free regulator problem. The new method developed here, is applied to do well-known problems, confirming and extending, earlier results. The discussion is largely, self-contatained, and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix."
            },
            "slug": "A-New-Approach-to-Linear-Filtering-and-Prediction-Ba\u015far",
            "title": {
                "fragments": [],
                "text": "A New Approach to Linear Filtering and Prediction Problems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786606"
                        ],
                        "name": "R. Brodersen",
                        "slug": "R.-Brodersen",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Brodersen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brodersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48963764"
                        ],
                        "name": "C. Hewes",
                        "slug": "C.-Hewes",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Hewes",
                            "middleNames": [
                                "Robert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Hewes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1563805,
            "fieldsOfStudy": [
                "Computer Science",
                "Physics"
            ],
            "id": "f7760fb2a41c9ba811ede43ea4709e07413192fd",
            "isKey": false,
            "numCitedBy": 327,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The present capabilities of speech recognition algorithms will be surveyed. The application of IC technology to the implementation of these algorithms will be explored and potential future directions will be determined."
            },
            "slug": "Speech-recognition-Brodersen-Hewes",
            "title": {
                "fragments": [],
                "text": "Speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "The present capabilities of speech recognition algorithms will be surveyed and the application of IC technology to the implementation of these algorithm will be explored and potential future directions will be determined."
            },
            "venue": {
                "fragments": [],
                "text": "1983 IEEE International Solid-State Circuits Conference. Digest of Technical Papers"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362425"
                        ],
                        "name": "S. Amari",
                        "slug": "S.-Amari",
                        "structuredName": {
                            "firstName": "Shun\u2010ichi",
                            "lastName": "Amari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Amari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2811608,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "17f3e82330d9e94fb9f7f45549b80016c7f0e24f",
            "isKey": false,
            "numCitedBy": 1663,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The dynamics of pattern formation is studied for lateral-inhibition type homogeneous neural fields with general connections. Neural fields consisting of single layer are first treated, and it is proved that there are five types of pattern dynamics. The type of the dynamics of a field depends not only on the mutual connections within the field but on the level of homogeneous stimulus given to the field. An example of the dynamics is as follows: A fixed size of localized excitation, once evoked by stimulation, can be retained in the field persistently even after the stimulation vanishes. It moves until it finds the position of the maximum of the input stimulus. Fields consisting of an excitatory and an inhibitory layer are next analyzed. In addition to stationary localized excitation, fields have such pattern dynamics as production of oscillatory waves, travelling waves, active and dual active transients, etc."
            },
            "slug": "Dynamics-of-pattern-formation-in-lateral-inhibition-Amari",
            "title": {
                "fragments": [],
                "text": "Dynamics of pattern formation in lateral-inhibition type neural fields"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "The dynamics of pattern formation is studied for lateral-inhibition type homogeneous neural fields with general connections and it is proved that there are five types of pattern dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18470994,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1a3d22599028a05669e884f3eaf19a342e190a87",
            "isKey": false,
            "numCitedBy": 4036,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Backpropagation is now the most widely used tool in the field of artificial neural networks. At the core of backpropagation is a method for calculating derivatives exactly and efficiently in any large system made up of elementary subsystems or calculations which are represented by known, differentiable functions; thus, backpropagation has many applications which do not involve neural networks as such. This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis. Next, it presents the basic equations for backpropagation through time, and discusses applications to areas like pattern recognition involving dynamic systems, systems identification, and control. Finally, i t describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed."
            },
            "slug": "Backpropagation-Through-Time:-What-It-Does-and-How-Werbos",
            "title": {
                "fragments": [],
                "text": "Backpropagation Through Time: What It Does and How to Do It"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper first reviews basic backpropagation, a simple method which is now being widely used in areas like pattern recognition and fault diagnosis, and describes further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations or true recurrent networks, and other practical issues which arise with this method."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116092871"
                        ],
                        "name": "R. Taya",
                        "slug": "R.-Taya",
                        "structuredName": {
                            "firstName": "Raiten",
                            "lastName": "Taya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Taya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815494"
                        ],
                        "name": "W. Ehrenstein",
                        "slug": "W.-Ehrenstein",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Ehrenstein",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Ehrenstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2367975"
                        ],
                        "name": "C. Cavonius",
                        "slug": "C.-Cavonius",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Cavonius",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cavonius"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40299891,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "cb9e5911dc805fe0f344bd0390f736d222322ba7",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In the Munker\u2014White effect grey target bars appear lighter when they are flanked by white bars, and darker when they are flanked by black bars. It is shown that the effect is enhanced if the patterns are presented stereoscopically so that the grey bars appear either behind the grating, in which case they are seen as a rectangle that is occluded by the white bars of the grating, or in front of the grating, so that they form a transparent rectangle. These results are explained in terms of object perception: contrast enhances differences between an object and its surroundings, whereas assimilation reduces differences within an object."
            },
            "slug": "Varying-the-Strength-of-the-Munker\u2014White-Effect-by-Taya-Ehrenstein",
            "title": {
                "fragments": [],
                "text": "Varying the Strength of the Munker\u2014White Effect by Stereoscopic Viewing"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "In the Munker\u2014White effect grey target bars appear lighter when they are flanked by white bars, and darker when they is flanked by black bars."
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198578"
                        ],
                        "name": "J. Yedidia",
                        "slug": "J.-Yedidia",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Yedidia",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Yedidia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15300022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2799fd1254689eec52f86daf3668a5aac3ea943",
            "isKey": false,
            "numCitedBy": 1127,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Belief propagation (BP) was only supposed to work for treelike networks but works surprisingly well in many applications involving networks with loops, including turbo codes. However, there has been little understanding of the algorithm or the nature of the solutions it finds for general graphs. \n \nWe show that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics. This result characterizes BP fixed-points and makes connections with variational approaches to approximate inference. \n \nMore importantly, our analysis lets us build on the progress made in statistical physics since Bethe's approximation was introduced in 1935. Kikuchi and others have shown how to construct more accurate free energy approximations, of which Bethe's approximation is the simplest. Exploiting the insights from our analysis, we derive generalized belief propagation (GBP) versions of these Kikuchi approximations. These new message passing algorithms can be significantly more accurate than ordinary BP, at an adjustable increase in complexity. We illustrate such a new GBP algorithm on a grid Markov network and show that it gives much more accurate marginal probabilities than those found using ordinary BP."
            },
            "slug": "Generalized-Belief-Propagation-Yedidia-Freeman",
            "title": {
                "fragments": [],
                "text": "Generalized Belief Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that BP can only converge to a stationary point of an approximate free energy, known as the Bethe free energy in statistical physics, and generalized belief propagation (GBP) versions of these Kikuchi approximations are derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3180291"
                        ],
                        "name": "M. Bierling",
                        "slug": "M.-Bierling",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Bierling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bierling"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62673975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd4f920e0bce3c33e16371734c3d91602e1a4c51",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A hierarchical blockmatching algorithm for the estimation of displacement vector fields in digital television sequences is presented. Known blockmatching techniques fail frequently as a result of using a fixed measurement window size. Using distinct sizes of measurement windows at different levels of a hierarchy, the presented blockmatching technique yields reliable and homogeneous displacement vector - fields, which are close to the true displacements, rather than only a match in the sense of a minimum mean absolute luminance difference. In the environment of a low bit rate hybrid coder for image sequences, the hierarchical blockmatching algorithm is well suited for both, motion compensating prediction, and motion compensating interpolation. Compared to other high sophisticated displacement estimation techniques, the computational effort is decreased drastically. Due to the regularity and the very small number of necessary operations, the presented hierarchical blockmatching algorithm can be implemented in hardware very easily."
            },
            "slug": "Displacement-Estimation-By-Hierarchical-Bierling",
            "title": {
                "fragments": [],
                "text": "Displacement Estimation By Hierarchical Blockmatching"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A hierarchical blockmatching algorithm for the estimation of displacement vector fields in digital television sequences is presented, which yields reliable and homogeneous displacement vector - fields, which are close to the true displacements."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1889982"
                        ],
                        "name": "F. Kschischang",
                        "slug": "F.-Kschischang",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Kschischang",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kschischang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143681410"
                        ],
                        "name": "H. Loeliger",
                        "slug": "H.-Loeliger",
                        "structuredName": {
                            "firstName": "Hans-Andrea",
                            "lastName": "Loeliger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Loeliger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14394619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c370eb9ba13bfb836349e7f3ea428be4697818",
            "isKey": false,
            "numCitedBy": 4131,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms."
            },
            "slug": "Factor-graphs-and-the-sum-product-algorithm-Kschischang-Frey",
            "title": {
                "fragments": [],
                "text": "Factor graphs and the sum-product algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph, that computes-either exactly or approximately-various marginal functions derived from the global function."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5262555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "807c1f19047f96083e13614f7ce20f2ac98c239a",
            "isKey": false,
            "numCitedBy": 21898,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nClassifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation. \n \nC4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies. \n \nThis book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses."
            },
            "slug": "C4.5:-Programs-for-Machine-Learning-Quinlan",
            "title": {
                "fragments": [],
                "text": "C4.5: Programs for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A complete guide to the C4.5 system as implemented in C for the UNIX environment, which starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748824"
                        ],
                        "name": "C. Igel",
                        "slug": "C.-Igel",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Igel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Igel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722195"
                        ],
                        "name": "Michael H\u00fcsken",
                        "slug": "Michael-H\u00fcsken",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "H\u00fcsken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael H\u00fcsken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14027552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2bfc2d5d3ad8f13f8caca3ba5c0670f74681948",
            "isKey": false,
            "numCitedBy": 435,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Empirical-evaluation-of-the-improved-Rprop-learning-Igel-H\u00fcsken",
            "title": {
                "fragments": [],
                "text": "Empirical evaluation of the improved Rprop learning algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2673251"
                        ],
                        "name": "M. Alexander",
                        "slug": "M.-Alexander",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Alexander",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Alexander"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57799138,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3d6ae6e9b59a871fd9259836ac9b6b7628f697f2",
            "isKey": false,
            "numCitedBy": 8083,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I have developed \"tennis elbow\" from lugging this book around the past four weeks, but it is worth the pain, the effort, and the aspirin. It is also worth the (relatively speaking) bargain price. Including appendixes, this book contains 894 pages of text. The entire panorama of the neural sciences is surveyed and examined, and it is comprehensive in its scope, from genomes to social behaviors. The editors explicitly state that the book is designed as \"an introductory text for students of biology, behavior, and medicine,\" but it is hard to imagine any audience, interested in any fragment of neuroscience at any level of sophistication, that would not enjoy this book. The editors have done a masterful job of weaving together the biologic, the behavioral, and the clinical sciences into a single tapestry in which everyone from the molecular biologist to the practicing psychiatrist can find and appreciate his or"
            },
            "slug": "Principles-of-Neural-Science-Alexander",
            "title": {
                "fragments": [],
                "text": "Principles of Neural Science"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The editors have done a masterful job of weaving together the biologic, the behavioral, and the clinical sciences into a single tapestry in which everyone from the molecular biologist to the practicing psychiatrist can find and appreciate his or her own research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2420218"
                        ],
                        "name": "F. V. Hundelshausen",
                        "slug": "F.-V.-Hundelshausen",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Hundelshausen",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. V. Hundelshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144870565"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 37503070,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e053b4111a14a2e411895465ac47fcabcc33fd9f",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the omnidirectional local vision system developed for the FU-Fighters, a RoboCup F180 league soccer team. A small video camera mounted vertically on top of the robots looks at a concave parabolic mirror placed above the camera that reflects the field around. The image is sent via a radio link to an external PC for processing. Our computer vision system can find the ball and detect other robots as obstacles. The walls of the field are also recognized and are used to determine the initial position of the robot. In order to be able to process the video stream at full frame rate the movement of all objects is tracked, including the walls of the field. The key idea of our approach is to predict the location of color edges in the next frame and to search for such color transitions along lines that are perpendicular to the edge."
            },
            "slug": "An-Omnidirectional-Vision-System-That-Finds-and-and-Hundelshausen-Behnke",
            "title": {
                "fragments": [],
                "text": "An Omnidirectional Vision System That Finds and Tracks Color Edges and Blobs"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The omnidirectional local vision system developed for the FU-Fighters, a RoboCup F180 league soccer team, aims to predict the location of color edges in the next frame and to search for such color transitions along lines that are perpendicular to the edge."
            },
            "venue": {
                "fragments": [],
                "text": "RoboCup"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723150"
                        ],
                        "name": "R. McEliece",
                        "slug": "R.-McEliece",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "McEliece",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. McEliece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157745208"
                        ],
                        "name": "Jung-Fu Cheng",
                        "slug": "Jung-Fu-Cheng",
                        "structuredName": {
                            "firstName": "Jung-Fu",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jung-Fu Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14553992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26d953005dd08a863c157b528bbabdf5671d18b6",
            "isKey": false,
            "numCitedBy": 1004,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the close connection between the now celebrated iterative turbo decoding algorithm of Berrou et al. (1993) and an algorithm that has been well known in the artificial intelligence community for a decade, but which is relatively unknown to information theorists: Pearl's (1982) belief propagation algorithm. We see that if Pearl's algorithm is applied to the \"belief network\" of a parallel concatenation of two or more codes, the turbo decoding algorithm immediately results. Unfortunately, however, this belief diagram has loops, and Pearl only proved that his algorithm works when there are no loops, so an explanation of the experimental performance of turbo decoding is still lacking. However, we also show that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's (1962) low-density parity-check codes, serially concatenated codes, and product codes. Thus, belief propagation provides a very attractive general methodology for devising low-complexity iterative decoding algorithms for hybrid coded systems."
            },
            "slug": "Turbo-Decoding-as-an-Instance-of-Pearl's-\"Belief-McEliece-Mackay",
            "title": {
                "fragments": [],
                "text": "Turbo Decoding as an Instance of Pearl's \"Belief Propagation\" Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that Pearl's algorithm can be used to routinely derive previously known iterative, but suboptimal, decoding algorithms for a number of other error-control systems, including Gallager's low-density parity-check codes, serially concatenated codes, and product codes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE J. Sel. Areas Commun."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796770"
                        ],
                        "name": "E. Aarts",
                        "slug": "E.-Aarts",
                        "structuredName": {
                            "firstName": "Emile",
                            "lastName": "Aarts",
                            "middleNames": [
                                "H.",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Aarts"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8952312"
                        ],
                        "name": "J. Korst",
                        "slug": "J.-Korst",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Korst",
                            "middleNames": [
                                "H.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Korst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19877437,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43c99a08e6e84d6fb75b0c8d03977fbf8e9dc402",
            "isKey": false,
            "numCitedBy": 1307,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "SIMULATED ANNEALING. Combinatorial Optimization. Simulated Annealing. Asymptotic Convergence. Finite-Time Approximation. Simulated Annealing in Practice. Parallel Simulated Annealing Algorithms. BOLTZMANN MACHINES. Neural Computing. Boltzmann Machines. Combinatorial Optimization and Boltzmann Machines. Classification and Boltzmann Machines. Learning and Boltzmann Machines. Appendix. Bibliography. Indices."
            },
            "slug": "Simulated-annealing-and-Boltzmann-machines-a-to-and-Aarts-Korst",
            "title": {
                "fragments": [],
                "text": "Simulated annealing and Boltzmann machines - a stochastic approach to combinatorial optimization and neural computing"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Combinatorial Optimization and Boltzmann Machines, Parallel Simulated Annealing Algorithms, and Neural Computing."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley-Interscience series in discrete mathematics and optimization"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145430701"
                        ],
                        "name": "J. Pearl",
                        "slug": "J.-Pearl",
                        "structuredName": {
                            "firstName": "Judea",
                            "lastName": "Pearl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32583695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70ef29e6f0ce082bb8a47fd85b9bfb7cc0f20c93",
            "isKey": false,
            "numCitedBy": 18218,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nProbabilistic Reasoning in Intelligent Systems is a complete andaccessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty\u0097and offers techniques, based on belief networks, that provide a mechanism for making semantics-based systems operational. Specifically, network-propagation techniques serve as a mechanism for combining the theoretical coherence of probability theory with modern demands of reasoning-systems technology: modular declarative inputs, conceptually meaningful inferences, and parallel distributed computation. Application areas include diagnosis, forecasting, image interpretation, multi-sensor fusion, decision support systems, plan recognition, planning, speech recognition\u0097in short, almost every task requiring that conclusions be drawn from uncertain clues and incomplete information. \nProbabilistic Reasoning in Intelligent Systems will be of special interest to scholars and researchers in AI, decision theory, statistics, logic, philosophy, cognitive psychology, and the management sciences. Professionals in the areas of knowledge-based systems, operations research, engineering, and statistics will find theoretical and computational tools of immediate practical use. The book can also be used as an excellent text for graduate-level courses in AI, operations research, or applied probability."
            },
            "slug": "Probabilistic-reasoning-in-intelligent-systems-of-Pearl",
            "title": {
                "fragments": [],
                "text": "Probabilistic reasoning in intelligent systems - networks of plausible inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, truth maintenance systems, and nonmonotonic logic."
            },
            "venue": {
                "fragments": [],
                "text": "Morgan Kaufmann series in representation and reasoning"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749650"
                        ],
                        "name": "B. Frey",
                        "slug": "B.-Frey",
                        "structuredName": {
                            "firstName": "Brendan",
                            "lastName": "Frey",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Frey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6518359,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8871254256b95f52fe6a2c0edeee0fa706c1117",
            "isKey": false,
            "numCitedBy": 370,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Until recently, artificial intelligence researchers have frowned upon the application of probability propagation in Bayesian belief networks that have cycles. The probability propagation algorithm is only exact in networks that are cycle-free. However, it has recently been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation in belief networks with cycles."
            },
            "slug": "A-Revolution:-Belief-Propagation-in-Graphs-with-Frey-Mackay",
            "title": {
                "fragments": [],
                "text": "A Revolution: Belief Propagation in Graphs with Cycles"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Until recently, artificial intelligence researchers have frowned upon the application of probability propagation in Bayesian belief networks that have cycles, but it has recently been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation with cycles."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398371449"
                        ],
                        "name": "K. Smith\u2010Miles",
                        "slug": "K.-Smith\u2010Miles",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Smith\u2010Miles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Smith\u2010Miles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145389998"
                        ],
                        "name": "M. Palaniswami",
                        "slug": "M.-Palaniswami",
                        "structuredName": {
                            "firstName": "Marimuthu",
                            "lastName": "Palaniswami",
                            "middleNames": [
                                "Swami"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Palaniswami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157112"
                        ],
                        "name": "M. Krishnamoorthy",
                        "slug": "M.-Krishnamoorthy",
                        "structuredName": {
                            "firstName": "Mohan",
                            "lastName": "Krishnamoorthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Krishnamoorthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1534238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a41b68c04bbfdd47287fc132ac4169c9af0d114",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "After more than a decade of research, there now exist several neural-network techniques for solving NP-hard combinatorial optimization problems. Hopfield networks and self-organizing maps are the two main categories into which most of the approaches can be divided. Criticism of these approaches includes the tendency of the Hopfield network to produce infeasible solutions, and the lack of generalizability of the self-organizing approaches (being only applicable to Euclidean problems). This paper proposes two new techniques which have overcome these pitfalls: a Hopfield network which enables feasibility of the solutions to be ensured and improved solution quality through escape from local minima, and a self-organizing neural network which generalizes to solve a broad class of combinatorial optimization problems. Two sample practical optimization problems from Australian industry are then used to test the performances of the neural techniques against more traditional heuristic solutions."
            },
            "slug": "Neural-techniques-for-combinatorial-optimization-Smith\u2010Miles-Palaniswami",
            "title": {
                "fragments": [],
                "text": "Neural techniques for combinatorial optimization with applications"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A Hopfield network which enables feasibility of the solutions to be ensured and improved solution quality through escape from local minima, and a self-organizing neural network which generalizes to solve a broad class of combinatorial optimization problems are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13252401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcee7c85d237b79491a773ef51e746bbbcf48e35",
            "isKey": false,
            "numCitedBy": 13489,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions."
            },
            "slug": "Induction-of-Decision-Trees-Quinlan",
            "title": {
                "fragments": [],
                "text": "Induction of Decision Trees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail, which is described in detail."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101639166"
                        ],
                        "name": "S. P. Lloyd",
                        "slug": "S.-P.-Lloyd",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Lloyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. P. Lloyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10833328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9241ea3d8cb85633d314ecb74b31567b8e73f6af",
            "isKey": false,
            "numCitedBy": 11645,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "It has long been realized that in pulse-code modulation (PCM), with a given ensemble of signals to handle, the quantum values should be spaced more closely in the voltage regions where the signal amplitude is more likely to fall. It has been shown by Panter and Dite that, in the limit as the number of quanta becomes infinite, the asymptotic fractional density of quanta per unit voltage should vary as the one-third power of the probability density per unit voltage of signal amplitudes. In this paper the corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy. The optimization criterion used is that the average quantization noise power be a minimum. It is shown that the result obtained here goes over into the Panter and Dite result as the number of quanta become large. The optimum quautization schemes for 2^{b} quanta, b=1,2, \\cdots, 7 , are given numerically for Gaussian and for Laplacian distribution of signal amplitudes."
            },
            "slug": "Least-squares-quantization-in-PCM-Lloyd",
            "title": {
                "fragments": [],
                "text": "Least squares quantization in PCM"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The corresponding result for any finite number of quanta is derived; that is, necessary conditions are found that the quanta and associated quantization intervals of an optimum finite quantization scheme must satisfy."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38690711"
                        ],
                        "name": "K. Beyer",
                        "slug": "K.-Beyer",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Beyer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Beyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145858819"
                        ],
                        "name": "J. Goldstein",
                        "slug": "J.-Goldstein",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Goldstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goldstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709145"
                        ],
                        "name": "R. Ramakrishnan",
                        "slug": "R.-Ramakrishnan",
                        "structuredName": {
                            "firstName": "Raghu",
                            "lastName": "Ramakrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ramakrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758801"
                        ],
                        "name": "U. Shaft",
                        "slug": "U.-Shaft",
                        "structuredName": {
                            "firstName": "Uri",
                            "lastName": "Shaft",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Shaft"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206634099,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69fe08fb1aa15bbab4ca26c31cc9302e325870b1",
            "isKey": false,
            "numCitedBy": 2280,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "We explore the effect of dimensionality on the \"nearest neighbor\" problem. We show that under a broad set of conditions (much broader than independent and identically distributed dimensions), as dimensionality increases, the distance to the nearest data point approaches the distance to the farthest data point. To provide a practical perspective, we present empirical results on both real and synthetic data sets that demonstrate that this effect can occur for as few as 10-15 dimensions. \n \nThese results should not be interpreted to mean that high-dimensional indexing is never meaningful; we illustrate this point by identifying some high-dimensional workloads for which this effect does not occur. However, our results do emphasize that the methodology used almost universally in the database literature to evaluate high-dimensional indexing techniques is flawed, and should be modified. In particular, most such techniques proposed in the literature are not evaluated versus simple linear scan, and are evaluated over workloads for which nearest neighbor is not meaningful. Often, even the reported experiments, when analyzed carefully, show that linear scan would outperform the techniques being proposed on the workloads studied in high (10-15) dimensionality!"
            },
            "slug": "When-Is-''Nearest-Neighbor''-Meaningful-Beyer-Goldstein",
            "title": {
                "fragments": [],
                "text": "When Is ''Nearest Neighbor'' Meaningful?"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "The effect of dimensionality on the \"nearest neighbor\" problem is explored, and it is shown that under a broad set of conditions, as dimensionality increases, the Distance to the nearest data point approaches the distance to the farthest data point."
            },
            "venue": {
                "fragments": [],
                "text": "ICDT"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752732"
                        ],
                        "name": "T. Cover",
                        "slug": "T.-Cover",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Cover",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Cover"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5246200,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "0efb841403aa6252b39ae6975c1cc5410554ef7b",
            "isKey": false,
            "numCitedBy": 10768,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error R of such a rule must be at least as great as the Bayes probability of error R^{\\ast} --the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the M -category case that R^{\\ast} \\leq R \\leq R^{\\ast}(2 --MR^{\\ast}/(M-1)) , where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "slug": "Nearest-neighbor-pattern-classification-Cover-Hart",
            "title": {
                "fragments": [],
                "text": "Nearest neighbor pattern classification"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points, so it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60282629,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc52d1ede1b90bf9d296bc5b34c9310b7eaa99a2",
            "isKey": false,
            "numCitedBy": 4402,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Disclosed is an improved articulated bar flail having shearing edges for efficiently shredding materials. An improved shredder cylinder is disclosed with a plurality of these flails circumferentially spaced and pivotally attached to the periphery of a rotatable shaft. Also disclosed is an improved shredder apparatus which has a pair of these shredder cylinders mounted to rotate about spaced parallel axes which cooperates with a conveyer apparatus which has a pair of inclined converging conveyer belts with one of the belts mounted to move with respect to the other belt to allow the transport of articles of various sizes therethrough."
            },
            "slug": "The-mnist-database-of-handwritten-digits-LeCun-Cortes",
            "title": {
                "fragments": [],
                "text": "The mnist database of handwritten digits"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "An improved articulated bar flail having shearing edges for efficiently shredding materials and an improved shredder cylinder with a plurality of these flails circumferentially spaced and pivotally attached to the periphery of a rotatable shaft are disclosed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144733293"
                        ],
                        "name": "R. Fletcher",
                        "slug": "R.-Fletcher",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Fletcher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fletcher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123487779,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b84b383ad59f79e607ad0f08a8a10876631a0cd",
            "isKey": false,
            "numCitedBy": 9912,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface Table of Notation Part 1: Unconstrained Optimization Introduction Structure of Methods Newton-like Methods Conjugate Direction Methods Restricted Step Methods Sums of Squares and Nonlinear Equations Part 2: Constrained Optimization Introduction Linear Programming The Theory of Constrained Optimization Quadratic Programming General Linearly Constrained Optimization Nonlinear Programming Other Optimization Problems Non-Smooth Optimization References Subject Index."
            },
            "slug": "Practical-Methods-of-Optimization-Fletcher",
            "title": {
                "fragments": [],
                "text": "Practical Methods of Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The aim of this book is to provide a Discussion of Constrained Optimization and its Applications to Linear Programming and Other Optimization Problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397207814"
                        ],
                        "name": "F. Dell\u2019acqua",
                        "slug": "F.-Dell\u2019acqua",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Dell\u2019acqua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Dell\u2019acqua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843592"
                        ],
                        "name": "Robert B. Fisher",
                        "slug": "Robert-B.-Fisher",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fisher",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert B. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12707904,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "50430ec608fb03b810875e5b729f98fe9004559e",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Analysis and reconstruction of range images usually focuses on complex objects completely contained in the field of view; little attention has been devoted so far to the reconstruction of simply shaped wide areas like parts of a wall hidden behind furniture pieces in an indoor range image. The work presented in the paper is aimed at such reconstruction. First of all, the range image is partitioned based on depth discontinuities and fold edges. Next, the planes best fitting each of the regions constituting the partition of the image are determined. A third step locates potentially contiguous surfaces, while a final step reconstructs the hidden regions. The paper presents results for reconstruction of the shape of planar surfaces behind arbitrary occluding surfaces. The system proved to be effective and the reconstructed surfaces appear to be reasonable. Some examples of results are presented from the Bornholm church range images."
            },
            "slug": "Reconstruction-of-Planar-Surfaces-Behind-Occlusions-Dell\u2019acqua-Fisher",
            "title": {
                "fragments": [],
                "text": "Reconstruction of Planar Surfaces Behind Occlusions in Range Images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The paper presents results for reconstruction of the shape of planar surfaces behind arbitrary occluding surfaces and the system proved to be effective and the reconstructed surfaces appear to be reasonable."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47115885"
                        ],
                        "name": "Ralf Solomon",
                        "slug": "Ralf-Solomon",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Solomon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ralf Solomon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145292153"
                        ],
                        "name": "J. Hemmen",
                        "slug": "J.-Hemmen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Hemmen",
                            "middleNames": [
                                "Leo",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hemmen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6785680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41d004a355e51ef8dc2546cd28e07645493c232a",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Accelerating-backpropagation-through-dynamic-Solomon-Hemmen",
            "title": {
                "fragments": [],
                "text": "Accelerating backpropagation through dynamic self-adaptation"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119996251"
                        ],
                        "name": "G. Li\u00f1\u00e1n",
                        "slug": "G.-Li\u00f1\u00e1n",
                        "structuredName": {
                            "firstName": "Gustavo",
                            "lastName": "Li\u00f1\u00e1n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Li\u00f1\u00e1n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398274325"
                        ],
                        "name": "R. Dom\u00ednguez-Castro",
                        "slug": "R.-Dom\u00ednguez-Castro",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Dom\u00ednguez-Castro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dom\u00ednguez-Castro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9368775"
                        ],
                        "name": "S. Espejo",
                        "slug": "S.-Espejo",
                        "structuredName": {
                            "firstName": "Servando",
                            "lastName": "Espejo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Espejo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403293719"
                        ],
                        "name": "\u00c1. Rodr\u00edguez-V\u00e1zquez",
                        "slug": "\u00c1.-Rodr\u00edguez-V\u00e1zquez",
                        "structuredName": {
                            "firstName": "\u00c1ngel",
                            "lastName": "Rodr\u00edguez-V\u00e1zquez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c1. Rodr\u00edguez-V\u00e1zquez"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 24276668,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8e493cb8270f268f36f18799782947653aabbfbb",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new generation 128\u00d7128 Focal-Plane Analog Programmable Array Processor (FP-APAP), from a system level perspective. It has been manufactured in a 0.35\u00b5m standard digital 1P-5M CMOS Technology. The chip has been designed to achieve the high-speed and moderate-accuracy (\u223c8bits) requirements of most real time image processing applications. It has been designed to be easily embedded in conventional digital hosting systems: external data interchange and control are completely digital. The chip contains close to four millions transistors, 80% of them working in analog mode, and exhibits a relatively low power consumption (<4W, i.e. less than 1\u00b5W per transistor). Computing vs. power peak values are in the order of 1TeraOPS/W, while maintained VGA (640\u00d7480)processing throughputs of 100Frames/s are possible with about 10-20 basic image processing tasks on each frame."
            },
            "slug": "ACE16K:-An-advanced-focal-plane-analog-programmable-Li\u00f1\u00e1n-Dom\u00ednguez-Castro",
            "title": {
                "fragments": [],
                "text": "ACE16K: An advanced focal-plane analog programmable array processor"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper presents a new generation 128\u00d7128 Focal-Plane Analog Programmable Array Processor (FP-APAP), from a system level perspective, designed to achieve the high-speed and moderate-accuracy requirements of most real time image processing applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 27th European Solid-State Circuits Conference"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2626238"
                        ],
                        "name": "U. Kapasi",
                        "slug": "U.-Kapasi",
                        "structuredName": {
                            "firstName": "Ujval",
                            "lastName": "Kapasi",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Kapasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805158"
                        ],
                        "name": "S. Rixner",
                        "slug": "S.-Rixner",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Rixner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rixner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758404"
                        ],
                        "name": "John Douglas Owens",
                        "slug": "John-Douglas-Owens",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Owens",
                            "middleNames": [
                                "Douglas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Douglas Owens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125244"
                        ],
                        "name": "B. Khailany",
                        "slug": "B.-Khailany",
                        "structuredName": {
                            "firstName": "Brucek",
                            "lastName": "Khailany",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Khailany"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1205209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f56d40537a80e87a304390c65710ce07a07ce998",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The Imagine Stream Processor is a single-chip programmable media processor with 48 parallel ALUs. At 400 MHz, this translates to a peak arithmetic rate of 16 GFLOPS on single-precision data and 32 GOPS on 16 bit fixed-point data. The scalability of Imagine's programming model and architecture enable it to achieve such high arithmetic rates. Imagine executes applications that have been mapped to the stream programming model. The stream model decomposes applications into a set of computation kernels that operate on data streams. This mapping exposes the inherent locality and parallelism in the application, and Imagine exploits the locality and parallelism to provide a scalable architecture that supports 48 ALUs on a single chip. This paper presents the Imagine architecture and programming model in the first half and explores the scalability of the Imagine architecture in the second half."
            },
            "slug": "The-Imagine-Stream-Processor-Kapasi-Dally",
            "title": {
                "fragments": [],
                "text": "The Imagine Stream Processor"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Imagine architecture and programming model is presented in the first half and the scalability of the Imagine architecture is explored in the second half to provide a scalable architecture that supports 48 ALUs on a single chip."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. IEEE International Conference on Computer Design: VLSI in Computers and Processors"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2776623"
                        ],
                        "name": "N. Qian",
                        "slug": "N.-Qian",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Qian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Qian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2783597,
            "fieldsOfStudy": [
                "Physics",
                "Computer Science"
            ],
            "id": "735d4220d5579cc6afe956d9f6ea501a96ae99e2",
            "isKey": false,
            "numCitedBy": 1527,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-the-momentum-term-in-gradient-descent-learning-Qian",
            "title": {
                "fragments": [],
                "text": "On the momentum term in gradient descent learning algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122886"
                        ],
                        "name": "E. Meron",
                        "slug": "E.-Meron",
                        "structuredName": {
                            "firstName": "Ehud",
                            "lastName": "Meron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Meron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 120309324,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "42192f637d672ba07f2b837a649257d5931164cd",
            "isKey": false,
            "numCitedBy": 284,
            "numCiting": 155,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Pattern-formation-in-excitable-media-Meron",
            "title": {
                "fragments": [],
                "text": "Pattern formation in excitable media"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51084207"
                        ],
                        "name": "H. Nyquist",
                        "slug": "H.-Nyquist",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Nyquist",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nyquist"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8632488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db0172576316dc748aea82e8f13fb4719ac933d5",
            "isKey": false,
            "numCitedBy": 1797,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "The most obvious method for determining the distortion of telegraph signals is to calculate the transients of the telegraph system. This method has been treated by various writers, and solutions are available for telegraph lines with simple terminal conditions. It is well known that the extension of the same methods to more complicated terminal conditions, which represent the usual terminal apparatus, leads to great difficulties. The present paper attacks the same problem from the alternative standpoint of the steady-state characteristics of the system. This method has the advantage over the method of transients that the complication of the circuit which results from the use of terminal apparatus does not complicate the calculations materially. This method of treatment necessitates expressing the criteria of distortionless transmission in terms of the steady-state characteristics. Accordingly, a considerable portion of the paper describes and illustrates a method for making this translation. A discussion is given of the minimum frequency range required for transmission at a given speed of signaling. In the case of carrier telegraphy, this discussion includes a comparison of single-sideband and double-sideband transmission. A number of incidental topics is also discussed."
            },
            "slug": "Certain-Topics-in-Telegraph-Transmission-Theory-Nyquist",
            "title": {
                "fragments": [],
                "text": "Certain Topics in Telegraph Transmission Theory"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A considerable portion of the paper describes and illustrates a method for expressing the criteria of distortionless transmission in terms of the steady-state characteristics of the system, and of the minimum frequency range required for transmission at a given speed of signaling."
            },
            "venue": {
                "fragments": [],
                "text": "Transactions of the American Institute of Electrical Engineers"
            },
            "year": 1928
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510971"
                        ],
                        "name": "T. Tollenaere",
                        "slug": "T.-Tollenaere",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Tollenaere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tollenaere"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29674798,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa79c269b31af3834b6db801bb0ad9690e13631c",
            "isKey": false,
            "numCitedBy": 407,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "SuperSAB:-Fast-adaptive-back-propagation-with-good-Tollenaere",
            "title": {
                "fragments": [],
                "text": "SuperSAB: Fast adaptive back propagation with good scaling properties"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2502999"
                        ],
                        "name": "F. Pasemann",
                        "slug": "F.-Pasemann",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Pasemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Pasemann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1044975,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74a03dc8836090764f54b30422c526e1e0679537",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces an evolutionary algorithm that is tailored to generate recurrent neural networks functioning as nonlinear controllers. Network size and architecture, as well as network parameters like weights and bias terms, are developed simultaneously. There is no quantization of inputs, outputs or internal parameters. Different kinds of evolved networks are presented that solve the pole-balancing problem, i.e. balancing an inverted pendulum. In particular, controllers solving the problem for reduced phase space information (only angle and cart position) use a recurrent connectivity structure. Evolved controllers of 'minimal' size still have a very good benchmark performance."
            },
            "slug": "Evolving-neurocontrollers-for-balancing-an-inverted-Pasemann",
            "title": {
                "fragments": [],
                "text": "Evolving neurocontrollers for balancing an inverted pendulum."
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "An evolutionary algorithm that is tailored to generate recurrent neural networks functioning as nonlinear controllers that solve the pole-balancing problem, i.e. balancing an inverted pendulum is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "Network"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144870565"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4058321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19bdcf9a68292b32605456e733d0b1b6f5e2a1e7",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper discusses the hierarchical control architecture used to generate the behavior of individual agents and a team of robots for the RoboCup Small Size competition.Our reactive approach is based on control layers organized in a temporal hierarchy. Fast and simple behaviors reside on the bottom of the hierarchy, while an increasing number of slower and more complex behaviors are implemented in the higher levels. In our architecture deliberation is not implemented explicitly, but to an external viewer it seems to be present.Each layer is composed of three modules. First, the sensor module, where the perceptual dynamics aggregates the readings of fast changing sensors in time to form complex, slow changing percepts. Next, the activation module computes the activation dynamics that determines whether or not a behavior is allowed to influence actuators, and finally the actuator module, where the active behaviors influence the actuators to match a target dynamics.We illustrate our approach by describing the bottom-up design of behaviors for the RoboCup domain."
            },
            "slug": "A-Hierarchy-of-Reactive-Behaviors-Handles-Behnke-Rojas",
            "title": {
                "fragments": [],
                "text": "A Hierarchy of Reactive Behaviors Handles Complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The hierarchical control architecture used to generate the behavior of individual agents and a team of robots for the RoboCup Small Size competition is discussed, based on control layers organized in a temporal hierarchy."
            },
            "venue": {
                "fragments": [],
                "text": "Balancing Reactivity and Social Deliberation in Multi-Agent Systems"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679793"
                        ],
                        "name": "P. Arena",
                        "slug": "P.-Arena",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Arena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Arena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143998340"
                        ],
                        "name": "L. Fortuna",
                        "slug": "L.-Fortuna",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Fortuna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Fortuna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766733"
                        ],
                        "name": "M. Frasca",
                        "slug": "M.-Frasca",
                        "structuredName": {
                            "firstName": "Mattia",
                            "lastName": "Frasca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Frasca"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3998843,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "39c390d4190b547145917bb42fa8bef7007dc467",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the control system of a biologically inspired walking robot is presented. An analog distributed system acts as Central Pattern Generator for the locomotion control, while the attitude control is performed by using a proportional integrative controller for each leg. The inclusion of a saturation block in the attitude control scheme allows to take into account the joint limits, leading to the formulation of a cellular non\u2010linear network (CNN) based attitude controller. Thus, the whole control system can be structured as an analog control system realized by CNNs generating the locomotion pattern as a function of the sensorial stimuli from the environment. Both the network design and circuit realization are presented in this paper. Some experimental results obtained with the 18 degrees\u2010of\u2010freedom walking robot prototype are also reported. Moreover, some interesting experiments showing the robot capabilities to escape from unforeseen situations, in which overloading causes the saturation of a joint motor, are emphasized as an emerging result due to the action on both the locomotion control and the attitude control. Copyright \u00a9 2002 John Wiley & Sons, Ltd."
            },
            "slug": "Attitude-control-in-walking-hexapod-robots:-an-Arena-Fortuna",
            "title": {
                "fragments": [],
                "text": "Attitude control in walking hexapod robots: an analogic spatio\u2010temporal approach"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The whole control system of a biologically inspired walking robot can be structured as an analog control system realized by CNNs generating the locomotion pattern as a function of the sensorial stimuli from the environment."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Circuit Theory Appl."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39925442"
                        ],
                        "name": "Volker Baumgarten",
                        "slug": "Volker-Baumgarten",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Baumgarten",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volker Baumgarten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145595494"
                        ],
                        "name": "G. Ehlers",
                        "slug": "G.-Ehlers",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Ehlers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ehlers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38667184"
                        ],
                        "name": "F. May",
                        "slug": "F.-May",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "May",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. May"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3290642"
                        ],
                        "name": "A. N\u00fcckel",
                        "slug": "A.-N\u00fcckel",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "N\u00fcckel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00fcckel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3344184"
                        ],
                        "name": "M. Vorbach",
                        "slug": "M.-Vorbach",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Vorbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vorbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723920"
                        ],
                        "name": "M. Weinhardt",
                        "slug": "M.-Weinhardt",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Weinhardt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Weinhardt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6280710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9c17cd09e71c19f02c069f539df7ac55e6d82f1",
            "isKey": false,
            "numCitedBy": 374,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The eXtreme Processing Platform (XPPTM) is a new runtime-reconfigurable data processing architecture. It is based on a hierarchical array of coarsegrain, adaptive computing elements, and a packet-oriented communication network. The strength of the XPPTM technology originates from the combination of array processing with unique, powerful run-time reconfiguration mechanisms. Parts of the array can be configured rapidly in parallel while neighboring computing elements are processing data. Reconfiguration is triggered externally or even by special event signals originating within the array, enabling self-reconfiguring designs. The XPPTM architecture is designed to support different types of parallelism: pipelining, instruction level, data flow, and task level parallelism. Therefore this technology is well suited for applications in multimedia, telecommunications, simulation, signal processing (DSP), graphics, and similar stream-based application domains. The anticipated peak performance of the first commercial device running at 150MHz is estimated to be 57.6 GigaOps/sec, with a peak I/O bandwidth of several GByte/sec. Simulated applications achieve up to 43.5 GigaOps/sec (32-bit fixed point)."
            },
            "slug": "PACT-XPP\u2014A-Self-Reconfigurable-Data-Processing-Baumgarten-Ehlers",
            "title": {
                "fragments": [],
                "text": "PACT XPP\u2014A Self-Reconfigurable Data Processing Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The eXtreme Processing Platform (XPPTM) is a new runtime-reconfigurable data processing architecture based on a hierarchical array of coarsegrain, adaptive computing elements, and a packet-oriented communication network that is well suited for applications in multimedia, telecommunications, simulation, signal processing, graphics, and similar stream-based application domains."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Supercomputing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144733293"
                        ],
                        "name": "R. Fletcher",
                        "slug": "R.-Fletcher",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Fletcher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fletcher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116892656,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "65146925205d9ed3139bda27b4a6717667be854e",
            "isKey": false,
            "numCitedBy": 881,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Conjugate gradient methods have often been used to solve a ~lde variety of numerical problems, including linear and nonlinear algebraic equations, eigenvalue problems and minimization problems. These applications have been s~m~lar in that they involve large numbers of variables or dimensions. In these circumstances any method of solution which involves storing a full matrix of this large order, becomes inapplicable. Thus recourse to the conjugate gradient method may be the only alternative. For problems in linear equations, the conjugate gradient method requires that the e~fficient m~trix A , is not onl~ symmetric but also positive definite. This restriction is also implicit in applications to unconstrained minimization. Yet there are many problems in which non-trivial equations have to be added to v~hat would otherwise be an elliptic system, One example is the restriction to divergence-free vectors in fluid dynamics (linear or nonlinear), and there are various other examples from partial differential equations. Also minimization problems in gersral, when involving linear or nonlinear equality constraints, provide further examples. In all these cases the coefficient matrix of the linear model has the farm"
            },
            "slug": "Conjugate-gradient-methods-for-indefinite-systems-Fletcher",
            "title": {
                "fragments": [],
                "text": "Conjugate gradient methods for indefinite systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752857"
                        ],
                        "name": "L. Prechelt",
                        "slug": "L.-Prechelt",
                        "structuredName": {
                            "firstName": "Lutz",
                            "lastName": "Prechelt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Prechelt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2887064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acbc7015cf18a46d64e6bfb339cf30f5cf8a4de2",
            "isKey": false,
            "numCitedBy": 707,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-early-stopping-using-cross-validation:-Prechelt",
            "title": {
                "fragments": [],
                "text": "Automatic early stopping using cross validation: quantifying the criteria"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143622829"
                        ],
                        "name": "C. Schaffer",
                        "slug": "C.-Schaffer",
                        "structuredName": {
                            "firstName": "Cullen",
                            "lastName": "Schaffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schaffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11669559,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "1dc51725bf0308431eb81f50ebb264b1b7c4d115",
            "isKey": false,
            "numCitedBy": 285,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "If we lack relevant problem-specific knowledge, cross-validation methods may be used to select a classification method empirically. We examine this idea here to show in what senses cross-validation does and does not solve the selection problem. As illustrated empirically, cross-validation may lead to higher average performance than application of any single classification strategy, and it also cuts the risk of poor performance. On the other hand, cross-validation is no more or less a form of bias than simpler strategies, and applying it appropriately ultimately depends in the same way on prior knowledge. In fact, cross-validation may be seen as a way of applying partial information about the applicability of alternative classification strategies."
            },
            "slug": "Selecting-a-classification-method-by-Schaffer",
            "title": {
                "fragments": [],
                "text": "Selecting a classification method by cross-validation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Empirically, cross-validation may lead to higher average performance than application of any single classification strategy, and it also cuts the risk of poor performance."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31211229"
                        ],
                        "name": "R. K\u00e1lm\u00e1n",
                        "slug": "R.-K\u00e1lm\u00e1n",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "K\u00e1lm\u00e1n",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. K\u00e1lm\u00e1n"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1242324,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "255a77422b1da74da05d1714b7875356187385bd",
            "isKey": false,
            "numCitedBy": 12017,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A unitary, lightweight outer garment constructed of a thin polyethylene film includes front and rear panels which are joined together forming a medial body member, paired arms which extend outwardly and downwardly from the upper portion of the body member, and a head opening which is located in the upper margin of the body member. The arms and body member are arranged to have unjoined coplanar lower margins and the inner side margin of each arm and the adjacent side margin of the body member lie congruously along a common line. The garment is formed by placing two rectangular sheets of the film, having a width equal to the finished length of the garment, in overlying engagement with one another on a cutting surface, thermally die cutting the sheets into the appropriate shape, and thermally sealing the resulting cut margins to complete the garment."
            },
            "slug": "A-new-approach-to-linear-filtering-and-prediction-K\u00e1lm\u00e1n",
            "title": {
                "fragments": [],
                "text": "A new approach to linear filtering and prediction problems\" transaction of the asme~journal of basic"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A unitary, lightweight outer garment constructed of a thin polyethylene film includes front and rear panels which are joined together forming a medial body member, paired arms which extend outwardly and downwardly from the upper portion of the body member and a head opening which is located in the upper margin of theBody member."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1960
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8142232,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a36b028d024bf358c4af1a5e1dc3ca0aed23b553",
            "isKey": false,
            "numCitedBy": 3710,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady. The paper was first published in Russian as \u0412\u0430\u043f\u043d\u0438\u043a \u0412. \u041d. and \u0427\u0435\u0440\u0432\u043e\u043d\u0435\u043d\u043a\u0438\u0441 \u0410. \u042f. \u041e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0419 \u0441\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438 \u0447\u0430\u0441\u0442\u043e\u0442 \u043f\u043e\u044f\u0432\u043b\u0435\u043d\u0438\u044f \u0441\u043e\u0431\u044b\u0442\u0438\u0419 \u043a \u0438\u0445 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044f\u043c. \u0422\u0435\u043e\u0440\u0438\u044f \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u0435\u0419 \u0438 \u0435\u0435 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u044f 16(2), 264\u2013279 (1971)."
            },
            "slug": "Chervonenkis:-On-the-uniform-convergence-of-of-to-Vapnik",
            "title": {
                "fragments": [],
                "text": "Chervonenkis: On the uniform convergence of relative frequencies of events to their probabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter reproduces the English translation by B. Seckler of the paper by Vapnik and Chervonenkis in which they gave proofs for the innovative results they had obtained in a draft form in July 1966 and announced in 1968 in their note in Soviet Mathematics Doklady."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35043531"
                        ],
                        "name": "A. Dempster",
                        "slug": "A.-Dempster",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Dempster",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dempster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7890796"
                        ],
                        "name": "N. Laird",
                        "slug": "N.-Laird",
                        "structuredName": {
                            "firstName": "Nan",
                            "lastName": "Laird",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Laird"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235217"
                        ],
                        "name": "D. Rubin",
                        "slug": "D.-Rubin",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Rubin",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rubin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4193919,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "d36efb9ad91e00faa334b549ce989bfae7e2907a",
            "isKey": false,
            "numCitedBy": 48406,
            "numCiting": 134,
            "paperAbstract": {
                "fragments": [],
                "text": "Vibratory power unit for vibrating conveyers and screens comprising an asynchronous polyphase motor, at least one pair of associated unbalanced masses disposed on the shaft of said motor, with the first mass of a pair of said unbalanced masses being rigidly fastened to said shaft and with said second mass of said pair being movably arranged relative to said first mass, means for controlling and regulating the conveying rate during conveyer operation by varying the rotational speed of said motor between predetermined minimum and maximum values, said second mass being movably outwardly by centrifugal force against the pressure of spring means, said spring means being prestressed in such a manner that said second mass is, at rotational motor speeds lower than said minimum speed, held in its initial position, and at motor speeds between said lower and upper values in positions which are radially offset with respect to the axis of said motor to an extent depending on the value of said rotational motor speed."
            },
            "slug": "Maximum-likelihood-from-incomplete-data-via-the-EM-Dempster-Laird",
            "title": {
                "fragments": [],
                "text": "Maximum likelihood from incomplete data via the EM - algorithm plus discussions on the paper"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5369693"
                        ],
                        "name": "W. Barthlott",
                        "slug": "W.-Barthlott",
                        "structuredName": {
                            "firstName": "Wilhelm",
                            "lastName": "Barthlott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Barthlott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90571281"
                        ],
                        "name": "C. Neinhuis",
                        "slug": "C.-Neinhuis",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Neinhuis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Neinhuis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37872229,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "d2e9eab60548f178e0003b427d9d5e50456d076e",
            "isKey": false,
            "numCitedBy": 5115,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. The microrelief of plant surfaces, mainly caused by epicuticular wax crystalloids, serves different purposes and often causes effective water repellency. Furthermore, the adhesion of contaminating particles is reduced. Based on experimental data carried out on microscopically smooth (Fagus sylvatica L., Gnetum gnemon L., Heliconia densiflora Verlot, Magnolia grandiflora L.) and rough water-repellent plants (Brassica oleracea L., Colocasia esculenta (L.) Schott., Mutisia decurrens Cav., Nelumbo nucifera Gaertn.), it is shown here for the first time that the interdependence between surface roughness, reduced particle adhesion and water repellency is the keystone in the self-cleaning mechanism of many biological surfaces. The plants were artificially contaminated with various particles and subsequently subjected to artificial rinsing by sprinkler or fog generator. In the case of water-repellent leaves, the particles were removed completely by water droplets that rolled off the surfaces independent of their chemical nature or size. The leaves of N. nucifera afford an impressive demonstration of this effect, which is, therefore, called the \u201cLotus-Effect\u201d and which may be of great biological and technological importance."
            },
            "slug": "Purity-of-the-sacred-lotus,-or-escape-from-in-Barthlott-Neinhuis",
            "title": {
                "fragments": [],
                "text": "Purity of the sacred lotus, or escape from contamination in biological surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown here for the first time that the interdependence between surface roughness, reduced particle adhesion and water repellency is the keystone in the self-cleaning mechanism of many biological surfaces."
            },
            "venue": {
                "fragments": [],
                "text": "Planta"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064699986"
                        ],
                        "name": "D. Chakrabarti",
                        "slug": "D.-Chakrabarti",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Chakrabarti",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chakrabarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068766142"
                        ],
                        "name": "P. Hoyer",
                        "slug": "P.-Hoyer",
                        "structuredName": {
                            "firstName": "Patrik",
                            "lastName": "Hoyer",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hoyer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 118274211,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "6ade6139ee56684cdf190f7f1212541fcb5ffb69",
            "isKey": false,
            "numCitedBy": 2269,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An apparatus for hydrolytic degradation of plastics in which plastic material is deposited into a tubular housing via a feed hopper. An elongated screw shaft has a first section in the form of a high pitch screw thread disposed below the feed hopper to receive and advance the material to a second section. The second section of the screw shaft is in the form of a lower pitch thread for compressing the plastic material and transferring it to a longer, third section in the form of kneading discs, from which material passes through an outlet nozzle section to a cyclone separator where trapped gases and liquid may be withdrawn. The tubular housing is vented upstream of the feed hopper and a water inlet pipe is disposed adjacent to the second section of the screw shaft, downstream of the feed hopper. The outlet nozzle section is provided with pressure measuring and regulating means and a liquid level measuring and regulating device."
            },
            "slug": "A-fast-fixed-point-algorithm-for-independent-Chakrabarti-Hoyer",
            "title": {
                "fragments": [],
                "text": "A fast fixed - point algorithm for independent component analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49819174"
                        ],
                        "name": "W. Heisenberg",
                        "slug": "W.-Heisenberg",
                        "structuredName": {
                            "firstName": "Werner",
                            "lastName": "Heisenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Heisenberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122763326,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "c68b8299e4caefff8f1f67fce475b4740d69b9e0",
            "isKey": false,
            "numCitedBy": 3157,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "ZusammenfassungIn der vorliegenden Arbeit werden zun\u00e4chst exakte Definitionen der Worte: Ort, Geschwindigkeit, Energie usw. (z. B. des Elektrons) aufgestellt, die auch in der Quantenmechanik G\u00fcltigkeit behalten, und es wird gezeigt, da\u00df kanonisch konjugierte Gr\u00f6\u00dfen simultan nur mit einer charakteristischen Ungenauigkeit bestimmt werden k\u00f6nnen (\u00a7 1). Diese Ungenauigkeit ist der eigentliche Grund f\u00fcr das Auftreten statistischer Zusammenh\u00e4nge in der Quantenmechanik. Ihre mathematische Formulierung gelingt mittels der Dirac-Jordanschen Theorie (\u00a7 2). Von den so gewonnenen Grunds\u00e4tzen ausgehend wird gezeigt, wie die makroskopischen Vorg\u00e4nge aus der Quantenmechanik heraus verstanden werden k\u00f6nnen (\u00a7 3). Zur Erl\u00e4uterung der Theorie werden einige besondere Gedankenexperimente diskutiert (\u00a7 4)."
            },
            "slug": "\u00dcber-den-anschaulichen-Inhalt-der-Kinematik-und-Heisenberg",
            "title": {
                "fragments": [],
                "text": "\u00dcber den anschaulichen Inhalt der quantentheoretischen Kinematik und Mechanik"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1927
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145447865"
                        ],
                        "name": "A. Mansour",
                        "slug": "A.-Mansour",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mansour"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208963683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3af7f1ecb210ad315aeae4ffae932d17f9f85d47",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Blind-Separation-of-Sources-Mansour",
            "title": {
                "fragments": [],
                "text": "Blind Separation of Sources"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123013770"
                        ],
                        "name": "A. Rosenfeld",
                        "slug": "A.-Rosenfeld",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rosenfeld"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 236117774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58e7049da3b3e6b1f432ccaca78d16af790d6abc",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Coarse-fine-template-matching-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Coarse-fine template matching"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134256000"
                        ],
                        "name": "Kurd Lasswitz",
                        "slug": "Kurd-Lasswitz",
                        "structuredName": {
                            "firstName": "Kurd",
                            "lastName": "Lasswitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kurd Lasswitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 178033635,
            "fieldsOfStudy": [],
            "id": "0e93809ae46a24aa5bc9257205b0f600333fb35a",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gustav-Theodor-Fechner-Lasswitz",
            "title": {
                "fragments": [],
                "text": "Gustav Theodor Fechner"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1910
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144506416"
                        ],
                        "name": "R. Caminiti",
                        "slug": "R.-Caminiti",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Caminiti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caminiti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400330681"
                        ],
                        "name": "A. Battaglia-Mayer",
                        "slug": "A.-Battaglia-Mayer",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Battaglia-Mayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Battaglia-Mayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189155"
                        ],
                        "name": "R. Andersen",
                        "slug": "R.-Andersen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Andersen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Andersen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 141999808,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a0475fc8ce174ca8ff4322e609e723f6e8a7d0f0",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-and-movement-:-mechanisms-in-the-cerebral-Caminiti-Battaglia-Mayer",
            "title": {
                "fragments": [],
                "text": "Vision and movement : mechanisms in the cerebral cortex"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144246983"
                        ],
                        "name": "H. Barlow",
                        "slug": "H.-Barlow",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Barlow",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Barlow"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 124937374,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d4c74862e9b0011ea922e3ee171ebd06af568bf5",
            "isKey": false,
            "numCitedBy": 1503,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision:-A-computational-investigation-into-the-and-Barlow",
            "title": {
                "fragments": [],
                "text": "Vision: A computational investigation into the human representation and processing of visual information: David Marr. San Francisco: W. H. Freeman, 1982. pp. xvi + 397"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103312634"
                        ],
                        "name": "A. Haar",
                        "slug": "A.-Haar",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Haar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Haar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120024038,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "94d5f555219cf3a657b3fb80325bbb7624f42176",
            "isKey": false,
            "numCitedBy": 1898,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Zur-Theorie-der-orthogonalen-Funktionensysteme-Haar",
            "title": {
                "fragments": [],
                "text": "Zur Theorie der orthogonalen Funktionensysteme"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1910
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2267665"
                        ],
                        "name": "T. Odanaka",
                        "slug": "T.-Odanaka",
                        "structuredName": {
                            "firstName": "Toshio",
                            "lastName": "Odanaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Odanaka"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64110208,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c7ed37a5da5f26c5abb7042a93eb0e18e72308b",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ADAPTIVE-CONTROL-PROCESSES-Odanaka",
            "title": {
                "fragments": [],
                "text": "ADAPTIVE CONTROL PROCESSES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144873562"
                        ],
                        "name": "R. Bellman",
                        "slug": "R.-Bellman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bellman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bellman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62668616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a0cd8a28b7668fcd38b98b8e1598c33e1852077",
            "isKey": false,
            "numCitedBy": 846,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "V.-Adaptive-Control-Processes-Bellman",
            "title": {
                "fragments": [],
                "text": "V. Adaptive Control Processes"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066028102"
                        ],
                        "name": "E. Weber",
                        "slug": "E.-Weber",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Weber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Weber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60370401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f83b01a0b2fe92e5f570eb0a91eee1105e237f7f",
            "isKey": false,
            "numCitedBy": 329,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "De-pulsu,-resorptione,-auditu-et-tactu.-anatomicae-Weber",
            "title": {
                "fragments": [],
                "text": "De pulsu, resorptione, auditu et tactu. Annotationes anatomicae et physiologicae"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1834
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703768"
                        ],
                        "name": "A. Andrew",
                        "slug": "A.-Andrew",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Andrew",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Andrew"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 195937764,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "8c63689611fd1bf40d6a5ca14ba730ca7e62d283",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reinforcement-Learning:-:-An-Introduction-Andrew",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: : An Introduction"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624227"
                        ],
                        "name": "C. Koch",
                        "slug": "C.-Koch",
                        "structuredName": {
                            "firstName": "Christof",
                            "lastName": "Koch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108840492"
                        ],
                        "name": "Hua Li",
                        "slug": "Hua-Li",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57804459,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bc1b88d39b9df0843786b7c9f28f3882533b4b4",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Vision-Chips:-Implementing-Vision-Algorithms-with-Koch-Li",
            "title": {
                "fragments": [],
                "text": "Vision Chips: Implementing Vision Algorithms with Analog VLSI Circuits"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57100530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e70b4af0c13eac9bbb4445b9822350a60aad15b3",
            "isKey": false,
            "numCitedBy": 1244,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-Systems-That-Learn-Weiss",
            "title": {
                "fragments": [],
                "text": "Computer Systems That Learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144780498"
                        ],
                        "name": "D. Lovell",
                        "slug": "D.-Lovell",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lovell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lovell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 53921568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "113e01dbe268a49431eba4501e4fa9dd1718bd0e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-neocognitron-as-a-system-for-handwritten-:-and-Lovell",
            "title": {
                "fragments": [],
                "text": "The neocognitron as a system for handwritten character recognition : limitations and improvements"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109503620"
                        ],
                        "name": "Temple F. Smith",
                        "slug": "Temple-F.-Smith",
                        "structuredName": {
                            "firstName": "Temple",
                            "lastName": "Smith",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Temple F. Smith"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 4276691,
            "fieldsOfStudy": [
                "Biology",
                "Medicine"
            ],
            "id": "0b4d43ef0051a225e07af8194e81007ebba8d787",
            "isKey": false,
            "numCitedBy": 705,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Occam's-razor-Smith",
            "title": {
                "fragments": [],
                "text": "Occam's razor"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136478"
                        ],
                        "name": "P. Grother",
                        "slug": "P.-Grother",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Grother",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Grother"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60882981,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b103253be683ed1b502764678181682ecd7cca74",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We report recognition results for several pattern classifiers trained and tested on disjoint sets of 30620 digits selected from the first 500 writers of NIST Special Database 3. The classifiers are ubiquitous in traditional pattern recognition literature (minimum distance, maximum a posteriori, nearest neighbor) as well as neural network literature (multilayer perceptron, radial basis functions, probabilistic neural network). For the purpose of valid comparison of classifiers fixed sets of Karhunen-Loeve Transforms, were used as features. These were produced from images preprocessed using the fixed methods for size and orientation normalization. The \u201cKmeans\u201d clustering algorithm is used to produce subclasses thereby supervising training and aiding recognition. Graphical displays of classification and associated confidences illustrate classifier complexity. Recognition error rates for all the classifiers are tabulated as a function of feature vector dimension. Computational and memory requirements of the different classifiers are also compared."
            },
            "slug": "Comparison-of-Handprinted-Digit-Classifiers-Grother",
            "title": {
                "fragments": [],
                "text": "Comparison of Handprinted Digit Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "Recognition results for several pattern classifiers trained and tested on disjoint sets of 30620 digits selected from the first 500 writers of NIST Special Database 3.0 are reported."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699019"
                        ],
                        "name": "Sven Behnke",
                        "slug": "Sven-Behnke",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Behnke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Behnke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3273339"
                        ],
                        "name": "B. Fr\u00f6tschl",
                        "slug": "B.-Fr\u00f6tschl",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Fr\u00f6tschl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Fr\u00f6tschl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053131033"
                        ],
                        "name": "R. Rojas",
                        "slug": "R.-Rojas",
                        "structuredName": {
                            "firstName": "Ra\u00fal",
                            "lastName": "Rojas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rojas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70601184"
                        ],
                        "name": "P. Ackers",
                        "slug": "P.-Ackers",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Ackers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ackers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782386"
                        ],
                        "name": "Wolf Lindstrot",
                        "slug": "Wolf-Lindstrot",
                        "structuredName": {
                            "firstName": "Wolf",
                            "lastName": "Lindstrot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolf Lindstrot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144951500"
                        ],
                        "name": "M. P. Melo",
                        "slug": "M.-P.-Melo",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Melo",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. P. Melo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1883425"
                        ],
                        "name": "A. Schebesch",
                        "slug": "A.-Schebesch",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Schebesch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schebesch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114371266"
                        ],
                        "name": "Mark Simon",
                        "slug": "Mark-Simon",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Simon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35127306"
                        ],
                        "name": "M. Sprengel",
                        "slug": "M.-Sprengel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Sprengel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sprengel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2554155"
                        ],
                        "name": "Oliver Tenchio",
                        "slug": "Oliver-Tenchio",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Tenchio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oliver Tenchio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 46486244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a722128321a56794ce690b8c774569dbd7670e4",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the mechanical and electrical design, as well as the control strategy, of the FU-Fighters robots, a F180 league team that won the second place at RoboCup'99. It explains how we solved the computer vision and radio communication problems that arose in the course of the project.The paper mainly discusses the hierarchical control architecture used to generate the behavior of individual agents and the team. Our reactive approach is based on the Dual Dynamics framework developed by H. Jager, in which activation dynamics determines when a behavior is allowed to influence the actuators, and a target dynamics establishes how this is done. We extended the original framework by adding a third module, the perceptual dynamics. Here, the readings of fast changing sensors are aggregated temporarily to form complex, slow changing percepts.We describe the bottom-up design of behaviors and illustrate our approach using examples from the RoboCup domain."
            },
            "slug": "Using-Hierarchical-Dynamical-Systems-to-Control-Behnke-Fr\u00f6tschl",
            "title": {
                "fragments": [],
                "text": "Using Hierarchical Dynamical Systems to Control Reactive Behavior"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper describes the mechanical and electrical design, as well as the control strategy, of the FU-Fighters robots, a F180 league team that won the second place at RoboCup'99, and explains how it solved the computer vision and radio communication problems that arose in the course of the project."
            },
            "venue": {
                "fragments": [],
                "text": "RoboCup"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092878885"
                        ],
                        "name": "J. Wellner",
                        "slug": "J.-Wellner",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Wellner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wellner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242001"
                        ],
                        "name": "A. Schierwagen",
                        "slug": "A.-Schierwagen",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Schierwagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Schierwagen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58530391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31365ee3f810b7c7630906238953693cebba8d85",
            "isKey": false,
            "numCitedBy": 3,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In modelling neuronal phenomena one can generally choose two different methods (Levine, 1991): One way is to setup a network of discrete model neurons and all their interconnection weights, which is usually done in the so-called PDP approach (Rumelhart and McClelland, 1986; McClelland and Rumelhart, 1986). The main interest lies on the learning capabilities of the established network, i. e. on the correct adaptations of the connection weights, in order to generate the correct output for a given input. Another approach to neuronal modelling is using continuous networks (so-called fields) with special attention to the spatio-temporal activities of the network. The number of neurons is unlimited in these models, and the connections between the neurons are handled in a general way (e. g. statistically) without having individually changing weights. Therefore, instead of being interested in the learning mechanisms of the network one investigates the various dynamics of the fields. It is a convenient way to describe the evolution equations of the field by integro-differential equations (IDEs)."
            },
            "slug": "Cellular-automata-like-simulations-of-dynamic-Wellner-Schierwagen",
            "title": {
                "fragments": [],
                "text": "Cellular-automata-like simulations of dynamic neural fields"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "In modelling neuronal phenomena one can generally choose two different methods (Levine, 1991): one way is to setup a network of discrete model neurons and all their interconnection weights, which is usually done in the so-called PDP approach, while another approach is using continuous networks with special attention to the spatio-temporal activities of the network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Size and position invariance of neuronal responses in inferotemporal cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Neurophysiology"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Application to face recognition.Optical Engineering, 38:2894\u20132899"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The neurophysiology of figureground segregation in primary visual cortex"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Neuroscience"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "USS -Code 39. BC1, ANSI/AIM"
            },
            "venue": {
                "fragments": [],
                "text": "USS -Code 39. BC1, ANSI/AIM"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for non"
            },
            "venue": {
                "fragments": [],
                "text": "factorization.Nature,"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Single units and sensation"
            },
            "venue": {
                "fragments": [],
                "text": "Perception"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "USS -Code 49"
            },
            "venue": {
                "fragments": [],
                "text": "USS -Code 49"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Perception of obj"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NIST special database 3 \u2013 handwritten segmented characters"
            },
            "venue": {
                "fragments": [],
                "text": "NIST special database 3 \u2013 handwritten segmented characters"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Faster-learning variations on backpropagation: An empirical study"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1988 Connectionist Models Summer School \u2013 Pittsburg"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Polynomial codes ov"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AIM, Inc. ISS Data Matrix. BC11, ANSI/AIM"
            },
            "venue": {
                "fragments": [],
                "text": "AIM, Inc. ISS Data Matrix. BC11, ANSI/AIM"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Example-based superresolution"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Local connections in a neural network improve pattern completion"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Cognitive and Neural Systems (CNS'99) \u2013 Boston"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Organization of Behaviour"
            },
            "venue": {
                "fragments": [],
                "text": "The Organization of Behaviour"
            },
            "year": 1949
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning by online gradient descent"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Physics A"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An algorithm for the machine computation of the complex Fourier series"
            },
            "venue": {
                "fragments": [],
                "text": "Mathematics of Computation"
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Acceleration tec"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature discovery"
            },
            "venue": {
                "fragments": [],
                "text": "Nature,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Principles of Gestalt Psychology. A Harbinger Book"
            },
            "venue": {
                "fragments": [],
                "text": "Principles of Gestalt Psychology. A Harbinger Book"
            },
            "year": 1935
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shape represen"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recurrent V1-V2 inter"
            },
            "venue": {
                "fragments": [],
                "text": "Spatial Vision,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The \u2019echo state"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optische Urteilt\u00e4uschungen. Archiv f\u00fcr Anatomie und Physilogie"
            },
            "venue": {
                "fragments": [],
                "text": "Optische Urteilt\u00e4uschungen. Archiv f\u00fcr Anatomie und Physilogie"
            },
            "year": 1889
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Displacement estimation by hierarchical blockmatching. SPIE Visual Communications and Image Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Displacement estimation by hierarchical blockmatching. SPIE Visual Communications and Image Processing"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Selective attention stimulus integration"
            },
            "venue": {
                "fragments": [],
                "text": "S. Dornie, editor, Attention and Performance VI"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Methodus fluxionum et serierum infinitarum"
            },
            "venue": {
                "fragments": [],
                "text": "Methodus fluxionum et serierum infinitarum"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Signal processing and compression with wave packets"
            },
            "venue": {
                "fragments": [],
                "text": "Wavelets and Their Applications"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Young infants perception of object trajectories: Filling in a spatiotemporal gap"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 12th International Conference on Infant Studies (ICIS2000) \u2013"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Infineon enables third dimension of chip integration \u2013 develops SOLID stacking technology to connect multiple chips for 'system-in-package' electronics. Press release"
            },
            "venue": {
                "fragments": [],
                "text": "Infineon enables third dimension of chip integration \u2013 develops SOLID stacking technology to connect multiple chips for 'system-in-package' electronics. Press release"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Least squares quantization in PCM Technical note, Bell laboratories"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Information Theory"
            },
            "year": 1957
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition with a backpropagation network"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information processing in dynamical s"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing hand-wr"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A learning algorithm for Boltzman machines"
            },
            "venue": {
                "fragments": [],
                "text": "Cognitive Science"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and Its Applications"
            },
            "venue": {
                "fragments": [],
                "text": "On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and Its Applications"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Organization in Vision"
            },
            "venue": {
                "fragments": [],
                "text": "Organization in Vision"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pitney Bowes Model M postage meter 1920 Designated the 20th international historic mechanical engineering landmark, The American Society of Mechanical Engineers"
            },
            "venue": {
                "fragments": [],
                "text": "Pitney Bowes Model M postage meter 1920 Designated the 20th international historic mechanical engineering landmark, The American Society of Mechanical Engineers"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High-speed VSD ima"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A study on the combination of classifiers for handwritten digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of Third International Workshop on Neural Networks in Applications (NN'98) \u2013"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Uber ein wichtiges psychophysisches Grundgesetz und dessen Beziehung zur Sch\u00e4tzung von Sterngr\u00f6ssen"
            },
            "venue": {
                "fragments": [],
                "text": "Abk. k. Ges. Wissensch. Math.-Phys"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Uber ein wichtiges psychophysisches Grundgesetz und dessen Beziehung zur Sch\u00e4tzung von Sterngr\u00f6ssen"
            },
            "venue": {
                "fragments": [],
                "text": "Abk. k. Ges. Wissensch. Math.-Phys"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scale-space and edge"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards an axiomatic theory of preattentive vision"
            },
            "venue": {
                "fragments": [],
                "text": "Dynamic Aspects of Neocortical Function"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Pattern Recognition and Scene Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognition and Scene Analysis"
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speech recognition with missing data techniques using recurrent neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems 14"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ingrid Daubechies. Ten Lectures on Wavelets CBMS-NSF Series in Applied Mathematics. SIAM Publications"
            },
            "venue": {
                "fragments": [],
                "text": "Ingrid Daubechies. Ten Lectures on Wavelets CBMS-NSF Series in Applied Mathematics. SIAM Publications"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rank order coding: A new coding scheme for rapid processing in neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Computational Neuroscience : Trends in Research"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 267,
        "totalPages": 27
    },
    "page_url": "https://www.semanticscholar.org/paper/Hierarchical-Neural-Networks-for-Image-Behnke/43b87f5f4da973a513eaddb779032f0ceacfa394?sort=total-citations"
}