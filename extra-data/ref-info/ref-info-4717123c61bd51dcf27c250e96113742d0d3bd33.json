{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46817286"
                        ],
                        "name": "F. Stein",
                        "slug": "F.-Stein",
                        "structuredName": {
                            "firstName": "Fridtjof",
                            "lastName": "Stein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Stein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3463966"
                        ],
                        "name": "G. Medioni",
                        "slug": "G.-Medioni",
                        "structuredName": {
                            "firstName": "G\u00e9rard",
                            "lastName": "Medioni",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Medioni"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5329255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2f8292adaeed138fcb63bf9de7d7f79127e6096",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of recognition of multiple flat objects in a cluttered environment from an arbitrary viewpoint (weak perspective) is addressed. The models are acquired automatically and initially approximated by polygons with multiple line tolerances for robustness. Groups of consecutive segments (supersegments) are then gray-coded and entered into a hash table. This provides the essential mechanism for indexing and fast retrieval. Once the database of all models is built, the recognition proceeds by segmenting the scene into a polygonal approximation; the gray code for each supersegment retrieves model hypotheses from the hash table. Hypotheses are clustered if they are mutually consistent and represent the instance of a model. The estimate of the transformation is refined. This methodology makes it possible to recognize models in the presence of noise, occlusion, scale, rotation, translation, and weak perspective. Unlike most of the current systems, its complexity grows as O(kN), where N is the number of models and k<<1/.<<ETX>>"
            },
            "slug": "Efficient-two-dimensional-object-recognition-Stein-Medioni",
            "title": {
                "fragments": [],
                "text": "Efficient two dimensional object recognition"
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings. 10th International Conference on Pattern Recognition"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 678619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8735690a9e8f8884bf27717877ddf7f9071472e5",
            "isKey": false,
            "numCitedBy": 1457,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Three-Dimensional-Object-Recognition-from-Single-Lowe",
            "title": {
                "fragments": [],
                "text": "Three-Dimensional Object Recognition from Single Two-Dimensional Images"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33470636,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "754b3ce07da5ea86193c4f4733be80fa72de5858",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Object recognition from sensory data involves, in part, determining the pose of a model with respect to a scene. A common method for finding an object's pose is the generalized Hough transform, which accumulates evidence for possible coordinate transformations in a parameter space whose axes are the quantized transformation parameters. Large clusters of similar transformations in that space are taken as evidence of a correct match. A theoretical analysis of the behavior of such methods is presented. The authors derive bounds on the set of transformations consistent with each pairing of data and model features, in the presence of noise and occlusion in the image. Bounds are provided on the likelihood of false peaks in the parameter space, as a function of noise, occlusion, and tessellation effects. It is argued that haphazardly applying such methods to complex recognition tasks is risky, as the probability of false positives can be very high. >"
            },
            "slug": "On-The-Sensitivity-Of-The-Hough-Transform-For-Grimson-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "On the Sensitivity of the Hough Transform for Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is argued that haphazardly applying generalized Hough transform methods to complex recognition tasks is risky, as the probability of false positives can be very high."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2331213"
                        ],
                        "name": "S. Edelman",
                        "slug": "S.-Edelman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Edelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Edelman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 61
                            }
                        ],
                        "text": "In recent work, Poggio has recognized wire objects and faces [15; 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4361875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50899b2355d6908a304bacb5e406f800f3dde558",
            "isKey": false,
            "numCitedBy": 1019,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "THE visual recognition of three-dimensional (3-D) objects on the basis of their shape poses at least two difficult problems. First, there is the problem of variable illumination, which can be addressed by working with relatively stable features such as intensity edges rather than the raw intensity images1,2. Second, there is the problem of the initially unknown pose of the object relative to the viewer. In one approach to this problem, a hypothesis is first made about the viewpoint, then the appearance of a model object from such a viewpoint is computed and compared with the actual image3\u20137. Such recognition schemes generally employ 3-D models of objects, but the automatic learning of 3-D models is itself a difficult problem8,9. To address this problem in computational vision, we have developed a scheme, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view. A network equivalent to this scheme will thus 'recognize' the object on which it was trained from any viewpoint."
            },
            "slug": "A-network-that-learns-to-recognize-objects-Poggio-Edelman",
            "title": {
                "fragments": [],
                "text": "A network that learns to recognize three-dimensional objects"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A scheme is developed, based on the theory of approximation of multivariate functions, that learns from a small set of perspective views a function mapping any viewpoint to a standard view, and a network equivalent to this scheme will 'recognize' the object on which it was trained from any viewpoint."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743045"
                        ],
                        "name": "S. Ullman",
                        "slug": "S.-Ullman",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Ullman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760994"
                        ],
                        "name": "R. Basri",
                        "slug": "R.-Basri",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Basri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Basri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8989489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d781d5e651e12bf666cf993ae307db785113b9ae",
            "isKey": false,
            "numCitedBy": 951,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed. It is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views. For objects with sharp edges, the linear combination representation is exact. For objects with smooth boundaries, it is an approximation that often holds over a wide range of viewing angles. Rigid transformations (with or without scaling) can be distinguished from more general linear transformations of the object by testing certain constraints placed on the coefficients of the linear combinations. Three alternative methods of determining the transformation that matches a model to a given image are proposed. >"
            },
            "slug": "Recognition-by-Linear-Combinations-of-Models-Ullman-Basri",
            "title": {
                "fragments": [],
                "text": "Recognition by Linear Combinations of Models"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to visual object recognition in which a 3D object is represented by the linear combination of 2D images of the object is proposed and it is shown that for objects with sharp edges as well as with smooth bounding contours, the set of possible images of a given object is embedded in a linear space spanned by a small number of views."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1530384,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4462c82748d81489f4f453f516754438b35a8cec",
            "isKey": false,
            "numCitedBy": 961,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "With contributions from Tomas LozanoPerez and Daniel P. Huttenlocher.An intelligent system must know \"what \"the objects are and \"where \"they are in its environment. Examples of this ubiquitous problem in computer vision arise in tasks involving hand-eye coordination (such as assembling or sorting), inspection tasks, gauging operations, and in navigation and localization of mobile robots. This book describes an extended series of experiments into the role of geometry in the critical area of object recognition. It provides precise definitions of the recognition and localization problems, describes the methods used to address them, analyzes the solutions to these problems, and addresses the implications of this analysis.The solution to problems of object recognition are of fundamental importance in many real applications and versions of the techniques described here are already being used in industrial settings. Although a number of questions remain to be solved, the authors provide a valuable framework for understanding both the strengths and limitations of using object shape to guide recognition.W. Eric L. Grimson is Matsushita Associate Professor in the Department of Electrical Engineering and Computer Science at MIT.Contents: Introduction. Recognition as a Search Problem. Searching for Correspondences. Two-Dimensional Constraints. Three-Dimensional Constraints. Verifying Hypotheses. Controlling the Search Explosion. Selecting Subspaces of the Search Space. Empirical Testing. The Combinatorics of the Matching Process. The Combinatorics of Hough Transforms. The Combinatorics of Verification. The Combinatorics of Indexing. Evaluating the Methods. Recognition from Libraries. Parameterized Objects. The Role of Grouping. Sensing Strategies. Applications. The Next Steps."
            },
            "slug": "Object-recognition-by-computer-the-role-of-Grimson",
            "title": {
                "fragments": [],
                "text": "Object recognition by computer - the role of geometric constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This book describes an extended series of experiments into the role of geometry in the critical area of object recognition, providing precise definitions of the recognition and localization problems, the methods used to address them, the solutions to these problems, and the implications of this analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145299933"
                        ],
                        "name": "R. Mohr",
                        "slug": "R.-Mohr",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Mohr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mohr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10291007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a221ae60093283ef438e8b69e26094a2480a6299",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of recognizing objects in large image databases. The method is based on local characteristics which are invariant to similarity transformations in the image. These characteristics are computed at automatically detected keypoints using the greyvalue signal. The method therefore works on images such as paintings for which geometry based recognition fails. Due to the locality of the method, images can be recognized being given part of an image and in the presence of occlusions. Applying a voting algorithm and semi-local constraints makes the method robust to noise, scene clutter and small perspective deformations. Experiments show an efficient recognition for different types of images. The approach has been validated on an image database containing 1020 images, some of them being very similar by structure, texture or shape."
            },
            "slug": "Combining-greyvalue-invariants-with-local-for-Schmid-Mohr",
            "title": {
                "fragments": [],
                "text": "Combining greyvalue invariants with local constraints for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The method is based on local characteristics which are invariant to similarity transformations in the image and computed at automatically detected keypoints using the greyvalue signal and works on images such as paintings for which geometry based recognition fails."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82910116"
                        ],
                        "name": "H. Murase",
                        "slug": "H.-Murase",
                        "structuredName": {
                            "firstName": "Hiroshi",
                            "lastName": "Murase",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Murase"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750470"
                        ],
                        "name": "S. Nayar",
                        "slug": "S.-Nayar",
                        "structuredName": {
                            "firstName": "Shree",
                            "lastName": "Nayar",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nayar"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61999742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c5648d1f511a5180cc0bf7af80a42d3dea3a4680",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation. In contrast to the traditional approach, they formulate the recognition problem as one of matching visual appearance rather than shape. The appearance of an object in a two-dimensional image depends on its shape, reflectance properties, pose in the scene, and the illumination conditions. While shape and reflectance are intrinsic properties of an object and are constant, pose and illumination vary from scene to scene. They present a new compact representation of object appearance that is parameterized by pose and illumination. They have conducted experiments using several objects with complex appearance characteristics.<<ETX>>"
            },
            "slug": "Learning-and-recognition-of-3D-objects-from-Murase-Nayar",
            "title": {
                "fragments": [],
                "text": "Learning and recognition of 3D objects from appearance"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "The authors address the problem of automatically learning object models for recognition and pose estimation as one of matching visual appearance rather than shape and present a new compact representation of object appearance that is parameterized by pose and illumination."
            },
            "venue": {
                "fragments": [],
                "text": "[1993] Proceedings IEEE Workshop on Qualitative Vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 2
                            }
                        ],
                        "text": ", [17; 19; 2] but also visually, for various representations [20; 3; 1; 5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 39741769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e9eab710eb82fdab42e980e74a0784eb3e581b",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to representing objects viewed over long periods of time and with changing resolutions is presented. The basic strategy is to apply different representations as they become appropriate. As a result, the model of an object typically goes through a sequence of representation as new data are gathered and processed. One of these sequences might start with a crude blob description of an initially detected object, include a detailed structural model derived from a set of high-resolution images, and end with a semantic label based on the object's description and the sensor system's task. This evolution in representation is guided by a structure referred to as representation space: a lattice or representation that is traversed as new information about an object becomes available. One of the representations is associated with an object only after it has been judged to be valid. One approach for evaluating the validity of an object's description is described, based on the temporal stability of the description. These ideas are illustrated with results from a system which constructs and refines models of outdoor objects detected in sequences of range data.<<ETX>>"
            },
            "slug": "Representation-space:-an-approach-to-the-of-visual-Bobick-Bolles",
            "title": {
                "fragments": [],
                "text": "Representation space: an approach to the integration of visual information"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "One approach for evaluating the validity of an object's description is described, based on the temporal stability of the description, and results from a system which constructs and refines models of outdoor objects detected in sequences of range data are illustrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings CVPR '89: IEEE Computer Society Conference on Computer Vision and Pattern Recognition"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144827643"
                        ],
                        "name": "N. Ayache",
                        "slug": "N.-Ayache",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Ayache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ayache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33726225"
                        ],
                        "name": "O. Faugeras",
                        "slug": "O.-Faugeras",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Faugeras",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Faugeras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 61
                            }
                        ],
                        "text": ", [17; 19; 2] but also visually, for various representations [20; 3; 1; 5]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6559782,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9191de6f4059469b54cb576322e331c51312dc6f",
            "isKey": false,
            "numCitedBy": 559,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method has been designed to identify and locate objects lying on a flat surface. The merit of the approach is to provide strong robustness to partial occlusions (due for instance to uneven lighting conditions, shadows, highlights, touching and overlapping objects) thanks to a local and compact description of the objects boundaries and to a new fast recognition method involving generation and recursive evaluation of hypotheses named HYPER (HY potheses Predicted and Evaluated Recursively). The method has been integrated within a vision system coupled to an indutrial robot arm, to provide automatic picking and repositioning of partially overlapping industrial parts."
            },
            "slug": "HYPER:-A-New-Approach-for-the-Recognition-and-of-Ayache-Faugeras",
            "title": {
                "fragments": [],
                "text": "HYPER: A New Approach for the Recognition and Positioning of Two-Dimensional Objects"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The method has been integrated within a vision system coupled to an indutrial robot arm, to provide automatic picking and repositioning of partially overlapping industrial parts to provide strong robustness to partial occlusions."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096453"
                        ],
                        "name": "Y. Lamdan",
                        "slug": "Y.-Lamdan",
                        "structuredName": {
                            "firstName": "Yehezkel",
                            "lastName": "Lamdan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Lamdan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756534"
                        ],
                        "name": "H. Wolfson",
                        "slug": "H.-Wolfson",
                        "structuredName": {
                            "firstName": "Haim",
                            "lastName": "Wolfson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wolfson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20693764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce5271110e0b1ef852fd3bd3ed57b1932e08642e",
            "isKey": false,
            "numCitedBy": 966,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A general method for model-based object recognition in occluded scenes is presented. It is based on geometric hashing. The method stands out for its efficiency. We describe the general framework of the method and illustrate its applications for various recogni- tion problems both in 3-D and 2-D. Special attention is given to the recognition of 3-D objects in occluded scenes from 2-D gray scale images. New experimental results are included for this important case."
            },
            "slug": "Geometric-Hashing:-A-General-And-Efficient-Scheme-Lamdan-Wolfson",
            "title": {
                "fragments": [],
                "text": "Geometric Hashing: A General And Efficient Model-based Recognition Scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "A general method for model-based object recognition in occluded scenes is presented based on geometric hashing, which stands out for its efficiency and applications both in 3-D and 2-D."
            },
            "venue": {
                "fragments": [],
                "text": "[1988 Proceedings] Second International Conference on Computer Vision"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31614700"
                        ],
                        "name": "R. Nelson",
                        "slug": "R.-Nelson",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Nelson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nelson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 19385513,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "73025334a96b1171ab98ffa5e998c75586f5902e",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A method is described for extracting lineal features from an image using extended local information to provide robustness and sensitivity. The method utilizes both gradient magnitude and direction information, and incorporates explicit lineal and end-stop terms. These terms are combined nonlinearly to produce an energy landscape in which local minima correspond to lineal features called sticks that can be represented as line segments. A hill climbing (stick-growing) process is used to find these minima. The method is compared to two others, and found to have improved gap-crossing characteristics. >"
            },
            "slug": "Finding-Line-Segments-by-Stick-Growing-Nelson",
            "title": {
                "fragments": [],
                "text": "Finding Line Segments by Stick Growing"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A method is described for extracting lineal features from an image using extended local information to provide robustness and sensitivity and is compared to two others, and found to have improved gap-crossing characteristics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47246616"
                        ],
                        "name": "R. Brunelli",
                        "slug": "R.-Brunelli",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Brunelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brunelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16859093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "239beb3861ceceb4c7c7f229234d97198d5c7697",
            "isKey": false,
            "numCitedBy": 2828,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching, are presented. The results obtained for the testing sets show about 90% correct recognition using geometrical features and perfect recognition using template matching. >"
            },
            "slug": "Face-Recognition:-Features-Versus-Templates-Brunelli-Poggio",
            "title": {
                "fragments": [],
                "text": "Face Recognition: Features Versus Templates"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two new algorithms for computer recognition of human faces, one based on the computation of a set of geometrical features, such as nose width and length, mouth position, and chin shape, and the second based on almost-gray-level template matching are presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719838"
                        ],
                        "name": "W. Grimson",
                        "slug": "W.-Grimson",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Grimson",
                            "middleNames": [
                                "Eric",
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Grimson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713089"
                        ],
                        "name": "D. Huttenlocher",
                        "slug": "D.-Huttenlocher",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Huttenlocher",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huttenlocher"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21629245,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "5c165b95ec0dbb1bae2c401ad9e015c98b23acf4",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "A formal model is presented for analyzing how the method performs in the presence of sensory uncertainty. The method performs well for simple images or for exact data. However, the performance degrades rapidly for cluttered scenes or in the presence of even moderate sensor error (3-5 pixels).<<ETX>>"
            },
            "slug": "On-the-sensitivity-of-geometric-hashing-Grimson-Huttenlocher",
            "title": {
                "fragments": [],
                "text": "On the sensitivity of geometric hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A formal model is presented for analyzing how the method performs in the presence of sensory uncertainty and the performance degrades rapidly for cluttered scenes or in the absence of even moderate sensor error."
            },
            "venue": {
                "fragments": [],
                "text": "[1990] Proceedings Third International Conference on Computer Vision"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 2
                            }
                        ],
                        "text": ", [17; 19; 2] but also visually, for various representations [20; 3; 1; 5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recovery of parameteric models from range images"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE  Trans. PAMI,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient 2-dimensional ob-  ject recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. ICPR,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 61
                            }
                        ],
                        "text": ", [17; 19; 2] but also visually, for various representations [20; 3; 1; 5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "E cient 2-dimensional object recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. ICPR,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object classiication with high-dimensional vectors"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Telluride Workshop on Neuromorphic Engineering"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object classification with high-dimensional vectors"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. Telluride Workshop on Neuromorphic Engineering, Telluride CO,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "Mel [12] takes a somewhat similar approach using a database of stored feature vectors representing multiple low-level cues."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Object classi cation with high-dimensional vectors"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. Telluride Workshop  on Neuromorphic Engineering, Telluride CO,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognition by linear combi-  nations of models"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. PAMI,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient 2-dimensional object recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. ICPR,"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 61
                            }
                        ],
                        "text": ", [17; 19; 2] but also visually, for various representations [20; 3; 1; 5]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recognizing and localizing partially visible objects: The  local-features-focus method"
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Robotics Research,"
            },
            "year": 1982
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "EEcient 2-dimensional object recgnition"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. ICPR"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Primitive shape extraction from range data"
            },
            "venue": {
                "fragments": [],
                "text": "In Proc. IEEE Workshop on Computer Viszon,"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Primitive shape extraction from range data"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE Workshop on Computer Vision"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 26,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-cubist-approach-to-object-recognition-Nelson-Salgian/4717123c61bd51dcf27c250e96113742d0d3bd33?sort=total-citations"
}