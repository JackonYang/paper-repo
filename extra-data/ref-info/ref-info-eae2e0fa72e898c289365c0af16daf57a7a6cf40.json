{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2444123"
                        ],
                        "name": "W. Osberger",
                        "slug": "W.-Osberger",
                        "structuredName": {
                            "firstName": "Wilfried",
                            "lastName": "Osberger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Osberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731327"
                        ],
                        "name": "N. Bergmann",
                        "slug": "N.-Bergmann",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Bergmann",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bergmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144426436"
                        ],
                        "name": "A. Maeder",
                        "slug": "A.-Maeder",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Maeder",
                            "middleNames": [
                                "John"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Maeder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16512808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d473a8a055c332f652e11b23270cee25cc6bc3c",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an objective image quality assessment technique which is based on the properties of the human visual system (HVS). It consists of two major components: an early vision model (multi-channel and designed specifically for complex natural images), and a visual attention model which indicates regions of interest in a scene through the use of importance maps. Visible errors are then weighted, depending on the perceptual importance of the region in which they occur. We show that this technique produces a high correlation with subjective test data (0.93), compared to only 0.65 for PSNR. This technique is particularly useful for images coded with spatially varying quality."
            },
            "slug": "An-automatic-image-quality-assessment-technique-Osberger-Bergmann",
            "title": {
                "fragments": [],
                "text": "An automatic image quality assessment technique incorporating higher level perceptual factors"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An objective image quality assessment technique which is based on the properties of the human visual system and consists of an early vision model and a visual attention model which indicates regions of interest in a scene through the use of importance maps."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1491092225"
                        ],
                        "name": "Zhou Wang",
                        "slug": "Zhou-Wang",
                        "structuredName": {
                            "firstName": "Zhou",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhou Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14488670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41227e1a654638b8a612f04d2030c94e37426f96",
            "isKey": false,
            "numCitedBy": 4878,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new universal objective image quality index, which is easy to calculate and applicable to various image processing applications. Instead of using traditional error summation methods, the proposed index is designed by modeling any image distortion as a combination of three factors: loss of correlation, luminance distortion, and contrast distortion. Although the new index is mathematically defined and no human visual system model is explicitly employed, our experiments on various image distortion types indicate that it performs significantly better than the widely used distortion metric mean squared error. Demonstrative images and an efficient MATLAB implementation of the algorithm are available online at http://anchovy.ece.utexas.edu//spl sim/zwang/research/quality_index/demo.html."
            },
            "slug": "A-universal-image-quality-index-Wang-Bovik",
            "title": {
                "fragments": [],
                "text": "A universal image quality index"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Although the new index is mathematically defined and no human visual system model is explicitly employed, experiments on various image distortion types indicate that it performs significantly better than the widely used distortion metric mean squared error."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Letters"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2761918"
                        ],
                        "name": "P. Teo",
                        "slug": "P.-Teo",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Teo",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Teo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 10524960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4546452e3f6d520f087a6f91aa15b07ef2ec8a66",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of numerous digital image processing algorithms is to reproduce an image as accurately as possible given some specific restrictions. For example, in digital image halftoning, a gray scale version of an image needs to be approximated by a high spatial resolution binary image. Likewise, lossy image compression seeks to reconstruct an image from a minimally coded description of the original. In these and many other applications, image fidelity is determined by the human observer; hence, the effectiveness of the algorithm is measured by the extent to which reproduction errors are visible. As a result, a model that predicts human perceptual sensitivity to image distortion is beneficial to both the design and evaluation of many such image processing algorithms. This summary briefly describes an extension of our work on perceptual image distortion. Our extended perceptual model accounts for: (1) contrast sensitivity as a function of spatial frequency, mean luminance and spatial extent, (2) luminance masking, and (3) contrast masking."
            },
            "slug": "A-model-of-perceptual-image-fidelity-Heeger-Teo",
            "title": {
                "fragments": [],
                "text": "A model of perceptual image fidelity"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The extended perceptual model accounts for: (1) contrast sensitivity as a function of spatial frequency, mean luminance and spatial extent, (2) luminance masking, and (3) contrast masking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings., International Conference on Image Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1491092225"
                        ],
                        "name": "Zhou Wang",
                        "slug": "Zhou-Wang",
                        "structuredName": {
                            "firstName": "Zhou",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhou Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767317"
                        ],
                        "name": "Ligang Lu",
                        "slug": "Ligang-Lu",
                        "structuredName": {
                            "firstName": "Ligang",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ligang Lu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "The authors would like to thank Dr. Jesus Malo and Dr. L. Lu for insightful comments, Dr. Jeffrey Lubin and Dr. Douglas Dixon for providing the Sarnoff JNDmetrix software, Dr. Philip Corriveau and Dr. John Libert for supplying the MatLab routines used in VQEG Phase I FR-TV test for the regression\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "These are appealing because they are simple to calculate, have clear physical meanings, and are mathematically convenient in the context of optimization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7731697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4e1853acf75a91f64bd65de91ae05f4f7ef35a4",
            "isKey": false,
            "numCitedBy": 840,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Image quality assessment plays an important role in various image processing applications. A great deal of effort has been made in recent years to develop objective image quality metrics that correlate with perceived quality measurement. Unfortunately, only limited success has been achieved. In this paper, we provide some insights on why image quality assessment is so difficult by pointing out the weaknesses of the error sensitivity based framework, which has been used by most image quality assessment approaches in the literature. Furthermore, we propose a new philosophy in designing image quality metrics: The main function of the human eyes is to extract structural information from the viewing field, and the human visual system is highly adapted for this purpose. Therefore, a measurement of structural distortion should be a good approximation of perceived image distortion. Based on the new philosophy, we implemented a simple but effective image quality indexing algorithm, which is very promising as shown by our current results."
            },
            "slug": "Why-is-image-quality-assessment-so-difficult-Wang-Bovik",
            "title": {
                "fragments": [],
                "text": "Why is image quality assessment so difficult?"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "In this paper, insights on why image quality assessment is so difficult are provided by pointing out the weaknesses of the error sensitivity based framework and a new philosophy in designing image quality metrics is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "2002 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145231261"
                        ],
                        "name": "S. Winkler",
                        "slug": "S.-Winkler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Winkler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Winkler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "Finally, the reference and the distorted images may be modified using a nonlinear point operation to simulate light adaptation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14522716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b46ea9b915fb17abb5e8f071c6e26e60a019425",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 230,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Issues-in-vision-modeling-for-perceptual-video-Winkler",
            "title": {
                "fragments": [],
                "text": "Issues in vision modeling for perceptual video quality assessment"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152923334"
                        ],
                        "name": "Wen Xu",
                        "slug": "Wen-Xu",
                        "structuredName": {
                            "firstName": "Wen",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3267783"
                        ],
                        "name": "G. Hauske",
                        "slug": "G.-Hauske",
                        "structuredName": {
                            "firstName": "Gert",
                            "lastName": "Hauske",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hauske"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "We define the structural information in an image as those attributes that represent the structure of objects in the scene, independent of the average luminance and contrast."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 63402790,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "95cbfe11d3e02679bd537a702ff3c3ea5a9026ff",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "A segmentation-based error metric (SEM) is proposed to evaluate the quality of pictures with impairments resulting from typical source coding algorithms and channel interference. After appropriate visual preprocessing, the error picture is segmented into errors on own edges of the picture, errors representing exotic or spurious edges, and remaining errors in flat regions to describe edge errors like blurring, exotic structures like blocking and contouring, and residual errors like random noise, respectively. Error parameters or distortion factors are derived by appropriate summation over the segmented components. The distortion metric is built by a combination of the parameters using a generalized multiple linear regression procedure. Tests with a picture data base consisting of impairments from various picture coding techniques applied to different types of pictures have shown that the SEM yields very promising results. The correlation coefficient with subjective ratings was 0.875, whereas the widely used PSNR had only a correlation of 0.653. In addition, it is also possible to classify type and amount of individual distortions."
            },
            "slug": "Picture-quality-evaluation-based-on-error-Xu-Hauske",
            "title": {
                "fragments": [],
                "text": "Picture quality evaluation based on error segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A segmentation-based error metric (SEM) is proposed to evaluate the quality of pictures with impairments resulting from typical source coding algorithms and channel interference, and yields very promising results."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8288524"
                        ],
                        "name": "M. Eckert",
                        "slug": "M.-Eckert",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Eckert",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Eckert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720617"
                        ],
                        "name": "A. Bradley",
                        "slug": "A.-Bradley",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bradley",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bradley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "Twenty-nine high-resolution 24 bits/pixel RGB color images (typically 768\u00d7512 or similar size) were compressed at a range of quality levels using either JPEG or JPEG2000, producing a total of 175 JPEG images and 169 JPEG2000 images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 88
                            }
                        ],
                        "text": "Finally, the reference and the distorted images may be modified using a nonlinear point operation to simulate light adaptation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16122613,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2292e45ce3509b4bf5ab30ff4c3fecb052e024a5",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perceptual-quality-metrics-applied-to-still-image-Eckert-Bradley",
            "title": {
                "fragments": [],
                "text": "Perceptual quality metrics applied to still image compression"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2336203"
                        ],
                        "name": "Yung-Kai Lai",
                        "slug": "Yung-Kai-Lai",
                        "structuredName": {
                            "firstName": "Yung-Kai",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yung-Kai Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9363144"
                        ],
                        "name": "C.-C. Jay Kuo",
                        "slug": "C.-C.-Jay-Kuo",
                        "structuredName": {
                            "firstName": "C.-C.",
                            "lastName": "Kuo",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C.-C. Jay Kuo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "First, the error sensitivity approach estimates perceived errors to quantify image degradations, while the new philosophy considers image degradations as perceived changes in structural information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8504726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d563e63630d960e5dcf11b9c572e39cc4bc0be6",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The traditional mean-squared-error and peak-signal-to-noise-ratio error measures are mainly focused on the pixel-by-pixel difference between the original and compressed images. Such metrics are improper for subjective quality assessment, since human perception is very sensitive to specific correlations between adjacent pixels. In this work, we explore the Haar wavelet to model the space?frequency localization property of human visual system (HVS) responses. It is shown that the physical contrast in different resolutions can be easily represented in terms of wavelet coefficients. By analyzing and modeling several visual mechanisms of the HVS with the Haar transform, we develop a new subjective fidelity measure which is more consistent with human observation experience."
            },
            "slug": "A-Haar-Wavelet-Approach-to-Compressed-Image-Quality-Lai-Kuo",
            "title": {
                "fragments": [],
                "text": "A Haar Wavelet Approach to Compressed Image Quality Measurement"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "By analyzing and modeling several visual mechanisms of the HVS with the Haar transform, a new subjective fidelity measure is developed which is more consistent with human observation experience."
            },
            "venue": {
                "fragments": [],
                "text": "J. Vis. Commun. Image Represent."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145834258"
                        ],
                        "name": "A. Pons",
                        "slug": "A.-Pons",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Pons",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pons"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144432320"
                        ],
                        "name": "J. Malo",
                        "slug": "J.-Malo",
                        "structuredName": {
                            "firstName": "Jes\u00fas",
                            "lastName": "Malo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237862"
                        ],
                        "name": "J. Artigas",
                        "slug": "J.-Artigas",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Artigas",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Artigas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1953485"
                        ],
                        "name": "P. Capilla",
                        "slug": "P.-Capilla",
                        "structuredName": {
                            "firstName": "Pascual",
                            "lastName": "Capilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Capilla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1055302,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ab5005798ef7878de17b8d6f9b2a422989e8500",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-quality-metric-based-on-multidimensional-Pons-Malo",
            "title": {
                "fragments": [],
                "text": "Image quality metric based on multidimensional contrast perception models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150066863"
                        ],
                        "name": "C. van den Branden Lambrecht",
                        "slug": "C.-van-den-Branden-Lambrecht",
                        "structuredName": {
                            "firstName": "C.J.",
                            "lastName": "van den Branden Lambrecht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. van den Branden Lambrecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748830"
                        ],
                        "name": "O. Verscheure",
                        "slug": "O.-Verscheure",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Verscheure",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Verscheure"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "Channel decompositions tuned to various temporal frequencies have also been reported for video quality assessment [5], [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "A spatial map indicating the relative importance of different regions may also be used to provide spatially variant weighting [25], [27], [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15210448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0ac2dde8ff9418d3d3473cc1ac8080a693951fb",
            "isKey": false,
            "numCitedBy": 421,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of quality estimation of digitally coded video sequences. The topic is of great interest since many products in digital video are about to be released and it is thus important to have robust methodologies for testing and performance evaluation of such devices. The inherent problem is that human vision has to be taken into account in order to assess the quality of a sequence with a good correlation with human judgment. It is well known that the commonly used metric, the signal-to-noise ratio is not correlated with human vision. A metric for the assessment of video coding quality is presented. It is based on a multi- channel model of human spatio-temporal vision that has been parameterized for video coding applications by psychophysical experiments. The visual mechanisms of vision are simulated by a spatio-temporal filter bank. The decomposition is then used to account for phenomena as contrast sensitivity and masking. Once the amount of distortions actually perceived is known, quality estimation can be assessed at various levels. The described metric is able to rate the overall quality of the decoded video sequence as well as the rendition of important features of the sequence such as contours or textures."
            },
            "slug": "Perceptual-quality-measure-using-a-spatiotemporal-Lambrecht-Verscheure",
            "title": {
                "fragments": [],
                "text": "Perceptual quality measure using a spatiotemporal model of the human visual system"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A metric for the assessment of video coding quality is presented based on a multi- channel model of human spatio-temporal vision that has been parameterized for video coding applications by psychophysical experiments."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16952462"
                        ],
                        "name": "J. L. Mannos",
                        "slug": "J.-L.-Mannos",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Mannos",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. L. Mannos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2891424"
                        ],
                        "name": "D. Sakrison",
                        "slug": "D.-Sakrison",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sakrison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sakrison"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This approach was pioneered by Mannos and Sakrison [10], and has been extended by many other researchers over the years."
                    },
                    "intents": []
                }
            ],
            "corpusId": 24056678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12fa1fa16c0754a583dc65cce4788c0ce9b617b",
            "isKey": false,
            "numCitedBy": 1154,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Shannon's rate-distortion function provides a potentially useful lower bound against which to compare the rate-versus-distortion performance of practical encoding-transmission systems. However, this bound is not applicable unless one can arrive at a numerically-valued measure of distortion which is in reasonable correspondence with the subjective evaluation of the observer or interpreter. We have attempted to investigate this choice of distortion measure for monochrome still images. This investigation has considered a class of distortion measures for which it is possible to simulate the optimum (in a rate-distortion sense) encoding. Such simulation was performed at a fixed rate for various measures in the class and the results compared subjectively by observers. For several choices of transmission rate and original images, one distortion measure was fairly consistently rated as yielding the most satisfactory appearing encoded images."
            },
            "slug": "The-effects-of-a-visual-fidelity-criterion-of-the-Mannos-Sakrison",
            "title": {
                "fragments": [],
                "text": "The effects of a visual fidelity criterion of the encoding of images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This investigation has considered a class of distortion measures for which it is possible to simulate the optimum (in a rate-distortion sense) encoding and found one distortion measure was fairly consistently rated as yielding the most satisfactory appearing encoded images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585641"
                        ],
                        "name": "D. Fuhrmann",
                        "slug": "D.-Fuhrmann",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Fuhrmann",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fuhrmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49223797"
                        ],
                        "name": "J. A. Baro",
                        "slug": "J.-A.-Baro",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Baro",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Baro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144715151"
                        ],
                        "name": "J. R. Cox",
                        "slug": "J.-R.-Cox",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Cox",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, a human observer will give different quality scores to the same image if s/he is provided with different instructions [4], [ 30 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the suprathreshold range, can the relative visual distortions between different channels be normalized using the visibility thresholds? Recent efforts have been made to incorporate suprathreshold psychophysics for analyzing image distortions (e.g., [ 30 ]\u2013[34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44401653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3a7cde6f28ffa53eafbf9412b699e9239acd6bb",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Two experiments for evaluating psychophysical distortion metrics for JPEG-encoded images are described. The first is a threshold experiment, in which subjects determined the bit rate or level of distortion at which distortion was just noticeable. The second is a suprathreshold experiment in which subjects ranked image blocks according to perceived distortion. The results of these experiments were used to determine the predictive value of a number of computed image distortion metrics. It was found that mean-square-error is not a good predictor of distortion thresholds or suprathreshold perceived distortion. Some simple point- wise measures were in good agreement with psychophysical data; other more computationally intensive metrics involving spatial properties of the human visual system gave mixed results. It was determined that mean intensity, which is not accounted for in the JPEG algorithm, plays a significant role in perceived distortion."
            },
            "slug": "Experimental-evaluation-of-psychophysical-metrics-Fuhrmann-Baro",
            "title": {
                "fragments": [],
                "text": "Experimental evaluation of psychophysical distortion metrics for JPEG-encoded images"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It was found that mean-square-error is not a good predictor of distortion thresholds or suprathreshold perceived distortion, and it was determined that mean intensity plays a significant role in perceived distortion."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867250"
                        ],
                        "name": "S. Daly",
                        "slug": "S.-Daly",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Daly",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Daly"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62129590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31e03ad1c31e33003e7d67bec2d78ba6af6368a0",
            "isKey": false,
            "numCitedBy": 1332,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Image fidelity is the subset of overall image quality that specifically addresses the visual equivalence of two images. This paper describes an algorithm for determining whether the goal of image fidelity is met as a function of display parameters and viewing conditions. Using a digital image processing approach, this algorithm is intended for the design and analysis of image processing algorithms, imaging systems, and imaging media. The visual model, which is the central component of the algorithm, is comprised of three parts: an amplitude nonlinearity, a contrast sensitivity function, and a hierarchy of detection mechanisms."
            },
            "slug": "Visible-differences-predictor:-an-algorithm-for-the-Daly",
            "title": {
                "fragments": [],
                "text": "Visible differences predictor: an algorithm for the assessment of image fidelity"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An algorithm for determining whether the goal of image fidelity is met as a function of display parameters and viewing conditions is described, intended for the design and analysis of image processing algorithms, imaging systems, and imaging media."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "133678220"
                        ],
                        "name": "A. van Dijk",
                        "slug": "A.-van-Dijk",
                        "structuredName": {
                            "firstName": "Andre",
                            "lastName": "van Dijk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. van Dijk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165553"
                        ],
                        "name": "J. Martens",
                        "slug": "J.-Martens",
                        "structuredName": {
                            "firstName": "Jean-Bernard",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 132
                            }
                        ],
                        "text": "Raw scores for each subject were normalized by the mean and variance of scores for that subject (i.e., raw values were converted to Z-scores [54]) and then the entire data set was rescaled to fill the range from 1 to 100."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "converted to Z-scores [54]) and then the entire data set was rescaled to fill the range from 1 to 100."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62663691,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ab5113d32b6a8035f2a7663d5e37e46e43fe933",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "The large variety of algorithms for data compression has created a growing need for methods to judge (new) compression algorithms. The results of several subjective experiments illustrate that numerical category scaling techniques provide an efficient and valid way not only to obtain compression ratio versus quality curves that characterize coder performance over a broad range of compression ratios, but also to assess perceived image quality in a much smaller range (e.g. close to threshold level). Our first object is to discuss a number of simple techniques that can be used to assess perceived image quality. We show how to analyze data obtained from numerical category scaling experiments and how to set up such experiments. Second, we demonstrate that the results from a numerical scaling experiment depend on the specific nature of the subject's task in combination with the nature of the images to be judged. As results from subjective scaling experiments depend on many factors, we conclude that one should be very careful in selecting an appropriate assessment technique."
            },
            "slug": "Quality-asessment-of-coded-images-using-numerical-Dijk-Martens",
            "title": {
                "fragments": [],
                "text": "Quality asessment of coded images using numerical category scaling"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A number of simple techniques that can be used to assess perceived image quality are discussed and it is demonstrated that the results from a numerical scaling experiment depend on the specific nature of the subject's task in combination with the nature ofThe images to be judged."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2198311"
                        ],
                        "name": "A. Eskicioglu",
                        "slug": "A.-Eskicioglu",
                        "structuredName": {
                            "firstName": "Ahmet",
                            "lastName": "Eskicioglu",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Eskicioglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056670762"
                        ],
                        "name": "P. Fisher",
                        "slug": "P.-Fisher",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Fisher",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Fisher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9186472,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4fd5cb9a8067b7317f250cbe7d81be337c28aa16",
            "isKey": false,
            "numCitedBy": 1563,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of quality measures are evaluated for gray scale image compression. They are all bivariate, exploiting the differences between corresponding pixels in the original and degraded images. It is shown that although some numerical measures correlate well with the observers' response for a given compression technique, they are not reliable for an evaluation across different techniques. A graphical measure called Hosaka plots, however, can be used to appropriately specify not only the amount, but also the type of degradation in reconstructed images."
            },
            "slug": "Image-quality-measures-and-their-performance-Eskicioglu-Fisher",
            "title": {
                "fragments": [],
                "text": "Image quality measures and their performance"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Although some numerical measures correlate well with the observers' response for a given compression technique, they are not reliable for an evaluation across different techniques, and a graphical measure called Hosaka plots can be used to appropriately specify not only the amount, but also the type of degradation in reconstructed images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Commun."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144124701"
                        ],
                        "name": "D. Silverstein",
                        "slug": "D.-Silverstein",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Silverstein",
                            "middleNames": [
                                "Amnon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Silverstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292019"
                        ],
                        "name": "J. Farrell",
                        "slug": "J.-Farrell",
                        "structuredName": {
                            "firstName": "Joyce",
                            "lastName": "Farrell",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Farrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "Specifically, we iterate the following two linearalgebraic steps:\n(1) Y \u2192 Y\u00b1 \u03bb P (X,Y) ~\u2207YMSSIM(X,Y)\n(2) Y \u2192 X + \u03c3 E\u0302(X,Y)\nwhere \u03c3 is the square root of the constrained MSE, \u03bb controls the step size, E\u0302(X,Y) is a unit vector defined by\nE\u0302(X,Y) = Y\u2212X ||Y\u2212X|| ,\nand P (X,Y) is a projection operator:\nP\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17711937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4f00d0f6ca70dd7e38c0d7a277c8e463a266de5",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Image fidelity (inferred by the ability to discriminate between two images) and image quality (inferred by the preference for one image over another) are often assumed to be directly related. We investigated the relationship between the perceived image fidelity and image quality of halftone textures. Subjects were asked to rank order a set of printed halftone swatches on the basis of smoothness. They were then asked to reduce the contrast of each pattern until it was at threshold, thus providing an estimate of the pattern's perceptual strength and its discriminability from a non-textured swatch. We found only a moderate correlation between image fidelity and image quality."
            },
            "slug": "The-relationship-between-image-fidelity-and-image-Silverstein-Farrell",
            "title": {
                "fragments": [],
                "text": "The relationship between image fidelity and image quality"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work investigated the relationship between the perceived image fidelity and image quality of halftone textures by asking subjects to rank order a set of printed halftones on the basis of smoothness and reducing the contrast of each pattern until it was at threshold."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd IEEE International Conference on Image Processing"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1491092225"
                        ],
                        "name": "Zhou Wang",
                        "slug": "Zhou-Wang",
                        "structuredName": {
                            "firstName": "Zhou",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhou Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8060733,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c521992bc3dedfda0ada9ee53664a6b5caf1487",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "The human visual system (HVS) is highly space-variant in sampling, coding, processing, and understanding. The spatial resolution of the HVS is highest around the point of fixation (foveation point) and decreases rapidly with increasing eccentricity. By taking advantage of this fact, it is possible to remove considerable high-frequency information redundancy from the peripheral regions and still reconstruct a perceptually good quality image. Great success has been obtained previously by a class of embedded wavelet image coding algorithms, such as the embedded zerotree wavelet (EZW) and the set partitioning in hierarchical trees (SPIHT) algorithms. Embedded wavelet coding not only provides very good compression performance, but also has the property that the bitstream can be truncated at any point and still be decoded to recreate a reasonably good quality image. In this paper, we propose an embedded foveation image coding (EFIC) algorithm, which orders the encoded bitstream to optimize foveated visual quality at arbitrary bit-rates. A foveation-based image quality metric, namely, foveated wavelet image quality index (FWQI), plays an important role in the EFIC system. We also developed a modified SPIHT algorithm to improve the coding efficiency. Experiments show that EFIC integrates foveation filtering with foveated image coding and demonstrates very good coding performance and scalability in terms of foveated image quality measurement."
            },
            "slug": "Embedded-foveation-image-coding-Wang-Bovik",
            "title": {
                "fragments": [],
                "text": "Embedded foveation image coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An embedded foveation image coding (EFIC) algorithm, which orders the encoded bitstream to optimize foveated visual quality at arbitrary bit-rates, is proposed and a modified SPIHT algorithm is developed to improve the coding efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "First, the error sensitivity approach estimates perceived errors to quantify image degradations, while the new philosophy considers image degradations as perceived changes in structural information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7636177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2bb7b1ecaf96dbd2bc59b04c89d795530e4d6fa",
            "isKey": false,
            "numCitedBy": 770,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Several image compression standards (JPEG, MPEG, H.261) are based on the Discrete Cosine Transform (DCT). These standards do not specify the actual DCT quantization matrix. Ahumada & Peterson and Peterson, Ahumada & Watson provide mathematical formulae to compute a perceptually lossless quantization matrix. Here I show how to compute a matrix that is optimized for a particular image. The method treats each DCT coefficient as an approximation to the local response of a visual `channel.' For a given quantization matrix, the DCT quantization errors are adjusted by contrast sensitivity, light adaptation, and contrast masking, and are pooled non-linearly over the blocks of the image. This yields an 8 X 8 `perceptual error matrix.' A second non-linear pooling over the perceptual error matrix yields total perceptual error. With this model we may estimate the quantization matrix for a particular image that yields minimum bit rate for a given total perceptual error, or minimum perceptual error for a given bit rate. Custom matrices for a number of images show clear improvement over image-independent matrices. Custom matrices are compatible with the JPEG standard, which requires transmission of the quantization matrix."
            },
            "slug": "DCT-quantization-matrices-visually-optimized-for-Watson",
            "title": {
                "fragments": [],
                "text": "DCT quantization matrices visually optimized for individual images"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "Here I show how to compute a matrix that is optimized for a particular image, and custom matrices for a number of images show clear improvement over image-independent matrices."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153147862"
                        ],
                        "name": "James Hu",
                        "slug": "James-Hu",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26220263"
                        ],
                        "name": "J. McGowan",
                        "slug": "J.-McGowan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "McGowan",
                            "middleNames": [
                                "F."
                            ],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McGowan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9276824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a030400c1aba1e0ff58bda16af823cbeb1712b7",
            "isKey": false,
            "numCitedBy": 415,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The growth of digital video has given rise to a need for computational methods for evaluating the visual quality of digital video. We have developed a new digital video quality metric, which we call DVQ (digital video quality) (A. B. Watson, in Human Vision, Visual Processing, and Digital Display VIII, Proc. SPIE 3299, 139- 147 (1998)). Here, we provide a brief description of the metric, and give a preliminary report on its performance. DVQ accepts a pair of digital video sequences, and computes a measure of the magnitude of the visible difference between them. The metric is based on the discrete cosine transform. It incorporates aspects of early visual pro- cessing, including light adaptation, luminance, and chromatic chan- nels; spatial and temporal filtering; spatial frequency channels; con- trast masking; and probability summation. It also includes primitive dynamics of light adaptation and contrast masking. We have applied the metric to digital video sequences corrupted by various typical compression artifacts, and compared the results to quality ratings made by human observers. \u00a9 2001 SPIE and IS&T. (DOI: 10.1117/1.1329896)"
            },
            "slug": "Digital-video-quality-metric-based-on-human-vision-Watson-Hu",
            "title": {
                "fragments": [],
                "text": "Digital video quality metric based on human vision"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new digital video quality metric, which is based on the discrete cosine transform, which incorporates aspects of early visual pro- cessing, including light adaptation, luminance, and chromatic chan- nels; spatial and temporal filtering; spatial frequency channels; con- trast masking; and probability summation."
            },
            "venue": {
                "fragments": [],
                "text": "J. Electronic Imaging"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 122
                            }
                        ],
                        "text": "It has been shown that a strong dependency exists between intra- and inter-channel wavelet coefficients of natural images [36],[37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14163010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4646e76fe9b59e5a3ba46e388c63a268740acf89",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a parametric statistical model for visual images in the wavelet transform domain. We characterize the joint densities of coefficient magnitudes at adjacent spatial locations, adjacent orientations, and adjacent spatial scales. The model accounts for the statistics of a wide variety of visual images. As a demonstration of this, we used the model to design a progressive image encoder with state-of-the-art rate-distortion performance. We also show promising examples of image restoration and texture synthesis."
            },
            "slug": "Statistical-models-for-images:-compression,-and-Simoncelli",
            "title": {
                "fragments": [],
                "text": "Statistical models for images: compression, restoration and synthesis"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A parametric statistical model for visual images in the wavelet transform domain is presented and the joint densities of coefficient magnitudes at adjacent spatial locations, adjacent orientations, and adjacent spatial scales are characterized."
            },
            "venue": {
                "fragments": [],
                "text": "Conference Record of the Thirty-First Asilomar Conference on Signals, Systems and Computers (Cat. No.97CB36136)"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137991"
                        ],
                        "name": "I. Epifanio",
                        "slug": "I.-Epifanio",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Epifanio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Epifanio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144224730"
                        ],
                        "name": "Jaime Gutierrez",
                        "slug": "Jaime-Gutierrez",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Gutierrez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaime Gutierrez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144432320"
                        ],
                        "name": "J. Malo",
                        "slug": "J.-Malo",
                        "structuredName": {
                            "firstName": "Jes\u00fas",
                            "lastName": "Malo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17873086,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "851194387d6f35bd169ea3673dbec6eee581481f",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linear-transform-for-simultaneous-diagonalization-Epifanio-Gutierrez",
            "title": {
                "fragments": [],
                "text": "Linear transform for simultaneous diagonalization of covariance and perceptual metric matrix in image coding"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145231261"
                        ],
                        "name": "S. Winkler",
                        "slug": "S.-Winkler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Winkler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Winkler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Channel decompositions tuned to various temporal frequencies have also been reported for video quality assessment [5], [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17615814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da5f7ed12622c05399ffa4748c83e44766f908f8",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper I present a distortion metric for color video sequences. It is based on a contrast gain control model of the human visual system that incorporates spatial and temporal aspects of vision as well as color perception. The model achieves a close fit to contrast sensitivity and contrast masking data from several different psychophysical experiments for both luminance and color stimuli. The metric is used to assess the quality of MPEG-coded sequences."
            },
            "slug": "Perceptual-distortion-metric-for-digital-color-Winkler",
            "title": {
                "fragments": [],
                "text": "Perceptual distortion metric for digital color video"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A distortion metric for color video sequences is presented, based on a contrast gain control model of the human visual system that incorporates spatial and temporal aspects of vision as well as color perception."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48636481"
                        ],
                        "name": "Gloria Y. Yang",
                        "slug": "Gloria-Y.-Yang",
                        "structuredName": {
                            "firstName": "Gloria",
                            "lastName": "Yang",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gloria Y. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221312"
                        ],
                        "name": "J. Solomon",
                        "slug": "J.-Solomon",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Solomon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Solomon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9328275"
                        ],
                        "name": "J. Villasenor",
                        "slug": "J.-Villasenor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Villasenor",
                            "middleNames": [
                                "D."
                            ],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Villasenor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "First, the error sensitivity approach estimates perceived errors to quantify image degradations, while the new philosophy considers image degradations as perceived changes in structural information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15281614,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9dfe899599e46706f2ef3457d8d38760d138166c",
            "isKey": false,
            "numCitedBy": 640,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The discrete wavelet transform (DWT) decomposes an image into bands that vary in spatial frequency and orientation. It is widely used for image compression, measures of the visibility of DWT quantization errors are required to achieve optimal compression. Uniform quantization of a single band of coefficients results in an artifact that we call DWT uniform quantization noise; it is the sum of a lattice of random amplitude basis functions of the corresponding DWT synthesis filter. We measured visual detection thresholds for samples of DWT uniform quantization noise in Y, Cb, and Cr color channels. The spatial frequency of a wavelet is r2/sup -/spl lambda//, where r is the display visual resolution in pixels/degree, and /spl lambda/ is the wavelet level. Thresholds increase rapidly with wavelet spatial frequency. Thresholds also increase from Y to Cr to Cb, and with orientation from lowpass to horizontal/vertical to diagonal. We construct a mathematical model for DWT noise detection thresholds that is a function of level, orientation, and display visual resolution. This allows calculation of a \"perceptually lossless\" quantization matrix for which all errors are in theory below the visual threshold. The model may also be used as the basis for adaptive quantization schemes."
            },
            "slug": "Visibility-of-wavelet-quantization-noise-Watson-Yang",
            "title": {
                "fragments": [],
                "text": "Visibility of wavelet quantization noise"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A mathematical model is constructed for DWT noise detection thresholds that is a function of level, orientation, and display visual resolution that allows calculation of a \"perceptually lossless\" quantization matrix for which all errors are in theory below the visual threshold."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145165553"
                        ],
                        "name": "J. Martens",
                        "slug": "J.-Martens",
                        "structuredName": {
                            "firstName": "Jean-Bernard",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1954201"
                        ],
                        "name": "Lydia M. J. Meesters",
                        "slug": "Lydia-M.-J.-Meesters",
                        "structuredName": {
                            "firstName": "Lydia",
                            "lastName": "Meesters",
                            "middleNames": [
                                "M.",
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lydia M. J. Meesters"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15983639,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "cb6461c90d6733d189fe7cf31c40a4475471b31f",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Image-dissimilarity-Martens-Meesters",
            "title": {
                "fragments": [],
                "text": "Image dissimilarity"
            },
            "venue": {
                "fragments": [],
                "text": "Signal Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2761918"
                        ],
                        "name": "P. Teo",
                        "slug": "P.-Teo",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Teo",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Teo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "On the other hand, the image structures are changed dramatically in the worstcase MSSIM image, in some cases reversing contrast."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "This new philosophy can be best understood through comparison with the error sensitivity philosophy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1370281,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "63c13deef4ecb94d69b6763f43311720e40a2f61",
            "isKey": false,
            "numCitedBy": 401,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a perceptual distortion measure that predicts image integrity far better than mean-squared error. This perceptual distortion measure is based an a model of human visual processing that fits empirical measurements of the psychophysics of spatial pattern detection. The model of human visual processing proposed involves two major components: a steerable pyramid transform and contrast normalization. We also illustrate the usefulness of the model in predicting perceptual distortion in real images.<<ETX>>"
            },
            "slug": "Perceptual-image-distortion-Teo-Heeger",
            "title": {
                "fragments": [],
                "text": "Perceptual image distortion"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "A perceptual distortion measure that predicts image integrity far better than mean-squared error and the usefulness of the model in predicting perceptual distortion in real images is illustrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 1st International Conference on Image Processing"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1491092225"
                        ],
                        "name": "Zhou Wang",
                        "slug": "Zhou-Wang",
                        "structuredName": {
                            "firstName": "Zhou",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhou Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387140"
                        ],
                        "name": "H. Sheikh",
                        "slug": "H.-Sheikh",
                        "structuredName": {
                            "firstName": "Hamid",
                            "lastName": "Sheikh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sheikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 57332104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21b661f47e7e80b6f1de5e03f268903f7efbaaf2",
            "isKey": false,
            "numCitedBy": 330,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video data, stored in video databases and distributed through communication networks, is subject to various kinds of distortions during acquisition, compression, processing, transmission, and reproduction. For example, lossy video compression techniques, which are almost always used to reduce the bandwidth needed to store or transmit video data, may degrade the quality during the quantization process. For another instance, the digital video bitstreams delivered over error-prone channels, such as wireless channels, may be received imperfectly due to the impairment occurred during transmission. Package-switched communication networks, such as the Internet, can cause loss or severe delay of received data packages, depending on the network conditions and the quality of services. All these transmission errors may result in distortions in the received video data. It is therefore imperative for a video service system to be able to realize and quantify the video quality degradations that occur in the system, so that it can maintain, control and possibly enhance the quality of the video data. An effective image and video quality metric is crucial for this purpose."
            },
            "slug": "41-OBJECTIVE-VIDEO-QUALITY-ASSESSMENT-Wang-Sheikh",
            "title": {
                "fragments": [],
                "text": "41 OBJECTIVE VIDEO QUALITY ASSESSMENT"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is imperative for a video service system to be able to realize and quantify the video quality degradations that occur in the system, so that it can maintain, control and possibly enhance the quality of the video data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1953466"
                        ],
                        "name": "C. Privitera",
                        "slug": "C.-Privitera",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Privitera",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Privitera"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144145222"
                        ],
                        "name": "L. Stark",
                        "slug": "L.-Stark",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Stark",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Stark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16725426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60c2b03024f89c3f67d05d6b60d4ba1b032942c4",
            "isKey": false,
            "numCitedBy": 586,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Many machine vision applications, such as compression, pictorial database querying, and image understanding, often need to analyze in detail only a representative subset of the image, which may be arranged into sequences of loci called regions-of-interest (ROIs). We have investigated and developed a methodology that serves to automatically identify such a subset of aROIs (algorithmically detected ROIs) using different image processing algorithms (IPAs), and appropriate clustering procedures. In human perception, an internal representation directs top-down, context-dependent sequences of eye movements to fixate on similar sequences of hROIs (human identified ROIs). In the paper, we introduce our methodology and we compare aROIs with hROIs as a criterion for evaluating and selecting bottom-up, context-free algorithms. An application is finally discussed."
            },
            "slug": "Algorithms-for-Defining-Visual-Regions-of-Interest:-Privitera-Stark",
            "title": {
                "fragments": [],
                "text": "Algorithms for Defining Visual Regions-of-Interest: Comparison with Eye Fixations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper investigates and develops a methodology that serves to automatically identify a subset of aROIs (algorithmically detected ROIs) using different image processing algorithms (IPAs), and appropriate clustering procedures, and compares hROIs with hROI as a criterion for evaluating and selecting bottom-up, context-free algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720617"
                        ],
                        "name": "A. Bradley",
                        "slug": "A.-Bradley",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Bradley",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bradley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5908238,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "0f239fb00f0048ef33cd5403a8215bc919b2a5c5",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a model of the human visual system (HVS) based on the wavelet transform. This model is largely based on a previously proposed model, but has a number of modifications that make it more amenable to potential integration into a wavelet based image compression scheme. These modifications include the use of a separable wavelet transform instead of the cortex transform, the application of a wavelet contrast sensitivity function (CSF), and a simplified definition of subband contrast that allows one to predict the noise visibility directly from the wavelet coefficients. Initially, we outline the luminance, frequency, and masking sensitivities of the HVS and discuss how these can be incorporated into the wavelet transform. We then outline a number of limitations of the wavelet transform as a model of the HVS, namely the lack of translational invariance and poor orientation sensitivity. In order to investigate the efficacy of this wavelet based model, a wavelet visible difference predictor (WVDP) is described. The WVDP is then used to predict visible differences between an original and compressed (or noisy) image. Results are presented to emphasize the limitations of commonly used measures of image quality and to demonstrate the performance of the WVDP. The paper concludes with suggestions on how the WVDP can be used to determine a visually optimal quantization strategy for wavelet coefficients and produce a quantitative measure of image quality."
            },
            "slug": "A-wavelet-visible-difference-predictor-Bradley",
            "title": {
                "fragments": [],
                "text": "A wavelet visible difference predictor"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A model of the human visual system (HVS) based on the wavelet transform that has a number of modifications that make it more amenable to potential integration into a wavelet based image compression scheme is described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32052472"
                        ],
                        "name": "R. Buccigrossi",
                        "slug": "R.-Buccigrossi",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Buccigrossi",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Buccigrossi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1887438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "156ed6cd90506cd1111dffcd8e80e33ff62ca5ae",
            "isKey": false,
            "numCitedBy": 620,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a probability model for natural images, based on empirical observation of their statistics in the wavelet transform domain. Pairs of wavelet coefficients, corresponding to basis functions at adjacent spatial locations, orientations, and scales, are found to be non-Gaussian in both their marginal and joint statistical properties. Specifically, their marginals are heavy-tailed, and although they are typically decorrelated, their magnitudes are highly correlated. We propose a Markov model that explains these dependencies using a linear predictor for magnitude coupled with both multiplicative and additive uncertainties, and show that it accounts for the statistics of a wide variety of images including photographic images, graphical images, and medical images. In order to directly demonstrate the power of the model, we construct an image coder called EPWIC (embedded predictive wavelet image coder), in which subband coefficients are encoded one bitplane at a time using a nonadaptive arithmetic encoder that utilizes conditional probabilities calculated from the model. Bitplanes are ordered using a greedy algorithm that considers the MSE reduction per encoded bit. The decoder uses the statistical model to predict coefficient values based on the bits it has received. Despite the simplicity of the model, the rate-distortion performance of the coder is roughly comparable to the best image coders in the literature."
            },
            "slug": "Image-compression-via-joint-statistical-in-the-Buccigrossi-Simoncelli",
            "title": {
                "fragments": [],
                "text": "Image compression via joint statistical characterization in the wavelet domain"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A Markov model is proposed that explains dependencies using a linear predictor for magnitude coupled with both multiplicative and additive uncertainties, and it is shown that it accounts for the statistics of a wide variety of images including photographic images, graphical images, and medical images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143773338"
                        ],
                        "name": "A. Said",
                        "slug": "A.-Said",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Said",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Said"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718894"
                        ],
                        "name": "W. Pearlman",
                        "slug": "W.-Pearlman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pearlman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pearlman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1268433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "974334c336e87267704cb41e748fc24e5bc0e8e6",
            "isKey": false,
            "numCitedBy": 5932,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Embedded zerotree wavelet (EZW) coding, introduced by Shapiro (see IEEE Trans. Signal Processing, vol.41, no.12, p.3445, 1993), is a very effective and computationally simple technique for image compression. We offer an alternative explanation of the principles of its operation, so that the reasons for its excellent performance can be better understood. These principles are partial ordering by magnitude with a set partitioning sorting algorithm, ordered bit plane transmission, and exploitation of self-similarity across different scales of an image wavelet transform. Moreover, we present a new and different implementation based on set partitioning in hierarchical trees (SPIHT), which provides even better performance than our previously reported extension of EZW that surpassed the performance of the original EZW. The image coding results, calculated from actual file sizes and images reconstructed by the decoding algorithm, are either comparable to or surpass previous results obtained through much more sophisticated and computationally complex methods. In addition, the new coding and decoding procedures are extremely fast, and they can be made even faster, with only small loss in performance, by omitting entropy coding of the bit stream by the arithmetic code."
            },
            "slug": "A-new,-fast,-and-efficient-image-codec-based-on-set-Said-Pearlman",
            "title": {
                "fragments": [],
                "text": "A new, fast, and efficient image codec based on set partitioning in hierarchical trees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The image coding results, calculated from actual file sizes and images reconstructed by the decoding algorithm, are either comparable to or surpass previous results obtained through much more sophisticated and computationally complex methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Circuits Syst. Video Technol."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1491092225"
                        ],
                        "name": "Zhou Wang",
                        "slug": "Zhou-Wang",
                        "structuredName": {
                            "firstName": "Zhou",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhou Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2387140"
                        ],
                        "name": "H. Sheikh",
                        "slug": "H.-Sheikh",
                        "structuredName": {
                            "firstName": "Hamid",
                            "lastName": "Sheikh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sheikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14092157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05ae650ef38a5ee7a76936840c3cf84c24e3c345",
            "isKey": false,
            "numCitedBy": 308,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital video data, stored in video databases and distributed through communication networks, is subject to various kinds of distortions during acquisition, compression, processing, transmission, and reproduction. For example, lossy video compression techniques, which are almost always used to reduce the bandwidth needed to store or transmit video data, may degrade the quality during the quantization process. For another instance, the digital video bitstreams delivered over error-prone channels, such as wireless channels, may be received imperfectly due to the impairment occurred during transmission. Package-switched communication networks, such as the Internet, can cause loss or severe delay of received data packages, depending on the network conditions and the quality of services. All these transmission errors may result in distortions in the received video data. It is therefore imperative for a video service system to be able to realize and quantify the video quality degradations that occur in the system, so that it can maintain, control and possibly enhance the quality of the video data. An effective image and video quality metric is crucial for this purpose."
            },
            "slug": "OBJECTIVE-VIDEO-QUALITY-ASSESSMENT-Wang-Sheikh",
            "title": {
                "fragments": [],
                "text": "OBJECTIVE VIDEO QUALITY ASSESSMENT"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is imperative for a video service system to be able to realize and quantify the video quality degradations that occur in the system, so that it can maintain, control and possibly enhance the quality of the video data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144909085"
                        ],
                        "name": "M. G. Ramos",
                        "slug": "M.-G.-Ramos",
                        "structuredName": {
                            "firstName": "Marcia",
                            "lastName": "Ramos",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. G. Ramos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720838"
                        ],
                        "name": "S. Hemami",
                        "slug": "S.-Hemami",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Hemami",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hemami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 40768603,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "4b5b3ea14029cdca09fd69b1ba6548d287d38d9f",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A psychophysical experiment is described that quantifies human sensitivities to suprathreshold distortions caused by wavelet coefficient quantization in natural images, and the resulting analysis is explained. The quantizer step sizes that cause the first three visible degradations relative to the original image are well predicted by exponential functions of subband standard deviation. The resulting root-mean-square (RMS) error in the image is constant for a spatial frequency and is independent of orientation. Contrast sensitivity calculations suggest a higher sensitivity to bands with higher energy, and threshold elevations for the second and third visible degradations are predicted well by the constant-RMS model. A quantization strategy based on the results is proposed for low-bit-rate applications."
            },
            "slug": "Suprathreshold-wavelet-coefficient-quantization-in-Ramos-Hemami",
            "title": {
                "fragments": [],
                "text": "Suprathreshold wavelet coefficient quantization in complex stimuli: psychophysical evaluation and analysis."
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A psychophysical experiment is described that quantifies human sensitivities to suprathreshold distortions caused by wavelet coefficient quantization in natural images, and a quantization strategy based on the results is proposed for low-bit-rate applications."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108516799"
                        ],
                        "name": "Juan Liu",
                        "slug": "Juan-Liu",
                        "structuredName": {
                            "firstName": "Juan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juan Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742248"
                        ],
                        "name": "P. Moulin",
                        "slug": "P.-Moulin",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Moulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Moulin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "It has been shown that a strong dependency exists between intra- and inter-channel wavelet coefficients of natural images [36],[37]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 383653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "906c53e64d81e129d9fbf02254d5c23f1a5f6c9c",
            "isKey": false,
            "numCitedBy": 297,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an information-theoretic analysis of statistical dependencies between image wavelet coefficients. The dependencies are measured using mutual information, which has a fundamental relationship to data compression, estimation, and classification performance. Mutual information is computed analytically for several statistical image models, and depends strongly on the choice of wavelet filters. In the absence of an explicit statistical model, a method is studied for reliably estimating mutual information from image data. The validity of the model-based and data-driven approaches is assessed on representative real-world photographic images. Our results are consistent with empirical observations that coding schemes exploiting inter- and intrascale dependencies alone perform very well, whereas taking both into account does not significantly improve coding performance. A similar observation applies to other image processing applications."
            },
            "slug": "Information-theoretic-analysis-of-interscale-and-Liu-Moulin",
            "title": {
                "fragments": [],
                "text": "Information-theoretic analysis of interscale and intrascale dependencies between image wavelet coefficients"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "An information-theoretic analysis of statistical dependencies between image wavelet coefficients is presented, consistent with empirical observations that coding schemes exploiting inter- and intrascale dependencies alone perform very well, whereas taking both into account does not significantly improve coding performance."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13113212"
                        ],
                        "name": "D. Chandler",
                        "slug": "D.-Chandler",
                        "structuredName": {
                            "firstName": "Damon",
                            "lastName": "Chandler",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720838"
                        ],
                        "name": "S. Hemami",
                        "slug": "S.-Hemami",
                        "structuredName": {
                            "firstName": "Sheila",
                            "lastName": "Hemami",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hemami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 951011,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "39e514ce74858cfe02098d3a293f2f05ab342f22",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The additivity of wavelet subband quantization distortions was investigated in an unmasked detection task and in masked detection and discrimination tasks. Contrast thresholds were measured for both simple targets (artifacts induced by uniform quantization of individual discrete wavelet transform subbands) and compound targets (artifacts induced by uniform quantization of pairs of discrete wavelet transform subbands) in the presence of no mask and eight different natural image maskers. The results were used to assess summation between wavelet subband quantization distortions on orientation and spatial-frequency dimensions. In the unmasked detection experiment, subthreshold quantization distortions pooled in a non-linear fashion and the amount of summation agreed with those of previous summation-at-threshold experiments ((beta) equals 2.43; relative sensitivity equals 1.33). In the masked detection and discrimination experiments, suprathreshold quantization distortions pooled in a linear fashion. Summation increased as the distortions became increasingly suprathreshold but quickly settled to near-linear values. Summation on the spatial-frequency dimension was greater than summation on the orientation dimension for all suprathreshold contrasts. A high degree of uncertainty imposed by the natural image maskers precludes quantifying an absolute measure of summation."
            },
            "slug": "Additivity-models-for-suprathreshold-distortion-in-Chandler-Hemami",
            "title": {
                "fragments": [],
                "text": "Additivity models for suprathreshold distortion in quantized wavelet-coded images"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A high degree of uncertainty imposed by the natural image maskers precludes quantifying an absolute measure of summation between wavelet subband quantization distortions on orientation and spatial-frequency dimensions."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "On the other hand, the image structures are changed dramatically in the worstcase MSSIM image, in some cases reversing contrast."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18810256,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "839853188cbdd19617e5a0e07d8aecc7dc2a54a4",
            "isKey": false,
            "numCitedBy": 139,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The ModelFest Phase One dataset is a collection of luminance contrast thresholds for 43 two-dimensional monochromatic spatial patterns confined to an area of approximately two by two degrees. These data were collected by a collaboration among twelve laboratories, and were designed to provide a common database for calibration and testing of spatial vision models. Here I report fits of the ModelFest data with five models: Peak Contrast, Contrast Energy, Generalized Energy, a Gabor Channels model, and a Discrete Cosine Transform model. The Gabor Channels model provides the best fit, though the other, simpler models, with the exception of Peak Contrast, provide remarkably good fits as well. Though there are clear individual differences, regularities in the data suggest the possibility of constructing a standard observer for spatial vision."
            },
            "slug": "Visual-detection-of-spatial-contrast-patterns:-of-Watson",
            "title": {
                "fragments": [],
                "text": "Visual detection of spatial contrast patterns: evaluation of five simple models."
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Fits of the ModelFest data with five models are reported: Peak Contrast, Contrast Energy, Generalized Energy, a Gabor Channels model, and a Discrete Cosine Transform model."
            },
            "venue": {
                "fragments": [],
                "text": "Optics express"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144432320"
                        ],
                        "name": "J. Malo",
                        "slug": "J.-Malo",
                        "structuredName": {
                            "firstName": "Jes\u00fas",
                            "lastName": "Malo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2536342"
                        ],
                        "name": "R. Navarro",
                        "slug": "R.-Navarro",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Navarro",
                            "middleNames": [
                                "Fonolla"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Navarro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2137991"
                        ],
                        "name": "I. Epifanio",
                        "slug": "I.-Epifanio",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Epifanio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Epifanio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682325"
                        ],
                        "name": "F. Ferri",
                        "slug": "F.-Ferri",
                        "structuredName": {
                            "firstName": "Francesc",
                            "lastName": "Ferri",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ferri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145237862"
                        ],
                        "name": "J. Artigas",
                        "slug": "J.-Artigas",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Artigas",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Artigas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 36378322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eebb6e8084e0e9ed4b95b9f3a2d4e659e28143b1",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The aim of many image mappings is representing the signal in a basis of decorrelated features. Two fundamental aspects must be taken into account in the basis selection problem: data distribution and the qualitative meaning of the underlying space. The classical PCA techniques reduce the statistical correlation using the data distribution. However, in applications where human vision has to be taken into account, there are perceptual factors that make the feature space uneven, and additional interaction among the dimensions may arise. \n \nIn this work a common framework is presented to analyse the perceptual and statistical interactions among the coefficients of any representation. Using a recent non-linear perception model a set of input-dependent features is obtained which simultaneously remove the statistical and perceptual correlations between coefficients. A fast method to invert this representation is also presented, so no input-dependent transform has to be stored. The decorrelating power of the proposed representation suggests that it is a promising alternative to the linear transforms used in image coding, fusion or retrieval applications."
            },
            "slug": "Non-linear-Invertible-Representation-for-Joint-and-Malo-Navarro",
            "title": {
                "fragments": [],
                "text": "Non-linear Invertible Representation for Joint Statistical and Perceptual Feature Decorrelation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A common framework is presented to analyse the perceptual and statistical interactions among the coefficients of any representation using a recent non-linear perception model and a fast method to invert this representation is presented, so no input-dependent transform has to be stored."
            },
            "venue": {
                "fragments": [],
                "text": "SSPR/SPR"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2344693"
                        ],
                        "name": "J. M. Shapiro",
                        "slug": "J.-M.-Shapiro",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Shapiro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Shapiro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In fact, state-of-the-art wavelet image compression techniques achieve their success by exploiting this strong dependency [ 38 ]\u2013[41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18047405,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f6fe641e9110bddb73ab685922b0ad014540c35",
            "isKey": false,
            "numCitedBy": 5781,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code. The embedded code represents a sequence of binary decisions that distinguish an image from the \"null\" image. Using an embedded coding algorithm, an encoder can terminate the encoding at any point thereby allowing a target rate or target distortion metric to be met exactly. Also, given a bit stream, the decoder can cease decoding at any point in the bit stream and still produce exactly the same image that would have been encoded at the bit rate corresponding to the truncated bit stream. In addition to producing a fully embedded bit stream, the EZW consistently produces compression results that are competitive with virtually all known compression algorithms on standard test images. Yet this performance is achieved with a technique that requires absolutely no training, no pre-stored tables or codebooks, and requires no prior knowledge of the image source. The EZW algorithm is based on four key concepts: (1) a discrete wavelet transform or hierarchical subband decomposition, (2) prediction of the absence of significant information across scales by exploiting the self-similarity inherent in images, (3) entropy-coded successive-approximation quantization, and (4) universal lossless data compression which is achieved via adaptive arithmetic coding. >"
            },
            "slug": "Embedded-image-coding-using-zerotrees-of-wavelet-Shapiro",
            "title": {
                "fragments": [],
                "text": "Embedded image coding using zerotrees of wavelet coefficients"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The embedded zerotree wavelet algorithm (EZW) is a simple, yet remarkably effective, image compression algorithm, having the property that the bits in the bit stream are generated in order of importance, yielding a fully embedded code."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97920742"
                        ],
                        "name": "Lindsay Kreslake",
                        "slug": "Lindsay-Kreslake",
                        "structuredName": {
                            "firstName": "Lindsay",
                            "lastName": "Kreslake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lindsay Kreslake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14349395,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a19b5a931c8353f1c288d26aa442a7c1e31af6d2",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The study of subjective visual quality, and the development of computed quality metrics, require accurate and meaningful measurement of visual impairment. A natural unit for impairment is the JND. In many cases, what is required is a measure of an impairment scale, that is, the growth of the subjective impairment, in JNDS, as some physical parameters is increased."
            },
            "slug": "Measurement-of-visual-impairment-scales-for-digital-Watson-Kreslake",
            "title": {
                "fragments": [],
                "text": "Measurement of visual impairment scales for digital video"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "The study of subjective visual quality, and the development of computed quality metrics, require accurate and meaningful measurement of visual impairment, and a natural unit for impairment is the JND."
            },
            "venue": {
                "fragments": [],
                "text": "IS&T/SPIE Electronic Imaging"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145358192"
                        ],
                        "name": "E. Adelson",
                        "slug": "E.-Adelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Adelson",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Adelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360881"
                        ],
                        "name": "D. Heeger",
                        "slug": "D.-Heeger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heeger",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 43701174,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8515604037444b3f079a9d328b0c560f33da0a19",
            "isKey": false,
            "numCitedBy": 1428,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the major drawbacks of orthogonal wavelet transforms is their lack of translation invariance: the content of wavelet subbands is unstable under translations of the input signal. Wavelet transforms are also unstable with respect to dilations of the input signal and, in two dimensions, rotations of the input signal. The authors formalize these problems by defining a type of translation invariance called shiftability. In the spatial domain, shiftability corresponds to a lack of aliasing; thus, the conditions under which the property holds are specified by the sampling theorem. Shiftability may also be applied in the context of other domains, particularly orientation and scale. Jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored. Two examples of jointly shiftable transforms are designed and implemented: a 1-D transform that is jointly shiftable in position and scale, and a 2-D transform that is jointly shiftable in position and orientation. The usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated. >"
            },
            "slug": "Shiftable-multiscale-transforms-Simoncelli-Freeman",
            "title": {
                "fragments": [],
                "text": "Shiftable multiscale transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Two examples of jointly shiftable transforms that are simultaneously shiftable in more than one domain are explored and the usefulness of these image representations for scale-space analysis, stereo disparity measurement, and image enhancement is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Inf. Theory"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11167243,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c215a24ed2c75bf370d690ba8d5e1b5b11af1290",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A custom quantization matrix tailored to a particular image is designed by an image-dependent perceptual method incorporating solutions to the problems of luminance and contrast masking, error pooling and quality selectability.<<ETX>>"
            },
            "slug": "Visually-optimal-DCT-quantization-matrices-for-Watson",
            "title": {
                "fragments": [],
                "text": "Visually optimal DCT quantization matrices for individual images"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A custom quantization matrix tailored to a particular image is designed by an image-dependent perceptual method incorporating solutions to the problems of luminance and contrast masking, error pooling and quality selectability."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] DCC `93: Data Compression Conference"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221312"
                        ],
                        "name": "J. Solomon",
                        "slug": "J.-Solomon",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Solomon",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Solomon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "But it is easily understood with the new philosophy since nearly all the structural information of the reference image is preserved, in the sense that the original information can be nearly fully recovered via a simple pointwise inverse linear luminance transform (except perhaps for the very bright\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6142390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d364b0790e05ee106941218d84881870759fc152",
            "isKey": false,
            "numCitedBy": 501,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We have implemented a model of contrast gain and control in human vision that incorporates a number of key features, including a contrast sensitivity function, multiple oriented bandpass channels, accelerating nonlinearities, and a devisive inhibitory gain control pool. The parameters of this model have been optimized through a fit to the recent data that describe masking of a Gabor function by cosine and Gabor masks [J. M. Foley, \"Human luminance pattern mechanisms: masking experiments require a new model,\" J. Opt. Soc. Am. A 11, 1710 (1994)]. The model achieves a good fit to the data. We also demonstrate how the concept of recruitment may accommodate a variant of this model in which excitatory and inhibitory paths have a common accelerating nonlinearity, but which include multiple channels tuned to different levels of contrast."
            },
            "slug": "Model-of-visual-contrast-gain-control-and-pattern-Watson-Solomon",
            "title": {
                "fragments": [],
                "text": "Model of visual contrast gain control and pattern masking."
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A model of contrast gain and control in human vision that incorporates a number of key features, including a contrast sensitivity function, multiple oriented bandpass channels, accelerating nonlinearities, and a devisive inhibitory gain control pool is implemented."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152845083"
                        ],
                        "name": "J. M. Foley",
                        "slug": "J.-M.-Foley",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Foley",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. Foley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355118"
                        ],
                        "name": "G. Boynton",
                        "slug": "G.-Boynton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Boynton",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Boynton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62599879,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "5a7fb8350f07f9effb37c100add098b4797bc6a8",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Models of human pattern vision mechanisms are examined in light of new results in psychophysics and single-cell recording. Four experiments on simultaneous masking of Gabor patterns by sinewave gratings are described. In these experiments target contrast thresholds are measured as functions of masker contrast, orientation, spatial phase, and temporal frequency. The results are used to test the theory of simultaneous masking proposed by Legge and Foley that is based on mechanisms that sum excitation linearly over a receptive field and produce a response that is an s-shaped transform of this sum. The theory is shown to be inadequate. Recent single-cell-recording results from simple cells in the cat show that these cells receive a broadband divisive input as well as an input that is summed linearly over their receptive fields. A new theory of simultaneous masking based on mechanisms with similar properties is shown to describe the psychophysical results well. Target threshold vs masker contrast (TvC) functions for a set of target-masker pairs are used to estimate the parameters of the theory including the excitatory and inhibitory sensitivities of the mechanisms along the various pattern dimensions. The human luminance pattern vision mechanisms, unlike most of the cells, do not saturate at high contrast."
            },
            "slug": "New-model-of-human-luminance-pattern-vision-of-the-Foley-Boynton",
            "title": {
                "fragments": [],
                "text": "New model of human luminance pattern vision mechanisms: analysis of the effects of pattern orientation, spatial phase, and temporal frequency"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Models of human pattern vision mechanisms are examined in light of new results in psychophysics and single-cell recording and a new theory of simultaneous masking based on mechanisms with similar properties is shown to describe the psychophysical results well."
            },
            "venue": {
                "fragments": [],
                "text": "Other Conferences"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771014"
                        ],
                        "name": "Umesh Rajashekar",
                        "slug": "Umesh-Rajashekar",
                        "structuredName": {
                            "firstName": "Umesh",
                            "lastName": "Rajashekar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Umesh Rajashekar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727781"
                        ],
                        "name": "L. Cormack",
                        "slug": "L.-Cormack",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Cormack",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Cormack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747569"
                        ],
                        "name": "A. Bovik",
                        "slug": "A.-Bovik",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Bovik",
                            "middleNames": [
                                "Conrad"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bovik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 58471,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cba6b1e8cb41f3d9f4b1ef0b8a8018b835861c0",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to automatically detect 'visually interesting' regions in an image has many practical applications especially in the design of active machine vision systems. This paper describes a data-driven approach that uses eye tracking in tandem with principal component analysis to extract low-level image features that attract human gaze. Data analysis on an ensemble of image patches extracted at the observer's point of gaze revealed features that resemble derivatives of the 2D Gaussian operator. Dissimilarities between human and random fixations are investigated by comparing the features extracted at the point of gaze to the general image structure obtained by random sampling in Monte-Carlo simulations. Finally, a simple application where these features are used to predict fixations is illustrated."
            },
            "slug": "Image-features-that-draw-fixations-Rajashekar-Cormack",
            "title": {
                "fragments": [],
                "text": "Image features that draw fixations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A data-driven approach that uses eye tracking in tandem with principal component analysis to extract low-level image features that attract human gaze that resemble derivatives of the 2D Gaussian operator is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2003 International Conference on Image Processing (Cat. No.03CH37429)"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721860"
                        ],
                        "name": "M. Wainwright",
                        "slug": "M.-Wainwright",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wainwright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wainwright"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47590737"
                        ],
                        "name": "O. Schwartz",
                        "slug": "O.-Schwartz",
                        "structuredName": {
                            "firstName": "Odelia",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 592657,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "935e580d058c78cf8f1c08e3885254015c153089",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding the functional role of neurons and neural systems is a primary goal of systems neuroscience. A longstanding hypothesis states that sensory systems are matched to the statistical properties of the signals to which they are exposed [e.g., 4, 6]. In particular, Barlow has proposed that the role of early sensory systems is to remove redundancy in the sensory input, resulting in a set of neural responses that are statistically independent. Variants of this hypothesis have been formulated by a number of other authors [e.g., 2, 52] (see [47] for a review). The basic version assumes a fixed environmental model, but Barlow and Foldiak later augmented the theory by suggesting that adaptation in neural systems might be thought of as an adjustment to remove redundancies in the responses to recently presented stimuli [8, 7]. There are two basic methodologies for testing such hypotheses. The most direct approach is to examine the statistical properties of neural responses under natural stimulation conditions [e.g., 25, 41, 17, 5, 40] or the statistical dependency of pairs (or groups) of neural responses. Due to their technical difficulty, such multi-cellular experiments are only recently becoming possible, and the earliest reports appear consistent with the hypothesis [e.g., 54]. An alternative approach is to \" derive \" a model for early sensory processing [e. statistical properties of environmental signals and shows that a transformation derived according to some statistical optimization criterion provides a good description of the response properties of a set of sensory neurons. We follow this latter approach in this chapter."
            },
            "slug": "Natural-image-statistics-and-divisive-Modeling-and-Wainwright-Schwartz",
            "title": {
                "fragments": [],
                "text": "Natural image statistics and divisive normalization: Modeling nonlinearity and adaptation in cortical neurons"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This chapter examines the statistical properties of neural responses under natural stimulation conditions and derives a model for early sensory processing that shows that a transformation derived according to some statistical optimization criterion provides a good description of the response properties of a set of sensory neurons."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067802372"
                        ],
                        "name": "J. Xing",
                        "slug": "J.-Xing",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Xing",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Xing"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the suprathreshold range, can the relative visual distortions between different channels be normalized using the visibility thresholds? Recent efforts have been made to incorporate suprathreshold psychophysics for analyzing image distortions (e.g., [30]\u2013[ 34 ])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62735941,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1aa093bce575959cc40f8407f0dc3693973d2130",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "An multi\u2010layered image processing model of the primary visual system was built to simulate the center\u2010surround effect on apparent contrast perception and contrast discrimination at the suprathreshold level. The simulation revealed that the mechanisms for apparent contrast perception and contrast discrimination were instinctually different. We questioned the reliability of the perceptual image quality models that were based on the results of contrast discrimination experiments."
            },
            "slug": "P\u201014:-An-Image-Processing-Model-of-Contrast-and-of-Xing",
            "title": {
                "fragments": [],
                "text": "P\u201014: An Image Processing Model of Contrast Perception and Discrimination of the Human Visual System"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "An multi-layered image processing model of the primary visual system was built to simulate the center-surround effect on apparent contrast perception and contrast discrimination at the suprathreshold level, and revealed that the mechanisms for apparent Contrast Perception and Contrast discrimination were instinctually different."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3027053"
                        ],
                        "name": "A. Poirson",
                        "slug": "A.-Poirson",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Poirson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Poirson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2022202"
                        ],
                        "name": "B. Wandell",
                        "slug": "B.-Wandell",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Wandell",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Wandell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "The Minkowski error metric is based on pointwise signal differences, which are independent of the underlying signal structure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14982278,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "26d99d614d7c2780b56f7b2e287acfbb5c9c1d19",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We have measured how color appearance of square-wave bars varies with stimulus strength and spatial frequency. Observers adjusted the color of a uniform patch to match the color appearance of the bars in square-wave patterns. We used low-to-moderate square-wave patterns, from 1 to 8 cycles per degree (c/deg). The matches are not photoreceptor matches but rather are established at more central neural sites. The signals at the putative central sites obey several simple regularities. The cone contrast of the uniform patch is proportional to square-wave stimulus strength (color homogeneity) and additive with respect to the superposition of equal-frequency square waves containing different colors (color superposition). We use the asymmetric matches to derive, from first principles, three pattern-color-separable appearance pathways. The matches are explained by two spectrally opponent, spatially low-pass mechanisms and one spectrally positive, spatially bandpass mechanism. The spectral mechanisms that we derive are similar to luminance and opponent mechanisms that are derived with entirely different experimental methods."
            },
            "slug": "Appearance-of-colored-patterns:-pattern-color-Poirson-Wandell",
            "title": {
                "fragments": [],
                "text": "Appearance of colored patterns: pattern-color separability."
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "It is measured how color appearance of square-wave bars varies with stimulus strength and spatial frequency and uses the asymmetric matches to derive, from first principles, three pattern-color-separable appearance pathways."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Optical Society of America. A, Optics, image science, and vision"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1828659"
                        ],
                        "name": "A. Watson",
                        "slug": "A.-Watson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Watson",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Watson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "This new philosophy can be best understood through comparison with the error sensitivity philosophy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62573517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba6eed20f600d6c70058b83b2fef0ea694b572b0",
            "isKey": false,
            "numCitedBy": 480,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-cortex-transform:-rapid-computation-of-neural-Watson",
            "title": {
                "fragments": [],
                "text": "The cortex transform: rapid computation of simulated neural images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47590737"
                        ],
                        "name": "O. Schwartz",
                        "slug": "O.-Schwartz",
                        "structuredName": {
                            "firstName": "Odelia",
                            "lastName": "Schwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Schwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "On the other hand, the image structures are changed dramatically in the worstcase MSSIM image, in some cases reversing contrast."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6346299,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "561b6f0ea628a70e5170b4fef920ebc3f6f63907",
            "isKey": false,
            "numCitedBy": 824,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a form of nonlinear decomposition that is well-suited for efficient encoding of natural signals. Signals are initially decomposed using a bank of linear filters. Each filter response is then rectified and divided by a weighted sum of rectified responses of neighboring filters. We show that this decomposition, with parameters optimized for the statistics of a generic ensemble of natural images or sounds, provides a good characterization of the nonlinear response properties of typical neurons in primary visual cortex or auditory nerve, respectively. These results suggest that nonlinear response properties of sensory neurons are not an accident of biological implementation, but have an important functional role."
            },
            "slug": "Natural-signal-statistics-and-sensory-gain-control-Schwartz-Simoncelli",
            "title": {
                "fragments": [],
                "text": "Natural signal statistics and sensory gain control"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that this decomposition, with parameters optimized for the statistics of a generic ensemble of natural images or sounds, provides a good characterization of the nonlinear response properties of typical neurons in primary visual cortex or auditory nerve, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Neuroscience"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739786"
                        ],
                        "name": "B. Girod",
                        "slug": "B.-Girod",
                        "structuredName": {
                            "firstName": "Bernd",
                            "lastName": "Girod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Girod"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "These are appealing because they are simple to calculate, have clear physical meanings, and are mathematically convenient in the context of optimization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60888133,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "1c2b76c592cb8b487ff8df953ac02ecd1a01faad",
            "isKey": false,
            "numCitedBy": 673,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The invention relates to a spark plug tightener with a cylindrical housing having on one end a multi-faceted opening for engaging the spark plug and on the other end an annular shaped profile in front view through which passes a turning shaft with a corresponding profile in front view whereby the turning shaft is held under the tension of cup springs by means of a cover cap screwed over the housing."
            },
            "slug": "What's-wrong-with-mean-squared-error-Girod",
            "title": {
                "fragments": [],
                "text": "What's wrong with mean-squared error?"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The invention relates to a spark plug tightener with a cylindrical housing having on one end a multi-faceted opening for engaging the spark plug and on the other end an annular shaped profile in front view through which passes a turning shaft."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682725"
                        ],
                        "name": "D. Taubman",
                        "slug": "D.-Taubman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Taubman",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Taubman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722764"
                        ],
                        "name": "M. Marcellin",
                        "slug": "M.-Marcellin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Marcellin",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcellin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 198120358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c05212969d9438fc859897898b1de9fe3e34659f",
            "isKey": false,
            "numCitedBy": 2132,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "JPEG2000-image-compression-fundamentals,-standards-Taubman-Marcellin",
            "title": {
                "fragments": [],
                "text": "JPEG2000 - image compression fundamentals, standards and practice"
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39102803"
                        ],
                        "name": "J. Lubin",
                        "slug": "J.-Lubin",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Lubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59651339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c927b5581f4fe972dd89fcdd1ba35ecb265d6075",
            "isKey": false,
            "numCitedBy": 402,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-VISUAL-DISCRIMINATION-MODEL-FOR-IMAGING-SYSTEM-Lubin",
            "title": {
                "fragments": [],
                "text": "A VISUAL DISCRIMINATION MODEL FOR IMAGING SYSTEM DESIGN AND EVALUATION"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39102803"
                        ],
                        "name": "J. Lubin",
                        "slug": "J.-Lubin",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Lubin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lubin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59774068,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "bf96d9ef61e001d6dcdc1d5be6587591487430f5",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-use-of-psychophysical-data-and-models-in-the-of-Lubin",
            "title": {
                "fragments": [],
                "text": "The use of psychophysical data and models in the analysis of display system performance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714983"
                        ],
                        "name": "T. Pappas",
                        "slug": "T.-Pappas",
                        "structuredName": {
                            "firstName": "Thrasyvoulos",
                            "lastName": "Pappas",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Pappas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Finally, the reference and the distorted images may be modified using a nonlinear point operation to simulate light adaptation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14595075,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2f9f89f1c30a9f1f0d9493601f5803ce33b02ef",
            "isKey": false,
            "numCitedBy": 323,
            "numCiting": 122,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Perceptual-criteria-for-image-quality-evaluation-Pappas",
            "title": {
                "fragments": [],
                "text": "Perceptual criteria for image quality evaluation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Final report from the video quality experts group on the validation of objective models of video quality assessment"
            },
            "venue": {
                "fragments": [],
                "text": "Final report from the video quality experts group on the validation of objective models of video quality assessment"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A visual discrimination mode for image system design and evaluation, \" in Visual Models for Target Detection and Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "A visual discrimination mode for image system design and evaluation, \" in Visual Models for Target Detection and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SSIM index for image quality assessment"
            },
            "venue": {
                "fragments": [],
                "text": "The SSIM index for image quality assessment"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "PSNR; (b) Sarnoff model [56]; (c) UQI [7] (equivalent to MSSIM with square window and K1 = K2 = 0); (d) MSSIM (Gaussian window, K1 = 0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "The quality assessment models used for comparison include PSNR, the well-known Sarnoff model [56](2), UQI [7] and MSSIM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A visual discrimination mode for image system design and evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Visual Models for Target Detection and Recognition (E. Peli, ed.), pp. 245\u2013283, Singapore: World Scientific Publishers, 1995."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The visible difference predictor: An algorithm for the assessment of image fidelity, \" in Digital images and human vision"
            },
            "venue": {
                "fragments": [],
                "text": "The visible difference predictor: An algorithm for the assessment of image fidelity, \" in Digital images and human vision"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "This new philosophy can be best understood through comparison with the error sensitivity philosophy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shiftable multi-scale transforms"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Information Theory"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "On the other hand, the image structures are changed dramatically in the worstcase MSSIM image, in some cases reversing contrast."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An image processing model of contrast perception and discrimination of the human visual system"
            },
            "venue": {
                "fragments": [],
                "text": "SID Conference"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "A MatLab implementation of the SSIM index algorithm is available online at [53]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SSIM index for image quality assessment"
            },
            "venue": {
                "fragments": [],
                "text": "http: //www.cns.nyu.edu/~lcv/ssim/."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Demo Images and Free Software for 'a Universal Image Quality Index'. [Online] Available"
            },
            "venue": {
                "fragments": [],
                "text": "Demo Images and Free Software for 'a Universal Image Quality Index'. [Online] Available"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mar.) Final Report From the Video Quality Experts Group on the Validation of Objective Models of Video Quality Assessment"
            },
            "venue": {
                "fragments": [],
                "text": "VQEG"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Prior information regarding the image content, or attention and fixation, may also affect the evaluation of the image quality [4], [47]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Joint photographic experts group (JPEG) compatible data compression of mammo-  14  IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 13, NO. 4, APRIL 2004 grams"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Digital Imaging, vol. 7, no. 3, pp. 123\u2013132, 1994."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Rate scalable foveated image and video communications"
            },
            "venue": {
                "fragments": [],
                "text": "Rate scalable foveated image and video communications"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image and Video Quality Assessment Research at LIVE. [Online] Available"
            },
            "venue": {
                "fragments": [],
                "text": "Image and Video Quality Assessment Research at LIVE. [Online] Available"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image and video quality assessment research at LIVE A visual discrimination mode for image system design and evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Visual Models for Target Detection and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Demo images and free software for 'a universal image quality index"
            },
            "venue": {
                "fragments": [],
                "text": "Demo images and free software for 'a universal image quality index"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image and video quality assessment research at LIVE"
            },
            "venue": {
                "fragments": [],
                "text": "Image and video quality assessment research at LIVE"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON IMAGE PROCESSING"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON IMAGE PROCESSING"
            },
            "year": 2004
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 70,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Image-quality-assessment:-from-error-visibility-to-Wang-Bovik/eae2e0fa72e898c289365c0af16daf57a7a6cf40?sort=total-citations"
}