{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701734"
                        ],
                        "name": "X. Carreras",
                        "slug": "X.-Carreras",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Carreras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Carreras"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 203
                            }
                        ],
                        "text": "In our final experiments, we tested eight different parsing configurations, representing all possible choices between baseline and cluster-based feature sets, first-order (Eisner, 2000) and second-order (Carreras, 2007) factorizations, and labeled and unlabeled parsing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 66
                            }
                        ],
                        "text": "For complex structured models like higher-order depenency parsers (McDonald and Pereira, 2006; Carreras, 2007), implementing algorithms that compute marginal probabilities can require effort."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 69
                            }
                        ],
                        "text": "Our feature sets are similar to other feature sets in the literature (McDonald et al., 2005a; Carreras, 2007), so we will not attempt to give a complete description of our features in this section."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 8000929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c205e82ddf7d9bd759cca3e16baa60c49cecf056",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present experiments with a dependency parsing model defined on rich factors. Our model represents dependency trees with factors that include three types of relations between the tokens of a dependency and their children. We extend the projective parsing algorithm of Eisner (1996) for our case, and train models using the averaged perceptron. Our experiments show that considering higher-order information yields significant improvements in parsing accuracy, but comes at a high cost in terms of both time and memory consumption. In the multilingual exercise of the CoNLL-2007 shared task (Nivre et al., 2007), our system obtains the best accuracy for English, and the second best accuracies for Basque and Czech."
            },
            "slug": "Experiments-with-a-Higher-Order-Projective-Parser-Carreras",
            "title": {
                "fragments": [],
                "text": "Experiments with a Higher-Order Projective Dependency Parser"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "In the multilingual exercise of the CoNLL-2007 shared task (Nivre et al., 2007), the system obtains the best accuracy for English, and the second best accuracies for Basque and Czech."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782178"
                        ],
                        "name": "S. Buchholz",
                        "slug": "S.-Buchholz",
                        "structuredName": {
                            "firstName": "Sabine",
                            "lastName": "Buchholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Buchholz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748039"
                        ],
                        "name": "E. Marsi",
                        "slug": "E.-Marsi",
                        "structuredName": {
                            "firstName": "Erwin",
                            "lastName": "Marsi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Marsi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 145
                            }
                        ],
                        "text": "To demonstrate the effectiveness of our approach, we conduct experiments in dependency parsing, which has been the focus of much recent research (Buchholz and Marsi, 2006; Nivre et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 12
                            }
                        ],
                        "text": "Recent work (Buchholz and Marsi, 2006; Nivre et al., 2007) has focused on dependency parsing as an alternative to phrase-structure parsing."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13075323,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1deed1a4a03e07aee3b8b8e4716f35033c715a57",
            "isKey": false,
            "numCitedBy": 1047,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "Each year the Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their systems on exactly the same data sets, in order to better compare systems. The tenth CoNLL (CoNLL-X) saw a shared task on Multilingual Dependency Parsing. In this paper, we describe how treebanks for 13 languages were converted into the same dependency format and how parsing performance was measured. We also give an overview of the parsing approaches that participants took and the results that they achieved. Finally, we try to draw general conclusions about multi-lingual parsing: What makes a particular language, treebank or annotation scheme easier or harder to parse and which phenomena are challenging for any dependency parser?"
            },
            "slug": "CoNLL-X-Shared-Task-on-Multilingual-Dependency-Buchholz-Marsi",
            "title": {
                "fragments": [],
                "text": "CoNLL-X Shared Task on Multilingual Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "How treebanks for 13 languages were converted into the same dependency format and how parsing performance was measured is described and general conclusions about multi-lingual parsing are drawn."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754497"
                        ],
                        "name": "Slav Petrov",
                        "slug": "Slav-Petrov",
                        "structuredName": {
                            "firstName": "Slav",
                            "lastName": "Petrov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Slav Petrov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37157794"
                        ],
                        "name": "Leon Barrett",
                        "slug": "Leon-Barrett",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Barrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leon Barrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3323298"
                        ],
                        "name": "R. Thibaux",
                        "slug": "R.-Thibaux",
                        "structuredName": {
                            "firstName": "Romain",
                            "lastName": "Thibaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Thibaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 138
                            }
                        ],
                        "text": "Previous research in this area includes several models which incorporate hidden variables (Matsuzaki et al., 2005; Koo and Collins, 2005; Petrov et al., 2006; Titov and Henderson, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6684426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52de7242e574b70410ca6fb70b79c811919fc00",
            "isKey": false,
            "numCitedBy": 965,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank. Starting with a simple X-bar grammar, we learn a new grammar whose nonterminals are subsymbols of the original nonterminals. In contrast with previous work, we are able to split various terminals to different degrees, as appropriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more accurate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F1 of 90.2% on the Penn Treebank, higher than fully lexicalized systems."
            },
            "slug": "Learning-Accurate,-Compact,-and-Interpretable-Tree-Petrov-Barrett",
            "title": {
                "fragments": [],
                "text": "Learning Accurate, Compact, and Interpretable Tree Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144464152"
                        ],
                        "name": "K. Hall",
                        "slug": "K.-Hall",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058589931"
                        ],
                        "name": "V\u00e1clav Nov\u00e1k",
                        "slug": "V\u00e1clav-Nov\u00e1k",
                        "structuredName": {
                            "firstName": "V\u00e1clav",
                            "lastName": "Nov\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V\u00e1clav Nov\u00e1k"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4 Hall and Nov\u00e1k (2005) 85."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7966094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1b1a28b10a5547b7907d58f07b07b3fd5714eb6",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a corrective model for recovering non-projective dependency structures from trees generated by state-of-the-art constituency-based parsers. The continuity constraint of these constituency-based parsers makes it impossible for them to posit non-projective dependency trees. Analysis of the types of dependency errors made by these parsers on a Czech corpus show that the correct governor is likely to be found within a local neighborhood of the governor proposed by the parser. Our model, based on a MaxEnt classifier, improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non-projective structures."
            },
            "slug": "Corrective-Modeling-for-Non-Projective-Dependency-Hall-Nov\u00e1k",
            "title": {
                "fragments": [],
                "text": "Corrective Modeling for Non-Projective Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "A corrective model for recovering non-projective dependency structures from trees generated by state-of-the-art constituency-based parsers improves overall dependency accuracy by .7% (a 4.5% reduction in error) with over 50% accuracy for non- projective structures."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2396002"
                        ],
                        "name": "Alena B\u00f6hmov\u00e1",
                        "slug": "Alena-B\u00f6hmov\u00e1",
                        "structuredName": {
                            "firstName": "Alena",
                            "lastName": "B\u00f6hmov\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alena B\u00f6hmov\u00e1"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002335"
                        ],
                        "name": "Jan Hajic",
                        "slug": "Jan-Hajic",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Hajic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Hajic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735736"
                        ],
                        "name": "E. Hajicov\u00e1",
                        "slug": "E.-Hajicov\u00e1",
                        "structuredName": {
                            "firstName": "Eva",
                            "lastName": "Hajicov\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Hajicov\u00e1"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1963585"
                        ],
                        "name": "B. Hladk\u00e1",
                        "slug": "B.-Hladk\u00e1",
                        "structuredName": {
                            "firstName": "Barbora",
                            "lastName": "Hladk\u00e1",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hladk\u00e1"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56699379,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "d4e29d756711d9bf143afffd913d9a2ced391904",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The availability of annotated data (with as rich and \u201cdeep\u201d annotation as possible) is desirable in any new developments. Textual data are being used for so-called training phase of various empirical methods solving various problems in the field of computational linguistics. While there are many methods that use texts in their plain (or raw) form (in most cases for so-called unsupervised training), more accurate results may be obtained if annotated corpora are available. The data annotation itself is a complex task. While morphologically annotated corpora (pioneered by Henry Kucera in the 60\u2019s) are now available for English and other languages, syntactically annotated corpora are rare. Inspired by the Penn Treebank, the most widely used syntactically annotated corpus of English, we decided to develop a similarly sized corpus of Czech with a rich annotation scheme."
            },
            "slug": "The-Prague-Dependency-Treebank-B\u00f6hmov\u00e1-Hajic",
            "title": {
                "fragments": [],
                "text": "The Prague Dependency Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Inspired by the Penn Treebank, the most widely used syntactically annotated corpus of English, this work decided to develop a similarly sized corpus of Czech with a rich annotation scheme."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116761611"
                        ],
                        "name": "Qin Iris Wang",
                        "slug": "Qin-Iris-Wang",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Wang",
                            "middleNames": [
                                "Iris"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qin Iris Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690956"
                        ],
                        "name": "Dekang Lin",
                        "slug": "Dekang-Lin",
                        "structuredName": {
                            "firstName": "Dekang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Wang et al. (2005) used distributional similarity scores to smooth a generative probability model for dependency parsing and obtained improvements in a Chinese parsing task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7996917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90146f35a26eec06cdd3aa7c5c4a23344a24dca1",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a strictly lexical parsing model where all the parameters are based on the words. This model does not rely on part-of-speech tags or grammatical categories. It maximizes the conditional probability of the parse tree given the sentence. This is in contrast with most previous models that compute the joint probability of the parse tree and the sentence. Although the maximization of joint and conditional probabilities are theoretically equivalent, the conditional model allows us to use distributional word similarity to generalize the observed frequency counts in the training corpus. Our experiments with the Chinese Treebank show that the accuracy of the conditional model is 13.6% higher than the joint model and that the strictly lexicalized conditional model outperforms the corresponding unlexicalized model based on part-of-speech tags."
            },
            "slug": "Strictly-Lexical-Dependency-Parsing-Wang-Schuurmans",
            "title": {
                "fragments": [],
                "text": "Strictly Lexical Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A strictly lexical parsing model where all the parameters are based on the words, which maximizes the conditional probability of the parse tree given the sentence and outperforms the corresponding unlexicalized model based on part-of-speech tags."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712813"
                        ],
                        "name": "Johan Hall",
                        "slug": "Johan-Hall",
                        "structuredName": {
                            "firstName": "Johan",
                            "lastName": "Hall",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johan Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804668"
                        ],
                        "name": "Sandra K\u00fcbler",
                        "slug": "Sandra-K\u00fcbler",
                        "structuredName": {
                            "firstName": "Sandra",
                            "lastName": "K\u00fcbler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sandra K\u00fcbler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145446170"
                        ],
                        "name": "Jens Nilsson",
                        "slug": "Jens-Nilsson",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Nilsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Nilsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941665"
                        ],
                        "name": "S. Riedel",
                        "slug": "S.-Riedel",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Riedel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riedel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2808366"
                        ],
                        "name": "Deniz Yuret",
                        "slug": "Deniz-Yuret",
                        "structuredName": {
                            "firstName": "Deniz",
                            "lastName": "Yuret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Deniz Yuret"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1585700,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10a9abb4c78f0be5cc85847f248d3e8277b3c810",
            "isKey": false,
            "numCitedBy": 768,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The Conference on Computational Natural Language Learning features a shared task, in which participants train and test their learning systems on the same data sets. In 2007, as in 2006, the shared task has been devoted to dependency parsing, this year with both a multilingual track and a domain adaptation track. In thispaper, we definethe tasksof the different tracks and describe how the data sets were created from existing treebanks for ten languages. In addition, we characterize the different approaches of the participating systems, report the test results, and provide a first analysis of these results."
            },
            "slug": "The-CoNLL-2007-Shared-Task-on-Dependency-Parsing-Nivre-Hall",
            "title": {
                "fragments": [],
                "text": "The CoNLL 2007 Shared Task on Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The tasks of the different tracks are defined and how the data sets were created from existing treebanks for ten languages are described, to characterize the different approaches of the participating systems and report the test results and provide a first analysis of these results."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33860574"
                        ],
                        "name": "Takuya Matsuzaki",
                        "slug": "Takuya-Matsuzaki",
                        "structuredName": {
                            "firstName": "Takuya",
                            "lastName": "Matsuzaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Takuya Matsuzaki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768065"
                        ],
                        "name": "Yusuke Miyao",
                        "slug": "Yusuke-Miyao",
                        "structuredName": {
                            "firstName": "Yusuke",
                            "lastName": "Miyao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yusuke Miyao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737901"
                        ],
                        "name": "Junichi Tsujii",
                        "slug": "Junichi-Tsujii",
                        "structuredName": {
                            "firstName": "Junichi",
                            "lastName": "Tsujii",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junichi Tsujii"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8008954,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "713a4825ea09801ebc24ce207ca9ae5fbc97ac65",
            "isKey": false,
            "numCitedBy": 298,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper defines a generative probabilistic model of parse trees, which we call PCFG-LA. This model is an extension of PCFG in which non-terminal symbols are augmented with latent variables. Fine-grained CFG rules are automatically induced from a parsed corpus by training a PCFG-LA model using an EM-algorithm. Because exact parsing with a PCFG-LA is NP-hard, several approximations are described and empirically compared. In experiments using the Penn WSJ corpus, our automatically trained model gave a performance of 86.6% (F1, sentences \u2264 40 words), which is comparable to that of an unlexicalized PCFG parser created using extensive manual feature selection."
            },
            "slug": "Probabilistic-CFG-with-Latent-Annotations-Matsuzaki-Miyao",
            "title": {
                "fragments": [],
                "text": "Probabilistic CFG with Latent Annotations"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This paper defines a generative probabilistic model of parse trees, which is an extension of PCFG in which non-terminal symbols are augmented with latent variables, and automatically induced fine-grained CFG rules are automatically induced from a parsed corpus by training a PCFG-LA model using an EM-algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 92
                            }
                        ],
                        "text": "Table 2 compiles our final test results and also includes two results from previous work by McDonald et al. (2005a) and McDonald and Pereira (2006), for the purposes of comparison."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 46
                            }
                        ],
                        "text": "To facilitate comparisons with previous work (McDonald et al., 2005b; McDonald and Pereira, 2006), we used the training/development/test partition defined in the corpus and we also used the automatically-assigned part of speech tags provided in the corpus.10 Czech word clusters were derived from\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 16
                            }
                        ],
                        "text": "1We augment the McDonald et al. (2005a) feature set with backed-off versions of the \u201cSurrounding Word POS Features\u201d that include only one neighboring POS tag."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 78
                            }
                        ],
                        "text": "The feature sets we used are similar to other feature sets in the literature (McDonald et al., 2005a; Carreras, 2007), so we will not attempt to give a exhaustive description of the features in this section."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 201
                            }
                        ],
                        "text": "In addition, in English parsing we ignore the parent-predictions of punctuation tokens,13 and in Czech parsing we retain the punctuation tokens; this matches previous work (Yamada and Matsumoto, 2003; McDonald et al., 2005a; McDonald and Pereira, 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 223
                            }
                        ],
                        "text": "\u2026and structure domains Y(\u00b7), it is possible to solve the above maximization efficiently, and several recent efforts have concentrated on designing new maximization algorithms with increased contextsensitivity (Eisner, 2000; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 155
                            }
                        ],
                        "text": "10Following Collins et al. (1999), we used a coarsened version of the Czech part of speech tags; this choice also matches the conditions of previous work (McDonald et al., 2005b; McDonald and Pereira, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 98
                            }
                        ],
                        "text": "The data partition and head rules were chosen to match previous work (Yamada and Matsumoto, 2003; McDonald et al., 2005a; McDonald and Pereira, 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 152
                            }
                        ],
                        "text": "Czech dependency structures may contain nonprojective edges, so we employ a maximum directed spanning tree algorithm (Chu and Liu, 1965; Edmonds, 1967; McDonald et al., 2005b) as our firstorder parser for Czech."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The feature sets we used are similar to other feature sets in the literature (McDonald et al., 2005a; Carreras, 2007), so we will not attempt to give a exhaustive description of the features in"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 70
                            }
                        ],
                        "text": "Our first-order baseline feature set is similar to the feature set of McDonald et al. (2005a), and consists of indicator functions for combinations of words and parts of speech for the head and modifier of each dependency, as well as certain contextual tokens.1 Our second-order baseline features\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We augment the McDonald et al. (2005a) feature set with backed-off versions of the \u201cSurrounding Word POS Features\u201d that include only one neighboring POS tag."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12926517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d3b27746f7a53f2dc5d9b8c2f3d343313622ec36",
            "isKey": true,
            "numCitedBy": 917,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an effective training algorithm for linearly-scored dependency parsers that implements online large-margin multi-class training (Crammer and Singer, 2003; Crammer et al., 2003) on top of efficient parsing techniques for dependency trees (Eisner, 1996). The trained parsers achieve a competitive dependency accuracy for both English and Czech with no language specific enhancements."
            },
            "slug": "Online-Large-Margin-Training-of-Dependency-Parsers-McDonald-Crammer",
            "title": {
                "fragments": [],
                "text": "Online Large-Margin Training of Dependency Parsers"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An effective training algorithm for linearly-scored dependency parsers that implements online large-margin multi-class training on top of efficient parsing techniques for dependency trees is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060101052"
                        ],
                        "name": "Terry Koo",
                        "slug": "Terry-Koo",
                        "structuredName": {
                            "firstName": "Terry",
                            "lastName": "Koo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terry Koo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6163275,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3fdc954fa36b123da63a3d35a8eecfdaf1b298b",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new method for the representation of NLP structures within reranking approaches. We make use of a conditional log-linear model, with hidden variables representing the assignment of lexical items to word clusters or word senses. The model learns to automatically make these assignments based on a discriminative training criterion. Training and decoding with the model requires summing over an exponential number of hidden-variable assignments: the required summations can be computed efficiently and exactly using dynamic programming. As a case study, we apply the model to parse reranking. The model gives an F-measure improvement of a 1.25% beyond the base parser, and an a 0.25% improvement beyond the Collins (2000) reranker. Although our experiments are focused on parsing, the techniques described generalize naturally to NLP structures other than parse trees."
            },
            "slug": "Hidden-Variable-Models-for-Discriminative-Reranking-Koo-Collins",
            "title": {
                "fragments": [],
                "text": "Hidden-Variable Models for Discriminative Reranking"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A conditional log-linear model is made use, with hidden variables representing the assignment of lexical items to word clusters or word senses, based on a discriminative training criterion for NLP structures within reranking approaches."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2240597"
                        ],
                        "name": "David McClosky",
                        "slug": "David-McClosky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McClosky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David McClosky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177220"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 73
                            }
                        ],
                        "text": "Semi-supervised phrase structure parsing has been previously explored by McClosky et al. (2006), who applied a reranked parser to a large unsupervised corpus in order to obtain additional training data for the parser; this self-training appraoch was shown to be quite effective in practice."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, the parser of McDonald and Pereira (2006) defines parts for sibling interactions, such as the trio \u201cplays\u201d, \u201cElianti\u201d, and \u201c."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 125
                            }
                        ],
                        "text": "These improved clusters can then be used to retrain an improved parser, resulting in an overall algorithm similar to that of McClosky et al. (2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Semi-supervised phrase structure parsing has been previously explored by McClosky et al. (2006),"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "These improved clusters can then be used to retrain an improved parser, resulting in an overall algorithm similar to that of McClosky et al. (2006). Setting aside the development of new clustering"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1 McDonald et al. (2005b) 84."
                    },
                    "intents": []
                }
            ],
            "corpusId": 628455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78a9513e70f596077179101f6cb6eadc51602039",
            "isKey": true,
            "numCitedBy": 586,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple, but surprisingly effective, method of self-training a two-phase parser-reranker system using readily available unlabeled data. We show that this type of bootstrapping is possible for parsing when the bootstrapped parses are processed by a discriminative reranker. Our improved model achieves an f-score of 92.1%, an absolute 1.1% improvement (12% error reduction) over the previous best result for Wall Street Journal parsing. Finally, we provide some analysis to better understand the phenomenon."
            },
            "slug": "Effective-Self-Training-for-Parsing-McClosky-Charniak",
            "title": {
                "fragments": [],
                "text": "Effective Self-Training for Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work presents a simple, but surprisingly effective, method of self-training a two-phase parser-reranker system using readily available unlabeled data and shows that this type of bootstrapping is possible for parsing when the bootstrapped parses are processed by a discriminative reranker."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075292388"
                        ],
                        "name": "P. Liang",
                        "slug": "P.-Liang",
                        "structuredName": {
                            "firstName": "Percy",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Liang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "We chose to work with the Brown algorithm due to its simplicity and prior success in other NLP applications (Miller et al., 2004; Liang, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 54
                            }
                        ],
                        "text": "For all of the experiments in this paper, we used the Liang (2005) implementation of the Brown algorithm to obtain the necessary word clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14740218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31b4c03d721dc10b87c178277c1d369f91db8f0e",
            "isKey": false,
            "numCitedBy": 354,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical supervised learning techniques have been successful for many natural language processing tasks, but they require labeled datasets, which can be expensive to obtain. On the other hand, unlabeled data (raw text) is often available \"for free\" in large quantities. Unlabeled data has shown promise in improving the performance of a number of tasks, e.g. word sense disambiguation, information extraction, and natural language parsing. In this thesis, we focus on two segmentation tasks, named-entity recognition and Chinese word segmentation. The goal of named-entity recognition is to detect and classify names of people, organizations, and locations in a sentence. The goal of Chinese word segmentation is to find the word boundaries in a sentence that has been written as a string of characters without spaces. Our approach is as follows: In a preprocessing step, we use raw text to cluster words and calculate mutual information statistics. The output of this step is then used as features in a supervised model, specifically a global linear model trained using the Perceptron algorithm. We also compare Markov and semi-Markov models on the two segmentation tasks. Our results show that features derived from unlabeled data substantially improves performance, both in terms of reducing the amount of labeled data needed to achieve a certain performance level and in terms of reducing the error using a fixed amount of labeled data. We find that sometimes semi-Markov models can also improve performance over Markov models. Thesis Supervisor: Michael Collins Title: Assistant Professor, CSAIL"
            },
            "slug": "Semi-Supervised-Learning-for-Natural-Language-Liang",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning for Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This thesis focuses on two segmentation tasks, named-entity recognition and Chinese word segmentation, and shows that features derived from unlabeled data substantially improves performance, both in terms of reducing the amount of labeled data needed to achieve a certain performance level and in termsof reducing the error using a fixed amount of labeling data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145446170"
                        ],
                        "name": "Jens Nilsson",
                        "slug": "Jens-Nilsson",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Nilsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17842042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b92c0e898b1fee243864176e18a2b50105be3e54",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures. We show how a data-driven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures. Experiments using data from the Prague Dependency Treebank show that the combined system can handle non-projective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy. This leads to the best reported performance for robust non-projective parsing of Czech."
            },
            "slug": "Pseudo-Projective-Dependency-Parsing-Nivre-Nilsson",
            "title": {
                "fragments": [],
                "text": "Pseudo-Projective Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments show that the combined system can handle non-projective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy, leading to the best reported performance for robust non- projective parsing of Czech."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 61
                            }
                        ],
                        "text": "The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 46
                            }
                        ],
                        "text": "The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set (Sections 2\u201321), a development set (Section 22), and several test sets (Sections 0,7 1, 23, and 24)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 38
                            }
                        ],
                        "text": "9We ensured that the sentences of the Penn Treebank were excluded from the text used for the clustering."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 137
                            }
                        ],
                        "text": "We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank (Marcus et al., 1993) and Prague Dependency Treebank (Hajic\u030c, 1998; Hajic\u030c et al., 2001) (see Sections 4.1 and 4.3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": true,
            "numCitedBy": 8177,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002335"
                        ],
                        "name": "Jan Hajic",
                        "slug": "Jan-Hajic",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Hajic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Hajic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744313"
                        ],
                        "name": "L. Ramshaw",
                        "slug": "L.-Ramshaw",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Ramshaw",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ramshaw"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324070"
                        ],
                        "name": "C. Tillmann",
                        "slug": "C.-Tillmann",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Tillmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Tillmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 12
                            }
                        ],
                        "text": "10Following Collins et al. (1999), we used a coarsened version of the Czech part of speech tags; this choice also matches the conditions of previous work (McDonald et al., 2005b; McDonald and Pereira, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Following Collins et al. (1999), we used a coarsened version of the Czech part of speech tags; this choice also matches the conditions of previous work (McDonald et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1269169,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cb912b4a208b217c45d57e28fc0f59599f92330",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers statistical parsing of Czech, which differs radically from English in at least two respects: (1) it is a highly inflected language, and (2) it has relatively free word order. These differences are likely to pose new problems for techniques that have been developed on English. We describe our experience in building on the parsing model of (Collins 97). Our final results- 80% dependency accuracy - represent good progress towards the 91% accuracy of the parser on English (Wall Street Journal) text."
            },
            "slug": "A-Statistical-Parser-for-Czech-Collins-Hajic",
            "title": {
                "fragments": [],
                "text": "A Statistical Parser for Czech"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper considers statistical parsing of Czech, which differs radically from English in at least two respects: (1) it is a highly inflected language, and (2) it has relatively free word order."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 66
                            }
                        ],
                        "text": "For complex structured models like higher-order depenency parsers (McDonald and Pereira, 2006; Carreras, 2007), implementing algorithms that compute marginal probabilities can require effort."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 802998,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d1d98807843fad7de1734629edb0c873015c14a",
            "isKey": false,
            "numCitedBy": 552,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we extend the maximum spanning tree (MST) dependency parsing framework of McDonald et al. (2005c) to incorporate higher-order feature representations and allow dependency structures with multiple parents per word. We show that those extensions can make the MST framework computationally intractable, but that the intractability can be circumvented with new approximate parsing algorithms. We conclude with experiments showing that discriminative online learning using those approximate algorithms achieves the best reported parsing accuracy for Czech and Danish."
            },
            "slug": "Online-Learning-of-Approximate-Dependency-Parsing-McDonald-Pereira",
            "title": {
                "fragments": [],
                "text": "Online Learning of Approximate Dependency Parsing Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This paper extends the maximum spanning tree dependency parsing framework to incorporate higher-order feature representations and allow dependency structures with multiple parents per word, and shows that those extensions can make the MST framework computationally intractable, but that the intractability can be circumvented with new approximate parsing algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "EACL"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40400230"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", Li and McCallum (2005))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 97
                            }
                        ],
                        "text": "However, we expect that our approach can function with other clustering algorithms (as in, e.g., Li and McCallum (2005))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6407325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b89926ec5f0046f3a5671d8e68c918ab9cac76fd",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Although there has been significant previous work on semi-supervised learning for classification, there has been relatively little in sequence modeling. This paper presents an approach that leverages recent work in manifold-learning on sequences to discover word clusters from language data, including both syntactic classes and semantic topics. From unlabeled data we form a smooth. low-dimensional feature space, where each word token is projected based on its underlying role as a function or content word. We then use this projection as additional input features to a linear-chain conditional random field trained on limited labeled training data. On standard part-of-speech tagging and Chinese word segmentation data sets we show as much as 14% error reduction due to the unlabeled data, and also statistically-significant improvements over a related semi-supervised sequence tagging method due to Miller et al."
            },
            "slug": "Semi-Supervised-Sequence-Modeling-with-Syntactic-Li-McCallum",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Sequence Modeling with Syntactic Topic Models"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper presents an approach that leverages recent work in manifold-learning on sequences to discover word clusters from language data, including both syntactic classes and semantic topics, with statistically-significant improvements over a related semi-supervised sequence tagging method."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46838106"
                        ],
                        "name": "H. Yamada",
                        "slug": "H.-Yamada",
                        "structuredName": {
                            "firstName": "Hiroyasu",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 173
                            }
                        ],
                        "text": "In addition, in English parsing we ignore the parent-predictions of punctuation tokens,13 and in Czech parsing we retain the punctuation tokens; this matches previous work (Yamada and Matsumoto, 2003; McDonald et al., 2005a; McDonald and Pereira, 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 70
                            }
                        ],
                        "text": "The data partition and head rules were chosen to match previous work (Yamada and Matsumoto, 2003; McDonald et al., 2005a; McDonald and Pereira, 2006)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 129
                            }
                        ],
                        "text": "The English experiments were performed on the Penn Treebank (Marcus et al., 1993), using a standard set of head-selection rules (Yamada and Matsumoto, 2003) to convert the phrase structure syntax of the Treebank to a dependency tree representation.6 We split the Treebank into a training set\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13163488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0e1883cf9d1b3c911125f46359f908557fc5827",
            "isKey": true,
            "numCitedBy": 715,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method for analyzing word-word dependencies using deterministic bottom-up manner using Support Vector machines. We experimented with dependency trees converted from Penn treebank data, and achieved over 90% accuracy of word-word dependency. Though the result is little worse than the most up-to-date phrase structure based parsers, it looks satisfactorily accurate considering that our parser uses no information from phrase structures."
            },
            "slug": "Statistical-Dependency-Analysis-with-Support-Vector-Yamada-Matsumoto",
            "title": {
                "fragments": [],
                "text": "Statistical Dependency Analysis with Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Though the result is little worse than the most up-to-date phrase structure based parsers, it looks satisfactorily accurate considering that the parser uses no information from phrase structures."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123937952"
                        ],
                        "name": "Scott Miller",
                        "slug": "Scott-Miller",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111931"
                        ],
                        "name": "J. Guinness",
                        "slug": "J.-Guinness",
                        "structuredName": {
                            "firstName": "Jethran",
                            "lastName": "Guinness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Guinness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885046"
                        ],
                        "name": "Alex Zamanian",
                        "slug": "Alex-Zamanian",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Zamanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Zamanian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15548439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad269ba941949a1d66b6649a71d752784c576dc3",
            "isKey": false,
            "numCitedBy": 316,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus. Cluster membership is encoded in features that are incorporated in a discriminatively trained tagging model. Active learning is used to select training examples. We evaluate the technique for named-entity tagging. Compared with a state-of-the-art HMM-based name finder, the presented technique requires only 13% as much annotated data to achieve the same level of performance. Given a large annotated training set of 1,000,000 words, the technique achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material."
            },
            "slug": "Name-Tagging-with-Word-Clusters-and-Discriminative-Miller-Guinness",
            "title": {
                "fragments": [],
                "text": "Name Tagging with Word Clusters and Discriminative Training"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus that achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957226"
                        ],
                        "name": "Ryan T. McDonald",
                        "slug": "Ryan-T.-McDonald",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "McDonald",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan T. McDonald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111414"
                        ],
                        "name": "Kiril Ribarov",
                        "slug": "Kiril-Ribarov",
                        "structuredName": {
                            "firstName": "Kiril",
                            "lastName": "Ribarov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kiril Ribarov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002335"
                        ],
                        "name": "Jan Hajic",
                        "slug": "Jan-Hajic",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Hajic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Hajic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6681594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "936d36404165a724f90e4483eee34e65c28feeb1",
            "isKey": false,
            "numCitedBy": 1011,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We formalize weighted dependency parsing as searching for maximum spanning trees (MSTs) in directed graphs. Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n3) time. More surprisingly, the representation is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding an O(n2) parsing algorithm. We evaluate these methods on the Prague Dependency Treebank using online large-margin learning techniques (Crammer et al., 2003; McDonald et al., 2005) and show that MST parsing increases efficiency and accuracy for languages with non-projective dependencies."
            },
            "slug": "Non-Projective-Dependency-Parsing-using-Spanning-McDonald-Pereira",
            "title": {
                "fragments": [],
                "text": "Non-Projective Dependency Parsing using Spanning Tree Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Using this representation, the parsing algorithm of Eisner (1996) is sufficient for searching over all projective trees in O(n3) time and is extended naturally to non-projective parsing using Chu-Liu-Edmonds (Chu and Liu, 1965; Edmonds, 1967) MST algorithm, yielding an O( n2) parsing algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "HLT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32538203"
                        ],
                        "name": "P. Brown",
                        "slug": "P.-Brown",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Brown",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39944066"
                        ],
                        "name": "V. D. Pietra",
                        "slug": "V.-D.-Pietra",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Pietra",
                            "middleNames": [
                                "J.",
                                "Della"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. D. Pietra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144856857"
                        ],
                        "name": "P. D. Souza",
                        "slug": "P.-D.-Souza",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Souza",
                            "middleNames": [
                                "V.",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. D. Souza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3853032"
                        ],
                        "name": "J. Lai",
                        "slug": "J.-Lai",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Lai",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2474650"
                        ],
                        "name": "R. Mercer",
                        "slug": "R.-Mercer",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Mercer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mercer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 148
                            }
                        ],
                        "text": "\u2026the features in a wide range of parsing configurations, including first-order and second-order parsers, and labeled and unlabeled parsers.5\n3As in Brown et al. (1992), we limit the clustering algorithm so that it recovers at most 1,000 distinct bit-strings; thus full bit strings are not\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 95
                            }
                        ],
                        "text": "In order to provide word clusters for our experiments, we used the Brown clustering algorithm (Brown et al., 1992)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10986188,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3de5d40b60742e3dfa86b19e7f660962298492af",
            "isKey": false,
            "numCitedBy": 3318,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of predicting a word from previous words in a sample of text. In particular, we discuss n-gram models based on classes of words. We also discuss several statistical algorithms for assigning words to classes based on the frequency of their co-occurrence with other words. We find that we are able to extract classes that have the flavor of either syntactically based groupings or semantically based groupings, depending on the nature of the underlying statistics."
            },
            "slug": "Class-Based-n-gram-Models-of-Natural-Language-Brown-Pietra",
            "title": {
                "fragments": [],
                "text": "Class-Based n-gram Models of Natural Language"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work addresses the problem of predicting a word from previous words in a sample of text and discusses n-gram models based on classes of words, finding that these models are able to extract classes that have the flavor of either syntactically based groupings or semanticallybased groupings, depending on the nature of the underlying statistics."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145043214"
                        ],
                        "name": "Jason Eisner",
                        "slug": "Jason-Eisner",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Eisner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Eisner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 171
                            }
                        ],
                        "text": "In our final experiments, we tested eight different parsing configurations, representing all possible choices between baseline and cluster-based feature sets, first-order (Eisner, 2000) and second-order (Carreras, 2007) factorizations, and labeled and unlabeled parsing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5897173,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "c356cdc3f3293938a82662c727439be82b97cbc8",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter introduces weighted bilexical grammars, a formalism in which individual lexical items, such as verbs and their arguments, can have idiosyncratic selectional influences on each other. Such \u2018bilexicalism\u2019 has been a theme of much current work in parsing. The new formalism can be used to describe bilexical approaches to both dependency and phrase-structure grammars, and a slight modification yields link grammars. Its scoring approach is compatible with a wide variety of probability models."
            },
            "slug": "Bilexical-Grammars-and-their-Cubic-Time-Parsing-Eisner",
            "title": {
                "fragments": [],
                "text": "Bilexical Grammars and their Cubic-Time Parsing Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This chapter introduces weighted bilexical grammars, a formalism in which individual lexical items, such as verbs and their arguments, can have idiosyncratic selectional influences on each other."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144889265"
                        ],
                        "name": "Ivan Titov",
                        "slug": "Ivan-Titov",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Titov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Titov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144915758"
                        ],
                        "name": "James Henderson",
                        "slug": "James-Henderson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 159
                            }
                        ],
                        "text": "Previous research in this area includes several models which incorporate hidden variables (Matsuzaki et al., 2005; Koo and Collins, 2005; Petrov et al., 2006; Titov and Henderson, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2847717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd9983d42eba7f25f27d437df8c5d8bdb2b778e",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a framework for syntactic parsing with latent variables based on a form of dynamic Sigmoid Belief Networks called Incremental Sigmoid Belief Networks. We demonstrate that a previous feed-forward neural network parsing model can be viewed as a coarse approximation to inference with this class of graphical model. By constructing a more accurate but still tractable approximation, we significantly improve parsing accuracy, suggesting that ISBNs provide a good idealization for parsing. This generative model of parsing achieves state-of-theart results on WSJ text and 8% error reduction over the baseline neural network parser."
            },
            "slug": "Constituent-Parsing-with-Incremental-Sigmoid-Belief-Titov-Henderson",
            "title": {
                "fragments": [],
                "text": "Constituent Parsing with Incremental Sigmoid Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By constructing a more accurate but still tractable approximation, thisGenerative model of parsing achieves state-of-theart results on WSJ text and 8% error reduction over the baseline neural network parser."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10888973,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a7958b418bceb48a315384568091ab1898b1640",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "slug": "Discriminative-Training-Methods-for-Hidden-Markov-Collins",
            "title": {
                "fragments": [],
                "text": "Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results on part-of-speech tagging and base noun phrase chunking are given, in both cases showing improvements over results for a maximum-entropy tagger."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 97
                            }
                        ],
                        "text": "The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 89
                            }
                        ],
                        "text": "The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajic\u030c, 1998; Hajic\u030c et al., 2001), which is directly annotated with dependency structures."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5914287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a574e320d899e7e82e341eb64baef7dfe8a24642",
            "isKey": true,
            "numCitedBy": 1545,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy The model can be classi ed as a Maximum Entropy model and simultaneously uses many contextual features to predict the POS tag Furthermore this paper demonstrates the use of specialized fea tures to model di cult tagging decisions discusses the corpus consistency problems discovered during the implementation of these features and proposes a training strategy that mitigates these problems"
            },
            "slug": "A-Maximum-Entropy-Model-for-Part-Of-Speech-Tagging-Ratnaparkhi",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Model for Part-Of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy and discusses the corpus consistency problems discovered during the implementation of these features."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13411,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693407"
                        ],
                        "name": "K. Crammer",
                        "slug": "K.-Crammer",
                        "structuredName": {
                            "firstName": "Koby",
                            "lastName": "Crammer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Crammer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716876"
                        ],
                        "name": "O. Dekel",
                        "slug": "O.-Dekel",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Dekel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Dekel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771345"
                        ],
                        "name": "Joseph Keshet",
                        "slug": "Joseph-Keshet",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Keshet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Keshet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389955537"
                        ],
                        "name": "S. Shalev-Shwartz",
                        "slug": "S.-Shalev-Shwartz",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Shalev-Shwartz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shalev-Shwartz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 94
                            }
                        ],
                        "text": "First, the MD1 and MD2 parsers were trained via the MIRA algorithm (Crammer and Singer, 2003; Crammer et al., 2004), while we use the averaged perceptron."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5919882,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ca4d4229b8a843c0847fc70531790df6bd017ec",
            "isKey": false,
            "numCitedBy": 1772,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a unified view for online classification, regression, and uni-class problems. This view leads to a single algorithmic framework for the three problems. We prove worst case loss bounds for various algorithms for both the realizable case and the non-realizable case. A conversion of our main online algorithm to the setting of batch learning is also discussed. The end result is new algorithms and accompanying loss bounds for the hinge-loss."
            },
            "slug": "Online-Passive-Aggressive-Algorithms-Crammer-Dekel",
            "title": {
                "fragments": [],
                "text": "Online Passive-Aggressive Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This work presents a unified view for online classification, regression, and uni-class problems, and proves worst case loss bounds for various algorithms for both the realizable case and the non-realizable case."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69414945"
                        ],
                        "name": "M. Sansalone",
                        "slug": "M.-Sansalone",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Sansalone",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sansalone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70421745"
                        ],
                        "name": "N. Carino",
                        "slug": "N.-Carino",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Carino",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Carino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11820188"
                        ],
                        "name": "N. Hsu",
                        "slug": "N.-Hsu",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Hsu",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hsu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 137
                            }
                        ],
                        "text": "Czech dependency structures may contain nonprojective edges, so we employ a maximum directed spanning tree algorithm (Chu and Liu, 1965; Edmonds, 1967; McDonald et al., 2005b) as our firstorder parser for Czech."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9848776,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "1fe4464ae0e8210cec1a5b999dc0b9ae69154bdd",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "[8] Newbold, R. F., Warren, W., Medcalf, A. S. C., and Amos, J., Nature 283, 596 (1980). [91 Eadie, J. S., Conrad, M., Toorchen, D., and Topal, M. D., Nature 308, 201 (1984). [101 Brennand, J., and Fox, M., Carcinogenesis 1, 795 (1980). [11] Dyroff, M. C., Richardson, F. C., Popp, J. A., Bedell, M. A., and Swenberg, J. A., Carcinogenesis 7, 241 (1986). [12] Safhill, R., and Fox, M., Carcinogenesis 1, 487 (1980); Singer, B., Chavez, F., and Spengler, S. J., Biochem. 25, 1201 (1986). [13] Ashworth, D. J., Baird, W. M., Chang, C.-j., Ciupek, J. D., Busch, K. L., and Cooks, R. G., Biomed. Mass Spectrom. 12, 309 (1985). [14] DaSilva Gomes, J., and Chang, C.-j., Anal. Biochem. 129, 387 (1983). [15] Busch, K. L., and Cooks, R. G., Anal. Chem. 55, 38A (1983). [16] McLafferty, F. W., Tandem Mass Spectrometry, Wiley, New York (1983). [17] Lyon, P. A., (ed.), Desorption Mass Spectrometry. Are SIMS and FAB the Same?, American Chemical Society, Washington, DC (1985). [18] Magee, C. W., Int. J. Mass Spectrom. Ion Phys. 49, 211 (1983). [19] Burlingame, A. L., and Castagnoli, N., Jr., (eds.), Mass Spectrometry in the Health and Life Sciences, Elsevier, Amsterdam (1985). [20] Maquestiau, A., and Flammang, R., Tandem Mass Spectrometry, McLafferty, F. W., (ed.), John Wiley & Sons, New York (1983), p. 401. [21] Richter, W. J., Blum, W., Schlunegger, U. A., and Senn, M., Tandem Mass Spectrometry, McLafferty, F. W., (ed.), John Wiley & Sons, New York (1983), p. 417. [22] Baldwin, M. A., and McLafferty, F. W., Org. Mass Spectrom, 7, 1353 (1973). [23] Esmans, F. L., Freyne, E. J., Vanbroeckhoven, J H., and Alderweireldt, F. S., Biomed. Mass. Spec. 7, 377 (1980). [24] MacFarlane, R. D., Anal. Chem. 55, 1247A (1983). [25] Sundqvist, B., Hedin, A., Haakansson, P., Kamensky, I., Selahpour, M., and Saewa, G., Int. J. Mass Spectrom. Ion Proc. 65, 69 (1985). [26] MacFarlane, R. D., Springer Ser. Chem. Phys. 25, 32 (1983). [27] Benninghoven, A., J. Vac. Sci. Technol. 3, 451 (1985). [28] Wickramanayake, P. P., Arbogast, B. L,, Buhler, D. R., Deinzer, M. L., and Burlingame, A. L., J. Am. Chem. Soc. 107, 2485 (1985). [29] Slowikowski, D. L., and Schram, K. H., Nucleosides Nucleotides 4, 309 (1985). [30] Slowikowski, D. L., and Schram, K. H., Nucleosides Nucleotides 4, 347 (1985). [31] Mitchum, R. K., Evans, F. E., Freeman, J. P., and Roach, D., Int. J. Mass Spectrom. Ion Phys. 46, 383 (1983). [32] Hogg, A. M., Kelland, J. G., Vederas, J. C., and Tamm, C., Helv. Chim. Acta 69, 908 (1986). (33] Virelizier, H., Hagemann, K., and Jankowski, K., Biomed. Mass Spectrom. 10, 559 (1983). [34] Chang, C.-j., Ashworth, D. J., Isern-Flecha, I., Jiang, X.Y., and Cooks, R. G., Chem.-Biol. Interactions 57, 295 (1986). [35] O'Lear, J. R., Ph.D. Thesis, Purdue University (1987). Ion Mobility Spectrometry after Chromatography-Accomplishments, Goals, Challenges"
            },
            "slug": "Journal-of-Research-of-the-National-Bureau-of-Sansalone-Carino",
            "title": {
                "fragments": [],
                "text": "Journal of Research of the National Bureau of Standards"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1959
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 220
                            }
                        ],
                        "text": "\u2026were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajic\u030c, 1998; Hajic\u030c et al., 2001), which is directly annotated with dependency structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 483,
                                "start": 457
                            }
                        ],
                        "text": "The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajic\u030c, 1998; Hajic\u030c et al., 2001), which is directly annotated with dependency structures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 203
                            }
                        ],
                        "text": "We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank (Marcus et al., 1993) and Prague Dependency Treebank (Hajic\u030c, 1998; Hajic\u030c et al., 2001) (see Sections 4.1 and 4.3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 39
                            }
                        ],
                        "text": ", 1993) and Prague Dependency Treebank (Haji\u010d, 1998; Haji\u010d et al., 2001) (see Sections 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Prague Dependency Treebank 1.0, LDC No. LDC2001T10"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 483,
                                "start": 457
                            }
                        ],
                        "text": "The part of speech tags for the development and test data were automatically assigned by MXPOST (Ratnaparkhi, 1996), where the tagger was trained on the entire training corpus; to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajic\u030c, 1998; Hajic\u030c et al., 2001), which is directly annotated with dependency structures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 162
                            }
                        ],
                        "text": "We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank (Marcus et al., 1993) and Prague Dependency Treebank (Hajic\u030c, 1998; Hajic\u030c et al., 2001) (see Sections 4.1 and 4.3)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 39
                            }
                        ],
                        "text": ", 1993) and Prague Dependency Treebank (Haji\u010d, 1998; Haji\u010d et al., 2001) (see Sections 4."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building a Syntactically Annotated Corpus: The Prague Dependency Treebank"
            },
            "venue": {
                "fragments": [],
                "text": "E. Haji\u010dov\u00e1, editor, Issues of Valency and Meaning. Studies in Honor of Jarmila Panevov\u00e1, pages 12\u201319."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 40
                            }
                        ],
                        "text": "For example, the parser of McDonald and Pereira (2006) defines parts for sibling interactions, such as the trio \u201cplays\u201d, \u201cElianti\u201d, and \u201c.\u201d in Figure 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 133
                            }
                        ],
                        "text": "Table 2 compiles our final test results and also includes two results from previous work by McDonald et al. (2005a) and McDonald and Pereira (2006), for the purposes of comparison."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 83
                            }
                        ],
                        "text": "To facilitate comparisons with previous work (McDonald et al., 2005b; McDonald and Pereira, 2006), we used the training/development/test partition defined in the corpus and we also used the automatically-assigned part of speech tags provided in the corpus.10 Czech word clusters were derived from\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 31
                            }
                        ],
                        "text": "To overcome this, McDonald and Pereira (2006) use a\n15We leave labeled parsing experiments to future work.\ntwo-stage approximate decoding process in which the output of their second-order parser is \u201cdeprojectivized\u201d via greedy search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 238
                            }
                        ],
                        "text": "In addition, in English parsing we ignore the parent-predictions of punctuation tokens,13 and in Czech parsing we retain the punctuation tokens; this matches previous work (Yamada and Matsumoto, 2003; McDonald et al., 2005a; McDonald and Pereira, 2006)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 260
                            }
                        ],
                        "text": "\u2026and structure domains Y(\u00b7), it is possible to solve the above maximization efficiently, and several recent efforts have concentrated on designing new maximization algorithms with increased contextsensitivity (Eisner, 2000; McDonald et al., 2005b; McDonald and Pereira, 2006; Carreras, 2007)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 192
                            }
                        ],
                        "text": "10Following Collins et al. (1999), we used a coarsened version of the Czech part of speech tags; this choice also matches the conditions of previous work (McDonald et al., 2005b; McDonald and Pereira, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 135
                            }
                        ],
                        "text": "The data partition and head rules were chosen to match previous work (Yamada and Matsumoto, 2003; McDonald et al., 2005a; McDonald and Pereira, 2006)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "fective Self - Training for Parsing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 220
                            }
                        ],
                        "text": "\u2026were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague Dependency Treebank 1.0 (Hajic\u030c, 1998; Hajic\u030c et al., 2001), which is directly annotated with dependency structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 203
                            }
                        ],
                        "text": "We show that our semi-supervised approach yields improvements for fixed datasets by performing parsing experiments on the Penn Treebank (Marcus et al., 1993) and Prague Dependency Treebank (Hajic\u030c, 1998; Hajic\u030c et al., 2001) (see Sections 4.1 and 4.3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Prague Dependency Treebank 1"
            },
            "venue": {
                "fragments": [],
                "text": "LDC No. LDC2001T10. Linguistics Data Consortium"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090910179"
                        ],
                        "name": "Treebank Penn",
                        "slug": "Treebank-Penn",
                        "structuredName": {
                            "firstName": "Treebank",
                            "lastName": "Penn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Treebank Penn"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 67371551,
            "fieldsOfStudy": [
                "Linguistics"
            ],
            "id": "3fa4a8191e37b601877716858e6b1026e66e3c5c",
            "isKey": false,
            "numCitedBy": 1127,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Linguistic-Data-Consortium-Penn",
            "title": {
                "fragments": [],
                "text": "Linguistic Data Consortium"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "-order 85.2 Nivre and Nilsson (2005) 80.1 Hall and Nov\u00e1k"
            },
            "venue": {
                "fragments": [],
                "text": "-order 85.2 Nivre and Nilsson (2005) 80.1 Hall and Nov\u00e1k"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shared Task on Dependency Parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of EMNLP-CoNLL"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "We chose to work with the Brown algorithm due to its simplicity and prior success in other NLP applications (Miller et al., 2004; Liang, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 54
                            }
                        ],
                        "text": "For all of the experiments in this paper, we used the Liang (2005) implementation of the Brown algorithm to obtain the necessary word clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 142
                            }
                        ],
                        "text": "We used a modified version of the Brown algorithm which restricts the search space by placing a maximum 2 on the number of available clusters (Liang, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-supervised learning for natural"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 130
                            }
                        ],
                        "text": "We chose to work with the Brown algorithm due to its simplicity and prior success in other NLP applications (Miller et al., 2004; Liang, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 54
                            }
                        ],
                        "text": "For all of the experiments in this paper, we used the Liang (2005) implementation of the Brown algorithm to obtain the necessary word clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-Supervised Learning for Natural Language. Master's thesis"
            },
            "venue": {
                "fragments": [],
                "text": "Semi-Supervised Learning for Natural Language. Master's thesis"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 74
                            }
                        ],
                        "text": "projective edges, so we employ a maximum directed spanning tree algorithm (Chu and Liu, 1965; Edmonds, 1967; McDonald et al., 2005b) as our firstorder parser for Czech."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On the shortest arborescence of a directed graph"
            },
            "venue": {
                "fragments": [],
                "text": "Science Sinica, 14:1396\u2013 1400."
            },
            "year": 1965
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "\u2026to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 59
                            }
                        ],
                        "text": "8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "BLLIP 1987\u201389 WSJ Corpus Release 1, LDC No"
            },
            "venue": {
                "fragments": [],
                "text": "LDC2000T43. Linguistic Data Consortium."
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Effect of Training Corpus Size @BULLET Used machine-assigned POS tags given in the corpus Training Sentences Baseline Cluster-based"
            },
            "venue": {
                "fragments": [],
                "text": "Effect of Training Corpus Size @BULLET Used machine-assigned POS tags given in the corpus Training Sentences Baseline Cluster-based"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Xavier Carreras was supported by the Catalan Ministry of Innovation, Universities and Enterprise, and a grant from NTT"
            },
            "venue": {
                "fragments": [],
                "text": "Agmt. Dtd"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 74
                            }
                        ],
                        "text": "projective edges, so we employ a maximum directed spanning tree algorithm (Chu and Liu, 1965; Edmonds, 1967; McDonald et al., 2005b) as our firstorder parser for Czech."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimum branchings"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Research of the National Bureau of Standards, 71B:233\u2013 240."
            },
            "year": 1967
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 143
                            }
                        ],
                        "text": "\u2026to generate part of speech tags for the training data, we used 10-way jackknifing.8 English word clusters were derived from the BLLIP corpus (Charniak et al., 2000), which contains roughly 43 million words of Wall Street Journal text.9\nThe Czech experiments were performed on the Prague\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "BLLIP 1987\u201389 WSJ Corpus Release 1, LDC No. LDC2000T43. Linguistic Data Consortium"
            },
            "venue": {
                "fragments": [],
                "text": "BLLIP 1987\u201389 WSJ Corpus Release 1, LDC No. LDC2000T43. Linguistic Data Consortium"
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 24,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 43,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Simple-Semi-supervised-Dependency-Parsing-Koo-Carreras/790ecefeaf2b471b439743a772ccce026131bef5?sort=total-citations"
}