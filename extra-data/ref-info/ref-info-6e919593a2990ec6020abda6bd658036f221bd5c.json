{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4723637"
                        ],
                        "name": "J. Mao",
                        "slug": "J.-Mao",
                        "structuredName": {
                            "firstName": "Jianchang",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7460228"
                        ],
                        "name": "M. Abayan",
                        "slug": "M.-Abayan",
                        "structuredName": {
                            "firstName": "Marlon",
                            "lastName": "Abayan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Abayan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143677016"
                        ],
                        "name": "K. Mohiuddin",
                        "slug": "K.-Mohiuddin",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Mohiuddin",
                            "middleNames": [
                                "Moidin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mohiuddin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5225709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5f63d35563636d5540b344a715e5364da8e7df0",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a model-based form processing sub-system, which consists of a form model database and five modules: (i) form modeling, (ii) form recognition, (iii) form dropout, (iv) form definition tool, and (v) form reconstruction. The form modeling module builds explicit representations of scanned form templates to facilitate form recognition and dropout. It can also assist a user to define various fields on a form. The automatic form recognition eliminates the need for manually sorting input forms. The form dropout module effectively removes pre-printed form content to achieve a high data compression rate and to provide clean data for OCR. Our model-driven form dropout scheme has two major advantages over image-based subtraction methods in both dropout efficiency and quality preservation of filled-in data."
            },
            "slug": "A-model-based-form-processing-sub-system-Mao-Abayan",
            "title": {
                "fragments": [],
                "text": "A model-based form processing sub-system"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A model-driven form dropout scheme has two major advantages over image-based subtraction methods in both dropout efficiency and quality preservation of filled-in data."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098101"
                        ],
                        "name": "S. Shimotsuji",
                        "slug": "S.-Shimotsuji",
                        "structuredName": {
                            "firstName": "Shigeyoshi",
                            "lastName": "Shimotsuji",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Shimotsuji"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40162920"
                        ],
                        "name": "M. Asano",
                        "slug": "M.-Asano",
                        "structuredName": {
                            "firstName": "Mieko",
                            "lastName": "Asano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Asano"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5585402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd30d2052973e3212cb66acbf7fa2d154c39ca15",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new form document identification technique that uses the structure of cells in a form. The proposed method represents the cell structure by the location of the center points of each cell. This representation allows the form identification to be realized by a process of matching the points in an input image to the points in registered forms. We have implemented the point matching process using the two-dimensional hash table. This implementation enables the system to robustly identify an input form even if it is skewed or deformed by a scanning process, and to reduce the time for the identification. Moreover, the similarity between two forms defined by the implementation can be used to evaluate the identification ability when a set of registered forms is specified. Experimental results show the robustness and effectiveness of the proposed technique."
            },
            "slug": "Form-identification-based-on-cell-structure-Shimotsuji-Asano",
            "title": {
                "fragments": [],
                "text": "Form identification based on cell structure"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A new form document identification technique that uses the structure of cells in a form by the location of the center points of each cell, which enables the system to robustly identify an input form even if it is skewed or deformed by a scanning process, and to reduce the time for the identification."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074293587"
                        ],
                        "name": "Q. Luo",
                        "slug": "Q.-Luo",
                        "structuredName": {
                            "firstName": "Qin",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692608"
                        ],
                        "name": "N. Sugie",
                        "slug": "N.-Sugie",
                        "structuredName": {
                            "firstName": "Noboru",
                            "lastName": "Sugie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sugie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23198522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa208b677239912cb394e5dbc6e7483a75f16ea4",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Many approaches have reported that knowledge-based layout recognition methods are very successful in classifying the meaningful data from document images automatically. However, these approaches are applicable to only the same kind of documents because they are based on the paradigm that specifies the structure definition information in advance so as to be able to analyze a particular class of documents intelligently. In this paper, the authors propose a method to recognize the layout structures of multi-kinds of table-form document images. For this purpose, the authors introduce a classification tree to manage the relationships among different classes of layout structures. The authors' recognition system has two modes: layout knowledge acquisition and layout structure recognition. In the layout knowledge acquisition mode, table-form document images are distinguished according to this. Classification tree and then the structure description trees which specify the logical structures of table-form documents are generated automatically. While, in the layout structure recognition mode, individual item fields in the table-form document images are extracted and classified successfully by searching the classification tree and interpreting the structure description tree. >"
            },
            "slug": "Layout-Recognition-of-Multi-Kinds-of-Table-Form-Watanabe-Luo",
            "title": {
                "fragments": [],
                "text": "Layout Recognition of Multi-Kinds of Table-Form Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The authors introduce a classification tree to manage the relationships among different classes of layout structures and propose a method to recognize the layout structures of multi-kinds of table-form document images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2725849"
                        ],
                        "name": "T. Sobue",
                        "slug": "T.-Sobue",
                        "structuredName": {
                            "firstName": "Tsuneo",
                            "lastName": "Sobue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sobue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1500661115"
                        ],
                        "name": "Toyohide Watanabe",
                        "slug": "Toyohide-Watanabe",
                        "structuredName": {
                            "firstName": "Toyohide",
                            "lastName": "Watanabe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toyohide Watanabe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1956745,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79de5eef79f1df8ecacdaac69f01609b232dc302",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Many methods to recognize the layout structures of table-form documents have been proposed until today. Most of them interpret table-form document images using the knowledge which is adaptable to the specification of layout structures of individual table-form documents. H.Naruse et al. proposed a successful method, based on neighboring/connective relationships among item fields in table-form documents, to recognize the layout structures of tableform document images. Our method is an advanced version of their method. In comparison with their method, our method further recognizes the layout structures of table-form document images whose item fields are not surrounded with real line segments. The main idea in our approach is to transform the original table-form document images so as to be adaptable to their method."
            },
            "slug": "Identification-of-Item-Fields-in-Table-form-Line-Sobue-Watanabe",
            "title": {
                "fragments": [],
                "text": "Identification of Item Fields in Table-form Documents with/without Line Segments"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The main idea in the approach is to transform the original table-form document images so as to be adaptable to the proposed method, based on neighboring/connective relationships among item fields in table- form documents."
            },
            "venue": {
                "fragments": [],
                "text": "MVA"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1826457"
                        ],
                        "name": "P. H\u00e9roux",
                        "slug": "P.-H\u00e9roux",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "H\u00e9roux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H\u00e9roux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15177643"
                        ],
                        "name": "S. Diana",
                        "slug": "S.-Diana",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Diana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Diana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2510130"
                        ],
                        "name": "Arnaud Ribert",
                        "slug": "Arnaud-Ribert",
                        "structuredName": {
                            "firstName": "Arnaud",
                            "lastName": "Ribert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arnaud Ribert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35863204"
                        ],
                        "name": "\u00c9. Trupin",
                        "slug": "\u00c9.-Trupin",
                        "structuredName": {
                            "firstName": "\u00c9ric",
                            "lastName": "Trupin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c9. Trupin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17264036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2ab8f9a8ec4b6e243a88260296811c306636809",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We present three classifiers used in automatic forms class identification. The first category of classifier includes the k-nearest neighbours (kNN) and the multilayer perceptron (MLP) classifiers. The second category corresponds to a new structural classifier based on tree comparison. The low level information based on a pyramidal decomposition of the document image is used by the kNN and the MLP classifiers, while the high level information represents the form content with a hierarchical structure used by the new structural classifier. Experimental results are presented. Some strategies of classifier co-operation are proposed."
            },
            "slug": "Classification-method-study-for-automatic-form-H\u00e9roux-Diana",
            "title": {
                "fragments": [],
                "text": "Classification method study for automatic form class identification"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "Two new structural classifiers based on tree comparison and the k-nearest neighbours and the multilayer perceptron classifiers are presented, which represent the form content with a hierarchical structure in automatic forms class identification."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. Fourteenth International Conference on Pattern Recognition (Cat. No.98EX170)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48572350"
                        ],
                        "name": "S. Lam",
                        "slug": "S.-Lam",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Lam",
                            "middleNames": [
                                "Wang-Cheung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398880839"
                        ],
                        "name": "L. Javanbakht",
                        "slug": "L.-Javanbakht",
                        "structuredName": {
                            "firstName": "Ladan",
                            "lastName": "Javanbakht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Javanbakht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206774379,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1462c98095382d867cb9d026988ed6e3455f9617",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Forms are used extensively in today's offices. The task of an automated form reader is to locate data filled on a form and to encode the content into appropriate symbolic descriptions. The challenges in form reading are due to high volume and large variety. A robust form reader with high adaptability and trainability. The form reader consists of two modules: field registration and data recognition module. The field registration module acquires knowledge about the forms of interest and the data recognition module recognizes text data on filled forms using the acquired knowledge. The capability of the reader increases progressively through supervised learning. The form reader has been training to read a large variety of forms with machine-printed data. The adaptability and trainability of the system have been demonstrated through the experiments.<<ETX>>"
            },
            "slug": "Anatomy-of-a-form-reader-Lam-Javanbakht",
            "title": {
                "fragments": [],
                "text": "Anatomy of a form reader"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A robust form reader with high adaptability and trainability, training to read a large variety of forms with machine-printed data is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2nd International Conference on Document Analysis and Recognition (ICDAR '93)"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108323668"
                        ],
                        "name": "Jiun-Lin Chen",
                        "slug": "Jiun-Lin-Chen",
                        "structuredName": {
                            "firstName": "Jiun-Lin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiun-Lin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721539"
                        ],
                        "name": "Hsi-Jian Lee",
                        "slug": "Hsi-Jian-Lee",
                        "structuredName": {
                            "firstName": "Hsi-Jian",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsi-Jian Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28669035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc321e47c75998b23f89b207918294a03b7c937f",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A form processing system aims to extract meaningful data from a form document for office automation. To locate the data, we have to extract and understand the form structure. In this paper, a strip projection method is presented for extracting form structure. We first segment the input form image uniformly into vertical and horizontal strips. Since most lines in a form are vertical and horizontal lines, we project the image in each vertical strip horizontally and in each horizontal strip vertically. The peak positions in the projection profiles denote the possible existence of lines in the form image. Next we trace the lines started from the possible line positions in the source image. After all lines are extracted, redundant lines are removed by a line verification algorithm and broken lines are linked by a line merging algorithm. This proposed method can reduce much computation time than other methods such as Hough transformation and line detection and approximation algorithm. Experimental results demonstrate that the proposed method is very effective."
            },
            "slug": "A-novel-form-structure-extraction-method-using-Chen-Lee",
            "title": {
                "fragments": [],
                "text": "A novel form structure extraction method using strip projection"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A strip projection method is presented for extracting form structure that can reduce much computation time than other methods such as Hough transformation and line detection and approximation algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73282614"
                        ],
                        "name": "Y. Hirayama",
                        "slug": "Y.-Hirayama",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Hirayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hirayama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 206774876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dcf75b367f24919a8a4b0f627960f6d6bf5ae33f",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel method for table structure analysis. Many documents have table areas, and some have both table and figure areas. It is very important to be able to classify table and figure areas automatically. Furthermore, in tables, the column and row in which a character string is located are very important pieces of information. To detect and analyze table areas, the following method is applied: First, areas that may contain tables or figures are distinguished from text areas by the presence of horizontal and vertical lines. Next, the areas are assumed to be table areas and are analyzed as such. A judgment is made on whether each of the areas can in fact be a table area or not; in this way, the actual table areas are detected. Finally, the structures of the areas are analyzed and character strings in the areas are arranged by using the DP matching method. This method was applied to sixty-five pages of Japanese technical papers, magazines, manuals for software programs, and pages including 34 table areas, 48 line drawing areas, and 35 image areas. As a result, 96.6 percent of the areas were detected correctly and 91.7 percent of the tables were analyzed and arranged correctly."
            },
            "slug": "A-method-for-table-structure-analysis-using-DP-Hirayama",
            "title": {
                "fragments": [],
                "text": "A method for table structure analysis using DP matching"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This paper presents a novel method for table structure analysis that was applied to sixty-five pages of Japanese technical papers, magazines, manuals for software programs, and pages including 34 table areas, 48 line drawing areas, and 35 image areas."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 3rd International Conference on Document Analysis and Recognition"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73282614"
                        ],
                        "name": "Y. Hirayama",
                        "slug": "Y.-Hirayama",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Hirayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hirayama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11346240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37ff8723fc271c1e16096b8f62542cd30dfb9d7",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We deal with formats whose fields do not have rigidly determined positions and sizes but have topological relations between them. Such formats are called the \"topological formats\". The objective of our research is to establish a method for defining a topological format and detecting fields in images by using that format. The method has the following characteristics: 1) a line-shared-adjacent (LSA) cell relation and a LSA format are proposed, and a topological format can be defined with the LSA format; 2) concepts of hierarchical class can be applied to the format, where a format unification operator is defined to create the hierarchy and can be used to generate a superclass format, and it also allows users to generate formats from scanned images; and 3) an LSA format can be converted into an equivalent line-oriented format that can be used for processing actual forms. Since the format consists of line connection information, the method is robust with respect to flaws of line segments extracted from the images. The method was applied to images of sample forms that have various flaws, and satisfying results were obtained."
            },
            "slug": "Analyzing-form-images-by-using-line-shared-adjacent-Hirayama",
            "title": {
                "fragments": [],
                "text": "Analyzing form images by using line-shared-adjacent cell relations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The objective of this research is to establish a method for defining a topological format and detecting fields in images by using that format and satisfying results were obtained."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 13th International Conference on Pattern Recognition"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sookmyung Woman's University, email: ywchoi ~c(:. .~ookmymlg.ac.kr)"
            },
            "venue": {
                "fragments": [],
                "text": "Sookmyung Woman's University, email: ywchoi ~c(:. .~ookmymlg.ac.kr)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Layout R.ecognition of Multi-Kinds of Table-form DocumentsA Model-B~L~ed Form Processing Sub-System"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Analysis and Machine Intelligence"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "By using this approach, the recognition of an input form and the extraction of field items can be pro- \ntessed at a high recognition rate in a reasonable time span. in terms of al)plicability, the experimental \nrecognition rate and processing time seem to be encouraging."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient Form Processing Methods for Various Kinds of Form Do(mments"
            },
            "venue": {
                "fragments": [],
                "text": "Efficient Form Processing Methods for Various Kinds of Form Do(mments"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient Form Processing Methods for Various Kinds of Form Do(mments"
            },
            "venue": {
                "fragments": [],
                "text": "DAS, pp.153-156, 1998. 4"
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 13,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Form-classification-using-DP-matching-Byun-Lee/6e919593a2990ec6020abda6bd658036f221bd5c?sort=total-citations"
}