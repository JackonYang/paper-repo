{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 131767086,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b80caf0492cbbe00310c1f4867aa8512b6f73320",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We adapt the dynamic-oracle training method of Goldberg and Nivre (2012; 2013) to train classifiers that produce probabilistic output. Evaluation of an Arc-Eager parser on 6 languages shows that the AdaGrad-RDA based training procedure results in models that provide the same high level of accuracy as the averagedperceptron trained models, while being sparser and providing well-calibrated probabilistic output."
            },
            "slug": "Dynamic-oracle-Transition-based-Parsing-with-Output-Goldberg",
            "title": {
                "fragments": [],
                "text": "Dynamic-oracle Transition-based Parsing with Calibrated Probabilistic Output"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Evaluation of an Arc-Eager parser on 6 languages shows that the AdaGrad-RDA based training procedure results in models that provide the same high level of accuracy as the averagedperceptron trained models, while being sparser and providing well-calibrated probabilistic output."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1195002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4bd0035fe14832626279e6c3c72b73c21c7f5d8",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "The standard training regime for transition-based dependency parsers makes use of an oracle, which predicts an optimal transition sequence for a sentence and its gold tree. We present an improved oracle for the arc-eager transition system, which provides a set of optimal transitions for every valid parser configuration, including configurations from which the gold tree is not reachable. In such cases, the oracle provides transitions that will lead to the best reachable tree from the given configuration. The oracle is efficient to implement and provably correct. We use the oracle to train a deterministic left-to-right dependency parser that is less sensitive to error propagation, using an online training procedure that also explores parser configurations resulting from non-optimal sequences of transitions. This new parser outperforms greedy parsers trained using conventional oracles on a range of data sets, with an average improvement of over 1.2 LAS points and up to almost 3 LAS points on some data sets."
            },
            "slug": "A-Dynamic-Oracle-for-Arc-Eager-Dependency-Parsing-Goldberg-Nivre",
            "title": {
                "fragments": [],
                "text": "A Dynamic Oracle for Arc-Eager Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work uses an improved oracle for the arc-eager transition system to train a deterministic left-to-right dependency parser that is less sensitive to error propagation and outperforms greedy parsers trained using conventional oracles on a range of data sets."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40348417"
                        ],
                        "name": "Ashish Vaswani",
                        "slug": "Ashish-Vaswani",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Vaswani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Vaswani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757166"
                        ],
                        "name": "Kenji Sagae",
                        "slug": "Kenji-Sagae",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Sagae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenji Sagae"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8298000,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2eeb74085c00449ea08fc0f68fa151d181e893e0",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Transition-based approaches based on local classification are attractive for dependency parsing due to their simplicity and speed, despite producing results slightly below the state-of-the-art. In this paper, we propose a new approach for approximate structured inference for transition-based parsing that produces scores suitable for global scoring using local models. This is accomplished with the introduction of error states in local training, which add information about incorrect derivation paths typically left out completely in locally-trained models. Using neural networks for our local classifiers, our approach achieves 93.61% accuracy for transition-based dependency parsing in English."
            },
            "slug": "Efficient-Structured-Inference-for-Transition-Based-Vaswani-Sagae",
            "title": {
                "fragments": [],
                "text": "Efficient Structured Inference for Transition-Based Parsing with Neural Networks and Error States"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a new approach for approximate structured inference for transition-based parsing that produces scores suitable for global scoring using local models with the introduction of error states in local training."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69910001"
                        ],
                        "name": "Majid Yazdani",
                        "slug": "Majid-Yazdani",
                        "structuredName": {
                            "firstName": "Majid",
                            "lastName": "Yazdani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Majid Yazdani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144915758"
                        ],
                        "name": "James Henderson",
                        "slug": "James-Henderson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Henderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 59
                            }
                        ],
                        "text": "In order to be able to compare with similar greedy parsers (Yazdani and Henderson, 2015; Andor et al., 2016)5 we report the performance of the parser on the multilingual treebanks of the CoNLL 2009"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 67
                            }
                        ],
                        "text": "probability of making a mistake has also been explored for parsing (Yazdani and Henderson, 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16667486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b0c87c3368f270137f5eec7fe1a52c6d98123ef",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a discriminatively trained recurrent neural network (RNN) that predicts the actions for a fast and accurate shift-reduce dependency parser. The RNN uses its output-dependent model structure to compute hidden vectors that encode the preceding partial parse, and uses them to estimate probabilities of parser actions. Unlike a similar previous generative model (Henderson and Titov, 2010), the RNN is trained discriminatively to optimize a fast beam search. This beam search prunes after each shift action, so we add a correctness probability to each shift action and train this score to discriminate between correct and incorrect sequences of parser actions. We also speed up parsing time by caching computations for frequent feature combinations, including during training, giving us both faster training and a form of backoff smoothing. The resulting parser is over 35 times faster than its generative counterpart with nearly the same accuracy, producing state-of-art dependency parsing results while requiring minimal feature engineering."
            },
            "slug": "Incremental-Recurrent-Neural-Network-Dependency-Yazdani-Henderson",
            "title": {
                "fragments": [],
                "text": "Incremental Recurrent Neural Network Dependency Parser with Search-based Discriminative Training"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "A discriminatively trained recurrent neural network that predicts the actions for a fast and accurate shift-reduce dependency parser that speed up parsing time by caching computations for frequent feature combinations, including during training, giving us both faster training and a form of backoff smoothing."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50536468"
                        ],
                        "name": "Danqi Chen",
                        "slug": "Danqi-Chen",
                        "structuredName": {
                            "firstName": "Danqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11616343,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a14045a751f5d8ed387c8630a86a3a2861b90643",
            "isKey": false,
            "numCitedBy": 1640,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Almost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly. In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser. Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets. Concretely, our parser is able to parse more than 1000 sentences per second at 92.2% unlabeled attachment score on the English Penn Treebank."
            },
            "slug": "A-Fast-and-Accurate-Dependency-Parser-using-Neural-Chen-Manning",
            "title": {
                "fragments": [],
                "text": "A Fast and Accurate Dependency Parser using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser that can work very fast, while achieving an about 2% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 78
                            }
                        ],
                        "text": "(2015) to support a training-with-exploration procedure using dynamic oracles (Goldberg and Nivre, 2013) instead of assuming an error-free action history."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 815755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f90fc459c305f13b3fab0abf42b8dd1801c59511",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Greedy transition-based parsers are very fast but tend to suffer from error propagation. This problem is aggravated by the fact that they are normally trained using oracles that are deterministic and incomplete in the sense that they assume a unique canonical path through the transition system and are only valid as long as the parser does not stray from this path. In this paper, we give a general characterization of oracles that are nondeterministic and complete, present a method for deriving such oracles for transition systems that satisfy a property we call arc decomposition, and instantiate this method for three well-known transition systems from the literature. We say that these oracles are dynamic, because they allow us to dynamically explore alternative and nonoptimal paths during training \u2014 in contrast to oracles that statically assume a unique optimal path. Experimental evaluation on a wide range of data sets clearly shows that using dynamic oracles to train greedy parsers gives substantial improvements in accuracy. Moreover, this improvement comes at no cost in terms of efficiency, unlike other techniques like beam search."
            },
            "slug": "Training-Deterministic-Parsers-with-Oracles-Goldberg-Nivre",
            "title": {
                "fragments": [],
                "text": "Training Deterministic Parsers with Non-Deterministic Oracles"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "Experimental evaluation on a wide range of data sets clearly shows that using dynamic oracles to train greedy parsers gives substantial improvements in accuracy, unlike other techniques like beam search."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3295092"
                        ],
                        "name": "S. Chopra",
                        "slug": "S.-Chopra",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Chopra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chopra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2325985"
                        ],
                        "name": "Michael Auli",
                        "slug": "Michael-Auli",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Auli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Auli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 55
                            }
                        ],
                        "text": ", 2015), and reinforcement learning have been proposed (Ranzato et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 153
                            }
                        ],
                        "text": "Solutions based on curriculum learning (Bengio et al., 2015), expected loss training (Shen et al., 2015), and reinforcement learning have been proposed (Ranzato et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7147309,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35c1668dc64d24a28c6041978e5fcca754eb2f4b",
            "isKey": false,
            "numCitedBy": 1223,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster."
            },
            "slug": "Sequence-Level-Training-with-Recurrent-Neural-Ranzato-Chopra",
            "title": {
                "fragments": [],
                "text": "Sequence Level Training with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE, and outperforms several strong baselines for greedy generation."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450508"
                        ],
                        "name": "Carlos G\u00f3mez-Rodr\u00edguez",
                        "slug": "Carlos-G\u00f3mez-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "G\u00f3mez-Rodr\u00edguez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos G\u00f3mez-Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083856746"
                        ],
                        "name": "Francesco Sartorio",
                        "slug": "Francesco-Sartorio",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Sartorio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Sartorio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152299194"
                        ],
                        "name": "G. Satta",
                        "slug": "G.-Satta",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Satta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Satta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 146
                            }
                        ],
                        "text": "\u2026in different ways (Goldberg and Nivre, 2012; Goldberg and Nivre, 2013; Goldberg et al., 2014; Honnibal et al., 2013; Honnibal and Johnson, 2014; Go\u0301mez-Rodr\u0131\u0301guez et al., 2014;\n5We report the performance of these parsers in the most comparable setup, that is, with beam size 1 or greedy search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13156058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d774808ac953da42d30f0b1923df2db989db970",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The introduction of dynamic oracles has considerably improved the accuracy of greedy transition-based dependency parsers, without sacrificing parsing efficiency. However, this enhancement is limited to projective parsing, and dynamic oracles have not yet been implemented for parsers supporting non-projectivity. In this paper we introduce the first such oracle, for a non-projective parser based on Attardi\u2019s parser. We show that training with this oracle improves parsing accuracy over a conventional (static) oracle on a wide range of datasets."
            },
            "slug": "A-Polynomial-Time-Dynamic-Oracle-for-Non-Projective-G\u00f3mez-Rodr\u00edguez-Sartorio",
            "title": {
                "fragments": [],
                "text": "A Polynomial-Time Dynamic Oracle for Non-Projective Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper introduces the first dynamic oracle for a non-projective parser based on Attardi\u2019s parser, and shows that training with this oracle improves parsing accuracy over a conventional (static) oracle on a wide range of datasets."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3182726"
                        ],
                        "name": "Matthew Honnibal",
                        "slug": "Matthew-Honnibal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Honnibal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Honnibal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177145"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "\u2026oracles, has been explored by several researchers in different ways (Goldberg and Nivre, 2012; Goldberg and Nivre, 2013; Goldberg et al., 2014; Honnibal et al., 2013; Honnibal and Johnson, 2014; Go\u0301mez-Rodr\u0131\u0301guez et al., 2014;\n5We report the performance of these parsers in the most comparable\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10403498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d32c62d9709a10fc75096246971edc36a5855b53",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous incremental parsers have used monotonic state transitions. However, transitions can be made to revise previous decisions quite naturally, based on further information. We show that a simple adjustment to the Arc-Eager transition system to relax its monotonicity constraints can improve accuracy, so long as the training data includes examples of mistakes for the nonmonotonic transitions to repair. We evaluate the change in the context of a stateof-the-art system, and obtain a statistically significant improvement (p < 0.001) on the English evaluation and 5/10 of the CoNLL languages."
            },
            "slug": "A-Non-Monotonic-Arc-Eager-Transition-System-for-Honnibal-Goldberg",
            "title": {
                "fragments": [],
                "text": "A Non-Monotonic Arc-Eager Transition System for Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that a simple adjustment to the Arc-Eager transition system to relax its monotonicity constraints can improve accuracy, so long as the training data includes examples of mistakes for the nonmonotonic transitions to repair."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3289329"
                        ],
                        "name": "S. Riezler",
                        "slug": "S.-Riezler",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Riezler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Riezler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2694275"
                        ],
                        "name": "D. Prescher",
                        "slug": "D.-Prescher",
                        "structuredName": {
                            "firstName": "Detlef",
                            "lastName": "Prescher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prescher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716963"
                        ],
                        "name": "Jonas Kuhn",
                        "slug": "Jonas-Kuhn",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Kuhn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonas Kuhn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152465203"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 33
                            }
                        ],
                        "text": "3A similar objective was used by Riezler et al (2000), Charniak and Johnson (2005) and Goldberg (2013) in the context of log-linear probabilistic models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63346,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e06e39c0750dab5971f1bdfb132d55b39c715515",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new approach to stochastic modeling of constraint-based grammars that is based on loglinear models and uses EM for estimation from unannotated data. The techniques are applied to an LFG grammar for German. Evaluation on an exact match task yields 86% precision for an ambiguity rate of 5.4, and 90% precision on a subcat frame match for an ambiguity rate of 25. Experimental comparison to training from a parsebank shows a 10% gain from EM training. Also, a new class-based grammar lexicalization is presented, showing a 10% gain over unlexicalized models."
            },
            "slug": "Lexicalized-Stochastic-Modeling-of-Constraint-Based-Riezler-Prescher",
            "title": {
                "fragments": [],
                "text": "Lexicalized Stochastic Modeling of Constraint-Based Grammars using Log-Linear Measures and EM Training"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A new approach to stochastic modeling of constraint-based grammars that is based on loglinear models and uses EM for estimation from unannotated data and a new class-based grammar lexicalization is presented, showing a 10% gain over unlexicalized models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083856746"
                        ],
                        "name": "Francesco Sartorio",
                        "slug": "Francesco-Sartorio",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Sartorio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Sartorio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152299194"
                        ],
                        "name": "G. Satta",
                        "slug": "G.-Satta",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Satta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Satta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 77
                            }
                        ],
                        "text": "While it is possible to compute dynamic oracles for the arc-standard system (Goldberg et al., 2014), the computation relies on a dynamic programming algorithm which is polynomial in the length of the stack."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "\u2026facilitated by dynamic oracles, has been explored by several researchers in different ways (Goldberg and Nivre, 2012; Goldberg and Nivre, 2013; Goldberg et al., 2014; Honnibal et al., 2013; Honnibal and Johnson, 2014; Go\u0301mez-Rodr\u0131\u0301guez et al., 2014;\n5We report the performance of these parsers\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 76
                            }
                        ],
                        "text": "While it is possible to compute dynamic oracles for the arc-standard system (Goldberg et al., 2014), the computation relies on a dynamic programming algorithm which is polyno-"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2512012,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09d5446fd2cb488e9cf0663dcd9f41ca4869e292",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop parsing oracles for two transition-based dependency parsers, including the arc-standard parser, solving a problem that was left open in (Goldberg and Nivre, 2013). We experimentally show that using these oracles during training yields superior parsing accuracies on many languages."
            },
            "slug": "A-Tabular-Method-for-Dynamic-Oracles-in-Parsing-Goldberg-Sartorio",
            "title": {
                "fragments": [],
                "text": "A Tabular Method for Dynamic Oracles in Transition-Based Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work develops parsing oracles for two transition-based dependency parsers, including the arc-standard parser, solving a problem that was left open in (Goldberg and Nivre, 2013)."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3365603"
                        ],
                        "name": "D. Andor",
                        "slug": "D.-Andor",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Andor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Andor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114577307"
                        ],
                        "name": "Chris Alberti",
                        "slug": "Chris-Alberti",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Alberti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Alberti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145045509"
                        ],
                        "name": "David Weiss",
                        "slug": "David-Weiss",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3091861"
                        ],
                        "name": "Aliaksei Severyn",
                        "slug": "Aliaksei-Severyn",
                        "structuredName": {
                            "firstName": "Aliaksei",
                            "lastName": "Severyn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aliaksei Severyn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3377551"
                        ],
                        "name": "A. Presta",
                        "slug": "A.-Presta",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Presta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Presta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422385"
                        ],
                        "name": "K. Ganchev",
                        "slug": "K.-Ganchev",
                        "structuredName": {
                            "firstName": "Kuzman",
                            "lastName": "Ganchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Ganchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754497"
                        ],
                        "name": "Slav Petrov",
                        "slug": "Slav-Petrov",
                        "structuredName": {
                            "firstName": "Slav",
                            "lastName": "Petrov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Slav Petrov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123052390"
                        ],
                        "name": "Michael Collins",
                        "slug": "Michael-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Collins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 89
                            }
                        ],
                        "text": "In order to be able to compare with similar greedy parsers (Yazdani and Henderson, 2015; Andor et al., 2016)5 we report the performance of the parser on the multilingual treebanks of the CoNLL 2009 shared task (Hajic\u030c et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 138
                            }
                        ],
                        "text": "Finally, abandoning greedy search in favor of approximate global search offers an alternative solution to the problems with greedy search (Andor et al., 2016), and has been analyzed as well (Kulesza and Pereira, 2007; Finley and Joachims, 2008), including for parsing (Martins et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 59
                            }
                        ],
                        "text": "In order to be able to compare with similar greedy parsers (Yazdani and Henderson, 2015; Andor et al., 2016)5 we report the performance of the parser on the multilingual treebanks of the CoNLL 2009"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 139
                            }
                        ],
                        "text": "Finally, abandoning greedy search in favor of approximate global search offers an alternative solution to the problems with greedy search (Andor et al., 2016), and has been analyzed as well (Kulesza and Pereira, 2007; Finley and Joachims, 2008), including for parsing (Martins et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2952144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4be0dd53aa1c751219fa6f19fed8a6324f6d2766",
            "isKey": true,
            "numCitedBy": 529,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a globally normalized transition-based neural network model that achieves state-of-the-art part-of-speech tagging, dependency parsing and sentence compression results. Our model is a simple feed-forward neural network that operates on a task-specific transition system, yet achieves comparable or better accuracies than recurrent models. We discuss the importance of global as opposed to local normalization: a key insight is that the label bias problem implies that globally normalized models can be strictly more expressive than locally normalized models."
            },
            "slug": "Globally-Normalized-Transition-Based-Neural-Andor-Alberti",
            "title": {
                "fragments": [],
                "text": "Globally Normalized Transition-Based Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A globally normalized transition-based neural network model that achieves state-of-the-art part- of-speech tagging, dependency parsing and sentence compression results is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749837"
                        ],
                        "name": "Eugene Charniak",
                        "slug": "Eugene-Charniak",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Charniak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Charniak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177220"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11599080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ecb33ced5b0976accdf13817151f80568b6fdcb",
            "isKey": false,
            "numCitedBy": 1244,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative reranking is one method for constructing high-performance statistical parsers (Collins, 2000). A discriminative reranker requires a source of candidate parses for each sentence. This paper describes a simple yet novel method for constructing sets of 50-best parses based on a coarse-to-fine generative parser (Charniak, 2000). This method generates 50-best lists that are of substantially higher quality than previously obtainable. We used these parses as the input to a MaxEnt reranker (Johnson et al., 1999; Riezler et al., 2002) that selects the best parse from the set of parses for each sentence, obtaining an f-score of 91.0% on sentences of length 100 or less."
            },
            "slug": "Coarse-to-Fine-n-Best-Parsing-and-MaxEnt-Reranking-Charniak-Johnson",
            "title": {
                "fragments": [],
                "text": "Coarse-to-Fine n-Best Parsing and MaxEnt Discriminative Reranking"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper describes a simple yet novel method for constructing sets of 50- best parses based on a coarse-to-fine generative parser that generates 50-best lists that are of substantially higher quality than previously obtainable."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " where t is the number of epochs completed. No momentum was used. To mitigate the effects of \u201cexploding\u201d gradients, we clipped the \u21132 norm of the gradient to 5 before applying the weight update rule (Sutskever et al., 2014; Graves, 2013). An \u21132 penalty of 1\u00d7 10\u22126 was applied to all weights. Matrix and vector parameters were initialized with uniform samples in \u00b1 p 6/(r + c), where r and were the number of rows and colum"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7961699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "isKey": false,
            "numCitedBy": 14881,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "slug": "Sequence-to-Sequence-Learning-with-Neural-Networks-Sutskever-Vinyals",
            "title": {
                "fragments": [],
                "text": "Sequence to Sequence Learning with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure, and finds that reversing the order of the words in all source sentences improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2589625"
                        ],
                        "name": "Shiqi Shen",
                        "slug": "Shiqi-Shen",
                        "structuredName": {
                            "firstName": "Shiqi",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shiqi Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145161801"
                        ],
                        "name": "Yong Cheng",
                        "slug": "Yong-Cheng",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37985966"
                        ],
                        "name": "Zhongjun He",
                        "slug": "Zhongjun-He",
                        "structuredName": {
                            "firstName": "Zhongjun",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhongjun He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48692318"
                        ],
                        "name": "W. He",
                        "slug": "W.-He",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40354707"
                        ],
                        "name": "Hua Wu",
                        "slug": "Hua-Wu",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753344"
                        ],
                        "name": "Maosong Sun",
                        "slug": "Maosong-Sun",
                        "structuredName": {
                            "firstName": "Maosong",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maosong Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144090485"
                        ],
                        "name": "Yang Liu",
                        "slug": "Yang-Liu",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 32
                            }
                        ],
                        "text": ", 2015), expected loss training (Shen et al., 2015), and reinforcement learning have been proposed (Ranzato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 86
                            }
                        ],
                        "text": "Solutions based on curriculum learning (Bengio et al., 2015), expected loss training (Shen et al., 2015), and reinforcement learning have been proposed (Ranzato et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3913537,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f2a8e923965b23c11066a2ead79658208f1fae1",
            "isKey": false,
            "numCitedBy": 376,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose minimum risk training for end-to-end neural machine translation. Unlike conventional maximum likelihood estimation, minimum risk training is capable of optimizing model parameters directly with respect to arbitrary evaluation metrics, which are not necessarily differentiable. Experiments show that our approach achieves significant improvements over maximum likelihood estimation on a state-of-the-art neural machine translation system across various languages pairs. Transparent to architectures, our approach can be applied to more neural networks and potentially benefit more NLP tasks."
            },
            "slug": "Minimum-Risk-Training-for-Neural-Machine-Shen-Cheng",
            "title": {
                "fragments": [],
                "text": "Minimum Risk Training for Neural Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Experiments show that the proposed minimum risk training approach achieves significant improvements over maximum likelihood estimation on a state-of-the-art neural machine translation system across various languages pairs."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846258"
                        ],
                        "name": "Noam M. Shazeer",
                        "slug": "Noam-M.-Shazeer",
                        "structuredName": {
                            "firstName": "Noam",
                            "lastName": "Shazeer",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noam M. Shazeer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "Solutions based on curriculum learning (Bengio et al., 2015), expected loss training (Shen et al., 2015), and reinforcement learning have been proposed (Ranzato et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 39
                            }
                        ],
                        "text": "Solutions based on curriculum learning (Bengio et al., 2015), expected loss training (Shen et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1820089,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df137487e20ba7c6e1e2b9a1e749f2a578b5ad99",
            "isKey": false,
            "numCitedBy": 1414,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used succesfully in our winning entry to the MSCOCO image captioning challenge, 2015."
            },
            "slug": "Scheduled-Sampling-for-Sequence-Prediction-with-Bengio-Vinyals",
            "title": {
                "fragments": [],
                "text": "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38666915"
                        ],
                        "name": "D. Klein",
                        "slug": "D.-Klein",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 73
                            }
                        ],
                        "text": "3 The part-of-speech tags are predicted by using the Stanford POS tagger (Toutanova et al., 2003) with an accuracy of 97."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14835360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42a490cf4f186d3383c92963817d100afd81e2",
            "isKey": false,
            "numCitedBy": 3438,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24% accuracy on the Penn Treebank WSJ, an error reduction of 4.4% on the best previous single automatically learned tagging result."
            },
            "slug": "Feature-Rich-Part-of-Speech-Tagging-with-a-Cyclic-Toutanova-Klein",
            "title": {
                "fragments": [],
                "text": "Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A new part-of-speech tagger is presented that demonstrates the following ideas: explicit use of both preceding and following tag contexts via a dependency network representation, broad use of lexical features, and effective use of priors in conditional loglinear models."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51050859"
                        ],
                        "name": "Alper Tokg\u00f6z",
                        "slug": "Alper-Tokg\u00f6z",
                        "structuredName": {
                            "firstName": "Alper",
                            "lastName": "Tokg\u00f6z",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alper Tokg\u00f6z"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3348151"
                        ],
                        "name": "G. Eryigit",
                        "slug": "G.-Eryigit",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Eryigit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Eryigit"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5464204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b77698ef61449e555fabce5272795d569adb0df1",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In most of the dependency parsing studies, dependency relations within a sentence are often presented as a tree structure. Whilst the tree structure is sufficient to represent the surface relations, deep dependencies which may result to multi-headed relations require more general dependency structures, namely Directed Acyclic Graphs (DAGs). This study proposes a new dependency DAG parsing approach which uses a dynamic oracle within a shift-reduce transitionbased parsing framework. Although there is still room for improvement on performance with more feature engineering, we already obtain competitive performances compared to static oracles as a result of our initial experiments conducted on the ITU-METU-Sabanci Turkish Treebank (IMST)."
            },
            "slug": "Transition-based-Dependency-DAG-Parsing-Using-Tokg\u00f6z-Eryigit",
            "title": {
                "fragments": [],
                "text": "Transition-based Dependency DAG Parsing Using Dynamic Oracles"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This study proposes a new dependency DAG parsing approach which uses a dynamic oracle within a shift-reduce transitionbased parsing framework and obtains competitive performances compared to static oracles."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737207"
                        ],
                        "name": "Anders Bj\u00f6rkelund",
                        "slug": "Anders-Bj\u00f6rkelund",
                        "structuredName": {
                            "firstName": "Anders",
                            "lastName": "Bj\u00f6rkelund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anders Bj\u00f6rkelund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12121080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8050106f433e70a5738e0e6c53f1031bc032b1ec",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We study non-deterministic oracles for training non-projective beam search parsers with swap transitions. We map out the spurious ambiguities of the transition system and present two non-deterministic oracles as well as a static oracle that minimizes the number of swaps. An evaluation on 10 treebanks reveals that the difference between static and non-deterministic oracles is generally insignificant for beam search parsers but that non-deterministic oracles can improve the accuracy of greedy parsers that use swap transitions."
            },
            "slug": "Non-Deterministic-Oracles-for-Unrestricted-Parsing-Bj\u00f6rkelund-Nivre",
            "title": {
                "fragments": [],
                "text": "Non-Deterministic Oracles for Unrestricted Non-Projective Transition-Based Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "An evaluation on 10 treebanks reveals that the difference between static and non-deterministic oracles is generally insignificant for beam search parsers but that non-DeterministicOracles can improve the accuracy of greedy parsers that use swap transitions."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3182726"
                        ],
                        "name": "Matthew Honnibal",
                        "slug": "Matthew-Honnibal",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Honnibal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Honnibal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177145"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18046506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0793694f7934b2fc466f4e1c0cac73546de90a8d",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an incremental dependency parsing model that jointly performs disfluency detection. The model handles speech repairs using a novel non-monotonic transition system, and includes several novel classes of features. For comparison, we evaluated two pipeline systems, using state-of-the-art disfluency detectors. The joint model performed better on both tasks, with a parse accuracy of 90.5% and 84.0% accuracy at disfluency detection. The model runs in expected linear time, and processes over 550 tokens a second."
            },
            "slug": "Joint-Incremental-Disfluency-Detection-and-Parsing-Honnibal-Johnson",
            "title": {
                "fragments": [],
                "text": "Joint Incremental Disfluency Detection and Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "An incremental dependency parsing model that jointly performs disfluency detection and handles speech repairs using a novel non-monotonic transition system, and includes several novel classes of features."
            },
            "venue": {
                "fragments": [],
                "text": "TACL"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 115
                            }
                        ],
                        "text": "tures; this formalization is known as transitionbased parsing, and is often coupled with a greedy search procedure (Yamada and Matsumoto, 2003; Nivre, 2003; Nivre, 2004; Nivre, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14358598,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "032906f0d86fd6bbf7512d3fffd06fcb83593012",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Deterministic dependency parsing is a robust and efficient approach to syntactic parsing of unrestricted natural language text. In this paper, we analyze its potential for incremental processing and conclude that strict incrementality is not achievable within this framework. However, we also show that it is possible to minimize the number of structures that require non-incremental processing by choosing an optimal parsing algorithm. This claim is substantiated with experimental evidence showing that the algorithm achieves incremental parsing for 68.9% of the input when tested on a random sample of Swedish text. When restricted to sentences that are accepted by the parser, the degree of incrementality increases to 87.9%."
            },
            "slug": "Incrementality-in-Deterministic-Dependency-Parsing-Nivre",
            "title": {
                "fragments": [],
                "text": "Incrementality in Deterministic Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is concluded that strict incrementality is not achievable within this framework and it is shown that it is possible to minimize the number of structures that require non-incremental processing by choosing an optimal parsing algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450508"
                        ],
                        "name": "Carlos G\u00f3mez-Rodr\u00edguez",
                        "slug": "Carlos-G\u00f3mez-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "G\u00f3mez-Rodr\u00edguez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos G\u00f3mez-Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403069822"
                        ],
                        "name": "Daniel Fern\u00e1ndez-Gonz\u00e1lez",
                        "slug": "Daniel-Fern\u00e1ndez-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Fern\u00e1ndez-Gonz\u00e1lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Fern\u00e1ndez-Gonz\u00e1lez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14800772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b6e7f7f80d625f51be1824974320702aec39cc7",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We define a dynamic oracle for the Covington non-projective dependency parser. This is not only the first dynamic oracle that supports arbitrary non-projectivity, but also considerably more efficient (O(n)) than the only existing oracle with restricted non-projectivity support. Experiments show that training with the dynamic oracle significantly improves parsing accuracy over the static oracle baseline on a wide range of treebanks."
            },
            "slug": "An-Efficient-Dynamic-Oracle-for-Unrestricted-G\u00f3mez-Rodr\u00edguez-Fern\u00e1ndez-Gonz\u00e1lez",
            "title": {
                "fragments": [],
                "text": "An Efficient Dynamic Oracle for Unrestricted Non-Projective Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This is not only the first dynamic oracle that supports arbitrary non-projectivity, but also considerably more efficient than the only existing oracle with restricted non- projectivity support."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 115
                            }
                        ],
                        "text": "tures; this formalization is known as transitionbased parsing, and is often coupled with a greedy search procedure (Yamada and Matsumoto, 2003; Nivre, 2003; Nivre, 2004; Nivre, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10901371,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "053f1cf10ced2321c1853f307075f0a6a83b6840",
            "isKey": false,
            "numCitedBy": 460,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Parsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing because of the massive ambiguity typically found in natural language grammars. Nevertheless, it has been shown that such algorithms, combined with treebank-induced classifiers, can be used to build highly accurate disambiguating parsers, in particular for dependency-based syntactic representations. In this article, we first present a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing, formalized as transition systems. We then describe and analyze two families of such algorithms: stack-based and list-based algorithms. In the former family, which is restricted to projective dependency structures, we describe an arc-eager and an arc-standard variant; in the latter family, we present a projective and a non-projective variant. For each of the four algorithms, we give proofs of correctness and complexity. In addition, we perform an experimental evaluation of all algorithms in combination with SVM classifiers for predicting the next parsing action, using data from thirteen languages. We show that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms for languages with a non-negligible proportion of non-projective constructions. However, the projective algorithms often produce comparable results when combined with the technique known as pseudo-projective parsing. The linear time complexity of the stack-based algorithms gives them an advantage with respect to efficiency both in learning and in parsing, but the projective list-based algorithm turns out to be equally efficient in practice. Moreover, when the projective algorithms are used to implement pseudo-projective parsing, they sometimes become less efficient in parsing (but not in learning) than the non-projective list-based algorithm. Although most of the algorithms have been partially described in the literature before, this is the first comprehensive analysis and evaluation of the algorithms within a unified framework."
            },
            "slug": "Algorithms-for-Deterministic-Incremental-Dependency-Nivre",
            "title": {
                "fragments": [],
                "text": "Algorithms for Deterministic Incremental Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This article presents a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing, formalized as transition systems and shows that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms for languages with a non-negligible proportion of non- projective constructions."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145644643"
                        ],
                        "name": "Andr\u00e9 F. T. Martins",
                        "slug": "Andr\u00e9-F.-T.-Martins",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Martins",
                            "middleNames": [
                                "F.",
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9 F. T. Martins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": ", 2016), and has been analyzed as well (Kulesza and Pereira, 2007; Finley and Joachims, 2008), including for parsing (Martins et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 269
                            }
                        ],
                        "text": "Finally, abandoning greedy search in favor of approximate global search offers an alternative solution to the problems with greedy search (Andor et al., 2016), and has been analyzed as well (Kulesza and Pereira, 2007; Finley and Joachims, 2008), including for parsing (Martins et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16010178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4dfc0611c68a2d8f097fd4f4f0166860fdd9da1",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent approaches to learning structured predictors often require approximate inference for tractability; yet its effects on the learned model are unclear. Meanwhile, most learning algorithms act as if computational cost was constant within the model class. This paper sheds some light on the first issue by establishing risk bounds for max-margin learning with LP relaxed inference and addresses the second issue by proposing a new paradigm that attempts to penalize \"time-consuming\" hypotheses. Our analysis relies on a geometric characterization of the outer polyhedra associated with the LP relaxation. We then apply these techniques to the problem of dependency parsing, for which a concise LP formulation is provided that handles non-local output features. A significant improvement is shown over arc-factored models."
            },
            "slug": "Polyhedral-outer-approximations-with-application-to-Martins-Smith",
            "title": {
                "fragments": [],
                "text": "Polyhedral outer approximations with application to natural language parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper establishes risk bounds for max-margin learning with LP relaxed inference and addresses the second issue by proposing a new paradigm that attempts to penalize \"time-consuming\" hypotheses."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39939186"
                        ],
                        "name": "Yue Zhang",
                        "slug": "Yue-Zhang",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144523372"
                        ],
                        "name": "S. Clark",
                        "slug": "S.-Clark",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Clark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Clark"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " al., 2003) with an accuracy of 97.3%. This treebank contains a negligible amount of non-projective arcs (Chen and Manning, 2014). \u2022 For Chinese, we use the Penn Chinese Treebank 5.1 (CTB5) following Zhang and Clark (2008),4 with gold part-of-speech tags which is also the same as in Chen and Manning (2014). Language model word embeddings were generated from the AFP portion of the English Gigaword corpus (version 5), an"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15533677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad1181d188f730b7917a95ae452efb48f830c90a",
            "isKey": true,
            "numCitedBy": 330,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Graph-based and transition-based approaches to dependency parsing adopt very different views of the problem, each view having its own strengths and limitations. We study both approaches under the framework of beam-search. By developing a graph-based and a transition-based dependency parser, we show that a beam-search decoder is a competitive choice for both methods. More importantly, we propose a beam-search-based parser that combines both graph-based and transition-based parsing into a single system for training and decoding, showing that it outperforms both the pure graph-based and the pure transition-based parsers. Testing on the English and Chinese Penn Treebank data, the combined system gave state-of-the-art accuracies of 92.1% and 86.2%, respectively."
            },
            "slug": "A-Tale-of-Two-Parsers:-Investigating-and-Combining-Zhang-Clark",
            "title": {
                "fragments": [],
                "text": "A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A beam-search-based parser that combines both graph-based and transition-based parsing into a single system for training and decoding is proposed, showing that it outperforms both the pure graph- based and the pure transition- based parsers."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002335"
                        ],
                        "name": "Jan Hajic",
                        "slug": "Jan-Hajic",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Hajic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Hajic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2754495"
                        ],
                        "name": "Massimiliano Ciaramita",
                        "slug": "Massimiliano-Ciaramita",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Ciaramita",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Massimiliano Ciaramita"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341661"
                        ],
                        "name": "Richard Johansson",
                        "slug": "Richard-Johansson",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Johansson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Johansson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368642"
                        ],
                        "name": "Daisuke Kawahara",
                        "slug": "Daisuke-Kawahara",
                        "structuredName": {
                            "firstName": "Daisuke",
                            "lastName": "Kawahara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daisuke Kawahara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40430085"
                        ],
                        "name": "M. A. Mart\u00ed",
                        "slug": "M.-A.-Mart\u00ed",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Mart\u00ed",
                            "middleNames": [
                                "Ant\u00f2nia"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Mart\u00ed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049328"
                        ],
                        "name": "Llu\u00eds M\u00e0rquez i Villodre",
                        "slug": "Llu\u00eds-M\u00e0rquez-i-Villodre",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Villodre",
                            "middleNames": [
                                "M\u00e0rquez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds M\u00e0rquez i Villodre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144817783"
                        ],
                        "name": "Adam Meyers",
                        "slug": "Adam-Meyers",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Meyers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Meyers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708581"
                        ],
                        "name": "Sebastian Pad\u00f3",
                        "slug": "Sebastian-Pad\u00f3",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Pad\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sebastian Pad\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153593239"
                        ],
                        "name": "J. Step\u00e1nek",
                        "slug": "J.-Step\u00e1nek",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Step\u00e1nek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Step\u00e1nek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788237"
                        ],
                        "name": "P. Stran\u00e1k",
                        "slug": "P.-Stran\u00e1k",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Stran\u00e1k",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Stran\u00e1k"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760868"
                        ],
                        "name": "M. Surdeanu",
                        "slug": "M.-Surdeanu",
                        "structuredName": {
                            "firstName": "Mihai",
                            "lastName": "Surdeanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Surdeanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702849"
                        ],
                        "name": "Nianwen Xue",
                        "slug": "Nianwen-Xue",
                        "structuredName": {
                            "firstName": "Nianwen",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nianwen Xue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49889438"
                        ],
                        "name": "Yi Zhang",
                        "slug": "Yi-Zhang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9210201,
            "fieldsOfStudy": [
                "Computer Science",
                "Linguistics"
            ],
            "id": "c7d3f610b528226f1c862c4f9cd6b37623f7390f",
            "isKey": false,
            "numCitedBy": 556,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "For the 11th straight year, the Conference on Computational Natural Language Learning has been accompanied by a shared task whose purpose is to promote natural language processing applications and evaluate them in a standard setting. In 2009, the shared task was dedicated to the joint parsing of syntactic and semantic dependencies in multiple languages. This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task. In this paper, we define the shared task, describe how the data sets were created and show their quantitative properties, report the results and summarize the approaches of the participating systems."
            },
            "slug": "The-CoNLL-2009-Shared-Task:-Syntactic-and-Semantic-Hajic-Ciaramita",
            "title": {
                "fragments": [],
                "text": "The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This shared task combines the shared tasks of the previous five years under a unique dependency-based formalism similar to the 2008 task and describes how the data sets were created and show their quantitative properties."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL Shared Task"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162125"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 704519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c9d9f3c6f7508f4e29730924529dc993c27cddc",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Searn, an algorithm for integrating search and learning to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology, and vision. Searn is a meta-algorithm that transforms these complex problems into simple classification problems to which any binary classifier may be applied. Unlike current algorithms for structured learning that require decomposition of both the loss function and the feature functions over the predicted structure, Searn is able to learn prediction functions for any loss function and any class of features. Moreover, Searn comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies good performance on the structured prediction problem."
            },
            "slug": "Search-based-structured-prediction-Daum\u00e9-Langford",
            "title": {
                "fragments": [],
                "text": "Search-based structured prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "Searn is an algorithm for integrating search and learning to solve complex structured prediction problems such as those that occur in natural language, speech, computational biology, and vision and comes with a strong, natural theoretical guarantee: good performance on the derived classification problems implies goodperformance on the structured prediction problem."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145446170"
                        ],
                        "name": "Jens Nilsson",
                        "slug": "Jens-Nilsson",
                        "structuredName": {
                            "firstName": "Jens",
                            "lastName": "Nilsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jens Nilsson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 148
                            }
                        ],
                        "text": "Since some of the treebanks contain nonprojective sentences and archybrid does not allow nonprojective trees, we use the pseudo-projective approach (Nivre and Nilsson, 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17842042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b92c0e898b1fee243864176e18a2b50105be3e54",
            "isKey": false,
            "numCitedBy": 336,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In order to realize the full potential of dependency-based syntactic parsing, it is desirable to allow non-projective dependency structures. We show how a data-driven deterministic dependency parser, in itself restricted to projective structures, can be combined with graph transformation techniques to produce non-projective structures. Experiments using data from the Prague Dependency Treebank show that the combined system can handle non-projective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy. This leads to the best reported performance for robust non-projective parsing of Czech."
            },
            "slug": "Pseudo-Projective-Dependency-Parsing-Nivre-Nilsson",
            "title": {
                "fragments": [],
                "text": "Pseudo-Projective Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experiments show that the combined system can handle non-projective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy, leading to the best reported performance for robust non- projective parsing of Czech."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46838106"
                        ],
                        "name": "H. Yamada",
                        "slug": "H.-Yamada",
                        "structuredName": {
                            "firstName": "Hiroyasu",
                            "lastName": "Yamada",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yamada"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681502"
                        ],
                        "name": "Yuji Matsumoto",
                        "slug": "Yuji-Matsumoto",
                        "structuredName": {
                            "firstName": "Yuji",
                            "lastName": "Matsumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuji Matsumoto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 115
                            }
                        ],
                        "text": "tures; this formalization is known as transitionbased parsing, and is often coupled with a greedy search procedure (Yamada and Matsumoto, 2003; Nivre, 2003; Nivre, 2004; Nivre, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13163488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0e1883cf9d1b3c911125f46359f908557fc5827",
            "isKey": false,
            "numCitedBy": 715,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a method for analyzing word-word dependencies using deterministic bottom-up manner using Support Vector machines. We experimented with dependency trees converted from Penn treebank data, and achieved over 90% accuracy of word-word dependency. Though the result is little worse than the most up-to-date phrase structure based parsers, it looks satisfactorily accurate considering that our parser uses no information from phrase structures."
            },
            "slug": "Statistical-Dependency-Analysis-with-Support-Vector-Yamada-Matsumoto",
            "title": {
                "fragments": [],
                "text": "Statistical Dependency Analysis with Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Though the result is little worse than the most up-to-date phrase structure based parsers, it looks satisfactorily accurate considering that the parser uses no information from phrase structures."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695463"
                        ],
                        "name": "D. Marcu",
                        "slug": "D.-Marcu",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Marcu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Marcu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5c48c673b0d3152010e3374cac189314a13df10",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Mappings to structured output spaces (strings, trees, partitions, etc.) are typically learned using extensions of classification algorithms to simple graphical structures (eg., linear chains) in which search and parameter estimation can be performed exactly. Unfortunately, in many complex problems, it is rare that exact search or parameter estimation is tractable. Instead of learning exact models and searching via heuristic means, we embrace this difficulty and treat the structured output problem in terms of approximate search. We present a framework for learning as search optimization, and two parameter updates with convergence the-orems and bounds. Empirical evidence shows that our integrated approach to learning and decoding can outperform exact models at smaller computational cost."
            },
            "slug": "Learning-as-search-optimization:-approximate-large-Daum\u00e9-Marcu",
            "title": {
                "fragments": [],
                "text": "Learning as search optimization: approximate large margin methods for structured prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a framework for learning as search optimization, and two parameter updates with convergence the-orems and bounds, and shows that this integrated approach to learning and decoding can outperform exact models at smaller computational cost."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40462390"
                        ],
                        "name": "Marco Kuhlmann",
                        "slug": "Marco-Kuhlmann",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Kuhlmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Kuhlmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450508"
                        ],
                        "name": "Carlos G\u00f3mez-Rodr\u00edguez",
                        "slug": "Carlos-G\u00f3mez-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "G\u00f3mez-Rodr\u00edguez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos G\u00f3mez-Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152299194"
                        ],
                        "name": "G. Satta",
                        "slug": "G.-Satta",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Satta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Satta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 64
                            }
                        ],
                        "text": "We chose instead to switch to the arc-hybrid transition system (Kuhlmann et al., 2011), which is very similar to the arc-standard system but is arc-decomposable and hence admits an efficient O(1) dynamic oracle, resulting in only negligible increase to training runtime."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12822570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f1631fa69fe6ae17dbe9dc975304ae13f24ff0a",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a general dynamic programming technique for the tabulation of transition-based dependency parsers, and apply it to obtain novel, polynomial-time algorithms for parsing with the arc-standard and arc-eager models. We also show how to reverse our technique to obtain new transition-based dependency parsers from existing tabular methods. Additionally, we provide a detailed discussion of the conditions under which the feature models commonly used in transition-based parsing can be integrated into our algorithms."
            },
            "slug": "Dynamic-Programming-Algorithms-for-Transition-Based-Kuhlmann-G\u00f3mez-Rodr\u00edguez",
            "title": {
                "fragments": [],
                "text": "Dynamic Programming Algorithms for Transition-Based Dependency Parsers"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A general dynamic programming technique for the tabulation of transition-based dependency parsers is developed and applied to obtain novel, polynomial-time algorithms for parsing with the arc-standard and arc-eager models."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745899"
                        ],
                        "name": "Chris Dyer",
                        "slug": "Chris-Dyer",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Dyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143668305"
                        ],
                        "name": "Miguel Ballesteros",
                        "slug": "Miguel-Ballesteros",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Ballesteros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miguel Ballesteros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1379953252"
                        ],
                        "name": "Wang Ling",
                        "slug": "Wang-Ling",
                        "structuredName": {
                            "firstName": "Wang",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wang Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144633696"
                        ],
                        "name": "Austin Matthews",
                        "slug": "Austin-Matthews",
                        "structuredName": {
                            "firstName": "Austin",
                            "lastName": "Matthews",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Austin Matthews"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144365875"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 111
                            }
                        ],
                        "text": "The definition of what constitutes a \u201ccorrect\u201d action is the major difference between a static oracle as used by Dyer et al. (2015) and the dynamic oracle explored here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "We also include results with pretrained word embeddings for English, Chinese, German, and Spanish following the same training setup as Dyer et al. (2015); for English and Chinese we used the same pretrained word embeddings as in Table 1, for German we used the monolingual training data from the WMT\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 54
                            }
                        ],
                        "text": "Our departure point is the parsing model described by Dyer et al. (2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Dyer et al. (2015) presented a parser in which the parser\u2019s unbounded state is embedded in a fixeddimensional continuous space using recurrent neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 59
                            }
                        ],
                        "text": "Following the same settings of Chen and Manning (2014) and Dyer et al (2015) we report results4 in the English PTB and Chinese CTB-5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Dyer et al. (2015) presented stack LSTMs and used them to implement a transition-based dependency parser."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6278207,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "b36b7f7c68923d14ba2859b5d28a1124616a8c89",
            "isKey": false,
            "numCitedBy": 708,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This work was sponsored in part by the U. S. Army Research Laboratory and the U. S. Army Research Office/nunder contract/grant number W911NF-10-1-0533, and in part by NSF CAREER grant IIS-1054319./nMiguel Ballesteros is supported by the European Commission under the contract numbers FP7-ICT-610411 (project MULTISENSOR) and H2020-RIA-645012 (project KRISTINA)."
            },
            "slug": "Transition-Based-Dependency-Parsing-with-Stack-Long-Dyer-Ballesteros",
            "title": {
                "fragments": [],
                "text": "Transition-Based Dependency Parsing with Stack Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work was sponsored in part by the U. S. Army Research Laboratory and the NSF CAREER grant IIS-1054319 and the European Commission."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782886"
                        ],
                        "name": "Kai-Wei Chang",
                        "slug": "Kai-Wei-Chang",
                        "structuredName": {
                            "firstName": "Kai-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37019006"
                        ],
                        "name": "A. Krishnamurthy",
                        "slug": "A.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Akshay",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krishnamurthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40333747"
                        ],
                        "name": "Alekh Agarwal",
                        "slug": "Alekh-Agarwal",
                        "structuredName": {
                            "firstName": "Alekh",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alekh Agarwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162125"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 276
                            }
                        ],
                        "text": "\u2026paying attention to the expected classifier behavior during test time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daume\u0301 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daume\u0301 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 86
                            }
                        ],
                        "text": "time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daum\u00e9 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daum\u00e9 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16610517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed02ce4a53407d460eff371f506bfea1e13187d2",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Methods for learning to search for structured prediction typically imitate a reference policy, with existing theoretical guarantees demonstrating low regret compared to that reference. This is unsatisfactory in many applications where the reference policy is suboptimal and the goal of learning is to improve upon it. Can learning to search work even when the reference is poor? \n \nWe provide a new learning to search algorithm, LOLS, which does well relative to the reference policy, but additionally guarantees low regret compared to deviations from the learned policy: a local-optimality guarantee. Consequently, LOLS can improve upon the reference policy, unlike previous algorithms. This enables us to develop structured contextual bandits, a partial information structured prediction setting with many potential applications."
            },
            "slug": "Learning-to-Search-Better-than-Your-Teacher-Chang-Krishnamurthy",
            "title": {
                "fragments": [],
                "text": "Learning to Search Better than Your Teacher"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A new learning to search algorithm, LOLS, is provided, which does well relative to the reference policy, but additionally guarantees low regret compared to deviations from the learned policy: a local-optimality guarantee."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145500336"
                        ],
                        "name": "Alex Kulesza",
                        "slug": "Alex-Kulesza",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Kulesza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Kulesza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 39
                            }
                        ],
                        "text": ", 2016), and has been analyzed as well (Kulesza and Pereira, 2007; Finley and Joachims, 2008), including for parsing (Martins et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10876177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "325ea1f2022ee3886a5810df76dcfbe4010ad439",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many structured prediction problems, the highest-scoring labeling is hard to compute exactly, leading to the use of approximate inference methods. However, when inference is used in a learning algorithm, a good approximation of the score may not be sufficient. We show in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees. There are two reasons for this. First, approximate methods can effectively reduce the expressivity of an underlying model by making it impossible to choose parameters that reliably give good predictions. Second, approximations can respond to parameter changes in such a way that standard learning algorithms are misled. In contrast, we give two positive results in the form of learning bounds for the use of LP-relaxed inference in structured perceptron and empirical risk minimization settings. We argue that without understanding combinations of inference and learning, such as these, that are appropriately compatible, learning performance under approximate inference cannot be guaranteed."
            },
            "slug": "Structured-Learning-with-Approximate-Inference-Kulesza-Pereira",
            "title": {
                "fragments": [],
                "text": "Structured Learning with Approximate Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown in particular that learning can fail even with an approximate inference method with rigorous approximation guarantees, and argued that without understanding combinations of inference and learning, such as these that are appropriately compatible, learning performance under approximate inference cannot be guaranteed."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50256971"
                        ],
                        "name": "Thomas Finley",
                        "slug": "Thomas-Finley",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Finley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Finley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 39
                            }
                        ],
                        "text": ", 2016), and has been analyzed as well (Kulesza and Pereira, 2007; Finley and Joachims, 2008), including for parsing (Martins et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 505690,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc243b4920cdc9f45ef18ef0bad5b6576c444a34",
            "isKey": false,
            "numCitedBy": 307,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "While discriminative training (e.g., CRF, structural SVM) holds much promise for machine translation, image segmentation, and clustering, the complex inference these applications require make exact training intractable. This leads to a need for approximate training methods. Unfortunately, knowledge about how to perform efficient and effective approximate training is limited. Focusing on structural SVMs, we provide and explore algorithms for two different classes of approximate training algorithms, which we call undergenerating (e.g., greedy) and overgenerating (e.g., relaxations) algorithms. We provide a theoretical and empirical analysis of both types of approximate trained structural SVMs, focusing on fully connected pairwise Markov random fields. We find that models trained with overgenerating methods have theoretic advantages over undergenerating methods, are empirically robust relative to their undergenerating brethren, and relaxed trained models favor non-fractional predictions from relaxed predictors."
            },
            "slug": "Training-structural-SVMs-when-exact-inference-is-Finley-Joachims",
            "title": {
                "fragments": [],
                "text": "Training structural SVMs when exact inference is intractable"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work provides a theoretical and empirical analysis of both types of approximate trained structural SVMs, focusing on fully connected pairwise Markov random fields, and finds that models trained with overgenerating methods have theoretic advantages over undergeneration methods, are empirically robust relative to their undergenerating brethren, and relaxed trained models favor non-fractional predictions from relaxed predictors."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055979341"
                        ],
                        "name": "Huihsin Tseng",
                        "slug": "Huihsin-Tseng",
                        "structuredName": {
                            "firstName": "Huihsin",
                            "lastName": "Tseng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huihsin Tseng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113641500"
                        ],
                        "name": "Pi-Chuan Chang",
                        "slug": "Pi-Chuan-Chang",
                        "structuredName": {
                            "firstName": "Pi-Chuan",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pi-Chuan Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144339350"
                        ],
                        "name": "Galen Andrew",
                        "slug": "Galen-Andrew",
                        "structuredName": {
                            "firstName": "Galen",
                            "lastName": "Andrew",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Galen Andrew"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746807"
                        ],
                        "name": "Dan Jurafsky",
                        "slug": "Dan-Jurafsky",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Jurafsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dan Jurafsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 217
                            }
                        ],
                        "text": "Language model word embeddings were generated from the AFP portion of the English Gigaword corpus (version 5), and from the complete Chinese Gigaword corpus (version 2), as segmented by the Stanford Chinese Segmenter (Tseng et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1324511,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c9f46f7e2f43f0b38a31007aebb78f94c6f146c8",
            "isKey": false,
            "numCitedBy": 491,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a Chinese word segmentation system submitted to the closed track of Sighan bakeoff 2005. Our segmenter was built using a conditional random field sequence model that provides a framework to use a large number of linguistic features such as character identity, morphological and character reduplication features. Because our morphological features were extracted from the training corpora automatically, our system was not biased toward any particular variety of Mandarin. Thus, our system does not overfit the variety of Mandarin most familiar to the system's designers. Our final system achieved a F-score of 0.947 (AS), 0.943 (HK), 0.950 (PK) and 0.964 (MSR)."
            },
            "slug": "A-Conditional-Random-Field-Word-Segmenter-for-2005-Tseng-Chang",
            "title": {
                "fragments": [],
                "text": "A Conditional Random Field Word Segmenter for Sighan Bakeoff 2005"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A Chinese word segmentation system built using a conditional random field sequence model that provides a framework to use a large number of linguistic features such as character identity, morphological and character reduplication features is presented."
            },
            "venue": {
                "fragments": [],
                "text": "SIGHAN@IJCNLP 2005"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700433"
                        ],
                        "name": "St\u00e9phane Ross",
                        "slug": "St\u00e9phane-Ross",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Ross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "St\u00e9phane Ross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21889436"
                        ],
                        "name": "Geoffrey J. Gordon",
                        "slug": "Geoffrey-J.-Gordon",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey J. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 257
                            }
                        ],
                        "text": "\u2026paying attention to the expected classifier behavior during test time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daume\u0301 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daume\u0301 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 86
                            }
                        ],
                        "text": "time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daum\u00e9 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daum\u00e9 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 175
                            }
                        ],
                        "text": "Since the parser is likely to make mistakes at test time and encounter states it has not seen during training, this training criterion is problematic (Daume\u0301 III et al., 2009; Ross et al., 2011; Goldberg and Nivre, 2012; Goldberg and Nivre, 2013, inter alia)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 103456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79ab3c49903ec8cb339437ccf5cf998607fc313e",
            "isKey": false,
            "numCitedBy": 1878,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common i.i.d. assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem."
            },
            "slug": "A-Reduction-of-Imitation-Learning-and-Structured-to-Ross-Gordon",
            "title": {
                "fragments": [],
                "text": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting and demonstrates that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3119801"
                        ],
                        "name": "Xavier Glorot",
                        "slug": "Xavier-Glorot",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Glorot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Glorot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 77
                            }
                        ],
                        "text": "6/(r + c), wherer and c were the number of rows and columns in the structure (Glorot and Bengio, 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5575601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b71ac1e9fb49420d13e084ac67254a0bbd40f83f",
            "isKey": false,
            "numCitedBy": 12434,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a \u201cbetter\u201d basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact)."
            },
            "slug": "Understanding-the-difficulty-of-training-deep-Glorot-Bengio",
            "title": {
                "fragments": [],
                "text": "Understanding the difficulty of training deep feedforward neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064056928"
                        ],
                        "name": "Andreas Vlachos",
                        "slug": "Andreas-Vlachos",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Vlachos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Vlachos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 86
                            }
                        ],
                        "text": "time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daum\u00e9 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daum\u00e9 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c688e187cede868e35fc1b53913e0fbbe6e38ea0",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In the imitation learning paradigm algorithms learn from expert demonstrations in order to become able to accomplish a particular task. Daume III et al. [2009] framed structured prediction in this paradigm and developed the search-based structured prediction algorithm (Searn) which has been applied successfully to various natural language processing tasks with state-of-the-art performance. Recently, Ross et al. [2011] proposed the dataset aggregation algorithm (DAgger) and compared it with Searn in sequential prediction tasks. In this paper, we compare these two algorithms in the context of a more complex structured prediction task, namely biomedical event extraction. We demonstrate that DAgger has more stable performance and faster learning than Searn, and that these advantages are more pronounced in the parameter-free versions of the algorithms."
            },
            "slug": "An-investigation-of-imitation-learning-algorithms-Vlachos",
            "title": {
                "fragments": [],
                "text": "An investigation of imitation learning algorithms for structured prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is demonstrated that DAgger has more stable performance and faster learning than Searn, and that these advantages are more pronounced in the parameter-free versions of the algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "EWRL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2241127"
                        ],
                        "name": "Marie-Catherine de Marneffe",
                        "slug": "Marie-Catherine-de-Marneffe",
                        "structuredName": {
                            "firstName": "Marie-Catherine",
                            "lastName": "Marneffe",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marie-Catherine de Marneffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3257930"
                        ],
                        "name": "Bill MacCartney",
                        "slug": "Bill-MacCartney",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "MacCartney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bill MacCartney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3102322,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cc228402f31ca749112197720b9ef6af0c16790",
            "isKey": false,
            "numCitedBy": 2563,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a system for extracting typed dependency parses of English sentences from phrase structure parses. In order to capture inherent relations occurring in corpus texts that can be critical in real-world applications, many NP relations are included in the set of grammatical relations used. We provide a comparison of our system with Minipar and the Link parser. The typed dependency extraction facility described here is integrated in the Stanford Parser, available for download."
            },
            "slug": "Generating-Typed-Dependency-Parses-from-Phrase-Marneffe-MacCartney",
            "title": {
                "fragments": [],
                "text": "Generating Typed Dependency Parses from Phrase Structure Parses"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A system for extracting typed dependency parses of English sentences from phrase structure parses that captures inherent relations occurring in corpus texts that can be critical in real-world applications is described."
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720988"
                        ],
                        "name": "Joakim Nivre",
                        "slug": "Joakim-Nivre",
                        "structuredName": {
                            "firstName": "Joakim",
                            "lastName": "Nivre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joakim Nivre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 115
                            }
                        ],
                        "text": "tures; this formalization is known as transitionbased parsing, and is often coupled with a greedy search procedure (Yamada and Matsumoto, 2003; Nivre, 2003; Nivre, 2004; Nivre, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59829005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "24439a2a35b834aa710373d62da4c6f86a180125",
            "isKey": false,
            "numCitedBy": 607,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a deterministic parsing algorithm for projective dependency grammar. The running time of the algorithm is linear in the length of the input string, and the dependency graph produced is guaranteed to be projective and acyclic. The algorithm has been experimentally evaluated in parsing unrestricted Swedish text, achieving an accuracy above 85% with a very simple grammar."
            },
            "slug": "An-Efficient-Algorithm-for-Projective-Dependency-Nivre",
            "title": {
                "fragments": [],
                "text": "An Efficient Algorithm for Projective Dependency Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This paper presents a deterministic parsing algorithm for projective dependency grammar that has been experimentally evaluated in parsing unrestricted Swedish text, achieving an accuracy above 85% with a very simple grammar."
            },
            "venue": {
                "fragments": [],
                "text": "IWPT"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144466851"
                        ],
                        "name": "He He",
                        "slug": "He-He",
                        "structuredName": {
                            "firstName": "He",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "He He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145043214"
                        ],
                        "name": "Jason Eisner",
                        "slug": "Jason-Eisner",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Eisner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Eisner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 216
                            }
                        ],
                        "text": "\u2026paying attention to the expected classifier behavior during test time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daume\u0301 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daume\u0301 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 86
                            }
                        ],
                        "text": "time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daum\u00e9 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daum\u00e9 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 567577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1299732e905399066a36d11990a3921911de63b7",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Imitation Learning has been shown to be successful in solving many challenging real-world problems. Some recent approaches give strong performance guarantees by training the policy iteratively. However, it is important to note that these guarantees depend on how well the policy we found can imitate the oracle on the training data. When there is a substantial difference between the oracle's ability and the learner's policy space, we may fail to find a policy that has low error on the training set. In such cases, we propose to use a coach that demonstrates easy-to-learn actions for the learner and gradually approaches the oracle. By a reduction of learning by demonstration to online learning, we prove that coaching can yield a lower regret bound than using the oracle. We apply our algorithm to cost-sensitive dynamic feature selection, a hard decision problem that considers a user-specified accuracy-cost trade-off. Experimental results on UCI datasets show that our method outperforms state-of-the-art imitation learning methods in dynamic feature selection and two static feature selection methods."
            },
            "slug": "Imitation-Learning-by-Coaching-He-Daum\u00e9",
            "title": {
                "fragments": [],
                "text": "Imitation Learning by Coaching"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "By a reduction of learning by demonstration to online learning, it is proved that coaching can yield a lower regret bound than using the oracle and this method outperforms state-of-the-art imitation learning methods in dynamic feature selection and two static feature selection methods."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1697424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89b1f4740ae37fd04f6ac007577bdd34621f0861",
            "isKey": false,
            "numCitedBy": 3153,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles."
            },
            "slug": "Generating-Sequences-With-Recurrent-Neural-Networks-Graves",
            "title": {
                "fragments": [],
                "text": "Generating Sequences With Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 86
                            }
                        ],
                        "text": "time has been explored under the imitation learning and learning-to-search frameworks (Abbeel and Ng, 2004; Daum\u00e9 III and Marcu, 2005; Vlachos, 2012; He et al., 2012; Daum\u00e9 III et al., 2009; Ross et al., 2011; Chang et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207155342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f65020fc3b1692d7989e099d6b6e698be5a50a93",
            "isKey": false,
            "numCitedBy": 2544,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform. This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off. We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert. Our algorithm is based on using \"inverse reinforcement learning\" to try to recover the unknown reward function. We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function."
            },
            "slug": "Apprenticeship-learning-via-inverse-reinforcement-Abbeel-Ng",
            "title": {
                "fragments": [],
                "text": "Apprenticeship learning via inverse reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work thinks of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and gives an algorithm for learning the task demonstrated by the expert, based on using \"inverse reinforcement learning\" to try to recover the unknown reward function."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 286,
                                "start": 268
                            }
                        ],
                        "text": "\u2026directed edges from each function\u2019s inputs to its outputs) for the negative log probability for the oracle transition sequence as a function of the current model parameters and uses forward- and backpropagation to obtain the gradients respect to the model parameters (Lecun et al., 1998, section 4)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35264,
            "numCiting": 248,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 111
                            }
                        ],
                        "text": "The definition of what constitutes a \u201ccorrect\u201d action is the major difference between a static oracle as used by Dyer et al. (2015) and the dynamic oracle explored here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "We also include results with pretrained word embeddings for English, Chinese, German, and Spanish following the same training setup as Dyer et al. (2015); for English and Chinese we used the same pretrained word embeddings as in Table 1, for German we used the monolingual training data from the WMT\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 54
                            }
                        ],
                        "text": "Our departure point is the parsing model described by Dyer et al. (2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Dyer et al. (2015) presented a parser in which the parser\u2019s unbounded state is embedded in a fixeddimensional continuous space using recurrent neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 59
                            }
                        ],
                        "text": "Following the same settings of Chen and Manning (2014) and Dyer et al (2015) we report results4 in the English PTB and Chinese CTB-5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Dyer et al. (2015) presented stack LSTMs and used them to implement a transition-based dependency parser."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transitionbased dependency parsing with stack long short-term memory"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of ACL."
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 54
                            }
                        ],
                        "text": "Our departure point is the parsing model described in (Dyer et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 111
                            }
                        ],
                        "text": "The definition of what constitutes a \u201ccorrect\u201d action is the major difference between a static oracle as used by Dyer et al. (2015) and the dynamic oracle explored here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 118
                            }
                        ],
                        "text": "The definition of what constitutes a \u201ccorrect\u201d action is the major difference between static oracle which was used in (Dyer et al., 2015) and the dynamic oracle explored here."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 135
                            }
                        ],
                        "text": "We also include results with pretrained word embeddings for English, Chinese, German, and Spanish following the same training setup as Dyer et al. (2015); for English and Chinese we used the same pretrained word embeddings as in Table 1, for German we used the monolingual training data from the WMT\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 54
                            }
                        ],
                        "text": "Our departure point is the parsing model described by Dyer et al. (2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Dyer et al. (2015) presented a parser in which the parser\u2019s unbounded state is embedded in a fixeddimensional continuous space using recurrent neural networks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 59
                            }
                        ],
                        "text": "Following the same settings of Chen and Manning (2014) and Dyer et al (2015) we report results4 in the English PTB and Chinese CTB-5."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 0
                            }
                        ],
                        "text": "Dyer et al. (2015) presented stack LSTMs and used them to implement a transition-based dependency parser."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Transitionbased dependency parsing with stack long shortterm memory"
            },
            "venue": {
                "fragments": [],
                "text": "InProceedings of the Annual Meeting of the Association for Computational Linguistics"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "improve the stack LSTM parser, achieving 93.56 UAS for English, maintaining greedy search"
            },
            "venue": {
                "fragments": [],
                "text": "improve the stack LSTM parser, achieving 93.56 UAS for English, maintaining greedy search"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "system for dependency parsing"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of CoNLL"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A non-monotonic arc-eager"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Miguel Ballesteros is supported by the European Commission under the contract numbers FP7-ICT-610411 (project MULTISENSOR) and H2020-RIA-645012 (project KRISTINA)"
            },
            "venue": {
                "fragments": [],
                "text": "Yoav Goldberg is supported by the Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) and the Israeli Science Foundation"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Slav Petrov, and Michael Collins. 2016. Globally normalized transition-based neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of ACL"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 55
                            }
                        ],
                        "text": ", 2015), and reinforcement learning have been proposed (Ranzato et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 153
                            }
                        ],
                        "text": "Solutions based on curriculum learning (Bengio et al., 2015), expected loss training (Shen et al., 2015), and reinforcement learning have been proposed (Ranzato et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computational Linguistics, 34:4:513\u2013553"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "St\u00e9phane Ross, Geoffrey J"
            },
            "venue": {
                "fragments": [],
                "text": "Gordon, and J. Andrew Bagnell. 2011. A reduction of imitation learning and structured prediction to no-regret online learn-"
            },
            "year": 2016
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 16
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 54,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Training-with-Exploration-Improves-a-Greedy-Stack-Ballesteros-Goldberg/6789e0dbd294cccb3b7dd4e001c9e8ba4813f334?sort=total-citations"
}