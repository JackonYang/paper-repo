{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145272844"
                        ],
                        "name": "C. Apt\u00e9",
                        "slug": "C.-Apt\u00e9",
                        "structuredName": {
                            "firstName": "Chidanand",
                            "lastName": "Apt\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Apt\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68982679"
                        ],
                        "name": "Fred J. Damerau",
                        "slug": "Fred-J.-Damerau",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Damerau",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fred J. Damerau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10826654,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9257779eed46107bcdce9f4dc86298572ff466ce",
            "isKey": false,
            "numCitedBy": 945,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to \u201cread\u201d documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features."
            },
            "slug": "Automated-learning-of-decision-rules-for-text-Apt\u00e9-Damerau",
            "title": {
                "fragments": [],
                "text": "Automated learning of decision rules for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation, and compared with other machine-learning techniques."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697855"
                        ],
                        "name": "M. Ringuette",
                        "slug": "M.-Ringuette",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Ringuette",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ringuette"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16894634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9fd1a7ae0322d417ab2d32017e373dd50efc063",
            "isKey": false,
            "numCitedBy": 745,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines the use of inductive learning to categorize natural language documents into predeened content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it diicult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classiier and a decision tree learning algorithm on two text categorization data sets. We nd that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial preeltering of features, connrming the results found by Almuallim and Dietterich on artiicial data sets. We also demonstrate the impact of the time-varying nature of category deenitions."
            },
            "slug": "A-comparison-of-two-learning-algorithms-for-text-Lewis-Ringuette",
            "title": {
                "fragments": [],
                "text": "A comparison of two learning algorithms for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "It is shown that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives, and the stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934343"
                        ],
                        "name": "David Hecherman",
                        "slug": "David-Hecherman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hecherman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Hecherman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "\u20261998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "\u20261999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 83
                            }
                        ],
                        "text": "Among these, the most noteworthy are the ones based on Bayesian inference networks [Dumais et al. 1998; Lam et al. 1997; Tzeras and Hartmann 1993], genetic algorithms [Clack et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 161
                            }
                        ],
                        "text": "\u2026example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 142
                            }
                        ],
                        "text": "\u2026Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 57
                            }
                        ],
                        "text": "1995] or before applying another more sophisticated form [Dumais et al. 1998; Li and Jain 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 107
                            }
                        ],
                        "text": "MH committee \ncommittee [Schapire and Singer 2000] [Weiss et al. 1999] .860 .878 Bayesian net Bayesian net [Dumais \net al. 1998] [Lam et al. 1997] .542 (MF1) .800 .850 and Pedersen [1997].21 The documents are titles \nor title-plus-abstracts from medical journals (OHSUMED is actually a subset of the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 84
                            }
                        ],
                        "text": "Among these, the most noteworthy are the ones based on Bayesian inference networks [Dumais et al. 1998; \nLam et al. 1997; Tzeras and Hartmann 1993], genetic algorithms [Clack et al. 1997; Masand 1994], and \nmaximum entropy modelling [Manning and Sch utze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 247
                            }
                        ],
                        "text": "\u2026is adopted by many authors, who remove all terms occurring in at most x train\u00ading documents \n(popular values for x range from 1 to 3), either as the only form of DR [Maron 1961; Ittner et al. 1995] \nor before applying another more sophisticated form [Dumais et al. 1998; Li and Jain 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 53
                            }
                        ],
                        "text": "TC efforts based on experimental DT packages include [Dumais et al. 1998; Lewis and Ringuette 1994; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 45
                            }
                        ],
                        "text": "In a number of experiments [Apte\u00b4et al. 1994; Dumais et al. 1998; Lewis 1992a], it \nhas been found that represen\u00adtations more sophisticated than this do not yield signi.cantly better effectiveness, \nthereby con.rming similar results from IR 4 An exception to this is represented by learning\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 365,
                                "start": 165
                            }
                        ],
                        "text": "2001; Larkey 1998; Lewis 1992a; Lewis and Ringuette 1994; Mladeni\u0107 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997; Yang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis and Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno 1999; Yang and Pedersen 1997], odds ratio [Caropreso et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 116
                            }
                        ],
                        "text": "The support vector machine (SVM) method has been introduced in TC by Joachims [1998, 1999] and subsequently used in [Drucker et al. 1999; Dumais et al. 1998; Dumais and Chen 2000; Klinkenberg and Joachims 2000; Taira and Haruno 1999; Yang and Liu 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "\u20261998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1843,
                                "start": 1835
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 27
                            }
                        ],
                        "text": "In a number of experiments [Apt\u00e9 et al. 1994; Dumais et al. 1998; Lewis 1992a] it has been found that representations more sophisticated than this do not yield significantly better effectiveness, thereby confirming similar results from IR [Salton and Buckley 1988]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 617436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02adea3455cd7b09e1dac9ddf2637a1e7ae84005",
            "isKey": true,
            "numCitedBy": 1291,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "1. ABSTRACT Text categorization \u2013 the assignment of natural language texts to one or more predefined categories based on their content \u2013 is an important component in many information organization and management tasks. We compare the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy. We also examine training set size, and alternative document representations. Very accurate text classifiers can be learned automatically from training examples. Linear Support Vector Machines (SVMs) are particularly promising because they are very accurate, quick to train, and quick to evaluate. 1.1"
            },
            "slug": "Inductive-learning-algorithms-and-representations-Dumais-Platt",
            "title": {
                "fragments": [],
                "text": "Inductive learning algorithms and representations for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A comparison of the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy is compared."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2745994"
                        ],
                        "name": "Luigi Galavotti",
                        "slug": "Luigi-Galavotti",
                        "structuredName": {
                            "firstName": "Luigi",
                            "lastName": "Galavotti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luigi Galavotti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35184435"
                        ],
                        "name": "M. Simi",
                        "slug": "M.-Simi",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Simi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Simi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14311264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9780dc6eaeb6e5c151a0d7993f414143420082cd",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We tackle two different problems of text categorization (TC), namely feature selection and classifier induction. Feature selection (FS) refers to the activity of selecting, from the set of r distinct features (i.e. words) occurring in the collection, the subset of r\u2032 \u226a r features that are most useful for compactly representing the meaning of the documents. We propose a novel FS technique, based on a simplified variant of the X2 statistics. Classifier induction refers instead to the problem of automatically building a text classifier by learning from a set of documents pre-classified under the categories of interest. We propose a novel variant, based on the exploitation of negative evidence, of the well-known k-NN method. We report the results of systematic experimentation of these two methods performed on the standard REUTERS-21578 benchmark."
            },
            "slug": "Experiments-on-the-Use-of-Feature-Selection-and-in-Galavotti-Sebastiani",
            "title": {
                "fragments": [],
                "text": "Experiments on the Use of Feature Selection and Negative Evidence in Automated Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a novel variant, based on the exploitation of negative evidence, of the well-known k-NN method, and reports the results of systematic experimentation of these two methods performed on the standard REUTERS-21578 benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "ECDL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789324"
                        ],
                        "name": "Isabelle Moulinier",
                        "slug": "Isabelle-Moulinier",
                        "structuredName": {
                            "firstName": "Isabelle",
                            "lastName": "Moulinier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Isabelle Moulinier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686738"
                        ],
                        "name": "J. Ganascia",
                        "slug": "J.-Ganascia",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ganascia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ganascia"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17719301,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28d7bc36509e6b0e3f2e890928ec9b1a8c9fb53e",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The information retrieval community is becoming increasingly interested in machine learning techniques, of which text categorization is an application. This paper describes how we have applied an existing similarity-based learning algorithm, Charade, to the text categorization problem and compares the results with those obtained using decision tree construction algorithms. From a machine learning point of view, this study was motivated by the size of the inspected data in such applications. Using the same representation of documents, Charade offers better performance than earlier reported experiments with decision trees on the same corpus. In addition, the way in which learning with redundancy influences categorization performance is also studied."
            },
            "slug": "Applying-an-existing-machine-learning-algorithm-to-Moulinier-Ganascia",
            "title": {
                "fragments": [],
                "text": "Applying an existing machine learning algorithm to text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper describes how an existing similarity-based learning algorithm, Charade, is applied to the text categorization problem and compares the results with those obtained using decision tree construction algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "Learning for Natural Language Processing"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117760"
                        ],
                        "name": "W. B. Cavnar",
                        "slug": "W.-B.-Cavnar",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cavnar",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. B. Cavnar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31419242"
                        ],
                        "name": "J. Trenkle",
                        "slug": "J.-Trenkle",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Trenkle",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Trenkle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 289
                            }
                        ],
                        "text": "2000; Schapire and Singer 2000], multimedia document categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author identification for literary texts of unknown or disputed authorship [Forsyth 1999], language identification for texts of unknown language [Cavnar and Trenkle 1994], automated identification of text genre [Kessler et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 148
                            }
                        ],
                        "text": "\u20262000], author \niden\u00adti.cation for literary texts of unknown or disputed authorship [Forsyth 1999], lan\u00adguage identi.cation \nfor texts of unknown language [Cavnar and Trenkle 1994], automated identi.cation of text genre [Kessler \net al. 1997], and automated essay grading [Larkey 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 170740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49af572ef8f7ea89db06d5e7b66e9369c22d7607",
            "isKey": false,
            "numCitedBy": 1816,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization is a fundamental task in document processing, allowing the automated handling of enormous streams of documents in electronic form. One difficulty in handling some classes of documents is the presence of different kinds of textual errors, such as spelling and grammatical errors in email, and character recognition errors in documents that come through OCR. Text categorization must work reliably on all input, and thus must tolerate some level of these kinds of problems. We describe here an N-gram-based approach to text categorization that is tolerant of textual errors. The system is small, fast and robust. This system worked very well for language classification, achieving in one test a 99.8% correct classification rate on Usenet newsgroup articles written in different languages. The system also worked reasonably well for classifying articles from a number of different computer-oriented newsgroups according to subject, achieving as high as an 80% correct classification rate. There are also several obvious directions for improving the system`s classification performance in those cases where it did not do as well. The system is based on calculating and comparing profiles of N-gram frequencies. First, we use the system to compute profiles on training set data that represent the variousmore\u00a0\u00bb categories, e.g., language samples or newsgroup content samples. Then the system computes a profile for a particular document that is to be classified. Finally, the system computes a distance measure between the document`s profile and each of the category profiles. The system selects the category whose profile has the smallest distance to the document`s profile. The profiles involved are quite small, typically 10K bytes for a category training set, and less than 4K bytes for an individual document. Using N-gram frequency profiles provides a simple and reliable way to categorize documents in a wide range of classification tasks.\u00ab\u00a0less"
            },
            "slug": "N-gram-based-text-categorization-Cavnar-Trenkle",
            "title": {
                "fragments": [],
                "text": "N-gram-based text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An N-gram-based approach to text categorization that is tolerant of textual errors is described, which worked very well for language classification and worked reasonably well for classifying articles from a number of different computer-oriented newsgroups according to subject."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793347"
                        ],
                        "name": "C. Y. Ho",
                        "slug": "C.-Y.-Ho",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Ho",
                            "middleNames": [
                                "Yang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Y. Ho"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 68
                            }
                        ],
                        "text": "A combination of profile- and example-based methods is presented in [Lam and Ho 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 144
                            }
                        ],
                        "text": "\u2026et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 17789045,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1acd80c22b99662c5850dcb683f1065c3ecfedaf",
            "isKey": true,
            "numCitedBy": 224,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate several recent approaches for text categorization under the framework of similaritybased learning. They include two families of text categorization techniques, namely the k-nearest neighbor (kNN) algorithm and linear classifiers. After identifying the weakness and strength of each technique, we propose a new technique known as the generalized instance set (GIS) algorithm by unifying the strengths of k-NN and linear classifiers and adapting to characteristics of text categorization problems. We also explore some variants of our GIS approach. We have implemented our GIS algorithm, the ExpNet algorithm, and some linear classifiers. Extensive experiments have been conducted on two common document corpora, namely the OHSUMED collection and the Reuters-21578 collection. The results show that our new approach outperforms the latest k-NN approach and linear classifiers in all experiments."
            },
            "slug": "Using-a-generalized-instance-set-for-automatic-text-Lam-Ho",
            "title": {
                "fragments": [],
                "text": "Using a generalized instance set for automatic text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a new technique known as the generalized instance set (GIS) algorithm by unifying the strengths of k-NN and linear classifiers and adapting to characteristics of text categorization problems."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879979"
                        ],
                        "name": "Jacqueline W. Wong",
                        "slug": "Jacqueline-W.-Wong",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Wong",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacqueline W. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586042"
                        ],
                        "name": "W. Kan",
                        "slug": "W.-Kan",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Kan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40120705"
                        ],
                        "name": "G. Young",
                        "slug": "G.-Young",
                        "structuredName": {
                            "firstName": "Gilbert",
                            "lastName": "Young",
                            "middleNames": [
                                "H.",
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 47
                            }
                        ],
                        "text": "Another non-learning classifier is proposed in [Wong et al. 1996]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2136617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82c8e93dea41398f9de8b627c91408e71aab6732",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "An important step in building up the document database of a full-text retrieval system is to classify each document under one or more classes according to the topical domains that the document discusses. This is commonly referred to as classification. Automatic classification attempts to replace human classifiers by using computers to automate this process. Automatic classification has two major components: (1) the classification scheme which defines the available classes under which a document can be classified and their inter-relationships; and (2) the classification algorithm which defines the rules and procedures for assigning one or more classes defined in the classification scheme to a document.In this paper, we present an automatic classification approach called ACTION. The design goal of ACTION is to achieve the appropriate balance between specificity and exhaustivity, which are important metrics for assessing an automatic classification approach. The key idea of ACTION is a scheme for measuring the significance of each keyword in a given document. The scheme not only takes into account the occurrence frequency of a keyword, but also the logical relationships between the available classes."
            },
            "slug": "ACTION:-automatic-classification-for-full-text-Wong-Kan",
            "title": {
                "fragments": [],
                "text": "ACTION: automatic classification for full-text documents"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The key idea of ACTION is a scheme for measuring the significance of each keyword in a given document that takes into account the occurrence frequency of a keyword, but also the logical relationships between the available classes."
            },
            "venue": {
                "fragments": [],
                "text": "SIGF"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093248943"
                        ],
                        "name": "Sam Scott",
                        "slug": "Sam-Scott",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Scott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam Scott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749003"
                        ],
                        "name": "S. Matwin",
                        "slug": "S.-Matwin",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Matwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Matwin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18493939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e518946c59c8c5d005054af319783b3eba128a9",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Most research in text classification to date has used a \u201cbag of words\u201d representation in which each feature corresponds to a single word. This paper examines some alternative ways to represent text based on syntactic and semantic relationships between words (phrases, synonyms and hypernyms). We describe the new representations and try to justify our hypothesis that they could improve the performance of a rule-based learner. The representations are evaluated using the RIPPER learning algorithm on the Reuters-21578 and DigiTrad test corpora. On their own the new representations are not found to produce significant performance improvements. We also try combining classifiers based on different representations using a majority voting technique, and this improves performance on both test collections. In our opinion, more sophisticated Natural Language Processing techniques need to be developed before better text representations can be produced for classification."
            },
            "slug": "Feature-Engineering-for-Text-Classification-Scott-Matwin",
            "title": {
                "fragments": [],
                "text": "Feature Engineering for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "More sophisticated Natural Language Processing techniques need to be developed before better text representations can be produced for classification."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 11
                            }
                        ],
                        "text": "5 (used in [Cohen and Hirsh 1998; Cohen and Singer 1999; Joachims 1998; Lewis and Catlett 1994]) and C5 (used in [Li and Jain 1998])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 203
                            }
                        ],
                        "text": "\u2026as well as their top performing \nsystem (a SVM classi.er), will probably renew the interest in decision trees, an interest that had dwindled \nafter the unimpres\u00adsive results reported in earlier litera\u00adture [Cohen and Singer 1999; Joachims 1998; \nLewis and Catlett 1994; Lewis and Ringuette 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 324,
                                "start": 319
                            }
                        ],
                        "text": "However, the work by Dumais et al. \n[1998], in which a decision tree classi.er was shown to perform nearly as well as their top performing \nsystem (a SVM classi.er), will probably renew the interest in decision trees, an interest that had dwindled \nafter the unimpres\u00adsive results reported in earlier litera\u00adture [Cohen and Singer 1999; Joachims 1998; \nLewis and Catlett 1994; Lewis and Ringuette 1994]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 37
                            }
                        ],
                        "text": "We call this policy CSV thresholding [Cohen and Singer 1999; Schapire et al. 1998; Wiener et al. 1995]; it is also called Scut in [Yang 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 123
                            }
                        ],
                        "text": "This is \nmost fre\u00adquently used for category-ranking classi.ers (see Lam et al. [1999]; Larkey and Croft [1996]; \nSchapire and Singer [2000]; Wiener et al. [1995])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 134
                            }
                        ],
                        "text": "These recent results will no doubt bring about a re\u00adnewed interest \nfor the Rocchio classi.er, previously considered an underperformer [Cohen and Singer 1999; Joachims 1998; \nLewis et al. 1996; Sch utze et al. 1995; Yang \u00a81999]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 200
                            }
                        ],
                        "text": "Other on-line methods for building text classi.ers are WIDROW-HOFF, a re.nement of it called \nEXPONENTIATED GRADIENT (both applied for the .rst time to TC in [Lewis et al. 1996]) and SLEEPING EXPERTS \n[Cohen and Singer 1999], a version of BALANCED WINNOW."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 149
                            }
                        ],
                        "text": "\u2026et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "For instance, \nSchapire and Singer [2000] classi.ed answers given to a phone operator s request How may I help you? \nso as to be able to route the call to a specialized operator according to call type."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 269
                            }
                        ],
                        "text": "In other words, \nthe semantics of a document is reduced to the collective lexical semantics of the terms that occur in \nit, thereby disregarding the issue of compositional semantics (an ex\u00adception are the representation techniques \nused for FOIL [Cohen 1995a] and SLEEPING EXPERTS [Cohen and Singer 1999])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 144
                            }
                        ],
                        "text": "\u2026SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 79
                            }
                        ],
                        "text": "Other works where \nutility is employed are Amati and Crestani [1999], Cohen and Singer [1999], Hull et al. [1996], Lewis \nand Catlett [1994], and Schapire et al. [1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 179
                            }
                        ],
                        "text": "DT text classi.ers have been used either as the main classi.cation \ntool [Fuhr et al. 1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classi.ers \n[Cohen and Singer 1999; Joachims 1998], or as members of classi.er committees [Li and Jain 1998; Schapire \nand Singer 2000; Weiss et al. 1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 114
                            }
                        ],
                        "text": "Among the most popular \nones are ID3 (used by Fuhr et al. [1991]), C4.5 (used by Cohen and Hirsh [1998], Cohen and Singer [1999], \nJoachims [1998], and Lewis and Catlett [1994]), and C5 (used by Li and Jain [1998])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 300,
                                "start": 277
                            }
                        ],
                        "text": "In other words, the semantics of a document is reduced to the collective lexical semantics of the terms that occur in it, thereby disregarding the issue of compositional semantics (an exception are the representation techniques used for Foil [Cohen 1995a] and Sleeping Experts [Cohen and Singer 1999])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 35
                            }
                        ],
                        "text": "1997], or as a baseline classifier [Cohen and Singer 1999; Galavotti et al. 2000; Joachims 1998; Lewis et al. 1996; Schapire and Singer 2000; Sch\u00fctze et al. 1995], or as a member of a classifier committee [Larkey and Croft 1996] (see Section 6."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 39
                            }
                        ],
                        "text": "In the BOOSTEXTER \nsystem [Schapire and Singer 2000], two different boosting al\u00adgorithms are tested, using a one-level decision \ntree weak learner."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 37
                            }
                        ],
                        "text": "MH committee \ncommittee [Schapire and Singer 2000] [Weiss et al. 1999] .860 .878 Bayesian net Bayesian net [Dumais \net al. 1998] [Lam et al. 1997] .542 (MF1) .800 .850 and Pedersen [1997].21 The documents are titles \nor title-plus-abstracts from medical journals (OHSUMED is actually a subset of the Medline document base); \n21 The OHSUMED collection may be freely down\u00adloaded for experimentation purposes from ftp:// medir.ohsu.edu/pub/ohsumed. \nthe categories are the postable terms of the MESH thesaurus. the 20 Newsgroups collection, set up by \nLang [1995] and used by Baker and McCallum [1998], Joachims [1997], McCallum and Nigam [1998], McCallum \net al. [1998], Nigam et al. ACM Computing Surveys, Vol. 34, No. 1, March 2002."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 316,
                                "start": 311
                            }
                        ],
                        "text": "If for |C| i=no values of the .i s n and P are ex\u00adactly equal, the .i s are set to the value for which \nn and P are closest, and an interpolated breakeven is computed as the average of the values of n and \nP.19 (3) The Ff function [van Rijsbergen 1979, Chapter 7], for some 0 :f:+. (e.g., Cohen [1995a]; Cohen \nand Singer [1999]; Lewis and Gale [1994]; Lewis [1995a]; Moulinier et al. [1996]; Ruiz and Srinivassan \n[1999]), where (f2 +1)nP Ff = f2n +P Here f may be seen as the relative de\u00adgree of importance attributed \nto n and P.If f =0 then Ff coincides with n, whereas if f =+.then Ff coincides with P."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 56
                            }
                        ],
                        "text": "The boosting method [Schapire et al. 1998; Schapire and Singer 2000] occupies a special place in the \nclassi\u00ad.er committees literature, since the k clas\u00adsi.ers s1, ..., sk forming the committee are obtained \nby the same learning method (here called the weak learner)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 398
                            }
                        ],
                        "text": "An approach similar to boosting was also em\u00adployed by Weiss et al. [1999], who experi\u00admented \nwith committees of decision trees each having an average of 16 leaves (and hence much more complex than \nthe sim\u00ad 15 Schapire et al. [1998] also showed that a simple modi.cation of this policy allows optimization \nof the classi.er based on utility (see Section 7.1.3). ple decision stumps used in Schapire and Singer \n[2000]), eventually combined by using the simple MV rule as a combi\u00adnation rule; similarly to boosting, \na mech\u00adanism for emphasising documents that have been misclassi.ed by previous de\u00adcision trees is used."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "[2000], and Schapire \nand Singer [2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 131
                            }
                        ],
                        "text": "The role of negative examples is usually deempha- Sebastiani sized, \nby setting f to a high value and \u00df to a low one (e.g., Cohen and Singer [1999], Ittner et al. [1995], \nand Joachims [1997] use f =16 and \u00df =4)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 42
                            }
                        ],
                        "text": "Other works where utility is employed are [Amati and Crestani 1999; Cohen and Singer 1999; Hull et al. 1996; Lewis and Catlett 1994; Schapire et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 120
                            }
                        ],
                        "text": "Similarly, when a document title is available, one can pay extra importance \nto the words it contains [Apt\u00b4 e et al. 1994; Cohen and Singer 1999; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 162
                            }
                        ],
                        "text": "Other applications we do not explicitly discuss are speech catego\u00adrization by \nmeans of a combination of speech recognition and TC [Myers et al. 2000; Schapire and Singer 2000], multi\u00admedia \ndocument categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author \niden\u00adti.cation for literary texts of unknown or disputed authorship [Forsyth 1999], lan\u00adguage identi.cation \nfor texts of unknown language [Cavnar and Trenkle 1994], automated identi.cation of text genre [Kessler \net al. 1997], and automated essay grading [Larkey 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 175
                            }
                        ],
                        "text": "Among \nthe DNF rule learners that have been applied to TC are CHARADE [Moulinier and Ganascia 1996], DL-ESC \n[Li and Yamanishi 1999], RIPPER [Cohen 1995a; Cohen and Hirsh 1998; Cohen and Singer 1999], SCAR [Moulinier \net al. 1996], and SWAP-1 [Apt\u00b4 e 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 150
                            }
                        ],
                        "text": "\u2026\nown right [Ittner et al. 1995; Joachims 1997; Sable and Hatzivassiloglou 2000; Schapire et al. 1998; \nSinghal et al. 1997], or as a base\u00adline classi.er [Cohen and Singer 1999; Galavotti et al. 2000; Joachims \n1998; Lewis et al. 1996; Schapire and Singer 2000; Sch \u00a8 utze et al. 1995], or as a\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 28
                            }
                        ],
                        "text": "1996]) and Sleeping Experts [Cohen and Singer 1999], a version of Balanced Winnow."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 360,
                                "start": 355
                            }
                        ],
                        "text": "In their experiments Ittner et al. [1995] have found that, by employing \nnoisy texts also in the training phase (i.e. texts af\u00adfected by the same source of noise that is also \nat work in the test documents), effectiveness levels comparable to those obtainable in the case of standard \ntext can be achieved. speech transcripts [Myers et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 101
                            }
                        ],
                        "text": "Similarly, when a document title is available, one can pay extra importance to the words it contains [Apt\u00e9 et al. 1994; Cohen and Singer 1999; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 130
                            }
                        ],
                        "text": "In experiments conducted over three different test collections, Schapire et al. [1998] have \nshown ADABOOST to outperform SLEEPING EXPERTS, a classi.er that had proven quite effective in the ex\u00adperiments \nof Cohen and Singer [1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 165
                            }
                        ],
                        "text": "The documents are messages posted to Usenet newsgroups, and the categories are the \nnewsgroups themselves. the AP collection, used by Cohen [1995a, 1995b], Cohen and Singer [1999], Lewis \nand Catlett [1994], Lewis and Gale [1994], Lewis et al. [1996], Schapire and Singer [2000], and Schapire \net al. [1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 134
                            }
                        ],
                        "text": "These recent results will no doubt bring about a renewed interest for the Rocchio classifier, previously considered an underperformer [Cohen and Singer 1999; Joachims 1998; Lewis et al. 1996; Sch\u00fctze et al. 1995; Yang 1999]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 301,
                                "start": 296
                            }
                        ],
                        "text": "This adaptation was .rst pro\u00adposed \nby Hull [1994], and has been used by many authors since then, either as an object of research in its \nown right [Ittner et al. 1995; Joachims 1997; Sable and Hatzivassiloglou 2000; Schapire et al. 1998; \nSinghal et al. 1997], or as a base\u00adline classi.er [Cohen and Singer 1999; Galavotti et al. 2000; Joachims \n1998; Lewis et al. 1996; Schapire and Singer 2000; Sch \u00a8 utze et al. 1995], or as a mem\u00adber of a classi.er \ncommittee [Larkey and Croft 1996] (see Section 6.11)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 1
                            }
                        ],
                        "text": "[Cohen and Singer 1999; Schapire et al. 1998; Wiener et al. 1995]; it is also \ncalled Scut in Yang [1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 100
                            }
                        ],
                        "text": "(2) The breakeven \npoint, that is, the value at which n equals P (e.g., Apte\u00b4et al. [1994]; Cohen and Singer [1999]; Dagan \net al. [1997]; Joachims [1998]; 17 While Pi can always be increased at will by low\u00adering .i , usually \nat the cost of decreasing ni , ni can usually be increased at will by raising .i , always at the cost \nof decreasing Pi ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 126
                            }
                        ],
                        "text": "[1998] have shown AdaBoost to outperform Sleeping Experts, a classifier that had proven quite effective in the experiments of [Cohen and Singer 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 182
                            }
                        ],
                        "text": "Other effectiveness measures different from the ones discussed here have occa\u00adsionally \nbeen used in the literature; these include adjacent score [Larkey 1998], coverage [Schapire and Singer \n2000], one\u00aderror [Schapire and Singer 2000], Pear\u00adson product-moment correlation [Larkey 1998], recall \nat n [Larkey and Croft 1996], top candidate [Larkey and Croft 1996], and top n [Larkey and Croft 1996]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 101
                            }
                        ],
                        "text": "Further experiments by Schapire and Singer [2000] showed ADABOOST to out\u00adperform, \naside from SLEEPING EXPERTS,a Na\u00a8 ive Bayes classi.er, a standard (nonen\u00adhanced) Rocchio classi.er, and \nJoachims [1997] PRTFIDF classi.er."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 84
                            }
                        ],
                        "text": "1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classifiers [Cohen and Singer 1999; Joachims 1998], or as members of classifier committees [Li and Jain 1998; Schapire and Singer 2000; Weiss et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 270
                            }
                        ],
                        "text": "\u2026words, \nthe semantics of a document is reduced to the collective lexical semantics of the terms that occur in \nit, thereby disregarding the issue of compositional semantics (an ex\u00adception are the representation techniques \nused for FOIL [Cohen 1995a] and SLEEPING EXPERTS [Cohen and Singer 1999])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 144
                            }
                        ],
                        "text": "\u2026CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 732,
                                "start": 725
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 151
                            }
                        ],
                        "text": "\u2026have been used either as the main classi.cation \ntool [Fuhr et al. 1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classi.ers \n[Cohen and Singer 1999; Joachims 1998], or as members of classi.er committees [Li and Jain 1998; Schapire \nand Singer 2000; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5327274,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce2d6de9cec4a6d135c32bb8d2d02bba09928b33",
            "isKey": true,
            "numCitedBy": 572,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": "Two recently implemented machine-learning algorithms, RIPPER and sleeping-experts for phrases, are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the \u201ccontext\u201d of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "slug": "Context-sensitive-learning-methods-for-text-Cohen-Singer",
            "title": {
                "fragments": [],
                "text": "Context-sensitive learning methods for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods and are viewed as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52835205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e020852e8e00ac1adba7201d96fe0f5beafd063e",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Two recently implemented machine-learning algorithms, RIPPERand sleeping-experts for phrases, are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the \u201ccontext\u201d of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "slug": "Context-sensitive-learning-methods-for-text-Cohen-Singer",
            "title": {
                "fragments": [],
                "text": "Context-sensitive learning methods for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods and are viewed as a confirmation of the usefulness of classifiers that represent contextual information."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25294406"
                        ],
                        "name": "R. Forsyth",
                        "slug": "R.-Forsyth",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Forsyth",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Forsyth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 219
                            }
                        ],
                        "text": "2000; Schapire and Singer 2000], multimedia document categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author identification for literary texts of unknown or disputed authorship [Forsyth 1999], language identification for texts of unknown language [Cavnar and Trenkle 1994], automated identification of text genre [Kessler et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 148
                            }
                        ],
                        "text": "\u2026through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author \niden\u00adti.cation for literary texts of unknown or disputed authorship [Forsyth 1999], lan\u00adguage identi.cation \nfor texts of unknown language [Cavnar and Trenkle 1994], automated identi.cation of text genre [Kessler\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59624916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30d997c5672a95ab881e57005a6744ac85018e8f",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "As more and more documents are held in machine-readable form, problems of efficient text processing and text analysis become more pressing. An important kind of text processing, which has recently attracted the attention of researchers in Artificial Intelligence (AI), is text categorization, e.g. automatically assigning news stories [11.5] or medical case notes [11.46] a suitable category code. However, classifying documents is not a new problem: workers in the field of stylometry have been grappling with it for more than a century. Typically, stylometers have given most attention to authorship attribution and used statistical methods, while AI-based research has concentrated on discrimination by subject matter, using machine-learning techniques. The present chapter reports several recent studies drawing on both these traditions. In addition, it investigates various methods of Textual Feature-Finding, i.e. methods of choosing textual features or attributes that: (1) do not depend on subjective judgement; (2) do not need knowledge sources external to the texts being analyzed, such as a computerized lexicon; (3) do not presume that the texts being studied are in English; and (4) do not assume that the word is the only possible textual unit."
            },
            "slug": "NEW-DIRECTIONS-IN-TEXT-CATEGORIZATION-Forsyth",
            "title": {
                "fragments": [],
                "text": "NEW DIRECTIONS IN TEXT CATEGORIZATION"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The present chapter investigates various methods of Textual Feature-Finding, i.e. methods of choosing textual features or attributes that do not depend on subjective judgement; do not need knowledge sources external to the texts being analyzed; and do not assume that the word is the only possible textual unit."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2752514"
                        ],
                        "name": "Elizabeth D. Liddy",
                        "slug": "Elizabeth-D.-Liddy",
                        "structuredName": {
                            "firstName": "Elizabeth",
                            "lastName": "Liddy",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elizabeth D. Liddy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40475640"
                        ],
                        "name": "Woojin Paik",
                        "slug": "Woojin-Paik",
                        "structuredName": {
                            "firstName": "Woojin",
                            "lastName": "Paik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Woojin Paik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2242807"
                        ],
                        "name": "E. S. Yu",
                        "slug": "E.-S.-Yu",
                        "structuredName": {
                            "firstName": "Edmund",
                            "lastName": "Yu",
                            "middleNames": [
                                "Szu-Li"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. S. Yu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14968958,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "353a7ccc1d55afc516dc527e2e69d2607022b73a",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The text categorization module described here provides a front-end filtering function for the larger DR-LINK text retrieval system [Liddy and Myaeing 1993]. The model evaluates a large incoming stream of documents to determine which documents are sufficiently similar to a profile at the broad subject level to warrant more refined representation and matching. To accomplish this task, each substantive word in a text is first categorized using a feature set based on the semantic Subject Field Codes (SFCs) assigned to individual word senses in a machine-readable dictionary. When tested on 50 user profiles and 550 megabytes of documents, results indicate that the feature set that is the basis of the text categorization module and the algorithm that establishes the boundary of categories of potentially relevant documents accomplish their tasks with a high level of performance.\nThis means that the category of potentially relevant documents for most profiles would contain at least 80% of all documents later determined to be relevant to the profile. The number of documents in this set would be uniquely determined by the system's category-boundary predictor, and this set is likely to contain less than 5% of the incoming stream of documents."
            },
            "slug": "Text-categorization-for-multiple-users-based-on-a-Liddy-Paik",
            "title": {
                "fragments": [],
                "text": "Text categorization for multiple users based on semantic features from a machine-readable dictionary"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The text categorization module described here provides a front-end filtering function for the larger DR-LINK text retrieval system to determine which documents are sufficiently similar to a profile at the broad subject level to warrant more refined representation and matching."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736370"
                        ],
                        "name": "D. Koller",
                        "slug": "D.-Koller",
                        "structuredName": {
                            "firstName": "Daphne",
                            "lastName": "Koller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Koller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764547"
                        ],
                        "name": "M. Sahami",
                        "slug": "M.-Sahami",
                        "structuredName": {
                            "firstName": "Mehran",
                            "lastName": "Sahami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sahami"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 53
                            }
                        ],
                        "text": "For other examples of significance testing in TC see [Cohen 1995a; Cohen 1995b; Cohen and Hirsh 1998; Joachims 1997; Koller and Sahami 1997; Lewis et al. 1996; Wiener et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 76
                            }
                        ],
                        "text": "Techniques exploiting this intuition in a TC context have been presented in [Dumais and Chen 2000; Chakrabarti et al. 1998a; Koller and Sahami 1997; McCallum et al. 1998; Ruiz and Srinivasan 1999; Weigend et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 160
                            }
                        ],
                        "text": "This may be the hardest route to follow, since this produces classifiers of higher computational cost and characterized by harder parameter estimation problems [Koller and Sahami 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 160
                            }
                        ],
                        "text": "This may be the hardest \nroute to follow, since this produces classi.ers of higher computational cost and characterized by harder \nparameter estimation prob\u00adlems [Koller and Sahami 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2112467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23354987095a8a9a283ce4c9a690522d6b11e2dd",
            "isKey": true,
            "numCitedBy": 1089,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "The proliferation of topic hierarchies for text documents has resulted in a need for tools that automatically classify new documents within such hierarchies. One can use existing classifiers by ignoring the hierarchical structure, treating the topics as separate classes. Unfortunately, in the context of text categorization, we are faced with a large number of classes and a huge number of relevant features needed to distinguish between them. Consequently, we are restricted to using only very simple classifiers, both because of computational cost and the tendency of complex models to overfit. We propose an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree. As we show, each of these smaller problems can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand. This set of relevant features varies widely throughout the hierarchy, so that, while the overall relevant feature set may be large, each classifier only examines a small subset. The use of reduced feature sets allows us to utilize more complex (probabilistic) models, without encountering the computational and robustness difficulties described above."
            },
            "slug": "Hierarchically-Classifying-Documents-Using-Very-Few-Koller-Sahami",
            "title": {
                "fragments": [],
                "text": "Hierarchically Classifying Documents Using Very Few Words"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes an approach that utilizes the hierarchical topic structure to decompose the classification task into a set of simpler problems, one at each node in the classification tree, which can be solved accurately by focusing only on a very small set of features, those relevant to the task at hand."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120100599"
                        ],
                        "name": "Xin Liu",
                        "slug": "Xin-Liu",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6465383,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43015e9790c812bdc25bf0539b2ee4055a1882a7",
            "isKey": false,
            "numCitedBy": 2969,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reports a controlled study with statistical signi cance tests on ve text categorization methods: the Support Vector Machines (SVM), a k-Nearest Neighbor (kNN) classi er, a neural network (NNet) approach, the Linear Leastsquares Fit (LLSF) mapping and a Naive Bayes (NB) classier. We focus on the robustness of these methods in dealing with a skewed category distribution, and their performance as function of the training-set category frequency. Our results show that SVM, kNN and LLSF signi cantly outperform NNet and NB when the number of positive training instances per category are small (less than ten), and that all the methods perform comparably when the categories are su ciently common (over 300 instances)."
            },
            "slug": "A-re-examination-of-text-categorization-methods-Yang-Liu",
            "title": {
                "fragments": [],
                "text": "A re-examination of text categorization methods"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The results show that SVM, kNN and LLSF signi cantly outperform NNet and NB when the number of positive training instances per category are small, and that all the methods perform comparably when the categories are over 300 instances."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067947117"
                        ],
                        "name": "Andrew Y. Ng",
                        "slug": "Andrew-Y.-Ng",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Ng",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Y. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 134
                            }
                        ],
                        "text": "One possible answer is to switch from an interpretation of N\u00e4\u0131ve Bayes in which documents are events to one in which terms are events [Baker and McCallum 1998; McCallum et al. 1998; Chakrabarti et al. 1998a; Guthrie et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 160
                            }
                        ],
                        "text": "One possible answer is to switch from an interpretation of Na\u00a8ive Bayes in which documents are events \nto one in which terms are events [Baker and McCallum 1998; McCallum et al. 1998; Chakrabarti et al. 1998a; \nGuthrie et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 76
                            }
                        ],
                        "text": "Techniques exploiting this intuition in a TC context have been presented in [Dumais and Chen 2000; Chakrabarti et al. 1998a; Koller and Sahami 1997; McCallum et al. 1998; Ruiz and Srinivasan 1999; Weigend et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 65
                            }
                        ],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used in [Baker and McCallum 1998; Joachims 1997; McCallum and Nigam 1998; McCallum et al. 1998; Nigam et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9086884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2671b151fad7e176176b35d425b2b6356ff4595",
            "isKey": true,
            "numCitedBy": 621,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "When documents are organized in a large number of topic categories, the categories are often arranged in a hierarchy. The U.S. patent database and Yahoo are two examples. This paper shows that the accuracy of a naive Bayes text classi er can be signi cantly improved by taking advantage of a hierarchy of classes. We adopt an established statistical technique called shrinkage that smoothes parameter estimates of a data-sparse child with its parent in order to obtain more robust parameter estimates. The approach is also employed in deleted interpolation, a technique for smoothing n-grams in language modeling for speech recognition. Our method scales well to large data sets, with numerous categories in large hierarchies. Experimental results on three real-world data sets from UseNet, Yahoo, and corporate web pages show improved performance, with a reduction in error up to 29% over the traditional at classi er."
            },
            "slug": "Improving-Text-Classification-by-Shrinkage-in-a-of-McCallum-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Improving Text Classification by Shrinkage in a Hierarchy of Classes"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows that the accuracy of a naive Bayes text classi er can be improved by taking advantage of a hierarchy of classes, and adopts an established statistical technique called shrinkage that smoothes parameter estimates of a data-sparse child with its parent in order to obtain more robust parameter estimates."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144295902"
                        ],
                        "name": "H. Borko",
                        "slug": "H.-Borko",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Borko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Borko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17003204"
                        ],
                        "name": "M. Bernick",
                        "slug": "M.-Bernick",
                        "structuredName": {
                            "firstName": "Myrna",
                            "lastName": "Bernick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bernick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12524579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "031dc9cc38bb9a1c4f868d5822f8334610280658",
            "isKey": false,
            "numCitedBy": 176,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Starting with a collection of 405 document abstracts dealing with computers, the experiment in automatic document classification proceeds to construct an empirically based mathematically derived classification system by use of a factor analysis technique. The documents are then classified into these derived categories by five subjects, and the resulting classification serves as a criterion against which the automatic classification is to be evaluated. Of the ninety documents in the Validation Group which contained two or more clue words, and which therefore could be automatically classified, 44 documents, or 48.9%, were placed into their correct categories by use of a computer formula. These results are almost identical to the results obtained by Maron in a previous experiment using the same data but with a different set of classification categories and a different computational formula. The experimental evidence supports the conclusion that automatic document classification is possible. Additional experiments are described which when executed should improve the accuracy of the automatic classification technique. (Author)"
            },
            "slug": "Automatic-Document-Classification-Borko-Bernick",
            "title": {
                "fragments": [],
                "text": "Automatic Document Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Of the ninety documents in the Validation Group which contained two or more clue words, and which could be automatically classified, 44 documents, or 48.9%, were placed into their correct categories by use of a computer formula."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1963
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14637549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b02d18edb2284b35b5ca234fc3eda017f107da83",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Information Retrieval (IR), broadly intended as the discipline concerned with computerized access to data with poorly understood semantics, has grown in the last decade from a relatively small academic specialty to a richly articulated field at the forefront of computer science. The most conspicuous trend of the '90s within IR, aside from the emergence of Web search engines, has been the proliferation of a number of subtasks that depart from the mainstream \" text search \" paradigm, and tackle information access and use from a larger perspective. Tasks such as automated text categorization, information filtering (or routing), information extraction , text mining, question answering, text summarization, and topic (or event) detection and tracking, are no longer the \" next frontier \" of IR, but have become its pulsating heart. Central to the development of these novel (or relatively novel) IR tasks is the application of techniques from machine learning (ML). The key idea is that there is a lot of knowledge out there that can be brought to bear on information access tasks, but this knowledge hardly ever comes in the form of a systematized knowledge base, since such knowledge bases have to be manually built, and for most applications are thus unavailable or too costly to develop. Rather, knowledge manifests itself in the data, and has to be extracted from it; the shift of focus is thus from an \" intensional \" to an \" extensional \" notion of semantics, whereby the semantics of a concept is no more a declarative description of it or a set of rules for recognizing its instances, but is the set of contexts (e.g. documents) in which it is instantiated. In this setting, the goal of ML techniques is to help structure data in various respects. Probably the best known among the disciplines that lie at the crossroads of IR and ML is Automated Text Categorization (ATC), the task of building software tools capable of classifying text documents under one or more of a set of predefined categories or subject codes. ATC dates back to the early '60s, when it was mainly viewed as a means to alleviate the task of indexing scientific literature by controlled vocabulary terms. However, it was only in the early '90s that ATC fully flourished, under the pressure caused by the increased availability of ever larger numbers of text documents in digital form and by the ensuing need \u2026"
            },
            "slug": "Guest-Editors'-Introduction-to-the-Special-Issue-on-Joachims-Sebastiani",
            "title": {
                "fragments": [],
                "text": "Guest Editors' Introduction to the Special Issue on Automated Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Information Retrieval (IR), broadly intended as the discipline concerned with computerized access to data with poorly understood semantics, has grown in the last decade from a relatively small academic specialty to a richly articulated field at the forefront of computer science."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Intelligent Information Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16041292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc8e59e4c7c2cbb6695ee5488aa569780449b212",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Expert Network (ExpNet) is our new approach to automatic categorization and retrieval of natural language texts. We use a training set of texts with expert-assigned categories to construct a network which approximately reflects the conditional probabilities of categories given a text. The input nodes of the network are words in the training texts, the nodes on the intermediate level are the training texts, and the output nodes are categories. The links between nodes are computed based on statistics of the word distribution and the category distribution over the training set. ExpNet is used for relevance ranking of candidate categories of an arbitrary text in the case of text categorization, and for relevance ranking of documents via categories in the case of text retrieval. We have evaluated ExpNet in categorization and retrieval on a document collection of the MEDLINE database, and observed a performance in recall and precision comparable to the Linear Least Squares Fit (LLSF) mapping method, and significantly better than other methods tested. Computationally, ExpNet has an O(N 1og N) time complexity which is much more efficient than the cubic complexity of the LLSF method. The simplicity of the model, the high recall-precision rates, and the efficient computation together make ExpNet preferable as a practical solution for real-world applications."
            },
            "slug": "Expert-network:-effective-and-efficient-learning-in-Yang",
            "title": {
                "fragments": [],
                "text": "Expert network: effective and efficient learning from human decisions in text categorization and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The simplicity of the model, the high recall-precision rates, and the efficient computation together make ExpNet preferable as a practical solution for real-world applications."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17559593"
                        ],
                        "name": "Karen A. Hamill",
                        "slug": "Karen-A.-Hamill",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Hamill",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen A. Hamill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143688931"
                        ],
                        "name": "Antonio Zamora",
                        "slug": "Antonio-Zamora",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Zamora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Zamora"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The first use to which automatic text classifiers were put at, and the application that spawned most of the early research in the field [Borko and Bernick 1963; Fangmeyer and Lustig 1968; Field 1975; Gray and Harley 1971; Hamill and Zamora 1978; Hamill and Zamora 1980; Heaps 1973; Hoyle 1973; Klingbiel 1973a; Klingbiel 1973b; Maron 1961], is that of automatic document indexing for use in information retrieval (IR) systems relying on a controlled dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This is exemplified by the well-known phenomenon of inter-indexer inconsistency [Cleverdon 1984; Hamill and Zamora 1980]: when two different humans must take a decision on whether to classify document dj under category ci, they may disagree, and this in fact happens with relatively high frequency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35392792,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0eb4d0b059058b6ab39dd1660d91789d63a5e485",
            "isKey": false,
            "numCitedBy": 33,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "An experimental computer program has been developed to classify documents according to the 80 sections and five major section groupings of Chemical Abstracts (CA). The program uses pattern recognition techniques supplemented by heuristics. During the \u201ctraining\u201d phase, words from pre\u2010classified documents are selected, and the probability of occurrence of each word in each section of CA is computed and stored in a reference dictionary. The \u201cclassification\u201d phase matches each word of a document title against the dictionary and assigns a section number to the document using weights derived from the probabilities in the dictionary. Heuristic techniques are used to normalize word variants such as plurals, past tenses, and gerunds in both the training phase and the classification phase. The dictionary lookup technique is supplemented by the analysis of chemical nomenclature terms into their component word roots to influence the section to which the documents are assigned. Program performance and human consistency have been evaluated by comparing the program results against the published sections of CA and by conducting an experiment with people experienced in the assignment of documents to CA sections. The program assigned approximately 78% of the documents to the correct major section groupings of CA and 67% of the correct sections or cross\u2010references at a rate of 100 documents per second."
            },
            "slug": "The-use-of-titles-for-automatic-document-Hamill-Zamora",
            "title": {
                "fragments": [],
                "text": "The use of titles for automatic document classification"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An experimental computer program has been developed to classify documents according to the 80 sections and five major section groupings of Chemical Abstracts (CA) using pattern recognition techniques supplemented by heuristics."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255005"
                        ],
                        "name": "Alessandro Vullo",
                        "slug": "Alessandro-Vullo",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vullo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Vullo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1042533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad31ce43522928bc272d0d2d3d543530ed6438b5",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization is typically formulated as a concept learning prob lem where each instance is a single isolated document. In this paper we are interested in a more general formulation where documents are organized as page sequences, as naturally occurring in digital libraries of scanned books and magazines. We describe a method for classifying pages of sequential OCR text documents into one of several assigned categories and suggest that taking into account contextual information provided by the whole page sequence can significantly improve classification accuracy. The proposed architecture relies on hidden Markov models whose emissions are bag-of-words according to a multinomial word event model, as in the generative portion of the Naive Bayes classifier. Our results on a collection of scanned journals from the Making of America project confirm the importance of using whole page sequences. Empirical evaluation indicates that the error rate (as obtained by running a plain Naive Bayes classifier on isolated page) can be roughly reduced by half if contextual information is incorporated."
            },
            "slug": "Text-categorization-for-multi-page-documents:-a-HMM-Frasconi-Soda",
            "title": {
                "fragments": [],
                "text": "Text categorization for multi-page documents: a hybrid naive Bayes HMM approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A method for classifying pages of sequential OCR text documents into one of several assigned categories is described and it is suggested that taking into account contextual information provided by the whole page sequence can significantly improve classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "JCDL '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60458454,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "69859be3ea6cb8eb38434c80fef5d4997eaec2dc",
            "isKey": false,
            "numCitedBy": 452,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation introduces a new theoretical model for text classification systems, including systems for document retrieval, automated indexing, electronic mail filtering, and similar tasks. The Concept Learning model emphasizes the role of manual and automated feature selection and classifier formation in text classification. It enables drawing on results from statistics and machine learning in explaining the effectiveness of alternate representations of text, and specifies desirable characteristics of text representations. \nThe use of syntactic parsing to produce indexing phrases has been widely investigated as a possible route to better text representations. Experiments with syntactic phrase indexing, however, have never yielded significant improvements in text retrieval performance. The Concept Learning model suggests that the poor statistical characteristics of a syntactic indexing phrase representation negate its desirable semantic characteristics. The application of term clustering to this representation to improve its statistical properties while retaining its desirable meaning properties is proposed. \nStandard term clustering strategies from information retrieval (IR), based on cooccurrence of indexing terms in documents or groups of documents, were tested on a syntactic indexing phrase representation. In experiments using a standard text retrieval test collection, small effectiveness improvements were obtained. \nAs a means of evaluating representation quality, a text retrieval test collection introduces a number of confounding factors. In contrast, the text categorization task allows much cleaner determination of text representation properties. In preparation for the use of text categorization to study text representation, a more effective and theoretically well-founded probabilistic text categorization algorithm was developed, building on work by Maron, Fuhr, and others. \nText categorization experiments supported a number of predictions of the Concept Learning model about properties of phrasal representations, including dimensionality properties not previously measured for text representations. However, in carefully controlled experiments using syntactic phrases produced by Church's stochastic bracketer, in conjunction with reciprocal nearest neighbor clustering, term clustering was found to produce essentially no improvement in the properties of the phrasal representation. New cluster analysis approaches are proposed to remedy the problems found in traditional term clustering methods."
            },
            "slug": "Representation-and-Learning-in-Information-Lewis",
            "title": {
                "fragments": [],
                "text": "Representation and Learning in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new theoretical model for text classification systems, including systems for document retrieval, automated indexing, electronic mail filtering, and similar tasks, is introduced, suggesting that the poor statistical characteristics of a syntactic indexing phrase representation negate its desirable semantic characteristics."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34789794"
                        ],
                        "name": "H. Ng",
                        "slug": "H.-Ng",
                        "structuredName": {
                            "firstName": "Hwee",
                            "lastName": "Ng",
                            "middleNames": [
                                "Tou"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399346520"
                        ],
                        "name": "Wei Boon Goh",
                        "slug": "Wei-Boon-Goh",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Goh",
                            "middleNames": [
                                "Boon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Boon Goh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400215485"
                        ],
                        "name": "Kok Leong Low",
                        "slug": "Kok-Leong-Low",
                        "structuredName": {
                            "firstName": "Kok",
                            "lastName": "Low",
                            "middleNames": [
                                "Leong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kok Leong Low"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3366452,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c97e8fcd80d9a3779826f2930724c9d789faa05",
            "isKey": false,
            "numCitedBy": 552,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an automated learning approach to text categorization based on perception learning and a new feature selection metric, called correlation coefficient. Our approach has been teated on the standard Reuters text categorization collection. Empirical results indicate that our approach outperforms the best published results on this % uters collection. In particular, our new feature selection method yields comiderable improvement. We also investigate the usability of our automated hxu-n~ approach by actually developing a system that categorizes texts into a treeof categories. We compare tbe accuracy of our learning approach to a rrddmsed, expert system ap preach that uses a text categorization shell built by Cams gie Group. Although our automated learning approach still gives a lower accuracy, by appropriately inmrporating a set of manually chosen worda to use as f~ures, the combined, semi-automated approach yields accuracy close to the * baaed approach."
            },
            "slug": "Feature-selection,-perceptron-learning,-and-a-case-Ng-Goh",
            "title": {
                "fragments": [],
                "text": "Feature selection, perceptron learning, and a usability case study for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "An automated learning approach to text categorization based on perception learning and a new feature selection metric, called correlation coefficient, is described and empirical results indicate that this approach outperforms the best published results on this % uters collection."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732997"
                        ],
                        "name": "M. Rodr\u00edguez",
                        "slug": "M.-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Rodr\u00edguez",
                            "middleNames": [
                                "de",
                                "Buenaga"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2045680"
                        ],
                        "name": "J. M. G. Hidalgo",
                        "slug": "J.-M.-G.-Hidalgo",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Hidalgo",
                            "middleNames": [
                                "Mar\u00eda",
                                "G\u00f3mez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. M. G. Hidalgo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398602510"
                        ],
                        "name": "B. D\u00edaz-Agudo",
                        "slug": "B.-D\u00edaz-Agudo",
                        "structuredName": {
                            "firstName": "Bel\u00e9n",
                            "lastName": "D\u00edaz-Agudo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. D\u00edaz-Agudo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3265397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a24be92f23e7d2b07c7a1396d401a058870bb5f",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic Text Categorization (TC) is a complex and useful task for many natural language applications, and is usually performed through the use of a set of manually classified documents, a training collection. We suggest the utilization of additional resources like lexical databases to increase the amount of information that TC systems make use of, and thus, to improve their performance. Our approach integrates WordNet information with two training approaches through the Vector Space Model. The training approaches we test are the Rocchio (relevance feedback) and the Widrow-Hoff (machine learning) algorithms. Results obtained from evaluation show that the integration of WordNet clearly outperforms training approaches, and that an integrated technique can effectively address the classification of low frequency categories."
            },
            "slug": "Using-WordNet-to-Complement-Training-Information-in-Rodr\u00edguez-Hidalgo",
            "title": {
                "fragments": [],
                "text": "Using WordNet to Complement Training Information in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work integrates WordNet information with two training approaches through the Vector Space Model and shows that the integration of WordNet clearly outperforms training approaches, and that an integrated technique can effectively address the classification of low frequency categories."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7465342"
                        ],
                        "name": "Ido Dagan",
                        "slug": "Ido-Dagan",
                        "structuredName": {
                            "firstName": "Ido",
                            "lastName": "Dagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ido Dagan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47137139"
                        ],
                        "name": "Yael Karov",
                        "slug": "Yael-Karov",
                        "structuredName": {
                            "firstName": "Yael",
                            "lastName": "Karov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yael Karov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 497031,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "78686d02b1c4c3ac4fca5f27d7f562c0dcb31d58",
            "isKey": false,
            "numCitedBy": 224,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning problems in the text processing domain often map the text to a space whose dimensions are the measured features of the text, e.g., its words. Three characteristic properties of this domain are (a) very high dimensionality, (b) both the learned concepts and the instances reside very sparsely in the feature space, and (c) a high variation in the number of active features in an instance. In this work we study three mistake-driven learning algorithms for a typical task of this nature -- text categorization. We argue that these algorithms -- which categorize documents by learning a linear separator in the feature space -- have a few properties that make them ideal for this domain. We then show that a quantum leap in performance is achieved when we further modify the algorithms to better address some of the specific characteristics of the domain. In particular, we demonstrate (1) how variation in document length can be tolerated by either normalizing feature weights or by using negative weights, (2) the positive effect of applying a threshold range in training, (3) alternatives in considering feature frequency, and (4) the benefits of discarding features while training. Overall, we present an algorithm, a variation of Littlestone's Winnow, which performs significantly better than any other algorithm tested on this task using a similar feature set."
            },
            "slug": "Mistake-Driven-Learning-in-Text-Categorization-Dagan-Karov",
            "title": {
                "fragments": [],
                "text": "Mistake-Driven Learning in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work studies three mistake-driven learning algorithms for a typical task of this nature -- text categorization and presents an algorithm, a variation of Littlestone's Winnow, which performs significantly better than any other algorithm tested on this task using a similar feature set."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688235"
                        ],
                        "name": "P. Frasconi",
                        "slug": "P.-Frasconi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Frasconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frasconi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2540925"
                        ],
                        "name": "G. Soda",
                        "slug": "G.-Soda",
                        "structuredName": {
                            "firstName": "Giovanni",
                            "lastName": "Soda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Soda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255005"
                        ],
                        "name": "Alessandro Vullo",
                        "slug": "Alessandro-Vullo",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vullo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Vullo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 271
                            }
                        ],
                        "text": "\u2026it \nhas been found that represen\u00adtations more sophisticated than this do not yield signi.cantly better effectiveness, \nthereby con.rming similar results from IR 4 An exception to this is represented by learning ap\u00adproaches \nbased on hidden Markov models [Denoyer et al. 2001; Frasconi et al. 2002]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 4400391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8276ca615db0d6e38214524a544dd36ce9154086",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "In the traditional setting, text categorization is formulated as a concept learning problem where each instance is a single isolated document. However, this perspective is not appropriate in the case of many digital libraries that offer as contents scanned and optically read books or magazines. In this paper, we propose a more general formulation of text categorization, allowing documents to be organized as sequences of pages. We introduce a novel hybrid system specifically designed for multi-page text documents. The architecture relies on hidden Markov models whose emissions are bag-of-words resulting from a multinomial word event model, as in the generative portion of the Naive Bayes classifier. The rationale behind our proposal is that taking into account contextual information provided by the whole page sequence can help disambiguation and improves single page classification accuracy. Our results on two datasets of scanned journals from the Making of America collection confirm the importance of using whole page sequences. The empirical evaluation indicates that the error rate (as obtained by running the Naive Bayes classifier on isolated pages) can be significantly reduced if contextual information is incorporated."
            },
            "slug": "Hidden-Markov-Models-for-Text-Categorization-in-Frasconi-Soda",
            "title": {
                "fragments": [],
                "text": "Hidden Markov Models for Text Categorization in Multi-Page Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel hybrid system specifically designed for multi-page text documents, relying on hidden Markov models whose emissions are bag-of-words resulting from a multinomial word event model, as in the generative portion of the Naive Bayes classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Intelligent Information Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792682"
                        ],
                        "name": "C. Chute",
                        "slug": "C.-Chute",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Chute",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chute"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16063479,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f926a0022e794485ec469124894aaaf29b087d70",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A unified model for text categorization and text retrieval is introduced. We use a training set of manually categorized documents to learn word-category associations, and use these associations to predict the categories of arbitrary documents. Similarly, we use a training set of queries and their related documents to obtain empirical associations between query words and indexing terms of documents, and use these associations to predict the related documents of arbitrary queries. A Linear Least Squares Fit (LLSF) technique is employed to estimate the likelihood of these associations. Document collections from the MEDLINE database and Mayo patient records are used for studies on the effectiveness of our approach, and on how much the effectiveness depends on the choices of training data, indexing language, word-weighting scheme, and morphological canonicalization. Alternative methods are also tested on these data collections for comparison. It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language. Such a semantic mapping lead to a significant improvement in categorization and retrieval, compared to alternative approaches."
            },
            "slug": "An-example-based-mapping-method-for-text-and-Yang-Chute",
            "title": {
                "fragments": [],
                "text": "An example-based mapping method for text categorization and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125121"
                        ],
                        "name": "Hirotoshi Taira",
                        "slug": "Hirotoshi-Taira",
                        "structuredName": {
                            "firstName": "Hirotoshi",
                            "lastName": "Taira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hirotoshi Taira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47348275"
                        ],
                        "name": "M. Haruno",
                        "slug": "M.-Haruno",
                        "structuredName": {
                            "firstName": "Masahiko",
                            "lastName": "Haruno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Haruno"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3142786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c026ffbd40e4beb386c18946e9079fac5da4afc0",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper investigates the effect of prior feature selection in Support Vector Machine (SVM) text categorization. The input space was gradually increased by using mutual information (MI) filtering and part-of-speech (POS) filtering, which determine the portion of words that are appropriate for learning from the information-theoretic and the linguistic perspectives, respectively. We tested the two filtering methods on SVMs as well as a decision tree algorithm C4.5. The SVMs' results common to both filtering are that 1) the optimal number of features differed completely across categories, and 2) the average performance for all categories was best when all of the words were used. In addition, a comparison of the two filtering methods clarified that POS filtering on SVMs consistently outperformed MI filtering, which indicates that SVMs cannot find irrelevant parts of speech. These results suggest a simple strategy for the SVM text categorization: use a full number of words found through a rough filtering technique like part-of-speech tagging."
            },
            "slug": "Feature-Selection-in-SVM-Text-Categorization-Taira-Haruno",
            "title": {
                "fragments": [],
                "text": "Feature Selection in SVM Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Results suggest a simple strategy for the SVM text categorization: use a full number of words found through a rough filtering technique like part-of-speech tagging, which indicates that SVMs cannot find irrelevant parts of speech."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 915058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5194b668c67aa83c037e71599a087f63c98eb713",
            "isKey": false,
            "numCitedBy": 2404,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "slug": "A-sequential-algorithm-for-training-text-Lewis-Gale",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task and reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1925215"
                        ],
                        "name": "W. Lehnert",
                        "slug": "W.-Lehnert",
                        "structuredName": {
                            "firstName": "Wendy",
                            "lastName": "Lehnert",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Lehnert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2497200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54aa030597d0211d1a2f27fe1711cc27ab0b0349",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to text classification that represents a compromise between traditional word-based techniques and in-depth natural language processing. Our approach uses a natural language processing task called \u201cinformation extraction\u201d as a basis for high-precision text classification. We present three algorithms that use varying amounts of extracted information to classify texts. The relevancy signatures algorithm uses linguistic phrases; the augmented relevancy signatures algorithm uses phrases and local context; and the case-based text classification algorithm uses larger pieces of context. Relevant phrases and contexts are acquired automatically using a training corpus. We evaluate the algorithms on the basis of two test sets from the MUC-4 corpus. All three algorithms achieved high precision on both test sets, with the augmented relevancy signatures algorithm and the case-based algorithm reaching 100% precision with over 60% recall on one set. Additionally, we compare the algorithms on a larger collection of 1700 texts and describe an automated method for empirically deriving appropriate threshold values. The results suggest that information extraction techniques can support high-precision text classification and, in general, that using more extracted information improves performance. As a practical matter, we also explain how the text classification system can be easily ported across domains."
            },
            "slug": "Information-extraction-as-a-basis-for-text-Riloff-Lehnert",
            "title": {
                "fragments": [],
                "text": "Information extraction as a basis for high-precision text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An approach to text classification that represents a compromise between traditional word-based techniques and in-depth natural language processing and an automated method for empirically deriving appropriate threshold values is described."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49666627"
                        ],
                        "name": "Giuseppe Attardi",
                        "slug": "Giuseppe-Attardi",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Attardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Giuseppe Attardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8779131"
                        ],
                        "name": "Antonio Gull\u00ec",
                        "slug": "Antonio-Gull\u00ec",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Gull\u00ec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antonio Gull\u00ec"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[Attardi et al. 1999; Baker and McCallum 1998; Chakrabarti et al. 1998; McCallum et al. 1998; Mladeni\u0107 1998b]), and will be more extensively discussed in Section 9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2480084,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45b3a973887b1919e3143dba91cdd696407cbe2e",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Assistance in retrieving documents on the World Wide Web is provided either by search engines, through keyword-based queries, or by catalogues, which organize documents into hierarchical collections. Maintaining catalogues manually is becoming increasingly difficult, due to the sheer amount of material on the Web; it is thus becoming necessary to resort to techniques for the automatic classification of documents. Automatic classification is traditionally performed by extracting the information for representing a document (\u201cindexing\u201d) from the document itself. The paper describes the novel technique of categorization by context, which instead extracts useful information for classifying a document from the context where a URL referring to it appears. We present the results of experimenting with Theseus, a classifier that exploits this technique."
            },
            "slug": "Automatic-Web-Page-Categorization-by-Link-and-Attardi-Gull\u00ec",
            "title": {
                "fragments": [],
                "text": "Automatic Web Page Categorization by Link and Context Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The paper describes the novel technique of categorization by context, which instead extracts useful information for classifying a document from the context where a URL referring to it appears, and presents the results of experimenting with Theseus, a classifier that exploits this technique."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889602"
                        ],
                        "name": "Erik D. Wiener",
                        "slug": "Erik-D.-Wiener",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Wiener",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik D. Wiener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14603963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acf17f7365669ab9aceabc5f1760ef20898254fa",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "With the recent dramatic increase in electronic access to documents, text categorization\u2014the task of assigning topics to a given document\u2014has moved to the center of the information sciences and knowledge management. This article uses the structure that is present in the semantic space of topics in order to improve performance in text categorization: according to their meaning, topics can be grouped together into \u201cmeta-topics\u201d, e.g., gold, silver, and copper are all metals. The proposed architecture matches the hierarchical structure of the topic space, as opposed to a flat model that ignores the structure. It accommodates both single and multiple topic assignments for each document. Its probabilistic interpretation allows its predictions to be combined in a principled way with information from other sources. The first level of the architecture predicts the probabilities of the meta-topic groups. This allows the individual models for each topic on the second level to focus on finer discriminations within the group. Evaluating the performance of a two-level implementation on the Reuters-22173 testbed of newswire articles shows the most significant improvement for rare classes."
            },
            "slug": "Exploiting-Hierarchy-in-Text-Categorization-Weigend-Wiener",
            "title": {
                "fragments": [],
                "text": "Exploiting Hierarchy in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The structure that is present in the semantic space of topics is used in order to improve performance in text categorization: according to their meaning, topics can be grouped together into \u201cmeta-topics\u201d, e.g., gold, silver, and copper are all metals."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749815"
                        ],
                        "name": "A. Sperduti",
                        "slug": "A.-Sperduti",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Sperduti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sperduti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770301"
                        ],
                        "name": "Nicola Valdambrini",
                        "slug": "Nicola-Valdambrini",
                        "structuredName": {
                            "firstName": "Nicola",
                            "lastName": "Valdambrini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicola Valdambrini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u2026literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 228058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13aa34092cdd1ca854ca5e5c0ce434b846ec8211",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an improved boosting algorithm, called {\\sc AdaBoost.MH$^{KR}$}, and its application to text categorization. Boosting is a method for supervised learning which has successfully been applied to many different domains, and that has proven one of the best performers in text categorization exercises so far. Boosting is based on the idea of relying on the collective judgment of a committee of classifiers that are trained sequentially. In training the $i$-th classifier special emphasis is placed on the correct categorization of the training documents which have proven harder for the previously trained classifiers. {\\sc AdaBoost.MH$^{KR}$} is based on the idea to build, at every iteration of the learning phase, not a single classifier but a sub-committee of the $K$ classifiers which, at that iteration, look the most promising. We report the results of systematic experimentation of this method performed on the standard {\\sf Reuters-21578} benchmark. These experiments have shown that {\\sc AdaBoost.MH$^{KR}$} is both more efficient to train and more effective than the original {\\sc AdaBoost.MH$^{R}$} algorithm."
            },
            "slug": "An-improved-boosting-algorithm-and-its-application-Sebastiani-Sperduti",
            "title": {
                "fragments": [],
                "text": "An improved boosting algorithm and its application to text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "An improved boosting algorithm, called {\\sc AdaBoost.MH$^{KR}$}, is described, and its application to text categorization is described and shown to be both more efficient to train and more effective than the original Ada boost.MH algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144947410"
                        ],
                        "name": "R. Agrawal",
                        "slug": "R.-Agrawal",
                        "structuredName": {
                            "firstName": "Rakesh",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145503401"
                        ],
                        "name": "P. Raghavan",
                        "slug": "P.-Raghavan",
                        "structuredName": {
                            "firstName": "Prabhakar",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Raghavan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 862030,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2ace1134350e37d1ed8ab765140a3a48079cc16",
            "isKey": false,
            "numCitedBy": 275,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. We explore how to organize large text databases hierarchically by topic to aid better searching, browsing and filtering. Many corpora, such as internet directories, digital libraries, and patent databases are manually organized into topic hierarchies, also called taxonomies. Similar to indices for relational data, taxonomies make search and access more efficient. However, the exponential growth in the volume of on-line textual information makes it nearly impossible to maintain such taxonomic organization for large, fast-changing corpora by hand.\nWe describe an automatic system that starts with a small sample of the corpus in which topics have been assigned by hand, and then updates the database with new documents as the corpus grows, assigning topics to these new documents with high speed and accuracy.\nTo do this, we use techniques from statistical pattern recognition to efficiently separate the feature words, or discriminants, from thenoise words at each node of the taxonomy. Using these, we build a multilevel classifier. At each node, this classifier can ignore the large number of \u201cnoise\u201d words in a document. Thus, the classifier has a small model size and is very fast. Owing to the use of context-sensitive features, the classifier is very accurate. As a by-product, we can compute for each document a set of terms that occur significantly more often in it than in the classes to which it belongs.\nWe describe the design and implementation of our system, stressing how to exploit standard, efficient relational operations like sorts and joins. We report on experiences with the Reuters newswire benchmark, the US patent database, and web document samples from Yahoo!. We discuss applications where our system can improve searching and filtering capabilities."
            },
            "slug": "Scalable-feature-selection,-classification-and-for-Chakrabarti-Dom",
            "title": {
                "fragments": [],
                "text": "Scalable feature selection, classification and signature generation for organizing large text databases into hierarchical topic taxonomies"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An automatic system that starts with a small sample of the corpus in which topics have been assigned by hand, and then updates the database with new documents as the corpus grows, assigning topics to these new documents with high speed and accuracy is described."
            },
            "venue": {
                "fragments": [],
                "text": "The VLDB Journal"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Similarly, an e-mail filter might be trained to further classify previously filtered e-mail into topical categories of interest to the user [Cohen 1996]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12621391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f02948f2976991bb76419775f303c27fc8afb7b5",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Two methods for learning text classifiers are compared on classification problems that might arise in filtering and filing personM e-mail messages: a \"traxiitionM IR\" method based on TF-IDF weighting, and a new method for learning sets of \"keyword-spotting rules\" based on the RIPPER rule learning algorithm. It is demonstrated that both methods obtain significant generalizations from a small number of examples; that both methods are comparable in generalization performance on problems of this type; and that both methods axe reasonably efficient, even with fairly large training sets. However, the greater comprehensibility of the rules may be advantageous in a system that allows users to extend or otherwise modify a learned classifier."
            },
            "slug": "Learning-Rules-that-Classify-E-Mail-Cohen",
            "title": {
                "fragments": [],
                "text": "Learning Rules that Classify E-Mail"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Two methods for learning text classifiers are compared on classification problems that might arise in filtering and filing personM e-mail messages: a \"traxiitionM IR\" method based on TF-IDF weighting, and a new method for learning sets of \"keyword-spotting rules\" based on the RIPPER rule learning algorithm."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used in [Baker and McCallum 1998; Joachims 1997; McCallum and Nigam 1998; McCallum et al. 1998; Nigam et al. 1998; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1460876,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63287d3220fe96d5cbf73067545abbb88cc180a6",
            "isKey": false,
            "numCitedBy": 426,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "In many important text classification problems, acquiring class labels for training documents is costly, while gathering large quantities of unlabeled data is cheap. This paper shows that the accuracy of text classifiers trained with a small number of labeled documents can be improved by augmenting this small training set with a large pool of unlabeled documents. We present a theoretical argument showing that, under common assumptions, unlabeled data contain information about the target function. We then introduce an algorithm for learning from labeled and unlabeled text based on the combination of Expectation-Maximization with a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents; it then trains a new classifier using the labels for all the documents, and iterates to convergence. Experimental results, obtained using text from three different realworld tasks, show that the use of unlabeled data reduces classification error by up to 33%."
            },
            "slug": "Learning-to-Classify-Text-from-Labeled-and-Nigam-McCallum",
            "title": {
                "fragments": [],
                "text": "Learning to Classify Text from Labeled and Unlabeled Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the accuracy of text classifiers trained with a small number of labeled documents can be improved by augmenting this small training set with a large pool of unlabeled documents, and an algorithm is introduced based on the combination of Expectation-Maximization with a naive Bayes classifier."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2203954"
                        ],
                        "name": "Markus Junker",
                        "slug": "Markus-Junker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Junker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Junker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36422303"
                        ],
                        "name": "R. Hoch",
                        "slug": "R.-Hoch",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Hoch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hoch"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38611857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "83cd992d4e1b3c650a00ae3d2c0d0cc0339e9fb2",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. In the literature, many feature types are proposed for document classification. However, an extensive and systematic evaluation of the various approaches has not yet been done. In particular, evaluations on OCR documents are very rare. In this paper we investigate seven text representations based on n-grams and single words. We compare their effectiveness in classifying OCR texts and the corresponding correct ASCII texts in two domains: business letters and abstracts of technical reports. Our results indicate that the use of n-grams is an attractive technique which can even compare to techniques relying on a morphological analysis. This holds for OCR texts as well as for correct ASCII texts."
            },
            "slug": "An-experimental-evaluation-of-OCR-text-for-learning-Junker-Hoch",
            "title": {
                "fragments": [],
                "text": "An experimental evaluation of OCR text representations for learning document classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The results indicate that the use of n-grams is an attractive technique which can even compare to techniques relying on a morphological analysis, which holds for OCR texts as well as for correct ASCII texts."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881417"
                        ],
                        "name": "M. Ruiz",
                        "slug": "M.-Ruiz",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Ruiz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ruiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144684950"
                        ],
                        "name": "P. Srinivasan",
                        "slug": "P.-Srinivasan",
                        "structuredName": {
                            "firstName": "Padmini",
                            "lastName": "Srinivasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Srinivasan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5557829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "18257110908b685268f14facd74c5f4d8cae5bdc",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop an automatic text categorization approach and investigate its application to text retrieval. The categorization approach is derived from a combination of a learning paradigm known as instance-based learning and an advanced document retrieval technique known as retrieval feedback. We demonstrate the effectiveness of our categorization approach using two real-world document collections from the MEDLINE database. Next, we investigate the application of automatic categorization to text retrieval. Our experiments clearly indicate that automatic categorization improves the retrieval performance compared with no categorization. We also demonstrate that the retrieval performance using automatic categorization achieves the same retrieval quality as the performance using manual categorization. Furthermore, detailed analysis of the retrieval performance on each individual test query is provided."
            },
            "slug": "Automatic-Text-Categorization-and-Its-Application-Lam-Ruiz",
            "title": {
                "fragments": [],
                "text": "Automatic Text Categorization and Its Application to Text Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This work develops an automatic text categorization approach and investigates its application to text retrieval, demonstrating the effectiveness of the approach and demonstrating that the retrieval performance using automatic categorization achieves the same retrieval quality as the performance using manual categorization."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764321"
                        ],
                        "name": "D. Mladenic",
                        "slug": "D.-Mladenic",
                        "structuredName": {
                            "firstName": "Dunja",
                            "lastName": "Mladenic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mladenic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61061713,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad77a84d4566a19c41c3d80b962c77d9f1ac6665",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Classi er Dunja Mladeni c1 Abstract. The paper describes an approach to automatic Web-page classi cation based on the Yahoo hierarchy. Machine learning techniques developed for learning on text data are used here on the hierarchical classi cation structure. The high number of features is reduced by taking into account the hierarchical structure and using feature subset selection based on the method known from information retrieval. Documents are represented as feature-vectors that include n-grams instead of including only single words (unigrams) as commonly used when learning on text data. Based on the hierarchical structure the problem is divided into subproblems, each representing one on the categories included in the Yahoo hierarchy. The result of learning is a set of independent classi ers, each used to predict the probability that a new example is a member of the corresponding category. Experimental evaluation on real-world data shows that the proposed approach gives good results. For more than a half of testing examples a correct category is among the 3 categories with the highest predicted probability."
            },
            "slug": "Turning-{{\\sc-Yahoo!}}\\-into-an-automatic-Web-page-Mladenic",
            "title": {
                "fragments": [],
                "text": "Turning {{\\sc Yahoo!}}\\ into an automatic Web page classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "An approach to automatic Web-page classi cation based on the Yahoo hierarchy, where documents are represented as feature-vectors that include n-grams instead of including only single words (unigrams) as commonly used when learning on text data."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3253837"
                        ],
                        "name": "Norbert G\u00f6vert",
                        "slug": "Norbert-G\u00f6vert",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "G\u00f6vert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Norbert G\u00f6vert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684032"
                        ],
                        "name": "M. Lalmas",
                        "slug": "M.-Lalmas",
                        "structuredName": {
                            "firstName": "Mounia",
                            "lastName": "Lalmas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lalmas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 162
                            }
                        ],
                        "text": "(2) |T | s=1(t.df (ts, dj ))2 Although \nnormalized t.df is the most popular one, other indexing functions have also been used, including proba\u00adbilistic \ntechniques [G\u00a8 overt et al. 1999] or techniques for indexing structured docu\u00adments [Larkey and Croft \n1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "WSD may be seen as a TC task (see e.g [ Gale et al. 1993;  Escudero et al. 2000]) once we view word occurrence contexts as documents and word senses as categories."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8101062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a3759f93e450a67a9daae3de1f2ff7cb9c657c9",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic categorisation of web documents is becoming crucial for organising the huge amount of information available in the Internet. We are facing a new challenge due to the fact that web documents have a rich structure and are highly heterogeneous. Two ways to respond to this challenge are (1) using a representation of the content of web documents that captures these two characteristics and (2) using more effective classifiers.\nOur categorisation approach is based on a probabilistic description-oriented representation of web documents, and a probabilistic interpretation of the k-nearest neighbour classifier. With the former, we provide an enhanced document representation that incorporates the structural and heterogeneous nature of web documents. With the latter, we provide a theoretical sound justification for the various parameters of the k-nearest neighbour classifier.\nExperimental results show that (1) using an enhanced representation of web documents is crucial for an effective categorisation of web documents, and (2) a theoretical interpretation of the k-nearest neighbour classifier gives us improvement over the standard k-nearest neighbour classifier."
            },
            "slug": "A-probabilistic-description-oriented-approach-for-G\u00f6vert-Lalmas",
            "title": {
                "fragments": [],
                "text": "A probabilistic description-oriented approach for categorizing web documents"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work provides an enhanced document representation that incorporates the structural and heterogeneous nature of web documents and provides a theoretical sound justification for the various parameters of the k-nearest neighbour classifier."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40975594"
                        ],
                        "name": "Tom Michael Mitchell",
                        "slug": "Tom-Michael-Mitchell",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Mitchell",
                            "middleNames": [
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom Michael Mitchell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 49
                            }
                        ],
                        "text": ") is almost always performed (exceptions include [Lewis et al. 1996; Nigam et al. 2000; Riloff 1995])(6)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 65
                            }
                        ],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used in [Baker and McCallum 1998; Joachims 1997; McCallum and Nigam 1998; McCallum et al. 1998; Nigam et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 686980,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2de29049d62de925cf709024b92774cd82b0a5a",
            "isKey": false,
            "numCitedBy": 3072,
            "numCiting": 79,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents. This is important because in many text classification problems obtaining training labels is expensive, while large quantities of unlabeled documents are readily available.We introduce an algorithm for learning from labeled and unlabeled documents based on the combination of Expectation-Maximization (EM) and a naive Bayes classifier. The algorithm first trains a classifier using the available labeled documents, and probabilistically labels the unlabeled documents. It then trains a new classifier using the labels for all the documents, and iterates to convergence. This basic EM procedure works well when the data conform to the generative assumptions of the model. However these assumptions are often violated in practice, and poor performance can result. We present two extensions to the algorithm that improve classification accuracy under these conditions: (1) a weighting factor to modulate the contribution of the unlabeled data, and (2) the use of multiple mixture components per class. Experimental results, obtained using text from three different real-world tasks, show that the use of unlabeled data reduces classification error by up to 30%."
            },
            "slug": "Text-Classification-from-Labeled-and-Unlabeled-EM-Nigam-McCallum",
            "title": {
                "fragments": [],
                "text": "Text Classification from Labeled and Unlabeled Documents using EM"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This paper shows that the accuracy of learned text classifiers can be improved by augmenting a small number of labeled training documents with a large pool of unlabeled documents, and presents two extensions to the algorithm that improve classification accuracy under these conditions."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 93891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890c16ca29a781a7b793c603822ffd57aee9f57f",
            "isKey": false,
            "numCitedBy": 2034,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on a comparative evaluation of a wide-range of text categorization methods, including previously published results on the Reuters corpus and new results of additional experiments. A controlled study using three classifiers, kNN, LLSF and WORD, was conducted to examine the impact of configuration variations in five versions of Reuters on the observed performance of classifiers. Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature. Using the results evaluated on the other versions of Reuters which exclude the unlabelled documents, the performance of twelve methods are compared directly or indirectly. For indirect compararions, kNN, LLSF and WORD were used as baselines, since they were evaluated on all versions of Reuters that exclude the unlabelled documents. As a global observation, kNN, LLSF and a neural network method had the best performance; except for a Naive Bayes approach, the other learning algorithms also performed relatively well."
            },
            "slug": "An-Evaluation-of-Statistical-Approaches-to-Text-Yang",
            "title": {
                "fragments": [],
                "text": "An Evaluation of Statistical Approaches to Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Analysis and empirical evidence suggest that the evaluation results on some versions of Reuters were significantly affected by the inclusion of a large portion of unlabelled documents, mading those results difficult to interpret and leading to considerable confusions in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "Information Retrieval"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2255318"
                        ],
                        "name": "R. Liere",
                        "slug": "R.-Liere",
                        "structuredName": {
                            "firstName": "Ray",
                            "lastName": "Liere",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Liere"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729906"
                        ],
                        "name": "Prasad Tadepalli",
                        "slug": "Prasad-Tadepalli",
                        "structuredName": {
                            "firstName": "Prasad",
                            "lastName": "Tadepalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasad Tadepalli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7530337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80ef14d2a1b8c7efbf45bedae9d001fe5446c7de",
            "isKey": false,
            "numCitedBy": 183,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In many real-world domains, supervised learning requires a large number of training examples. In this paper, we describe an active learning method that uses a committee of learners to reduce the number of training examples required for learning. Our approach is similar to the Query by Committee framework, where disagreement among the committee members on the predicted label for the input part of the example is used to signal the need for knowing the actual value of the label. Our experiments are conducted in the text categorization domain, which is characterized by a large number of features, many of which are irrelevant. We report here on experiments using a committee of Winnowbased learners and demonstrate that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude. 1. Hntroduction"
            },
            "slug": "Active-Learning-with-Committees-for-Text-Liere-Tadepalli",
            "title": {
                "fragments": [],
                "text": "Active Learning with Committees for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper reports on experiments using a committee of Winnowbased learners and demonstrates that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2203954"
                        ],
                        "name": "Markus Junker",
                        "slug": "Markus-Junker",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Junker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Junker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689856"
                        ],
                        "name": "A. Abecker",
                        "slug": "A.-Abecker",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Abecker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Abecker"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14112002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dc090d56ae4fc3e4344114f063db9df028a34c6",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems for learning text classiiers recently gained considerable interest. One technique to implement such systems is rule induction. While most other approaches rely on a relatively simple document representation and do not make use of any background knowledge, rule induction algorithms ooer a good potential for improvements in both of these areas. In this paper , we show how an operator-based view of rule induction enables the easy integration of a thesaurus as background knowledge. Results with an algorithm extended by thesaurus knowledge are presented and interpreted. The interpretation shows the strengths and weaknesses of using thesaurus knowledge and gives hints for future research."
            },
            "slug": "Exploiting-Thesaurus-Knowledge-in-Rule-Induction-Junker-Abecker",
            "title": {
                "fragments": [],
                "text": "Exploiting Thesaurus Knowledge in Rule Induction for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper shows how an operator-based view of rule induction enables the easy integration of a thesaurus as background knowledge and shows the strengths and weaknesses of using thesauri knowledge and gives hints for future research."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742457"
                        ],
                        "name": "L. Larkey",
                        "slug": "L.-Larkey",
                        "structuredName": {
                            "firstName": "Leah",
                            "lastName": "Larkey",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Larkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 15762467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22a909e89f8c863802deb24d0c61977b30a38c02",
            "isKey": false,
            "numCitedBy": 279,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Several standard text-categorization techniques were applied to the problem of automated essay grading. Bayesian independence classifiers and knearest-neighbor classifiers were trained to assign scores to manually-graded essays. These scores were combined with several other summary text measures using linear regression. The classifiers and regression equations were then applied to a new set of essays. The classifiers worked very well. The agreement between the automated grader and the final manual grade was as good as the agreement between human graders."
            },
            "slug": "Automatic-essay-grading-using-text-categorization-Larkey",
            "title": {
                "fragments": [],
                "text": "Automatic essay grading using text categorization techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "Several standard text-categorization techniques were applied and Bayesian independence classifiers and knearest-neighbor classifiers worked very well, and the agreement between the automated grader and the final manual grade was as good as the agreement among human graders."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49666627"
                        ],
                        "name": "Giuseppe Attardi",
                        "slug": "Giuseppe-Attardi",
                        "structuredName": {
                            "firstName": "Giuseppe",
                            "lastName": "Attardi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Giuseppe Attardi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47816439"
                        ],
                        "name": "S. D. Marco",
                        "slug": "S.-D.-Marco",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Marco",
                            "middleNames": [
                                "Di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. D. Marco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047998466"
                        ],
                        "name": "Davide Salvi",
                        "slug": "Davide-Salvi",
                        "structuredName": {
                            "firstName": "Davide",
                            "lastName": "Salvi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Davide Salvi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Techniques exploiting this intuition in a TC context have been presented in [ Attardi et al. 1998;  Chakrabarti et al. 1998b; F\u00a8urnkranz 1999; G\u00a8overt et al. 1999; Oh et al. 2000] and experimentally compared in [Yang et al. 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5072232,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75ac6082db2cc241d32badfc132732a30073213e",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The traditional approach to document categorization is categorization by content, since information for categorizing a document is extracted from the document itself. In a hypertext environment like the Web, the structure of documents and the link topology can be exploited to perform what we call categorization by context [Attardi 98]: the context surrounding a link in an HTML document is used for categorizing the document referred by the link. Categorization by context is capable of dealing also with multimedia material, since it does not rely on the ability to analyze the content of documents. Categorization by context leverages on the categorization activity implicitly performed when someone places or refers to a document on the Web. By focusing the analysis to the documents used by a group of people, one can build a catalogue tuned to the need of that group. Categorization by context is based on the following assumptions:"
            },
            "slug": "Categorisation-by-Context-Attardi-Marco",
            "title": {
                "fragments": [],
                "text": "Categorisation by Context"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Categorization by context leverages on the categorization activity implicitly performed when someone places or refers to a document on the Web, and can build a catalogue tuned to the need of that group."
            },
            "venue": {
                "fragments": [],
                "text": "J. Univers. Comput. Sci."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2344874"
                        ],
                        "name": "Maria Fernanda Caropreso",
                        "slug": "Maria-Fernanda-Caropreso",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Caropreso",
                            "middleNames": [
                                "Fernanda"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maria Fernanda Caropreso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749003"
                        ],
                        "name": "S. Matwin",
                        "slug": "S.-Matwin",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Matwin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Matwin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145077269"
                        ],
                        "name": "F. Sebastiani",
                        "slug": "F.-Sebastiani",
                        "structuredName": {
                            "firstName": "Fabrizio",
                            "lastName": "Sebastiani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Sebastiani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17862891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "21a031b2a602621fac57e73858e52321724aaab3",
            "isKey": false,
            "numCitedBy": 249,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the usefulness of n-grams for document indexing in text categorization (TC). We call n-gram a set gk of n word stems, and we say that gk occurs in a document dj when a sequence of words appears in dj that, after stop word removal and stemming, consists exactly of the n stems in gk, in some order. Previous researches have investigated the use of n-grams (or some variant of them) in the context of specific learning algorithms, and thus have not obtained general answers on their usefulness for TC. In this work we investigate the usefulness of n-grams in TC independently of any specific learning algorithm. We do so by applying feature selection to the pool of all k-grams (k \u2264 n), and checking how many n-grams score high enough to be selected in the top \u03c3 k-grams. We report the results of our experiments, using various feature selection measures and varying values of \u03c3, performed on the Reuters-21578 standard TC benchmark. We also report results of making actual use of the selected n-grams in the context of a linear classifier induced by means of the Rocchio method."
            },
            "slug": "A-learner-independent-evaluation-of-the-usefulness-Caropreso-Matwin",
            "title": {
                "fragments": [],
                "text": "A learner-independent evaluation of the usefulness of statistical phrases for automated text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work investigates the usefulness of n-grams for document indexing in text categorization (TC) independently of any specific learning algorithm, by applying feature selection to the pool of all k- grams, and checking how many n- Grams score high enough to be selected in the top \u03c3 k-rams."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881417"
                        ],
                        "name": "M. Ruiz",
                        "slug": "M.-Ruiz",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Ruiz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ruiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144684950"
                        ],
                        "name": "P. Srinivasan",
                        "slug": "P.-Srinivasan",
                        "structuredName": {
                            "firstName": "Padmini",
                            "lastName": "Srinivasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Srinivasan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 149
                            }
                        ],
                        "text": "\u2026Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 150
                            }
                        ],
                        "text": "\u20262001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 175
                            }
                        ],
                        "text": "\u2026\nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and Srinivasan \n1999], relevancy score [Wiener et al. 1995], and GSS coef.cient [Galavotti et al. 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 34
                            }
                        ],
                        "text": "A nonlinear NN [Lam and \nLee 1999; Ruiz and Srinivasan 1999; Sch \u00a8 utze et al. 1995; Weigend et al. 1999; Wiener et al. 1995; \nYang and Liu 1999] is instead a net\u00adwork with one or more additional layers of units, which in TC usually \nrepresent higher-order interactions between terms that the\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11892134,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf3948a9e2ed1808c2db09c1433d2539506e4e56",
            "isKey": true,
            "numCitedBy": 87,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the design and evaluation of a text categorization method based on the Hierarchical Mixture of Experts model. This model uses a divide and conquer principle to define smaller categorization problems based on a predefined hierarchical structure. The final classifier is a hierarchical array of neural networks. The method is evaluated using the UMLS Metathesaurus as the underlying hierarchical structure, and the OHSUMED test set of MEDLINE records. Comparisons with traditional Rocchio\u2019s algorithm adapted for text categorization, as well as flat neural network classifiers are provided. The results show that the use of the hierarchical structure improves text categorization performance significantly."
            },
            "slug": "Hierarchical-neural-networks-for-text-(poster-Ruiz-Srinivasan",
            "title": {
                "fragments": [],
                "text": "Hierarchical neural networks for text categorization (poster abstract)"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results show that the use of the hierarchical structure improves text categorization performance significantly."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37365764"
                        ],
                        "name": "C. Sable",
                        "slug": "C.-Sable",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Sable",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sable"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[Apt\u00e9 et al. 1994; Lewis and Ringuette 1994; Li and Jain 1998; Ng et al. 1997; Sable and Hatzivassiloglou 1999; Sch\u00fctze et al. 1995; Wiener et al. 1995])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This adaptation was first proposed by Hull [1994]; since then, the Rocchio classifier has been used by many authors, either as an object of research in its own right [Ittner et al. 1995; Joachims 1997; Ragas and Koster 1998; Sable and Hatzivassiloglou 1999; Schapire et al. 1998; Singhal et al. 1997], or as a baseline classifier [Cohen and Singer 1999; Fuhr et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other applications we do not explicitly discuss for reasons of space are speech categorisation by means of a combination of speech recognition and TC [Schapire and Singer 2000], multimedia document categorisation through caption analysis [Sable and Hatzivassiloglou 1999], author identification for literary texts of unknown or disputed authorship [Forsyth 1999], and (gasp!) automatic essay grading [Larkey 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14768553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f3819290aa8401709b9146c28f0ea1f3eab7a14f",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "The rapid expansion of multimedia digital collections brings to the fore the need for classifying not only text documents but their embedded non-textual parts as well. We propose a model for basing classification of multimedia on broad, non-topical features, and show how information on targeted nearby pieces of text can be used to effectively classify photographs on a first such feature, distinguishing between indoor and outdoor images. We examine several variations to a TF*IDF-based approach for this task, empirically analyze their effects, and evaluate our system on a large collection of images from current news newsgroups. In addition, we investigate alternative classification and evaluation methods, and the effect that a secondary feature can have on indoor/outdoor classification. We obtain a classification accuracy of 82%, a number that clearly outperforms baseline estimates and competing image-based approaches and nears the accuracy of humans who perform the same task with access to comparable information."
            },
            "slug": "Text-Based-Approaches-for-the-Categorization-of-Sable-Hatzivassiloglou",
            "title": {
                "fragments": [],
                "text": "Text-Based Approaches for the Categorization of Images"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model for basing classification of multimedia on broad, non-topical features, and it is shown how information on targeted nearby pieces of text can be used to effectively classify photographs on a first such feature, distinguishing between indoor and outdoor images."
            },
            "venue": {
                "fragments": [],
                "text": "ECDL"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1380069640"
                        ],
                        "name": "L. Baker",
                        "slug": "L.-Baker",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Baker",
                            "middleNames": [
                                "Douglas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 134
                            }
                        ],
                        "text": "One possible answer is to switch from an interpretation of N\u00e4\u0131ve Bayes in which documents are events to one in which terms are events [Baker and McCallum 1998; McCallum et al. 1998; Chakrabarti et al. 1998a; Guthrie et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 135
                            }
                        ],
                        "text": "One possible answer is to switch from an interpretation of Na\u00a8ive Bayes in which documents are events \nto one in which terms are events [Baker and McCallum 1998; McCallum et al. 1998; Chakrabarti et al. 1998a; \nGuthrie et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 65
                            }
                        ],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used in [Baker and McCallum 1998; Joachims 1997; McCallum and Nigam 1998; McCallum et al. 1998; Nigam et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "[Baker and McCallum 1998]), the recent tendency is to adopt it,"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6146974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e733226b881f11f25c87e8bac8d602ba3d9c220e",
            "isKey": true,
            "numCitedBy": 843,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes the application of Distributional Clustering [20] to document classification. This approach clusters words into groups based on the distribution of class labels associated with each word. Thus, unlike some other unsupervised dimensionalityreduction techniques, such as Latent Semantic Indexing, we are able to compress the feature space much more aggressively, while still maintaining high document classification accuracy. Experimental results obtained on three real-world data sets show that we can reduce the feature dimensional&y by three orders of magnitude and lose only 2% accuracy-significantly better than Latent Semantic Indexing [6], class-based clustering [l], feature selection by mutual information [23], or Markov-blanket-based feature selection [13]. We also show that less aggressive clustering sometimes results in improved classification accuracy over classification without clustering."
            },
            "slug": "Distributional-clustering-of-words-for-text-Baker-McCallum",
            "title": {
                "fragments": [],
                "text": "Distributional clustering of words for text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper describes the application of Distributional Clustering to document classification and shows that it can reduce the feature dimensional&y by three orders of magnitude and lose only 2% accuracy-significantly better than Latent Semantic Indexing, class-based clustering, feature selection by mutual information, or Markov-blanket-based feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682522"
                        ],
                        "name": "Se\u00e1n Slattery",
                        "slug": "Se\u00e1n-Slattery",
                        "structuredName": {
                            "firstName": "Se\u00e1n",
                            "lastName": "Slattery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Se\u00e1n Slattery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791498"
                        ],
                        "name": "R. Ghani",
                        "slug": "R.-Ghani",
                        "structuredName": {
                            "firstName": "Rayid",
                            "lastName": "Ghani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ghani"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 295949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "056dc21b3283e6a69783921367babea2d220684c",
            "isKey": false,
            "numCitedBy": 353,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Hypertext poses new research challenges for text classification. Hyperlinks, HTML tags, category labels distributed over linked documents, and meta data extracted from related Web sites all provide rich information for classifying hypertext documents. How to appropriately represent that information and automatically learn statistical patterns for solving hypertext classification problems is an open question. This paper seeks a principled approach to providing the answers. Specifically, we define five hypertext regularities which may (or may not) hold in a particular application domain, and whose presence (or absence) may significantly influence the optimal design of a classifier. Using three hypertext datasets and three well-known learning algorithms (Naive Bayes, Nearest Neighbor, and First Order Inductive Learner), we examine these regularities in different domains, and compare alternative ways to exploit them. Our results show that the identification of hypertext regularities in the data and the selection of appropriate representations for hypertext in particular domains are crucial, but seldom obvious, in real-world problems. We find that adding the words in the linked neighborhood to the page having those links (both inlinks and outlinks) were helpful for all our classifiers on one data set, but more harmful than helpful for two out of the three classifiers on the remaining datasets. We also observed that extracting meta data from related Web sites was extremely useful for improving classification accuracy in some of those domains. Finally, the relative performance of the classifiers being tested provided insights into their strengths and limitations for solving classification problems involving diverse and often noisy Web pages."
            },
            "slug": "A-Study-of-Approaches-to-Hypertext-Categorization-Yang-Slattery",
            "title": {
                "fragments": [],
                "text": "A Study of Approaches to Hypertext Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper examines five hypertext regularities which may (or may not) hold in a particular application domain, and whose presence (or absence) may significantly influence the optimal design of a classifier."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Intelligent Information Systems"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104688"
                        ],
                        "name": "Yu-Hwan Kim",
                        "slug": "Yu-Hwan-Kim",
                        "structuredName": {
                            "firstName": "Yu-Hwan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-Hwan Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052333334"
                        ],
                        "name": "Shang-Yoon Hahn",
                        "slug": "Shang-Yoon-Hahn",
                        "structuredName": {
                            "firstName": "Shang-Yoon",
                            "lastName": "Hahn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang-Yoon Hahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692756"
                        ],
                        "name": "Byoung-Tak Zhang",
                        "slug": "Byoung-Tak-Zhang",
                        "structuredName": {
                            "firstName": "Byoung-Tak",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byoung-Tak Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6810945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17fb50629464d7ea320e9956152b324e1e37b3af",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Several machine learning algorithms have recently been used for text categorization and filtering. In particular, boosting methods such as AdaBoost have shown good performance applied to real text data. However, most of existing boosting algorithms are based on classifiers that use binary-valued features. Thus, they do not fully make use of the weight information provided by standard term weighting methods. In this paper, we present a boosting-based learning method for text filtering that uses naive Bayes classifiers as a weak learner. The use of naive Bayes allows the boosting algorithm to utilize term frequency information while maintaining probabilistically accurate confidence ratio. Applied to TREC-7 and TREC-8 filtering track documents, the proposed method obtained a significant improvement in LF1, LF2, F1 and F3 measures compared to the best results submitted by other TREC entries."
            },
            "slug": "Text-filtering-by-boosting-naive-Bayes-classifiers-Kim-Hahn",
            "title": {
                "fragments": [],
                "text": "Text filtering by boosting naive Bayes classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A boosting-based learning method for text filtering that uses naive Bayes classifiers as a weak learner allows the boosting algorithm to utilize term frequency information while maintaining probabilistically accurate confidence ratio."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153168891"
                        ],
                        "name": "Hao Chen",
                        "slug": "Hao-Chen",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 116
                            }
                        ],
                        "text": "The support vector machine (SVM) method has been introduced in TC by Joachims [1998, 1999] and subsequently used in [Drucker et al. 1999; Dumais et al. 1998; Dumais and Chen 2000; Klinkenberg and Joachims 2000; Taira and Haruno 1999; Yang and Liu 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 76
                            }
                        ],
                        "text": "Techniques exploiting this intuition in a TC context have been presented in [Dumais and Chen 2000; Chakrabarti et al. 1998a; Koller and Sahami 1997; McCallum et al. 1998; Ruiz and Srinivasan 1999; Weigend et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1194024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa8fa93373d508a91e78dcf47268d9831e9420a5",
            "isKey": false,
            "numCitedBy": 914,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of hierarchical structure for classifying a large, heterogeneous collection of web content. The hierarchical structure is initially used to train different second-level classifiers. In the hierarchical case, a model is learned to distinguish a second-level category from other categories within the same top level. In the flat non-hierarchical case, a model distinguishes a second-level category from all other second-level categories. Scoring rules can further take advantage of the hierarchy by considering only second-level categories that exceed a threshold at the top level.\nWe use support vector machine (SVM) classifiers, which have been shown to be efficient and effective for classification, but not previously explored in the context of hierarchical classification. We found small advantages in accuracy for hierarchical models over flat models. For the hierarchical approach, we found the same accuracy using a sequential Boolean decision rule and a multiplicative decision rule. Since the sequential approach is much more efficient, requiring only 14%-16% of the comparisons used in the other approaches, we find it to be a good choice for classifying text into large hierarchical structures."
            },
            "slug": "Hierarchical-classification-of-Web-content-Dumais-Chen",
            "title": {
                "fragments": [],
                "text": "Hierarchical classification of Web content"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This paper explores the use of hierarchical structure for classifying a large, heterogeneous collection of web content using support vector machine (SVM) classifiers, which have been shown to be efficient and effective for classification, but not previously explored in the context of hierarchical classification."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17260485,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91cbbe24c807473b7b935d39b63df5b15da9bb32",
            "isKey": false,
            "numCitedBy": 392,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Text retrieval systems typically produce a ranking of documents and let a user decide how far down that ranking to go. In contrast, programs that filter text streams, software that categorizes documents, agents which alert users, and many other IR systems must make decisions without human input or supervision. It is important to define what constitutes good effectiveness for these autonomous systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed. We show how to do this for binary text classification systems, emphasizing that different goals for the system le ad to different optimal behaviors. Optimizing and estimating effectiveness is greatly aided if classifiers that explicitly estimate the probability of class membership are used. Ranked retrieval is the information retrieval (IR) researc her\u2019s favorite tool for dealing with information overload. Ranked retrieval systems display documents in order of probability of releva nce or some similar measure. Users see the best documents first, anddecide how far down the ranking to go in examining the available information. The central role played by ranking in this appr oach has led researchers to evaluate IR systems primarily, often exclusively, on the quality of their rankings. (See, for instance , the TREC evaluations [1].) In some IR applications, however, ranking is not enough: A company provides an SDI (selective dissemination of information) service which filters newswire feeds. Relevant articles are faxed each morning to clients. Interaction between customer and system takes place infrequently. The cost of resources (tying up phone lines, fax machine paper, etc.) is a factor to consider in operating the system. A text categorization system assigns controlled vocabulary categories to incoming documents as they are stored in a text database. Cost cutting has eliminated manual checking of category assignments."
            },
            "slug": "Evaluating-and-optimizing-autonomous-text-systems-Lewis",
            "title": {
                "fragments": [],
                "text": "Evaluating and optimizing autonomous text classification systems"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work shows how to define what constitutes good effectiveness for binary text classification systems, tune the systems to achieve the highest possible effectiveness, and estimate how the effectiveness changes as new data is processed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742457"
                        ],
                        "name": "L. Larkey",
                        "slug": "L.-Larkey",
                        "structuredName": {
                            "firstName": "Leah",
                            "lastName": "Larkey",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Larkey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17791727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70dad986b772b92b19b8cd5e4043f1fa23e69348",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Three different types of classifiers were investigatedin the context of a text categorization problem in the medical domain: the automatic assignment of ICD9 codes to dictated inpatient discharge summaries. K-nearest-neighbor, relevance feedback, and Bayesian independence classifiers were applied individually and in combination. A coknbination of different classifiers produced better results than any single type of classifier. For this specific medical categorization problem, new query formulation and weighting methods used in the k-nearest-neighbor classifier improved performance."
            },
            "slug": "Combining-classifiers-in-text-categorization-Larkey-Croft",
            "title": {
                "fragments": [],
                "text": "Combining classifiers in text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "For this specific medical categorization problem, new query formulation and weighting methods used in the k-nearest-neighbor classifier improved performance."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2427083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40212e9474c3ddf3d8c6ffd13dd3211ec9406c49",
            "isKey": false,
            "numCitedBy": 8601,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper explores the use of Support Vector Machines (SVMs) for learning text classifiers from examples. It analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task. Empirical results support the theoretical findings. SVMs achieve substantial improvements over the currently best performing methods and behave robustly over a variety of different learning tasks. Furthermore they are fully automatic, eliminating the need for manual parameter tuning."
            },
            "slug": "Text-Categorization-with-Support-Vector-Machines:-Joachims",
            "title": {
                "fragments": [],
                "text": "Text Categorization with Support Vector Machines: Learning with Many Relevant Features"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper explores the use of Support Vector Machines for learning text classifiers from examples and analyzes the particular properties of learning with text data and identifies why SVMs are appropriate for this task."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716404"
                        ],
                        "name": "D. Roussinov",
                        "slug": "D.-Roussinov",
                        "structuredName": {
                            "firstName": "Dmitri",
                            "lastName": "Roussinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roussinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47666658"
                        ],
                        "name": "Hsinchun Chen",
                        "slug": "Hsinchun-Chen",
                        "structuredName": {
                            "firstName": "Hsinchun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsinchun Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 99
                            }
                        ],
                        "text": "The advantages of this approach are an accuracy comparable to that achieved by human experts, \nand a considerable savings in terms of expert labor power, since no intervention from ei\u00adther knowledge \nengineers or domain ex\u00adperts is needed for the construction of the classi.er or for its porting to\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18422519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "262a27b0249899d185091f851864c122761407bd",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The rapid proliferation of textual and multimedia online databases, digital libraries, Internet servers, and intranet services has turned researchers' and practitioners' dream of creating an information-rich society into a nightmare of info-gluts. Many researchers believe that turning an info-glut into a useful digital library requires automated techniques for organizing and categorizing large-scale information. This paper presents research in which we sought to develop a scaleable textual classification and categorization system based on the Kohonen's self-organizing feature map (SOM) algorithm. In our paper, we show how self-organization can be used for automatic thesaurus generation. Our proposed data structure and algorithm took advantage of the sparsity of coordinates in the document input vectors and reduced the SOM computational complexity by several order of magnitude. The proposed Scaleable SOM (SSOM) algorithm makes large-scale textual categorization tasks a possibility. Algorithmic intuition and the mathematical foundation of our research are presented in detail. We also describe three benchmarking experiments to examine the algorithm's performance at various scales: classification of electronic meeting comments, Internet homepages, and the Compendex collection."
            },
            "slug": "A-Scalable-Self-organizing-Map-Algorithm-for-A-to-Roussinov-Chen",
            "title": {
                "fragments": [],
                "text": "A Scalable Self-organizing Map Algorithm for Textual Classification: A Neural Network Approach to Thesaurus Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "In this paper, it is shown how self-organization can be used for automatic thesaurus generation and the proposed Scaleable SOM (SSOM) algorithm makes large-scale textual categorization tasks a possibility."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891854"
                        ],
                        "name": "Y. Diao",
                        "slug": "Y.-Diao",
                        "structuredName": {
                            "firstName": "Yanlei",
                            "lastName": "Diao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Diao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775519"
                        ],
                        "name": "Hongjun Lu",
                        "slug": "Hongjun-Lu",
                        "structuredName": {
                            "firstName": "Hongjun",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongjun Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390150"
                        ],
                        "name": "Dekai Wu",
                        "slug": "Dekai-Wu",
                        "structuredName": {
                            "firstName": "Dekai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dekai Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1528172,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15de5bde46e4ebda776ab2f84b5ac46160e8604b",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses personal E-mail filtering by casting it in the framework of text classification. Modeled as semi-structured documents, Email messages consist of a set of fields with predefined semantics and a number of variable length free-text fields. While most work on classification either concentrates on structured data or free text, the work in this paper deals with both of them. To perform classification, a naive Bayesian classifier was designed and implemented, and a decision tree based classifier was implemented. The design considerations and implementation issues are discussed. Using a relatively large amount of real personal E-mail data, a comprehensive comparative study was conducted using the two classifiers. The importance of different features is reported. Results of other issues related to building an effective personal E-mail classifier are presented and discussed. It is shown that both classifiers can perform filtering with reasonable accuracy. While the decision tree based classifier outperforms the Bayesian classifier when features and training size are selected optimally for both, a carefully designed naive Bayesian classifier is more robust."
            },
            "slug": "A-Comparative-Study-of-Classification-Based-E-mail-Diao-Lu",
            "title": {
                "fragments": [],
                "text": "A Comparative Study of Classification Based Personal E-mail Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper addresses personal E-mail filtering by casting it in the framework of text classification, and shows that both classifiers can perform filtering with reasonable accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "PAKDD"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37365764"
                        ],
                        "name": "C. Sable",
                        "slug": "C.-Sable",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Sable",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sable"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799688"
                        ],
                        "name": "V. Hatzivassiloglou",
                        "slug": "V.-Hatzivassiloglou",
                        "structuredName": {
                            "firstName": "Vasileios",
                            "lastName": "Hatzivassiloglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Hatzivassiloglou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14759948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7ade965805a2c072c10d075c761dee6f721ea2f",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.The rapid expansion of multimedia digital collections brings to the fore the need for classifying not only text documents but their embedded non-textual parts as well. We propose a model for basing classification of multimedia on broad, non-topical features, and show how information on targeted nearby pieces of text can be used to effectively classify photographs on a first such feature, distinguishing between indoor and outdoor images. We examine several variations to a TF*IDF-based approach for this task, empirically analyze their effects, and evaluate our system on a large collection of images from current news newsgroups. In addition, we investigate alternative classification and evaluation methods, and the effects that secondary features have on indoor/outdoor classification. Using density estimation over the raw TF*IDF values, we obtain a classification accuracy of 82%, a number that outperforms baseline estimates and earlier, image-based approaches, at least in the domain of news articles, and that nears the accuracy of humans who perform the same task with access to comparable information."
            },
            "slug": "Text-based-approaches-for-non-topical-image-Sable-Hatzivassiloglou",
            "title": {
                "fragments": [],
                "text": "Text-based approaches for non-topical image categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A model for basing classification of multimedia on broad, non-topical features, and it is shown how information on targeted nearby pieces of text can be used to effectively classify photographs on a first such feature, distinguishing between indoor and outdoor images."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Digital Libraries"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5083193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3ebcef26c22a373b6f26a67934213eb0582804e",
            "isKey": false,
            "numCitedBy": 5555,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is a comparative study of feature selection methods in statistical learning of text categorization The focus is on aggres sive dimensionality reduction Five meth ods were evaluated including term selection based on document frequency DF informa tion gain IG mutual information MI a test CHI and term strength TS We found IG and CHI most e ective in our ex periments Using IG thresholding with a k nearest neighbor classi er on the Reuters cor pus removal of up to removal of unique terms actually yielded an improved classi cation accuracy measured by average preci sion DF thresholding performed similarly Indeed we found strong correlations between the DF IG and CHI values of a term This suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive TS compares favorably with the other methods with up to vocabulary reduction but is not competitive at higher vo cabulary reduction levels In contrast MI had relatively poor performance due to its bias towards favoring rare terms and its sen sitivity to probability estimation errors"
            },
            "slug": "A-Comparative-Study-on-Feature-Selection-in-Text-Yang-Pedersen",
            "title": {
                "fragments": [],
                "text": "A Comparative Study on Feature Selection in Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper finds strong correlations between the DF IG and CHI values of a term and suggests that DF thresholding the simplest method with the lowest cost in computation can be reliably used instead of IG or CHI when the computation of these measures are too expensive."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14591650,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b1a9e50f18af8a7b9f8dd38f40e0466ad7a8e8",
            "isKey": false,
            "numCitedBy": 3047,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Transductive Support Vector Machines (TSVMs) for text classi cation. While regular Support Vector Machines (SVMs) try to induce a general decision function for a learning task, Transductive Support Vector Machines take into account a particular test set and try to minimize misclassi cations of just those particular examples. The paper presents an analysis of why TSVMs are well suited for text classi cation. These theoretical ndings are supported by experiments on three test collections. The experiments show substantial improvements over inductive methods, especially for small training sets, cutting the number of labeled training examples down to a twentieth on some tasks. This work also proposes an algorithm for training TSVMs e ciently, handling 10,000 examples and more."
            },
            "slug": "Transductive-Inference-for-Text-Classification-Joachims",
            "title": {
                "fragments": [],
                "text": "Transductive Inference for Text Classification using Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "An analysis of why Transductive Support Vector Machines are well suited for text classi cation is presented, and an algorithm for training TSVMs, handling 10,000 examples and more is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2185716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7a07c3aaef303850e5a1fcc81bb44f6d2db6696",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 85,
            "paperAbstract": {
                "fragments": [],
                "text": "This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. Our approach is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses."
            },
            "slug": "BoosTexter:-A-Boosting-based-System-for-Text-Schapire-Singer",
            "title": {
                "fragments": [],
                "text": "BoosTexter: A Boosting-based System for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work describes in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks, and presents results comparing the performance of Boos Texter and a number of other text-categorization algorithms on a variety of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112064"
                        ],
                        "name": "W. Hoyle",
                        "slug": "W.-Hoyle",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Hoyle",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hoyle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 27739486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "614d23d1cb7981ca93b8f0a21587fb1d1d23b9b9",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-indexing-and-generation-of-classification-Hoyle",
            "title": {
                "fragments": [],
                "text": "Automatic indexing and generation of classification systems by algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Storage Retr."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207226010,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3261bb81085f59efae1e1c72453c47daaee777ac",
            "isKey": false,
            "numCitedBy": 926,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "A major challenge in indexing unstructured hypertext databases is to automatically extract meta-data that enables structured search using topic taxonomies, circumvents keyword ambiguity, and improves the quality of search and profile-based routing and filtering. Therefore, an accurate classifier is an essential component of a hypertext database. Hyperlinks pose new problems not addressed in the extensive text classification literature. Links clearly contain high-quality semantic clues that are lost upon a purely term-based classifier, but exploiting link information is non-trivial because it is noisy. Naive use of terms in the link neighborhood of a document can even degrade accuracy. Our contribution is to propose robust statistical models and a relaxation labeling technique for better classification by exploiting link information in a small neighborhood around documents. Our technique also adapts gracefully to the fraction of neighboring documents having known topics. We experimented with pre-classified samples from Yahoo!1 and the US Patent Database2. In previous work, we developed a text classifier that misclassified only 13% of the documents in the well-known Reuters benchmark; this was comparable to the best results ever obtained. This classifier misclassified 36% of the patents, indicating that classifying hypertext can be more difficult than classifying text. Naively using terms in neighboring documents increased error to 38%; our hypertext classifier reduced it to 21%. Results with the Yahoo! sample were more dramatic: the text classifier showed 68% error, whereas our hypertext classifier reduced this to only 21%."
            },
            "slug": "Enhanced-hypertext-categorization-using-hyperlinks-Chakrabarti-Dom",
            "title": {
                "fragments": [],
                "text": "Enhanced hypertext categorization using hyperlinks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work has developed a text classifier that misclassified only 13% of the documents in the well-known Reuters benchmark; this was comparable to the best results ever obtained and its technique also adapts gracefully to the fraction of neighboring documents having known topics."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056131613"
                        ],
                        "name": "P. M. Andersen",
                        "slug": "P.-M.-Andersen",
                        "structuredName": {
                            "firstName": "Peggy",
                            "lastName": "Andersen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. M. Andersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3299906"
                        ],
                        "name": "I. Nirenburg",
                        "slug": "I.-Nirenburg",
                        "structuredName": {
                            "firstName": "Irene",
                            "lastName": "Nirenburg",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Nirenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48846484"
                        ],
                        "name": "L. Schmandt",
                        "slug": "L.-Schmandt",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Schmandt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmandt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62018333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b2c824684e57f3e47dd76bccdd7fcbdf7ba5fba",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The kind of application that the text categorization shell, TCS, can produce is characterized. Many of its applications have great commercial value. The design goals for TCS are discussed, and other approaches to text categorization in the light of these goals are examined. The TCS and how it meets its design goals are described, and examples of applications built with TCS are given. A text-categorization application developed with TCS consists of the TCS run-time system and a rule base. The rule base defines what categories the application can assign to texts and contains rules that make the categorization decisions for particular texts. The data-driven nature of TCS allows it is to satisfy fully the requirements of ease of application development, portability to other applications and maintainability.<<ETX>>"
            },
            "slug": "TCS:-a-shell-for-content-based-text-categorization-Hayes-Andersen",
            "title": {
                "fragments": [],
                "text": "TCS: a shell for content-based text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The kind of application that the text categorization shell, TCS, can produce is characterized and how it meets its design goals are described, and examples of applications built with TCS are given."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth Conference on Artificial Intelligence for Applications"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118384802"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34755863"
                        ],
                        "name": "K. Yamanishi",
                        "slug": "K.-Yamanishi",
                        "structuredName": {
                            "firstName": "Kenji",
                            "lastName": "Yamanishi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yamanishi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2411270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0b1916081b30cd32863375a68405c85946a267b",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method of text classification using stochastic decision lists. A stochastic decision list is an ordered sequence of IF-THEN rules, and our method can be viewed as a rule-based method for text classification having advantages of readability and refinability of acquired knowledge. Our method is unique in that decision lists are automatically constructed on the basis of the principle of minimizing Extended Stochastic Complexity (ESC), and with it we are able to construct decision lists that have fewer errors in classification. The accuracy of classification achieved with our method appears better than or comparable to those of existing rule-based methods."
            },
            "slug": "Text-classification-using-ESC-based-stochastic-Li-Yamanishi",
            "title": {
                "fragments": [],
                "text": "Text classification using ESC-based stochastic decision lists"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "This work proposes a new method of text classification using stochastic decision lists, which is unique in that decision lists are automatically constructed on the basis of the principle of minimizing Extended Stochastic Complexity (ESC), and with it it is able to construct decision lists that have fewer errors in classification."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145172877"
                        ],
                        "name": "K. Nigam",
                        "slug": "K.-Nigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nigam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "McCallum 1998; Joachims 1997;  McCallum and Nigam 1998;  McCallum et al. 1998; Nigam et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14278367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b3b54848c1bc6ffea2625ce79302abed8e8deb9",
            "isKey": false,
            "numCitedBy": 836,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how a text classifier\u2019s need for labeled training documents can be reduced by taking advantage of a large pool of unlabeled documents. We modify the Query-by-Committee (QBC) method of active learning to use the unlabeled pool for explicitly estimating document density when selecting examples for labeling. Then active learning is combined with ExpectationMaximization in order to \u201cfill in\u201d the class labels of those documents that remain unlabeled. Experimental results show that the improvements to active learning require less than two-thirds as many labeled training examples as previous QBC approaches, and that the combination of EM and active learning requires only slightly more than half as many labeled training examples to achieve the same accuracy as either the improved active learning or EM alone."
            },
            "slug": "Employing-EM-and-Pool-Based-Active-Learning-for-McCallum-Nigam",
            "title": {
                "fragments": [],
                "text": "Employing EM and Pool-Based Active Learning for Text Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper shows how a text classifier\u2019s need for labeled training documents can be reduced by taking advantage of a large pool of unlabeled documents by modifying the Query-by-Committee method of active learning to use it for explicitly estimating document density when selecting examples for labeling."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777060"
                        ],
                        "name": "D. Merkl",
                        "slug": "D.-Merkl",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Merkl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Merkl"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "[Merkl 1998]), a task usually called text clustering, or (iv) any activity of placing text items into groups, a task that has thus both TC and text clustering as particular instances [Manning and Sch\u00fctze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29733167,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20ec6dfee7d8ab08245aa4cccad3558dba813bef",
            "isKey": false,
            "numCitedBy": 128,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-classification-with-self-organizing-maps:-Some-Merkl",
            "title": {
                "fragments": [],
                "text": "Text classification with self-organizing maps: Some lessons learned"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5842708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "094fc15bc058b0d62a661a1460885a9490bdb1bd",
            "isKey": false,
            "numCitedBy": 1533,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : A probabilistic analysis of the Rocchio relevance feedback algorithm, one of the most popular learning methods from information retrieval, is presented in a text categorization framework. The analysis results in a probabilistic version of the Rocchio classifier and offers an explanation for the TFIDF word weighting heuristic. The Rocchio classifier, its probabilistic variant and a standard naive Bayes classifier are compared on three text categorization tasks. The results suggest that the probabilistic algorithms are preferable to the heuristic Rocchio classifier."
            },
            "slug": "A-Probabilistic-Analysis-of-the-Rocchio-Algorithm-Joachims",
            "title": {
                "fragments": [],
                "text": "A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A Probabilistic analysis of the Rocchio relevance feedback algorithm, one of the most popular learning methods from information retrieval, is presented in a text categorization framework and suggests that the probabilistic algorithms are preferable to the heuristic Rocchio classifier."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14928769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87618241774c6e5fafd0b757c799fd5981400325",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for probabilistic document indexing using relevance feedback data that has been collected from a set of queries. Our approach is based on three new concepts: (1) Abstraction from specific terms and documents, which overcomes the restriction of limited relevance information for parameter estimation. (2) Flexibility of the representation, which allows the integration of new text analysis and knowledge-based methods in our approach as well as the consideration of document structures or different types of terms. (3) Probabilistic learning or classification methods for the estimation of the indexing weights making better use of the available relevance information, Our approach can be applied under restrictions that hold for real applications. We give experimental results for five test collections which show improvements over other methods."
            },
            "slug": "A-probabilistic-learning-approach-for-document-Fuhr-Buckley",
            "title": {
                "fragments": [],
                "text": "A probabilistic learning approach for document indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A method for probabilistic document indexing using relevance feedback data that has been collected from a set of queries based on three new concepts, which allows the integration of new text analysis and knowledge-based methods in this approach as well as the consideration of document structures or different types of terms."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152971314"
                        ],
                        "name": "Kevin Knight",
                        "slug": "Kevin-Knight",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Knight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Knight"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 203
                            }
                        ],
                        "text": "Current-day TC is thus a discipline at the crossroads of ML and IR, and as such it shares a number of characteristics with other tasks such as information/knowledge extraction from texts and text mining [Knight 1999; Pazienza 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 205
                            }
                        ],
                        "text": "Current-day \nTC is thus a discipline at the crossroads of ML and IR, and as such it shares a number of characteris\u00adtics \nwith other tasks such as information/ knowledge extraction from texts and text mining [Knight 1999; Pazienza \n1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10361211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0dfec7cc31561f3447c2919c9cd0819455e057a",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural-language applications, such as machine translation, speech recognition, information retrieval, and summarization, are reaching a broader range of users today. Anyone who has used these products knows how imperfect they are. Still, people use them because they are desperate for ways to organize and sift through the vast amount of information available to them\u2014textually\u2014 online. In addition, vast online texts are a potential gold mine of linguistic information for natural language processing (NLP) application builders to improve the quality of their systems. Building mining apps in natural language processing poses special challenges, but also offers great rewards. NLP problems, like most in AI, require large amounts of formally codified knowledge, that is, knowledge about words, parts of speech, grammar, word meanings, phonetics, text structure, and the world itself. For small or circumscribed domains, this knowledge can be typed in manually , but for general-purpose programs (the kind that most users want), the amount of knowledge is overwhelming. The quest for automating or semiautomating the acquisition of NLP knowledge has recently spawned a collection of new techniques that sometimes go under the heading \" statistical NLP. \" The phrase is not a particularly good one, as it seems to exclude approaches that do not use statistical frequency counting or probability theory. But it is brief and commonly used. The type of research described here might more broadly be called \" automated or semiautomated knowledge acquisition from linguistic resources. \" Let's begin with a straightforward example. Languages like Japanese, Chinese, and Russian lack the small words we call articles (a, an, the)."
            },
            "slug": "Mining-online-text-Knight",
            "title": {
                "fragments": [],
                "text": "Mining online text"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The quest for automating or semiautomating the acquisition of NLP knowledge has recently spawned a collection of new techniques that sometimes go under the heading \" statistical NLP, \" the phrase is not a particularly good one, as it seems to exclude approaches that do not use statistical frequency counting or probability theory."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144987107"
                        ],
                        "name": "Jamie Callan",
                        "slug": "Jamie-Callan",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Callan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Callan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47394834"
                        ],
                        "name": "R. Papka",
                        "slug": "R.-Papka",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Papka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Papka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 1650587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dc36b8d0c08613fb213ad419973d379a2264765",
            "isKey": false,
            "numCitedBy": 620,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Systems for text retrieval, routing, categorization and other IR tasks rely heavily on linear classifiers. We propose that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers. In contrast to most IR methods, theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms. Experimental data is presented showing Widrow-Hoff and EG to be more effective than the widely used Rocchio algorithm on several categorization and routing tasks."
            },
            "slug": "Training-algorithms-for-linear-text-classifiers-Lewis-Schapire",
            "title": {
                "fragments": [],
                "text": "Training algorithms for linear text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This work proposes that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers for IR tasks, and theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771637"
                        ],
                        "name": "C. Clack",
                        "slug": "C.-Clack",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Clack",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Clack"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1942953"
                        ],
                        "name": "J. Farringdon",
                        "slug": "J.-Farringdon",
                        "structuredName": {
                            "firstName": "Jonny",
                            "lastName": "Farringdon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Farringdon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2991367"
                        ],
                        "name": "Peter Lidwell",
                        "slug": "Peter-Lidwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Lidwell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Lidwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4819884"
                        ],
                        "name": "T. Yu",
                        "slug": "T.-Yu",
                        "structuredName": {
                            "firstName": "Tina",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9774673,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d74c87807465a41ddded70fba688c0f84a04e69f",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "With the continuing exponential growth of the Internet and the more recent growth of business Intranets, the commercial world is becoming increasingly aware of the problem of electronic information overload. This has encouraged interest in developing agents/softbots that can act as electronic personal assistants and can develop and adapt representations of users information needs, commonly known as profiles. As the result of collaborative research with Friends of the Earth, a leading environmental campaigning organization, we have developed a general purpose information classification agent architecture and are applying it to the problem of document classification and routing. Collaboration with Friends of the Earth allows us to test our ideas in a non-academic context involving high volumes of documents. We use the technique of genetic programming (GP), (Koza & Rice 1992), to evolve classifying agents. This is a novel approach for document classification, where each agent evolves a parse-tree representation of a user's particular information need. The other unusual features of our research are the longevity of our agents and the fact that they undergo a continual training process; feedback from the user enables the agent to adapt to the user's long-term information requirements."
            },
            "slug": "Autonomous-document-classification-for-business-Clack-Farringdon",
            "title": {
                "fragments": [],
                "text": "Autonomous document classification for business"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A general purpose information classification agent architecture is developed and is applying it to the problem of document classification and routing and feedback from the user enables the agent to adapt to the user's long-term information requirements."
            },
            "venue": {
                "fragments": [],
                "text": "AGENTS '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2104994444"
                        ],
                        "name": "Kamal Nigamyknigam",
                        "slug": "Kamal-Nigamyknigam",
                        "structuredName": {
                            "firstName": "Kamal",
                            "lastName": "Nigamyknigam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kamal Nigamyknigam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 65
                            }
                        ],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used in [Baker and McCallum 1998; Joachims 1997; McCallum and Nigam 1998; McCallum et al. 1998; Nigam et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14133176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f17768a9fe231a2fd38708be90f98db3890c986",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper shows how a text classiier's need for labeled training data can be reduced by a combination of active learning and Expectation Maximization (EM) on a pool of unlabeled data. Query-by-Committee is used to actively select documents for labeling, then EM with a naive Bayes model further improves classiication accuracy by concurrently estimating probabilistic labels for the remaining unlabeled documents and using them to improve the model. We also present a metric for better measuring disagreement among committee members; it accounts for the strength of their disagreement and for the distribution of the documents. Experimental results show that our method of combining EM and active learning requires only half as many labeled training examples to achieve the same accuracy as either EM or active learning alone."
            },
            "slug": "Employing-Em-in-Pool-based-Active-Learning-for-Text-Nigamyknigam",
            "title": {
                "fragments": [],
                "text": "Employing Em in Pool-based Active Learning for Text Classiication"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper shows how a text classiier's need for labeled training data can be reduced by a combination of active learning and Expectation Maximization on a pool of unlabeled data and presents a metric for better measuring disagreement among committee members."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92949325"
                        ],
                        "name": "H. Ragas",
                        "slug": "H.-Ragas",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Ragas",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ragas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713642"
                        ],
                        "name": "C. Koster",
                        "slug": "C.-Koster",
                        "structuredName": {
                            "firstName": "Cornelis",
                            "lastName": "Koster",
                            "middleNames": [
                                "H.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Koster"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "1996]) and the Sleeping Experts algorithm [Cohen and Singer 1999; Ragas and Koster 1998], a version of Balanced Winnow."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Balanced Winnow [Dagan et al. 1997; Ragas and Koster 1998] is a further variant of Positive Winnow, in which the classifier consists of two weights w ki and w \u2212 ki for each term tk; the final weight wki used in computing the inner product is the difference w ki \u2212 w\u2212 ki."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "This adaptation was first proposed by Hull [1994]; since then, the Rocchio classifier has been used by many authors, either as an object of research in its own right [Ittner et al. 1995; Joachims 1997; Ragas and Koster 1998; Sable and Hatzivassiloglou 1999; Schapire et al. 1998; Singhal et al. 1997], or as a baseline classifier [Cohen and Singer 1999; Fuhr et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11755419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d3528be8538c5ac20beee48bfe421ca792d4db9",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an experiment in applying text classification algorithms to Dutch texts. Four well-known learning algorithms, Rocchio\u2019s algorithm, the Simple Bayesian Classifier (SBC), the Sleeping Experts (SE) and Winnow were implemented. They were tested on a corpus of articles from the Dutch newspaper NRC, pre-classified into four categories. The algorithms are compared on learning speed and error rate. We also investigated the effect of discarding terms, using either a dynamic stoplist or the Winnow heuristic."
            },
            "slug": "Four-text-classification-algorithms-compared-on-a-Ragas-Koster",
            "title": {
                "fragments": [],
                "text": "Four text classification algorithms compared on a Dutch corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "Four well-known learning algorithms, Rocchio\u2019s algorithm, the Simple Bayesian Classifier, the SBC, the Sleeping Experts and Winnow were implemented and tested on a corpus of articles from the Dutch newspaper NRC, pre-classified into four categories."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055160"
                        ],
                        "name": "David J. Ittner",
                        "slug": "David-J.-Ittner",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ittner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Ittner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053105315"
                        ],
                        "name": "David D. Ahn",
                        "slug": "David-D.-Ahn",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ahn",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David D. Ahn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16611584,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72fe75228c198854d4c43cc70a381643a28deca6",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Categorization of text images into content oriented classes would be a useful capability in a variety of document handling systems Many methods can be used to cat egorize texts once their words are known but OCR can garble a large proportion of words particularly when low quality images are used Despite this we show for one data set that fax quality images can be cat egorized with nearly the same accuracy as the original text Further the categoriza tion system can be trained on noisy OCR output without need for the true text of any image or for editing of OCR output The use of a vector space classi er and train ing method robust to large feature sets com bined with discarding of low frequency OCR output strings are the key to our approach"
            },
            "slug": "Text-categorization-of-low-quality-images-Ittner-Lewis",
            "title": {
                "fragments": [],
                "text": "Text categorization of low quality images"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown for one data set that fax quality images can be catgorized with nearly the same accuracy as the original text and the categoriza tion system can be trained on noisy OCR output without need for the true text of any image or for editing of O CR output."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69466224"
                        ],
                        "name": "B. J. Field",
                        "slug": "B.-J.-Field",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. J. Field"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 88
                            }
                        ],
                        "text": "This is often used, for instance, in applications of TC to au\u00adtomated document \nindexing [Field 1975; Lam et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 73
                            }
                        ],
                        "text": "The application that has spawned most of the early research in the field [Borko and Bernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961], is that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 149
                            }
                        ],
                        "text": "\u2026Indexing for Boolean Information \nRetrieval Systems The application that has spawned most of the early research in the .eld [Borko and \nBernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961] is that of automatic document \nindexing for IR systems relying on a controlled\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 87
                            }
                        ],
                        "text": "This is often used, for instance, in applications of TC to automated document indexing [Field 1975; Lam et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61027436,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c861655734b54a0d6363614b093c849bc13c9bc0",
            "isKey": true,
            "numCitedBy": 38,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of techniques have been studied for the automatic assignment of controlled subject headings and classifications from free indexing. These techniques involve the automatic manipulation and truncation of the free\u2010index phrases assigned to a document and the use of a manually\u2010constructed thesaurus and automatically\u2010generated dictionaries together with statistical ranking and weighting methods. These are based on the use of a statistically\u2010generated \u2018adhesion coefficient\u2019 which reflects the degree of association between the free\u2010indexing terms, the controlled subject headings, and the classifications. By the analysis of a large sample of manually\u2010indexed documents the system generates dictionaries of free\u2010language and controlled\u2010language terms together with their associated classifications and adhesion coefficients. Having learnt from the manually\u2010indexed documents the system uses these dictionaries in the subsequent automatic classification procedure. The accuracy and cost\u2010effectiveness of the automatically\u2010assigned subject headings and classifications has been compared with that of the manual system. The results were encouraging and the costs comparable to those of a manual system."
            },
            "slug": "TOWARDS-AUTOMATIC-INDEXING:-AUTOMATIC-ASSIGNMENT-OF-Field",
            "title": {
                "fragments": [],
                "text": "TOWARDS AUTOMATIC INDEXING: AUTOMATIC ASSIGNMENT OF CONTROLLED\u2010LANGUAGE INDEXING AND CLASSIFICATION FROM FREE INDEXING"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The accuracy and cost\u2010effectiveness of the automatically\u2010assigned subject headings and classifications has been compared with that of the manual system and the results were encouraging and the costs comparable to those of a manual system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16644750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b07f0f4553cfb42c0ed2bd6b07c9b22777b313d8",
            "isKey": false,
            "numCitedBy": 693,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Syntactic phrase indexing and term clustering have been widely explored as text representation techniques for text retrieval. In this paper we study the properties of phrasal and clustered indexing languages on a text categorization task, enabling us to study their properties in isolation from query interpretation issues. We show that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing. We also present results suggesting that traditional term clustering method are unlikely to provide significantly improved text representations. An improved probabilistic text categorization method is also presented."
            },
            "slug": "An-evaluation-of-phrasal-and-clustered-on-a-text-Lewis",
            "title": {
                "fragments": [],
                "text": "An evaluation of phrasal and clustered representations on a text categorization task"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that optimal effectiveness occurs when using only a small proportion of the indexing terms available, and that effectiveness peaks at a higher feature set size and lower effectiveness level for a syntactic phrase indexing than for word-based indexing."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6516914"
                        ],
                        "name": "Joo-Hwee Lim",
                        "slug": "Joo-Hwee-Lim",
                        "structuredName": {
                            "firstName": "Joo-Hwee",
                            "lastName": "Lim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joo-Hwee Lim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 486,
                                "start": 9
                            }
                        ],
                        "text": "resents the so-called Frobenius norm of a |C| \u00d7 |T | matrix, I is the |T | \u00d7 |Tr| matrix whose columns are the input vectors of the training documents, and O is the |C| \u00d7 |Tr| matrix whose columns are the output vectors of the training documents. The M\u0302 matrix is usually computed by performing a singular value decomposition on the training set, and its generic entry m\u0302ik represents the degree of association between category ci and term tk . The experiments of Yang and Chute [1994] and Yang and Liu [1999] indicate that LLSF is one of the most effective text classifiers known to date."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 782,
                                "start": 1
                            }
                        ],
                        "text": "The documents in Te cannot participate in any way in the inductive construction of the classifiers; if this condition were not satisfied, the experimental results obtained would likely be unrealistically good, and the evaluation would thus have no scientific character [Mitchell 1996, page 129]. In an operational setting, after evaluation has been performed one would typically retrain the classifier on the entire initial corpus, in order to boost effectiveness. In this case, the results of the previous evaluation would be a pessimistic estimate of the real performance, since the final classifier has been trained on more data than the classifier evaluated. This is called the train-and-test approach. An alternative is the k-fold crossvalidation approach (see Mitchell [1996], page 146), in which k different classifiers 81, ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 35
                            }
                        ],
                        "text": "In fact, as noted in Manning and Sch\u00fctze [1999], page 589,"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 59
                            }
                        ],
                        "text": "16 Conversely, it is well known from everyday IR practice that higher levels of \u03c0 may be obtained at the price of low values of \u03c1. In practice, by tuning \u03c4i a function CSVi : D \u2192 {T, F } is tuned to be, in the words of Riloff and Lehnert [1994], more liberal (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 278,
                                "start": 1
                            }
                        ],
                        "text": "The \u2211 {d j\u2208NPOSi} wkj |NPOSi | factor is more significant than \u2211 {d j\u2208NEGi} wkj |NEGi | , since nearpositives are the most difficult documents to tell apart from the positives. Using near-positives corresponds to the query zoning method proposed for IR by Singhal et al. [1997]. This method originates from the observation that, when the original"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 47
                            }
                        ],
                        "text": "A simple and effective global TSR function is the document frequency #Tr(tk) of a term tk , that is, only the terms that occur in the highest number of documents are retained. In a series of experiments Yang and Pedersen [1997] have shown that with #Tr(tk) it is possible to reduce the dimensionality by a factor of 10 with no loss in effectiveness (a"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 1
                            }
                        ],
                        "text": "the approximation of a real-valued (instead than binary, as in the case of classification) function 8\u0306 by means of a function 8 that fits the training data [Mitchell 1996, page 236]. Here we will describe one such model, the Linear Least-Squares Fit (LLSF) applied to TC by Yang and Chute [1994]. In LLSF, each document d j has two vectors associated to it: an input vector I (d j ) of |T | weighted terms, and an output vector O(d j ) of |C| weights representing the categories (the weights for this latter vector are binary for training documents, and are nonbinary CSV \u2032s for test documents)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 322,
                                "start": 1
                            }
                        ],
                        "text": "The difference from the original k-NN approach is that if a training document dz similar to the test document d j does not belong to ci, this information is not discarded but weights negatively in the decision to classify d j under ci. A combination of profile- and examplebased methods was presented in Lam and Ho [1998]. In this work a k-NN system was fed generalized instances (GIs) in place of training documents."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 7
                            }
                        ],
                        "text": "(a) with categories in place of IR queries. This is most frequently used for document-ranking classifiers (see Sch\u00fctze et al. [1995]; Yang [1994]; Yang [1999]; Yang and Pedersen [1997]);"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15502746,
            "fieldsOfStudy": [
                "Computer Science",
                "Education",
                "Economics"
            ],
            "id": "423dc7573e04835c0b85fbcf686584460fe8d369",
            "isKey": true,
            "numCitedBy": 26,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic categorization of multimedia documents is an important function for a digital library system. While text categorization has received much attentions by IR researchers, classi cation of visual data is at its infancy stage. In this paper, we propose a notion of visual keywords for similarity matching between visual contents. Visual keywords can be constructed automatically from samples of visual data through supervised/unsupervised learning. Given a visual content, the occurrences of visual keywords are detected, summarized spatially, and coded via singular value decomposition to arrive at a concise coded description. The methods to create, detect, summarize, select, and code visual keywords will be detailed. Last but not least, we describe an evaluation experiment that classi es professional nature scenery photographs to demonstrate the e ectiveness and e ciency of visual keywords for automatic categorization of images in digital libraries."
            },
            "slug": "Learnable-visual-keywords-for-image-classification-Lim",
            "title": {
                "fragments": [],
                "text": "Learnable visual keywords for image classification"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a notion of visual keywords for similarity matching between visual contents, and describes an evaluation experiment that classi es professional nature scenery photographs to demonstrate the e ectiveness and e ciency ofVisual keywords for automatic categorization of images in digital libraries."
            },
            "venue": {
                "fragments": [],
                "text": "DL '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127759"
                        ],
                        "name": "B. Masand",
                        "slug": "B.-Masand",
                        "structuredName": {
                            "firstName": "Brij",
                            "lastName": "Masand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Masand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2132345"
                        ],
                        "name": "G. Linoff",
                        "slug": "G.-Linoff",
                        "structuredName": {
                            "firstName": "Gordon",
                            "lastName": "Linoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Linoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7048166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1240054ed60e8e42de9683947d21bd76582a281d",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method for classifying news stories using Memory Based Reasoning (MBR) a k-nearest neighbor method), that does not require manual topic definitions. Using an already coded training database of about 50,000 stories from the Dow Jones Press Release News Wire, and SEEKER [Stanfill] (a text retrieval system that supports relevance feedback) as the underlying match engine, codes are assigned to new, unseen stories with a recall of about 80% and precision of about 70%. There are about 350 different codes to be assigned. Using a massively parallel supercomputer, we leverage the information already contained in the thousands of coded stories and are able to code a story in about 2 seconds. Given SEEKER, the text retrieval system, we achieved these results in about two person-months. We believe this approach is effective in reducing the development time to implement classification systems involving large number of topics for the purpose of classification, message routing etc."
            },
            "slug": "Classifying-news-stories-using-memory-based-Masand-Linoff",
            "title": {
                "fragments": [],
                "text": "Classifying news stories using memory based reasoning"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A method for classifying news stories using Memory Based Reasoning (MBR) a k-nearest neighbor method, that does not require manual topic definitions, that is effective in reducing the development time to implement classification systems involving large number of topics for the purpose of classification, message routing etc."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '92"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3104832"
                        ],
                        "name": "H. Heaps",
                        "slug": "H.-Heaps",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Heaps",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Heaps"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 73
                            }
                        ],
                        "text": "The application that has spawned most of the early research in the field [Borko and Bernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961], is that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 150
                            }
                        ],
                        "text": "\u2026\nRetrieval Systems The application that has spawned most of the early research in the .eld [Borko and \nBernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961] is that of automatic document \nindexing for IR systems relying on a controlled dictionary, the most prominent example of\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36425150,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics",
                "Education"
            ],
            "id": "a1763f8997a4a89cdfe82c61f1379edb2dfc283a",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Theory-of-Relevance-for-Automatic-Document-Heaps",
            "title": {
                "fragments": [],
                "text": "A Theory of Relevance for Automatic Document Classification"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Control."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025731"
                        ],
                        "name": "H. Hirsh",
                        "slug": "H.-Hirsh",
                        "structuredName": {
                            "firstName": "Haym",
                            "lastName": "Hirsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hirsh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 53
                            }
                        ],
                        "text": "For other examples of significance testing in TC see [Cohen 1995a; Cohen 1995b; Cohen and Hirsh 1998; Joachims 1997; Koller and Sahami 1997; Lewis et al. 1996; Wiener et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 11
                            }
                        ],
                        "text": "5 (used in [Cohen and Hirsh 1998; Cohen and Singer 1999; Joachims 1998; Lewis and Catlett 1994]) and C5 (used in [Li and Jain 1998])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 153
                            }
                        ],
                        "text": "Among \nthe DNF rule learners that have been applied to TC are CHARADE [Moulinier and Ganascia 1996], DL-ESC \n[Li and Yamanishi 1999], RIPPER [Cohen 1995a; Cohen and Hirsh 1998; Cohen and Singer 1999], SCAR [Moulinier \net al. 1996], and SWAP-1 [Apt\u00b4 e 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9644666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1022696090666eab5c82ebc07d63c0de2fca2521",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "WHIRL is an extension of relational databases that can perform \"soft joins\" based on the similarity of textual identifiers; these soft joins extend the traditional operation of joining tables based on the equivalence of atomic values. This paper evaluates WHIRL on a number of inductive classification tasks using data from the World Wide Web. We show that although WHIRL is designed for more general similarity-based reasoning tasks, it is competitive with mature inductive classification systems on these classification tasks. In particular, WHIRL generally achieves lower generalization error than C4.5, RIPPER, and several nearest-neighbor methods. WHIRL is also fast\u2014up to 500 times faster than C4.5 on some benchmark problems. We also show that WHIRL can be efficiently used to select from a large pool of unlabeled items those that can be classified correctly with high confidence."
            },
            "slug": "Joins-that-Generalize:-Text-Classification-Using-Cohen-Hirsh",
            "title": {
                "fragments": [],
                "text": "Joins that Generalize: Text Classification Using WHIRL"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that although WHIRL is designed for more general similarity-based reasoning tasks, it is competitive with mature inductive classification systems on these classification tasks and generally achieves lower generalization error than C4.5, RIPPER, and several nearest-neighbor methods."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8905591"
                        ],
                        "name": "Ludovic Denoyer",
                        "slug": "Ludovic-Denoyer",
                        "structuredName": {
                            "firstName": "Ludovic",
                            "lastName": "Denoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ludovic Denoyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2833561"
                        ],
                        "name": "H. Zaragoza",
                        "slug": "H.-Zaragoza",
                        "structuredName": {
                            "firstName": "Hugo",
                            "lastName": "Zaragoza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zaragoza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741426"
                        ],
                        "name": "P. Gallinari",
                        "slug": "P.-Gallinari",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Gallinari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gallinari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9094435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ce494aaaf3a24cc14f1cd8566665b26246c24be",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of Hidden Markov Models to supervised document classification and ranking. We consider a family of models that take into account the fact that relevant documents may contain irrelevant passages; the originality of the model is that it does not explicitly segment documents but rather considers all possible segmentations in its final score. This model generalizes the multinomial Naive Bayes and it is derived from a more general model for different access tasks. The model is evaluated on the REUTERS test collection and compared to the multinomial Naive Bayes model. It is shown to be more robust with respect to the training set size and to improve the performance both for ranking and classification, specially for classes with few training examples."
            },
            "slug": "HMM-based-passage-models-for-document-and-ranking-Denoyer-Zaragoza",
            "title": {
                "fragments": [],
                "text": "HMM-based passage models for document classification and ranking"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A family of models that take into account the fact that relevant documents may contain irrelevant passages are considered, which generalizes the multinomial Naive Bayes and is derived from a more general model for different access tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110525452"
                        ],
                        "name": "Yonghong Li",
                        "slug": "Yonghong-Li",
                        "structuredName": {
                            "firstName": "Yonghong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yonghong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145295484"
                        ],
                        "name": "Anil K. Jain",
                        "slug": "Anil-K.-Jain",
                        "structuredName": {
                            "firstName": "Anil",
                            "lastName": "Jain",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anil K. Jain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8805137,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94a4a4fdb58a6777f13bb60955470bb10a415d6f",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate four different classification methods for document classification: the naive Bayes classifier, nearest neighbor classifier, decision tree classifier, and subspace method. The classifiers were applied to seven-class Yahoo newsgroups individually and in combination. We study three classifier combination approaches: simple voting, dynamic classifier selection, and adaptive classifier combination. Our experimental results indicate that the naive Bayes classifier and the subspace method outperform the other two classification methods on our data sets. Combinations of multiple classifiers did not always improve classification accuracy. Among the three different combination approaches, the adaptive classifier combination method proposed here performed the best."
            },
            "slug": "Classification-of-text-documents-Li-Jain",
            "title": {
                "fragments": [],
                "text": "Classification of Text Documents"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "The authors' experimental results indicate that the naive Bayes classifier and the subspace method outperform the other two classification methods on their data sets."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 15704538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33c1f29dbc73cc4d0f787d6b048b465649b2d92b",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "At ACM SIGIR '94, I compared the effectiveness of uncertainty sampling with that of random sampling and relevance sampling in choosing training data for a text categorization data set [1]. (Relevance sampling is the application of relevance feedback [3] to producing a training sample.) I have discovered a bug in my experimental software which caused the relevance sampling results reported in the SIGIR '94 paper to be incorrect. (The uncertainty sampling and random sampling results in that paper were correct.) I have since fixed the bug and rerun the experiments. This note presents the corrected results, along with additional data supporting the original claim that uncertainty sampling has an advantage over relevance sampling in most training situations."
            },
            "slug": "A-sequential-algorithm-for-training-text-and-data-Lewis",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training text classifiers: corrigendum and additional data"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A bug in my experimental software caused the relevance sampling results reported in the SIGIR '94 paper to be incorrect, and this note presents the corrected results, along with additional data supporting the original claim that uncertainty sampling has an advantage over relevance sampling in most training situations."
            },
            "venue": {
                "fragments": [],
                "text": "SIGF"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764321"
                        ],
                        "name": "D. Mladenic",
                        "slug": "D.-Mladenic",
                        "structuredName": {
                            "firstName": "Dunja",
                            "lastName": "Mladenic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mladenic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12718468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5bf6046f3d0a37fe8e03d6e26b27e07c0a55a76",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes several known and some new methods for feature subset selection on large text data. Experimental comparison given on real-world data collected from Web users shows that characteristics of the problem domain and machine learning algorithm should be considered when feature scoring measure is selected. Our problem domain consists of hyperlinks given in a form of small-documents represented with word vectors. In our learning experiments naive Bayesian classifier was used on text data. The best performance was achieved by the feature selection methods based on the feature scoring measure called Odds ratio that is known from information retrieval."
            },
            "slug": "Feature-Subset-Selection-in-Text-Learning-Mladenic",
            "title": {
                "fragments": [],
                "text": "Feature Subset Selection in Text-Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Experimental comparison given on real-world data collected from Web users shows that characteristics of the problem domain and machine learning algorithm should be considered when feature scoring measure is selected."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2237198,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d81d19d270106805389d22b8d54b1f755797d440",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies noise reduction for computational efficiency improvements in a statistical learning method for text categorization, the Linear Least Squares Fit (LLSF) mapping. Multiple noise reduction strategies are proposedand evaluated, including: an aggressive removal of \u201cnon-informative words\u201d from texts before training; the use of a truncated singular value decomposition to cut off noisy \u201clatent semantic structures\u201d during training; the elimination of non-influential components in the LLSF solution (a word-concept association matrix) after training. Text collections in different domains were used for evaluation. Significant improvements in computational efficiency without losing categorization accuracy were evident in the testing results."
            },
            "slug": "Noise-reduction-in-a-statistical-approach-to-text-Yang",
            "title": {
                "fragments": [],
                "text": "Noise reduction in a statistical approach to text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Noise reduction strategies are proposed and evaluated, including an aggressive removal of \u201cnon-informative words\u201d from texts before training; the use of a truncated singular value decomposition to cut off noisy \u201clatent semantic structures\u201d during training."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2685671"
                        ],
                        "name": "L. F. Rau",
                        "slug": "L.-F.-Rau",
                        "structuredName": {
                            "firstName": "Lisa",
                            "lastName": "Rau",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. F. Rau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770316"
                        ],
                        "name": "P. Jacobs",
                        "slug": "P.-Jacobs",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Jacobs",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jacobs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other examples of this \u201cmanual\u201d approach to the construction of text classifiers are [Goodman 1990; Rau and Jacobs 1991]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13308030,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science"
            ],
            "id": "5136244c1171ab39710805a689addeae48d1dddb",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Indexing text for accurate retrieval ZS a dificuli and in)portant problem.. On-ltne information services generally depend on \u201ckeyword\u201d mdtces rather ihat~ other methods of retrieval, because of the pract~cal jealures of keywords for storage, dtssemtnatlonj and browsing m well as for retrveval. However, these methods OJ ~ndex~ng hove two major drawbacks: First, they m vst be laboriously asstgned by human indexers. Second, they are znaccuraie, because of mistakes made by these zndezers as well as the dtficulties users have tn choosing keywords jor their queries, and the ambzgulty a keyword may have. Carrent natural language text processing (AILP) lneihods help to overcome lhese problems. Such methods caa provzde auiomaiic ~ndezlng and keyword assign njeni capabilities that are at least as accuraie as human indezers in many applications. In adddlon, NLP syste?ns can merease the information conta~ned Ln keyword fields by separating keywords into segment~, or distinct fields that capture certain dtscrlminating content or relations among keywords. Th~s paper reports on a system that uses natural language text processing to derive keywords from free ted news siorles, separat,e these kegwords into segments, and awtomatica!iy butld a segmented database. The systenl M used as part of a conlmerctai news \u201ccllpplng\u201d altd relrieual prodwct. Preliminary rrsvlts show zn~provfd accuracy, as well as reduced cost. r[sulitng front fhesc oo tornated techniques."
            },
            "slug": "Creating-segmented-databases-from-free-text-for-Rau-Jacobs",
            "title": {
                "fragments": [],
                "text": "Creating segmented databases from free text for text retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A system that uses natural language text processing to derive keywords from free ted news siorles, separat,e these kegwords into segments, and awtomatica!iy butld a segmented database, as well as reduced cost."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144702"
                        ],
                        "name": "Makoto Iwayama",
                        "slug": "Makoto-Iwayama",
                        "structuredName": {
                            "firstName": "Makoto",
                            "lastName": "Iwayama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Makoto Iwayama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37090109"
                        ],
                        "name": "T. Tokunaga",
                        "slug": "T.-Tokunaga",
                        "structuredName": {
                            "firstName": "Takenobu",
                            "lastName": "Tokunaga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Tokunaga"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 67
                            }
                        ],
                        "text": "A second, popular experimental policy is proportional thresholding [Iwayama and Tokunaga 1995; Larkey 1998; Lewis 1992a; Lewis and Ringuette 1994; Wiener et al. 1995], also called Pcut in [Yang 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 68
                            }
                        ],
                        "text": "A second, popular \nexperimental pol\u00adicy is proportional thresholding [Iwayama and Tokunaga 1995; Larkey 1998; Lewis 1992a; \nLewis and Ringuette 1994; Wiener et al. 1995], also called Pcut in Yang [1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2229104,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aae3851aca403fe4ea9953ec2b312ceb21bfb36",
            "isKey": false,
            "numCitedBy": 166,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Text categorization can be viewed asaprocessof catego~ search, in which one or more categories for a testdocument are searchedfor by using given training documents with known categories. In this paper a cluster-based search with a probabilistic clustering algorithm is proposed and evaluated on two data sets. The \u201cefficiency, effectiveness, and noise tolerance of this search strategy were confirmed to be better than those of a full search, a category-based search, and a cluster-based search with nonprobabilistic clustering."
            },
            "slug": "Cluster-based-text-categorization:-a-comparison-of-Iwayama-Tokunaga",
            "title": {
                "fragments": [],
                "text": "Cluster-based text categorization: a comparison of category search strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The \u201cefficiency, effectiveness, and noise tolerance of this search strategy were confirmed to be better than those of a full search, a category-based search, and a cluster- based search with nonprobabilistic clustering."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802339"
                        ],
                        "name": "M. Pazienza",
                        "slug": "M.-Pazienza",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Pazienza",
                            "middleNames": [
                                "Teresa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazienza"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1102517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06894f06b6411af67a0ffde61d27efd86a5d31c7",
            "isKey": false,
            "numCitedBy": 916,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "It seems widely agreed that IE (Information Extraction) is now a tested language technology that has reached precision+recall values that put it in about the same position as Information Retrieval and Machine Translation, both of which are widely used commercially. There is also a clear range of practical applications that would be eased by the sort of template-style data that IE provides. The problem for wider deployment of the technology is adaptability: the ability to customize IE rapidly to new domains. In this paper we discuss some methods that have been tried to ease this problem, and to create something more rapid than the bench-mark one-month figure, which was roughly what ARPA teams in IE needed to adapt an existing system by hand to a new domain of corpora and templates. An important distinction in discussing the issue is the degree to which a user can be assumed to know what is wanted, to have preexisting templates ready to hand, as opposed to a user who has a vague idea of what is needed from a corpus. We shall discuss attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora. An important issue is how far established methods in Information Retrieval of tuning to a user\u2019s needs with feedback at an interface can be transferred to IE."
            },
            "slug": "Information-Extraction-Pazienza",
            "title": {
                "fragments": [],
                "text": "Information Extraction"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper discusses attempts to derive templates directly from corpora; to derive knowledge structures and lexicons directly from Corpora, including discussion of the recent LE project ECRAN which attempted to tune existing lexicons to new corpora."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10593270"
                        ],
                        "name": "S. L. Lam",
                        "slug": "S.-L.-Lam",
                        "structuredName": {
                            "firstName": "Savio",
                            "lastName": "Lam",
                            "middleNames": [
                                "L.",
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. L. Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692152"
                        ],
                        "name": "Lee",
                        "slug": "Lee",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 41
                            }
                        ],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used by Baker and McCallum [1998], Joachims [1997], McCallum and Nigam [1998], McCallum et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7860651,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab5866df2ab290b34550cfc1efc40aeb1f350033",
            "isKey": false,
            "numCitedBy": 162,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In a text categorization model using an artificial neural network as the text classifier scalability is poor if the neural network is trained using the raw feature space since textural data has a very high-dimension feature space. We proposed and compared four dimensionality reduction techniques to reduce the feature space into an input space of much lower dimension for the neural network classifier. To test the effectiveness of the proposed model, experiments were conducted using a subset of the Reuters-22173 test collection for text categorization. The results showed that the proposed model was able to achieve high categorization effectiveness as measured by precision and recall. Among the four dimensionality reduction techniques proposed, principal component analysis was found to be the most effective in reducing the dimensionality of the feature space."
            },
            "slug": "Feature-reduction-for-neural-network-based-text-Lam-Lee",
            "title": {
                "fragments": [],
                "text": "Feature reduction for neural network based text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed and compared four dimensionality reduction techniques to reduce the feature space into an input space of much lower dimension for the neural network classifier showed that the proposed model was able to achieve high categorization effectiveness as measured by precision and recall."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 6th International Conference on Advanced Systems for Advanced Applications"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716902"
                        ],
                        "name": "Marti A. Hearst",
                        "slug": "Marti-A.-Hearst",
                        "structuredName": {
                            "firstName": "Marti",
                            "lastName": "Hearst",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marti A. Hearst"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 2
                            }
                        ],
                        "text": "g [Gale et al. 1993; Hearst 1991]) once we view word occurrence contexts as documents and word senses as categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8112529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f041c48820535bfaf374b162cfc6acfc52ff87d",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an accurate, relatively inexpensive method for the disambiguation of noun homographs using large text corpora. The algorithm checks the context surrounding the target noun against that of previously observed instances and chooses the sense for which the most evidence is found, where evidence consists of a set of orthographic, syntactic, and lexical features. Because the sense distinctions made are coarse, the disambiguation can be accomplished without the expense of knowledge bases or inference mechanisms. An implementation of the algorithm is described which, starting with a small set of hand-labeled instances, improves its results automatically via unsupervised training. The approach is compared to other attempts at homograph disambiguation using both machine readable dictionaries and unrestricted text and the use of training instances is determined to be a crucial di erence."
            },
            "slug": "Noun-Homograph-Disambiguation-Using-Local-Context-Hearst",
            "title": {
                "fragments": [],
                "text": "Noun Homograph Disambiguation Using Local Context in Large Text Corpora"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An accurate, relatively inexpensive method for the disambiguation of noun homographs using large text corpora using both machine readable dictionaries and unrestricted text and the use of training instances is determined to be a crucial di erence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8754851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd9fd8a36c8feb74bb20ae25817edb9c6a0518c",
            "isKey": false,
            "numCitedBy": 1401,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering. Senses are interpreted as groups (or clusters) of similar contexts of the ambiguous word. Words, contexts, and senses are represented in Word Space, a high-dimensional, real-valued space in which closeness corresponds to semantic similarity. Similarity in Word Space is based on second-order co-occurrence: two tokens (or contexts) of the ambiguous word are assigned to the same sense cluster if the words they co-occur with in turn occur with similar words in a training corpus. The algorithm is automatic and unsupervised in both training and application: senses are induced from a corpus without labeled training instances or other external knowledge sources. The paper demonstrates good performance of context-group discrimination for a sample of natural and artificial ambiguous words."
            },
            "slug": "Automatic-Word-Sense-Discrimination-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Automatic Word Sense Discrimination"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents context-group discrimination, a disambiguation algorithm based on clustering that demonstrates good performance of context- group discrimination for a sample of natural and artificial ambiguous words."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Linguistics"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056360"
                        ],
                        "name": "William W. Cohen",
                        "slug": "William-W.-Cohen",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cohen",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William W. Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "Cohen [1995a] has extensively compared PL and FOL learning in \nTC (for instance, comparing the PL learner RIPPER with its FOL version FLIPPER), and has found that the \nadditional represen\u00adtational power of FOL brings about only modest bene.ts. 6.5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 126
                            }
                        ],
                        "text": "In their experiments this technique outper\u00adformed a number of other classi.ers, \nsuch as a C4.5 decision tree classi.er and the RIPPER CNF rule-based classi.er."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 140
                            }
                        ],
                        "text": "Among \nthe DNF rule learners that have been applied to TC are CHARADE [Moulinier and Ganascia 1996], DL-ESC \n[Li and Yamanishi 1999], RIPPER [Cohen 1995a; Cohen and Hirsh 1998; Cohen and Singer 1999], SCAR [Moulinier \net al. 1996], and SWAP-1 [Apt\u00b4 e 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 53
                            }
                        ],
                        "text": "For other examples of significance testing in TC see [Cohen 1995a; Cohen 1995b; Cohen and Hirsh 1998; Joachims 1997; Koller and Sahami 1997; Lewis et al. 1996; Wiener et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 235
                            }
                        ],
                        "text": "\u2026words, \nthe semantics of a document is reduced to the collective lexical semantics of the terms that occur in \nit, thereby disregarding the issue of compositional semantics (an ex\u00adception are the representation techniques \nused for FOIL [Cohen 1995a] and SLEEPING EXPERTS [Cohen and Singer 1999])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 716,
                                "start": 710
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                }
            ],
            "corpusId": 47270497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90848c88f56fcd421ac3cfd2c87d3e61211103ea",
            "isKey": true,
            "numCitedBy": 107,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Text-Categorization-and-Relational-Learning-Cohen",
            "title": {
                "fragments": [],
                "text": "Text Categorization and Relational Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693517"
                        ],
                        "name": "David Yarowsky",
                        "slug": "David-Yarowsky",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Yarowsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Yarowsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 2
                            }
                        ],
                        "text": "g [Gale et al. 1993; Escudero et al. 2000]) once we view word occurrence contexts as documents and word senses as categories."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17567112,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf35ed0864ff6cf524a24f0a65aa6951f9d6f214",
            "isKey": false,
            "numCitedBy": 657,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Word sense disambiguation has been recognized as a major problem in natural language processing research for over forty years. Both quantitive and qualitative methods have been tried, but much of this work has been stymied by difficulties in acquiring appropriate lexical resources. The availability of this testing and training material has enabled us to develop quantitative disambiguation methods that achieve 92% accuracy in discriminating between two very distinct senses of a noun. In the training phase, we collect a number of instances of each sense of the polysemous noun. Then in the testing phase, we are given a new instance of the noun, and are asked to assign the instance to one of the senses. We attempt to answer this question by comparing the context of the unknown instance with contexts of known instances using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval. The proposed method is probably most appropriate for those aspects of sense disambiguation that are closest to the information retrieval task. In particular, the proposed method was designed to disambiguate senses that are usually associated with different topics."
            },
            "slug": "A-method-for-disambiguating-word-senses-in-a-large-Gale-Church",
            "title": {
                "fragments": [],
                "text": "A method for disambiguating word senses in a large corpus"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The proposed method was designed to disambiguate senses that are usually associated with different topics using a Bayesian argument that has been applied successfully in related tasks such as author identification and information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Humanit."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691993"
                        ],
                        "name": "E. Riloff",
                        "slug": "E.-Riloff",
                        "structuredName": {
                            "firstName": "Ellen",
                            "lastName": "Riloff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Riloff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1357817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17c1a3d78cb2547ad41ddb9b6f72f8b570fc1cff",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Most information retrieval systems use stopword lists and stemming algorithms. However, we have found that recognizing singular and plural nouns, verb forms, negation, and prepositions can produce dramatically different text classification results. We present results from text classification experiments that compare relevancy signatures, which use local linguistic context, with corresponding indexing terms that do not. In two different domains, relevancy signatures produced better results than the simple indexing terms. These experiments suggest that stopword lists and stemming algorithms may remove or conflate many words that could be used to create more effective indexing terms."
            },
            "slug": "Little-words-can-make-a-big-difference-for-text-Riloff",
            "title": {
                "fragments": [],
                "text": "Little words can make a big difference for text classification"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work presents results from text classification experiments that compare relevancy signatures, which use local linguistic context, with corresponding indexing terms that do not, and suggests that stopword lists and stemming algorithms may remove or conflate many words that could be used to create more effective indexing Terms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365155"
                        ],
                        "name": "S. Deerwester",
                        "slug": "S.-Deerwester",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Deerwester",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Deerwester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737579"
                        ],
                        "name": "G. Furnas",
                        "slug": "G.-Furnas",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Furnas",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Furnas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154682"
                        ],
                        "name": "R. Harshman",
                        "slug": "R.-Harshman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Harshman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Harshman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 31
                            }
                        ],
                        "text": "Latent se\u00admantic indexing (LSI [Deerwester et al. 1990]) is a DR technique developed in IR in order to \naddress the problems deriv\u00ading from the use of synonymous, near\u00adsynonymous, and polysemous words as dimensions \nof document representations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3252915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20a80a7356859daa4170fb4da6b87b84adbb547f",
            "isKey": false,
            "numCitedBy": 7019,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising."
            },
            "slug": "Indexing-by-Latent-Semantic-Analysis-Deerwester-Dumais",
            "title": {
                "fragments": [],
                "text": "Indexing by Latent Semantic Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "A new method for automatic indexing and retrieval to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9131020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92062ccb796efbf56fe1ae2dcc8b3a943a2c989b",
            "isKey": false,
            "numCitedBy": 566,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we compare learning techniques based on statistical classification to traditional methods of relevance feedback for the document routing problem. We consider three classification techniques which have decision rules that are derived via explicit error minimization: linear discriminant analysis, logistic regression, and neural networks. We demonstrate that the classifiers perform 1015% better than relevance feedback via Rocchio expansion for the TREC-2 and TREC-3 routing tasks. Error minimization is difficult in high-dimensional feature spaces because the convergence process is slow and the models are prone to overfitting. We use two different strategies, latent semantic indexing and optimal term selection, to reduce the number of features. Our results indicate that features based on latent semantic indexing are more effective for techniques such as linear discriminant analysis and logistic regression, which have no way to protect against overfitting. Neural networks perform equally well with either set of features and can take advantage of the additional information available when both feature sets are used as input."
            },
            "slug": "A-comparison-of-classifiers-and-document-for-the-Sch\u00fctze-Hull",
            "title": {
                "fragments": [],
                "text": "A comparison of classifiers and document representations for the routing problem"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper compares learning techniques based on statistical classification to traditional methods of relevance feedback for the document routing problem and indicates that features based on latent semantic indexing are more effective for techniques such as linear discriminant analysis and logistic regression, which have no way to protect against overfitting."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6134427,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aab43c9c33af00b718cf2ae374b861d49862a563",
            "isKey": false,
            "numCitedBy": 15727,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine Learning is the study of methods for programming computers to learn. Computers are applied to a wide range of tasks, and for most of these it is relatively easy for programmers to design and implement the necessary software. However, there are many tasks for which this is difficult or impossible. These can be divided into four general categories. First, there are problems for which there exist no human experts. For example, in modern automated manufacturing facilities, there is a need to predict machine failures before they occur by analyzing sensor readings. Because the machines are new, there are no human experts who can be interviewed by a programmer to provide the knowledge necessary to build a computer system. A machine learning system can study recorded data and subsequent machine failures and learn prediction rules. Second, there are problems where human experts exist, but where they are unable to explain their expertise. This is the case in many perceptual tasks, such as speech recognition, hand-writing recognition, and natural language understanding. Virtually all humans exhibit expert-level abilities on these tasks, but none of them can describe the detailed steps that they follow as they perform them. Fortunately, humans can provide machines with examples of the inputs and correct outputs for these tasks, so machine learning algorithms can learn to map the inputs to the outputs. Third, there are problems where phenomena are changing rapidly. In finance, for example, people would like to predict the future behavior of the stock market, of consumer purchases, or of exchange rates. These behaviors change frequently, so that even if a programmer could construct a good predictive computer program, it would need to be rewritten frequently. A learning program can relieve the programmer of this burden by constantly modifying and tuning a set of learned prediction rules. Fourth, there are applications that need to be customized for each computer user separately. Consider, for example, a program to filter unwanted electronic mail messages. Different users will need different filters. It is unreasonable to expect each user to program his or her own rules, and it is infeasible to provide every user with a software engineer to keep the rules up-to-date. A machine learning system can learn which mail messages the user rejects and maintain the filtering rules automatically. Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis. Statistics focuses on understanding the phenomena that have generated the data, often with the goal of testing different hypotheses about those phenomena. Data mining seeks to find patterns in the data that are understandable by people. Psychological studies of human learning aspire to understand the mechanisms underlying the various learning behaviors exhibited by people (concept learning, skill acquisition, strategy change, etc.)."
            },
            "slug": "Machine-learning-Dietterich",
            "title": {
                "fragments": [],
                "text": "Machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Machine learning addresses many of the same research questions as the fields of statistics, data mining, and psychology, but with differences of emphasis."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144590225"
                        ],
                        "name": "D. Roth",
                        "slug": "D.-Roth",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Roth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Roth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1785,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ed17a1114e2dc48597ab17cc8d5234006f525c9",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze a few of the commonly used statistics based and machine learning algorithms for natural language disambiguation tasks and observe that they can be recast as learning linear separators in the feature space. Each of the methods makes a priori assumptions which it employs, given the data, when searching for its hypothesis. Nevertheless, as we show, it searches a space that is as rich as the space of all linear separators. We use this to build an argument for a data driven approach which merely searches for a good linear separator in the feature space, without further assumptions on the domain or a specific problem.We present such an approach - a sparse network of linear separators, utilizing the Winnow learning algorithm - and show how to use it in a variety of ambiguity resolution problems. The learning approach presented is attribute-efficient and, therefore, appropriate for domains having very large number of attributes.In particular, we present an extensive experimental comparison of our approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging. In all cases we show that our approach either outperforms other methods tried for these tasks or performs comparably to the best."
            },
            "slug": "Learning-to-Resolve-Natural-Language-Ambiguities:-A-Roth",
            "title": {
                "fragments": [],
                "text": "Learning to Resolve Natural Language Ambiguities: A Unified Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An extensive experimental comparison of the approach with other methods on several well studied lexical disambiguation tasks such as context-sensitive spelling correction, prepositional phrase attachment and part of speech tagging shows that it outperforms other methods tried for these tasks or performs comparably to the best."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2274294"
                        ],
                        "name": "R. Klinkenberg",
                        "slug": "R.-Klinkenberg",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Klinkenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Klinkenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680188"
                        ],
                        "name": "T. Joachims",
                        "slug": "T.-Joachims",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Joachims",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Joachims"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2274179,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b9ce3415654bd4d5f6c311adb26c1d50dcc1372",
            "isKey": false,
            "numCitedBy": 482,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "For many learning tasks where data is collected over an extended period of time, its underlying distribution is likely to change. A typical example is information ltering, i.e. the adaptive classiication of documents with respect to a particular user interest. Both the interest of the user and the document content change over time. A ltering system should be able to adapt to such concept changes. This paper proposes a new method to recognize and handle concept changes with support vector machines. The method maintains a window on the training data. The key idea is to automatically adjust the window size so that the estimated generalization error is minimized. The new approach is both theoretically well-founded as well as eeective and eecient in practice. Since it does not require complicated parameterization, it is simpler to use and more robust than comparable heuristics. Experiments with simulated concept drift scenarios based on real-world text data compare the new method with other window management approaches. We show that it can eeectively select an appropriate window size in a robust way."
            },
            "slug": "Detecting-Concept-Drift-with-Support-Vector-Klinkenberg-Joachims",
            "title": {
                "fragments": [],
                "text": "Detecting Concept Drift with Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new method to recognize and handle concept changes with support vector machines that maintains a window on the training data and can eeectively select an appropriate window size in a robust way is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34929449"
                        ],
                        "name": "George H. John",
                        "slug": "George-H.-John",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "John",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George H. John"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726733"
                        ],
                        "name": "Ron Kohavi",
                        "slug": "Ron-Kohavi",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kohavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Kohavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30079006"
                        ],
                        "name": "Karl Pfleger",
                        "slug": "Karl-Pfleger",
                        "structuredName": {
                            "firstName": "Karl",
                            "lastName": "Pfleger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karl Pfleger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15089378,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f7cc43c9dbf6991a91db6314523bec861d087b86",
            "isKey": false,
            "numCitedBy": 2679,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Irrelevant-Features-and-the-Subset-Selection-John-Kohavi",
            "title": {
                "fragments": [],
                "text": "Irrelevant Features and the Subset Selection Problem"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2455696"
                        ],
                        "name": "P. H. Klingbiel",
                        "slug": "P.-H.-Klingbiel",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Klingbiel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H. Klingbiel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The use of utility measures in TC is discussed in detail by Lewis [1995a]. Other works where utility measures are employed are [Amati and Crestani 1999; Cohen and Singer 1999; Hull et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The first use to which automatic text classifiers were put at, and the application that spawned most of the early research in the field [Borko and Bernick 1963; Fangmeyer and Lustig 1968; Field 1975; Gray and Harley 1971; Hamill and Zamora 1978; Hamill and Zamora 1980; Heaps 1973; Hoyle 1973; Klingbiel 1973a; Klingbiel 1973b; Maron 1961], is that of automatic document indexing for use in information retrieval (IR) systems relying on a controlled dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33180854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e70b8b6408932e3df8150bf3b0dc125156b242f",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Machine-aided-indexing-of-technical-literature-Klingbiel",
            "title": {
                "fragments": [],
                "text": "Machine-aided indexing of technical literature"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Storage Retr."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3310475"
                        ],
                        "name": "Jochen D\u00f6rre",
                        "slug": "Jochen-D\u00f6rre",
                        "structuredName": {
                            "firstName": "Jochen",
                            "lastName": "D\u00f6rre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jochen D\u00f6rre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703913"
                        ],
                        "name": "P. Gerstl",
                        "slug": "P.-Gerstl",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Gerstl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gerstl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2446081"
                        ],
                        "name": "R. Seiffert",
                        "slug": "R.-Seiffert",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Seiffert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Seiffert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 250,
                                "start": 203
                            }
                        ],
                        "text": "Current-day TC is thus a discipline at the crossroads of ML and IR, and as such it shares a number of characteristics with other tasks such as information/knowledge extraction from texts and text mining [D\u00f6rre et al. 1999; Knight 1999; Pazienza 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3878042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7175428d95d3b92741018e2889fc593b08e0a259",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Text mining applies the same analytical functions of data mining to the domain of textual information, relying on sophisticated text analysis techniques that distill information from free-text documents. IBM\u2019s Intelligent Miner for Text provides the necessary tools to unlock the business information that is \u201ctrapped\u201d in email, insurance claims, news feeds, or other document repositories. It has been successfully applied in analyzing patent portfolios, customer complaint letters, and even competitors\u2019 Web pages. After defining our notion of \u201ctext mining\u201d, we focus on the differences between text and data mining and describe in some more detail the unique technologies that are key to successful text mining."
            },
            "slug": "Text-mining:-finding-nuggets-in-mountains-of-data-D\u00f6rre-Gerstl",
            "title": {
                "fragments": [],
                "text": "Text mining: finding nuggets in mountains of textual data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work defines the notion of \u201ctext mining\u201d, focuses on the differences between text and data mining, and describes in some more detail the unique technologies that are key to successful text mining."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050470845"
                        ],
                        "name": "H. Drucker",
                        "slug": "H.-Drucker",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Drucker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Drucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116668597"
                        ],
                        "name": "Donghui Wu",
                        "slug": "Donghui-Wu",
                        "structuredName": {
                            "firstName": "Donghui",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donghui Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 95
                            }
                        ],
                        "text": "Similarly, an e-mail .lter might be trained to discard junk mail [Androutsopoulos \net al. 2000; Drucker et al. 1999] and further classify nonjunk mail into topical categories of in\u00adterest \nto the user."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14895712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29fa9b903dbd8d19e39b0d7fb06efc6a1907dfdb",
            "isKey": false,
            "numCitedBy": 1429,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the use of support vector machines (SVM's) in classifying e-mail as spam or nonspam by comparing it to three other classification algorithms: Ripper, Rocchio, and boosting decision trees. These four algorithms were tested on two different data sets: one data set where the number of features were constrained to the 1000 best features and another data set where the dimensionality was over 7000. SVM's performed best when using binary features. For both data sets, boosting trees and SVM's had acceptable test performance in terms of accuracy and speed. However, SVM's had significantly less training time."
            },
            "slug": "Support-vector-machines-for-spam-categorization-Drucker-Wu",
            "title": {
                "fragments": [],
                "text": "Support vector machines for spam categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "The use of support vector machines in classifying e-mail as spam or nonspam is studied by comparing it to three other classification algorithms: Ripper, Rocchio, and boosting decision trees, which found SVM's performed best when using binary features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764321"
                        ],
                        "name": "D. Mladenic",
                        "slug": "D.-Mladenic",
                        "structuredName": {
                            "firstName": "Dunja",
                            "lastName": "Mladenic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mladenic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775954"
                        ],
                        "name": "M. Grobelnik",
                        "slug": "M.-Grobelnik",
                        "structuredName": {
                            "firstName": "Marko",
                            "lastName": "Grobelnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Grobelnik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14534907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8317e01a4b7c94d5138d14ab3a4cf77a42977e89",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Dunja Mladeni c & Marko Grobelnik J.Stefan Institute Jamova 39, 1000 Ljubljana, Slovenia Dunja.Mladenic@ijs.si, Marko.Grobelnik@ijs.si Abstract This paper proposes an e cient algorithm for the generation of new features that enrich the known bagof-words document representation. New features are generated based on word sequences of di erent length. Learning is performed using Naive Bayesian classi er on feature-vectors, where only highly scored features are used. The performance of enriched document representation is evaluated on the problem of automatic document categorization using Yahoo text hierarchy. Our experiments show that using word sequences of length up to 3 instead of using only single words improves the performance, while longer sequences in average have no in uence to the performance."
            },
            "slug": "Word-sequences-as-features-in-text-learning-Mladenic-Grobelnik",
            "title": {
                "fragments": [],
                "text": "Word sequences as features in text-learning"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "Experiments show that using word sequences of length up to 3 instead of using only single words improves the performance, while longer sequences in average have no effect on the performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46442363"
                        ],
                        "name": "K. Lang",
                        "slug": "K.-Lang",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Lang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Lang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1921714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38b3a4447a47a6a6ed1869f3da03352c487f8fe3",
            "isKey": false,
            "numCitedBy": 2117,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "NewsWeeder:-Learning-to-Filter-Netnews-Lang",
            "title": {
                "fragments": [],
                "text": "NewsWeeder: Learning to Filter Netnews"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 0
                            }
                        ],
                        "text": "[Fuhr 1989; Salton and Buckley 1988]) accounting for the \u201cimportance\u201d of tk for dj play a key role in IR."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 1
                            }
                        ],
                        "text": "[Salton and Buckley 1988]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 161
                            }
                        ],
                        "text": "As such, this \nwould seem to contradict a well-known law of IR, according to which the terms with low-to-medium document \nfrequency are the most informative ones [Salton and Buckley 1988]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 179
                            }
                        ],
                        "text": "1998; Lewis 1992a] it has been found that representations more sophisticated than this do not yield significantly better effectiveness, thereby confirming similar results from IR [Salton and Buckley 1988]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 162
                            }
                        ],
                        "text": "As such, this would seem to contradict a well-known \u201claw\u201d of IR, according to which the terms with low-to-medium document frequency are the most informative ones [Salton and Buckley 1988]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 67
                            }
                        ],
                        "text": "Formula 1 is just one of the possible instances of this class; see [Salton and Buckley 1988; Singhal et al. 1996] for variations on this theme."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7725217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50a316f97c9a405aa000d883a633bd5707f1a34",
            "isKey": true,
            "numCitedBy": 9461,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Term-Weighting-Approaches-in-Automatic-Text-Salton-Buckley",
            "title": {
                "fragments": [],
                "text": "Term-Weighting Approaches in Automatic Text Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7913028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5a4f203dcc8ee607a3d41c1f96c5e91f4a66117",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss two learning algorithms for text filtering: modified Rocchio and a boosting algorithm called AdaBoost. We show how both algorithms can be adapted to maximize any general utility matrix that associates cost (or gain) for each pair of machine prediction and correct label. We first show that AdaBoost significantly outperforms another highly effective text filtering algorithm. We then compare AdaBoost and Rocchio over three large text filtering tasks. Overall both algorithms are comparable and are quite effective. AdaBoost produces better classifiers than Rocchio when the training collection contains a very large number of relevant documents. However, on these tasks, Rocchio runs much faster than AdaBoost."
            },
            "slug": "Boosting-and-Rocchio-applied-to-text-filtering-Schapire-Singer",
            "title": {
                "fragments": [],
                "text": "Boosting and Rocchio applied to text filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper discusses two learning algorithms for text filtering: modified Rocchio and a boosting algorithm called AdaBoost, and shows how both algorithms can be adapted to maximize any general utility matrix that associates cost for each pair of machine prediction and correct label."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144850246"
                        ],
                        "name": "Louise Guthrie",
                        "slug": "Louise-Guthrie",
                        "structuredName": {
                            "firstName": "Louise",
                            "lastName": "Guthrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Louise Guthrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2967060"
                        ],
                        "name": "E. Walker",
                        "slug": "E.-Walker",
                        "structuredName": {
                            "firstName": "Elbert",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9108563,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "171592f09aeb1e8720154e4f0b5d59b81b5f9a10",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "In this note, we present results concerning the theory and practice of determining for a given document which of several categories it best fits. We describe a mathematical model of classification schemes and the one scheme which can be proved optimal among all those based on word frequencies. Finally, we report the results of an experiment which illustrates the efficacy of this classification method."
            },
            "slug": "Document-Classification-by-Machine:Theory-and-Guthrie-Walker",
            "title": {
                "fragments": [],
                "text": "Document Classification by Machine:Theory and Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A mathematical model of classification schemes and the one scheme which can be proved optimal among all those based on word frequencies is described and an experiment illustrates the efficacy of this classification method."
            },
            "venue": {
                "fragments": [],
                "text": "COLING"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144610645"
                        ],
                        "name": "P. Willett",
                        "slug": "P.-Willett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Willett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Willett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[Willett 1988b])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17113895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fb58b6de34ae18174a111a9f32efaf79bbb0bbe",
            "isKey": false,
            "numCitedBy": 877,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Recent-trends-in-hierarchic-document-clustering:-A-Willett",
            "title": {
                "fragments": [],
                "text": "Recent trends in hierarchic document clustering: A critical review"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724728"
                        ],
                        "name": "R. Tong",
                        "slug": "R.-Tong",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Tong",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3436703"
                        ],
                        "name": "Adam S. Winkler",
                        "slug": "Adam-S.-Winkler",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Winkler",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam S. Winkler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097866859"
                        ],
                        "name": "P. Gage",
                        "slug": "P.-Gage",
                        "structuredName": {
                            "firstName": "Pamela",
                            "lastName": "Gage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Gage"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 35115314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ff1bee7ddba26462105b4c91c901dad20ce407a",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe an approach to document routing on the TREC corpus that employs a technique for the automatic construction of classification trees. The approach makes use of the Classification and Regression Trees (CART) algorithm that has seen application in various areas of machine learning"
            },
            "slug": "Classification-Trees-for-Document-Routing,-A-Report-Tong-Winkler",
            "title": {
                "fragments": [],
                "text": "Classification Trees for Document Routing, A Report on the TREC Experiment"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An approach to document routing on the TREC corpus that employs a technique for the automatic construction of classification trees that has seen application in various areas of machine learning."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742457"
                        ],
                        "name": "L. Larkey",
                        "slug": "L.-Larkey",
                        "structuredName": {
                            "firstName": "Leah",
                            "lastName": "Larkey",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Larkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 185413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25360587f36bfa025542cfb3484fb08c93b96926",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a system for searching and classifying U.S. patent documents, based on Inquery. Patents are distributed through hundreds of collections, divided up by general area. The system selects the best collections for the query. Users can search for patents or classify patent text. The user interface helps users search in fields without requiring the knowledge of Inquery query operators. The system includes a unique \u201cphrase help\u201d facility, which helps users find and add phrases and terms related to those in their query."
            },
            "slug": "A-patent-search-and-classification-system-Larkey",
            "title": {
                "fragments": [],
                "text": "A patent search and classification system"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A system for searching and classifying U.S. patent documents, based on Inquery, which includes a unique \u201cphrase help\u201d facility, which helps users find and add phrases and terms related to those in their query."
            },
            "venue": {
                "fragments": [],
                "text": "DL '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144864352"
                        ],
                        "name": "M. Maron",
                        "slug": "M.-Maron",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Maron",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6692916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c390dbf06af49d3691bc7b906f5fd9b909c2f89b",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This inquiry examines a technique for automatically classifying (indexing) documents according to their subject content. The task, in essence, is to have a computing machine read a document and on the basis of the occurrence of selected clue words decide to which of many subject categories the document in question belongs. This paper describes the design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexing."
            },
            "slug": "Automatic-Indexing:-An-Experimental-Inquiry-Maron",
            "title": {
                "fragments": [],
                "text": "Automatic Indexing: An Experimental Inquiry"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The design, execution and evaluation of a modest experimental study aimed at testing empirically one statistical technique for automatic indexed documents according to their subject content are described."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145786318"
                        ],
                        "name": "G. Escudero",
                        "slug": "G.-Escudero",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Escudero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Escudero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049328"
                        ],
                        "name": "Llu\u00eds M\u00e0rquez i Villodre",
                        "slug": "Llu\u00eds-M\u00e0rquez-i-Villodre",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Villodre",
                            "middleNames": [
                                "M\u00e0rquez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds M\u00e0rquez i Villodre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 208022631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8953bdaf26842dc7cd5a76a53a5b9b77d65eef30",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we apply Schapire and Singer's AdaBoost.MH boosting algorithm to the Word Sense Disambiguation (WSD) \nproblem. Initial experiments on a set of 15 selected polysemous words show that the boosting approach surpasses Naive Bayes \nand Exemplar--based approaches, which represent state--of--the--art accuracy on WSD. In order to make boosting practical for a \nreal learning domain of thousands of words we study several ways of accelerating the algorithm by reducing the feature space. \nThe best variant, which we call LazyBoosting, is tested on a medium--large sense--tagged corpus containing 192,800 examples of \nthe 191 most frequent and ambiguous English words. Again, boosting compares favourably to the other benchmank algorithms."
            },
            "slug": "Boosting-Applied-to-Word-Sense-Disambiguation-Escudero-Villodre",
            "title": {
                "fragments": [],
                "text": "Boosting Applied to Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Initial experiments show that the boosting approach surpasses Naive Bayes and Exemplar--based approaches, which represent state-of-the-art accuracy on WSD, and compares favourably to the other benchmank algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34734963"
                        ],
                        "name": "B. Kessler",
                        "slug": "B.-Kessler",
                        "structuredName": {
                            "firstName": "Brett",
                            "lastName": "Kessler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kessler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144462875"
                        ],
                        "name": "G. Nunberg",
                        "slug": "G.-Nunberg",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Nunberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Nunberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 213
                            }
                        ],
                        "text": "\u20262000], author \niden\u00adti.cation for literary texts of unknown or disputed authorship [Forsyth 1999], lan\u00adguage identi.cation \nfor texts of unknown language [Cavnar and Trenkle 1994], automated identi.cation of text genre [Kessler \net al. 1997], and automated essay grading [Larkey 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 376,
                                "start": 355
                            }
                        ],
                        "text": "2000; Schapire and Singer 2000], multimedia document categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author identification for literary texts of unknown or disputed authorship [Forsyth 1999], language identification for texts of unknown language [Cavnar and Trenkle 1994], automated identification of text genre [Kessler et al. 1997], and automated essay grading [Larkey 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11113728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbfbe12f4f16d02b987759d97cc8430f016569d2",
            "isKey": false,
            "numCitedBy": 439,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "As the text databases available to users become larger and more heterogeneous, genre becomes increasingly important for computational linguistics as a complement to topical and structural principles of classification. We propose a theory of genres as bundles of facets, which correlate with various surface cues, and argue that genre detection based on surface cues is as successful as detection based on deeper structural properties."
            },
            "slug": "Automatic-Detection-of-Text-Genre-Kessler-Nunberg",
            "title": {
                "fragments": [],
                "text": "Automatic Detection of Text Genre"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A theory of genres as bundles of facets, which correlate with various surface cues, are proposed, and it is argued that genre detection based on surface cues is as successful as Detection based on deeper structural properties."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153873834"
                        ],
                        "name": "A. Wong",
                        "slug": "A.-Wong",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40498308"
                        ],
                        "name": "Chung-Shu Yang",
                        "slug": "Chung-Shu-Yang",
                        "structuredName": {
                            "firstName": "Chung-Shu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chung-Shu Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "[Salton et al. 1975]) that the large majority of the words occurring in a corpus have a very low document frequency; this means that by reducing the term set by a factor of 10 using document frequency, only such words are removed, while the words from low-to-medium to high document frequency are preserved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6473756,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5f169880e30e1f76827d72f862555d00b01bed9",
            "isKey": false,
            "numCitedBy": 7617,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In a document retrieval, or other pattern matching environment where stored entities (documents) are compared with each other or with incoming patterns (search requests), it appears that the best indexing (property) space is one where each entity lies as far away from the others as possible; in these circumstances the value of an indexing system may be expressible as a function of the density of the object space; in particular, retrieval performance may correlate inversely with space density. An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents. Typical evaluation results are shown, demonstating the usefulness of the model."
            },
            "slug": "A-vector-space-model-for-automatic-indexing-Salton-Wong",
            "title": {
                "fragments": [],
                "text": "A vector space model for automatic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An approach based on space density computations is used to choose an optimum indexing vocabulary for a collection of documents, demonstating the usefulness of the model."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121352283"
                        ],
                        "name": "Van Rijsbergen",
                        "slug": "Van-Rijsbergen",
                        "structuredName": {
                            "firstName": "Van",
                            "lastName": "Rijsbergen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Van Rijsbergen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62560433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ea50374077a506b86dce4796c683abcd98e18d7",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper provides a foundation for a practical way of improving the effectiveness of an automatic retrieval system. Its main concern is with the weighting of index terms as a device for increasing retrieval effectiveness. Previously index terms have been assumed to be independent for the good reason that then a very simple weighting scheme can be used. In reality index terms are most unlikely to be independent. This paper explores one way of removing the independence assumption. Instead the extent of the dependence between index terms is measured and used to construct a non\u2010linear weighting function. In a practical situation the values of some of the parameters of such a function must be estimated from small samples of documents. So a number of estimation rules are discussed and one in particular is recommended. Finally the feasibility of the computations required for a non\u2010linear weighting scheme is examined."
            },
            "slug": "A-theoretical-basis-for-the-use-of-co-occurence-in-Rijsbergen",
            "title": {
                "fragments": [],
                "text": "A theoretical basis for the use of co-occurence data in information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper provides a foundation for a practical way of improving the effectiveness of an automatic retrieval system by measuring the extent of the dependence between index terms and using it to construct a non\u2010linear weighting function."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144002848"
                        ],
                        "name": "W. Gray",
                        "slug": "W.-Gray",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Gray",
                            "middleNames": [
                                "Alex"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29815157"
                        ],
                        "name": "A. Harley",
                        "slug": "A.-Harley",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Harley",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Harley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 73
                            }
                        ],
                        "text": "The application that has spawned most of the early research in the field [Borko and Bernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961], is that"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Boolean Information \nRetrieval Systems The application that has spawned most of the early research in the .eld [Borko and \nBernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961] is that of automatic document \nindexing for IR systems relying on a controlled dictionary, the most\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 40097002,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52992f8a805e93f98a510d544e398b43cded2ccd",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Computer-assisted-indexing-Gray-Harley",
            "title": {
                "fragments": [],
                "text": "Computer assisted indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Storage Retr."
            },
            "year": 1971
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145786318"
                        ],
                        "name": "G. Escudero",
                        "slug": "G.-Escudero",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Escudero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Escudero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049328"
                        ],
                        "name": "Llu\u00eds M\u00e0rquez i Villodre",
                        "slug": "Llu\u00eds-M\u00e0rquez-i-Villodre",
                        "structuredName": {
                            "firstName": "Llu\u00eds",
                            "lastName": "Villodre",
                            "middleNames": [
                                "M\u00e0rquez",
                                "i"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Llu\u00eds M\u00e0rquez i Villodre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785173"
                        ],
                        "name": "German Rigau",
                        "slug": "German-Rigau",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Rigau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "German Rigau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3263109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c4de7862ddd4c899f6ab5b73e882f6f6f61a486",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper Schapire and Singer's AdaBoost. MH boosting algorithm is applied to the Word Sense Disambiguation (WSD) problem. Initial experiments on a set of 15 selected polysemous words show that the boosting approach surpasses Naive Bayes and Exemplar-based approaches, which represent state-of-the-art accuracy on supervised WSD. In order to make boosting practical for a real learning domain of thousands of words, several ways of accelerating the algorithm by reducing the feature space are studied. The best variant, which we call LazyBoosting, is tested on the largest sense-tagged corpus available containing 192, 800 examples of the 191 most frequent and ambiguous English words. Again, boosting compares favourably to the other benchmark algorithms."
            },
            "slug": "Boosting-Applied-toe-Word-Sense-Disambiguation-Escudero-Villodre",
            "title": {
                "fragments": [],
                "text": "Boosting Applied toe Word Sense Disambiguation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Initial experiments show that the boosting approach surpasses Naive Bayes and Exemplar-based approaches, which represent state-of-the-art accuracy on supervised WSD, and compares favourably to the other benchmark algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2455696"
                        ],
                        "name": "P. H. Klingbiel",
                        "slug": "P.-H.-Klingbiel",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Klingbiel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. H. Klingbiel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The first use to which automatic text classifiers were put at, and the application that spawned most of the early research in the field [Borko and Bernick 1963; Fangmeyer and Lustig 1968; Field 1975; Gray and Harley 1971; Hamill and Zamora 1978; Hamill and Zamora 1980; Heaps 1973; Hoyle 1973; Klingbiel 1973a; Klingbiel 1973b; Maron 1961], is that of automatic document indexing for use in information retrieval (IR) systems relying on a controlled dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205006409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6e91e8130c3cbcda9517529ecd6de8efb827a3a",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-technique-for-machine-aided-indexing-Klingbiel",
            "title": {
                "fragments": [],
                "text": "A technique for machine-aided indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Storage Retr."
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47394834"
                        ],
                        "name": "R. Papka",
                        "slug": "R.-Papka",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Papka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Papka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144890574"
                        ],
                        "name": "James Allan",
                        "slug": "James-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Allan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 0
                            }
                        ],
                        "text": "[Merkl 1998; Papka and Allan 1998; Roussinov and Chen 1998]), a task usually called text clustering, or (iv) any activity of placing text items into groups, a task that has thus both TC and text clustering as particular instances [Manning and Sch\u00fctze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11990991,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbdddff8a1cc9bbdcd9d6138e475c05e49074d47",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the use of multiword query features to improve the eeectiveness of text-retrieval systems that accept natural-language queries. A relevance feedback process is explained that expands an initial query with single and multiword features. The multiword features are modelled as a set of words appearing within windows of varying sizes. Our experimental results suggest that windows of larger span yield improvements in retrieval over windows of smaller span. This result gives rise to a query contraction process that prunes 25% of the features in an expanded query with no loss in retrieval eeectiveness."
            },
            "slug": "Document-classification-using-multiword-features-Papka-Allan",
            "title": {
                "fragments": [],
                "text": "Document classification using multiword features"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work investigates the use of multiword query features to improve the eeectiveness of text-retrieval systems that accept natural-language queries and suggests that windows of larger span yield improvements in retrieval over windows of smaller span."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747752"
                        ],
                        "name": "Johannes F\u00fcrnkranz",
                        "slug": "Johannes-F\u00fcrnkranz",
                        "structuredName": {
                            "firstName": "Johannes",
                            "lastName": "F\u00fcrnkranz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johannes F\u00fcrnkranz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 33
                            }
                        ],
                        "text": "F\u00a8 J. Exploiting structural infor- URNKRANZ, 1999. mation for text classi.cation on the WWW."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16633970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b709bb2249239d873bd0a7c95ccec47fbe3aa24a",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we report on a set of experiments that explore the utility of making use of the structural information of WWW documents. Our working hypothesis is that it is often easier to classify a hypertext page using information provided on pages that point to it instead of using information that is provided on the page itself. We present experimental evidence that confirms this hypothesis on a set of Web-pages that relate to Computer Science Departments."
            },
            "slug": "Exploiting-Structural-Information-for-Text-on-the-F\u00fcrnkranz",
            "title": {
                "fragments": [],
                "text": "Exploiting Structural Information for Text Classification on the WWW"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "Experimental evidence is presented that confirms the working hypothesis that it is often easier to classify a hypertext page using information provided on pages that point to it instead of using information that is provided on the page itself."
            },
            "venue": {
                "fragments": [],
                "text": "IDA"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 32800624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44e915a220ce74badf755aae870fa0b69ee2b82a",
            "isKey": false,
            "numCitedBy": 2252,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The naive Bayes classifier, currently experiencing a renaissance in machine learning, has long been a core technique in information retrieval. We review some of the variations of naive Bayes models used for text retrieval and classification, focusing on the distributional assumptions made about word occurrences in documents."
            },
            "slug": "Naive-(Bayes)-at-Forty:-The-Independence-Assumption-Lewis",
            "title": {
                "fragments": [],
                "text": "Naive (Bayes) at Forty: The Independence Assumption in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "The naive Bayes classifier, currently experiencing a renaissance in machine learning, has long been a core technique in information retrieval, and some of the variations used for text retrieval and classification are reviewed."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072065076"
                        ],
                        "name": "P. Harding",
                        "slug": "P.-Harding",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Harding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Harding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28397441,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "762606928b5bec6fd9921cbe5b7d72cc33fb4f92",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "A probabilistic model previously used in relevance feedback is adapted for use in automatic indexing of documents (in the sense of imitating human indexers). The model fits with previous work in this area (the \u2018adhesion coefficient\u2019 method), in effect merely suggesting a different way of arriving at the adhesion coefficients. Methods for the application of the model are proposed. The independence assumptions used in the model are interpreted, and the possibility of a dependence model is discussed."
            },
            "slug": "Probabilistic-Automatic-Indexing-by-Learning-from-Robertson-Harding",
            "title": {
                "fragments": [],
                "text": "Probabilistic Automatic Indexing by Learning from Human indexers"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A probabilistic model previously used in relevance feedback is adapted for use in automatic indexing of documents (in the sense of imitating human indexers) and the possibility of a dependence model is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Documentation"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103447"
                        ],
                        "name": "S. Hartmann",
                        "slug": "S.-Hartmann",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hartmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084356644"
                        ],
                        "name": "G. Lustig",
                        "slug": "G.-Lustig",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lustig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1959019"
                        ],
                        "name": "M. Schwantner",
                        "slug": "M.-Schwantner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schwantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schwantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334474"
                        ],
                        "name": "Kostas Tzeras",
                        "slug": "Kostas-Tzeras",
                        "structuredName": {
                            "firstName": "Kostas",
                            "lastName": "Tzeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kostas Tzeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15004699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f61812ea95500993fada9f12c23577d2ba670d33",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "AIR/X is a rule-based system for indexing with terms (descriptors) from a prescribed vocabulary. For this task, an indexing dictionary with rules for mapping terms from the text onto descriptors is required, which can be derived automatically from a set of manually indexed documents. Based on the Darmstadt Indexing Approach, the indexing task is divided into a description step and a decision step. First, terms (single words or phrases) are identiied in the document text. With term-descriptor rules from the dictionary, descriptor indications are formed. The set of all indications from a document leading to the same descriptor is called a relevance description. A probabilistic classiication procedure computes indexing weights for each relevance description. Since the whole system is rule-based, it can be adapted to diierent subject elds by appropriate modiications of the rule bases. A major application of AIR/X is the AIR/PHYS system developed for a large physics database. This application is described in more detail along with experimental results."
            },
            "slug": "AIR/X-A-rule-based-multistage-indexing-system-for-Fuhr-Hartmann",
            "title": {
                "fragments": [],
                "text": "AIR/X - A rule-based multistage indexing system for Iarge subject fields"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A rule-based system for indexing with terms (descriptors) from a prescribed vocabulary, AIR/X is the AIR/PHYS system developed for a large physics database and can be adapted to diierent subject elds by appropriate modiications of the rule bases."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29603600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e67a0031c22e0d9bde96008f2590b0bd2bd3c6a2",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A decision theory approach to the development of retrieval systems is presented. Within this framework, optimalindexing is defined. Both the searching and the indexing problem turn out to have a common structure which is described using the concept of a 'recognition problem'. A knowledge based approach to an approximately optimalindexing, strictly related to the information need of user is outlined. The theory and the used approximation methods are illustrated by a brief description of WAI/AIR projects and some of their results."
            },
            "slug": "A-Decision-Theory-Approach-to-Optimal-Automatic-Knorz",
            "title": {
                "fragments": [],
                "text": "A Decision Theory Approach to Optimal Automatic Indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "A decision theory approach to the development of retrieval systems is presented, and a knowledge based approach to an approximately optimalindexing, strictly related to the information need of user is outlined."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752430"
                        ],
                        "name": "Ion Androutsopoulos",
                        "slug": "Ion-Androutsopoulos",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Androutsopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ion Androutsopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2123061"
                        ],
                        "name": "J. Koutsias",
                        "slug": "J.-Koutsias",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Koutsias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koutsias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1819585"
                        ],
                        "name": "K. Chandrinos",
                        "slug": "K.-Chandrinos",
                        "structuredName": {
                            "firstName": "Konstantinos",
                            "lastName": "Chandrinos",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chandrinos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124138"
                        ],
                        "name": "C. Spyropoulos",
                        "slug": "C.-Spyropoulos",
                        "structuredName": {
                            "firstName": "Constantine",
                            "lastName": "Spyropoulos",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Spyropoulos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1111139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46711283e72e45dc2efe1b86db8db6ce65efd82c",
            "isKey": false,
            "numCitedBy": 540,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The growing problem of unsolicited bulk e-mail, also known as \u201cspam\u201d, has generated a need for reliable anti-spam e-mail filters. Filters of this type have so far been based mostly on manually constructed keyword patterns. An alternative approach has recently been proposed, whereby a Naive Bayesian classifier is trained automatically to detect spam messages. We test this approach on a large collection of personal e-mail messages, which we make publicly available in \u201cencrypted\u201d form contributing towards standard benchmarks. We introduce appropriate cost-sensitive measures, investigating at the same time the effect of attribute-set size, training-corpus size, lemmatization, and stop lists, issues that have not been explored in previous experiments. Finally, the Naive Bayesian filter is compared, in terms of performance, to a filter that uses keyword patterns, and which is part of a widely used e-mail reader."
            },
            "slug": "An-experimental-comparison-of-naive-Bayesian-and-Androutsopoulos-Koutsias",
            "title": {
                "fragments": [],
                "text": "An experimental comparison of naive Bayesian and keyword-based anti-spam filtering with personal e-mail messages"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work introduces appropriate cost-sensitive measures, and investigates at the same time the effect of attribute-set size, training-corpus size, lemmatization, and stop lists, issues that have not been explored in previous experiments."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 140
                            }
                        ],
                        "text": "Batch .ltering thus coincides with single-label TC un\u00adder |C|=2 categories; \nsince this latter is a completely general TC task, some au\u00adthors [Hull 1994; Hull et al. 1996; Schapire \net al. 1998; Sch \u00a8 utze et al. 1995], some\u00adwhat confusingly, use the term .ltering in place of the more \nappropriate\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 198
                            }
                        ],
                        "text": "Within the TC literature, one example of a batch method is linear discriminant \nanalysis, a model of the stochastic dependence be\u00adtween terms that relies on the covari\u00adance matrices \nof the categories [Hull 1994; Sch \u00a8 utze et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 0
                            }
                        ],
                        "text": "[Hull 1994; Ittner et al. 1995]) generally did not make a distinction between near-positives and generic negatives."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 141
                            }
                        ],
                        "text": "Batch filtering thus coincides with single-label TC under |C| = 2 categories; since this latter is a completely general TC task some authors [Hull 1994; Hull et al. 1996; Schapire et al. 1998; Sch\u00fctze et al. 1995], somewhat confusingly, use the term \u201cfiltering\u201d in place of the more appropriate term \u201ccategorization\u201d."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 197
                            }
                        ],
                        "text": "Within the TC literature, one example of a batch method is linear discriminant analysis, a model of the stochastic dependence between terms that relies on the covariance matrices of the categories [Hull 1994; Sch\u00fctze et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13177734,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e3729dcdf9230f695cac56d5f291391762a1262",
            "isKey": true,
            "numCitedBy": 209,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Latent Semantic Indexing (LSI) is a novel approach to information retrieval that attempts to model the underlying structure of term associations by transforming the traditional representation of documents as vectors of weighted term frequencies to a new coordinate space where both documents and terms are represented as linear combinations of underlying semantic factors. In previous research, LSI has produced a small improvement in retrieval performance. In this paper, we apply LSI to the routing task, which operates under the assumption that a sample of relevant and non-relevant documents is available to use in constructing the query. Once again, LSI slightly improves performance. However, when LSI is used is conjuction with statistical classification, there is a dramatic improvement in performance."
            },
            "slug": "Improving-text-retrieval-for-the-routing-problem-Hull",
            "title": {
                "fragments": [],
                "text": "Improving text retrieval for the routing problem using latent semantic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper applies LSI to the routing task, which operates under the assumption that a sample of relevant and non-relevant documents is available to use in constructing the query, and finds that when LSI is used is conjuction with statistical classification, there is a dramatic improvement in performance."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068005320"
                        ],
                        "name": "Raj D. Iyer",
                        "slug": "Raj-D.-Iyer",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Iyer",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raj D. Iyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 53
                            }
                        ],
                        "text": "Boosting-based approaches have also been employed in [Escudero et al. 2000; Iyer et al. 2000; Kim et al. 2000; Li and Jain 1998; Myers et al. 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2638818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0ba761803c9b11245e9c1cfb0a3279453836d3b",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "RankBoost is a recently proposed algorithm for learning ranking functions. It is simple to implement and has strong justifica tions from computational learning theory. We describe the algorithm and present experimental results on applying it to the document routing problem. The first set of results applies RankBoost t o a text representation produced using modern term weighting methods. Performance of RankBoost is somewhat inferior to that of a state-of-the-art routing algorithm which is, however, more complex and less theoretically justified than RankBoost. RankB oost achieves comparable performance to the state-of-the-art algorithm when combined with feature or example selection heuristics. Our second set of results examines the behavior of RankBoost when it has to learn not only a ranking function but also all aspect s of term weighting from raw data. Performance is usually, though not always, less good here, but the term weighting functions implicit in the resulting ranking functions are intriguing, and the a pproach could easily be adapted to mixtures of textual and nontextual data."
            },
            "slug": "Boosting-for-document-routing-Iyer-Lewis",
            "title": {
                "fragments": [],
                "text": "Boosting for document routing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The algorithm is described and experimental results on applying it to the document routing problem are presented, finding that RankBoost achieves comparable performance to the state-of-the-art algorithm when combined with feature or example selection heuristics."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 50
                            }
                        ],
                        "text": "1997; Masand 1994], and maximum entropy modelling [Manning and Sch\u00fctze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 183
                            }
                        ],
                        "text": "[Merkl 1998]), a task usually called text clustering, or (iv) any activity of placing text items into groups, a task that has thus both TC and text clustering as particular instances [Manning and Sch\u00fctze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52800448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "084c55d6432265785e3ff86a2e900a49d501c00a",
            "isKey": false,
            "numCitedBy": 7801,
            "numCiting": 294,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical approaches to processing natural language text have become dominant in recent years. This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear. The book contains all the theory and algorithms needed for building NLP tools. It provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations. The book covers collocation finding, word sense disambiguation, probabilistic parsing, information retrieval, and other applications."
            },
            "slug": "Foundations-of-statistical-natural-language-Manning-Sch\u00fctze",
            "title": {
                "fragments": [],
                "text": "Foundations of statistical natural language processing"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "This foundational text is the first comprehensive introduction to statistical natural language processing (NLP) to appear and provides broad but rigorous coverage of mathematical and linguistic foundations, as well as detailed discussion of statistical methods, allowing students and researchers to construct their own implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SGMD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092997919"
                        ],
                        "name": "Ulrich Pfeifer",
                        "slug": "Ulrich-Pfeifer",
                        "structuredName": {
                            "firstName": "Ulrich",
                            "lastName": "Pfeifer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ulrich Pfeifer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 14888569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff1ba0b9e5d77d0845a3c9ce85795fc9405daff2",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that former approaches in probabilistic information retrieval are based on one or two of the three concepts abstraction, inductive learning, and probabilistic assumptions, and we propose a new approach which combines all three concepts. This approach is illustrated for the case of indexing with a controlled vocabulary. For this purpose, we describe a new probabilistic model first, which is then combined with logistic regression, thus yielding a generalization of the original model. Experimental results for the pure theoretical model as well as for heuristic variants are given. Furthermore, linear and logistic regression are compared."
            },
            "slug": "Probabilistic-information-retrieval-as-a-of-and-Fuhr-Pfeifer",
            "title": {
                "fragments": [],
                "text": "Probabilistic information retrieval as a combination of abstraction, inductive learning, and probabilistic assumptions"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A new probabilistic model is described first, which is then combined with logistic regression, thus yielding a generalization of the original model, and this approach is illustrated for the case of indexing with a controlled vocabulary."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39275321"
                        ],
                        "name": "Kary L. Myers",
                        "slug": "Kary-L.-Myers",
                        "structuredName": {
                            "firstName": "Kary",
                            "lastName": "Myers",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kary L. Myers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81338045"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699868"
                        ],
                        "name": "Satinder Singh",
                        "slug": "Satinder-Singh",
                        "structuredName": {
                            "firstName": "Satinder",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satinder Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760530"
                        ],
                        "name": "M. Walker",
                        "slug": "M.-Walker",
                        "structuredName": {
                            "firstName": "Marilyn",
                            "lastName": "Walker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Walker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 130
                            }
                        ],
                        "text": "Other applications we do not explicitly discuss are speech catego\u00adrization by \nmeans of a combination of speech recognition and TC [Myers et al. 2000; Schapire and Singer 2000], multi\u00admedia \ndocument categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 245
                            }
                        ],
                        "text": "\u2026texts also in the training phase (i.e. texts af\u00adfected by the same source of noise that is also \nat work in the test documents), effectiveness levels comparable to those obtainable in the case of standard \ntext can be achieved. speech transcripts [Myers et al. 2000; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 53
                            }
                        ],
                        "text": "Boosting-based approaches have also been employed in [Escudero et al. 2000; Iyer et al. 2000; Kim et al. 2000; Li and Jain 1998; Myers et al. 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 129
                            }
                        ],
                        "text": "Other applications we do not explicitly discuss are speech categorization by means of a combination of speech recognition and TC [Myers et al. 2000; Schapire and Singer 2000], multimedia document categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author identification for literary texts of unknown or disputed authorship [Forsyth 1999], language identification for texts of unknown language [Cavnar and Trenkle 1994], automated identification of text genre [Kessler et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5538863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dac11e0188b3a85db4390371aefbdebe8e3f8cff",
            "isKey": true,
            "numCitedBy": 38,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We report the results of a study on topic spotting in conversational speech. Using a machine learning approach, we build classifiers that accept an audio file of conversational human speech as input, and output an estimate of the topic being discussed. Our methodology makes use of a wellknown corpus of transcribed and topic-labeled speech (the Switchboard corpus), and involves an interesting double use of the BOOSTEXTER learning algorithm. Our work is distinguished from previous efforts in topic spotting by our explicit study of the effects of dialogue length on classifier performance, and by our use of off-theshelf speech recognition technology. One of our main results is the identification of a single classifier with good performance (relative to our classifier space) across all subdialogue lengths."
            },
            "slug": "A-Boosting-Approach-to-Topic-Spotting-on-Myers-Kearns",
            "title": {
                "fragments": [],
                "text": "A Boosting Approach to Topic Spotting on Subdialogues"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A machine learning approach is used to build classifiers that accept an audio file of conversational human speech as input, and output an estimate of the topic being discussed, using the Switchboard corpus."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711099"
                        ],
                        "name": "Kagan Tumer",
                        "slug": "Kagan-Tumer",
                        "structuredName": {
                            "firstName": "Kagan",
                            "lastName": "Tumer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kagan Tumer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34724702"
                        ],
                        "name": "Joydeep Ghosh",
                        "slug": "Joydeep-Ghosh",
                        "structuredName": {
                            "firstName": "Joydeep",
                            "lastName": "Ghosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joydeep Ghosh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17242145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5e755eaf904eddc1bd3f3f176f4fe76985ac21b",
            "isKey": false,
            "numCitedBy": 652,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Using an ensemble of classifiers, instead of a single classifier, can lead to improved generalization. The gains obtained by combining, however, are often affected more by the selection of what is presented to the combiner than by the actual combining method that is chosen. In this paper, we focus on data selection and classifier training methods, in order to 'prepare' classifiers for combining. We review a combining framework for classification problems that quantifies the need for reducing the correlation among individual classifiers. Then, we discuss several methods that make the classifiers in an ensemble more complementary. Experimental results are provided to illustrate the benefits and pitfalls of reducing the correlation among classifiers, especially when the training data are in limited supply."
            },
            "slug": "Error-Correlation-and-Error-Reduction-in-Ensemble-Tumer-Ghosh",
            "title": {
                "fragments": [],
                "text": "Error Correlation and Error Reduction in Ensemble Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper focuses on data selection and classifier training methods, in order to 'prepare' classifiers for combining, and discusses several methods that make the classifiers in an ensemble more complementary."
            },
            "venue": {
                "fragments": [],
                "text": "Connect. Sci."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144356748"
                        ],
                        "name": "J. Catlett",
                        "slug": "J.-Catlett",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Catlett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Catlett"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5319590,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b69e0cce79eb288ffb43ad7ae3b99b8dea9ac5ac",
            "isKey": false,
            "numCitedBy": 1095,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Heterogeneous-Uncertainty-Sampling-for-Supervised-Lewis-Catlett",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Uncertainty Sampling for Supervised Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15424327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61af1deb7a3016cd0760aca0f0a38a4fecda3d61",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Models-for-retrieval-with-probabilistic-indexing-Fuhr",
            "title": {
                "fragments": [],
                "text": "Models for retrieval with probabilistic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107261059"
                        ],
                        "name": "S. K. Wong",
                        "slug": "S.-K.-Wong",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Wong",
                            "middleNames": [
                                "K.",
                                "Michael"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. K. Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698696"
                        ],
                        "name": "Yiyu Yao",
                        "slug": "Yiyu-Yao",
                        "structuredName": {
                            "firstName": "Yiyu",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiyu Yao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "As they are defined here, Pri and Rei (and consequently Pr and Re) are to be understood, in the line of [Wong and Yao 1995], as subjective probabilities, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15663228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ce8078bce4dea312a2c28d34af4dd82667bbffe",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "This article examines and extends the logical models of information retrieval in the context of probability theory. The fundamental notions of term weights and relevance are given probabilistic interpretations. A unified framework is developed for modeling the retrieval process with probabilistic inference. This new approach provides a common conceptual and mathematical basis for many retrieval models, such as the Boolean, fuzzy set, vector space, and conventional probabilistic models. Within this framework, the underlying assumptions employed by each model are identified, and the inherent relationships between these models are analyzed. Although this article is mainly a theoretical analysis of probabilistic inference for information retrieval, practical methods for estimating the required probabilities are provided by simple examples."
            },
            "slug": "On-modeling-information-retrieval-with-inference-Wong-Yao",
            "title": {
                "fragments": [],
                "text": "On modeling information retrieval with probabilistic inference"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This article examines and extends the logical models of information retrieval in the context of probability theory, and the fundamental notions of term weights and relevance are given probabilistic interpretations."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145876066"
                        ],
                        "name": "F. Crestani",
                        "slug": "F.-Crestani",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Crestani",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Crestani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684032"
                        ],
                        "name": "M. Lalmas",
                        "slug": "M.-Lalmas",
                        "structuredName": {
                            "firstName": "Mounia",
                            "lastName": "Lalmas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lalmas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709413"
                        ],
                        "name": "C. J. V. Rijsbergen",
                        "slug": "C.-J.-V.-Rijsbergen",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Rijsbergen",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. V. Rijsbergen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069725668"
                        ],
                        "name": "I. Campbell",
                        "slug": "I.-Campbell",
                        "structuredName": {
                            "firstName": "Iain",
                            "lastName": "Campbell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Campbell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9133292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8baa04d56f9567a1c9ad5326027d13b35513024",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": "This article surveys probablistic approaches to modeling information retrieval. The basic concepts of probabilistic approaches to information retrieval are outlined and the principles and assumptions upon which the approaches are based are presented. The various models proposed in the development of IR are described, classified, and compared using a common formalism. New approaches that constitute the basis of future research are described."
            },
            "slug": "\u201cIs-this-document-relevant\u2026probably\u201d:-a-survey-of-Crestani-Lalmas",
            "title": {
                "fragments": [],
                "text": "\u201cIs this document relevant?\u2026probably\u201d: a survey of probabilistic models in information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "The basic concepts of probabilistic approaches to information retrieval are outlined and the principles and assumptions upon which the approaches are based are presented."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40941894"
                        ],
                        "name": "Soumen Chakrabarti",
                        "slug": "Soumen-Chakrabarti",
                        "structuredName": {
                            "firstName": "Soumen",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumen Chakrabarti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786444"
                        ],
                        "name": "B. Dom",
                        "slug": "B.-Dom",
                        "structuredName": {
                            "firstName": "Byron",
                            "lastName": "Dom",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Dom"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145503401"
                        ],
                        "name": "P. Raghavan",
                        "slug": "P.-Raghavan",
                        "structuredName": {
                            "firstName": "Prabhakar",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941159"
                        ],
                        "name": "S. Rajagopalan",
                        "slug": "S.-Rajagopalan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Rajagopalan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajagopalan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060104135"
                        ],
                        "name": "David Gibson",
                        "slug": "David-Gibson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Gibson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Gibson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371403"
                        ],
                        "name": "J. Kleinberg",
                        "slug": "J.-Kleinberg",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Kleinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kleinberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[Attardi et al. 1999; Baker and McCallum 1998; Chakrabarti et al. 1998; McCallum et al. 1998; Mladeni\u0107 1998b]), and will be more extensively discussed in Section 9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 182
                            }
                        ],
                        "text": "One possible answer is to switch from an interpretation of Na\u00a8ive Bayes in which documents are events \nto one in which terms are events [Baker and McCallum 1998; McCallum et al. 1998; Chakrabarti et al. 1998a; \nGuthrie et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5206591,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc270f31bdb6a6106f9a04fb00eae51b89391317",
            "isKey": false,
            "numCitedBy": 831,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-Resource-Compilation-by-Analyzing-and-Chakrabarti-Dom",
            "title": {
                "fragments": [],
                "text": "Automatic Resource Compilation by Analyzing Hyperlink Structure and Associated Text"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Networks"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "D\u00b4IAZ ESTEBAN, A., DE BUENAGA RODR\u00b4 NA IGUEZ, \nM., URE L\u00b4IA VEGA, M."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "The idea that under\u00adlies \nthe DIA is the use of a much wider set of features than described in Sec\u00adtion 5.1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 4
                            }
                        ],
                        "text": "The Darmstadt \nIndexing Approach The AIR/X system [Fuhr et al. 1991] oc\u00adcupies a special place in the literature on \nindexing for TC."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "Here, indexing is used in the \nsense of Section 3.1, that is, as using terms from a controlled vocabulary, and is thus a synonym of \nTC (the DIA was later ex\u00adtended to indexing with free terms [Fuhr and Buckley 1991])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "The essential ideas of the DIA \ntransforming the classi.cation space by means of abstraction and using a more de\u00adtailed text representation \nthan the stan\u00addard bag-of-words approach have not 8 Association factors are called adhesion coef.cients \nin many early papers on TC; see Field [1975]; Robertson and Harding [1984]. been taken up by other researchers \nso far."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 90
                            }
                        ],
                        "text": "The approach to indexing taken in AIR/X is known as the Darmstadt Indexing Approach (DIA) [Fuhr 1985]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 275
                            }
                        ],
                        "text": "\u2026of scienti.c \nliterature of O(105) documents and O(104) categories, and has had important theoretical spin-offs in \nthe .eld of probabilistic indexing [Fuhr 1989; Fuhr and Buckely 1991].7 The approach to indexing taken \nin AIR/X is known as the Darmstadt In\u00addexing Approach (DIA) [Fuhr 1985]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Other more sophis\u00adticated information-theoretic functions have been used in the literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and Srinivasan \n1999], relevancy score [Wiener et al. 1995], and GSS coef.cient [Galavotti et al. 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "In contrast, \nthe DIA considers properties (of terms, documents, 7 The AIR/X system, its applications (including the \nAIR/PHYS system [Biebricher et al. 1988], an appli\u00adcation of AIR/X to indexing physics literature), and \nits experiments have also been richly documented in a series of papers and doctoral theses written in \nGerman."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 552,
                                "start": 549
                            }
                        ],
                        "text": "This system is the .nal result of the AIR project, one of the most important efforts \nin the history of TC: spanning a duration of more than 10 years [Knorz 1982; Tzeras and Hartmann 1993], \nit has produced a system operatively em\u00adployed since 1985 in the classi.cation of corpora of scienti.c \nliterature of O(105) documents and O(104) categories, and has had important theoretical spin-offs in \nthe .eld of probabilistic indexing [Fuhr 1989; Fuhr and Buckely 1991].7 The approach to indexing taken \nin AIR/X is known as the Darmstadt In\u00addexing Approach (DIA) [Fuhr 1985]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "Function Denoted by Mathematical \nform DIA association factor z(tk , ci ) P(ci |tk ) Information gain IG(tk , ci ) cE{ci ,\u00afci } tE{tk , \n\u00aftk } P(t, c) \u00b7log P(t, c) P(t) \u00b7 P(c) Mutual information MI(tk , ci ) log P(tk , ci ) P(tk ) \u00b7 P(ci \n) Chi-square t2(tk , ci ) |Tr|\u00b7[P(tk , ci ) \u00b7 P(\u00aftk ,\u00afci ) -"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "The term-category relationship is described by estimates, derived from the training set, \nof the probability P(ci |tk ) that a document belongs to category ci, given that it con\u00adtains term tk \n(the DIA association factor).8 Relevance description vectors rd.(dj , ci ) are then the .nal representations \nthat are used for the classi.cation of document dj under category ci ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19886059,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c72e720cdc4b0e03b3c6568f6d0c825f48e8f0b",
            "isKey": true,
            "numCitedBy": 25,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The Darmstadt indexing approach is a framework for the development of automatic indexing systems for subject fields that can be quite large. The indexing procedure performs a coordinate indexing based on abstract texts by means of an indexing dictionary that is derived from a set of manually indexed documents. This paper describes a probabilistic model for this indexing approach. The model points out some improvements to the indexing procedure. Comparison is made to other indexing models and extensions of the model are suggested."
            },
            "slug": "A-probabilistic-model-of-dictionary-based-automatic-Fuhr",
            "title": {
                "fragments": [],
                "text": "A probabilistic model of dictionary based automatic indexing"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A probabilistic model for the Darmstadt indexing approach that points out some improvements to the indexing procedure and comparison is made to other indexing models and extensions of the model are suggested."
            },
            "venue": {
                "fragments": [],
                "text": "RIAO"
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70390710"
                        ],
                        "name": "Susan Brewer",
                        "slug": "Susan-Brewer",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Brewer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Susan Brewer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5823867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91280b12161670ec6bb0c818c526a43f6af30897",
            "isKey": false,
            "numCitedBy": 403,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The letter and/or sound combinations that make up a human language are limited by the human's ability to pronounce tnese sounds\u00b0 Therefore, the standard library search, which as a rule looks for all possible combinations of letters to find a word, is wasteful. Certain letters simply cannot be followed by certain other letters and a search for them is senseless. Following this same line of reasoning, letters very frequently occur in the combinations that are germane to the particular language. The growing amount of alphanumeric information presently being stored on magnetic tape presents increasingly difficult problems in both the number of tape reels used and the time necessary to search this mass of information in order to extract pertinent literature. At the present time most of this literature on tape utilizes the standard IBM 6-bit code to express alphanumeric symbols. ~t is entirely feasible to record standard English literature on tape -be it professional abstracts or novels -using only approximately two-thirds of the binary bits utilized to represent the same piece of written material in the conventional code. This can be accomplished by setting up, in a 9-bit code, the 400-odd letter combinations occurring most frequently. A 9-bit representation allows the programmer to set up as many as 512 symbols, thus leaving sufficient leeway to assign symbols to the most frequentlyused words, mathematical symbols, professional expressions, that are expected to be encountered in the literature to be recorded. In addition, these relatively short 9-bit symbols can be assigned to all key words that it may be necessary to look for later, thereby accelerating any future library search."
            },
            "slug": "Information-storage-and-retrieval-Brewer",
            "title": {
                "fragments": [],
                "text": "Information storage and retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The letter and/or sound combinations that make up a human language are limited by the human's ability to pronounce tnese sounds\u00b0 Therefore, the standard library search, which as a rule looks for all possible combinations of letters to find a word, is wasteful."
            },
            "venue": {
                "fragments": [],
                "text": "ACM '59"
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2334474"
                        ],
                        "name": "Kostas Tzeras",
                        "slug": "Kostas-Tzeras",
                        "structuredName": {
                            "firstName": "Kostas",
                            "lastName": "Tzeras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kostas Tzeras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145103447"
                        ],
                        "name": "S. Hartmann",
                        "slug": "S.-Hartmann",
                        "structuredName": {
                            "firstName": "Stephan",
                            "lastName": "Hartmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hartmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2861704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a283fb395343cd26984425306ca24c85b09ccdb",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, a Bayesian inference network model for automatic indexing with index terms (descriptors) from a prescribed vocabulary is presented. It requires an indexing dictionary with rules mapping terms of the respective subject field onto descriptors and inverted lists for terms occuring in a set of documents of the subject field and descriptors manually assigned to these documents. The indexing dictionary can be derived automatically from a set of manually indexed documents. An application of the network model is described, followed by an indexing example and some experimental results about the indexing performance of the network model."
            },
            "slug": "Automatic-indexing-based-on-Bayesian-inference-Tzeras-Hartmann",
            "title": {
                "fragments": [],
                "text": "Automatic indexing based on Bayesian inference networks"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A Bayesian inference network model for automatic indexing with index terms (descriptors) from a prescribed vocabulary is presented, followed by an indexing example and some experimental results about the indexing performance of the network model."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144418438"
                        ],
                        "name": "Hinrich Sch\u00fctze",
                        "slug": "Hinrich-Sch\u00fctze",
                        "structuredName": {
                            "firstName": "Hinrich",
                            "lastName": "Sch\u00fctze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hinrich Sch\u00fctze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 42
                            }
                        ],
                        "text": "Other works where utility is employed are [Amati and Crestani 1999; Cohen and Singer 1999; Hull et al. 1996; Lewis and Catlett 1994; Schapire et al. 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 141
                            }
                        ],
                        "text": "Batch filtering thus coincides with single-label TC under |C| = 2 categories; since this latter is a completely general TC task some authors [Hull 1994; Hull et al. 1996; Schapire et al. 1998; Sch\u00fctze et al. 1995], somewhat confusingly, use the term \u201cfiltering\u201d in place of the more appropriate term \u201ccategorization\u201d."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 146
                            }
                        ],
                        "text": "\u2026.ltering thus coincides with single-label TC un\u00adder |C|=2 categories; \nsince this latter is a completely general TC task, some au\u00adthors [Hull 1994; Hull et al. 1996; Schapire \net al. 1998; Sch \u00a8 utze et al. 1995], some\u00adwhat confusingly, use the term .ltering in place of the more \nappropriate\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18232336,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5dca7a84e17673eb3821b70c505c6a174bb6c6b0",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "There is strong empirical and theoretic evidence that combination of retrieval methods can improve performance. In this paper, we systematically compare combination strategies in the context of document filtering, using queries from the Tipster reference corpus. We find that simple averaging strategies do indeed improve performance, but that direet averaging of probability estimates is not the correet approach. Instead, the probabiJit y estimates must be renormalized using logistic regression on the known relevance judgments. We examine more complex combination strat~ gies but find them less successful due to the high correlations among our filtering methods which are optimized over the same training data and employ similar document represerttations."
            },
            "slug": "Method-combination-for-document-filtering-Hull-Pedersen",
            "title": {
                "fragments": [],
                "text": "Method combination for document filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is found that simple averaging strategies do indeed improve performance, but that direet averaging of probability estimates is not the correet approach, and the probabiJit y estimates must be renormalized using logistic regression on the known relevance judgments."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '96"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1787210"
                        ],
                        "name": "Hyo-Jung Oh",
                        "slug": "Hyo-Jung-Oh",
                        "structuredName": {
                            "firstName": "Hyo-Jung",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyo-Jung Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754166"
                        ],
                        "name": "Sung-Hyon Myaeng",
                        "slug": "Sung-Hyon-Myaeng",
                        "structuredName": {
                            "firstName": "Sung-Hyon",
                            "lastName": "Myaeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sung-Hyon Myaeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2207420"
                        ],
                        "name": "Mann-Ho Lee",
                        "slug": "Mann-Ho-Lee",
                        "structuredName": {
                            "firstName": "Mann-Ho",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mann-Ho Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 6978180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25db0c1e9d180c895101c3cecd97f393c1946b42",
            "isKey": false,
            "numCitedBy": 187,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "As WWW grows at an increasing speed, a classifier targeted at hypertext has become in high demand. While document categorization is quite a mature, the issue of utilizing hypertext structure and hyperlinks has been relatively unexplored. In this paper, we propose a practical method for enhancing both the speed and the quality of hypertext categorization using hyperlinks. In comparison against a recently proposed technique that appears to be the only one of the kind, we obtained up to 18.5% of improvement in effectiveness while reducing the processing time dramatically. We attempt to explain through experiments what factors contribute to the improvement."
            },
            "slug": "A-practical-hypertext-catergorization-method-using-Oh-Myaeng",
            "title": {
                "fragments": [],
                "text": "A practical hypertext catergorization method using links and incrementally available class information"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a practical method for enhancing both the speed and the quality of hypertext categorization using hyperlinks, and achieves up to 18.5% of improvement in effectiveness while reducing the processing time dramatically."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16376601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5857780939512bf49b5f56fdb2355d1840e382f5",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions of various sorts. One of the hazards inherent in this kind of theory construction is that the assumptions laid down may be inconsistent with the data to which they are applied. Another hazard is that the stated assumptions may not be the real assumptions on which the derived modelling equations or resulting experiments are actually based. Both kinds of error have been made repeatedly in research on probabilistic information retrieval. One consequence of these lapses is that the statistical character of certain probabilistic IR models, including the so-called \u2018binary independence\u2019 model, has been seriously misapprehended."
            },
            "slug": "Some-inconsistencies-and-misnomers-in-probabilistic-Cooper",
            "title": {
                "fragments": [],
                "text": "Some inconsistencies and misnomers in probabilistic information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The statistical character of certain probabilistic IR models, including the so-called \u2018binary independence\u2019 model, has been seriously misapprehended."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743641"
                        ],
                        "name": "G. Amati",
                        "slug": "G.-Amati",
                        "structuredName": {
                            "firstName": "Gianni",
                            "lastName": "Amati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Amati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145876066"
                        ],
                        "name": "F. Crestani",
                        "slug": "F.-Crestani",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Crestani",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Crestani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1979193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8d8425011b243444d1d7a29fa237bbbd3990caf0",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Probabilistic-learning-for-selective-dissemination-Amati-Crestani",
            "title": {
                "fragments": [],
                "text": "Probabilistic learning for selective dissemination of information"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Manag."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2126632"
                        ],
                        "name": "W. S. Cooper",
                        "slug": "W.-S.-Cooper",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cooper",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. S. Cooper"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11966912,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07ed0db70bd575984a764c45ed52da357d0be884",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Research in the probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions. One of the hazards inherent in this kind of theory construction is that the assumptions laid down maybe inconsmtent in unanticipated ways with the data to which they are applied. Another hazard is that the stated assumptions may not be those on which the derived modeling equations or resulting experiments are actually based. Both kinds of mistakes have been made m past research on probabihstic reformation retrieval. One consequence of these errors is that the statistical character of certain probabilistic IR models, including the so-called Binary Independence model, has been seriously misapprehended"
            },
            "slug": "Some-inconsistencies-and-misidentified-modeling-in-Cooper",
            "title": {
                "fragments": [],
                "text": "Some inconsistencies and misidentified modeling assumptions in probabilistic information retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Research in the probabilistic theory of information retrieval involves the construction of mathematical models based on statistical assumptions, including the so-called Binary Independence model, which has been seriously misapprehended."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889602"
                        ],
                        "name": "Erik D. Wiener",
                        "slug": "Erik-D.-Wiener",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Wiener",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik D. Wiener"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34165212"
                        ],
                        "name": "Jan O. Pedersen",
                        "slug": "Jan-O.-Pedersen",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Pedersen",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan O. Pedersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024710"
                        ],
                        "name": "A. Weigend",
                        "slug": "A.-Weigend",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Weigend",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Weigend"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17503448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abbe40b7503f51971c92f9f9b20ebea6c0b36d77",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an application of nonlinear neural networks to topic spotting. Neural networks allow us to model higher-order interaction between document terms and to simultaneously predict multiple topics using shared hidden features. In the context of this model, we compare two approaches to dimensionality reduction in representation: one based on term selection and another based on Latent Semantic Indexing (LSI). Two diierent methods are proposed for improving LSI representations for the topic spotting task. We nd that term selection and our modiied LSI representations lead to similar topic spotting performance, and that this performance is equal to or better than other published results on the same corpus."
            },
            "slug": "A-neural-network-approach-to-topic-spotting-Wiener-Pedersen",
            "title": {
                "fragments": [],
                "text": "A neural network approach to topic spotting"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "It is shown that term selection and the modiied LSI representations lead to similar topic spotting performance, and that this performance is equal to or better than other published results on the same corpus."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "134780689"
                        ],
                        "name": "Thomas Br\u00fcckner",
                        "slug": "Thomas-Br\u00fcckner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Br\u00fcckner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Br\u00fcckner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 36066918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87b4ffbfde947a3e86244657f27407790ad72c3e",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Participation on the filtering and routing tasks of TREC-6 with the commercial filtering system TEKLIS. TEKLIS is a training based statistical categorization system which incorporates shallow linguistic processing and fussy-set lethods"
            },
            "slug": "The-text-categorization-system-TEKLIS-at-TREC-6-Br\u00fcckner",
            "title": {
                "fragments": [],
                "text": "The text categorization system TEKLIS at TREC-6"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "Participation on the filtering and routing tasks of TREC-6 with the commercial filtering system TEKLIS is a training based statistical categorization system which incorporates shallow linguistic processing and fussy-set lethods."
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144430625"
                        ],
                        "name": "S. Robertson",
                        "slug": "S.-Robertson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Robertson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Robertson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848824"
                        ],
                        "name": "Karen Sp\u00e4rck Jones",
                        "slug": "Karen-Sp\u00e4rck-Jones",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Sp\u00e4rck Jones",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Sp\u00e4rck Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45186038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e3e57567e9803718623ec088cd7fea65cfbc9d",
            "isKey": false,
            "numCitedBy": 2372,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper examines statistical techniques for exploiting relevance information to weight search terms. These techniques are presented as a natural extension of weighting methods using information about the distribution of index terms in documents in general. A series of relevance weighting functions is derived and is justified by theoretical considerations. In particular, it is shown that specific weighted search methods are implied by a general probabilistic theory of retrieval. Different applications of relevance weighting are illustrated by experimental results for test collections."
            },
            "slug": "Relevance-weighting-of-search-terms-Robertson-Jones",
            "title": {
                "fragments": [],
                "text": "Relevance weighting of search terms"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper examines statistical techniques for exploiting relevance information to weight search terms using information about the distribution of index terms in documents in general and shows that specific weighted search methods are implied by a general probabilistic theory of retrieval."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797808"
                        ],
                        "name": "G. Salton",
                        "slug": "G.-Salton",
                        "structuredName": {
                            "firstName": "Gerard",
                            "lastName": "Salton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114660236"
                        ],
                        "name": "H. Schneider",
                        "slug": "H.-Schneider",
                        "structuredName": {
                            "firstName": "Hans-Jochen",
                            "lastName": "Schneider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Schneider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 39944136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "26f2e89f5585cf2ec4c0cdcd4ec4264d5726b07e",
            "isKey": false,
            "numCitedBy": 1414,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "research and development in information retrieval is available in our digital library an online access to it is set as public so you can get it instantly. Our books collection spans in multiple countries, allowing you to get the most less latency time to download any of our books like this one. Kindly say, the research and development in information retrieval is universally compatible with any devices to read."
            },
            "slug": "Research-and-Development-in-Information-Retrieval-Salton-Schneider",
            "title": {
                "fragments": [],
                "text": "Research and Development in Information Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The research and development in information retrieval is universally compatible with any devices to read, and can be downloaded instantly from the authors' digital library."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053062974"
                        ],
                        "name": "Marc Goodman",
                        "slug": "Marc-Goodman",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Goodman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Goodman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Other examples of this \u201cmanual\u201d approach to the construction of text classifiers are [Goodman 1990; Rau and Jacobs 1991]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 513159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce59353d04804879b7fbd91655bb972363ff1aaa",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Banks receive a wide variety of telex communications. Bank operators must sort these telexes and route them to the appropriate department for processing. Although certain messages can easily be classified and routed, others require a more thorough understanding of the telex content and bank organization to determine the proper destination. The large number of messages that must be reviewed each day, the urgency of these messages, and the difficulty of maintaining a staff of sufficiently skilled operators all indicate the advantages of automating this task. Thus, Prism is a system that combines case-based and inductive techniques to classify and route bank telexes. Developed by Cognitive Systems, Inc. (CSI), the Prism system has been in continual daily operation at Chase Manhattan Bank's Letter of Credit Department (Chase L/C) since October 1989 and has been customized for installation at Manufacturer's Hanover Trust (MHT) and the American Express Bank, Limited (AEBL)."
            },
            "slug": "Prism:-A-Case-Based-Telex-Classifier-Goodman",
            "title": {
                "fragments": [],
                "text": "Prism: A Case-Based Telex Classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Prism is a system that combines case-based and inductive techniques to classify and route bank telexes and has been in continual daily operation at Chase Manhattan Bank's Letter of Credit Department since October 1989."
            },
            "venue": {
                "fragments": [],
                "text": "IAAI"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094660110"
                        ],
                        "name": "Peter Biebricher",
                        "slug": "Peter-Biebricher",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Biebricher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Biebricher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084356644"
                        ],
                        "name": "G. Lustig",
                        "slug": "G.-Lustig",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lustig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1959019"
                        ],
                        "name": "M. Schwantner",
                        "slug": "M.-Schwantner",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Schwantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schwantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 133
                            }
                        ],
                        "text": "In contrast, \nthe DIA considers properties (of terms, documents, 7 The AIR/X system, its applications (including the \nAIR/PHYS system [Biebricher et al. 1988], an appli\u00adcation of AIR/X to indexing physics literature), and \nits experiments have also been richly documented in a series of papers and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "es considered, and is thus independent of speci\ufb01c terms, categories or documents (for multivalued features, appropriate aggregation 7The AIR/X system, its applications (including the AIR/PHYS system [Biebricher et al. 1988], an application of AIR/X to indexing physics literature), and its experiments, have also been richly documented in a series of papers and doctoral theses written in German. The interested reader may"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16543804,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "dacc3d6d45ec9bec3d2eedccd9dbb35881f0a225",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Since October 1985, the automatic indexing system AIR/PHYS has been used in the input production of the physics data base of the Fachinformationsentrum Karlsruhe/West Germany. The texts to be indexed are abstracts written in English. The system of descriptors is prescribed. For the application of the AIR/PHYS system a large-scale dictionary containing more than 600 000 word-descriptor relations reap. phrase-descriptor relations has been developed. Most of these relations have been obtained by means of statistical and heuristical methods. In consequence, the relation system is rather imperfect. Therefore, the indexing system needs some fault- tolerating features. An appropriate indexing approach and the corresponding structure of the AIR/PHYS system are described. Finally, the conditions of the application as well as problems of further development are discussed."
            },
            "slug": "The-automatic-indexing-system-AIR/PHYS-from-to-Biebricher-Fuhr",
            "title": {
                "fragments": [],
                "text": "The automatic indexing system AIR/PHYS - from research to applications"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An appropriate indexing approach and the corresponding structure of the AIR/PHYS system are described, and the conditions of the application as well as problems of further development are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740213"
                        ],
                        "name": "Pedro M. Domingos",
                        "slug": "Pedro-M.-Domingos",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Domingos",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro M. Domingos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694780"
                        ],
                        "name": "M. Pazzani",
                        "slug": "M.-Pazzani",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Pazzani",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Pazzani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 77139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "700666f0c59a4fedc8b08294424c47cb99a8e2ff",
            "isKey": false,
            "numCitedBy": 3124,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "The simple Bayesian classifier is known to be optimal when attributes are independent given the class, but the question of whether other sufficient conditions for its optimality exist has so far not been explored. Empirical results showing that it performs surprisingly well in many domains containing clear attribute dependences suggest that the answer to this question may be positive. This article shows that, although the Bayesian classifier's probability estimates are only optimal under quadratic loss if the independence assumption holds, the classifier itself can be optimal under zero-one loss (misclassification rate) even when this assumption is violated by a wide margin. The region of quadratic-loss optimality of the Bayesian classifier is in fact a second-order infinitesimal fraction of the region of zero-one optimality. This implies that the Bayesian classifier has a much greater range of applicability than previously thought. For example, in this article it is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption. Further, studies in artificial domains show that it will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain. This article's results also imply that detecting attribute dependence is not necessarily the best way to extend the Bayesian classifier, and this is also verified empirically."
            },
            "slug": "On-the-Optimality-of-the-Simple-Bayesian-Classifier-Domingos-Pazzani",
            "title": {
                "fragments": [],
                "text": "On the Optimality of the Simple Bayesian Classifier under Zero-One Loss"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The Bayesian classifier is shown to be optimal for learning conjunctions and disjunctions, even though they violate the independence assumption, and will often outperform more powerful classifiers for common training set sizes and numbers of attributes, even if its bias is a priori much less appropriate to the domain."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703148"
                        ],
                        "name": "N. Fuhr",
                        "slug": "N.-Fuhr",
                        "structuredName": {
                            "firstName": "Norbert",
                            "lastName": "Fuhr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Fuhr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084310078"
                        ],
                        "name": "Gerhard Knorz",
                        "slug": "Gerhard-Knorz",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Knorz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerhard Knorz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 13028170,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5188d128b38aaa97c17cb93357475a078fa563ee",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The automatic indexing system AIR/PHYS and its evaluation by means of a retrieval test with 309 requests and 15,000 documents is described. First, the underlying conception of a rule based approach is given which is suited to the task of a controlled-vocabulary indexing of even large subject fields. Preconditions, performance and results of the retrieval test are described, including first results of retrieval runs with weighted automatic indexing."
            },
            "slug": "Retrieval-Test-Evaluation-of-a-Rule-Based-Automatic-Fuhr-Knorz",
            "title": {
                "fragments": [],
                "text": "Retrieval Test Evaluation of a Rule Based Automatic Index (AIR/PHYS)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The underlying conception of a rule based approach is given which is suited to the task of a controlled-vocabulary indexing of even large subject fields and first results of retrieval runs with weighted automatic indexing are described."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739040"
                        ],
                        "name": "D. Tauritz",
                        "slug": "D.-Tauritz",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Tauritz",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tauritz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713683"
                        ],
                        "name": "J. Kok",
                        "slug": "J.-Kok",
                        "structuredName": {
                            "firstName": "Joost",
                            "lastName": "Kok",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kok"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403188161"
                        ],
                        "name": "I. Sprinkhuizen-Kuyper",
                        "slug": "I.-Sprinkhuizen-Kuyper",
                        "structuredName": {
                            "firstName": "Ida",
                            "lastName": "Sprinkhuizen-Kuyper",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Sprinkhuizen-Kuyper"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13549345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6eabcfb49f63c9c377213bba6871d7427cfc15d",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptive-Information-Filtering-using-Evolutionary-Tauritz-Kok",
            "title": {
                "fragments": [],
                "text": "Adaptive Information Filtering using Evolutionary Computation"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Sci."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688124"
                        ],
                        "name": "W. Hersh",
                        "slug": "W.-Hersh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Hersh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hersh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089238953"
                        ],
                        "name": "T. J. Leone",
                        "slug": "T.-J.-Leone",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Leone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. J. Leone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760869"
                        ],
                        "name": "D. Hickam",
                        "slug": "D.-Hickam",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hickam",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hickam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15094383,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "e91fc6cba8b23688d02b0dc3ead69ed05210bf33",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users. Using a commercial MEDLINE product based on the vector space model, these physicians searched just as effectively as more experienced searchers using Boolean searching. The results of this experiment were subsequently used to create a new large medical test collection, which was used in experiments with the SMART retrieval system to obtain baseline performance data as well as compare SMART with the other searchers."
            },
            "slug": "OHSUMED:-an-interactive-retrieval-evaluation-and-Hersh-Buckley",
            "title": {
                "fragments": [],
                "text": "OHSUMED: an interactive retrieval evaluation and new large test collection for research"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A series of information retrieval experiments was carried out with a computer installed in a medical practice setting for relatively inexperienced physician end-users using a commercial MEDLINE product based on the vector space model, finding that these physicians searched just as effectively as more experienced searchers using Boolean searching."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798723"
                        ],
                        "name": "Mandar Mitra",
                        "slug": "Mandar-Mitra",
                        "structuredName": {
                            "firstName": "Mandar",
                            "lastName": "Mitra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mandar Mitra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144009691"
                        ],
                        "name": "C. Buckley",
                        "slug": "C.-Buckley",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Buckley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Buckley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "\u2026then, either as an object of research in its \nown right [Ittner et al. 1995; Joachims 1997; Sable and Hatzivassiloglou 2000; Schapire et al. 1998; \nSinghal et al. 1997], or as a base\u00adline classi.er [Cohen and Singer 1999; Galavotti et al. 2000; Joachims \n1998; Lewis et al. 1996; Schapire and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 146
                            }
                        ],
                        "text": "This adaptation was first proposed by Hull [1994], and has been used by many authors since then, either as an object of research in its own right [Ittner et al. 1995; Joachims 1997; Sable and Hatzivassiloglou 2000; Schapire et al. 1998; Singhal et al. 1997], or as a baseline classifier [Cohen and Singer 1999; Galavotti et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2874538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f54a77f3ba4b86512da8b2922b1cd375d0aad2a0",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Word usage is domain dependent. A common word in one domain can be quite infrequent in another. In this study we exploit th~ property of word usage to improve document routing. We show that routing queries (profiles) learned only from the documents in a query domain are better than the routing profiles learned when query domains are not used. We approximate a query domain by a guerg zone. Experiments show that routing profiles learned from a query zone are 8\u201312~0 more effective than the profiles generated when no query zoning is used."
            },
            "slug": "Learning-routing-queries-in-a-query-zone-Singhal-Mitra",
            "title": {
                "fragments": [],
                "text": "Learning routing queries in a query zone"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This study shows that routing queries learned only from the documents in a query domain are better than the routing profiles learned when query domains are not used, and approximate a querydomain by a guerg zone."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145700185"
                        ],
                        "name": "S. Weiss",
                        "slug": "S.-Weiss",
                        "structuredName": {
                            "firstName": "Sholom",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145272844"
                        ],
                        "name": "C. Apt\u00e9",
                        "slug": "C.-Apt\u00e9",
                        "structuredName": {
                            "firstName": "Chidanand",
                            "lastName": "Apt\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Apt\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255019"
                        ],
                        "name": "F. J. Damerau",
                        "slug": "F.-J.-Damerau",
                        "structuredName": {
                            "firstName": "Fred",
                            "lastName": "Damerau",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. Damerau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150445399"
                        ],
                        "name": "David E. Johnson",
                        "slug": "David-E.-Johnson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Johnson",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3099493"
                        ],
                        "name": "F. J. Oles",
                        "slug": "F.-J.-Oles",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Oles",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. J. Oles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39230910"
                        ],
                        "name": "Thilo W. Goetz",
                        "slug": "Thilo-W.-Goetz",
                        "structuredName": {
                            "firstName": "Thilo",
                            "lastName": "Goetz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thilo W. Goetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2849109"
                        ],
                        "name": "T. Hampp",
                        "slug": "T.-Hampp",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hampp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hampp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 163
                            }
                        ],
                        "text": "1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classifiers [Cohen and Singer 1999; Joachims 1998], or as members of classifier committees [Li and Jain 1998; Schapire and Singer 2000; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 51
                            }
                        ],
                        "text": "MH committee \ncommittee [Schapire and Singer 2000] [Weiss et al. 1999] .860 .878 Bayesian net Bayesian net [Dumais \net al. 1998] [Lam et al. 1997] .542 (MF1) .800 .850 and Pedersen [1997].21 The documents are titles \nor title-plus-abstracts from medical journals (OHSUMED is actually a subset of the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 143
                            }
                        ],
                        "text": "Similarly, when a document title is available, one can pay extra importance \nto the words it contains [Apt\u00b4 e et al. 1994; Cohen and Singer 1999; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 101
                            }
                        ],
                        "text": "Similarly, when a document title is available, one can pay extra importance to the words it contains [Apt\u00e9 et al. 1994; Cohen and Singer 1999; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 53
                            }
                        ],
                        "text": "TC efforts based on experimental DT packages include [Dumais et al. 1998; Lewis and Ringuette 1994; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 273
                            }
                        ],
                        "text": "\u2026have been used either as the main classi.cation \ntool [Fuhr et al. 1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classi.ers \n[Cohen and Singer 1999; Joachims 1998], or as members of classi.er committees [Li and Jain 1998; Schapire \nand Singer 2000; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14039905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40eb18d2fbb609766c03a9f83164fe4d3f1bef8d",
            "isKey": true,
            "numCitedBy": 258,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors' adaptive resampling approach surpasses previous decision-tree performance and validates the effectiveness of small, pooled local dictionaries. They demonstrate their approach using the Reuters-21578 benchmark data and a real-world customer E-mail routing system."
            },
            "slug": "Maximizing-text-mining-performance-Weiss-Apt\u00e9",
            "title": {
                "fragments": [],
                "text": "Maximizing text-mining performance"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors' adaptive resampling approach surpasses previous decision-tree performance and validates the effectiveness of small, pooled local dictionaries."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Intell. Syst."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40199624"
                        ],
                        "name": "R. Creecy",
                        "slug": "R.-Creecy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Creecy",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Creecy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127759"
                        ],
                        "name": "B. Masand",
                        "slug": "B.-Masand",
                        "structuredName": {
                            "firstName": "Brij",
                            "lastName": "Masand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Masand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111051178"
                        ],
                        "name": "Stephen J. Smith",
                        "slug": "Stephen-J.-Smith",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smith",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen J. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788375"
                        ],
                        "name": "D. Waltz",
                        "slug": "D.-Waltz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Waltz",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Waltz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 133
                            }
                        ],
                        "text": "The .rst application of example-based methods (a.k.a. memory-based reason\u00ading methods) \nto TC is due to Creecy, Masand and colleagues [Creecy et al. 1992; Masand et al. 1992]; other examples \ninclude Joachims [1998], Lam et al. [1999], Larkey [1998], Larkey [1999], Li and Jain [1998], Yang and\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18744432,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "7403fa3e56cee44e0f48185bb4a79d935eb9b01c",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "mission to profile and economy of ~e Census Bureau ~dustry and occupation data for individuals in the labor force. For the 1990 Decennial Census, each of an estimated 22 million natural language responses to questions on the census long form had to be classified into one of 232 industry categories and 504 occupation categories. If done fully by hand the cost of this task would be on the order of $15 million."
            },
            "slug": "Trading-MIPS-and-memory-for-knowledge-engineering-Creecy-Masand",
            "title": {
                "fragments": [],
                "text": "Trading MIPS and memory for knowledge engineering"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "mission to profile and economy of ~e Census Bureau ~dustry and occupation data for individuals in the labor force, for the 1990 Decennial Census, which had to be classified into one of 232 industry categories and 504 occupation categories."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144785139"
                        ],
                        "name": "Ping Li",
                        "slug": "Ping-Li",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 27670263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4a0064912da9c9e3106b707311dfc5b3f694ae60",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "This study examined the role of covert semantic classes or 'cryptotypes' in determining children's overgeneralizations of reversive prefixes such as un - in *unsqueeze or *unpress . A training corpus of 160 English verbs was presented incrementally to a backpropagation network. In three simulations, we showed that the network developed structured representations for the semantic cryptotype associated with the use of the reversive prefix un- . Overgeneralizations produced by the network, such as *unbury or *unpress , match up well with actual overgeneralizations observed in human children, showing that structured cryptotypic semantic representations underlie this overgeneralization behaviour. Simulation 2 points towards a role of lexical competition in morphological acquisition and overgeneralizations. Simulation 3 provides insight into the relationship between plasticity in network learning and the ability to recover from overgeneralizations. Together, these analyses paint a dynamic picture in which compe..."
            },
            "slug": "Cryptotype,-Overgeneralization-and-Competition:-A-Li",
            "title": {
                "fragments": [],
                "text": "Cryptotype, Overgeneralization and Competition: A Connectionist Model of the Learning of English Reversive Prefixes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Overgeneralizations produced by the network match up well with actual overgeneralizations observed in human children, showing that structured cryptotypic semantic representations underlie this overgeneralization behaviour."
            },
            "venue": {
                "fragments": [],
                "text": "Connect. Sci."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49028220"
                        ],
                        "name": "A. Gammerman",
                        "slug": "A.-Gammerman",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Gammerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gammerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29809581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "192e26a49d943e1700d285d3d5b402b14e0950d5",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "I. Causal Models.- 1. Statistics, Causality, and Graphs.- 1.1 A Century of Denial.- 1.2 Researchers in Search of a Language.- 1.3 Graphs as a Mathematical Language.- 1.4 The Challenge.- References.- 2. Causal Conjecture.- 2.1 Introduction.- 2.2 Variables in a Probability Tree.- 2.3 Causal Uncorrelatedness.- 2.4 Three Positive Causal Relations.- 2.5 Linear Sign.- 2.6 Causal Uncorrelatedness Again.- 2.7 Scored Sign.- 2.8 Tracking.- References.- 3. Who Needs Counterfactuals?.- 3.1 Introduction.- 3.1.1 Decision-Theoretic Framework.- 3.1.2 Unresponsiveness and Insensitivity.- 3.2 Counterfactuals.- 3.3 Problems of Causal Inference.- 3.3.1 Causes of Effects.- 3.3.2 Effects of Causes.- 3.4 The Counterfactual Approach.- 3.4.1 The Counterfactual Setting.- 3.4.2 Counterfactual Assumptions.- 3.5 Homogeneous Population.- 3.5.1 Experiment and Inference.- 3.6 Decision-Analytic Approach.- 3.7 Sheep and Goats.- 3.7.1 ACE.- 3.7.2 Neyman and Fisher.- 3.7.3 Bioequivalence.- 3.8 Causes of Effects.- 3.8.1 A Different Approach?.- 3.9 Conclusion.- References.- 4. Causality: Independence and Determinism.- 4.1 Introduction.- 4.2 Conclusion.- References.- II. Intelligent Data Management.- 5. Intelligent Data Analysis and Deep Understanding.- 5.1 Introduction.- 5.2 The Question: The Strategy.- 5.3 Diminishing Returns.- 5.4 Conclusion.- References.- 6. Learning Algorithms in High Dimensional Spaces.- 6.1 Introduction.- 6.2 SVM for Pattern Recognition.- 6.2.1 Dual Representation of Pattern Recognition.- 6.3 SVM for Regression Estimation.- 6.3.1 Dual Representation of Regression Estimation.- 6.3.2 SVM Applet and Software.- 6.4 Ridge Regression and Least Squares Methods in Dual Variables.- 6.5 Transduction.- 6.6 Conclusion.- References.- 7. Learning Linear Causal Models by MML Sampling.- 7.1 Introduction.- 7.2 Minimum Message Length Principle.- 7.3 The Model Space.- 7.4 The Message Format.- 7.5 Equivalence Sets.- 7.5.1 Small Effects.- 7.5.2 Partial Order Equivalence.- 7.5.3 Structural Equivalence.- 7.5.4 Explanation Length.- 7.6 Finding Good Models.- 7.7 Sampling Control.- 7.8 By-products.- 7.9 Prior Constraints.- 7.10 Test Results.- 7.11 Remarks on Equivalence.- 7.11.1 Small Effect Equivalence.- 7.11.2 Equivalence and Causality.- 7.12 Conclusion.- References.- 8. Game Theory Approach to Multicommodity Flow Network Vulnerability Analysis.- References.- 9. On the Accuracy of Stochastic Complexity Approximations.- 9.1 Introduction.- 9.2 Stochastic Complexity and Its Applications.- 9.3 Approximating the Stochastic Complexity in the Incomplete Data Case.- 9.4 Empirical Results.- 9.4.1 The Problem.- 9.4.2 The Experimental Setting.- 9.4.3 The Algorithms.- 9.4.4 Results.- 9.5 Conclusion.- References.- 10. AI Modelling for Data Quality Control Xiaohui Liu.- 10.1 Introduction.- 10.2 Statistical Approaches to Outliers.- 10.3 Outlier Detection and Analysis.- 10.4 Visual Field Test.- 10.5 Outlier Detection.- 10.5.1 Self-Organising Maps (SOM).- 10.5.2 Applications of SOM.- 10.6 Outlier Analysis by Modelling 'Real Measurements'.- 10.7 Outlier Analysis by Modelling Noisy Data.- 10.7.1 Noise Model I: Noise Definition.- 10.7.2 Noise Model II: Construction.- 10.7.3 Noise Elimination.- 10.8 Concluding Remarks.- References.- 11. New Directions in Text Categorization.- 11.1 Introduction.- 11.2 Machine Learning for Text Classification.- 11.3 Radial Basis Functions and the Bard.- 11.4 An Evolutionary Algorithm for Text Classification.- 11.5 Text Classification by Vocabulary Richness.- 11.6 Text Classification with Frequent Function Words.- 11.7 Do Authors Have Semantic Signatures?.- 11.8 Syntax with Style.- 11.9 Intermezzo.- 11.10 Some Methods of Textual Feature-Finding.- 11.10.1 Progressive Pairwise Chunking.- 11.10.2 Monte Carlo Feature Finding.- 11.10.3 How Long Is a Piece of Substring?.- 11.10.4 Comparative Testing.- 11.11 Which Methods Work Best? - A Benchmarking Study.- 11.12 Discussion.- 11.12.1 In Praise of Semi-Crude Bayesianism.- 11.12.2 What's So Special About Linguistic Data?.- References."
            },
            "slug": "Causal-Models-and-Intelligent-Data-Management-Gammerman",
            "title": {
                "fragments": [],
                "text": "Causal Models and Intelligent Data Management"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This paper presents a meta-modelling framework called Intelligent Data Management for Data Quality Control (SOM), which automates the very labor-intensive and therefore time-heavy and therefore expensive and expensive process of manually modelling the data."
            },
            "venue": {
                "fragments": [],
                "text": "Springer Berlin Heidelberg"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2760429"
                        ],
                        "name": "T. Saracevic",
                        "slug": "T.-Saracevic",
                        "structuredName": {
                            "firstName": "Tefko",
                            "lastName": "Saracevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Saracevic"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32261178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cba4ace41cc20de16438c2e538f3f40e476e6af",
            "isKey": false,
            "numCitedBy": 888,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Information science emerged as the third subject, along with logic and philosophy, to deal with relevance-an elusive, human notion. The concern with relevance, as a key notion in information science, is traced to the problems of scientific communication. Relevance is considered as a measure of the effectiveness of a contact between a source and a destination in a communication process. The different views of relevance that emerged are interpreted and related within a framework of communication of knowledge. Different views arose because relevance was considered at a number of different points in the process of knowledge communication. It is suggested that there exists an interlocking, interplaying cycle of various systems of relevances."
            },
            "slug": "RELEVANCE:-A-review-of-and-a-framework-for-the-on-Saracevic",
            "title": {
                "fragments": [],
                "text": "RELEVANCE: A review of and a framework for the thinking on the notion in information science"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Information science emerged as the third subject, along with logic and philosophy, to deal with relevance-an elusive, human notion that is traced to the problems of scientific communication."
            },
            "venue": {
                "fragments": [],
                "text": "J. Am. Soc. Inf. Sci."
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222817"
                        ],
                        "name": "C. Cleverdon",
                        "slug": "C.-Cleverdon",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Cleverdon",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cleverdon"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58488996,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14d643cc15d3de797506bc3e406d66eee7839214",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Analyse des variables affectant, peu ou prou, l'efficacite de la recherche en ligne: politique d'indexation, strategie de recherche, taille de la base de donnees et taux de couverture des domaines specialises etc"
            },
            "slug": "Optimizing-convenient-online-access-to-databases-Cleverdon",
            "title": {
                "fragments": [],
                "text": "Optimizing convenient online access to bibliographic databases"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Analyse des variables affectant, peu ou prou, l'efficacite de the Recherche en ligne: politique d'indexation, strategie de recherche, taille de la base de donnees et taux de couverture des domaines specialises etc."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "D\u00b4IAZ ESTEBAN, A., DE BUENAGA RODR\u00b4 NA IGUEZ, \nM., URE L\u00b4IA VEGA, M."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "The idea that under\u00adlies \nthe DIA is the use of a much wider set of features than described in Sec\u00adtion 5.1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 4
                            }
                        ],
                        "text": "The Darmstadt \nIndexing Approach The AIR/X system [Fuhr et al. 1991] oc\u00adcupies a special place in the literature on \nindexing for TC."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 92
                            }
                        ],
                        "text": "7 The approach to indexing taken in AIR/X is known as the Darmstadt Indexing Approach (DIA) [Fuhr 1985]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "Here, indexing is used in the \nsense of Section 3.1, that is, as using terms from a controlled vocabulary, and is thus a synonym of \nTC (the DIA was later ex\u00adtended to indexing with free terms [Fuhr and Buckley 1991])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 52
                            }
                        ],
                        "text": "Various TC efforts have used regression models (see Fuhr and Pfeifer [1994]; Ittner et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "The essential ideas of the DIA \ntransforming the classi.cation space by means of abstraction and using a more de\u00adtailed text representation \nthan the stan\u00addard bag-of-words approach have not 8 Association factors are called adhesion coef.cients \nin many early papers on TC; see Field [1975]; Robertson and Harding [1984]. been taken up by other researchers \nso far."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 60
                            }
                        ],
                        "text": "looks natural, given that weighted indexing techniques (see Fuhr [1989]; Salton and Buckley [1988]) accounting for the \u201cimportance\u201d of tk for d j play a key role in IR."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 284,
                                "start": 275
                            }
                        ],
                        "text": "\u2026of scienti.c \nliterature of O(105) documents and O(104) categories, and has had important theoretical spin-offs in \nthe .eld of probabilistic indexing [Fuhr 1989; Fuhr and Buckely 1991].7 The approach to indexing taken \nin AIR/X is known as the Darmstadt In\u00addexing Approach (DIA) [Fuhr 1985]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 106
                            }
                        ],
                        "text": "Other more sophis\u00adticated information-theoretic functions have been used in the literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and Srinivasan \n1999], relevancy score [Wiener et al. 1995], and GSS coef.cient [Galavotti et al. 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "In contrast, \nthe DIA considers properties (of terms, documents, 7 The AIR/X system, its applications (including the \nAIR/PHYS system [Biebricher et al. 1988], an appli\u00adcation of AIR/X to indexing physics literature), and \nits experiments have also been richly documented in a series of papers and doctoral theses written in \nGerman."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 52
                            }
                        ],
                        "text": "Various TC efforts have used regression models (see Fuhr and Pfeifer [1994]; Ittner et al. [1995]; Lewis and Gale [1994]; Sch\u00fctze et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 552,
                                "start": 549
                            }
                        ],
                        "text": "This system is the .nal result of the AIR project, one of the most important efforts \nin the history of TC: spanning a duration of more than 10 years [Knorz 1982; Tzeras and Hartmann 1993], \nit has produced a system operatively em\u00adployed since 1985 in the classi.cation of corpora of scienti.c \nliterature of O(105) documents and O(104) categories, and has had important theoretical spin-offs in \nthe .eld of probabilistic indexing [Fuhr 1989; Fuhr and Buckely 1991].7 The approach to indexing taken \nin AIR/X is known as the Darmstadt In\u00addexing Approach (DIA) [Fuhr 1985]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 52
                            }
                        ],
                        "text": "Various TC efforts have used regression models (see Fuhr and Pfeifer [1994]; Ittner et al. [1995]; Lewis and Gale [1994]; Sch\u00fctze et al. [1995])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "Function Denoted by Mathematical \nform DIA association factor z(tk , ci ) P(ci |tk ) Information gain IG(tk , ci ) cE{ci ,\u00afci } tE{tk , \n\u00aftk } P(t, c) \u00b7log P(t, c) P(t) \u00b7 P(c) Mutual information MI(tk , ci ) log P(tk , ci ) P(tk ) \u00b7 P(ci \n) Chi-square t2(tk , ci ) |Tr|\u00b7[P(tk , ci ) \u00b7 P(\u00aftk ,\u00afci ) -"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "The term-category relationship is described by estimates, derived from the training set, \nof the probability P(ci |tk ) that a document belongs to category ci, given that it con\u00adtains term tk \n(the DIA association factor).8 Relevance description vectors rd.(dj , ci ) are then the .nal representations \nthat are used for the classi.cation of document dj under category ci ."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A probabilistic model of dictionarybased automatic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of RIAO-85, 1st International Conference \u201cRecherche d\u2019Information Assistee par Ordinateur\u201d (Grenoble, France, 1985), 207\u2013216."
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144881417"
                        ],
                        "name": "M. Ruiz",
                        "slug": "M.-Ruiz",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "Ruiz",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ruiz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144684950"
                        ],
                        "name": "P. Srinivasan",
                        "slug": "P.-Srinivasan",
                        "structuredName": {
                            "firstName": "Padmini",
                            "lastName": "Srinivasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Srinivasan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "s implementing a form of logistic regression have also been proposed and tested by Schu\u00a8tze et al. [1995] and Wiener et al. [1995], yielding very good e\ufb00ectiveness. A non-linear NN [Lam and Lee 1999; Ruiz and Srinivasan 1999; Schu\u00a8tze et al. 1995; Weigend et al. 1999; Wiener et al. 1995; Yang and Liu 1999] is instead a networkwith one ormoreadditional \u201clayers\u201dofunits, whichin TC usuallyrepresent higher-order interactions"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "categories of ci, as in the application they work on (TC with hierarchical category sets) the notion of a \u201csibling category of ci\u201d is well-de\ufb01ned. A similar policy is also adopted in [Ng et al. 1997; Ruiz and Srinivasan 1999; Weigend et al. 1999]. By using query zoning plus other enhancements (TSR, statistical phrases, and a method called dynamic feedback optimization), Schapire et al. [1998] have found that a Rocchio cl"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ecision at an internal node. Techniques exploiting this intuition in a TC context have been presented in [Dumais and Chen 2000; Chakrabarti et al. 1998a; Koller and Sahami 1997; McCallum et al. 1998; Ruiz and Srinivasan 1999; Weigend et al. 1999]. 4. THE MACHINE LEARNING APPROACH TO TEXT CATEGORIZATION In the \u201980s the most popular approach (at least in operational settings) for the creation of automatic document classi\ufb01e"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "t 1996; Lewis and Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno 1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladeni\u00b4c 1998; Ruiz and Srinivasan 1999], relevancy score [Wiener et al. 1995], and GSS coe\ufb03cient [Galavotti et al. 2000]. The mathematical de\ufb01nitions of these measures are summarized for convenience in Table 19. Here, probabilities are in"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; Schu\u00a8tze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coe\ufb03cient [Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis 1992a; Lewis and Ringuette 1994; Mladeni\u00b4c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997; Yang and Liu 1999], mutual informat"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60497801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "601a7e59e5591595640b8cbb813d1fbbb6507449",
            "isKey": true,
            "numCitedBy": 129,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-neural-networks-for-text-Ruiz-Srinivasan",
            "title": {
                "fragments": [],
                "text": "Hierarchical neural networks for text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR 1999"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 23
                            }
                        ],
                        "text": "In the TREC community [Lewis 1995c], this is called adaptive \n.l\u00adtering, while the case in which no user\u00adspeci.ed pro.le is available is called ei\u00adther routing or \nbatch .ltering, depending on whether documents have to be ranked in decreasing order of estimated relevance \nor just accepted/rejected."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 135
                            }
                        ],
                        "text": "Utility has become popular within the text .lter\u00ading \ncommunity, and the TREC .ltering track evaluations have been using it for a while [Lewis 1995c]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 22
                            }
                        ],
                        "text": "In the TREC community [Lewis 1995c] this is called adaptive filtering, while the case in which no user-specified profile is available is called either routing or batch filtering, depending on whether documents have to be ranked in decreasing order of estimated relevance or just accepted/rejected."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 137
                            }
                        ],
                        "text": "Utility has become popular within the text filtering community, and the TREC \u201cfiltering track\u201d evaluations have been using it since long [Lewis 1995c]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 184
                            }
                        ],
                        "text": "The former method is possible only in the presence of a theoretical result that in\u00addicates how to compute \nthe threshold that maximizes the expected value of the ef\u00adfectiveness function [Lewis 1995a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The TREC-4 filtering track: description and analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of TREC-4, 4th Text Retrieval Conference (Gaithersburg, US, 1995), pp. 165\u2013180."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "Cohen [1995a] has extensively compared PL and FOL learning in \nTC (for instance, comparing the PL learner RIPPER with its FOL version FLIPPER), and has found that the \nadditional represen\u00adtational power of FOL brings about only modest bene.ts. 6.5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 242
                            }
                        ],
                        "text": "In other words, the semantics of a document is reduced to the collective lexical semantics of the terms that occur in it, thereby disregarding the issue of compositional semantics (an exception are the representation techniques used for Foil [Cohen 1995a] and Sleeping Experts [Cohen and Singer 1999])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 126
                            }
                        ],
                        "text": "In their experiments this technique outper\u00adformed a number of other classi.ers, \nsuch as a C4.5 decision tree classi.er and the RIPPER CNF rule-based classi.er."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 140
                            }
                        ],
                        "text": "Among \nthe DNF rule learners that have been applied to TC are CHARADE [Moulinier and Ganascia 1996], DL-ESC \n[Li and Yamanishi 1999], RIPPER [Cohen 1995a; Cohen and Hirsh 1998; Cohen and Singer 1999], SCAR [Moulinier \net al. 1996], and SWAP-1 [Apt\u00b4 e 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 53
                            }
                        ],
                        "text": "For other examples of significance testing in TC see [Cohen 1995a; Cohen 1995b; Cohen and Hirsh 1998; Joachims 1997; Koller and Sahami 1997; Lewis et al. 1996; Wiener et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 235
                            }
                        ],
                        "text": "\u2026words, \nthe semantics of a document is reduced to the collective lexical semantics of the terms that occur in \nit, thereby disregarding the issue of compositional semantics (an ex\u00adception are the representation techniques \nused for FOIL [Cohen 1995a] and SLEEPING EXPERTS [Cohen and Singer 1999])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 716,
                                "start": 710
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to classify English text with ILP methods"
            },
            "venue": {
                "fragments": [],
                "text": "L. De Raedt Ed., Advances in inductive logic programming , pp. 124\u2013143. Amsterdam, NL: IOS Press."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 148
                            }
                        ],
                        "text": "\u20261996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 386,
                                "start": 371
                            }
                        ],
                        "text": "However, the work by Dumais et al. \n[1998], in which a decision tree classi.er was shown to perform nearly as well as their top performing \nsystem (a SVM classi.er), will probably renew the interest in decision trees, an interest that had dwindled \nafter the unimpres\u00adsive results reported in earlier litera\u00adture [Cohen and Singer 1999; Joachims 1998; \nLewis and Catlett 1994; Lewis and Ringuette 1994]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 32
                            }
                        ],
                        "text": "Joachims [1999]; Lewis [1992a]; Lewis and Ringuette \n[1994]; Moulinier and Ganascia [1996]; Ng et al. [1997]; Yang [1999])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 276
                            }
                        ],
                        "text": "\u2026intermediate between WLC and DCS, is adaptive classi.er \ncombination (ACC), whereby the judgments of all the classi.ers in the com\u00admittee are summed together, \nbut their in\u00addividual contribution is weighted by their effectiveness on the l validation examples most \nsimilar to dj [Li and Jain 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 277
                            }
                        ],
                        "text": "There are two distinct ways of view\u00ading DR, depending on whether the \ntask is performed locally (i.e., for each individual category) or globally: local DR: for each category \nci, a set T lof i terms, with |Ti l|8|T |, is chosen for clas\u00adsi.cation under ci (see Apt\u00b4 e et al. [1994]; \nLewis and Ringuette [1994]; Li and Jain [1998]; Ng et al. [1997]; Sable and Hatzivassiloglou [2000]; \nSch \u00a8 utze et al. [1995], Wiener et al. [1995])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 115
                            }
                        ],
                        "text": "DT text classi.ers have been used either as the main classi.cation \ntool [Fuhr et al. 1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classi.ers \n[Cohen and Singer 1999; Joachims 1998], or as members of classi.er committees [Li and Jain 1998; Schapire \nand Singer 2000; Weiss et al. 1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 227
                            }
                        ],
                        "text": "Another policy \nis dynamic classi.er selection (DCS), whereby among committee {s1, ..., sk }the classi.er st most effective \non the l validation examples most similar to dj is selected, and its judgment adopted by the committee \n[Li and Jain 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 121
                            }
                        ],
                        "text": "A second, popular \nexperimental pol\u00adicy is proportional thresholding [Iwayama and Tokunaga 1995; Larkey 1998; Lewis 1992a; \nLewis and Ringuette 1994; Wiener et al. 1995], also called Pcut in Yang [1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 438,
                                "start": 423
                            }
                        ],
                        "text": "Other more sophis\u00adticated information-theoretic functions have been used in the literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and Srinivasan \n1999], relevancy score [Wiener et al. 1995], and GSS coef.cient [Galavotti et al. 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 232
                            }
                        ],
                        "text": "The simplest one \nis majority voting (MV), whereby the binary outputs of the k classi.ers are pooled together, and the \nclassi.cation decision that reaches the 1 majority of k+votes is taken (k obviously 2 needs to be an \nodd number) [Li and Jain 1998; Liere and Tadepalli 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 267
                            }
                        ],
                        "text": "\u2026is adopted by many authors, who remove all terms occurring in at most x train\u00ading documents \n(popular values for x range from 1 to 3), either as the only form of DR [Maron 1961; Ittner et al. 1995] \nor before applying another more sophisticated form [Dumais et al. 1998; Li and Jain 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 677,
                                "start": 662
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 75
                            }
                        ],
                        "text": "TC efforts based \non ex\u00adperimental DT packages include Dumais et al. [1998], Lewis and Ringuette [1994], and Weiss et al. \n[1999]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 229
                            }
                        ],
                        "text": "\u2026have been used either as the main classi.cation \ntool [Fuhr et al. 1991; Lewis and Catlett 1994; Lewis and Ringuette 1994], or as baseline classi.ers \n[Cohen and Singer 1999; Joachims 1998], or as members of classi.er committees [Li and Jain 1998; Schapire \nand Singer 2000; Weiss et al. 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Classification of text documents. The Computer Journal 41"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 153
                            }
                        ],
                        "text": "T l global DR: a set T l of terms, \nwith |T l|8|T |, is chosen for the classi.ca\u00adtion under all categories C ={c1, ..., c|C|}(see Caropreso \net al. [2001]; Mladenic\u00b4[1998]; Yang [1999]; Yang and Pedersen [1997])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 146
                            }
                        ],
                        "text": "\u2026decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 70
                            }
                        ],
                        "text": "Among \nthe DNF rule learners that have been applied to TC are CHARADE [Moulinier and Ganascia 1996], DL-ESC \n[Li and Yamanishi 1999], RIPPER [Cohen 1995a; Cohen and Hirsh 1998; Cohen and Singer 1999], SCAR [Moulinier \net al. 1996], and SWAP-1 [Apt\u00b4 e 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 124
                            }
                        ],
                        "text": "Var\u00adious experimental comparisons \nof TSR functions have thus been carried out [Caropreso et al. 2001; Galavotti et al. 2000; Mladeni\u00b4 c \n1998; Yang and Pedersen 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 456,
                                "start": 449
                            }
                        ],
                        "text": "Other more sophis\u00adticated information-theoretic functions have been used in the literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and Srinivasan \n1999], relevancy score [Wiener et al. 1995], and GSS coef.cient [Galavotti et al. 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "\u2026\n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 191
                            }
                        ],
                        "text": "It is likely that the .nal word on the usefulness of phrase \nindexing in TC has still to be told, and investigations in this direction are still being actively pursued \n[Caropreso et al. 2001; Mladeni\u00b4 c and Grobelnik 1998]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 747,
                                "start": 740
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 97
                            }
                        ],
                        "text": "Of course, stop words need to be removed in advance, lest only topic-neutral \nwords are retained [Mladeni\u00b4 c 1998]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "statistical, and symbolic approaches to learning for natural language processing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797501"
                        ],
                        "name": "K. Low",
                        "slug": "K.-Low",
                        "structuredName": {
                            "firstName": "Kon",
                            "lastName": "Low",
                            "middleNames": [
                                "Fan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Low"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793347"
                        ],
                        "name": "C. Y. Ho",
                        "slug": "C.-Y.-Ho",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Ho",
                            "middleNames": [
                                "Yang"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Y. Ho"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 83
                            }
                        ],
                        "text": "Among these, the most noteworthy are the ones based on Bayesian inference networks [Dumais et al. 1998; Lam et al. 1997; Tzeras and Hartmann 1993], genetic algorithms [Clack et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 128
                            }
                        ],
                        "text": "MH committee \ncommittee [Schapire and Singer 2000] [Weiss et al. 1999] .860 .878 Bayesian net Bayesian net [Dumais \net al. 1998] [Lam et al. 1997] .542 (MF1) .800 .850 and Pedersen [1997].21 The documents are titles \nor title-plus-abstracts from medical journals (OHSUMED is actually a subset of the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "Among these, the most noteworthy are the ones based on Bayesian inference networks [Dumais et al. 1998; \nLam et al. 1997; Tzeras and Hartmann 1993], genetic algorithms [Clack et al. 1997; Masand 1994], and \nmaximum entropy modelling [Manning and Sch utze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 142
                            }
                        ],
                        "text": "\u2026BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 365,
                                "start": 165
                            }
                        ],
                        "text": "2001; Larkey 1998; Lewis 1992a; Lewis and Ringuette 1994; Mladeni\u0107 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997; Yang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis and Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno 1999; Yang and Pedersen 1997], odds ratio [Caropreso et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 41005577,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c58a1f7238bd8c334e78779e505ef1a38da7e0d",
            "isKey": true,
            "numCitedBy": 34,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Using-a-Bayesian-Network-Induction-Approach-for-Lam-Low",
            "title": {
                "fragments": [],
                "text": "Using a Bayesian Network Induction Approach for Text Categorization"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1988453"
                        ],
                        "name": "R. Bekkerman",
                        "slug": "R.-Bekkerman",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Bekkerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bekkerman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 0
                            }
                        ],
                        "text": "[Attardi et al. 1999; Baker and McCallum 1998; Chakrabarti et al. 1998; McCallum et al. 1998; Mladeni\u0107 1998b]), and will be more extensively discussed in Section 9."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 65
                            }
                        ],
                        "text": "\u2014the 20 Newsgroups collection, set up by Lang [1995] and used in [Baker and McCallum 1998; Joachims 1997; McCallum and Nigam 1998; McCallum et al. 1998; Nigam et al. 1998; Schapire and Singer 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 3
                            }
                        ],
                        "text": "in [Baker and McCallum 1998; Cohen and Hirsch 1998; Guthrie et al. 1994; Koller and Sahami 1997; Joachims 1997; Larkey 1999; Li and Jain 1998; Moulinier and Ganascia 1996; Sch\u00fctze et al. 1995]) is often called the single-label case (or the non-overlapping categories case), whereas the general case in which any number of categories from 0 to m may be assigned to the same document is dubbed the multi-label case."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 135
                            }
                        ],
                        "text": "One possible answer is to switch from an interpretation of Na\u00a8ive Bayes in which documents are events \nto one in which terms are events [Baker and McCallum 1998; McCallum et al. 1998; Chakrabarti et al. 1998a; \nGuthrie et al. 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "[Baker and McCallum 1998]), the recent tendency is to adopt it (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60153502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "537f9485dfb8b3da498880fb4611b249c9afdd95",
            "isKey": true,
            "numCitedBy": 38,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Distributional-clustering-of-words-for-text-Bekkerman",
            "title": {
                "fragments": [],
                "text": "Distributional clustering of words for text categorization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 74
                            }
                        ],
                        "text": "Joachims [1999]; Lewis [1992a]; Lewis and Ringuette \n[1994]; Moulinier and Ganascia [1996]; Ng et al. [1997]; Yang [1999])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 146
                            }
                        ],
                        "text": "\u2026decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 205
                            }
                        ],
                        "text": "Among \nthe DNF rule learners that have been applied to TC are CHARADE [Moulinier and Ganascia 1996], DL-ESC \n[Li and Yamanishi 1999], RIPPER [Cohen 1995a; Cohen and Hirsh 1998; Cohen and Singer 1999], SCAR [Moulinier \net al. 1996], and SWAP-1 [Apt\u00b4 e 1994]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 484,
                                "start": 478
                            }
                        ],
                        "text": "Other more sophis\u00adticated information-theoretic functions have been used in the literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain [Caropreso et al. 2001; Larkey 1998; Lewis \n1992a; Lewis and Ringuette 1994; Mladeni\u00b4 c 1998; Moulinier and Ganascia 1996; Yang and Pedersen 1997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001; Mladenic\u00b41998; Ruiz and Srinivasan \n1999], relevancy score [Wiener et al. 1995], and GSS coef.cient [Galavotti et al. 2000]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 142
                            }
                        ],
                        "text": "\u20261997, \nYang and Liu 1999], mutual information [Dumais et al. 1998; Lam et al. 1997; Larkey and Croft 1996; Lewis \nand Ringuette 1994; Li and Jain 1998; Moulinier et al. 1996; Ruiz and Srinivasan 1999; Taira and Haruno \n1999; Yang and Pedersen 1997], odds ratio [Caropreso et al. 2001;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 958,
                                "start": 952
                            }
                        ],
                        "text": "#4 #5 # of documents # of training documents # of test documents # of categories 21,450 14,704 \n6,746 135 14,347 10,667 3,680 93 13,2729,610 3,662 92 12,902 9,603 3,299 90 12,902 9,603 3,299 10 System \nType Results reported by WORD (non-learning) Yang [1999] .150 .310 .290 PROPBAYES BIM NB probabilistic \nprobabilistic probabilistic probabilistic probabilistic probabilistic probabilistic [Dumais et al. 1998] \n[Joachims 1998] [Lam et al. 1997] [Lewis 1992a] [Li and Yamanishi 1999] [Li and Yamanishi 1999] [Yang \nand Liu 1999] .443 (MF1) .650 .752 .720 .747 .773 .795 .815 C4.5 IND decision trees decision trees decision \ntrees [Dumais et al. 1998] [Joachims 1998] [Lewis and Ringuette 1994] .670 .794 .884 SWAP-1 RIPPER SLEEPINGEXPERTS \nDL-ESC CHARADE CHARADE decision rules decision rules decision rules decision rules decision rules decision \nrules [Apt\u00b4e et al. 1994] [Cohen and Singer 1999] [Cohen and Singer 1999] [Li and Yamanishi 1999] [Moulinier \nand Ganascia 1996] [Moulinier et al. 1996] .683 .753 .805 .811 .759 .738 .783 (F1) .820 .827 .820 LLSF \nLLSF regression regression [Yang 1999] [Yang and Liu 1999] .855 .810 .849 BALANCEDWINNOW WIDROW-HOFF \non-line linear on-line linear [Dagan et al. 1997] [Lam and Ho 1998] .747 (M) .833 (M) .822 ROCCHIO FINDSIM \nROCCHIO ROCCHIO ROCCHIO batch linear batch linear batch linear batch linear batch linear [Cohen and Singer \n1999] [Dumais et al. 1998] [Joachims 1998] [Lam and Ho 1998] [Li and Yamanishi 1999] .660 .748 .776 .617 \n.799 .781 .625 .646 CLASSI NNET neural network neural network neural network [Ng et al. 1997] Yang and \nLiu 1999] [Wiener et al. 1995] .802 .820 .838 GIS-W k-NN k-NN k-NN k-NN example-based example-based example-based \nexample-based example-based [Lam and Ho 1998] [Joachims 1998] [Lam and Ho 1998] [Yang 1999] [Yang and \nLiu 1999] .690 .852 .820 .860 .823 .820 .856 SVMLIGHT SVMLIGHT SVMLIGHT SVM SVM SVM SVM [Dumais et al. \n1998] [Joachims 1998] [Li Yamanishi 1999] [Yang and Liu 1999] .870 .864 .841 .859 .920 ADABOOST."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text categorization: a symbolic approach"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of SDAIR-96, 5th Annual Symposium on Document Analysis and Information Retrieval (Las Vegas, US,"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145606490"
                        ],
                        "name": "Ewan Klein",
                        "slug": "Ewan-Klein",
                        "structuredName": {
                            "firstName": "Ewan",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ewan Klein"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 196062327,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72324e26cddab0792986dc8357e2459afec7ae5e",
            "isKey": false,
            "numCitedBy": 118,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Proceedings-of-the-38th-Annual-Meeting-of-the-for-Klein",
            "title": {
                "fragments": [],
                "text": "Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2000"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127759"
                        ],
                        "name": "B. Masand",
                        "slug": "B.-Masand",
                        "structuredName": {
                            "firstName": "Brij",
                            "lastName": "Masand",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Masand"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60743047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ab459fa129321f16ad1bfcb71d796bcc3b12e2e",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimizing-confidence-of-text-classification-by-of-Masand",
            "title": {
                "fragments": [],
                "text": "Optimizing confidence of text classification by evolution of symbolic expressions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121300608"
                        ],
                        "name": "J. Allan",
                        "slug": "J.-Allan",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Allan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Allan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60250556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ed22fb29a43401238928cd0c2dcc21e317211a5a",
            "isKey": false,
            "numCitedBy": 506,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Readings-in-information-retrieval.-Allan",
            "title": {
                "fragments": [],
                "text": "Readings in information retrieval."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2365155"
                        ],
                        "name": "S. Deerwester",
                        "slug": "S.-Deerwester",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Deerwester",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Deerwester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728602"
                        ],
                        "name": "S. Dumais",
                        "slug": "S.-Dumais",
                        "structuredName": {
                            "firstName": "Susan",
                            "lastName": "Dumais",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dumais"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2737579"
                        ],
                        "name": "G. Furnas",
                        "slug": "G.-Furnas",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Furnas",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Furnas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836606"
                        ],
                        "name": "T. Landauer",
                        "slug": "T.-Landauer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Landauer",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Landauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3154682"
                        ],
                        "name": "R. Harshman",
                        "slug": "R.-Harshman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Harshman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Harshman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60140915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22d61ddf11847dfc5442fd024eb0c86e0bdad852",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Indexing-by-latent-semantic-indexing-Deerwester-Dumais",
            "title": {
                "fragments": [],
                "text": "Indexing by latent semantic indexing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102639698"
                        ],
                        "name": "Alberto D\u00edaz",
                        "slug": "Alberto-D\u00edaz",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "D\u00edaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alberto D\u00edaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732997"
                        ],
                        "name": "M. Rodr\u00edguez",
                        "slug": "M.-Rodr\u00edguez",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Rodr\u00edguez",
                            "middleNames": [
                                "de",
                                "Buenaga"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rodr\u00edguez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145200121"
                        ],
                        "name": "L. A. U. L\u00f3pez",
                        "slug": "L.-A.-U.-L\u00f3pez",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "L\u00f3pez",
                            "middleNames": [
                                "Alfonso",
                                "Ure\u00f1a"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. U. L\u00f3pez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470500"
                        ],
                        "name": "M. Vega",
                        "slug": "M.-Vega",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Vega",
                            "middleNames": [
                                "Garc\u00eda"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Vega"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59641042,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c81ca7ff3c17acad97c649503eadd808f2ea4499",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Integrating-linguistic-resources-in-a-uniform-way-D\u00edaz-Rodr\u00edguez",
            "title": {
                "fragments": [],
                "text": "Integrating linguistic resources in a uniform way for Text classification tasks"
            },
            "venue": {
                "fragments": [],
                "text": "LREC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144610645"
                        ],
                        "name": "P. Willett",
                        "slug": "P.-Willett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Willett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Willett"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59677079,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c83feccb07558d7196d8aee630eb844d9cb7db69",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Document-Retrieval-Systems-Willett",
            "title": {
                "fragments": [],
                "text": "Document Retrieval Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116424847"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056561918"
                        ],
                        "name": "Daniel L. Stern",
                        "slug": "Daniel-L.-Stern",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Stern",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel L. Stern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145163573"
                        ],
                        "name": "A. Singhal",
                        "slug": "A.-Singhal",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singhal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "[Lewis et al. 1999]), thanks to a by now consolidated body of literature rooted in a solid experimental methodology."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209397718,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c101158de3c54f42bb90c8e671ea7b198c7c6e54",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ATTICS:-A-Software-Platform-for-Online-Text-(poster-Lewis-Stern",
            "title": {
                "fragments": [],
                "text": "ATTICS: A Software Platform for Online Text Classification (poster abstract)."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR 1999"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35211746"
                        ],
                        "name": "David A. Hull",
                        "slug": "David-A.-Hull",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Hull",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Hull"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the TREC community [Lewis 1995c; Hull 1998] this is called adaptive filtering, while the case in which no user-specified profile is available is called either routing or batch filtering, depending on whether documents have to be ranked in decreasing order of estimated relevance or just accepted/rejected."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "As a matter of fact, utility is being more and more used within the text filtering community, as the TREC \u201cfiltering track\u201d evaluations have recently been using utility measures [Lewis 1995c; Hull 1998]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195346649,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a4b59f50e06a56c265ee3d19765c3709cef34fb",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-TREC-7-Filtering-Track:-Description-and-Hull",
            "title": {
                "fragments": [],
                "text": "The TREC-7 Filtering Track: Description and Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "TREC"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816797"
                        ],
                        "name": "H. Fangmeyer",
                        "slug": "H.-Fangmeyer",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Fangmeyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Fangmeyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084356644"
                        ],
                        "name": "G. Lustig",
                        "slug": "G.-Lustig",
                        "structuredName": {
                            "firstName": "Gerhard",
                            "lastName": "Lustig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lustig"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The first use to which automatic text classifiers were put at, and the application that spawned most of the early research in the field [Borko and Bernick 1963; Fangmeyer and Lustig 1968; Field 1975; Gray and Harley 1971; Hamill and Zamora 1978; Hamill and Zamora 1980; Heaps 1973; Hoyle 1973; Klingbiel 1973a; Klingbiel 1973b; Maron 1961], is that of automatic document indexing for use in information retrieval (IR) systems relying on a controlled dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29773175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15f7caf65e1460916198d9eb1e4c9c112cd64d92",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-EURATOM-automatic-indexing-project-Fangmeyer-Lustig",
            "title": {
                "fragments": [],
                "text": "The EURATOM automatic indexing project"
            },
            "venue": {
                "fragments": [],
                "text": "IFIP Congress"
            },
            "year": 1968
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145428001"
                        ],
                        "name": "P. Hayes",
                        "slug": "P.-Hayes",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Hayes",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hayes"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 28937823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e8275ba4bdb61039903c8ca29e1bb9ab77ce63e",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Guest-Editorial-Special-Issue-on-Text-Lewis-Hayes",
            "title": {
                "fragments": [],
                "text": "Guest Editorial - Special Issue on Text Categorization"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Inf. Syst."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149443075"
                        ],
                        "name": "Kwok Leung Yu",
                        "slug": "Kwok-Leung-Yu",
                        "structuredName": {
                            "firstName": "Kwok",
                            "lastName": "Yu",
                            "middleNames": [
                                "Leung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwok Leung Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144594306"
                        ],
                        "name": "Wai Lam",
                        "slug": "Wai-Lam",
                        "structuredName": {
                            "firstName": "Wai",
                            "lastName": "Lam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wai Lam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 6751887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ae4c7313a8addce164aa63ebb6dd068f58ce0b8",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-new-on-line-learning-algorithm-for-adaptive-text-Yu-Lam",
            "title": {
                "fragments": [],
                "text": "A new on-line learning algorithm for adaptive text filtering"
            },
            "venue": {
                "fragments": [],
                "text": "CIKM '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095083"
                        ],
                        "name": "N. Belkin",
                        "slug": "N.-Belkin",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Belkin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Belkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144456145"
                        ],
                        "name": "W. Bruce Croft",
                        "slug": "W.-Bruce-Croft",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Croft",
                            "middleNames": [
                                "Bruce"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bruce Croft"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 165
                            }
                        ],
                        "text": "Text filtering is the activity of classifying a stream of incoming documents dispatched in an asynchronous way by an information producer to an information consumer [Belkin and Croft 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 180
                            }
                        ],
                        "text": "Text \nFiltering Text .ltering is the activity of classify\u00ading a stream of incoming documents dis\u00adpatched in \nan asynchronous way by an information producer to an information consumer [Belkin and Croft 1992]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14679722,
            "fieldsOfStudy": [
                "Computer Science",
                "Geology"
            ],
            "id": "69a5dba45472d34ba7246d6eb9065b5dad5ca51d",
            "isKey": false,
            "numCitedBy": 1499,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Information filtering systems are designed for unstructured or semistructured data, as opposed to database applications, which use very structured data. The systems also deal primarily with textual information, but they may also entail images, voice, video or other data types that are part of multimedia information systems. Information filtering systems also involve a large amount of data and streams of incoming data, whether broadcast from a remote source or sent directly by other sources. Filtering is based on descriptions of individual or group information preferences, or profiles, that typically represent long-term interests. Filtering also implies removal of data from an incoming stream rather than finding data in the stream; users see only the data that is extracted. Models of information retrieval and filtering, and lessons for filtering from retrieval research are presented."
            },
            "slug": "Information-filtering-and-information-retrieval:-of-Belkin-Croft",
            "title": {
                "fragments": [],
                "text": "Information filtering and information retrieval: two sides of the same coin?"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Models of information retrieval and filtering, and lessons for filtering from retrieval research are presented; users see only the data that is extracted."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 289
                            }
                        ],
                        "text": "2000; Schapire and Singer 2000], multimedia document categorization through the analysis of textual captions [Sable and Hatzivassiloglou 2000], author identification for literary texts of unknown or disputed authorship [Forsyth 1999], language identification for texts of unknown language [Cavnar and Trenkle 1994], automated identification of text genre [Kessler et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 148
                            }
                        ],
                        "text": "\u20262000], author \niden\u00adti.cation for literary texts of unknown or disputed authorship [Forsyth 1999], lan\u00adguage identi.cation \nfor texts of unknown language [Cavnar and Trenkle 1994], automated identi.cation of text genre [Kessler \net al. 1997], and automated essay grading [Larkey 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "N-grambased text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval (Las Vegas, NV, 1994), 161\u2013175."
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 35
                            }
                        ],
                        "text": "1997], or as a baseline classifier [Cohen and Singer 1999; Fuhr et al. 1998; Galavotti 1999; Joachims 1998; Lewis et al. 1996; Schapire and Singer 2000; Sch\u00fctze et al. 1995], or as a member of a classifier committee [Larkey and Croft 1996] (see Section 6."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 53
                            }
                        ],
                        "text": "So far, only the comparative evaluations reported in [Galavotti 1999; Yang and Pedersen 1997] seem conclusive in this respect."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Un sistema modulare per la classificazione di testi basato sull\u2019apprendimento automatico"
            },
            "venue": {
                "fragments": [],
                "text": "Master\u2019s thesis, Dipartimento di Informatica, Universit\u00e0 di Pisa, Pisa, IT."
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to classify English text with ILP methods Advances in inductive logic programming"
            },
            "venue": {
                "fragments": [],
                "text": "Learning to classify English text with ILP methods Advances in inductive logic programming"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 76
                            }
                        ],
                        "text": "Techniques exploiting this intuition in a TC context have been presented in [Attardi et al. 1998; Chakrabarti et al. 1998b; F\u00fcrnkranz 1999; G\u00f6vert et al. 1999; Oh et al. 2000] and experimentally compared in [Yang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorization by context"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Universal Computer Science 4, 9, 719\u2013736."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text classification with selforganizing maps: Some lessons learned"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing 21, 1/3, 61\u201377."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 35
                            }
                        ],
                        "text": "1997], or as a baseline classifier [Cohen and Singer 1999; Fuhr et al. 1998; Galavotti 1999; Joachims 1998; Lewis et al. 1996; Schapire and Singer 2000; Sch\u00fctze et al. 1995], or as a member of a classifier committee [Larkey and Croft 1996] (see Section 6."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "Although tfidf is by far the most popular one, other indexing functions have also been used, including probabilistic indexing methods [Fuhr et al. 1998] or techniques for indexing structured documents [Larkey and Croft 1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorisation tool: Final prototype"
            },
            "venue": {
                "fragments": [],
                "text": "Deliverable 4.3, Project LE4-8303 \u201cEUROSEARCH\u201d, Commission of the European Communities, 1999."
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 147
                            }
                        ],
                        "text": "\u2026value for which \nn and P are closest, and an interpolated breakeven is computed as the average of the values of n and \nP.19 (3) The Ff function [van Rijsbergen 1979, Chapter 7], for some 0 :f:+. (e.g., Cohen [1995a]; Cohen \nand Singer [1999]; Lewis and Gale [1994]; Lewis [1995a]; Moulinier et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval, 2nd ed"
            },
            "venue": {
                "fragments": [],
                "text": "Butterworths, London, UK. Available at http://www.dcs.gla.ac.uk/Keith."
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 162
                            }
                        ],
                        "text": "(2) |T | s=1(t.df (ts, dj ))2 Although \nnormalized t.df is the most popular one, other indexing functions have also been used, including proba\u00adbilistic \ntechniques [G\u00a8 overt et al. 1999] or techniques for indexing structured docu\u00adments [Larkey and Croft \n1996]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A probabillistic description-oriented approach for categorising Web documents"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CIKM-99, 8th ACM International Conference on Information and Knowledge Management"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorization by context"
            },
            "venue": {
                "fragments": [],
                "text": "J. Univers. Comput. Sci"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Categorisation tool: Final prototype. Deliverable 4.3, Project LE4-8303"
            },
            "venue": {
                "fragments": [],
                "text": "Commission of the European Communities"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u00b7"
            },
            "venue": {
                "fragments": [],
                "text": "\u00b7"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization \u00b7 57"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization \u00b7 57"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An improved boosting algorithm and its application to automated text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CIKM-00, 9th ACM International Conference on Information and Knowledge Management"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "N-grambased text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization \u00b7 55"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization \u00b7 55"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 78
                            }
                        ],
                        "text": "Although two international journals have devoted special issues to this topic [Joachims and Sebastiani 2001; Lewis and Hayes 1994], there are almost no systematic treatments of the subject: there are neither textbooks nor journals entirely devoted to TC yet, and [Manning and Sch\u00fctze 1999] is the only chapter-length treatment of the subject."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Special issue on text categorization: Guest editorial"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Intelligent Information Systems. Forthcoming."
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM International Conference on Information and Knowledge Management"
            },
            "venue": {
                "fragments": [],
                "text": "ACM International Conference on Information and Knowledge Management"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Un sistema modulare per la classificazione di testi basato sull'apprendimento automatico. Master's thesis"
            },
            "venue": {
                "fragments": [],
                "text": "Un sistema modulare per la classificazione di testi basato sull'apprendimento automatico. Master's thesis"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization \u00b7 59"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization \u00b7 59"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Development in Information Retrieval"
            },
            "venue": {
                "fragments": [],
                "text": "Development in Information Retrieval"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 154
                            }
                        ],
                        "text": "Unlike other types of classifiers, the literature on probabilistic classifiers is inextricably intertwined with that on probabilistic search systems (see [Crestani et al. 1998] for a review), since these latter attempt to determine the probability that a document falls in the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Is this document relevant"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Computing Surveys"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 215
                            }
                        ],
                        "text": "Within the TC literature, one example of a batch induction method is linear discriminant analysis, a model of the stochastic dependence between terms that relies on the covariance matrices of the various categories [Blosseville et al. 1992; Hull 1994; Sch\u00fctze et al. 1995]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic document classification: natural langage processing and expert system techniques used together"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SIGIR-92, 15th ACM International Conference on Research and Development in Information Retrieval (Kobenhavn, DK, 1992), pp. 51\u201357."
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorisation \u00b7 61"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorisation \u00b7 61"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text classification with selforganizing maps: Some lessons learned"
            },
            "venue": {
                "fragments": [],
                "text": "Neurocomputing"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 187
                            }
                        ],
                        "text": "Among these, the most noteworthy are the ones based on Bayesian inference networks [Dumais et al. 1998; \nLam et al. 1997; Tzeras and Hartmann 1993], genetic algorithms [Clack et al. 1997; Masand 1994], and \nmaximum entropy modelling [Manning and Sch utze 1999]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimising confidence of text classification by evolution of symbolic expressions Advances in genetic programming"
            },
            "venue": {
                "fragments": [],
                "text": "Optimising confidence of text classification by evolution of symbolic expressions Advances in genetic programming"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 251,
                                "start": 237
                            }
                        ],
                        "text": "\u2026based on a controlled vocabulary, \nto document .ltering, automated metadata generation, word sense disambiguation, population of Author \ns address: Istituto di Elaborazione dell Informazione, Consiglio Nazionale delle Ricerche, Via G. Moruzzi \n1, 56124 Pisa, Italy; e-mail: fabrizio@iei.pi.cnr.it."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information extraction. Number 1299 in Lecture Notes in Computer Science"
            },
            "venue": {
                "fragments": [],
                "text": "Information extraction. Number 1299 in Lecture Notes in Computer Science"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The TREC-4 filtering track: description and analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of TREC-4, 4th Text Retrieval Conference"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "it is often the 'little' words that give an author away (for example, the relative frequencies of words like because or though)"
            },
            "venue": {
                "fragments": [],
                "text": "it is often the 'little' words that give an author away (for example, the relative frequencies of words like because or though)"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization 45 Proceedings of ICML-97, Proceedings of ICML-97, 14th International Conference on Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning in Automated Text Categorization 45 Proceedings of ICML-97, Proceedings of ICML-97, 14th International Conference on Machine Learning"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A probabilistic model of dictionarybased automatic indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of RIAO-85, 1st International Conference"
            },
            "year": 1985
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 73
                            }
                        ],
                        "text": "The application that has spawned most of the early research in the field [Borko and Bernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961] is that of automatic document indexing for IR systems relying on a controlled dictionary, the most prominent example of which is Boolean systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "\u2026Boolean Information \nRetrieval Systems The application that has spawned most of the early research in the .eld [Borko and \nBernick 1963; Field 1975; Gray and Harley 1971; Heaps 1973; Maron 1961] is that of automatic document \nindexing for IR systems relying on a controlled dictionary, the most\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computerassisted indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inform. Storage Retrieval 7, 4, 167\u2013174."
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 339,
                                "start": 136
                            }
                        ],
                        "text": "The first use to which automatic text classifiers were put at, and the application that spawned most of the early research in the field [Borko and Bernick 1963; Fangmeyer and Lustig 1968; Field 1975; Gray and Harley 1971; Hamill and Zamora 1978; Hamill and Zamora 1980; Heaps 1973; Hoyle 1973; Klingbiel 1973a; Klingbiel 1973b; Maron 1961], is that of automatic document indexing for use in information retrieval (IR) systems relying on a controlled dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An automatic document classification system using pattern recognition techniques"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ASIS-78, 41st Annual Meeting of the American Society for Information Science (New York, US, 1978), pp. 152\u2013155."
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computerassisted indexing"
            },
            "venue": {
                "fragments": [],
                "text": "Inform. Storage Retrieval"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 147
                            }
                        ],
                        "text": "\u2026value for which \nn and P are closest, and an interpolated breakeven is computed as the average of the values of n and \nP.19 (3) The Ff function [van Rijsbergen 1979, Chapter 7], for some 0 :f:+. (e.g., Cohen [1995a]; Cohen \nand Singer [1999]; Lewis and Gale [1994]; Lewis [1995a]; Moulinier et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Information Retrieval (Second ed.). Butterworths, London, UK. Available at http://www.dcs.gla.ac.uk/Keith"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Text categorization: a symbolic approach"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of SDAIR-96, 5th Annual Symposium on Document Analysis and Information Retrieval"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sebastiani"
            },
            "venue": {
                "fragments": [],
                "text": "Sebastiani"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 339,
                                "start": 136
                            }
                        ],
                        "text": "The first use to which automatic text classifiers were put at, and the application that spawned most of the early research in the field [Borko and Bernick 1963; Fangmeyer and Lustig 1968; Field 1975; Gray and Harley 1971; Hamill and Zamora 1978; Hamill and Zamora 1980; Heaps 1973; Hoyle 1973; Klingbiel 1973a; Klingbiel 1973b; Maron 1961], is that of automatic document indexing for use in information retrieval (IR) systems relying on a controlled dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic indexing and generation of classification by algorithm"
            },
            "venue": {
                "fragments": [],
                "text": "Information Storage and Retrieval 9, 4, 233\u2013242."
            },
            "year": 1973
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Received December ACM Computing Surveys"
            },
            "venue": {
                "fragments": [],
                "text": "Received December ACM Computing Surveys"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 150
                            }
                        ],
                        "text": "\u2026literature, among them \nthe DIA association factor [Fuhr et al. 1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; \nSch \u00a8 utze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coef.cient \n[Ng et al. 1997; Ruiz and Srinivasan 1999], information gain\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 18
                            }
                        ],
                        "text": "1991], chi-square [Caropreso et al. 2001; Galavotti et al. 2000; Sch\u00fctze et al. 1995; Sebastiani et al. 2000; Yang and Pedersen 1997; Yang and Liu 1999], NGL coefficient [Ng et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An improved boosting algorithm and its application to automated text categorization"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of CIKM-00, 9th ACM International Conference on Information and Knowledge Management (McLean, US, 2000), pp. 78\u201385."
            },
            "year": 2000
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 64,
            "methodology": 53,
            "result": 5
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 224,
        "totalPages": 23
    },
    "page_url": "https://www.semanticscholar.org/paper/Machine-learning-in-automated-text-categorization-Sebastiani/6b20af22b0734757d9ead382b201a65f9dd637cc?sort=total-citations"
}